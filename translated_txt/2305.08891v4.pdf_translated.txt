--- ABSTRACT ---
우리는 일반적인 확산 노이즈 일정이 마지막 타임스텝이 신호 대 잡음비(SNR) 0이 되도록 강제하지 않으며, 확산 샘플러의 일부 구현이 마지막 타임스텝에서 시작하지 않는다는 것을 발견했습니다. 이러한 설계에는 결함이 있으며 추론 시 모델에 순수한 가우시안 노이즈가 제공되어 학습과 추론 간에 불일치가 발생한다는 사실을 반영하지 않습니다. 우리는 결함이 있는 설계가 기존 구현에서 실제 문제를 일으킨다는 것을 보여줍니다. 안정적 확산에서 이는 모델이 중간 밝기의 이미지만 생성하도록 심각하게 제한하고 매우 밝고 어두운 샘플을 생성하지 못하게 합니다. 우리는 몇 가지 간단한 수정 사항을 제안합니다. (1) 노이즈 일정을 재조정하여 터미널 SNR 0을 강제합니다. (2) v 예측으로 모델을 학습합니다. (3) 샘플러를 변경하여 항상 마지막 타임스텝에서 시작합니다. (4) 과다 노출을 방지하기 위해 분류기 없는 안내를 재조정합니다. 이러한 간단한 변경 사항은 확산 프로세스가 학습과 추론 사이에서 일치하도록 보장하고 모델이 원래 데이터 분포에 더 충실한 샘플을 생성할 수 있도록 합니다. 1.
--- METHOD ---
s 3.1. 0 터미널 SNR 적용 표 1은 일반적인 스케줄 정의와 터미널 타임스텝 T = 1000에서의 SNR(T) 및 √ā를 보여줍니다. 어떤 스케줄도 터미널 SNR이 0이 아닙니다. 게다가 코사인 스케줄은 터미널 SNR이 0에 도달하는 것을 방지하기 위해 ẞt를 의도적으로 0.999보다 크지 않도록 잘라냅니다. 안정적 확산에서 사용하는 노이즈 스케줄에 특히 결함이 있음을 알 수 있습니다. 터미널 SNR은 0에 도달하기에는 거리가 멉니다. 이 값을 방정식(4)에 대입하면 최종 타임스텝에서 신호가 완전히 파괴되기에는 거리가 멀다는 것도 알 수 있습니다. XT = 0.068265 x0 +0.997667 · € = (10) 이는 효과적으로 학습과 추론 사이에 갭을 만듭니다. 학습 시 t T일 때 모델에 대한 입력은 완전히 순수한 노이즈가 아닙니다. 소량의 신호가 여전히 포함됩니다. 누출된 신호에는 각 채널의 전체 평균과 같은 가장 낮은 주파수 정보가 포함됩니다. 이후 모델은 누출된 신호의 평균을 존중하여 잡음을 제거하는 방법을 학습합니다. 추론 시 대신 샘플링을 위해 순수한 가우시안 잡음이 제공됩니다. 가우시안 잡음은 항상 평균이 0이므로 모델은 t = T에서 주어진 평균에 따라 샘플을 계속 생성하여 중간 밝기의 이미지를 생성합니다. 반면, 터미널 SNR이 0인 잡음 일정은 학습 중 t = T에서 순수 잡음을 입력으로 사용하므로 추론 동작과 일치합니다. 동일한 문제가 일반적으로 모든 확산 잡음 일정에 외삽되지만 다른 일정의 터미널 SNR은 0에 더 가까워서 실제로 알아차리기 어렵습니다. 우리는 확산 잡음 일정이 학습과 추론 간의 불일치를 완전히 제거하기 위해 터미널 SNR을 0으로 강제해야 한다고 주장합니다. 이는 또한 분산 폭발 공식[17]이 실제로 터미널 SNR을 0으로 만들 수 없기 때문에 분산 보존 공식을 사용해야 함을 의미합니다. 우리는 분산 보존 공식에서 기존 잡음 일정을 재조정하여 터미널 SNR을 0으로 강제하는 간단한 해결책을 제안합니다. 영어: 방정식 (4)에서 √√āt가 혼합할 신호의 양을 제어한다는 것을 상기하십시오. 아이디어는 √√₁을 변경하지 않고 √를 0으로 변경하고 중간 t = [2, ..., T-1]에 대해 √√t를 선형적으로 재조정하는 것입니다. √āt 공간에서 스케줄을 조정하면 SNR(t) 공간에서 조정하는 것보다 곡선을 더 잘 보존할 수 있음을 발견했습니다. PyTorch 구현은 알고리즘 1에 나와 있습니다. 제안된 재조정 방법은 기존의 비코사인 스케줄을 수정하는 데만 필요합니다. 코사인 스케줄은 간단히 ẞt 클리핑을 제거하여 0 터미널 SNR을 달성할 수 있습니다. 향후 설계되는 스케줄은 ẞÃ = 1을 보장하여 0 터미널 SNR을 달성해야 합니다. 스케줄 선형 [3] 코사인 [8] 안정 확산 [10] 정의 (i = 1) ẞt ẞt = . 0.0001 (1 − i) + 0.02 ⋅ i min(1, 0.999), āt = f(t) f(0), f(t) = cos(+0.1+0.ẞt = (√0.00085. (1 − i) + √0.012 · į)² SNR(T) 4.035993e-)2 2.428735e-0.0.4.928220e-0.표 1. 일반적인 일정 정의와 마지막 시간 단계의 SNR 및 √ā. 모든 일정은 전체 시간 단계 T = 1000을 사용합니다. 어떤 일정도 마지막 시간 단계 t = T에서 SNR이 0이 아니므로 학습/추론 동작에 불일치가 발생합니다. = 일정을 재조정하여 최종 SNR, T가 0이 되도록 한 후 αT = 0이므로 VT = xo. 따라서 모델은 순수 노이즈 e를 입력으로 받아 xo를 출력으로 예측합니다. 이 특정 타임스텝에서 모델은 입력에 신호가 없으므로 노이즈 제거 작업을 수행하지 않습니다. 오히려 프롬프트에 따라 조건화된 데이터 분포의 평균을 예측하도록 재활용됩니다. 1. 원래의 우리 0. t0에서 원래의 우리 0.--0.-0.250 500 750(a) logSNR(t) (b) √āt 750그림 2. 원래 안정 확산 노이즈 일정과 재조정된 노이즈 일정의 비교. 재조정된 노이즈 일정은 0 터미널 SNR을 보장합니다. 알고리즘 1 0 터미널 SNR로 재조정 일정 1 def enforcement_zero_terminal_snr (betas): %23 베타를 alphas_bar_sqrt 알파 1 - 베타로 변환합니다. alphas_bar = alphas.cumprod (0) alphas_bar_sqrt =#23 이전 값을 저장합니다.alphas_bar.sqrt() alphas_bar_sqrt_0 alphas_bar_sqrt[0].clone() alphas_bar_sqrt_T = alphas_bar_sqrt[-1].clone() #23 마지막 타임스텝이 0이 되도록 이동합니다. alphas_bar_sqrt == alphas_bar_sqrt_T #23 첫 번째 타임스텝이 이전 값으로 돌아가도록 크기를 조정합니다. alphas_bar_sqrt *= alphas_bar_sqrt_0 / ( alphas_bar_sqrt_0 alphas_bar_sqrt_T) alphas_bar = alphas_bar_sqrt **%23 alphas_bar_sqrt를 betas로 변환합니다.alphas = alphas_bar[1:] / alphas_bar[:-1]return betas alphas = torch.cat ([alphas_bar [0:1], alphas]) betas = 1 - alphas 3.2. V 예측 및 V 손실로 학습 SNR이 0일 때 € 예측은 사소한 작업이 되고 손실은 모델이 데이터에 대해 의미 있는 것을 학습하도록 안내할 수 없습니다. 우리는 [13]에서 제안된 대로 v 예측 및 v 손실로 전환합니다.V₁ = √√āte – √1 – ā₁x (11) C = Xelot – l (12) = 우리는 λε 1인 v 손실을 사용하여 안정 확산 모델을 미세 조정하고 € 손실을 사용할 때와 유사한 시각적 품질을 찾습니다.우리는 항상 모델에 v 예측을 사용하고 필요한 경우 다른 손실 가중치를 달성하기 위해 +를 조정하는 것이 좋습니다.3.3. 마지막 타임스텝의 샘플링 최신 샘플러는 시각적으로 매력적인 샘플을 생성하기 위해 훨씬 적은 단계를 샘플링할 수 있습니다.일반적인 관행은 여전히 많은 양의 이산화된 타임스텝(예: T 1000)에서 모델을 훈련하고 추론 시 몇 개의 샘플 단계(예: S 25)만 수행하는 것입니다.이를 통해 추론 시 샘플 단계 S를 동적으로 변경하여 품질과 속도 간의 균형을 유지할 수 있습니다. = = 그러나 공식 DDIM [16] 및 PNDM [6] 구현을 포함한 많은 구현은 표 2에 표시된 대로 샘플링 프로세스에서 마지막 타임스텝을 제대로 포함하지 않습니다. 이는 t &lt; T에서 작동하는 모델이 0이 아닌 SNR 입력에 대해 학습되어 추론 동작과 일치하지 않기 때문에 잘못된 것입니다. 섹션 3.1에서 설명한 것과 같은 이유로 이는 안정 확산의 밝기 문제에 영향을 미칩니다. 우리는 0 터미널 SNR을 적용하는 노이즈 일정과 함께 마지막 타임스텝에서 샘플링하는 것이 중요하다고 주장합니다. 이런 방식으로만 초기 샘플 단계에서 모델에 순수한 가우시안 노이즈가 제공될 때 모델은 실제로 추론에서 이러한 입력을 예상하도록 학습됩니다. 표 2에서 샘플 단계를 선택하는 두 가지 추가 방법을 고려합니다. iDDPM [8]에서 제안된 Linspace는 첫 번째와 마지막 타임스텝을 모두 포함한 다음 선형 보간을 통해 중간 타임스텝을 균등하게 선택합니다. DPM [7]에서 제안된 Trailing은 마지막 타임스텝만 포함하고 끝에서 시작하여 균등한 간격으로 중간 타임스텝을 선택합니다.샘플 단계 선택은 특정 샘플러에 구속되지 않으며 쉽게 교환할 수 있습니다.우리는 trailing이 샘플을 더 효율적으로 사용한다는 것을 발견했습니다.Туре 방법 이산화 선행 DDIM [3], PNDM [6] |arange(1, T + 1, floor(T/S)) Linspace iDDPM [8] Trailing DPM [7] round (linspace(1,T,S)) | 시간 단계(예: T = 1000, S = 10) 1 101 201 301 401 501 601 701 8011 112 223 334 445 556 667 778 889round(flip(arange(T,0,-T/S))) |100 200 300 400 500 600 700 800 900표 2. 샘플 단계 선택 간 비교. T는 모델이 학습된 총 이산 시간 단계입니다. S는 샘플러에서 사용하는 샘플 단계 수입니다. 샘플 단계는 항상 샘플링 프로세스에서 마지막 시간 단계 t = T를 포함해야 한다고 주장합니다. 이 예에서는 설명을 위해 T = 1000, S = 10만 사용합니다. 여기서 타임스텝은 논문에서 사용된 수학 표기법과 일치하도록 범위 [1, ..., 1000]을 사용하지만 실제로 대부분의 구현에서는 타임스텝 범위 [0, ..., 999]를 사용하므로 이에 따라 이동해야 합니다. 특히 S가 작은 경우 단계입니다. 이는 대부분의 일정에서 x1이 B₁에 의해 제어되는 아주 작은 양의 노이즈에 의해서만 xo와 다르고 모델은 t = 1에서 샘플링될 때 많은 의미 있는 변경을 수행하지 않기 때문에 t = 1에서 샘플 단계가 쓸모없게 되기 때문입니다. 향후에는 트레일링으로 전환합니다.
--- EXPERIMENT ---
ation은 이러한 간단한 변경 사항이 문제를 완전히 해결한다는 것을 보여줍니다. 이러한 결함 있는 설계는 안정적 확산에만 국한되지 않고 모든 확산 모델에 일반적입니다. 향후 확산 모델 설계에서 이를 고려하기를 권장합니다. 2. 배경 확산 모델[3, 15]에는 순방향 및 역방향 프로세스가 포함됩니다. 순방향 프로세스는 일반적으로 학습되지 않고 수동으로 정의된 분산 일정 ẞ1,..., BT에 따라 데이터에 가우시안 노이즈를 점진적으로 추가하여 정보를 파괴합니다. 여기서는 다음과 같이 정의된 이산적이고 분산을 보존하는 공식을 고려합니다. T q(X1:T|xo) := II 9(xt|xt−1) t=q(xt|xt−1) := N(xt; √√1 – ßtxt−1, ẞtĪ) (1) (2) 순방향 프로세스를 사용하면 닫힌 형태로 임의의 시간 단계 t에서 xt를 샘플링할 수 있습니다. 영어: at := 1 - ẞt 및 āt := Пts=1로 하면 q(xt|xo) := N(xt; √ātxo, (1 — āt)I) 동등하게: (3) xt = √√ātxo + √√1 - ātε, 여기서 € ~ N(0, 1) (4) 신호 대 잡음비(SNR)는 다음과 같이 계산할 수 있습니다. at SNR(t) := 1- at (5) 확산 모델은 정보를 단계적으로 복원하기 위해 역방향 프로세스를 학습합니다. ẞt가 작은 경우 역방향 단계도 가우시안인 것으로 밝혀졌습니다. T pe(xo:T) := p(xT) [po(xt−1\xt) t=== po(2t_12t) :=N(t_1;t,ỠI) (6) (7) 신경 모델은 μt를 예측하는 데 사용됩니다. 일반적으로 모델은 잡음 &amp;를 예측하기 위해 재매개변수화됩니다.대신 다음과 같습니다.Mt:= (xt ẞt ✓ 1 at (8) 분산 ẞt는 순방향 프로세스 사후 확률에서 계산할 수 있습니다.ẞt 1-at-1-ẞt at (9) 3. 방법 3.1. 0 터미널 SNR 적용 표 1은 일반적인 일정 정의와 해당 SNR(T) 및 터미널 타임스텝 T = 1000에서의 √ā를 보여줍니다.어떤 일정도 0 터미널 SNR을 갖지 않습니다.또한 코사인 일정은 터미널 SNR이 0에 도달하는 것을 방지하기 위해 의도적으로 ẞt를 0.999보다 크지 않도록 잘라냅니다.안정적 확산에서 사용하는 잡음 일정이 특히 결함이 있음을 알 수 있습니다.터미널 SNR은 0에 도달하기 멀었습니다.값을 방정식 (4)에 대입하면 신호가 최종 타임스텝에서 완전히 파괴되기 멀다는 것도 알 수 있습니다.XT = 0.068265 x0 +0.997667 · € = (10) 이는 효과적으로 훈련과 추론 사이에 갭을 만듭니다. 훈련 시 t T일 때, 모델에 대한 입력은 완전히 순수한 노이즈가 아닙니다. 소량의 신호가 여전히 포함됩니다. 누출된 신호에는 각 채널의 전체 평균과 같은 가장 낮은 주파수 정보가 포함됩니다. 이후 모델은 누출된 신호의 평균을 존중하여 노이즈를 제거하는 방법을 학습합니다. 추론 시, 대신 순수한 가우시안 노이즈가 샘플링에 제공됩니다. 가우시안 노이즈는 항상 평균이 0이므로 모델은 t = T에서 제공된 평균에 따라 샘플을 계속 생성하여 중간 밝기의 이미지를 생성합니다. 반면, 터미널 SNR이 0인 노이즈 일정은 훈련 중 t = T에서 입력으로 순수한 노이즈를 사용하므로 추론 동작과 일치합니다. 동일한 문제가 일반적으로 모든 확산 노이즈 일정에 외삽되지만 다른 일정의 터미널 SNR은 0에 더 가까워서 실제로 알아차리기 어렵습니다. 우리는 확산 노이즈 일정이 훈련과 추론 간의 불일치를 완전히 제거하기 위해 터미널 SNR을 0으로 강제해야 한다고 주장합니다. 이는 또한 분산 폭발 공식[17]이 실제로 0 터미널 SNR에 도달할 수 없기 때문에 분산 보존 공식을 사용해야 함을 의미합니다. 분산 보존 공식에서 기존 노이즈 일정을 재조정하여 0 터미널 SNR을 강제하는 간단한 수정을 제안합니다. 방정식(4)에서 √√āt는 혼합할 신호의 양을 제어한다는 것을 기억하세요. 아이디어는 √√₁을 변경하지 않고 √를 0으로 변경하고 중간 t = [2, ..., T-1]에 대해 √√t를 각각 선형적으로 재조정하는 것입니다. √āt 공간에서 일정을 조정하는 것이 SNR(t) 공간에서 조정하는 것보다 곡선을 더 잘 보존할 수 있음을 발견했습니다. PyTorch 구현은 알고리즘 1에 나와 있습니다. 제안된 재조정 방법은 기존의 비코사인 일정을 수정하는 데만 필요합니다. 코사인 일정은 간단히 ẞt 클리핑을 제거하여 0 터미널 SNR을 달성할 수 있습니다. 미래에 설계된 일정은 0 터미널 SNR을 달성하기 위해 ẞÃ = 1을 보장해야 합니다. 일정 선형 [3] 코사인 [8] 안정 확산 [10] 정의 (i = 1) ẞt ẞt = . 0.0001 (1 − i) + 0.02 ⋅ i min(1, 0.999), āt = f(t) f(0), f(t) = cos(+0.1+0.ẞt = (√0.00085. (1 − i) + √0.012 · į)² SNR(T) 4.035993e-)2 2.428735e-0.0.4.928220e-0.표 1. 일반적인 일정 정의와 해당 SNR 및 마지막 타임스텝의 √ā. 모든 일정은 총 시간 단계 T = 1000을 사용합니다. 어떤 일정도 마지막 시간 단계 t = T에서 SNR이 0이 아니므로 학습/추론 동작에 불일치가 발생합니다. = 일정을 재조정하여 터미널 SNR이 0이 되도록 한 후 T, αT = 0이므로 VT = xo입니다. 따라서 모델은 순수 노이즈 e를 입력으로 받아 xo를 출력으로 예측합니다. 이 특정 시간 단계에서 모델은 입력에 신호가 없으므로 노이즈 제거 작업을 수행하지 않습니다. 오히려 프롬프트에 따라 조건화된 데이터 분포의 평균을 예측하는 데 재활용됩니다. 1. 원래의 우리 0. t에서의 원래 우리 0.--0.-0.250 500 750(a) logSNR(t) (b) √āt 750그림 2. 원래의 안정 확산 노이즈 일정과 재조정된 노이즈 일정의 비교. 재조정된 노이즈 일정은 터미널 SNR이 0이 되도록 보장합니다. 알고리즘 1 일정을 0 터미널 SNR 1로 재조정 def enforcement_zero_terminal_snr (betas): %23 베타를 alphas_bar_sqrt로 변환합니다.알파 1 - 베타.alphas_bar = alphas.cumprod (0) alphas_bar_sqrt =#23 이전 값을 저장합니다.alphas_bar.sqrt() alphas_bar_sqrt_0 alphas_bar_sqrt[0].clone() alphas_bar_sqrt_T = alphas_bar_sqrt[-1].clone() #23 마지막 타임스텝이 0이 되도록 이동합니다.alphas_bar_sqrt == alphas_bar_sqrt_T #23 첫 번째 타임스텝이 이전 값으로 돌아가도록 조정합니다. alphas_bar_sqrt *= alphas_bar_sqrt_0 / ( alphas_bar_sqrt_0 alphas_bar_sqrt_T) alphas_bar = alphas_bar_sqrt **%23 alphas_bar_sqrt를 betas로 변환합니다.alphas = alphas_bar[1:] / alphas_bar[:-1]return betas alphas = torch.cat ([alphas_bar [0:1], alphas]) betas = 1 - alphas 3.2. V 예측 및 V 손실로 학습 SNR이 0일 때 € 예측은 사소한 작업이 되고 손실은 모델이 데이터에 대해 의미 있는 것을 학습하도록 안내할 수 없습니다. 우리는 [13]에서 제안된 대로 v 예측 및 v 손실로 전환합니다.V₁ = √√āte – √1 – ā₁x (11) C = Xelot – l (12) = 우리는 λε 1인 v 손실을 사용하여 안정 확산 모델을 미세 조정하고 € 손실을 사용할 때와 유사한 시각적 품질을 찾습니다.우리는 항상 모델에 v 예측을 사용하고 필요한 경우 다른 손실 가중치를 달성하기 위해 +를 조정하는 것이 좋습니다.3.3. 마지막 타임스텝의 샘플링 최신 샘플러는 시각적으로 매력적인 샘플을 생성하기 위해 훨씬 적은 단계를 샘플링할 수 있습니다.일반적인 관행은 여전히 많은 양의 이산화된 타임스텝(예: T 1000)에서 모델을 훈련하고 추론 시 몇 개의 샘플 단계(예: S 25)만 수행하는 것입니다.이를 통해 추론 시 샘플 단계 S를 동적으로 변경하여 품질과 속도 간의 균형을 유지할 수 있습니다. = = 그러나 공식 DDIM [16] 및 PNDM [6] 구현을 포함한 많은 구현은 표 2에 표시된 대로 샘플링 프로세스에서 마지막 타임스텝을 제대로 포함하지 않습니다. 이는 t &lt; T에서 작동하는 모델이 0이 아닌 SNR 입력에 대해 학습되어 추론 동작과 일치하지 않기 때문에 잘못된 것입니다. 섹션 3.1에서 설명한 것과 같은 이유로 이는 안정 확산의 밝기 문제에 영향을 미칩니다. 우리는 0 터미널 SNR을 적용하는 노이즈 일정과 함께 마지막 타임스텝에서 샘플링하는 것이 중요하다고 주장합니다. 이런 방식으로만 초기 샘플 단계에서 모델에 순수한 가우시안 노이즈가 제공될 때 모델은 실제로 추론에서 이러한 입력을 예상하도록 학습됩니다. 표 2에서 샘플 단계를 선택하는 두 가지 추가 방법을 고려합니다. iDDPM [8]에서 제안된 Linspace는 첫 번째와 마지막 타임스텝을 모두 포함한 다음 선형 보간을 통해 중간 타임스텝을 균등하게 선택합니다. DPM [7]에서 제안된 Trailing은 마지막 타임스텝만 포함하고 끝에서 시작하여 균등한 간격으로 중간 타임스텝을 선택합니다.샘플 단계 선택은 특정 샘플러에 구속되지 않으며 쉽게 교환할 수 있습니다.우리는 trailing이 샘플을 더 효율적으로 사용한다는 것을 발견했습니다.Туре 방법 이산화 선행 DDIM [3], PNDM [6] |arange(1, T + 1, floor(T/S)) Linspace iDDPM [8] Trailing DPM [7] round (linspace(1,T,S)) | 시간 단계(예: T = 1000, S = 10) 1 101 201 301 401 501 601 701 8011 112 223 334 445 556 667 778 889round(flip(arange(T,0,-T/S))) |100 200 300 400 500 600 700 800 900표 2. 샘플 단계 선택 간 비교. T는 모델이 학습된 총 이산 시간 단계입니다. S는 샘플러에서 사용하는 샘플 단계 수입니다. 샘플 단계는 항상 샘플링 프로세스에서 마지막 시간 단계 t = T를 포함해야 한다고 주장합니다. 이 예에서는 설명을 위해 T = 1000, S = 10만 사용합니다. 여기서 타임스텝은 논문에서 사용된 수학 표기법과 일치시키기 위해 범위 [1, ..., 1000]을 사용하지만 실제로 대부분의 구현에서는 타임스텝 범위 [0, ..., 999]를 사용하므로 이에 따라 이동해야 합니다. 특히 S가 작은 경우 단계입니다. 대부분의 일정에서 x1은 B₁에 의해 제어되는 아주 작은 양의 노이즈에 의해서만 xo와 다르고 모델은 t = 1에서 샘플링될 때 많은 의미 있는 변경을 수행하지 않아 t = 1에서 샘플 단계가 쓸모없게 되기 때문입니다. 향후 실험을 위해 트레일링으로 전환하고 DDIM을 사용하여 공식 안정 확산 구현과 일치시킵니다. 일부 샘플러 구현에서는 제로 나눗셈 오류가 발생할 수 있습니다. 수정 방법은 섹션 6에서 제공합니다. 3.4. 분류기 없는 안내 재조정 터미널 SNR이 0에 가까워짐에 따라 분류기 없는 안내 [4]가 매우 민감해지고 이미지가 과다 노출될 수 있습니다. 이 문제는 다른 작업에서도 발견되었습니다. 예를 들어, Imagen [11]은 거의 0에 가까운 터미널 SNR을 갖는 코사인 스케줄을 사용하고 과다 노출 문제를 해결하기 위해 동적 임계값 설정을 제안합니다.그러나 이 접근 방식은 이미지 공간 모델에만 설계되었습니다.이에 영감을 받아 이미지 공간 및 잠재 공간 모델 모두에 적용 가능한 분류기 없는 안내를 재조정하는 새로운 방법을 제안합니다.Xcfg = xneg + w(xpos - Xneg) (13) 방정식 (13)은 일반적인 분류기 없는 안내를 보여줍니다.여기서 w는 안내 가중치이고 Xpos 및 Xneg는 각각 양수 및 음수 프롬프트를 사용하는 모델 출력입니다.w가 클 때 결과 xcfg의 크기가 매우 커서 이미지 과다 노출 문제가 발생합니다. 이를 해결하기 위해 분류기 없는 안내를 적용한 후 재조정하는 것을 제안합니다.std(xcfg) (14) Opos = std(xpos), cfg Opos Xrescaled xcfg Ocfg · Xrescaled + (1 — þ) · xcfg (15) (16) x final = 방정식 (14)에서 Xpos, cfg의 표준 편차를 pos, σcfg Є R로 계산합니다.방정식 (15)에서 분류기 없는 안내를 적용하기 전에 Xcfg를 원래 표준 편차로 재조정하지만 생성된 이미지가 지나치게 단순하다는 것을 발견했습니다.방정식 (16)에서 재조정 강도를 제어하기 위해 하이퍼 매개변수를 도입했습니다.경험적으로 w = 7.5, p = 0.7이 잘 작동한다는 것을 발견했습니다. 최적화된 PyTorch 구현은 알고리즘 2에 나와 있습니다.알고리즘 2 Rescale 1을 사용한 분류기 없는 안내 def apply_cfg (pos, neg, weight=7.5, rescale=0.7): # 일반적인 분류기 없는 안내를 적용합니다.cfg neg + weight * (pos neg) std_pos = pos.std ([1,2,3], keepdim=True) std_cfg = cfg.std ([1,2,3], keepdim=True)#23 표준 편차를 계산합니다.# 융합 연산으로 안내 rescale을 적용합니다.factor = std_pos / std_cfgfactor rescale * factor (1 - rescale) return cfg * factor 4. 평가 우리는 우리의 수정 사항을 사용하여 Laion 데이터 세트[14]에서 Stable Diffusion 2.1 기반 모델을 미세 조정합니다.우리의 Laion 데이터 세트는 원래의 Stable Diffusion에서 사용된 데이터와 유사하게 필터링됩니다. 우리는 동일한 학습 구성, 즉 배치 크기 2048, 학습률 1e-4, ema 감소 0.9999를 사용하여 50k 반복 동안 모델을 학습합니다.또한 공정한 비교를 위해 필터링된 Laion 데이터에서 변경되지 않은 참조 모델도 학습합니다.4.1. 정성적 그림 3은 우리 방법이 다양한 밝기 범위의 이미지를 생성할 수 있음을 보여줍니다.특히, 결함이 있는 설계를 가진 모델은 항상 중간 밝기의 샘플을 생성합니다.&quot;흰색 배경&quot; 및 &quot;단색 검은색 배경&quot; 등과 같은 명확한 프롬프트가 주어지면 올바른 이미지를 생성할 수 없습니다.반면에 우리 모델은 프롬프트에 따라 완벽하게 생성할 수 있습니다.4.2. 정량적 우리는 Fréchet Inception Distance(FID) [2,9] 및 Inception Score(IS) [12]를 계산하는 규칙을 따릅니다.우리는 COCO 2014 검증 데이터 세트 [5]에서 무작위로 10k 이미지를 선택하고 모델을 사용하여 해당 캡션으로 생성합니다. 표 3은 우리 모델이 불안정한 확산 우리 안정된 확산 우리 (a) 어두운 스튜디오에서 포즈를 취하는 정장을 입은 남자의 클로즈업 초상화, 림 조명, 청록색 색조, 옥탄, 비현실적 (b) 은하계 속의 사자, 나선, 성운, 별, 연기, 무지개빛, 복잡한 디테일, 옥탄 렌더링, 8k (c) 몇 개의 횃불만으로 밝혀진 어두운 마을 광장 (d) 별이 빛나는 하늘 (e) 흰색 배경에 있는 흰머리 독수리 (f) 흰색 배경에 있는 단색 선화 로고 IN CEIPT LOINS GOMEN TELLE (g) 금발 여성 모델, 흰색 셔츠, 흰색 바지, 흰색 배경, 스튜디오 (h) 단색 검은색 배경 = 그림 3. 정성적 비교. 왼쪽은 안정된 확산 참조 모델입니다. 오른쪽은 제안된 모든 수정 사항을 적용한 후의 안정된 확산 모델입니다. 모든 이미지는 DDIM 샘플러, S: 50단계, 후행 시간 단계 선택, 분류기 없는 안내 가중치 w = 7.5, 재조정 계수 = 0.7을 사용하여 생성되었습니다. 한 쌍 내의 이미지는 동일한 시드를 사용하여 생성됩니다. 다른 부정적 프롬프트가 사용됩니다. 입증된 FID/IS는 우리 모델이 이미지 분포에 더 잘 맞고 시각적으로 더 매력적임을 시사합니다. 모델 SD v2.1 기반 공식 SD(우리 데이터 포함), 수정 없음 SD(수정 포함) IS ↑ FID↓ 23.76 32.22.96 34.21.66 36. 표 3. 정량적 평가. 모든 모델은 S = 50단계, 안내 가중치 w = 7.5, 부정적 프롬프트가 없는 DDIM 샘플러를 사용합니다. 우리 모델은 0 터미널 SNR 노이즈 일정, v 예측, 후행 샘플 단계, 안내 재조정 계수 5를 사용합니다. 소거 5.1. 샘플 단계 비교 = 0.7. =그림 4는 0 터미널 SNR 노이즈 일정으로 학습된 모델에서 선행, 린스페이스, 후행을 사용하여 샘플링을 비교합니다. 샘플 단계 S가 작은 경우(예: S를 극단적인 예로 들 때) 후행이 린스페이스보다 눈에 띄게 성능이 우수합니다. 하지만 S = 25와 같은 일반적인 선택의 경우 후행과 린스페이스의 차이는 쉽게 눈에 띄지 않습니다. (a) 선행, S(b) 린스페이스, S =(c) 후행, S =(d) 선행, S = 25 (e) 린스페이스, S =(f) 후행, S =그림 4. 샘플 단계 선택 비교. 프롬프트는 &quot;밝은 빛 속에서 웃는 두 남자의 클로즈업 사진&quot;입니다. DDIM으로 샘플링했습니다. 동일한 시드입니다. 샘플 단계가 극히 작은 경우(예: S = 5) 후행이 린스페이스보다 눈에 띄게 좋습니다. 샘플 단계가 큰 경우(예: S = 25) 후행과 린스페이스의 차이는 미묘합니다. 5.2. 0 SNR을 사용한 모델 동작 분석 완벽한 수렴까지 훈련된 &quot;이상적인&quot; 무조건 모델을 고려해 보겠습니다. 이 모델은 터미널 SNR이 0인 상태에서 학습합니다. t = :T에서 모델은 노이즈 입력에 관계없이 모든 데이터 샘플의 정확히 같은 L2 평균을 예측하는 법을 배웁니다. 텍스트 조건부 사례에서 모델은 프롬프트에 따라 L2 평균을 예측하지만 노이즈 입력에는 불변합니다. 따라서 t T에서 첫 번째 샘플 단계는 이상적으로 노이즈 입력에 관계없이 정확히 같은 예측을 생성합니다. 변화는 두 번째 샘플 단계에서 시작됩니다. DDPM [3]에서 다른 랜덤 가우시안 노이즈가 첫 번째 단계의 동일한 예측 xo에 다시 추가됩니다. DDIM [16]에서 다른 예측 노이즈가 첫 번째 단계의 동일한 예측 xo에 다시 추가됩니다. 이제 xo의 사후 확률이 달라지고 모델은 다른 노이즈 입력에 대해 다른 결과를 생성하기 시작합니다. 이는 모델 동작과 일치합니다. 그림은 t = T에서 노이즈 입력에 관계없이 우리 모델이 거의 정확한 결과를 예측하고 변동은 다음 샘플 단계에서 시작됨을 보여줍니다. 다시 말해, t = T에서 노이즈 입력은 불필요하지만 구조적 편의를 위해 유지합니다. 5.3. 분류기 없는 안내 재조정의 효과 그림 6은 다른 재조정 계수 o를 사용한 결과를 비교합니다. 재조정 계수 = 0에 해당하는 일반적인 분류기 없는 안내를 사용할 때 이미지가 과다 노출되는 경향이 있습니다. 경험적으로 0과 0.75 사이로 설정하면 가장 매력적인 결과가 생성됩니다. 5.4. 오프셋 노이즈와의 비교 오프셋 노이즈는 안정적 확산에서 밝기 문제를 해결하기 위해 [1]에서 제안한 또 다른 기술입니다. NN(0, 1)을 샘플링하는 대신 Єhwc ~ N(0.18c, I)를 샘플링하는 것을 제안합니다. 여기서 Sc N(0, 1)이고 동일한 c가 ~ 모든 채널 c의 모든 픽셀 h, w에 사용됩니다. 오프셋 노이즈를 사용할 때 각 픽셀의 노이즈는 더 이상 iid가 아닙니다.8c가 전체 채널을 함께 이동하기 때문입니다.노이즈가 적용된 입력의 평균은 더 이상 실제 이미지의 평균을 나타내지 않습니다.따라서 모델은 모든 타임스텝에서 출력을 예측할 때 입력의 평균을 존중하지 않도록 학습합니다.따라서 t = T에서 순수한 가우시안 노이즈가 주어지고 신호가 결함이 있는 노이즈 스케줄에 의해 누출되더라도 모델은 이를 무시하고 모든 타임스텝에서 출력 평균을 자유롭게 변경할 수 있습니다.오프셋 노이즈는 안정적 확산 모델이 매우 밝고 어두운 샘플을 생성할 수 있게 하지만 확산 프로세스 이론과 일치하지 않으며 실제 데이터 분포에 맞지 않는 밝기, 즉 너무 밝거나 너무 어두운 샘플을 생성할 수 있습니다.근본적인 문제를 해결하지 못하는 속임수입니다. 6. 구현 이 섹션에서는 확산의 수학적 관점에서 0 터미널 SNR이 유효한지 보여주고 샘플러 구현에서 흔히 범하는 함정을 지적합니다.그림 5. &quot;말을 타는 우주인&quot;이라는 프롬프트에서 샘플 단계 시각화. 수평축은 타임스텝 t입니다. t = T에서 모델은 프롬프트를 기반으로 데이터 분포의 평균을 생성합니다. == 0.= 0.= 0.ED =QCD 그림 6. 분류기 없는 안내 재조정 계수의 비교. 모든 이미지는 S = 25단계와 안내 가중치 w = 7.5인 DDIM 샘플러를 사용합니다. 일반적인 분류기 없는 안내는 &gt; = O와 동일하며 과다 노출을 유발할 수 있습니다. Є [0.5,..., 0.75]가 잘 작동하는 것을 발견했습니다. 긍정적인 프롬프트는 (1) &quot;얼룩말&quot;, (2) &quot;풀밭에 서 있는 눈 올빼미의 수채화 그림&quot;, (3) &quot;빨간 앵무새, 파란색 앵무새와 녹색 앵무새가 마이크 앞에서 콘서트에서 노래를 부릅니다. 배경에 다채로운 조명이 있습니다.&quot;. 다른 부정적인 프롬프트가 사용됩니다. 샘플러 구현은 e 수학 공식을 피해야 합니다. DDPM [3] 샘플링을 고려하십시오. 일부 구현은 방정식 (17)을 사용하여 v 예측을 먼저 €로 변환한 다음 샘플링 방정식 방정식 (18)을 적용하여 처리합니다([3]의 방정식 11). 이것은 터미널 단계에서 SNR이 0인 경우 문제가 됩니다. €로 변환하면 모든 신호 정보가 손실되고 at = 0에서 나누기 오류가 0이 되기 때문입니다. € = √√ātv + √√1 – ātxtẞt μt == (xt (17) (18) 올바른 방법은 먼저 방정식 (19)에서 v 예측을 xo로 변환한 다음 방정식 (20)과 같이 xo 공식으로 직접 샘플링하는 것입니다([3]의 방정식 7). 이렇게 하면 ε 공식의 특이점 문제가 방지됩니다. € x0 = √√ātxt - √√1 – āt̃v (19) √āt-1ẞt μt = := -xo +xt (20) √√(1-at-1) 1 at DDIM [16]의 경우, 먼저 방정식 (17) 및 (19)를 사용하여 v 예측을 €, xo로 변환한 다음 방정식 (21)을 사용하여 샘플링합니다([16]의 방정식 12): xt-1 = √√āt-1x0+ 1 āt-1 - σ²²€ + σtz E (21) 여기서 z ~N(0, 1), ŋ Є [0, 1] 및 η σt(n) =1 at 다른 샘플러에도 동일한 논리가 적용됩니다. 7.
--- CONCLUSION ---
at at-(22) 요약하자면, 우리는 확산 모델이 터미널 SNR이 0인 노이즈 스케줄을 사용해야 하며, 훈련 동작이 추론과 일치하도록 하기 위해 마지막 타임스텝부터 샘플링해야 한다는 것을 발견했습니다. 우리는 기존 노이즈 스케줄을 재조정하여 터미널 SNR이 0인 간단한 방법과 이미지 과다 노출을 방지하기 위한 분류기 없는 안내 재조정 기술을 제안했습니다. 이를 고려하여 향후 확산 모델을 설계하는 것을 권장합니다. 참고문헌 [1] Nicholas Guttenberg. 오프셋 노이즈가 있는 확산, 2023.[2] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Sepp Hochreiter. 2개 타임스케일 업데이트 규칙으로 훈련된 Gans가 로컬 내쉬 균형으로 수렴, 2018.[3] Jonathan Ho, Ajay Jain, Pieter Abbeel. 잡음 제거 확산 확률 모델, 2020. 1, 2, 3, 4, 6,[4] Jonathan Ho 및 Tim Salimans. 분류기 없는 확산 안내, 2022. 1,[5] Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick, James Hays, Pietro Perona, Deva Ramanan, C. Lawrence Zitnick 및 Piotr Dollár. Microsoft coco: 컨텍스트의 일반 객체, 2015.[6] Luping Liu, Yi Ren, Zhijie Lin 및 Zhou Zhao. 매니폴드의 확산 모델을 위한 가상 수치 방법. 학습 표현 국제 컨퍼런스에서, 2022. 1,3,[7] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li 및 Jun Zhu. Dpm-solver: 약 10단계로 확산 확률 모델 샘플링을 위한 빠른 ode 솔버, 2022. 3,[8] Alex Nichol 및 Prafulla Dhariwal. 개선된 노이즈 제거 확산 확률 모델, 2021. 1, 3,[9] Gaurav Parmar, Richard Zhang 및 Jun-Yan Zhu. 앨리어싱 크기 조정 및 Gan 평가의 놀라운 미묘함에 관하여, 2022.[10] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser 및 Björn Ommer. 잠재 확산 모델을 사용한 고해상도 이미지 합성, 2021. 1,[11] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. Sara Mahdavi, Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho, David J Fleet, Mohammad Norouzi. 심층적 언어 이해를 사용한 사실적인 텍스트-이미지 확산 모델, 2022.[12] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen. 간 훈련을 위한 개선된 기술, 2016.[13] Tim Salimans 및 Jonathan Ho. 확산 모델의 빠른 샘플링을 위한 점진적 증류, 2022.[14] Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, Patrick Schramowski, Srivatsa Kundurthy, Katherine Crowson, Ludwig Schmidt, Robert Kaczmarczyk 및 Jenia Jitsev. Laion-5b: 차세대 이미지-텍스트 모델 훈련을 위한 개방형 대규모 데이터 세트, 2022.[15] Jascha Sohl-Dickstein, Eric A. Weiss, Niru Maheswaranathan 및 Surya Ganguli. 비평형 열역학을 이용한 심층 비지도 학습, 2015. 1,[16] Jiaming Song, Chenlin Meng, Stefano Ermon. 잡음 제거 확산 암묵적 모델, 2022. 1, 3, 6,[17] Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon 및 Ben Poole. 확률적 미분 방정식을 통한 점수 기반 생성 모델링, 2021.
