--- ABSTRACT ---
많은 사람들이 기술 비대칭으로 인해 문해력이 낮은 언어로 웹을 사용해야 합니다. 이러한 사용자의 제2 언어(L2)로 작성된 텍스트에는 종종 모국어(L1)의 영향을 받는 많은 오류가 포함됩니다. 우리는 L1과 L2 쌍의 음소 혼동(L1 화자가 혼동할 가능성이 있는 L2의 소리)을 채굴하는 방법을 제안합니다. 그런 다음 이러한 혼동을 생성 모델(BiPhone)에 연결하여 손상된 L2 텍스트를 합성적으로 생성합니다. 인간의 평가를 통해 Bi-Phone이 L1에 따라 다르고 웹에서 널리 사용되는 그럴듯한 손상을 생성한다는 것을 보여줍니다. 또한 우리의 기술(FunGLUE for Phonetically Noised GLUE)로 대중적인 언어 이해 벤치마크인 SuperGLUE를 손상시키고 SOTA 언어 이해 모델의 성능이 좋지 않음을 보여줍니다. 또한 바이트 모델이 SuperGLUE에 가까운 성능을 회복하도록 돕는 새로운 음소 예측 사전 학습 작업을 소개합니다. 마지막으로, 우리는 또한 음성학적으로 견고한 언어 모델에 대한 추가 연구를 촉진하기 위해 FunGLUE 벤치마크를 출시합니다. 우리가 아는 한, FunGLUE는 텍스트에서 L1-L2 상호 작용을 도입한 최초의 벤치마크입니다. 1
--- INTRODUCTION ---
우리는 전 세계적으로 7,개 이상의 언어가 사용되는 다국어 세계에 살고 있습니다(Eberhard와 Fennig, 2022). 그러나 기술은 비대칭적으로 몇 가지 특정 언어만 지원합니다. 예를 들어, 인터넷은 대부분 영어로 되어 있으며, 전 세계적으로 영어를 사용하는 인구가 약 16%에 불과함에도 불구하고 60%가 넘는 웹사이트가 영어를 사용합니다¹(Grefenstette와 Nioche, 2000). 점점 더 많은 사람들이 공식적으로 교육을 받지 않은 언어로 웹에서 탐색하고 콘텐츠를 제작해야 합니다. ESL(영어를 제2/L2 언어로 사용하는) &#39;https://w3techs.com/technologies/overview/content_language 작성자가 작성한 영어 텍스트는 모국어(L1)의 영향을 크게 받습니다. 제2언어 습득 분야의 연구에서는 특정 언어 쌍의 L2 텍스트에서 L1 영향에서 비롯된 음소 변화 기반 철자 오류의 증거를 발견했습니다(Ibrahim, 1978; Cook, 1997; Bestgen and Granger, 2011; Sari, 2014; Ogneva, 2018; Motohashi-Saigo and Ishizawa, 2020). 자연어 이해(NLU) 연구는 영어 학습자의 철자 교정(Nagata et al. (2017); Flor et al. (2019))과 모국어 식별(Chen et al. (2017); Nicolai et al. (2013))에 국한되었습니다. 이러한 연구에서는 주로 L2 언어에 대한 공식 교육을 받은 시험 응시자와 같은 매우 구체적인 인구 통계를 다루는 TOEFL11 데이터 세트(Blanchard et al., 2013)를 사용합니다. 우리는 텍스트와 음성에서 L1-L2 영향에 대한 연구에서 이전 작업에 대해 다음과 같은 네 가지 주요 관찰을 합니다. 첫째, 텍스트 철자에 대한 L1-L 영향에 대한 현재 모델은 특정 언어 쌍과 작업에 국한됩니다. 우리는 L1-L2 영향 현상이 훨씬 더 광범위하고 언어와 작업에 독립적이라고 주장합니다. 둘째, 오픈 웹에서 이 현상의 유행을 조사할 대규모 연구는 없습니다. 셋째, 이것이 특히 다국어, 인터넷 초보자 커뮤니티에 중요한 문제라는 점을 감안할 때 자연어 이해(NLU) 및 자연어 생성(NLG) 모델의 언어 간 음성 노이즈에 대한 견고성을 연구할 표준화된 벤치마크가 없습니다. 마지막으로, 대규모 언어 모델에 음성 견고성을 도입하기 위한 아키텍처/사전 학습 전략에 대한 문헌은 매우 드뭅니다. 이 논문에서는 위에서 언급한 격차를 해결하기 위한 모델링 기술, 데이터 분석 및 새로운 벤치마크를 제시합니다. 우리는 다음과 같이 우리의 기여를 요약합니다. 1. 우리는 모국어(L1)와 제2 언어(L2) 간의 간섭으로 인해 발생하는 음소 혼동을 찾아내는 언어에 독립적인 방법을 제안합니다. 우리의 방법은 L1 L2 및 L2 → L1 음역 모델에 포함된 &quot;숨겨진 지식&quot;을 활용합니다. 우리는 또한 L1-L혼란에 따라 철자 오류를 합성적으로 생성할 수 있는 생성 모델 BiPhone을 제안합니다(섹션 3.1, 3.2). 2. 인간 평가 및 적용 범위 분석을 통해 Bi-Phone이 모국어 L1 화자에게 그럴듯하다고 여겨질 뿐만 아니라 오픈 웹 크롤 코퍼스에서 상당한 적용 범위를 갖는 철자 오류를 생성한다는 것을 보여줍니다. 우리가 아는 한, Common Crawl(섹션 4)과 같은 대규모 공통 데이터 세트에서 L1-L2 음성 오류가 존재한다는 것을 입증한 이전 연구는 없습니다. 3. 우리는 Common Crawl에서 발견된 L1-L2 음성 철자 오류가 있는 문장으로 구성된 데이터 세트를 공개합니다. 또한 L1-L 철자 오류를 위한 SuperGLUE 벤치마크의 확장인 FunGLUE라는 벤치마크를 출시합니다. 저희가 아는 한 FunGLUE는 텍스트에서 L1-L2 간섭에 대한 모델의 견고성을 측정하는 최초의 벤치마크입니다(섹션 5). 4. SOTA 모델이 FunGLUE에서 좋은 성능을 보이지 않는다는 것을 보여줍니다. 그런 다음 음소 예측의 새로운 사전 학습 작업을 소개하는데, 이는 바이트 수준 아키텍처와 함께 노이즈가 있는 벤치마크의 격차를 상당히 메웁니다(특정 테스트 세트에서 최대 11% 절대값). 이는 모델에 노이즈가 있는 예제를 전혀 보여주지 않고도 이러한 이득을 얻었기 때문에 특히 인상적입니다(섹션 6). 2
--- RELATED WORK ---
우리는 관련 연구의 프레젠테이션을 두 섹션으로 나눕니다.(i) 첫째, 우리는 텍스트의 음성적 영향과 그것이 우리 연구와 어떻게 관련이 있는지에 대한 여러 연구 분야에 걸친 이전 연구에 대해 논의합니다.(ii) 둘째, 우리는 다국어 시나리오에서 언어 간 간섭으로 인해 발생하는 음성적 변형을 연구하는 음성 영역의 연구에 대해 논의합니다.2.1 텍스트의 음성적 영향 철자 오류에 대한 음성적 영향은 과거에 연구되었습니다(Kukich, 1992; Toutanova and Moore, 2002; Hládek et al., 2020). 이러한 오류의 원인은 모국어 화자와 비모국어 화자 모두 익숙하지 않은 단어나 이름에 대해 음성적 철자를 사용하기 때문입니다. 이러한 연구 방향은 모국어(L1) 기반 음소 변화가 제2 언어(L2) 철자에 미치는 영향을 다루지 않습니다. 또한 다양한 응용 프로그램을 위해 학습자 영어 2에 초점을 맞춘 연구도 있었습니다.Nagata et al.(2017); Flor et al. (2019) 분포형을 이용한 자동 철자 교정 연구
--- METHOD ---
L1과 L2 쌍에 대한 음소 혼동(L1 화자가 혼동할 가능성이 있는 L2의 소리)을 채굴합니다. 그런 다음 이러한 혼동을 생성 모델(BiPhone)에 플러그인하여 손상된 L2 텍스트를 합성적으로 생성합니다. 인간의 평가를 통해 Bi-Phone이 L1에 따라 다르고 웹에서 널리 사용되는 그럴듯한 손상을 생성한다는 것을 보여줍니다. 또한 우리의 기술(FunGLUE for Phonetically Noised GLUE)로 일반적인 언어 이해 벤치마크 SuperGLUE를 손상시키고 SOTA 언어 이해 모델의 성능이 좋지 않음을 보여줍니다. 또한 바이트 모델이 SuperGLUE에 가까운 성능을 회복하도록 돕는 새로운 음소 예측 사전 학습 작업을 소개합니다. 마지막으로 음성적으로 견고한 언어 모델에 대한 추가 연구를 촉진하기 위해 FunGLUE 벤치마크를 출시합니다. 우리가 아는 한, FunGLUE는 텍스트에서 L1-L2 상호 작용을 도입한 최초의 벤치마크입니다. 1 서론 우리는 전 세계적으로 7,개 이상의 언어가 사용되는 다국어 세계에 살고 있습니다(Eberhard 및 Fennig, 2022). 그러나 기술은 비대칭적으로 몇 가지 특정 언어만 지원합니다. 예를 들어, 인터넷은 대부분 영어로 되어 있으며, 전 세계적으로 영어를 사용하는 인구가 약 16%에 불과함에도 불구하고 60%가 넘는 웹사이트가 영어를 사용합니다¹(Grefenstette 및 Nioche, 2000). 점점 더 많은 사람들이 공식적으로 교육을 받지 않은 언어로 웹에서 탐색하고 콘텐츠를 제작해야 합니다. ESL(영어를 제2/L2 언어로 사용하는 언어) 작성자가 작성한 영어 텍스트는 모국어(L1)의 영향을 크게 받습니다. 제2언어 습득 분야의 연구에서는 특정 언어 쌍의 L2 텍스트에서 L1 영향에서 비롯된 음소 변화 기반 철자 오류의 증거를 발견했습니다(Ibrahim, 1978; Cook, 1997; Bestgen and Granger, 2011; Sari, 2014; Ogneva, 2018; Motohashi-Saigo and Ishizawa, 2020). 자연어 이해(NLU) 연구는 영어 학습자의 철자 교정(Nagata et al. (2017); Flor et al. (2019))과 모국어 식별(Chen et al. (2017); Nicolai et al. (2013))에 국한되었습니다. 이러한 연구에서는 주로 L2 언어에 대한 공식 교육을 받은 시험 응시자와 같은 매우 구체적인 인구 통계를 다루는 TOEFL11 데이터 세트(Blanchard et al., 2013)를 사용합니다. 우리는 텍스트와 음성에서 L1-L2 영향에 대한 연구에서 이전 작업에 대해 다음과 같은 네 가지 주요 관찰을 합니다. 첫째, 텍스트 철자에 대한 L1-L 영향에 대한 현재 모델은 특정 언어 쌍과 작업에 국한됩니다. 우리는 L1-L2 영향 현상이 훨씬 더 광범위하고 언어와 작업에 독립적이라고 주장합니다. 둘째, 오픈 웹에서 이 현상의 유행을 조사할 대규모 연구는 없습니다. 셋째, 이것이 특히 다국어, 인터넷 초보자 커뮤니티에 중요한 문제라는 점을 감안할 때 자연어 이해(NLU) 및 자연어 생성(NLG) 모델의 언어 간 음성 노이즈에 대한 견고성을 연구할 표준화된 벤치마크가 없습니다. 마지막으로, 대규모 언어 모델에 음성 견고성을 도입하기 위한 아키텍처/사전 학습 전략에 대한 문헌은 매우 드뭅니다. 이 논문에서는 위에서 언급한 격차를 해결하기 위한 모델링 기술, 데이터 분석 및 새로운 벤치마크를 제시합니다. 우리는 다음과 같이 우리의 기여를 요약합니다. 1. 우리는 모국어(L1)와 제2 언어(L2) 간의 간섭으로 인해 발생하는 음소 혼동을 찾아내는 언어에 독립적인 방법을 제안합니다. 우리의 방법은 L1 L2 및 L2 → L1 음역 모델에 포함된 &quot;숨겨진 지식&quot;을 활용합니다. 우리는 또한 L1-L혼란에 따라 철자 오류를 합성적으로 생성할 수 있는 생성 모델 BiPhone을 제안합니다(섹션 3.1, 3.2). 2. 인간 평가 및 적용 범위 분석을 통해 Bi-Phone이 모국어 L1 화자에게 그럴듯하다고 여겨질 뿐만 아니라 오픈 웹 크롤 코퍼스에서 상당한 적용 범위를 갖는 철자 오류를 생성한다는 것을 보여줍니다. 우리가 아는 한, Common Crawl(섹션 4)과 같은 대규모 공통 데이터 세트에서 L1-L2 음성 오류가 존재한다는 것을 입증한 이전 연구는 없습니다. 3. 우리는 Common Crawl에서 발견된 L1-L2 음성 철자 오류가 있는 문장으로 구성된 데이터 세트를 공개합니다. 또한 L1-L 철자 손상에 대한 SuperGLUE 벤치마크의 확장인 FunGLUE라는 벤치마크를 출시합니다. 저희가 아는 한 FunGLUE는 텍스트에서 L1-L2 간섭에 대한 모델의 견고성을 측정하는 최초의 벤치마크입니다(섹션 5). 4. 저희는 SOTA 모델이 FunGLUE에서 좋은 성능을 내지 못한다는 것을 보여줍니다. 그런 다음 음소 예측의 새로운 사전 학습 작업을 소개하는데, 이는 바이트 수준 아키텍처와 함께 노이즈가 있는 벤치마크와의 격차를 상당히 메웁니다(특정 테스트 세트에서 최대 11%의 절대값). 이는 모델에 노이즈가 있는 예를 전혀 보여주지 않고도 이러한 이득을 얻었기 때문에 특히 인상적입니다(섹션 6). 2 관련 작업 저희는 관련 작업의 프레젠테이션을 두 섹션으로 나눕니다. (i) 먼저, 텍스트의 음성적 영향과 그것이 저희 작업과 어떻게 관련이 있는지에 대한 여러 연구 분야에 걸친 이전 작업에 대해 논의합니다. (ii) 둘째, 다국어 시나리오에서 언어 간 간섭으로 인해 발생하는 음성 변형을 연구하는 음성 도메인의 작업에 대해 논의합니다. 2.1 텍스트에서의 음성적 영향 철자 오류에 대한 음성적 영향은 과거에 연구되었습니다(Kukich, 1992; Toutanova and Moore, 2002; Hládek et al., 2020). 이러한 오류의 원인은 모국어 화자와 비모국어 화자 모두 익숙하지 않은 단어나 이름에 대해 음성적 철자를 사용하기 때문입니다. 이러한 작업 방향은 모국어(L1) 기반 음소 변화가 제2언어(L2) 철자에 미치는 영향을 다루지 않습니다. 또한 다양한 응용 프로그램을 위해 학습자 영어 2에 초점을 맞춘 작업도 있었습니다. Nagata et al.(2017); Flor et al.(2019)은 더 큰 학습자 코퍼스가 필요한 분포적 방법을 사용하여 자동 철자 교정을 연구합니다. Chen et al.(2017); Nicolai et al.(2013)은 이러한 텍스트에서 모국어 식별(NLI)을 탐구합니다. 영어 학습자 과제에 널리 사용되는 데이터 세트는 TOEFL11 코퍼스(Blanchard et al., 2013)로, 여기에는 모국어가 아닌 시험 응시자가 쓴 영어 에세이가 포함되어 있습니다. 이러한 분석은 시험을 볼 자격이 있는 충분한 지식/훈련을 갖춘 저자가 저지른 철자 오류에 국한된다는 점에 유의하는 것이 중요합니다. 또한 철자 오류의 원인 또는 언어 간 간섭을 명시적으로 연구하지 않습니다. 제2언어 습득 분야에서도 L1이 L2 철자에 미치는 영향에 대한 관심이 상당히 많았습니다. Ibrahim(1978); Cook(1997); Bestgen 및 Granger(2011); Sari(2014); Ogneva(2018); Motohashi-Saigo 및 Ishizawa(2020)는 모두 특정 언어 쌍에서 그러한 영향의 증거를 발견했습니다. 이는 종종 L1에서 특정 소리가 부족하여 L2에서 유사한 소리를 구별하는 데 어려움이 있기 때문입니다. 그들은 또한 자음 클러스터에 대한 L1 제약이 학습자의 L2 철자에 반영되는 것과 같은 더 흥미로운 현상을 발견했습니다. 이러한 연구 방향이 우리 작업과 매우 관련이 있지만, 우리의 목표는 특정 언어 쌍에서 현상을 연구하는 대신 더 일반적으로 그럴듯한 L1-L2 음성 변화 기반 철자 오류를 생성하는 것입니다. 2.2 음성의 음성 편차에 대한 언어 간 영향 단어의 음성 변형은 음성 응용 프로그램의 맥락에서 잘 연구되었습니다. 여러 연구(Radzikowski et al., 2019; Shah et al., 2020; Radzikowski et al., 2021; Bird et al., 2019)는 모국어가 아닌 음성 데이터가 제공될 때 ASR, 구어체 용어 감지 등과 같은 음성 응용 프로그램의 성능이 저하되는 것에 대해 논의합니다. 그들은 이러한 저하를 주로 충분한 모국어가 아닌 음성 데이터가 부족하여 종종 훈련 데이터에 존재하지 않는 발음의 뉘앙스에 기인합니다. 이러한 격차를 해소하고 메우기 위해 여러 가지 전략이 있습니다.2learner English는 영어를 외국어로 지칭합니다.amazon Lअमेजन 3TH amejan amazon AE MAH Z AA N अमेज अमजों Lamezan으로의 음역 AE M AH JH AA N AE MEY Z AA N 3THGamejon AE MEY JH AO N 그림 1: 음소 혼동을 찾아내는 단어 쌍을 만드는 왕복 음역 방법 개요. 이 예에서 우리는 중심 언어로 힌디어를 통한 왕복 음역을 사용하여 사전 단어 &quot;amazon&quot;에 대한 쌍을 만듭니다. 원래 단어와 왕복 음역된 단어의 음소 시퀀스도 표시됩니다. 왕복 음역에 JH가 있는 여러 단어를 사용하면 힌디어 화자의 Z 소리를 JH 소리로 매핑할 수 있습니다. 원어 모국어 음역 회피 IH V EY ZH AH N 여기서 W EH R은 역음역을 획득합니다.음소 쌍 채굴 V -&gt; B (bn) এভাসন ebason IH BEY ZH AH N (hi) वेयर vare W-&gt; V VEH R GRAE BZ (ta) கிராப்ஸ் craps KRAE PSG -&gt; K, B -&gt; P 그림 2: 다른 중심 언어의 사전 단어의 왕복 음역 예, 해당 음소 시퀀스 및 채굴된 음소 혼동.세 번째 예에도 Z -&gt; S 이동이 있지만 (L1, L2) 쌍당 가장 빈번한 혼동 상위 10개만 고려하기 때문에 채굴되지 않습니다.언어 간/다중 언어 음운 목록 사용에서 종단 간 훈련에 이르기까지 다양한 방법이 적용되었습니다. 그러나 이러한 연구는 동일한 음성적 영향이 서면 텍스트에서 어떻게 나타나는지에 초점을 맞추지 않았습니다.3 방법 이 섹션에서는 언어 간 영향을 받는 음성적 철자 오류(또는 손상)를 만드는 방법을 소개합니다.이 기술을 두 부분으로 제시합니다.3.1절에서는 모국어 영향을 받는 음성적 혼동을 마이닝하는 방법을 제시합니다.3.2절에서는 마이닝된 음성적 혼동을 사용하여 철자 오류를 만드는 모델인 Bi-Phone에 대한 세부 정보를 포함합니다.3.1 음소-음소 혼동 마이닝 첫 번째 문제는 주어진 모국어(L1) 화자가 두 번째 언어(L2)를 말할 때 접할 가능성이 있는 음소 혼동을 식별하는 것입니다.이러한 혼동은 행렬 C(L1, L2)로 상상할 수 있으며, 여기에는 L1의 모국어 화자가 i번째 L2 음소(phi)를 J번째 L2 음소(ph;)로 혼동할 가능성이 셀 C(L1, L2)[i][j]의 값으로 포함됩니다. C(L1, L2)[i][j] = P(phj|phi) (1) 모든 언어 쌍에 걸쳐 이 행렬을 구축하는 것은 비용이 많이 드는 작업입니다. 또한 대규모 병렬 단어 데이터 세트 없이 이러한 혼동의 가능성을 정확하게 판단하는 것도 어렵습니다. 음역 모델은 한 언어의 단어를 나타내는 소리를 다른 언어의 문자로 변환하는 목적으로 대규모 병렬 데이터 세트에서 학습합니다. 그들은 다른 언어에서는 구별할 수 없는(따라서 동일하게 어휘화됨) 한 언어의 소리에 대한 중요한 정보를 흡수합니다. 우리는 음역 모델에 숨겨진 이 지식에서 이러한 음소 혼동과 그 가능성을 채굴하는 것을 목표로 하는 왕복 음역 기반 방법을 제안합니다. 우리는 영어 단어의 대규모 사전(선택한 L2)을 수집하고 두 단계의 음역 3(Bhat et al., 2015)을 적용하여 그림 1에서와 같이 피벗 언어(L1)를 통해 다시 영어로 변환합니다. 그런 다음 Needleman-Wunsch 알고리즘(Needleman and Wunsch, 1970)을 사용하여 원래 단어의 음소 시퀀스를 왕복 음역된 버전의 음소 시퀀스와 맞춥니다. 전체 코퍼스에서 가능한 각 사운드 변화의 빈도를 세어 가능성을 추정합니다. 그림은 다른 피벗 언어를 통해 생성된 단어 쌍과 이를 통해 발견된 음소 혼동의 예를 보여줍니다. 다음 단계에서는 (L1, L2)당 가장 빈번한 음소 혼동만 고려합니다. 3.2 BiPhone: L1-L음성적 철자 오류에 대한 생성 모델 우리가 집중하는 두 번째 문제는 L1 모국어 화자가 L2에서 주어진 단어(w)에 대해 할 가능성이 높은 음성적 철자 오류(w)를 샘플링하기 위한 모델을 만드는 것입니다. 이 모델이 학습한 확률 분포를 P(w|w)로 표현할 수 있습니다. 단어 w에서 음소 시퀀스 phw로의 결정적 매핑을 가정하고 최종적으로 https://github.com/libindic/indic-trans에서 w를 생성하는 손상된 음소 시퀀스(ph)를 도입하면 다음과 같이 다시 쓸 수 있습니다.P(ww) = P(w|phw) ) P(phphu) * P(phủ) phw 음소 이동 Hi Ta Bn AH2 -&gt; AHO 100% 100% IH2 -&gt; IHO 100% 100% ER2 -&gt; ERO 100% DH -&gt; TH 54% 62% ER2 -&gt; ERO 95% D-&gt;T 30% (2) B-&gt; P 39% DH -&gt; D 0% G -&gt; K 47% V -&gt; B 58% Z -&gt; S 50% 여기서 단어 w는 문자소 {w¹, w2, ..}로 구성되며, 여기서 w² = 문자소 (L2) 및 음소 시퀀스 phw는 음소 {ph¹, ph²,..}로 구성되며 각 개별 음소 ph²는 L2에 사용 가능한 음소 집합에서 가져온 것입니다.
--- EXPERIMENT ---
s, 우리는 영어 4에 대한 ARPAbet 음소 집합을 사용합니다. 음소-음소 오류 모델: 방정식 2의 합계 아래의 첫 번째 항은 L1의 모국어 화자가 L2에서 음소 시퀀스 phw를 말하려고 시도할 때 손상된 음소 시퀀스 ph를 생성할 가능성을 모델링합니다. 각 음소가 주변 음소와 무관하게 개별적으로 손상된다는 독립성 가정을 단순화하면, 우리가 찾아낸 음소 혼동 행렬을 활용하기 위해 이 항을 인수분해할 수 있습니다. P(phph) = P(phph) i = [[C(L1, L2)[ph¼v] [ph] i (3) 음소-문자 밀도 모델: 방정식 2의 두 번째 항은 음소 시퀀스 phw가 주어졌을 때 w를 나타내는 문자 시퀀스를 생성할 확률을 나타냅니다. 필요한 경우 일부 음소가 문자소를 생성하지 않도록 허용하여 두 시퀀스의 길이가 같다고 가정할 수 있습니다. 다시 말해, 주어진 음소를 나타내는 데 사용된 자소가 이웃 음소나 자소에 의존하지 않는 독립 가정을 합니다. P(wph) = P(w²|ph) i (4) P(w² | ph²)를 계산하기 위해 L2의 발음 사전(영어의 경우 CMUDict)을 사용합니다. 먼저, 정렬을 통해 음소-문자 확률이 생성됩니다. 다음으로, 각 단어에 대해 정렬 점수를 최대화하여 문자 시퀀스를 자소로 변환합니다. 마지막으로, https://en.wikipedia.org/wiki/ARPABET Shttp://www.speech.cs.cmu.edu/cgi-bin/cmudict와 함께 다양한 음소-자소 정렬 표 1: 힌디어, 타밀어 및 벵골어에서 다른 음소 이동에 대한 타당성 점수. LCorrect Word Mispelled Word Phoneme Variation Hindi they thay DH -&gt; TH Tamil exam eksam G -&gt; Kbacterial pactirial B -&gt; P Bengali very equation bery ikvasan V -&gt; B ZH -&gt; S 표 2: 모국어 화자가 평가한 다양한 L1 언어와 L2 언어가 영어인 매우 그럴듯한 오타의 예. 그 빈도는 음소의 빈도로 나누어 확률로 변환합니다. 추론: 손상될 단어의 원래 음소 시퀀스가 주어지면 고정 폭(K) 빔으로 왼쪽에서 오른쪽으로 샘플링을 시작합니다. 각 위치에서 음소-음소 이동과 음소-문자소 대안을 모두 포함하는 상위 K 후보를 탐욕스럽게 선택합니다. 음소-음소 오류 모델과 음소-문자소 밀도 모델은 모두 맥락과 독립적이므로 탐욕적 전략은 글로벌 상위 K 오타를 제공합니다. 마지막 단계에서 동일성 손상이 제거됩니다. 4 평가 우리는 두 가지 뚜렷한 차원에서 우리 모델에 의해 생성된 철자 오류를 평가한다.4.1 타당성 양음성에서 생성된 철자 오류의 타당성을 평가하기 위해 우리는 세 가지 모국어(L1), 즉 힌디어, 타밀어 및 벵골어에 초점을 맞추고 영어는 모국어가 아닌 언어(L2)로 사용한다.힌디어와 벵골어는 인도에서 가장 널리 사용되는 두 언어이며 세계에서도 몇 안 되는 언어에 속한다.타밀어도 인도에서 널리 사용되는 언어이며 소개정밀도 0.0.0.0.0.정밀도-적용 범위 곡선 0.0.0.0.0.2.0 2.적용 범위(%) 3.3.4.그림 3: 다양한 철자 오류 신뢰도 점수에서 표시된 정밀도와 적용 범위(점에 레이블).적용 범위는 영어가 아닌 사전 단어가 하나 이상 있는 31,755,066개 문장의 일부로 표현된다.분석에서 유형적 다양성을 감소시킨다. 마지막으로, L1을 선택한 것도 주석 작업을 위한 모국어 화자의 가용성에 따른 것입니다. 각 언어에 대해 BiPhone에서 모국어 화자에게 생성된 150개의 무작위로 선택된 철자 오류 쌍(힌디어의 경우 5개, 타밀어와 벵골어의 경우 각각 3개)을 제시합니다. 평가자 지침은 다음과 같습니다. 영어 쌍 목록(올바른 단어, 철자 오류)이 주어지면, 해당 첫 번째 언어 화자가 자주 하는 발음 변화에 대해 철자 오류가 타당한지 평가하는 것이 과제입니다. 예를 들어, 벵골어 화자는 종종 &quot;v&quot; 발음을 &quot;b&quot;로 바꾸기 때문에 &quot;evicted&quot;를 &quot;ebicted&quot; 또는 &quot;abicted&quot;로 철자 오류로 표기할 수 있습니다. 각 평가자는 각각 변형이 타당한지 여부를 나타내는 1 또는 0을 제공합니다. 우리는 단순 다수결을 사용하여 각 쌍에 전반적인 레이블을 지정합니다. 이 과제의 평가자는 주석을 달고 있는 언어의 모국어 화자인 동료입니다. 표 1은 각 음소 변화에 대해 타당하다고 평가된 철자 오류의 백분율을 보고합니다. 타밀어의 철자 오류는 다른 언어보다 타당성이 낮은 것으로 평가됩니다. 그 이유는 타밀어에서 발견되는 더 극적인 음소 변화(B -&gt; P 및 G -&gt; K) 때문입니다. 그러나 이러한 변화에서 비롯된 철자 오류는 여전히 완전히 타당하지 않다고 평가되지 않았으며, 이는 이러한 변화가 실제로 흔하다는 것을 강조합니다. 또한 힌디어의 경우 0.40, 타밀어의 경우 0.37, 벵골어의 경우 0.34인 카파 점수를 통해 주석자 간 일치도를 측정합니다. 4.2 보급도: 적용 범위 분석 이전 섹션에서는 Bi-Phone에서 발견된 음소 변화의 타당성과 그 결과로 생성된 철자 오류를 조사했습니다. 그러나 이 조사는 실제 콘텐츠에서 이러한 철자 오류의 만연함을 밝히지 않습니다. 이 섹션에서는 웹 데이터에서 이러한 철자 오류를 발견하여 음성적 철자 오류 문제의 심각성을 평가하는 것을 목표로 합니다. 분석을 위해 실제 웹 데이터의 공개적으로 사용 가능한 스크랩인 Common Crawl 코퍼스를 사용합니다. 대부분의 기존 언어 작업은 이 코퍼스의 매우 정리된 버전을 다루는 반면(Raffel et al., 2020b), 우리는 노이즈가 많은 사용자 생성 텍스트를 유지하기 위해 이러한 필터링 및 정리 단계를 건너뜁니다. 이 분석에서는 모국어(L1)로 힌디어만 사용합니다. 분석에는 (1) 후보 문장 검색, (2) 철자 오류 신뢰도 점수, (3) 인간 평가의 세 가지 단계가 있습니다. 1. 후보 문장 검색: Google ngram 코퍼스(Michel et al., 2011)에서 가장 흔한 영어 단어 상위 10,000개 중 10개의 오타와 Common Crawl 코퍼스에서 영어 단어의 90%-ile을 구성하는 단어를 생성하여 분석을 시작합니다. 영어에서 가장 흔한 단어는 모국어의 영향으로 오타가 발생할 가능성이 가장 높다는 가설이 있습니다. 문장 풀은 영어가 아닌 사전 단어가 하나 이상 있는 모든 문장의 집합입니다. 이 풀의 크기는 31,755,문장입니다. 이 풀에서 생성된 오타 중 하나를 포함하는 모든 문장을 검색하여 후보 세트를 만듭니다. 2. 오타 신뢰도 점수: 다음 단계는 검색된 오타가 실제로 의도한 원래 단어의 노이즈 형태이고 완전히 다른 단어가 아닌지 확인하는 것입니다. 예를 들어, &quot;vare&quot;는 영어 단어 &quot;where&quot;의 변형으로 W -&gt; V 발음이 바뀌거나, 덜 쓰이는 영어 단어로 족제비 7을 의미할 수 있습니다. 이 모호성을 해소하기 위해 간단한 1단어 좌우 맥락을 사용합니다. 맥락에서 잠재적으로 철자가 틀린 단어 Ŵ가 나타날 때마다(Lŵ, Ŵ, Rŵ), 동일한 맥락에서 해당하는 깨끗한 단어(W)를 볼 확률을 평가합니다. 다음과 같이 계산된 이 가능성 P(Lŵ, W, RŴ -)은 검색된 철자 오류에 대한 확신도를 나타내는 점수로 사용할 수 있습니다. &quot;https://commoncrawl.org/ https://www.merriam-webster.com/dictionary/vare 분할 설명 음성 P(Lŵ, W, Rw) F(LW, W, Rw) 잡음 포함 Σw F(Lw, w, Rw) F(Lw, w, Rw) &gt;train dev ข SuperGLUE에서 그대로 분할된 Train Dev가 SuperGLUE에서 그대로 분할됨 아니요 아니요 테스트 F(LW, W) = 0.4 * BiPhone으로 잡음이 적용된 SuperGLUE에서 분할된 Dev 예 + 그렇지 않은 경우 Σw F(Lw, w) F(W, Rw) Σw F(w, Rŵ) 여기서 0.4는 Brants et al.(2007)의 Stupid Backoff 기술에 따른 백오프 가중치입니다. 원래 풀의 총 문장 수에 대해 철자 오류 신뢰도 점수가 특정 임계값보다 큰 문장의 비율을 고려하여 웹 데이터에서 Bi-Phone의 적용 범위를 계산할 수 있습니다. 3. 인간 평가: 마지막으로, 우리는 또한 인간 평가자가 검색된 오타가 실제로 원래 단어와 일치하는지 확인하도록 문장의 하위 집합을 샘플링합니다. 우리는 평가자에게 생성된 오타가 포함된 원래 검색된 문장과 오타가 원래 단어로 대체된 병렬 문장을 보여주고 이 수정이 주어진 맥락에서 유효한지 묻습니다. 우리는 이 인간 평가를 통해 정밀도에 대한 신뢰할 수 있는 지표를 계산할 수 있습니다. 이 작업에 대한 평가는 클라우드 평가 서비스에서 가져오며, 평가자는 대학원 학위를 소지한 힌디어-영어 양방언 화자입니다. 그림 3은 오타 신뢰도 점수의 다양한 임계값에서의 정밀도와 적용 범위를 보여줍니다. 임계값 0.001에서 우리는 약 70%의 정밀도를 가지지만 적용 범위는 1.14%입니다(362,472개 문장*). 초기 풀의 크기(3,000만 개의 후보 문장)와 분석에 사용된 간단한 방법은 이러한 오타가 얼마나 널리 퍼져 있는지를 강조합니다. 또한 이러한 철자 오류는 순수한 UGC(사용자 생성 콘텐츠) 코퍼스에서 훨씬 더 흔할 것이라는 점에 유의하는 것이 중요합니다.C4에는 상당수의 깨끗한 영어 웹 페이지가 포함되어 있습니다.5 FunGLUE 벤치마크 최근 연구에서 언어 이해 과제의 성능을 크게 개선하기 위한 상당한 진전이 이루어졌습니다.SuperGLUE(Wang et al., 2019)는 다양하고 어려운 언어 이해 과제 10개가 있는 매우 인기 있는 벤치마크입니다.이러한 과제는 BoolQ, CommitmentBank(CB), Multi-Sentence Reading Comprehension(MultiRC), Choice of Plausible Alternatives(COPA), Reading Comprehension with Commonsense Reasoning(ReCoRD), Recognizing Textual EntailTable 3: FunGLUE의 분할에 대한 설명입니다.검사점 선택은 음성적 철자 오류가 포함되지 않은 개발 세트에서 수행됩니다.테스트 세트는 결과 보고에만 사용됩니다. 작업 BoolQ 필드 이름 질문 CB 전제 COPA 전제 MultiRC 질문 RECORD 쿼리 RTE 가설 WiC 문장 표 4: FunGLUE를 만들 때 다른 작업에 대해 노이즈를 생성하는 필드. RTE(문맥 내 단어), WiC(맥락 내 단어), Broadcoverage Diagnostics(AX-b), WSC(위노그라드 스키마 챌린지), AX-g(위노그라드 스키마 진단). 우리는 언어 이해 모델이 이중 언어 사용자에게 효과적이려면 언어 간 음성 철자 변화에 강해야 한다고 주장합니다. 이를 위해 우리는 Ph(F)onetically noised GLUE를 의미하는 FunGLUE를 도입합니다. 여기서 SuperGLUE 벤치마크의 작업에서 무작위로 선택된 단어는 Bi-Phone 기반 오타로 손상됩니다. SuperGLUE 개발 세트에 오타를 도입하여 생성된 홀드아웃 평가 세트만 생성한다는 점에 유의하는 것이 매우 중요합니다. 훈련 세트는 노이즈가 있는 훈련 데이터를 얻기 어려운 실제 시나리오를 모방하기 위해 그대로 둡니다. 또한 동일한 소스에서 합성 오타에 대한 모델을 훈련하고 평가하는 것은 불공평할 것입니다. 표 3은 FunGLUE의 훈련, 검증 및 테스트 세트를 요약한 것입니다. 원래 작업의 단어에 대한 오타는 다음과 같은 디자인 선택 사항을 사용하여 Bi-Phone에서 생성됩니다. (i) 노이즈를 적용할 대상: 작업을 현실적으로 유지하고자 하므로 모든 텍스트 필드가 아닌 특정 사전 선택된 필드에만 오타를 도입합니다. 이는 콘텐츠가 종종 잘 철자된 영어로 제공되지만 사용자 쿼리에 음성 오류가 있는 실제 상황을 반영합니다. 표 4는 https://github.com/google-research-datasets/FunGLUE 토큰 오타 예제 w/ 노이즈 작업 boolq 30.6% 96.2% cb 29.5% 96.4% multirc 33.8% 96.4% copa 25.2% 78.0% record 29.5% 99.4% rte wic 35.9% 28.9% 97.1% 84.0%를 보여줍니다. 표 5: FunGLUE에 추가된 노이즈 양에 대한 통계. 작업 SuperGLUE 텍스트 BoolQ 질문: 누군가가 웃음으로 죽을 수 있을까 CB 쿼리: 그는 또한 격렬하게 논란이 된 대선에 대해 언급했습니다 FunGLUE 텍스트 질문: 누군가가 웃음으로 죽을 수 있을까 쿼리: 그는 또한 격렬하게 논란이 된 대선에 대해 언급했습니다 그림 4: SuperGLUE에 대한 FunGLUE의 두 작업 검증 세트의 예. 노이즈가 적용된 버전으로 대체된 단어는 빨간색으로 표시했습니다. 실제로 노이즈를 처리하는 필드입니다. (ii) 사용할 오타: 벤치마크가 고품질일 것으로 예상하기 때문에 품질이 낮은 오타가 벤치마크에 통과하지 못하도록 여러 가지 보호 장치를 설치했습니다. 첫째, 모국어가 힌디어와 벵골어인 이중 음성 오타만 사용하는데, 타밀어 오타는 모국어 화자에 의해 그럴듯하지 않다고 평가되었기 때문입니다. 다음으로, 4자보다 작은 단어의 경우 그럴듯함 점수가 떨어지므로 더 긴 단어만 노이즈 처리합니다. 또한 규칙을 사용하여 Grapheme2Phoneme 모델에서 생성된 특정 패턴의 비현실적인 노이즈가 포함된 철자 오류를 필터링합니다. 마지막으로 FunGLUE에서 사용된 모든 (단어, 철자 오류) 쌍은 팀 구성원이 수동으로 타당하다고 확인합니다. (iii) 추가할 노이즈 양: 인위적으로 너무 많은 노이즈를 도입하고 싶지 않기 때문에 원래 벤치마크에서 작업 전체의 단어 중 30%만 대체합니다. 표 5에는 각 작업에 추가된 노이즈 양에 대한 통계가 나와 있습니다. 현재 평가 세트에 액세스하는 데 어려움이 있어 노이즈가 적용된 버전의 WSC, AX-b 및 AX-g 작업을 포함할 수 없습니다. 최종 데이터 릴리스에 이를 포함할 계획입니다. 5.1 모델 이 섹션에서는 SuperGLUE에서의 성능을 비교하여 최첨단 모델이 FunGLUE에서 도입된 음성 노이즈에 견고한지 조사합니다. 이러한 목적을 위해 mT5(Xue et al., 2021b) 및 ByT5(Xue et al., 2021a) 모델을 고려합니다. 이 둘은 모두 모든 언어 이해 작업을 시퀀스 생성으로 구성하는 변환기 기반 시퀀스-시퀀스 모델입니다. mT5는 텍스트를 표현하기 위해 다국어 코퍼스에 기반한 하위 단어 토큰화를 사용합니다. 따라서 다양성이 낮은 단일 언어 코퍼스에 대한 토큰화를 사용하는 비슷한 모델보다 입력 변형에 더 강해야 합니다. ByT5는 개별 바이트에서 입력 표현을 구축하여 토큰화 단계를 피하고 다양한 작업에서 노이즈가 있는 텍스트에서 더 우아하게 수행하도록 설계되었습니다. 모든 모델에서 기본 아키텍처를 사용합니다. 이러한 모델을 학습하는 데 비용이 많이 들기 때문에 하이퍼 매개변수 검색을 수행하지 않습니다. 대신 원래 논문의 미세 조정 매개변수 값을 사용합니다. 중요한 것은 모든 모델에 대한 미세 조정이 SuperGLUE의 깨끗한 데이터에서 동일하게 수행된다는 것입니다. Raffel et al.(2020a)과 동일한 작업 조합을 사용합니다. 미세 조정은 최대 200,000단계에 걸쳐 수행되며 최상의 검사점은 SuperGLUE의 클린 개발 세트에서의 성능에 따라 선택됩니다. 모든 모델의 미세 조정을 위해 16개의 TPUv3를 사용합니다. 5.2 철자 교정 기준선 철자 교정 방법은 철자가 잘못된 데이터를 처리할 때 명확한 기준선을 제공합니다. 그런 다음 철자가 교정된 데이터를 사용하여 기존 모델로 추론을 실행할 수 있습니다. 이 기술의 장점을 평가하기 위해 두 가지 최신 접근 방식으로 교정한 후의 성능을 측정합니다. (1) NeuSpell BERT(Jayanthi et al., 2020) - BERT 위에 구축된 철자 교정기. (2) BERT-Large 마스크 예측은 철자가 잘못된 위치에서 올바른 단어를 예측하기 위해 BERT Large 모델을 사용합니다. 이 두 접근 방식 모두에서 철자가 잘못된 단어의 위치를 제공합니다. 이 정보는 실제 노이즈가 있는 텍스트에서는 사용할 수 없기 때문에 이점이 있습니다. 우리는 이러한 접근 방식으로 수정된 FunGLUE 평가 세트에서 mT5와 ByT5의 성능을 비교합니다. 5.3 결과 표 6의 행 1-4는 SuperGLUE와 FunGLUE에서 mT와 ByT5의 성능을 보여줍니다. FunGLUE에서 두 모델 모두 성능이 명확히 떨어졌으며, mT5와 ByT5 모두 CB 데이터 세트에서 최대 16 F1 포인트가 떨어졌습니다. mT 모델은 또한 BoolQ 데이터 세트에서 정확도가 약 9포인트 떨어졌고, 마찬가지로 ReCORD 데이터 세트에서도 9 F1 포인트가 떨어졌습니다. ByT5 모델은 일반적으로 mT5 모델보다 더 견고하지만, No. 모델 BoolQ Acc CB COPA MultiRC ReCORD RTE WiC Acc FAcc EM FEM FAcc AccmTByT78.92.79.20 91.SuperGLUE 90.53 61.90.37 58.33.68 73.32.00 70.67.22 68.26 74.37 68.72.10 72.79 81.70.FunGLUEmTЗа mT5 - NeuSpell 3b mT5 - Bert-L 마스크 예측ByT4a ByT5 - NeuSpell 4bByT5 - Bert-L 마스크 예측 Phonetic mTPhonetic ByT68.81 80.36 74.21 55.00 28.23 70.37 58.46 59.46 67.67.92 76.79 74.99 64.00 30.43 70.85 60.36 61.33 65.66.42 71.43 79.6 57.00 27.70 67.91 55.6 56.63 58.74.04 80.36 73.67 58.00 32.42 72.73 67.54 68.19 70.40 66.72.84 76.79 67.86 54.00 32.53 72.47 63.64 64.25 69.68 66.70.52 75.00 70.7 55.00 26.76 68.60 59.75 60.35 64.62 64.71.80 80.36 73.66 53.00 25.81 72.2 55.85 56.86 61.37 63.74.37 87.50 85.46 66.00 33.26 75.15 70.21 70.88 76.17 66.63.65.62.표 6: 처음 4개 행: SuperGLUE 및 FunGLUE(노이즈 처리됨) 벤치마크에서 작업에 대한 SOTA 모델의 성능. mT5와 ByT5(행 3과 4는 행 1과 2와 비교)의 성능은 모두 noised 벤치마크에서 떨어지지만 ByT5(행 4)는 약간 더 강력합니다. 행 3a, 3b, 4a 및 4b는 평가 세트의 철자 오류 단어를 SoTA 기술의 수정으로 바꾼 후의 mT5와 ByT5의 성능을 보여줍니다. mT5는 이러한 수정으로 약간의 이점을 얻지만 철자 수정을 적용한 후 모든 작업에서 ByT5 성능이 저하됩니다. 이는 현재 철자 수정 모델이 이러한 철자 오류를 처리할 수 없음을 보여줍니다. 행 3a 및 4a는 NeuSpell(Jayanthi et al., 2020) 모델의 수정에 해당합니다. 행 3b 및 4b는 Bert-Large 모델의 마스크 예측을 사용한 수정에 해당합니다. 마지막 두 행: 깨끗한 데이터(Phonetic mT5 및 ByT5)에서 음소 예측 작업으로 몇 가지 추가 단계로 학습했을 때의 동일한 모델의 성능입니다. ByT5(행 4에 비해 행 6) 모델은 이러한 사전 학습으로 상당히 향상됩니다. 성능은 또한 RTE에서 정확도가 10포인트 떨어집니다. 철자 교정 기준선(행 3a, 3b, 4a, 4b)도 성능을 회복하지 못합니다. NeuSpell을 사용하면 mT5에서 BoolQ와 RTE가 떨어지고 CB, MultiRC, Record, WIC(&lt;2포인트 Acc/F1)에서 약간 향상됩니다. COPA에서는 상당한 회복(55 -&gt; 64)을 관찰합니다. 그러나 ByT5의 경우 전반적으로 성능이 저하됩니다. NeuSpell은 음성 오타를 처리할 만큼 잘 갖춰져 있지 않습니다. 따라서 철자 교정된 단어는 종종 오타보다 원래 단어에서 멀리 떨어져 있습니다. 이러한 잘못된 교정은 mT5보다 오타에 약간 더 강한 ByT5에 해를 끼칩니다. Bert-Large 마스크 예측을 사용하면 mT5의 경우 COPA와 CB(74.21 -&gt;79.6)가 약간 개선되었지만 다른 모든 작업의 성능은 떨어졌습니다. ByT5의 경우에도 전반적으로 성능이 저하되었습니다. 토큰의 30%가 음성적으로 잘못 철자되었기 때문에 문맥 마스크 예측 작업도 정확하지 않습니다. 관찰한 또 다른 실패 모드는 예측이 종종 올바른 유형(형용사에 대한 형용사)이지만 원래 토큰은 그렇지 않다는 것입니다. 이는 FunGLUE에 도입된 음소 이동 기반 노이즈 철자 오류로 인해 발생하는 문제를 분명히 보여줍니다. 현재 모델과 학습 체계는 이러한 데이터에서 작동하기에 적합하지 않습니다. Span 손상(0.8) 소파 디자인 이<m> 이 소파 디자인은 절묘합니다 디코더 인코더 음소 예측(0.2) /B/ /IH/ /L/ /D/ /IH/ /NG/ 빌딩 그림 5: 표준 범위 손상과 새로운 음소 예측 작업을 80:20 비율로 결합한 혼합 사전 학습 작업의 데모. 모델의 모든 가중치와 임베딩은 공유됩니다. 6 사전 학습 작업으로서의 음소 예측 입력에서 음성 노이즈를 처리하는 데 있어 기존 State-of-the-Art 모델의 부적절성을 감안하여, 우리는 음소 예측의 새로운 사전 학습 작업을 제안합니다. 우리는 음소 시퀀스를 예측하는 작업이 모델에 &quot;음성 정보&quot;를 가르치는 효과가 있을 것이라고 가정합니다. 같은 소리의 다른 어휘화는 같은 음소 시퀀스를 가지므로, 모델은 이러한 가까운 것을 임베딩하는 법을 배울 것입니다. 또한 가까운 소리는 종종 유사한 단어 내 맥락에 나타나므로, 그들의 문자적 표현도 함께 닫힙니다. 그러나 NLP 작업을 수행하려면 의미적 유사성이 여전히 중요합니다. 현재 모델에서 이는 종종 span 손상 작업(입력에서 span을 손상시키고 출력에서 예측)의 일부 변형을 통해 달성됩니다. 우리는 이 두 작업을 혼합하여 음소 예측 작업(20%)의 일부를 표준 span 손상 작업에 혼합하는 방식을 제안합니다. 그림 5는 두 가지 예시 인스턴스를 통해 제안을 보여줍니다. 첫 번째 인스턴스에서 span &quot;sofa design&quot;은 입력에서 마스크 처리되고(sentinel로 대체됨) 출력에서 생성될 것으로 예상됩니다. 이를 통해 모델에 &quot;exquisite&quot;와 같은 형용사가 의미적으로 가깝다는 것을 알려줍니다. 두 번째 인스턴스에는 입력에 &quot;building&quot;이라는 단어가 있고 출력에는 이 단어에 해당하는 음소 시퀀스(B, IH, L, D, IH, NG)가 있습니다. 이 과제는 동일한 소리를 내는 모든 토큰(예: IH의 경우 &quot;ui&quot; 또는 &quot;e&quot;)이 가까이에 임베드되어야 한다는 것을 모델에 알려줍니다. 이 혼합 과제에서 mT5와 ByT5 체크포인트를 모두 추가로 100,000단계(10% 추가 단계) 동안 학습합니다. 이 추가 사전 학습 단계를 &quot;음성 사전 학습&quot;이라고 합니다. 마지막으로 이러한 모델을 표준 클린 SuperGLUE 학습 세트에서 미세 조정합니다. 음소 예측 데이터는 Common Crawl English 데이터에서 가장 높은 빈도의 단어 약 2,000,000개를 가져와 기성 Grapheme to Phoneme 모델에서 발음을 가져와서 만듭니다. 나중에 살펴보겠지만, 이러한 종류의 노이즈가 있는 감독(인간 레이블이 지정되지 않음)은 모델을 음성적으로 견고하게 만드는 데 여전히 유용합니다. 표 6의 마지막 두 행은 FunGLUE에서 이러한 모델의 성능을 보여줍니다. 우리는 phonemeprediction의 간단한 추가 사전 학습 단계가 noised 벤치마크(행 6 대 행 4)에서 ByT5 모델의 성능을 상당히 개선한다는 것을 발견했습니다. CB에서의 성능은 11 F1 포인트 증가하고, COPA에서는 8 포인트의 정확도 향상이 있으며, RTE에서는 5 포인트의 정확도 향상이 있습니다. 성능은 대부분 작업에서 clean 벤치마크 SuperGLUE(행 6 대 행 2)에 비해 여전히 뒤떨어지지만, MultiRC 및 COPA의 경우, 음성학적으로 사전 학습된 ByT5 모델이 clean 작업에서 vanilla 사전 학습된 모델(행 2) 수치보다 더 우수한 것을 발견했습니다. 이것은 Phonetic ByT5 모델(행 6)이 학습하는 동안 노이즈가 있는 데이터를 본 적이 없기 때문에 특히 인상적입니다. 그러나 mT5 모델은 이 사전 학습 작업을 통해 동일한 인상적인 이득을 보지 못했습니다. 우리는 이것이 mT5에서 더 어려운 하위 단어 토큰화 때문이라고 가설을 세웠습니다. 이 모델이 노이즈가 있는 작업에서 필요로 하는 많은 토큰은 깨끗한 데이터로 학습했을 때는 전혀 보이지 않기 때문에 표현이 좋지 않습니다. 그러나 ByT5 모델에는 몇 가지 단점이 있습니다. 바이트 수준 표현에서는 입력 시퀀스가 훨씬 더 길기 때문에 학습 및 추론 시간이 하위 단어 토큰화 대안(예: mT5)보다 훨씬 느립니다. 또한 바이트 수준 표현은 입력 시퀀스 길이도 제한합니다. 이러한 음성학적으로 견고한 바이트 수준 모델을 하위 단어 토큰화 학생 모델의 교사로 사용하는 것은 향후 작업에 흥미로운 방향으로 남아 있습니다. 7
--- CONCLUSION ---
언어는 특히 새로운 인터넷 사용자에게 기술에 대한 상당한 장벽입니다. 이러한 사용자에게 영어는 종종 모국어가 아닙니다. 음성 커뮤니티는 언어 간 상호 작용을 설명하는 모델을 견고하게 만들어 이러한 사용자가 기술(예: ASR)을 사용할 수 있도록 하는 데 상당한 진전을 이루었습니다. 우리는 텍스트에 대한 자연어 이해 커뮤니티에서도 유사한 노력이 필요하다고 주장합니다. 이를 위해 먼저 텍스트에서 L1-L2 상호 작용을 설명할 수 있는 생성 모델인 Bi-Phone을 제안합니다. 다음으로 Bi-Phone에서 생성된 언어 간 섭동이 실제로 일반적인 크롤링 코퍼스에서 비삼각형 양으로 존재한다는 것을 보여줍니다. 또한 이 분야의 추가 연구를 돕기 위해 새로운 벤치마크 FunGLUE를 출시합니다. 또한 새로운 음소 예측 기반 사전 학습을 통해 자연어 이해 모델을 L1-L2 음성 변화에 견고하게 만드는 초기이지만 매우 유망한 탐색을 제시합니다. 8 제한 사항 알고리즘 제한 사항: 현재 접근 방식은 각 음소/음소 손상이 주변 음소/음소와 독립적이라고 가정하는데, 이는 추가적인 통찰력을 얻고 문맥적 음성 변화를 모델링하기 위해 완화할 수 있습니다. 음소와 음소 손상 간의 상대적 중요도는 커뮤니티의 오류 유형에 더 많이 개인화하기 위한 하이퍼파라미터로 탐색할 수도 있습니다. 기타 제한 사항(사용 가능한 데이터 및 기존 리소스와 관련하여): 당사의 커버리지 분석은 이러한 L1-L2 음성적 철자 오류가 더 흔할 수밖에 없는 다양한 소셜 미디어에서 사용자가 생성한 데이터를 포함하지 않기 때문에 보수적입니다. 또한 커버리지 분석은 문맥이 손상되지 않은 것에 의존합니다. 그러나 이는 반드시 성립하지 않을 수 있으며 분석은 손상된 문맥이 있는 사례도 고려하는 완화된 일치 기준을 신중하게 공식화하는 데 도움이 될 수 있습니다. 음역이 당사 솔루션에서 중요한 역할을 하기 때문에 음역 모듈을 구축할 모델이나 적절한 데이터 세트가 없는 저리소스 언어로 작업을 즉시 확장하기 어렵습니다. 참고 문헌 Yves Bestgen 및 Sylviane Granger. 2011. L2 쓰기 평가를 위한 철자 오류 분류. 국제 지속 공학 교육 및 평생 학습 저널, 21(2-3):235–252. Irshad Ahmad Bhat, Vandan Mujadia, Aniruddha Tammewar, Riyaz Ahmad Bhat, Manish Shrivastava. 2015. 문자 검색에 대한 fire2014 공유 과제를 위한 Iiit-h 시스템 제출. 정보 검색 평가 포럼 회의록, FIRE &#39;14, 48-53페이지, 뉴욕, 뉴욕, 미국. ACM. Jordan J. Bird, Elizabeth F. Wanner, Anikó Ekárt, Diego R. Faria. 2019. 영어 원어민과 비원어민을 위한 인간 음성 생체 인식의 악센트 분류. In Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments, PETRA 2019, Island of Rhodes, Greece, June 5-7, 2019, pages 554–560. ACM. Daniel Blanchard, Joel Tetreault, Derrick Higgins, Aoife Cahill, and Martin Chodorow. 2013. Toefl11: A corpus of non-native english. ETS Research Report Series, 2013:i-15. Thorsten Brants, Ashok C. Popat, Peng Xu, Franz J. Och, and Jeffrey Dean. 2007. Large language models in machine translation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CONLL)의 2007년 회의록, pages 858-867, Prague, Czech Republic. Association for Computational Linguistics. Lingzhen Chen, Carlo Strapparava, and Vivi Nastase. 2017. 철자 오류를 사용하여 모국어 식별 개선. Association for Computational Linguistics 제55회 연례 회의록(제2권: 단편 논문), 542-546쪽, 캐나다 밴쿠버. Association for Computational Linguistics. Vivian Cook. 1997. L2 사용자와 영어 철자. Journal of Multilingual and Multicultural Development, 18(6):474-488. Gary F. Simons Eberhard, David M. and Charles D. Fennig. 2022. Ethnologue, 세계 언어. http://www. ethnologue.com/. Michael Flor, Michael Fried, and Alla Rozovskaya. 2019. 영어 철자 오류의 벤치마크 코퍼스와 철자 교정을 위한 최소 감독 모델. 교육적 응용 프로그램을 구축하기 위한 NLP의 혁신적 사용에 대한 제14회 워크숍 회의록, 76-86페이지, 이탈리아 피렌체. 계산 언어학 협회. Gregory Grefenstette와 Julien Nioche. 2000. www에서 영어와 비영어 언어 사용에 대한 추정. 콘텐츠 기반 멀티미디어 정보 액세스 제1권, RIAO &#39;00, 237-246페이지, 프랑스 파리. LE CENTRE DE HAUTES ETUDES INTERNATIONALES D&#39;INFORMATIQUE DOCUMENTAIRE. Daniel Hládek, Ján Staš, and Matúš Pleva. 2020. 자동 철자 교정 조사. 전자, 9(10). Muhammad Hasan Ibrahim. 1978. 철자 오류의 패턴. 영어 교육, 32:207-212. Sai Muralidhar Jayanthi, Danish Pruthi, Graham Neubig. 2020. NeuSpell: 신경 철자 교정 툴킷. 2020 자연어 처리 경험적 방법에 대한 컨퍼런스 회의록: 시스템 데모, 158-164페이지, 온라인. 계산 언어학 협회. Karen Kukich. 1992. 텍스트에서 단어를 자동으로 교정하는 기술. ACM Comput. Surv., 24(4):377-439. Jean-Baptiste Michel, Yuan Kui Shen, Aviva Presser Aiden, Adrian Veres, Matthew K Gray, Google Books Team, Joseph P Pickett, Dale Hoiberg, Dan Clancy, Peter Norvig, et al. 2011. 수백만 권의 디지털화된 책을 사용한 문화의 양적 분석. 과학, 331(6014):176–182. 미키 모토하시-사이고와 토루 이시자와. 2020. L1 영어 화자의 12가지 일본어 음운론에서 철자 출력과 지각 간의 관계. 앰퍼샌드, 7:100071. 료 나가타, 히로야 타카무라, 그레이엄 노이빅. 2017. 학습자 영어를 위한 적응형 철자 오류 수정 모델. Procedia Computer Science, 112:474-483. 지식 기반 및 지능형 정보 및 엔지니어링 시스템: 21회 국제 회의록, KES-20176-2017년 9월, 프랑스 마르세유. Saul B. Needleman과 Christian D. Wunsch. 1970. 두 단백질의 아미노산 서열에서 유사성을 검색하는 데 적용할 수 있는 일반적인 방법. 분자 생물학 저널, 48(3):443–453. Garrett Nicolai, Bradley Hauer, Mohammad Salameh, Lei Yao, Grzegorz Kondrak. 2013. 자연어 식별을 위한 동족 및 철자 오류 기능. 교육적 응용 프로그램을 구축하기 위한 NLP의 혁신적 사용에 대한 제8회 워크숍 회의록, 140~145페이지, 조지아주 애틀랜타. Association for Computational Linguistics. Anastasiia Ogneva. 2018. L2 러시아어의 철자 오류: 스페인어를 사용하는 학생들의 증거. Estudios interlingüísticos, 6:116~131. Kacper Radzikowski, Robert Nowak, Le Wang, Osamu Yoshie. 2019. 모국어가 아닌 언어의 음성 인식을 위한 이중 지도 학습. EURASIP J. Audio Speech Music. Process., 2019:3. Kacper Radzikowski, Le Wang, Osamu Yoshie, Robert M. Nowak. 2021. 신경 스타일 전이를 이용한 비원어민의 음성 인식을 위한 악센트 수정. EURASIP J. Audio Speech Music. Process., 2021(1):11. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020a. 통합 텍스트-텍스트 변환기를 사용한 전이 학습의 한계 탐구. Journal of Machine Learning Research, 21(140):1-67. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. 2020b. 통합 텍스트-텍스트 변환기를 사용한 전이 학습의 한계 탐구. J. Mach. Learn. Res., 21(140):1–67. Ida Rukmana Sari. 2014. 7학년 필수 단어에 대한 학생들의 철자 오류의 일반적 사례. Educate, 4(2):35-43. Sanket Shah, Satarupa Guha, Simran Khanuja, and Sunayana Sitaram. 2020. 저소득 인도어를 위한 언어 간 및 다국어 구어체 용어 감지. CoRR, abs/2011.06226. Kristina Toutanova and Robert Moore. 2002. 철자 교정 개선을 위한 발음 모델링. 미국 펜실베이니아주 필라델피아에서 열린 제40회 전산언어학 협회 연례 회의록, 144-151쪽. 전산언어학 협회. Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. 2019. Superglue: 범용 언어 이해 시스템을 위한 더 끈적끈적한 벤치마크. 신경 정보 처리 시스템의 발전, 32. Linting Xue, Aditya Barua, Noah Constant, Rami AlRfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel. 2021a. Byt5: 사전 학습된 바이트-바이트 모델을 사용한 토큰 없는 미래를 향하여. CoRR, abs/2105.13626. Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel. 2021b. mT5: 대규모 다국어 사전 학습된 텍스트-텍스트 변환기. 2021년 북미 컴퓨터 언어학회 회의록: 인간 언어 기술, 483-498쪽, 온라인. 컴퓨터 언어학회.
