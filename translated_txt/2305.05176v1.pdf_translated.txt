--- ABSTRACT ---
사용자가 유료로 쿼리할 수 있는 대규모 언어 모델(LLM)의 수가 빠르게 증가하고 있습니다. 인기 있는 LLM API(예: GPT-4, ChatGPT, J1-Jumbo)를 쿼리하는 데 관련된 비용을 검토하고 이러한 모델에는 이질적인 가격 책정 구조가 있으며 수수료는 두 자릿수 차이가 날 수 있음을 발견했습니다. 특히, 대규모 쿼리 및 텍스트 컬렉션에 LLM을 사용하는 것은 비쌀 수 있습니다. 이를 바탕으로 사용자가 LLM 사용과 관련된 추론 비용을 줄이기 위해 활용할 수 있는 세 가지 유형의 전략을 개략적으로 설명하고 논의합니다. 1) 신속한 적응, 2) LLM 근사, 3) LLM 카스케이드. 예를 들어, 비용을 줄이고 정확도를 높이기 위해 다양한 쿼리에 사용할 LLM 조합을 학습하는 간단하면서도 유연한 LLM 카스케이드 인스턴스인 FrugalGPT를 제안합니다. 저희의 실험은 FrugalGPT가 최대 98%의 비용 절감으로 최상의 개별 LLM(예: GPT-4)의 성능과 맞먹거나 동일한 비용으로 GPT-4보다 정확도를 4% 향상시킬 수 있음을 보여줍니다. 여기에 제시된 아이디어와 결과는 LLM을 지속 가능하고 효율적으로 사용하기 위한 기반을 마련합니다.
--- INTRODUCTION ---
우리는 대규모 언어 모델(LLM)의 폭발적 증가의 한가운데에 있습니다. 상업, 과학, 금융과 같은 대규모 애플리케이션에 LLM을 사용할 수 있는 매혹적인 가능성으로 인해 점점 더 많은 회사(OpenAI, AI21, CoHere 등)가 LLM을 서비스로 제공하게 되었습니다. GPT-4와 같은 LLM은 질문 답변과 같은 작업에서 전례 없는 성능을 달성하지만, 이를 고처리량 애플리케이션에 사용하면 매우 비쌀 수 있습니다. 예를 들어, ChatGPT는 하루에 70만 달러 이상의 운영 비용이 들 것으로 추산되며 [Cosa], GPT-4를 사용하여 고객 서비스를 지원하려면 소규모 기업이 한 달에 21,000달러 이상의 비용이 들 수 있습니다 [Cosb]. 재정적 비용 외에도 가장 큰 LLM을 사용하면 상당한 환경 및 에너지 영향[BGMMS21, WRG+22]이 발생하여 현재와 미래 세대의 사회 복지에 영향을 미칩니다. 현재 API를 통해 사용할 수 있는 LLM이 많이 있으며 가격은 다양합니다. LLM API를 사용하는 비용은 일반적으로 세 가지 구성 요소로 구성됩니다. 1) 프롬프트 비용(프롬프트 길이에 비례), 2) 생성 비용(생성 길이에 비례), 3) 때로는 쿼리당 고정 비용입니다. OpenAI, AI21, CoHere 및 Textsynth를 포함한 주류 공급업체의 12가지 다른 상업용 LLM을 사용하는 데 따른 비용을 비교했습니다(표 1). 비용은 최대 수십 배까지 다를 수 있습니다. 예를 들어, 10M 토큰에 대한 프롬프트 비용은 OpenAI의 GPT-4의 경우 30달러이지만 Textsyth에서 호스팅하는 GPT-J의 경우 0.2달러에 불과합니다. 이질적인 비용과 품질을 감안할 때, LLM 옵션의 전체 세트를 효과적이고 효율적으로 활용하는 방법은 실무자에게 중요한 과제입니다. 작업이 비교적 간단한 경우 GPT-J[WK21](GPT-3보다 크기가 30배 작음)에서 여러 응답을 집계하면 GPT-3[ANC+22]과 유사한 성능을 제공하여 재정적 및 환경적 절감으로 이어집니다. 그러나 GPT-J의 성능은 어려운 작업에서 훨씬 더 나쁠 수 있습니다[TLI+23]. 게다가 하나의 API 공급자에 의존하는 것은 해당 공급자가 수요 급증으로 인해 사용할 수 없게 되면 신뢰할 수 없습니다. 모델 캐스케이드[VJ04, WLM11] 및 FrugalML[CZZ20, CZZ22]과 같은 기존 모델 앙상블 패러다임은 알려진 레이블 집합이 있는 예측 작업을 위해 설계되었으며 LLM의 모든 기능을 고려하지 않습니다. 따라서 LLM을 저렴하고 정확하게 사용하는 방법에는 새로운 접근 방식이 필요합니다. 저희의 기여. 이 논문에서는 예산 제약 내에서 자연어 쿼리를 처리하기 위해 LLM API를 사용하는 유연한 프레임워크인 FrugalGPT에 대한 비전을 제시합니다. 그림에서 보인 것처럼 Query ✓ GPT-(a) 기존 LLM 사용 Zero-shot Few-shot. → 정답 0.FrugalGPT 0.★GPT-0.●GPT-3JCOT 0.GPT-Neo 쿼리 프롬프트 적응 계단식 LLM 정확도 ChatGPT 0.0.GPT-GCoHere 0.J1-L 정답 0.Budget LLM 근사 0.FSQ FQ 0.◆GPT-CGPT-J ChatGPT GPT-비용 ($) (b) 제안된 FrugalGPT (c) 성능 및 비용 균형 그림 1: 정확도를 개선하는 동시에 LLM 비용을 줄이기 위한 비전. (a) 표준 사용은 단일 LLM(예: GPT-4)으로 쿼리를 보내는데, 이는 비용이 많이 들 수 있습니다. (b) 제안은 추론 비용을 줄이기 위해 프롬프트 적응, LLM 근사 및 LLM 계단식을 사용하는 것입니다. 다양한 LLM API(예: GPT-J, ChatGPT 및 GPT-4)의 선택과 프롬핑 전략(예: 제로샷[BMR+20], 퓨샷[LSZ+21], 생각의 사슬(CoT)[WWS+22])을 최적화함으로써 상당한 효율성 이득을 얻을 수 있습니다.(c) HEADLINES(금융 뉴스 데이터 세트)에서 FrugalGPT는 최상의 개별 LLM(GPT-4)의 성능을 능가하는 동시에 추론 비용을 98%까지 줄일 수 있습니다.1에서는 비용 절감을 위한 세 가지 주요 전략, 즉 프롬프트 적응, LLM 근사, LLM 카스케이드에 대해 설명합니다. 프롬프트 적응은 비용을 절감하기 위해 효과적인(종종 더 짧은) 프롬프트를 식별하는 방법을 살펴봅니다.LLM 근사는 특정 작업에서 강력하지만 비싼 LLM과 일치하도록 더 간단하고 저렴한 LLM을 만드는 것을 목표로 합니다.LLM 카스케이드는 다양한 쿼리에 사용할 LLM API를 적응적으로 선택하는 방법에 중점을 둡니다. 이러한 아이디어의 잠재력을 보여주기 위해 LLM 캐스케이드를 사용하여 FrugalGPT의 간단한 버전을 구현하고 평가합니다. 각 데이터 세트와 작업에서 FrugalGPT는 ChatGPT [Cha], GPT-3 [BMR+20] 및 GPT-4 [Ope23]를 포함한 다양한 LLM 조합에 대해 데이터 세트의 다양한 쿼리를 적응적으로 분류하는 방법을 학습합니다. 실험 결과 FrugalGPT는 다운스트림 작업에서 성능을 맞추는 동시에 최상의 개별 LLM API의 추론 비용을 최대 98%까지 절감할 수 있음을 보여줍니다. 반면 FrugalGPT는 동일한 비용으로 성능을 최대 4%까지 향상시킬 수 있습니다. 이것이 빙산의 일각일 뿐이라고 생각하며 FrugalGPT가 LLM의 추론 비용을 줄이고 성능을 개선하기 위한 새로운 창을 열기를 바랍니다.
--- RELATED WORK ---
s. 프롬프트 엔지니어링. 프롬프트 엔지니어링은 다양한 응용 프로그램에서 LLM의 성과를 향상시키기 위한 프롬프트를 제작하는 분야로 등장했습니다. 최근 개발된 것으로는 few-shot [BMR+20], chain-of-thought [WWS+22], knowledge enhancement [LLL+21, KSL+22] 및 기타 수많은 프롬프트 기술 [MDL+23, KTF+22, ZSH+22, DGSG22]이 있습니다. 기존의 프롬프트 엔지니어링 접근 방식은 종종 더 자세한 작업 설명과 맥락 내 예를 제공하는 것을 목표로 하며, 그 결과 더 길고 비용이 많이 드는 프롬프트가 생성됩니다. 이와 대조적으로 이 논문에서는 간결한 프롬프트를 사용하여 비용을 절감하는 방법을 살펴봅니다. 모델 앙상블. 예측을 위해 여러 ML 모델을 결합하는 모델 앙상블은 지도 학습 [VJ04, Fri02], 비지도 학습 [YLLL14], 반지도 학습 [GDMR22] 및 약한 지도 학습 [DSP+17]에서 인기를 얻었습니다. 모델 앙상블은 일반적으로 학습 목적으로 여러 모델에 대한 화이트박스 액세스가 필요하지만 LLM API는 종종 블랙박스입니다.또한 모델 앙상블은 단일 쿼리에 대해 모든 모델을 쿼리해야 하므로 비용이 증가합니다.LLM을 위한 시스템 최적화.수많은 노력이 시스템 최적화를 통해 최신 딥 러닝 모델의 학습 및 추론 시간을 가속화하는 것을 목표로 했습니다[HMD15, CHSV17, Cas19, JZA19, RRWN11].최근 연구는 LLM에 맞게 조정된 학습 후 양자화[BHS+22, YLW+23, XLS+22], 학습 파이프라인 병렬 처리[LZG+21] 및 하드웨어 인식 가지치기[KFA23]에 중점을 둡니다.시스템 최적화에는 LLM의 내부 상태(예: 모델 가중치)를 수정해야 하지만 많은 상업용 LLM API는 모델을 릴리스하지 않습니다.또한 LLM의 크기가 빠르게 증가함에 따라 재학습 비용이 매우 많이 듭니다.ML-as-a-Service. LLM API는 빠르게 확장 중인 Machine Learning-as-a-Service(MLaaS) 산업의 중요한 구성 요소입니다. 최근 연구에서는 다양한 ML API의 예측의 다양성[BG18, KNL+20, CCZZ21]을 입증했으며 다양한 분류 ML API를 활용하여 성능을 개선하기 위한 전략을 제안했습니다[CZZ20, CZZ22]. LLM API의 출력은 전체 자연어 공간을 포함하지만 기존 작업에는 고정된(그리고 알려진) 레이블 집합이 필요합니다. 게다가 프롬프트 선택과 LLM API 선택은 모두 생성 작업의 성능에 상당한 영향을 미쳐 표준 분류보다 상당히 더 큰 최적화 공간을 초래합니다. 논문의 나머지 부분은 다음과 같이 구성됩니다. 먼저 섹션 2에서 더 많은 맥락과 문제 진술을 제공합니다. 다음으로 섹션 3에서는 LLM API를 저렴하고 정확하게 사용하는 방법에 대한 비전을 제시합니다. 섹션 4에서는 실제 LLM API(GPT-3, Chat GPT 및 GPT-4 포함)를 사용하여 FrugalGPT의 경험적 이점을 보여줍니다. 마지막으로, 섹션 5에서 미래 전망에 대해 논의합니다.2 범위 및 문제 진술 자연어 질의 응답.이 논문에서는 자연어 질의 분포 Q에서 샘플링한 질의 q에 답하는 것이 목표인 표준 자연어 질의 응답 작업에 집중합니다.뉴스 분류, 독해 이해, 상식적 추론과 같은 다양한 실제 자연어 작업은 질의 응답 문제로 공식화할 수 있습니다.LLM 시장.{fi()}1로 표시되는 K개의 서로 다른 LLM API로 구성된 LLM 시장을 통해 질의에 답하는 것을 고려합니다.각 fi(·) : P⇒ A는 프롬프트 공간 P에서 프롬프트 p가 주어지면 답변 분포 A에서 답변을 생성하는 함수입니다.LLM API를 사용하려면 먼저 각 쿼리 q를 해당 프롬프트로 변환해야 합니다.LLM API는 자체 비용과 연관되며 일반적으로 프롬프트 길이에 비례하는 부분, 생성된 답변 길이에 비례하는 부분, (때로는) 쿼리당 고정 비용으로 구성됩니다. 형식적으로 프롬프트 p가 주어졌을 때 i번째 LLM API를 사용하는 비용은 Ci(p) či,2||fi(p)|| + či,1||P|| + či,0으로 표시되며, 여기서 či,j, j = 0, 1, 2는 상수입니다.Δ 설명적인 예.[Cosa]에서 제공한 사례 연구를 적용하여 소규모 기업이 GPT-4를 사용하여 고객 서비스를 운영한다고 가정합니다.이 회사는 매달 15,000명의 고객을 대상으로 하며, 각 고객은 일주일에 두 번씩 세 가지 질문을 하여 한 달에 총 360,000개의 쿼리를 처리합니다.각 질문에 대해 해당 프롬프트의 평균이 1,800개이고 답변이 약 80개 토큰이라고 가정합니다. GPT-4의 입력 및 응답 비용이 각각 천 개의 토큰당 $0.03 및 $0.06인 것을 고려하면 총 월간 비용은 360 × ($0.03 × 1800 + $0.06 × 80) ≈ $21.2K입니다. 이렇게 높은 비용은 많은 소규모 기업에게는 엄두도 못 낼 일입니다. 문제 설명: 예산을 고려한 LLM API 사용. 이 논문의 주요 목표는 예산 제약 내에서 LLM API를 활용하는 것입니다. 형식적으로 이는 전체 작업 성능 E(q,a)€Q×A[r(a, â(s, q))]을 최대화하는 동시에 평균 비용이 사용자 정의 값 b, 즉 E(q,a)€Q×A[C(8, 9)] ≤ b로 제한되도록 하는 것으로 공식화할 수 있습니다. 여기서 a는 질의 q에 대한 정답을 나타내고, â(s,q)는 질의 q에 대한 전략 s에 의해 생성된 정답이며, c(s, q)는 전략 s를 사용하여 질의 q를 처리하는 데 관련된 비용입니다. 보상 함수 r(·, ·)는 생성된 답이 정답과 얼마나 일치하는지 측정합니다. 전략에 대한 검색 공간이 방대하며, 사용할 프롬프트, 사용할 LLM API, 응답을 집계하는 방법 등의 요소를 포함한다는 점에 유의하는 것이 중요합니다. LLM을 저렴하고 정확하게 사용하는 방법 이제 예산 내에서 LLM API를 사용하는 방법에 대한 비전을 제시합니다. 그림 1(b)에서 볼 수 있듯이 프롬프트 적응, LLM 근사, LLM 캐스케이드라는 세 가지 비용 절감 전략을 설명합니다. 프롬프트: Q1+A1, Q2+A2, Q3+A3, Q4+AQ: 고온에서 N과 O2의 결과는 무엇입니까? 프롬프트: Q1+A1, Q2+A2,Q3+A3,Q4+AQ: N2와 Oat 고온의 결과는 무엇입니까? 프롬프트: Q1+A1,Q2+A2,Q3+A3,Q4+AQ: 먹이가 숨는 데 도움이 되는 것은 무엇입니까? Q: 고온에서 N과 O2의 결과는 무엇입니까? 프롬프트: Q2+A2,Q4+APrompt Selector Q: 고온에서 N과 O2의 결과는 무엇입니까? GPT-NO(a) 프롬프트 선택 프롬프트: Q1+Q2,A1+A2,Q3+Q4,A3+AQ1: 고온에서 NQuery Concatenator와 O2의 결과는 무엇입니까? NOGPT-Q2: 먹이가 숨는 데 도움이 되는 것은 무엇입니까? 위장 (b) 쿼리 연결 Q&#39;: 고온에서 N2와 O2는 무엇으로 이어집니까? Q≈ Q&#39; 캐시 NOA&#39;: GPT-NO와 질소산화물(c) 완료 캐시 Fine-Tuner 먹이가 숨는 데 도움이 되는 것은 무엇인가? 반향 정위에서 오는 것은 무엇인가? 위장 GPT-소나 Q: 고온에서 N₂ GPT-J와 O2의 결과는 무엇인가? (d) 모델 미세 조정 GPT-J LLM 체인 GPT-GPT-Q: 먹이가 숨는 데 도움이 되는 것은 무엇인가? 위장 점수 &lt;0.5 위장 점수 &lt;0.9 위장 답변 수락 답변 수락 답변 수락 (e) LLM 카스케이드 NOcamouflage 그림 2: 비용 절감 전략의 예. (a) 프롬프트 선택은 프롬프트의 크기를 줄이기 위해 컨텍스트 내 예제의 하위 집합을 프롬프트로 사용합니다. (b) 쿼리 연결은 여러 쿼리를 집계하여 프롬프트를 공유합니다. (c) 완료 캐시는 유사한 쿼리가 요청될 때 LLM API의 응답을 저장하고 재사용합니다. (d) 모델 미세 조정은 값비싼 LLM의 응답을 사용하여 값싼 LLM을 미세 조정합니다. (e) LLM 캐스케이드는 다른 쿼리에 대해 다른 LLM API를 사용합니다. 전략 1: 프롬프트 적응. LLM 쿼리의 비용은 프롬프트 크기에 따라 선형적으로 증가합니다. 결과적으로 LLM API 사용 비용을 줄이는 논리적인 접근 방식에는 프롬프트 크기를 줄이는 것이 포함되며, 이 프로세스를 프롬프트 적응이라고 합니다. 프롬프트 선택(그림(a)에 나와 있음)은 프롬프트 적응의 자연스러운 예입니다. 작업 수행 방법을 보여주는 수많은 예제가 포함된 프롬프트를 사용하는 대신 프롬프트에서 예제의 작은 하위 집합을 유지할 수 있습니다. 그 결과 프롬프트가 작아지고 결과적으로 비용이 낮아집니다. 프롬프트 선택의 흥미로운 과제는 작업 성능을 저하시키지 않고 다양한 쿼리에 대해 어떤 예제를 유지할지 결정하는 데 있습니다. 추가 인스턴스화는 쿼리 연결(그림 2(b))입니다. 쿼리를 개별적으로 처리하려면 동일한 프롬프트를 LLM API에 여러 번 보내야 한다는 점에 유의하는 것이 중요합니다. 따라서 쿼리 연결의 기본 개념은 여러 쿼리를 처리하면서 LLM API에 프롬프트를 한 번만 보내 중복된 프롬프트 처리를 방지하는 것을 포함합니다. 이를 위해 여러 쿼리를 하나의 쿼리로 연결해야 하며 프롬프트는 LLM API에 여러 쿼리를 처리하도록 명시적으로 요청해야 합니다. 예를 들어, 하나의 프롬프트를 사용하여 두 개의 쿼리를 처리하기 위해 프롬프트에 제시된 예에는 두 쿼리 뒤에 해당 답변이 포함될 수 있습니다. 전략 2: LLM 근사. LLM 근사 개념은 매우 간단합니다. LLM API를 사용하기에 비용이 너무 많이 드는 경우 더 저렴한 모델이나 인프라를 사용하여 근사할 수 있습니다. 한 가지 예는 완료 캐시입니다. 그림 2(c)에 나와 있듯이 기본 아이디어는 LLM API에 쿼리를 제출할 때 캐시(예: 데이터베이스)에 응답을 로컬로 저장하는 것입니다. 새 쿼리를 처리하려면 먼저 유사한 쿼리가 이전에 답변되었는지 확인합니다. 그렇다면 캐시에서 응답을 검색합니다. 캐시에서 유사한 쿼리가 발견되지 않는 경우에만 LLM API가 호출됩니다. 유사한 쿼리가 자주 제기될 때 완료 캐시는 상당한 비용 절감을 제공합니다. 예를 들어, LLM API로 구동되는 검색 엔진을 생각해 보세요. 여러 사용자가 동일하거나 유사한 키워드를 동시에 검색하는 경우 완료 캐시는 LLM을 한 번만 호출하여 모든 쿼리에 답할 수 있도록 해줍니다. LLM 근사의 또 다른 예는 모델 미세 조정입니다. 그림 2(d)에서 볼 수 있듯이 이 프로세스는 세 단계로 구성됩니다. 첫째, 강력하지만 비용이 많이 드는 LLM API의 몇 가지 쿼리에 대한 응답을 수집합니다. 둘째, 응답을 사용하여 더 작고 저렴한 AI 모델을 미세 조정합니다. 마지막으로 미세 조정된 모델을 새로운 쿼리에 사용합니다. 비용 절감 외에도 미세 조정된 모델은 긴 프롬프트가 필요하지 않으므로 부산물로 대기 시간 개선을 제공합니다. 전략 3: LLM 캐스케이드. 이기종 성능과 비용을 가진 LLM API의 가용성이 증가함에 따라 데이터 적응형 LLM 선택에 대한 고유한 기회가 제공됩니다. 다양한 LLM API에는 다양한 쿼리에 대한 고유한 강점과 약점이 있습니다. 따라서 사용할 LLM을 적절히 선택하면 비용 절감과 성능 개선을 모두 제공할 수 있습니다.그림 2(e)에 나와 있는 LLM 카스케이드가 그러한 예 중 하나입니다.LLM 카스케이드는 LLM API 목록에 순차적으로 쿼리를 보냅니다.한 LLM API의 응답이 신뢰할 수 있으면 해당 응답이 반환되고 목록에 더 이상 LLM이 필요하지 않습니다.나머지 LLM API는 이전 API의 세대가 충분히 신뢰할 수 없다고 간주되는 경우에만 쿼리됩니다.처음 몇 개의 API가 비교적 저렴하고 신뢰할 수 있는 세대를 생성하면 쿼리 비용이 크게 줄어듭니다.LLM 카스케이드의 핵심 구성 요소는 두 가지 요소로 구성됩니다.(i) 세대 점수 함수 및(ii) LLM 라우터.g(·, ·) : Q × A➡ [0, 1]로 표시되는 세대 점수 함수는 LLM API에서 생성된 쿼리와 답변이 주어졌을 때 신뢰성 점수를 생성합니다.LLM 라우터는 목록에 포함할 m개의 LLM API를 선택합니다. L = [K] m이 라우터에서 선택한 m개 API의 인덱스를 나타낸다고 하자. 새로운 쿼리가 주어지면, 목록에서 i번째 API를 반복적으로 호출하여 답변 fL;(9)을 얻는다. 그런 다음, 스코어링 함수를 사용하여 점수 g(q, fL; (9))를 생성한다. 점수가 임계값 Ti보다 높으면 세대를 반환하고, 그렇지 않으면 다음 서비스를 쿼리한다. 스코어링 함수는 쿼리와 생성된 답변에서 세대가 올바른지 여부를 학습하는 단순 회귀 모델을 학습하여 얻을 수 있다. 선택된 목록 L과 임계값 벡터 7을 학습하는 것은 제약 조건 최적화 문제로 모델링할 수 있다. max E[r(a, fL (9))] LT st EΣ ČL₁,2||ƒL; (9)|| + ČLi,1||9|| + ČLi,0| ≤b, Σ Li=z = arg min g(q, fL¿(9)) ≥ Ti i 여기서, z는 라우터가 멈추고 답을 반환하는 LLM API를 나타내고, 첫 번째 제약 조건은 평균 비용이 예산에 의해 제한되도록 보장하고, 목적은 쿼리 q에 대한 생성 fL₂(q)의 품질을 참 답 a와 비교하여 측정합니다. 이 문제는 본질적으로 혼합 정수 최적화이므로 해결하는 데 계산 비용이 많이 듭니다. 이 문제를 해결하기 위해 (i) 답의 불일치가 작은 LLM 목록을 무시하여 L의 검색 공간을 정리하고 (ii) 몇 개의 샘플 내에서 보간하여 목적을 근사하는 특수 최적화기를 개발합니다. 이는 그림 5에서 나중에 볼 수 있듯이 만족스러운 성능을 보이는 효율적인 구현으로 이어집니다. 구성. 다양한 전략 내부 및 전략 간에 접근 방식을 결합하면 비용을 더욱 절감하고 성능을 향상시킬 수 있습니다. 예를 들어, 공동 프롬프트 및 LLM 선택은 프롬프트 선택과 LLM 카스케이드의 구성입니다. 주어진 쿼리에 대해 만족스러운 작업 성능을 달성하는 가장 작은 프롬프트와 가장 저렴한 LLM을 검색합니다. 또 다른 예는 기존 LLM API와 미세 조정된 모델 모두에서 검색하는 것입니다. 다양한 접근 방식의 구성은 학습을 위한 계산 비용도 증가시킨다는 점에 유의하는 것이 중요합니다. 결과적으로 이는 쿼리 비용, 작업 성능 및 계산 비용 간의 상충 관계를 조사하는 길을 열어줍니다. LLM 카스케이드는 비용을 줄이고 정확도를 향상시킵니다 이 섹션에서는 FrugalGPT LLM 카스케이드에 대한 실증적 연구를 제시합니다. 저희의 목표는 세 가지입니다. (i) LLM 카스케이드의 간단한 인스턴스가 무엇을 학습하는지 이해합니다. (ii) 최상의 개별 LLM API의 성능과 일치하면서 Frugal GPT가 달성한 비용 절감을 정량화합니다. (iii) FrugalGPT가 가능하게 한 성능과 비용 간의 상충 관계를 측정합니다. 설정: LLM API, 작업, 데이터 세트 및 FrugalGPT 인스턴스. OpenAI [Ope], AI21 [AI2], CoHere [COH], Textsynth [Tex] 및 ForeFrontAI [FFA]라는 5개 주류 공급업체에서 12개의 LLM API를 선택했습니다. 세부 정보는 표 1에 요약되어 있습니다. FrugalGPT는 이러한 API를 기반으로 개발되었으며 HEADLINES [SK21], OVERRULING [ZGA+21] 및 COQA [RCM19]를 포함한 다양한 작업에 속하는 다양한 데이터 세트에서 평가되었습니다. 이러한 데이터 세트의 요약은 표 2에 나와 있습니다. HEADLINES는 금융 뉴스 제목을 읽어 금 가격 추세(상승, 하락, 중립 또는 없음)를 파악하는 것을 목표로 하는 금융 뉴스 데이터 세트입니다. 이는 특히 금융 시장에서 관련 뉴스를 필터링하는 데 유용합니다. OVERRULING은 주어진 문장이 이전 법적 판례를 기각하는 오버루링인지 여부를 판별하는 것이 목표인 법률 문서 데이터 세트입니다.COQA는 대화적 환경에서 개발된 독해 데이터 세트로, 직접 질의 응답 작업으로 적용했습니다.우리는 최적화 공간을 간소화하고 이미 좋은 결과를 보여주기 때문에 캐스케이드 길이가 3인 LLM 캐스케이드 접근 방식에 집중합니다.각 데이터 세트는 LLM 캐스케이드를 학습하는 훈련 세트와 평가를 위한 테스트 세트로 무작위로 분할됩니다.사례 연구.HEADLINES 데이터 세트에 대한 사례 연구로 시작해 보겠습니다.예산을 GPT-4 비용의 1/5인 6.5달러로 설정했습니다.회귀에 맞춰 조정된 DistilBERT[SDCW19]를 채점 함수로 사용합니다.DistilBERT는 여기에서 고려한 모든 LLM보다 상당히 작고 따라서 비용이 적게 든다는 점에 유의하는 것이 중요합니다. 그림 3(a)에 나와 있듯이 학습된 FrugalGPT는 GPT-J, J1-L, GPT-4를 순차적으로 호출합니다. 주어진 질의에 대해 먼저 GPT-J에서 답을 추출합니다. 이 답의 점수가 0.96보다 크면 답이 최종 응답으로 수락됩니다. 그렇지 않으면 J1-L이 질의됩니다. J1-L의 답은 점수가 0.37보다 크면 최종 응답으로 수락되고, 그렇지 않으면 GPT-4가 호출되어 최종 답을 얻습니다. 흥미롭게도 이 접근 방식은 수많은 질의에서 GPT-4보다 성능이 뛰어납니다. 예를 들어, NASDAQ의 &quot;미국 GDP 데이터 침체 이후 금 가격이 하락&quot;이라는 헤드라인이 주어졌을 때 FrugalGPT는 가격이 하락할 것이라고 정확하게 예측하는 반면 GPT-표 1: 상업용 LLM API 요약. 5개 공급업체의 12개 LLM API를 사용합니다. 비용은 2023년 3월에 검색되었습니다. 비용에는 세 가지 가산 요소가 있을 수 있습니다. 입력(입력 토큰 수에 비례), 출력(생성된 토큰 수에 비례) 및 요청당 고정 비용입니다. LLM의 비용은 최대 2배까지 다를 수 있습니다. 예를 들어, 10M개의 입력 토큰을 처리하려면 Textsynth의 GPT-J는 $0.2에 불과하지만 OpenAI의 GPT-4는 $30이 필요합니다. 비용(USD) 제공자 API 크기/B 10M 입력 토큰 10M 출력 토큰 요청 GPT-Curie ChatGPT 6.ΝΑOpenAI GPT-GPT-ΝΑJ1-Large 7.0.AIJ1-Grande0.J1-Jumbo0.Cohere XlargeForeFrontAI QA5.5.GPT-J0.Textsynth FAIRSEQ GPT-Neox0.1.표 2: FrugalGPT LLM 캐스케이드 실험에 사용된 데이터 세트 요약. 데이터 세트 헤드라인 도메인 크기 # 프롬프트의 예 OVERRULING Finance LawCOQA 구절 읽기 예 예 금융 뉴스 GPT-J 점수&lt;0.96? J1-L 점수&lt;0.37? GPT-No No (a) 학습된 FrugalGPT 전략 GPT-Gold는 암울한 미국 GDP 데이터 이후 최저가에서 벗어남 가격 상승 Frugal GPT 가격 하락 (b) 쿼리 및 응답 예제 접근 방식 정확도 비용($) GPT-FrugalGPT 0.33.0.6.(c) 전체 성능 및 비용 그림 3: HEADLINES 데이터 세트에서 FrugalGPT의 사례 연구. (a) Frugal GPT가 이 데이터 세트에서 전체 예산 $6.5로 학습한 계단식 전략은 GPT-4 비용의 1/5입니다. FrugalGPT는 GPT-J 및 J1-L이 고품질 답변을 생성하는 한 GPT-4 쿼리를 피합니다. (b) 때때로 GPT-4가 실수를 하지만 FrugalGPT는 J-1 및 GPT-J의 올바른 답변을 사용하는 법을 학습합니다. (c) 전반적으로 FrugalGPT는 비용을 80% 절감하고 GPT-4에 비해 정확도를 1.5% 향상시킨 것으로 나타났습니다.ChatGPT GPT-C GPT-GPT-J1-L J1-G ChatGPTGPT-3-GPT-C 0 18 17 21 9 14 17 14 13 12 16-GPT-C 0 23 25 25 12 8 14 22 11 8 8ChatGPT055GPT-4-J1-L 4 14 12 17 09 12 8 10 7 13J1-G 6 9 9 12 6086J1 4 5 6 7 440 45 5CoHere 5 10 9 12 4GPT-Neo-FA-Q-11 15 16 18 13 13 16 14 0 14 12GPT-J 4 12 10 14 4 8 10 6 80 12FSQ 15 16 18 18 16 15 17 17 12 1855 7 65-여기 GPT-J FSQ GPT-Neo --GPT-C 채팅 GPT-J1 10 21 22 22 11 6 22 9 2CoHere 6 68 9 4 9 10 09 12 10FA-Q-11 25 26 26 15 9 13 250 5 8GPT-J-26 45 46 46 31 19 24 46 23 0 14FSQ 16 33 35 34 21 11 17 33 15 4 0GPT-Neo-11 24 26 26 13 10 14 22 12 10 10GPT-3 2 1 0 2 1 2 3 0 35GPT-4-2 1 2 0 1 2 3 1 25J1-L-13 23 25 26 0 13 16 21 15 14 14J1-G 11 28 29 29 15 0 13 28 12 4 6GPT-C 0 7 18 18 13 15 16 13 14 12 1340 ChatGPT-19 0 27 22 23 24 26 20 23 19 23GPT-3-6GPT-4 9 1 13 0 12 12 14 9 13 11 12J1-L8 6 16 16 0 10 11J1-G 7 5 13 13 609-11-L J1-G 여기 GPT-J FSQ GPT-Neo16 5 12 13 6 707 75CoHere 10 4 16 14 10 12 13 0 11 9 11FA-Q-9 6 16 17 8 11 12 10 0 6 10GPT-J-12 7 19 19 11 14 15 12 10 0 12FSQ 9 7 16 16 9 11 12 10 10GPT-Neo-COHA (a) 헤드라인 (b) GPT-C 무효화 6 17 17 11 13 14 10 11 9 11GPT-ChatGPT GPT-J1-L J1-G CoHere (c) COQA GPT-J FSQ GPT-Neo 그림 4: 각 쌍의 LLM의 최대 성능 개선(MPI). (a), (b), (c)는 각각 세 개의 데이터 세트에 해당합니다. 한 항목은 행의 LLM이 틀렸지만 열의 LLM은 올바른 답을 제공하는 경우의 백분율을 나타냅니다. 전반적으로 저렴한 LLM이 비싼 LLM을 보완할 수 있는 경우가 매우 많다는 것을 알 수 있습니다. 예를 들어, 약 6%의 데이터에 대해 GPT는 실수를 하지만 GPJ-J(또는 JL 또는 GPT-C)는 HEADLINES에서 올바른 답을 제공합니다. 잘못된 답을 제공합니다(그림 3(b) 참조). 전반적으로 FrugalGPT는 정확도 향상과 비용 절감을 모두 가져옵니다. 그림 3(c)에서 볼 수 있듯이 비용은 80% 감소하는 반면 정확도는 1.5% 더 높습니다. LLM 다양성. 여러 LLM API가 최상의 개별 LLM보다 잠재적으로 더 나은 성능을 낼 수 있는 이유는 무엇일까요? 본질적으로 이는 생성 다양성 때문입니다. 저렴한 LLM조차도 때로는 더 비싼 LLM이 실패하는 쿼리에 올바르게 답할 수 있습니다. 이 다양성을 측정하기 위해 최대 성능 개선 또는 MPI를 사용합니다. LLM B에 대한 LLM A의 MPI는 LLM A가 올바른 답을 생성하는 반면 LLM B는 잘못된 답을 제공할 확률입니다. 이 메트릭은 기본적으로 LLM B 외에도 LLM A를 호출하여 달성할 수 있는 최대 성능 이득을 측정합니다. 모든 데이터 세트에 대한 각 LLM API 쌍 간의 MPI는 그림 4에 표시됩니다. 전반적으로 LLM 시장 내에서 상당한 잠재력을 관찰합니다. 예를 들어, GPT-C, GPT-J 및 J1-L은 모두 HEADLINES 데이터 세트에서 GPT-4의 성능을 최대 6%까지 향상시킬 수 있습니다. COQA 데이터 세트에서 GPT-4가 오류를 범하는 데이터 포인트가 13% 있지만 GPT-3는 정답을 제공합니다. 이러한 개선 상한을 항상 달성할 수는 없지만 더 저렴한 서비스를 활용하여 더 나은 성능을 달성할 가능성을 보여줍니다. 표 3: 최상의 개별 LLM 성능과 일치하기 위한 FrugalGPT의 비용 절감. 동일한 정확도에 도달하는 비용 최상의 개별 LLM FrugalGPT 데이터 세트 최상의 개별 LLM 헤드라인 COQA GPT-GPT-GPT-33.9.72를 초과하는 비용 절감 0.98.3% 2.73.3% 29.59.2% 비용 절감. 이어서 FrugalGPT가 정확도를 유지하면서 비용을 절감할 수 있는지, 그리고 그렇다면 얼마나 절감할 수 있는지 살펴봅니다. 표 3은 50%에서 98%까지의 FrugalGPT의 전체 비용 절감을 보여줍니다. 이는 FrugalGPT가 소규모 LLM에서 정확하게 답변할 수 있는 쿼리를 식별하고 결과적으로 비용 효율적인 LLM만 호출하기 때문에 가능합니다. GPT-4와 같은 강력하지만 비싼 LLM은 Frugal GPT에서 감지한 까다로운 쿼리에만 활용됩니다. 성능 및 비용 상충. 이제 그림 5에서 설명한 대로 FrugalGPT가 달성한 성능과 비용 간의 상충 관계를 조사합니다. 몇 가지 흥미로운 관찰이 가능합니다.정확도 정확도 정확도 →FrugalGPT 0.0.0.0.GPT-Neo ChatGPT 0.0.GPT J1-GCoHere 0.◆J1-L 0.0.FSQ FQ 0.◆GPT-CCost ($) FrugalGPT 0.97&gt;0.Gold는 저점에서 벗어났습니다.GPT-J ⭑GPT-미국 GDP 침체 이후 하락 GPT-●GPT-3J 하락 상승 FrugalGPT Gold는 0.16 &lt; 0.Up J1-L Down Down 0.44&gt;0.hawkish Fed 의견 GPT-✓ 중립 ✗ Kinross Gold는 GPT-J에서 아웃퍼포머로 업그레이드 상승 0.17 &lt; 0.Frugal GPT J1-L Up 0.13 &lt;0.GPT-None CIBC에서 중립적이지 않음 GPT-► 없음 (a) 헤드라인 FrugalGPT GPT-ChatGPT 0.CoHere 0.J0.J1-G GPT-CFQ FSQ 0.0.5 GPT-J이 분야에서 우리의 사례를 조정하고 정규화할 때가 왔습니다.Q: 기각일까요? 법원은 [...] 리마에서 이 법원에 의해 명시적으로 기각되었습니다.Q: 기각일까요? FrugalGPT GPT-J 예 예 0.91&gt;0.GPT-아니요 FrugalGPT GPT-J 예 0.6&lt; 0.J1-L 예 예 1.0&gt;0.GPT-아니요 [...] 이용 가능한 숙박 시설을 거부하는 결과입니다.GPT-J 예 0.2&lt;0.FrugalGPT ChatGPT 아니오 GPT-아니요 0.8&lt;0.No12 Q: 비용 ($) 무효화인가요? GPT-No (b) 무효화 0.FrugalGPT 0.0.31-G 0.35 J1-L FQ GPT-GPT-[..] 캡 윈터스는 [...] 머리에 백발이 천 개 더 생겼습니다 [...] Q: 그는 붉은 머리카락을 가지고 있었나요? FrugalGPT GPT-No GPT-No 0.8&gt;0. 본문에는 이에 대한 언급이 없습니다. CoHere QGPT-Neo ▶GPT-J 0.0.[...] 매주 화요일에 이야기 시간을 가졌습니다. [...]. Q: 언제 자유 시간이 있었나요? FrugalGPT GPT-휴가일 0.1 &lt; 0.학교에서 J화요일 0.6&gt;0.GPT-화요일 학교에서 휴무일 0.■CHATGPT 0 20 40 60 80 100비용 ($) 내가 [...] 작은 검은 호두 선반 140 [...] 질문: 선반은 무엇으로 만들어졌나요?GPT-검은 호두 0.1&lt;0.FrugalGPT J검은 호두 0.2&lt;0.3, GPT-검은 호두 → 검은 호두 GPT-→ 검은 호두 (a) COQA ☑ 그림 5: Frugal GPT가 달성한 정확도 및 비용 상쇄. 전반적으로 FrugalGPT는 종종 최상의 개별 LLM API(예: GPT-4)와 동일한 성능을 훨씬 더 작은 비용으로 달성합니다. 동일한 비용이 발생할 때 FrugalGPT는 정확도를 최대 5%까지 향상시킬 수 있습니다. 각 데이터 세트에 대한 LLM 캐스케이드의 예가 오른쪽에 나와 있습니다. 첫째, 다양한 LLM API의 비용 순위는 고정되어 있지 않습니다. 예를 들어, J1은 HEADLINES 데이터 세트에서 두 번째로 비싼 LLM인 반면, GPT-3는 OVERRULING 및 COQA 데이터 세트에서 그 위치를 유지합니다. 이는 주로 이기종 가격 책정 메커니즘 때문입니다. J1은 생성된 토큰마다 비용이 많이 들지만 입력 토큰에는 비용을 청구하지 않는 반면, GPT-3은 입력 및 출력 토큰 모두에 비용을 청구합니다. 게다가, 더 비싼 LLM API는 때때로 더 저렴한 대응 제품보다 성능이 떨어집니다. 예를 들어, J1은 HEADLINES에서 GPT-3보다 비용이 많이 들지만 성능은 떨어집니다. 이러한 관찰 결과는 예산 제약이 없더라도 LLM API를 적절하게 선택하는 것의 중요성을 강조합니다. 다음으로, FrugalGPT는 모든 평가된 데이터 세트에서 원활한 성능-비용 균형을 이룰 수 있음을 알 수 있습니다. 이를 통해 LLM 사용자에게 유연한 선택권을 제공하고 LLM API 제공자가 에너지를 절약하고 탄소 배출을 줄이는 데 도움이 될 수 있습니다. 사실, FrugalGPT는 비용을 절감하고 정확도를 동시에 개선할 수 있습니다. 예를 들어, OVERRULING 데이터 세트에서 FrugalGPT는 최고의 LLM API인 GPT-4에 비해 비용을 73% 절감하는 동시에 정확도를 1% 향상시킵니다. 이는 FrugalGPT가 여러 LLM의 지식을 통합하기 때문일 가능성이 큽니다. 그림 5에 표시된 예제 쿼리는 FrugalGPT가 성능을 개선하고 비용을 동시에 절감할 수 있는 이유를 이해하는 데 도움이 됩니다. GPT-4는 일부 쿼리(예: (a) 부분의 첫 번째 예제)에서 실수를 하지만 일부 저비용 API는 올바른 예측을 제공합니다. FrugalGPT는 이러한 쿼리를 정확하게 식별하고 저렴한 API에만 의존합니다. 예를 들어, GPT-4는 그림 5(b)에 표시된 대로 &quot;이 분야에서 우리의 사례를 조정하고 정규화할 때가 왔습니다&quot;라는 법적 진술에서 오버링이 없다고 잘못 추론합니다. 그러나 FrugalGPT는 GPT-J의 정답을 받아들여 값비싼 LLM을 사용하지 않고 전반적인 성능을 개선합니다. 당연히 단일 LLM API가 항상 올바른 것은 아닙니다.LLM 캐스케이드는 LLM API 체인을 사용하여 이를 극복합니다.예를 들어, 그림 5(a)에 표시된 두 번째 예에서 FrugalGPT는 GPT-J의 생성이 신뢰할 수 없을 수 있음을 식별하고 체인의 두 번째 LLM인 J1-L로 전환하여 올바른 답을 찾습니다.다시 말하지만, GPT는 잘못된 답을 제공합니다.FrugalGPT는 완벽하지 않으며 비용을 절감할 수 있는 여지가 많이 있습니다.예를 들어, 그림 5(c)의 세 번째 예에서 체인의 모든 LLM API는 동일한 답을 제공합니다.그러나 FrugalGPT는 첫 번째 LLM이 올바른지 확신하지 못하여 체인의 모든 LLM을 쿼리해야 합니다.이러한 경우를 피하는 방법을 식별하는 것은 여전히 미해결 문제로 남아 있습니다.토론, 제한 및 미래 전망 실제 시나리오에서 LLM을 사용하는 데 드는 상당한 비용은 광범위한 사용에 상당한 장벽을 제공합니다. 이 논문에서는 LLM API 사용 시 추론 비용을 줄이기 위한 실용적인 전략을 개략적으로 설명하고 논의합니다. 또한 비용 절감 전략 중 하나인 LLM 캐스케이드를 설명하기 위해 FrugalGPT를 개발했습니다. 경험적 결과에 따르면 FrugalGPT는 최첨단 LLM의 성능을 유지하면서 비용을 최대 98%까지 절감할 수 있습니다. Frugal GPT는 예산 제약 하에서 LLM API로 작업 성능을 최적화하기 위한 토대를 마련하지만 몇 가지 한계가 있습니다. FrugalGPT에서 LLM 캐스케이드 전략을 학습하려면 레이블이 지정된 몇 가지 예제가 필요합니다. 캐스케이드가 잘 작동하려면 학습 예제가 테스트 예제와 동일하거나 유사한 분포에서 나와야 합니다. 게다가 LLM 캐스케이드 자체를 학습하려면 리소스가 필요합니다. 이를 일회성 사전 비용으로 간주합니다. 이는 최종 쿼리 데이터 세트가 캐스케이드를 학습하는 데 사용된 데이터보다 클 때 유용합니다. 여기서 논의하지 않는 어텐션 계산 자체를 가속화하는 것과 같이 비용 절감을 위한 다른 유망한 전략도 있습니다. LLM의 급속한 발전을 감안할 때, 이 논문은 포괄적이거나 확실한 해결책을 제공하려는 것이 아닙니다. 저희의 목표는 이 중요한 연구 의제의 토대를 마련하고 간단한 캐스케이드조차도 이미 유망한 절감 효과를 얻을 수 있음을 보여주는 것입니다. 또한 향후 탐색을 위한 많은 관련 방향이 있습니다. FrugalGPT는 성능과 비용의 균형에 집중하는 반면, 실제 응용 프로그램은 지연, 공정성, 개인 정보 보호 및 환경 영향을 포함한 다른 중요한 요소의 평가를 요구합니다. 이러한 요소를 최적화에 통합
