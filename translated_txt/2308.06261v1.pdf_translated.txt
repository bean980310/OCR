--- ABSTRACT ---
대규모 언어 모델에서 생성된 코드를 사용하여 네트워크 관리 개선 Sathiya Kumaran Mani Yajie Zhout Kevin Hsieh Santiago Segarra §* Ranveer Chandra Srikanth Kandula Boston University *Rice University § Microsoft Research 네트워크 토폴로지와 통신 그래프를 분석하는 것은 현대 네트워크 관리에서 중요한 역할을 합니다. 그러나 응집력 있는 접근 방식이 없으면 학습 곡선이 어렵고 오류가 높아지며 비효율성이 발생합니다. 이 논문에서는 대규모 언어 모델(LLM)을 사용하여 자연어 쿼리에서 작업별 코드를 생성하는 자연어 기반 네트워크 관리 환경을 용이하게 하는 새로운 접근 방식을 소개합니다. 이 방법은 네트워크 운영자가 생성된 코드를 검사하고 LLM과 네트워크 데이터를 공유할 필요성을 없애고 일반 프로그램 합성 기술과 결합된 애플리케이션별 요청에 집중함으로써 설명 가능성, 확장성 및 개인 정보 보호의 과제를 해결합니다. 벤치마크 애플리케이션을 사용하여 프로토타입 시스템을 설계하고 평가하여 높은 정확도, 비용 효율성 및 보완 프로그램 합성 기술을 사용하여 추가 개선 가능성을 보여줍니다. 1
--- METHOD ---
설명 가능성, 확장성 및 개인 정보 보호의 과제를 해결하기 위해 네트워크 운영자는 생성된 코드를 검사하고, LLM과 네트워크 데이터를 공유할 필요성을 없애고, 일반 프로그램 합성 기술과 결합된 애플리케이션별 요청에 집중합니다. 벤치마크 애플리케이션을 사용하여 프로토타입 시스템을 설계하고 평가하여 높은 정확도, 비용 효율성 및 보완 프로그램 합성 기술을 사용하여 추가 개선 가능성을 보여줍니다. 1 서론 현대 네트워크 관리의 중요한 측면에는 용량 계획[39], 구성 분석[5, 17], 트래픽 분석[24, 25, 60]과 같은 작업을 위해 네트워크 토폴로지와 통신 그래프를 분석하고 작업을 수행하는 것이 포함됩니다. 예를 들어, 네트워크 운영자는 네트워크 토폴로지 데이터를 사용하여 &quot;이 두 데이터 센터 간의 네트워크 대역폭을 두 배로 늘리는 가장 비용 효율적인 방법은 무엇입니까?&quot;와 같은 용량 계획 질문을 제기할 수 있습니다. 마찬가지로 통신 그래프를 사용하여 &quot;이 두 노드 간의 데이터 전송에 필요한 홉 수는 무엇입니까?&quot;와 같은 진단 질문을 할 수 있습니다. 오늘날 네트워크 운영자는 이러한 작업을 위해 확장되는 도구와 도메인별 언어(DSL)에 의존합니다[17,39]. 통합된 접근 방식은 학습 곡선을 줄이고 수동 작업의 오류와 비효율성을 최소화하는 데 상당한 잠재력을 가지고 있습니다. 대규모 언어 모델(LLM)의 최근 발전[1,6,12,46,53]은 자연어를 사용하여 네트워크 관리 작업을 수행할 수 있는 귀중한 기회를 제공합니다. LLM은 인간 언어를 해석하고 다양한 도메인에서 고품질 답변을 제공하는 데 뛰어난 능력을 보여주었습니다[16,33,50,54]. LLM의 기능은 다양한 도구와 DSL 간의 격차를 메워 네트워크 관련 질문과 작업을 처리하는 데 보다 응집적이고 사용자 친화적인 접근 방식으로 이어질 수 있습니다. 안타깝게도 수많은 네트워크 관리 작업을 그래프 분석 또는 조작 작업으로 표현할 수 있지만 기존 시스템은 자연어를 사용하여 그래프 조작을 용이하게 하지 않습니다. LLM에 네트워크 토폴로지를 직접 조작하도록 요청하면 설명 가능성, 확장성 및 개인 정보 보호와 관련된 세 가지 근본적인 과제가 발생합니다. 첫째, LLM의 출력을 설명하고 복잡한 문제에 대해 추론할 수 있도록 하는 것은 여전히 해결되지 않은 문제로 남아 있습니다[59]. 최첨단 LLM조차도 환각[35] 및 기본 산술 실수[7,13]와 같은 확립된 문제로 어려움을 겪습니다. 이는 LLM이 답을 도출하고 정확성을 평가하는 데 사용하는 방법을 결정하는 프로세스를 복잡하게 만듭니다. 둘째, LLM은 제한된 토큰 창 크기[57]로 인해 광범위한 네트워크 토폴로지와 통신 그래프를 처리하는 용량이 제한됩니다. 예를 들어, Bard[20], ChatGPT[44], GPT-4[46]와 같은 최첨단 LLM은 프롬프트에서 2k~32k 토큰만 허용하므로 수십 개의 노드와 수백 개의 에지로 구성된 작은 네트워크 토폴로지만 수용할 수 있습니다. 셋째, 네트워크 데이터는 IP 주소[55]와 같은 개인 식별 정보(PII)로 구성될 수 있으며, 이 정보를 처리를 위해 LLM으로 전송할 때 개인 정보 보호 문제가 발생할 수 있습니다. 이러한 과제를 해결하는 것은 네트워크 관리 작업에 LLM을 통합하는 보다 효과적인 접근 방식을 개발하는 데 중요합니다. 비전 및 기술. 이 논문에서는 LLM의 힘을 활용하여 그래프 분석 및 조작을 위한 작업별 코드를 생성하여 네트워크 관리를 개선하는 새로운 접근 방식을 제시합니다. 이는 자연어 기반 네트워크 관리 경험을 용이하게 합니다. 그림 1은 이 시스템이 네트워크 운영자의 자연어 쿼리에 응답하여 LLM에서 생성된 코드를 생성하고 실행하는 방법의 예를 보여줍니다. 이 접근 방식은 네트워크 운영자가 LLM에서 생성된 코드를 검토하여 자연어 쿼리를 충족하는 기본 논리와 절차를 이해할 수 있도록 함으로써 설명 가능성 과제를 해결합니다. 또한 계산을 프로그램 실행 엔진에 위임하여 산술적 부정확성과 LLM으로 인한 환각을 최소화합니다. 또한 이 접근 방식은 LLM에 대한 입력이 다음과 같으므로 네트워크 데이터를 LLM으로 전송할 필요성을 제거하여 확장성 및 개인 정보 보호 문제를 극복합니다.각 /16 IP 주소 접두사에 고유한 색상을 지정합니다.세션 재설정 실행 LLM에서 생성된 코드 2-def process_graph(graph_data): ༥ ༠༣ པཿ o ú ༨ ༠ ཤ ཋ | | ཀཱ བྷ ཤཱ བྷ ། བྷ ཎྜ རྞ ཀྵIP 접두사와 연관된 색상을 저장할 사전을 만듭니다. ip_prefix_colors = {} # 그래프의 각 노드를 반복합니다. graph_data.nodes(): for node # 노드의 IP 주소를 가져옵니다. ip_address graph_data.nodes [node][&#39;ip_address&quot;] /16 IP 접두사를 가져옵니다. ip_prefix=.join(ip_address.split(&#39;.&#39;)[:2]) # IP 접두사가 사전에 없으면 고유한 색상을 지정합니다. if ip_prefix not in ip_prefix_colors: ip_prefix_colors[ip_prefix] = &#39;+.join([random.choice(&quot;012345€ # 노드에 색상을 지정합니다&quot; graph_data.nodes[node][&#39;color&#39;] = ip_prefix_colors[ip_prefix] # 그래프를 반환합니다. return object = { &#39;type&#39;: &#39;graph&#39;, &#39;data&#39;: graph data return return object 원래 통신 그래프 업데이트된 통신 그래프 그림 1: 자연어 기반 네트워크 관리 시스템이 네트워크 운영자의 쿼리인 &quot;각 /16 IP 주소 접두사에 고유한 색상을 지정하세요&quot;에 응답하여 프로그램을 생성하고 실행하는 방법의 예. 시스템은 LLM에서 생성된 코드와 업데이트된 통신 그래프를 표시합니다. 자연어 쿼리와 출력은 LLM에서 생성된 코드로만 구성됩니다. 이 접근 방식에서 가장 큰 기술적 과제는 네트워크 관리 작업을 안정적으로 수행할 수 있는 고품질 코드를 생성하는 것입니다. LLM은 일반 코드 생성에서 놀라운 역량을 보여주었지만[2,7,33] 도메인별 및 애플리케이션별 요구 사항에 대한 이해가 부족합니다. 이 과제를 해결하기 위해 네트워크 관리에서 그래프 조작 작업을 위한 사용자 지정 코드를 생성하기 위해 애플리케이션별 요청과 일반 프로그램 합성 기술을 결합하는 새로운 프레임워크를 제안합니다. 우리 아키텍처는 고품질 코드 생성 프로세스를 두 가지 핵심 구성 요소로 나눕니다. (1) 네트워크 구조, 속성 및 용어에 대한 LLM의 이해를 향상시키는 컨텍스트, 지침 또는 플러그인을 제공하는 애플리케이션별 요소, (2) 코드를 생성하기 위해 적합한 라이브러리 및 최첨단 프로그램 합성 기술[2,9-11,48,49]을 활용하는 코드 생성 요소입니다. 이 아키텍처는 개별 구성 요소의 독립적인 혁신을 촉진하며, 예비 연구에서는 코드 품질이 상당히 향상되었음을 나타냅니다. 구현 및 평가. 네트워크 운영자가 자연어 쿼리를 제출하고 네트워크 토폴로지 및 통신 그래프를 처리하는 코드를 얻을 수 있는 프로토타입 시스템을 설계합니다(그림 1). 효과를 체계적으로 평가하기 위해 그래프 조작으로 모델링할 수 있는 두 가지 애플리케이션으로 구성된 벤치마크인 NeMoEval을 설정합니다. (1) 통신 그래프를 사용한 네트워크 트래픽 분석[24, 25, 60], (2) 다중 추상화 계층 토폴로지 표현(MALT)[39]을 기반으로 하는 네트워크 수명 주기 관리. 일반화 가능성을 평가하기 위해 세 가지 코드 생성 접근 방식(SQL [14], pandas [41], NetworkX [15])과 네 가지 고유한 LLM [10,20,44, 46]을 사용하여 이러한 애플리케이션을 평가합니다. 예비 조사에 따르면 우리 시스템은 그래프 조작 작업에 대해 고품질 코드를 생성할 수 있습니다. NetworkX 기반 접근 방식을 활용하여 네트워크 트래픽 분석 및 네트워크 수명 주기 관리에 대해 각각 네 가지 LLM에 대해 모든 작업에서 평균 68% 및 56%의 코드 정확성을 달성했습니다(GPT-4를 사용하면 최대 88% 및 78%). 이에 비해 제한된 크기의 그래프 데이터를 LLM에 직접 입력하는 허수아비 기준선은 트래픽 분석 애플리케이션의 평균 정확성이 23%에 불과합니다. 우리 방법은 평균 정확성을 45%만큼 크게 개선하여 더욱 실행 가능한 옵션이 되었습니다. 또한 보완적인 프로그램 합성 방법과 시스템을 통합하면 복잡한 작업에 대한 코드 품질을 더욱 향상시킬 수 있음을 보여줍니다. 마지막으로, 우리의 접근 방식이 비용 효율적이며 작업당 평균 비용이 $0.1이고 LLM 비용은 네트워크 크기에 관계없이 일정하다는 것을 보여줍니다. 우리 연구는 이것이 잠재적으로 유망한 연구 방향임을 시사합니다. 우리는 추가 연구를 촉진하기 위해 벤치마크 및 데이터 세트인 NeMoEval¹을 릴리스합니다. 기여. 우리는 다음과 같은 기여를 합니다. • 자연어 기반 네트워크 관리 경험을 가능하게 하기 위해 LLM을 사용하여 그래프 조작 작업을 위한 코드를 생성하는 새로운 접근 방식을 소개합니다. 이 작업은 우리가 아는 한 그래프 조작 및 네트워크 관리를 위한 LLM 활용을 조사한 최초의 작업입니다. • 네트워크 트래픽 분석 및 네트워크 수명 주기 관리라는 두 가지 네트워크 관리 애플리케이션을 포함하는 벤치마크를 개발하여 릴리스합니다. • 세 가지 코드 생성 기술과 네 가지 고유한 LLM으로 이러한 애플리케이션을 평가하여 그래프 조작 작업을 위한 고품질 코드를 생성하는 접근 방식의 역량을 검증합니다. 2 예비 연구 네트워크 관리에서 그래프 분석 및 조작의 역할을 살펴본 다음 최근 LLM 발전과 네트워크 관리에 대한 잠재적 응용 프로그램에 대해 논의합니다. &#39;https://github.com/microsoft/NeMoEval2.1 네트워크 관리에서의 그래프 분석 및 조작 네트워크 관리에는 네트워크 계획, 모니터링, 구성 및 문제 해결과 같은 다양한 작업이 포함됩니다. 네트워크의 크기와 복잡성이 확장됨에 따라 이러한 작업은 점점 더 어려워집니다. 예를 들어, 네트워크 운영자는 복잡한 정책을 시행하고 이러한 장치를 모니터링하여 적절한 기능을 보장하도록 수많은 네트워크 장치를 구성해야 합니다. 수많은 작업을 네트워크 토폴로지 또는 통신 그래프에 대한 그래프 분석 및 조작으로 모델링할 수 있습니다. 이러한 작업의 두 가지 예가 아래에 설명되어 있습니다. 네트워크 트래픽 분석. 네트워크 운영자는 병목 현상, 혼잡 지점 및 활용도가 낮은 리소스를 식별하고 트래픽 분류를 수행하는 것을 포함하여 다양한 이유로 네트워크 트래픽을 분석합니다. 트래픽 분석에서 귀중한 표현은 트래픽 분산 그래프(TDG)[25] 또는 통신 그래프[19]로, 노드는 라우터, 스위치 또는 장치와 같은 네트워크 구성 요소를 나타내고 에지는 이러한 구성 요소 간의 연결 또는 경로를 상징합니다(예: 그림 1). 이러한 그래프는 데이터 패킷 경로의 시각적 표현을 제공하여 트래픽 패턴을 포괄적으로 이해하는 데 도움이 됩니다. 네트워크 운영자는 일반적으로 이러한 그래프를 두 가지 방법으로 활용합니다.(1) 네트워크 성능 최적화[25], 트래픽 분류[52], 이상 감지[29]를 위해 이러한 그래프를 검토하고, (2) 노드와 에지를 조작하여 네트워크 성능과 안정성에 미치는 해당 작업의 영향을 시뮬레이션합니다[30].네트워크 수명 주기 관리.네트워크의 전체 수명 주기를 관리하려면 용량 계획, 네트워크 토폴로지 설계, 배포 계획, 진단 작업을 포함한 다양한 단계가 필요합니다.이러한 작업의 대부분은 다양한 추상화 수준에서 네트워크 토폴로지를 정확하게 표현하고 원하는 네트워크 상태를 달성하기 위해 토폴로지를 조작해야 합니다[39].예를 들어, 네트워크 운영자는 상위 수준 토폴로지를 사용하여 네트워크 용량을 계획하고 두 데이터 센터 간 대역폭을 늘리기 위한 다양한 대안을 모색할 수 있습니다.마찬가지로, 네트워크 엔지니어는 하위 수준 토폴로지를 사용하여 특정 네트워크 장치의 위치와 다른 장치에 대한 연결을 확인할 수 있습니다.따라서 그래프 분석과 조작은 네트워크 관리의 중요한 부분입니다. 이러한 작업을 이해하고 실행할 수 있는 통합 인터페이스는 프로세스를 상당히 단순화하여 네트워크 운영자의 시간과 노력을 상당히 절약할 수 있는 잠재력이 있습니다.2.2 LLM 및 프로그램 합성 자연어 설명을 기반으로 하는 자동 프로그램 생성, 즉 프로그램 합성은 오랜 연구 과제였습니다[3,23,34].최근까지 프로그램 합성은 주로 문자열 처리[22], 입출력 예제를 기반으로 한 프로그램 생성[4], 데이터베이스 쿼리를 위한 자연어(예: [26, 28, 31])와 같은 특정 도메인에 국한되었습니다.반대로 일반적인 프로그램 합성은 도달 범위를 벗어난 것으로 간주되었습니다[2].이러한 획기적인 진전은 인터넷의 광범위한 자연어 텍스트 코퍼스와 GitHub과 같은 거대한 코드 저장소에서 학습된 LLM[6, 10, 18, 20, 32, 46]의 발전과 함께 나타났습니다. LLM은 자연어와 코드 간의 관계를 학습하는 데 있어 놀라운 능력을 보여주었고 자연어에서 데이터베이스 쿼리로의 작업[40,51]과 같은 도메인별 작업에서 최첨단 성능을 달성했으며 프로그래밍 경연 대회[33] 및 모의 기술 인터뷰[7]와 같은 작업에서 인간 수준의 성능을 달성했습니다. 아주 최근에 이러한 발전으로 인해
--- EXPERIMENT ---
영어: 코드 생성을 통해 수학적 문제를 해결하고 데이터 분석을 수행하도록 설계된 al 플러그인[43]. LLM을 사용한 프로그램 합성의 최근 획기적인 진전은 이 분야의 최첨단 기술을 발전시키기 위한 연구의 급증을 불러일으켰습니다. 이러한 기술은 일반적으로 세 가지 접근 방식으로 분류할 수 있습니다. (1) 코드 선택은 LLM을 사용하여 여러 샘플을 생성하고 실행 결과의 일관성[48] 또는 자동 생성된 테스트 사례[9]에 따라 최상의 샘플을 선택하는 것을 포함합니다. (2) few-shot 예제는 LLM에 대상 프로그램의 입출력 동작에 대한 여러 예를 제공합니다[2]. (3) 피드백 및 자체 반성은 피드백 또는 강화 학습 외부 루프를 통합하여 LLM이 오류로부터 학습하도록 돕습니다[8, 11, 49]. 이러한 고급 기술은 프로그램 합성의 지평을 계속 확장하여 LLM이 더 복잡하고 정확한 프로그램을 생성할 수 있도록 지원합니다. 섹션 1에서 논의하듯이 LLM에서 생성된 코드는 LLM 기반 네트워크 관리에서 설명 가능성, 확장성 및 개인 정보 보호 문제를 해결할 수 있습니다. 그러나 우리의 초기 연구는 기존 접근 방식을 적용하는 것만으로는 네트워크 관리 작업에 부적절하다는 것을 보여줍니다.기존 기술은 도메인별 및 애플리케이션별 요구 사항을 이해하지 못하기 때문입니다.핵심 기술적 과제는 LLM과 일반 프로그램 합성의 최근 발전을 활용하여 네트워크 관리 작업을 수행할 수 있는 통합 인터페이스를 개발하는 데 있으며, 이는 제안된 솔루션에 대한 설계 요구 사항을 형성합니다.3 시스템 프레임워크 우리는 LLM을 사용하여 작업별 코드를 생성하여 네트워크 관리를 향상시키도록 설계된 새로운 시스템 프레임워크를 제시합니다.우리의 프레임워크는 두 가지 통찰력을 기반으로 합니다.첫째, 많은 네트워크 관리 작업을 그래프 분석 및 조작 작업(섹션 2.1)으로 변환하여 코드 생성을 위한 통합 설계와 보다 집중된 작업을 허용할 수 있습니다.둘째, 프롬프트 생성을 도메인별 요구 사항과 일반 프로그램 합성의 두 가지 측면으로 나눌 수 있습니다.도메인 전문화의 강점과 프로그램 합성 기술의 최근 발전(섹션 2.2)을 결합함으로써 네트워크 관리 작업을 위한 고품질 코드를 생성할 수 있습니다.그림 2는 우리의 시스템 프레임워크를 보여줍니다. 제안하는 프레임워크는 도메인 특정 지식,1 애플리케이션 래퍼(그림 2의 ①⑪①), 사용자 쿼리 애플리케이션 및 그래프 설명, 애플리케이션 코드 생성, 완료 선택된 LLM 프롬프트, 애플리케이션 원시 데이터 또는 로그, 프롬프트 생성기, 프롬프트 생성기 그래프, 동기화 상태, 실행 UX 인터페이스 샌드박스를 사용하는 애플리케이션 래퍼(그림 2의 ①⑪①)로 구성됩니다.</> 형식 출력 코드 추출 및 생성된 코드 검증 그림 2: 노드 및 에지의 정의와 같은 자연어 및 LLM 생성 코드를 사용하여 애플리케이션 데이터를 그래프 표현으로 변환하는 네트워크 관리 시스템을 위한 일반 프레임워크. 이 정보는 자연어로 된 사용자 쿼리와 함께 애플리케이션 프롬프트 생성기(②)에서 처리되어 LLM에 대한 작업별 프롬프트를 생성합니다. 그런 다음 작업별 프롬프트를 일반 코드 생성 프롬프트 생성기(③)와 결합하여 LLM(③)에 코드를 생성하도록 지시합니다. 생성된 코드는 플러그인과 라이브러리를 활용하여 구성된 그래프에서 사용자의 자연어 쿼리에 응답합니다. 실행 샌드박스(5)는 네트워크의 그래프 표현에서 코드를 실행합니다. 코드와 그 결과는 UX 인터페이스(⑥)에 표시됩니다. 사용자가 결과를 승인하면 UX는 업데이트된 그래프를 애플리케이션 래퍼(1)로 다시 보내 네트워크 상태를 수정하고 향후 프롬프트 개선을 위해 입력/출력을 기록합니다[2, 11,49]. 아래에서 주요 구성 요소를 설명합니다. 애플리케이션 래퍼(1). 애플리케이션 래퍼는 네트워크 관리 애플리케이션 및 네트워크 자체와 관련된 컨텍스트별 정보를 제공합니다. 예를 들어, MALT(Multi-Abstraction-Layer Topology Representation) 래퍼[39]는 기본 데이터에서 엔터티 및 관계 그래프를 추출하여 자연어로 엔터티(예: 패킷 스위치, 제어점 등) 및 관계(예: 포함, 제어 등)를 설명할 수 있습니다. 이 정보는 LLM이 네트워크 관리 애플리케이션과 그래프 데이터 구조를 이해하는 데 도움이 됩니다. 또한 애플리케이션 래퍼는 애플리케이션별 플러그인[42] 또는 코드 라이브러리를 제공하여 LLM 작업을 더 간단하게 만들 수 있습니다. 애플리케이션 프롬프트 생성기(②). 애플리케이션 프롬프트 생성기의 목적은 사용자 쿼리와 애플리케이션 래퍼의 정보를 모두 입력으로 허용한 다음 LLM의 쿼리 및 작업에 맞게 특별히 맞춤화된 프롬프트를 생성하는 것입니다. 이를 달성하기 위해 프롬프트 생성기는 다양한 정적 및 동적 기술을 활용할 수 있습니다[37,56,58]. 예를 들어, MALT로 작업할 때 프롬프트 생성기는 사용자 쿼리를 기반으로 관련 엔터티와 관계를 동적으로 선택한 다음 컨텍스트 정보로 프롬프트 템플릿을 채울 수 있습니다.우리의 프레임워크는 코드 생성 프롬프트 생성기(3) 및 LLM(4)과 관련하여 유연성을 제공하도록 설계되어 다양한 애플리케이션에 다양한 기술을 사용할 수 있습니다.실행 샌드박스(5).이전 연구[10]에서 강조했듯이 LLM에서 생성된 코드를 실행하려면 안전한 환경을 갖는 것이 중요합니다.실행 샌드박스는 가상화 또는 컨테이너화 기술을 사용하여 설정하여 프로그램 라이브러리 및 시스템 호출에 대한 제한된 액세스를 보장할 수 있습니다.또한 이 모듈은 네트워크 불변식을 검증하거나 출력 형식을 검사하여 코드와 시스템 모두의 보안을 강화할 수 있는 기회를 제공합니다.4 구현 및 평가 4. 벤치마크 LLM 기반 네트워크 관리 시스템의 효과를 평가하기 위해 일반적인 벤치마크인 NeMoEval을 설계합니다. 그림 3은 세 가지 주요 구성 요소로 구성된 벤치마크의 아키텍처를 보여줍니다. 사용자 쿼리 골든 답변 선택기 프로토타입 B+ 골든 코드 실행 B+, LLM에서 생성된 코드 실행 그림 3: 벤치마크 설계 평가 및 분석 골든 답변 선택기. 각 입력 사용자 쿼리에 대해 인간 전문가의 도움을 받아 &quot;골든 답변&quot;을 만듭니다. 복잡도 수준 쉬움 보통 어려움 표 1: 사용자 쿼리 예. NeMoEval의 모든 쿼리를 참조하세요. 트래픽 분석 주소 접두사가 15인 노드에 app:prodution 레이블을 추가합니다. 각 /16 IP 주소 접두사에 고유한 색상을 지정합니다. 각 노드에서 총 바이트 무게를 계산하여 5개 그룹으로 클러스터링합니다. 선택기의 사전 파일에 저장된 이러한 검증된 답변은 LLM에서 생성된 코드를 평가하는 기준 진실 역할을 합니다. 결과 평가기. 시스템은 네트워크 데이터에서 LLM에서 생성된 코드를 실행하여 결과를 골든 답변의 결과와 비교합니다. 일치하면 LLM이 통과하고 그렇지 않으면 실패하며 추가 분석을 위해 결과를 문서화합니다. 결과 로거. LLM 성능 분석과 잠재적 개선 사항 식별을 용이하게 하기 위해 LLM 생성 코드, 골든 앤서, 비교 결과를 포함한 각 쿼리의 결과를 기록합니다. 결과 로거는 평가 프로세스 중에 발생할 수 있는 모든 코드 실행 오류도 기록합니다. 4.2 실험 설정 애플리케이션 및 쿼리. 네트워크 트래픽 분석 및 네트워크 수명 주기 관리(섹션 2.1)의 두 가지 애플리케이션을 구현하고 평가합니다. • 네트워크 트래픽 분석. 다양한 수의 노드와 에지가 있는 합성 통신 그래프를 생성합니다. 각 에지는 바이트, 연결 및 패킷의 무작위 가중치가 있는 두 노드 간의 통신 활동을 나타냅니다. 토폴로지 분석, 정보 계산 및 그래프 조작과 같은 일반적인 작업을 포함하여 평가판 사용자의 쿼리를 큐레이션하여 24개의 쿼리를 개발합니다. • 네트워크 수명 주기 관리. 예제 MALT 데이터 세트[21]를 사용하여 노드와 6424개의 에지가 있는 방향 그래프로 변환합니다. 각 노드는 패킷 스위치, 섀시 및 포트와 같이 네트워크의 하나 이상의 유형을 나타내며 다양한 속성을 포함하는 서로 다른 노드 유형이 있습니다. 지향된 에지는 제어 또는 컨테인먼트 연관과 같은 장치 간의 관계를 캡슐화합니다. 우리는 운영 관리, WAN 용량 계획 및 토폴로지 설계에 초점을 맞춘 네트워크 관리 쿼리를 개발합니다. 질의는 각각의 골든 답변의 복잡성을 기준으로 세 가지 복잡성 수준(&quot;쉬움&quot;, &quot;보통&quot;, &quot;어려움&quot;)으로 분류됩니다. 표 1은 페이지 제한으로 인해 각 범주의 예시 질의를 표시합니다. 향후 연구를 용이하게 하기 위해 질의의 전체 목록, 각각의 골든 답변, 벤치마크를 공개합니다². LLM. GPT-4[46], GPT-3[6], Text-davinci-003(GPT 3.5의 변형)[45], Google Bard[20]를 포함한 네 가지 최첨단 LLM에 대한 연구를 수행합니다. 두 가지 개방형 LLM인 StarCoder[32]와 InCoder[18]를 추가로 탐색합니다. 그러나 일관되지 않은 답변 때문에 여기서는 결과를 표시하지 않습니다. 2 https://github.com/microsoft/NeMoEval MALT 패킷 스위치 jul.al.m1.s2c1에 포함된 모든 포트를 나열합니다. 첫 번째와 용량 기준으로 두 번째로 큰 섀시. 섀시 4에서 패킷 스위치 P1을 제거한 후 용량을 균형 조정합니다. 표 2: 두 애플리케이션의 정확도 요약 GPT-GPT-text-davinci-Google Bard GPT-GPT-Strawman 0.0.0.0.트래픽 분석 SQL Pandas NetworkX SQL Pandas NetworkX 0.50 0.0.11 0.0.0.13 0.MALT 0.11 0.0.0.0.0.0.0.21 0.0.0.0.11 0.0.11 0.0.0.표 3: 트래픽 분석에 대한 세부 정보 text-davinci-Google Bard Strawman SQL E(8)/M(8)/H(8) E(8)/M(8)/H(8) E(8)/M(8)/H(8) E(8)/M(8)/H(8) 0.50/0.38/0.0 0.75/0.50/0.25 0.50/0.50/0.13 1.0/1.0/0.0.38/0.13/0.0.38/0.25/0.0.50/0.25/0.Pandas NetworkX 0.25/0.13/0.0 0.50/0.25/0.0 1.0/0.63/0.0.63/0.25/0.0 0.63/0.25/0.0 1.0/0.75/0.0.38/0.25/0.0 0.50/0.13/0.13 0.88/0.50/0.향후 조사에서 일관된 성능을 보장합니다. 모든 OpenAI LLM에서 온도를 0으로 설정하여 여러 시도에서 일관된 출력을 보장합니다. Google Bard의 온도를 변경할 수 없으므로 각 쿼리를 5번 보내고 평균 통과 확률을 계산합니다[10].접근 방식.잘 정립된 데이터/그래프 조작 라이브러리를 사용하여 세 가지 코드 생성 방법을 구현합니다.이 라이브러리는 LLM이 학습할 수 있는 공개 코드 저장소에서 풍부한 예를 제공합니다.• NetworkX. 네트워크 데이터를 NetworkX[15] 그래프로 표현합니다.이 그래프는 네트워크 그래프의 효율적인 조작 및 분석을 위한 유연한 API를 제공합니다.• pandas. 두 개의 pandas[41] 데이터프레임을 사용하여 네트워크 데이터를 표현합니다.노드 인덱스와 속성을 저장하는 노드 데이터프레임과 에지 목록을 통해 노드 간의 링크 정보를 캡슐화하는 에지 데이터프레임입니다.Pandas는 필터링, 정렬, 그룹화와 같은 많은 기본 제공 데이터 조작 기술을 제공합니다.• SQL. 네트워크 데이터를 SQL[14]을 통해 쿼리된 관계형 데이터베이스로 표현합니다.이는 노드에 대한 테이블과 에지에 대한 또 다른 테이블로 구성됩니다.테이블 스키마는 pandas의 테이블 스키마와 유사합니다. 최근 연구에서는 LLM이 최첨단 정확도로 SQL 쿼리를 생성할 수 있다는 것이 입증되었습니다[40,51]. 또한 JSON 형식의 원래 네트워크 그래프 데이터를 LLM에 직접 공급하고 쿼리를 처리하도록 요청하는 대체 기준선(허수아비)도 평가합니다. 그러나 LLM의 토큰 제약으로 인해 이 접근 방식에 대한 평가를 데이터 크기를 제어할 수 있는 네트워크 트래픽 분석을 위한 합성 그래프로 제한합니다.GPT-GPT-text-davinci-Google Bard 표 4: MALT SQL Pandas Strawman NetworkX에 대한 분석 1.E(3)/M(3)/H(3) E(3)/M(3)/H(3) E(3)/M(3)/H(3) 0.33/0.0/0.0.33/0.0/0.0.33/0.0/0.0.67/0.67/0.33 1.0/1.0/0.0.67/0.67/0.0 0.67/0.67/0.0.33/0.33/0.0 0.67/0.67/0.0.67/0.33/0.0 0.67/0.33/0.CDF 0.0.0.0.우리의 접근 방식(NetworkX) 평균 LLM 비용($)표 5: 오류 유형 LLM 생성 코드 요약 LLM의 오류 유형(NetworkX) 트래픽 분석(35) 구문 오류 MALT(17) 가상 그래프 속성 가상 파일/함수 인수 인수 오류 연산 오류 잘못된 계산 논리 그래프가 동일하지 않음 4. 코드 품질 표 2는 각각 네트워크 트래픽 분석 및 네트워크 수명 주기 관리에 대한 벤치마크 결과를 요약합니다. 세 가지 핵심 사항을 관찰합니다. 첫째, 네트워크 관리에서 코드를 생성하는 데 LLM을 활용하면 생성된 코드가 산술 오류와 LLM 환각을 줄여 두 응용 프로그램 모두에서 허수아비 기준선을 크게 능가합니다. 둘째, 그래프 라이브러리(NetworkX)를 사용하면 LLM이 NetworkX의 그래프 조작 API를 활용하여 생성된 코드를 단순화할 수 있으므로 pandas 및 SQL에 비해 코드 정확도가 크게 향상됩니다. 이러한 추세는 네 가지 LLM 모두에서 일관됩니다. 마지막으로 NetworkX를 최첨단 GPT-4 모델과 페어링하면 가장 높은 결과(각각 88% 및 78%)를 얻을 수 있어 네트워크 관리 코드 생성에 유망한 전략이 됩니다. 작업 난이도의 영향을 이해하기 위해 표 3과 4에서 정확도 결과를 분석했습니다. LLM에서 생성된 코드의 정확도는 작업 복잡성이 증가함에 따라 감소하는 것을 관찰했습니다. 이러한 추세는 모든 LLM과 접근 방식에서 일관되며 네트워크 수명 주기 관리의 성능 격차가 더욱 두드러집니다(표 4). LLM에서 생성된 코드에 대한 분석 결과 MALT 데이터 세트의 복잡한 관계로 인해 LLM이 어려운 작업에서 오류를 범하기 쉽고 향후 연구에서는 LLM이 복잡한 네트워크 관리 작업을 처리하는 능력을 개선하는 데 중점을 두어야 함을 보여줍니다. 4.4 잠재적 개선에 대한 사례 연구 4개의 LLM 모두에서 NetworkX 접근 방식의 경우 네트워크 트래픽 분석의 경우 96개 테스트(24×4) 중 35개가 실패하고 네트워크 수명 주기의 경우 36개 테스트(9×4) 중 17개가 실패했습니다.표 6: MALT에서 Bard를 사용한 개선 사례 Bard + Pass@5 Bard + 자체 디버그 NetworkX Bard + Pass@0.1.0.LLM 비용($) 그래프 노드 및 에지의 합 (a) 쿼리당 LLM 비용의 CDF (b) 그래프 크기(80개 노드 및 에지)에 대한 비용 분석 그림 4: 각각 비용 및 확장성 분석 관리.표 5는 오류 유형을 요약한 것입니다. 절반 이상의 오류는 구문 오류 또는 가상(존재하지 않는) 속성과 관련이 있습니다. 보완적인 프로그램 합성 기술(섹션 2.2)을 사용하면 이러한 오류를 수정할 수 있는지 확인하기 위해 사례 연구를 수행합니다. 우리는 두 가지 기술을 평가합니다: (1) pass@k [10], 여기서 LLM은 동일한 질문으로 k번 쿼리되고, 적어도 하나의 답변이 올바르면 성공한 것으로 간주됩니다. 이 방법은 LLM의 고유한 무작위성으로 인해 발생하는 오류를 줄이고 향상된 결과를 위해 코드 선택 기술 [9, 10, 48]과 결합할 수 있습니다; (2) 자체 디버그 [11], 이는 오류 메시지를 LLM에 다시 제공하고 이전 응답을 수정하도록 장려하는 것을 포함합니다. = 우리는 Bard 모델과 NetworkX 접근 방식을 사용하여 세 개의 실패한 네트워크 수명 주기 쿼리를 사용하여 사례 연구를 수행합니다. 표 6은 pass@k (k 5)와 자체 디버그 모두 코드 품질을 크게 향상시켜 각각 100%와 67%의 개선을 가져옴을 보여줍니다. 이러한 결과는 보완 기술을 적용하면 네트워크 관리 애플리케이션에서 LLM 생성 코드의 정확도를 더욱 향상시킬 수 있는 상당한 잠재력이 있음을 나타냅니다. 4.5 비용 및 확장성 분석 네트워크 트래픽 분석 애플리케이션에 대한 Azure [36]에서 GPT-4 가격을 활용하여 LLM 비용을 조사합니다. 그림 4a는 80개의 노드와 에지가 있는 작은 그래프의 경우 허수아비 접근 방식이 우리 방법보다 3배 더 비용이 많이 든다는 것을 보여줍니다. 그래프 크기가 확장됨에 따라(그림 4b) 두 접근 방식 간의 격차가 커지고 허수아비 접근 방식은 150개의 노드와 에지가 있는 중간 그래프의 경우 LLM의 토큰 한도를 초과합니다. 반대로 우리 방법은 그래프 크기 증가에 영향을 받지 않는 작은 비용(쿼리당 $0. 미만)을 갖습니다. 5 토론 및
--- CONCLUSION ---
LLM의 최근 발전은 네트워크 관리에서 새로운 기회의 길을 열었습니다. 설명 가능성, 확장성 및 개인 정보 보호 문제를 해결하면서 그래프 조작을 위한 작업별 코드를 생성하기 위해 LLM을 활용하는 시스템 프레임워크를 소개합니다. 우리의 프로토타입과 예비 연구는 이 방법의 잠재력을 보여주지만, 이 신생 연구 분야에는 여전히 많은 미해결 문제가 남아 있습니다. 복잡한 작업을 위한 코드 품질. 우리의 평가에서 알 수 있듯이, LLM에서 생성된 코드는 쉽고 중간 정도의 작업에 매우 정확하지만, 더 복잡한 작업에서는 정확도가 떨어집니다. 이는 부분적으로 LLM이 특정 네트워크 관리 지식 없이 일반 코드 코퍼스에서 학습되었기 때문입니다. 미해결 문제는 작업을 더 간단한 하위 작업으로 분해[56], 애플리케이션별 플러그인 통합[42] 또는 애플리케이션별 코드 예제로 모델을 미세 조정하는 것과 같이 복잡한 네트워크 관리 작업을 위한 고품질 코드를 생성할 수 있는 도메인별 프로그램 합성 기술을 개발하는 방법입니다. 코드 이해 및 검증. 네트워크 운영자에게 LLM 생성 코드의 정확성과 이해를 보장하는 것은 어려울 수 있습니다. LLM 생성 테스트 사례[9] 및 코드 설명[38]과 같은 일반적인 접근 방식이 있지만 복잡한 작업에는 충분하지 않습니다. 이해와 검증을 돕기 위한 견고하고 애플리케이션별 방법을 개발하는 것은 중요한 과제입니다. 벤치마크 및 애플리케이션 확장. 현재 벤치마크를 확장하여 더 많은 네트워크 관리 작업을 다루면 네트워크 장애 진단[27,47] 및 구성 검증[5,17]과 같은 다른 애플리케이션에 대한 더 광범위한 효과성과 적용 가능성에 대한 의문이 제기됩니다. 이러한 과제를 해결하려면 새로운 네트워크 상태 표현, 코드 생성 전략, 애플리케이션별 라이브러리 및 플러그인을 탐색해야 합니다. 요약하자면, 네트워크 관리에서 LLM을 사용하기 위한 일반 프레임워크를 도입하는 선구적인 단계를 밟아 네트워크 운영자의 작업을 단순화하기 위한 새로운 경계를 제시합니다. 벤치마크와 데이터 세트와 함께 우리의 작업이 이 분야에서 지속적인 탐색을 자극하기를 바랍니다. 6 참고문헌 [1] R. Anil, AM Dai, O. Firat, M. Johnson, D. Lepikhin, A. Passos, S. Shakeri, E. Taropa, P. Bailey, Z. Chen, E. Chu, JH Clark, LE Shafey, Y. Huang, K. Meier-Hellstern, G. Mishra, E. Moreira, M. Omernick, K. Robinson, S. Ruder, Y. Tay, K. Xiao, Y. Xu, Y. Zhang, GH Ábrego, J. Ahn, J. Austin, P. Barham, JA Botha, J. Bradbury, S. Brahma, K. Brooks, M. Catasta, Y. Cheng, C. Cherry, CA Choquette-Choo, A. Chowdhery, C. Crepy, S. Dave, M. Dehghani, S. Dev, J. Devlin, M. 디아즈, N. Du, E. Dyer, V. Feinberg, F. Feng, V. Fienber, M. Freitag, X. Garcia, S. Gehrmann, L. Gonzalez, et al. PaLM 2 기술 보고서. CoRR, abs/2305.10403, 2023. [2] J. Austin, A. Odena, MI Nye, M. Bosma, H. Michalewski, D. Dohan, E. Jiang, CJ Cai, M. Terry, QV Le, C. Sutton. 대규모 언어 모델을 사용한 프로그램 합성. CORR, abs/2108.07732, 2021. [3] JW Backus, RJ Beeber, S. Best, R. Goldberg, LM Haibt, HL Herrick, RA Nelson, D. Sayre, PB Sheridan, H. Stern, I. Ziller, RA Hughes, R. Nutt. FORTRAN 자동 코딩 시스템. 1957년 서부 공동 컴퓨터 컨퍼런스: 신뢰성을 위한 기술(IRE-AIEE-ACM), 1957. [4] M. Balog, AL Gaunt, M. Brockschmidt, S. Nowozin, D. Tarlow. DeepCoder: 프로그램 작성 학습. 제5회 국제 학습 표현 컨퍼런스(ICLR) 회의록, 2017. [5] R. Beckett, A. Gupta, R. Mahajan, D. Walker. 네트워크 구성 검증에 대한 일반적인 접근 방식. ACM 데이터 통신 특별 관심 그룹(SIGCOMM) 회의록, 2017. [6] TB Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, DM Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, D. Amodei. 언어 모델은 소수 학습자입니다. 신경 정보 처리 시스템(NeurIPS)의 발전, 2020. [7] S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Kamar, P. Lee, YT Lee, Y. Li, SM Lundberg, H. Nori, H. Palangi, MT Ribeiro 및 Y. Zhang. 일반 인공 지능의 불꽃: GPT-4를 사용한 초기 실험. CORR, abs/2303.12712, 2023. [8] A. Chen, J. Scheurer, T. Korbak, JA Campos, JS Chan, SR Bowman, K. Cho 및 E. Perez. 자연어 피드백을 통한 훈련을 통해 코드 생성을 개선합니다. CoRR, abs/2303.16749, 2023. [9] B. Chen, F. Zhang, A. Nguyen, D. Zan, Z. Lin, J. Lou 및 W. Chen. CodeT: 생성된 테스트를 사용한 코드 생성. CORR, abs/2207.10397, 2022. [10] M. Chen, J. Tworek, H. Jun, Q. Yuan, HP de Oliveira Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, A. Ray, R. Puri, G. Krueger, M. Petrov, H. Khlaaf, G. Sastry, P. Mishkin, B. Chan, S. Gray, N. Ryder, M. Pavlov, A. Power, L. Kaiser, M. Bavarian, C. Winter, P. Tillet, FP Such, D. Cummings, M. Plappert, F. Chantzis, E. Barnes, A. Herbert-Voss, WH Guss, A. Nichol, A. Paino, N. Tezak, J. Tang, I. Babuschkin, S. Balaji, S. Jain, W. Saunders, C. Hesse, AN Carr, J. Leike, J. Achiam, V. Misra, E. Morikawa, A. Radford, M. Knight, M. Brundage, M. Murati, K. Mayer, P. Welinder, B. McGrew, D. Amodei, S. McCandlish, I. Sutskever, W. Zaremba. 코드로 학습된 대규모 언어 모델 평가. CORR, abs/2107.03374, 2021. [11] X. Chen, M. Lin, N. Schärli, D. Zhou. 대규모 언어 모델에 자체 디버깅을 가르치기. CoRR, abs/2304.05128, 2023. [12] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, HW Chung, C. Sutton, S. Gehrmann, P. Schuh, K. Shi, S. Tsvyashchenko, J. Maynez, A. Rao, P. Barnes, Y. Tay, N. Shazeer, V. Prabhakaran, E. Reif, N. Du, B. Hutchinson, R. Pope, J. Bradbury, J. Austin, M. Isard, G. Gur-Ari, P. Yin, T. Duke, A. Levskaya, S. Ghemawat, S. Dev, H. Michalewski, X. Garcia, V. Misra, K. Robinson, L. Fedus, D. Zhou, D. 이폴리토, D. Luan, H. Lim, B. Zoph, A. Spiridonov, R. Sepassi, D. Dohan, S. Agrawal, M. Omernick, AM Dai, TS Pillai, M. Pellat, A. Lewkowycz, E. Moreira, R. Child, O. Polozov, K. Lee, Z. Zhou, X. Wang, B. Saeta, M. Diaz, O. Firat, M. Catasta, J. Wei, K. Meier-Hellstern, D. Eck, J. Dean, S. Petrov 및 N. Fiedel. PaLM: 경로를 통한 언어 모델링 확장. CORR, abs/2204.02311, 2022. [13] K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, M. Plappert, J. Tworek, J. Hilton, R. Nakano, C. Hesse, and J. Schulman. 수학 단어 문제를 풀기 위한 검증자 훈련. CoRR, abs/2110.14168, 2021. [14] CJ Date. SQL 표준 가이드. Addison-Wesley Longman Publishing Co., Inc., 1989. [15] N. Developers. NetworkX: Python에서의 네트워크 분석. https://networkx.org/, 2023-02에 검색됨. [16] T. Eloundou, S. Manning, P. Mishkin, and D. Rock. GPT는 GPTS입니다. 대규모 언어 모델의 노동 시장 영향 잠재력에 대한 초기 연구. CoRR, abs/2303.10130, 2023. [17] A. Fogel, S. Fung, L. Pedrosa, M. Walraed-Sullivan, R. Govindan, R. Mahajan, TD Millstein. 네트워크 구성 분석에 대한 일반적인 접근 방식. 제12회 USENIX 네트워크 시스템 설계 및 구현 심포지엄(NSDI), 2015. [18] D. Fried, A. Aghajanyan, J. Lin, S. Wang, E. Wallace, F. Shi, R. Zhong, W. Yih, L. Zettlemoyer, M. Lewis. InCoder: 코드 채우기 및 합성을 위한 생성 모델. CORR, abs/2204.05999, 2022. [19] E. Glatz, S. Mavromatidis, B. Ager, and XA Dimitropoulos. 빈번한 패턴 마이닝과 하이퍼그래프를 사용하여 대규모 네트워크 트래픽 데이터 시각화. 컴퓨팅, 96(1):27-38, 2014. [20] Google. Google Bard. https://bard.google.com/, 2023-06에 검색됨. [21] Google. MALT 예제 모델. https://github.com/google/malt-example-models, 2023-06에 검색됨. [22] S. Gulwani. 입출력 예제를 사용하여 스프레드시트에서 문자열 처리 자동화. 2011년 제38회 ACM SIGPLAN-SIGACT 프로그래밍 언어 원리 심포지엄(POPL) 회의록. [23] S. Gulwani, O. Polozov, R. Singh. 프로그램 합성. Found. Trends Program. Lang., 4(1-2), 2017. [24] A. Gupta, R. Harrison, M. Canini, N. Feamster, J. Rexford, W. Willinger. Sonata: 쿼리 기반 스트리밍 네트워크 원격 측정. ACM 데이터 통신 특별 관심 그룹(SIGCOMM) 연례 회의록, 2018. [25] M. Iliofotou, P. Pappu, M. Faloutsos, M. Mitzenmacher, S. Singh, G. Varghese. 트래픽 분산 그래프(TDG)를 사용한 네트워크 모니터링. 2007년 제7회 ACM SIGCOMM 인터넷 측정 컨퍼런스(IMC) 회의록.[26] S. Iyer, I. Konstas, A. Cheung, J. Krishnamurthy, L. Zettlemoyer. 사용자 피드백에서 신경 의미 파서 학습.2017년 제55회 계산 언어학 협회(ACL) 연례 회의록.[27] S. Kandula, D. Katabi, J. Vasseur.Shrink: IP 네트워크의 장애 진단 도구.2005년 제1회 ACM 네트워크 데이터 마이닝 워크숍(MineNet) 연례 회의록.[28] H. Kim, B. So, W. Han, H. Lee.자연어에서 SQL로: 오늘날 우리는 어디에 있는가?Proc. VLDB Endow., 13(10), 2020. [29] DQ Le, T. Jeong, HE Roman, and JW Hong. 트래픽 분산 그래프 기반 이상 탐지. 정보통신기술(SoICT) 심포지엄 논문집, 2011. [30] S. Lee, K. Levanti, and HS Kim. 네트워크 모니터링: 현재와 미래. Comput. Networks, 65, 2014. [31] F. Li and HV Jagadish. 관계형 데이터베이스를 위한 대화형 자연어 인터페이스 구축. Proc. VLDB Endow., 8(1), 2014. [32] R. Li, LB Allal, Y. Zi, N. Muennighoff, D. Kocetkov, C. Mou, M. Marone, C. Akiki, J. Li, J. Chim, Q. Liu, E. Zheltonozhskii, TY Zhuo, T. Wang, O. Dehaene, M. Davaadorj, J. Lamy-Poirier, J. Monteiro, O. Shliazhko, N. Gontier, N. Meade, A. Zebaze, M. Yee, LK Umapathi, J. Zhu, B. Lipkin, M. Oblokulov, Z. Wang, RM V, J. Stillerman, SS Patel, D. Abulkhanov, M. Zocca, M. Dey, Z. Zhang, N. Moustafa-Fahmy, U. 바타차리야, W. Yu, S. Singh, S. Luccioni, P. Villegas, M. Kunakov, F. Zhdanov, M. Romero, T. Lee, N. Timor, J. Ding, C. Schlesinger, H. Schoelkopf, J. Ebert, T. Dao, M. Mishra, A. Gu, J. Robinson, CJ Anderson, B. Dolan-Gavitt, D. Contractor, S. Reddy, D. Fried, D. Bahdanau, Y. Jernite, CM Ferrandis, S. Hughes, T. Wolf, A. Guha, L. von Werra 및 H. de Vries. StarCoder: 소스가 함께하길 바랍니다! CORR, abs/2305.06161, 2023. [33] Y. Li, DH Choi, J. Chung, N. Kushman, J. Schrittwieser, R. Leblond, T. Eccles, J. Keeling, F. Gimeno, AD Lago, T. Hubert, P. Choy, C. de Masson d&#39;Autume, I. Babuschkin, X. Chen, P. Huang, J. Welbl, S. Gowal, A. Cherepanov, J. Molloy, DJ Mankowitz, ES Robson, P. Kohli, N. de Freitas, K. Kavukcuoglu 및 O. Vinyals. AlphaCode를 사용한 경쟁 수준의 코드 생성. CORR, abs/2203.07814, 2022. [34] Z. Manna 및 RJ Waldinger. 자동 프로그램 합성을 지향합니다. 커뮤니케이터 ACM, 14(3), 1971. [35] J. Maynez, S. Narayan, B. Bohnet 및 RT McDonald. 추상 요약에서의 충실성과 사실성에 관하여. D. Jurafsky, J. Chai, N. Schluter 및 JR Tetreault 편집자, Association for Computational Linguistics(ACL)의 제58회 연례 회의록, 2020. [36] Microsoft. Azure OpenAI 서비스 가격 책정. https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/, 2023-06에 검색됨. [37] Microsoft. 대규모 언어 모델을 제어하기 위한 지침 언어. https://github.com/microsoft/guidance, 2023-06에 검색됨. [38] Microsoft. GitHub Copilot X 소개. https://github.com/features/preview/copilot-x, 2023-06에 검색됨. [39] JC Mogul, D. Goricanec, M. Pool, A. Shaikh, D. Turk, B. Koley, X. Zhao. 다중 추상화 수준에서 네트워크 토폴로지 모델링 경험. USENIX Symposium on Networked Systems Design and Implementation(NSDI), 2020. [40] A. Ni, S. Iyer, D. Radev, V. Stoyanov, W. Yih, SI Wang, XV Lin. LEVER: 실행을 통해 언어-코드 생성을 검증하는 방법 학습. CORR, abs/2302.08468, 2023. [41] NumFOCUS. pandas. https://pandas.pydata.org/, 2023-06에 검색됨. [42] OpenAI. ChatGPT 플러그인. https://openai.com/blog/chatgpt-plugins, 2023-05에 검색됨. [43] OpenAI. 코드 인터프리터. https://openai.com/blog/ chatgpt-plugins #code-interpreter, 2023-08에 검색됨. [44] OpenAI. ChatGPT 소개. https://openai.com/blog/chatgpt, 2023-02에 검색됨. [45] OpenAI. OpenAI 모델. https://platform.openai.com/docs/models/overview, 2023-06에 검색됨. [46] OpenAI. GPT-4 기술 보고서. CORR, abs/2303.08774, 2023. [47] A. Roy, H. Zeng, J. Bagga, AC Snoeren. 수동 실시간 데이터 센터 오류 감지 및 위치 파악. USENIX 네트워크 시스템 설계 및 구현 심포지엄(NSDI), 2017. [48] F. Shi, D. Fried, M. Ghazvininejad, L. Zettlemoyer, SI Wang. 실행을 통한 자연어에서 코드로의 번역. 자연어 처리 경험적 방법(EMNLP) 컨퍼런스 회의록, 2022. [49] N. Shinn, F. Cassano, B. Labash, A. Gopinath, K. Narasimhan, S. Yao. Reflexion: 언어적 강화 학습을 통한 언어 에이전트. CORR, abs/2303.11366, 2023. [50] K. Singhal, S. Azizi, T. Tu, SS Mahdavi, J. Wei, HW Chung, N. Scales, AK Tanwani, H. Cole-Lewis, S. Pfohl, P. Payne, M. Seneviratne, P. Gamble, C. Kelly, N. Schärli, A. Chowdhery, PA Mansfield, BA y Arcas, DR Webster, GS Corrado, Y. Matias, K. Chou, J. Gottweis, N. Tomasev, Y. Liu, A. Rajkomar, JK Barral, C. Semturs, A. Karthikesalingam 및 V. Natarajan. 대규모 언어 모델은 임상 지식을 인코딩합니다. CORR, abs/2212.13138, 2022. [51] R. Sun, S. Ö. Arik, H. Nakhost, H. Dai, R. Sinha, P. Yin, and T. Pfister. SQL-PALM: 텍스트-SQL을 위한 개선된 대규모 언어 모델 적응. CORR, abs/2306.00739, 2023. [52] H. Tahaei, F. Afifi, A. Asemi, F. Zaki, and NB Anuar. IoT 네트워크에서 트래픽 분류의 증가: 설문 조사. J. Netw. Comput. 영어: Appl., 154:102538, 2020. [53] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave, and G. Lample. LLAMA: 개방적이고 효율적인 기초 언어 모델. CORR, abs/2302.13971, 2023. [54] I. Trummer. CodexDB: GPT-3 코덱스를 사용하여 자연어 명령어에서 쿼리 처리를 위한 코드 합성. Proc. VLDB Endow., 15(11), 2022. [55] E. Union. 일반 데이터 보호 규정(GDPR). https://commission.europa.eu/law/law-topic/ data-protection_en, 2023-04에 검색됨. [56] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia, EH Chi, QV Le, D. Zhou. 사고의 사슬 프롬프트는 대규모 언어 모델에서 추론을 이끌어냅니다. 신경 정보 처리 시스템의 발전(NeurIPS), 2022년. [57] J. White, S. Hays, Q. Fu, J. Spencer-Smith, DC Schmidt. 코드 품질, 리팩토링, 요구 사항 도출 및 소프트웨어 설계를 개선하기 위한 ChatGPT 프롬프트 패턴. CoRR, abs/2303.07839, 2023. [58] Z. Zhang, A. Zhang, M. Li, A. Smola. 대규모 언어 모델에서 사고의 사슬을 자동으로 프롬프트합니다. CORR, abs/2210.03493, 2022. [59] WX Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang, J. Zhang, Z. Dong, Y. Du, C. Yang, Y. Chen, Z. Chen, J. Jiang, R. Ren, Y. Li, X. Tang, Z. Liu, P. Liu, J. Nie, J. Wen. 대규모 언어 모델 조사. CORR, abs/2303.18223, 2023. [60] Y. Zhou, C. Sun, HH Liu, R. Miao, S. Bai, B. Li, Z. Zheng, L. Zhu, Z. Shen, Y. Xi, P. Zhang, D. Cai, M. Zhang, M. Xu. 프로그래밍 가능 데이터 플레인의 흐름 이벤트 원격 측정. 2020년 ACM 데이터 통신 특별 관심 그룹(SIGCOMM) 연례 학술 대회 회의록.
