--- INTRODUCTION ---
추천 시나리오에서 언어를 사용하는 것은 새로운 개념이 아니다. 콘텐츠 기반 추천자는 약 30년 동안 항목 설명 및 리뷰와 같은 항목과 관련된 텍스트를 활용해 왔다[29]. 그러나 대화형 추천 시스템의 최근 발전으로 인해 사용자가 선호도를 표현하고 받은 추천에 대한 피드백을 제공하는 자연스럽고 직관적인 수단으로 언어가 최전선에 섰다[15, 24]. 가장 최근에는 사용자가 선호도를 NL 진술문으로 표현하는 자연어(NL) 사용자 프로필 개념이 제안되었다[37]. 텍스트 기반 사용자 표현을 사용한다는 아이디어는 여러 가지 이유로 매력적이다. 완전한 투명성을 제공하고 사용자가 시스템의 개인화를 제어할 수 있기 때문이다. 또한 사용 데이터가 거의 또는 전혀 없는(거의) 콜드 스타트 설정에서 선호도에 대한 NL 요약을 제공하면 개인화되고 만족스러운 *Google에서 휴가를 보내는 동안 수행한 작업. 이 작품의 일부 또는 전체를 개인 또는 교실에서 사용하기 위해 디지털 또는 하드 카피로 만드는 것은 무료입니다. 단, 이 작품의 사본을 수익 또는 상업적 이익을 위해 만들거나 배포하지 않고 사본에 이 고지 사항과 첫 페이지에 있는 전체 인용문을 포함해야 합니다. 이 작품의 타사 구성 요소에 대한 저작권은 존중해야 합니다. 다른 모든 용도에 대해서는 소유자/저자에게 문의하십시오. © 2023 저작권은 소유자/저자에게 있습니다. 2023년 9월 18-22일, 싱가포르, 싱가포르 ACMRecSys &#39;23에 제출된 원고 Scott Sanner, Krisztian Balog, Filip Radlinski, Ben Wedin, Lucas Dixon의 사용자 경험. 그러나 이러한 NL 선호도 설명과 기존 항목 기반 접근 방식의 통제된 양적 비교는 매우 제한적입니다. 따라서 이 연구를 주도하는 주요 연구 질문은 다음과 같습니다. 자연어 기반 선호도 설명에서 추천을 위한 대규모 언어 모델(LLM)을 사용한 프롬프트 전략은 항목 평가에만 기반한 협업 필터링 방법과 비교하여 얼마나 효과적입니까? 우리는 LLM의 최근 발전과 다양한 자연어 과제에서 최첨단 결과를 이끌어낸 프롬프팅 기반 패러다임을 기반으로 언어 기반 항목 추천 과제를 해결하며, 이를 통해 통합된 프레임워크에서 풍부한 긍정적, 부정적 설명적 콘텐츠와 항목 선호도를 활용할 수 있습니다. 이러한 새로운 기술을 정보 검색 기술[3]을 사용하는 기존 언어 기반 접근 방식과 협업 필터링 기반 접근 방식[14, 42]과 대조합니다. 새로운 과제이기 때문에 언어 기반 항목 추천을 위한 데이터 세트가 없습니다. 주요 기여 중 하나로 데이터 수집 프로토콜을 제시하고 선호도에 대한 자연어 설명과 항목 평가를 포함하는 테스트 컬렉션을 구축합니다. 이를 통해 다음과 같은 연구 질문에 답하고자 합니다. • RQ1: 자연어로 표현된 선호도가 (특히) 콜드 스타트 추천에 대한 항목을 대체하기에 충분한가요? 언어와 항목을 결합하면 성능이 얼마나 향상되나요? • RQ2: LLM 기반 추천 방법은 항목 기반 협업 필터링 방법과 어떻게 비교되나요? • RQ3: 어떤 LLM 프롬프트 스타일, 즉 완료, 지시 또는 few-shot 프롬프트가 가장 좋은 성과를 보입니까? • RQ4: 자연어 선호도 포함이 언어 기반 추천을 개선합니까? 우리의 주요 기여는 다음과 같습니다. (1) 언어 기반 항목 추천을 최첨단 항목 기반 추천 접근 방식과 직접 비교할 수 있는 실험 설계를 고안하고 새로운 데이터 수집 프로토콜을 제시합니다(섹션 3). (2) 언어 기반 항목 추천 작업을 위한 LLM을 위한 다양한 프롬프트 방법을 제안합니다(섹션 4). (3) 제안된 프롬프트 기반 방법을 텍스트 기반 및 항목 기반 접근 방식을 모두 포함하는 강력한 기준선 세트와 실험적으로 비교합니다(섹션 5). 궁극적으로 순수한 언어 기반 선호도 설명에서 LLM 기반 추천은 설명 가능하고 분석 가능한 언어 기반 선호도 표현을 기반으로 하는 경쟁력 있는 근접 콜드 스타트 추천 시스템을 제공한다는 것을 관찰합니다. 2
--- RELATED WORK ---
항목 기반 추천. 기존의 추천 시스템은 항목 평가에 의존합니다. 새로운 사용자의 경우, 이는 사용자가 추천자와 상호 작용함에 따라 시간이 지남에 따라 제공될 수 있지만, 이는 초기 성능이 좋지 않음을 의미합니다. 따라서 선호도는 종종 새로운 사용자를 위한 설문지를 통해 요청됩니다[22, 39, 41]. 항목 간의 상대적 선호도[10, 39]와 같은 다른 형태의 항목 기반 선호도를 살펴보는 작업도 있었지만, 개별 항목 평가에 의존하는 접근 방식이 문헌을 지배하고 있습니다. 사용자-항목 평가 코퍼스가 주어지면 매우 많은 추천 알고리즘이 존재합니다. 이러한 알고리즘은 다음과 같습니다.
--- METHOD ---
s. 이 조사를 지원하기 위해, 우리는 다양한 (편향된) 추천 항목과 (편향되지 않은) 무작위 항목에 대한 평가와 함께 사용자로부터 도출된 항목 기반 및 언어 기반 선호도로 구성된 새로운 데이터 세트를 수집합니다. 수많은
--- EXPERIMENT ---
모든 결과에 따르면, LLM은 이 특정 작업에 대한 감독 학습이 없거나(제로샷) 레이블이 몇 개뿐(피우샷)임에도 불구하고, 순수 언어 기반 선호도(항목 선호도 없음)에 대해 항목 기반 CF 방법과 비교했을 때 근접 콜드 스타트 사례에서 경쟁력 있는 추천 성능을 제공합니다. 이는 언어 기반 선호도 표현이 항목 기반 또는 벡터 기반 표현보다 더 설명하고 검토하기 쉽기 때문에 특히 유망합니다. CCS 개념: • 정보 시스템 → 추천 시스템. 추가 키워드 및 구문: 추천; 투명성; 검토 가능성; 자연어 ACM 참조 형식: Scott Sanner, Krisztian Balog, Filip Radlinski, Ben Wedin, Lucas Dixon. 2023. 대규모 언어 모델은 언어 및 항목 기반 선호도에 대한 경쟁력 있는 근접 콜드스타트 추천자입니다. 17회 ACM 추천 시스템 컨퍼런스(RecSys &#39;23), 2023년 9월 18-22일, 싱가포르, 싱가포르. ACM, New York, NY, USA, 11페이지. https://doi.org/10.1145/3604915. 서론 추천 시나리오에서 언어를 사용하는 것은 새로운 개념이 아니다. 콘텐츠 기반 추천자는 약 30년 동안 항목 설명 및 리뷰와 같은 항목과 관련된 텍스트를 활용해 왔다[29]. 그러나 대화형 추천 시스템의 최근 발전으로 인해 사용자가 선호도를 표현하고 받은 추천에 대한 피드백을 제공하는 자연스럽고 직관적인 수단으로 언어가 최전선에 섰다[15, 24]. 가장 최근에는 사용자가 선호도를 NL 진술로 표현하는 자연어(NL) 사용자 프로필 개념이 제안되었다[37]. 텍스트 기반 사용자 표현을 사용한다는 아이디어는 여러 가지 이유로 매력적이다. 완전한 투명성을 제공하고 사용자가 시스템의 개인화를 제어할 수 있게 해주기 때문이다. 또한 사용 데이터가 거의 또는 전혀 없는 (거의) 콜드 스타트 설정에서 선호도에 대한 NL 요약을 제공하면 개인화되고 만족스러운 *Google에서 휴직하는 동안 수행한 작업을 가능하게 할 수 있습니다. 이 작업의 일부 또는 전체를 개인 또는 교실용으로 디지털 또는 하드 카피로 만드는 것은 이익 또는 상업적 이점을 위해 사본을 만들거나 배포하지 않고 사본에 이 고지 사항과 첫 페이지에 전체 인용문을 표시하는 경우 무료로 허가됩니다. 이 작업의 타사 구성 요소에 대한 저작권은 존중해야 합니다. 다른 모든 용도의 경우 소유자/저자에게 문의하십시오. © 2023 저작권은 소유자/저자가 보유합니다. 2023년 9월 18-22일 싱가포르, 싱가포르 Scott Sanner, Krisztian Balog, Filip Radlinski, Ben Wedin 및 Lucas Dixon의 사용자 경험에 대한 ACMRecSys &#39;23에 제출된 원고. 그러나 이러한 NL 선호도 설명과 기존 항목 기반 접근 방식에 대한 통제된 정량적 비교는 매우 제한적입니다. 따라서 이 연구를 이끄는 주요 연구 질문은 다음과 같습니다. 대규모 언어 모델(LLM)을 사용한 프롬프팅 전략은 자연어 기반 선호도 설명에서 추천을 위해 항목 평가에만 기반한 협업 필터링 방법과 비교하여 얼마나 효과적인가요? 우리는 다양한 자연어 작업에서 최첨단 결과를 가져온 LLM 및 프롬프팅 기반 패러다임의 최근 발전을 바탕으로 언어 기반 항목 추천 과제를 해결하고, 이를 통해 통합된 프레임워크에서 풍부한 긍정적 및 부정적 설명적 콘텐츠와 항목 선호도를 활용할 수 있습니다. 이러한 새로운 기술을 정보 검색 기술[3]과 협업 필터링 기반 방법[14, 42]을 사용하는 기존 언어 기반 접근 방식과 대조합니다. 새로운 과제이기 때문에 언어 기반 항목 추천을 위한 데이터 세트가 없습니다. 우리의 주요 기여 중 하나로 데이터 수집 프로토콜을 제시하고 선호도에 대한 자연어 설명과 항목 평가를 포함하는 테스트 컬렉션을 구축합니다. 이를 통해 다음과 같은 연구 질문에 답하고자 합니다.• RQ1: 자연어로 표현된 선호도가 (특히) 콜드 스타트 추천에 대한 항목을 대체하기에 충분한가요?그리고 언어와 항목을 결합하면 성능이 얼마나 향상되나요?• RQ2: LLM 기반 추천 방법은 항목 기반 협업 필터링 방법과 어떻게 비교되나요?• RQ3: 완성, 지시 또는 퓨샷 프롬프트 중 어떤 LLM 프롬프트 스타일이 가장 좋은 성과를 보일까요?• RQ4: 자연어 선호도를 포함하면 언어 기반 추천이 향상되나요?저희의 주요 기여는 다음과 같습니다.(1) 언어 기반 항목 추천을 최첨단 항목 기반 추천 접근 방식과 직접 비교할 수 있는 실험 설계를 고안하고 새로운 데이터 수집 프로토콜을 제시합니다(섹션 3).(2) 언어 기반 항목 추천 작업을 위한 LLM에 대한 다양한 프롬프트 방법을 제안합니다(섹션 4). (3) 우리는 제안된 프롬프트 기반 방법을 텍스트 기반 및 항목 기반 접근 방식을 모두 포함하는 강력한 기준선 세트와 실험적으로 비교합니다(섹션 5). 궁극적으로 우리는 순수한 언어 기반 선호도 설명에서 LLM 기반 추천이 설명 가능하고 분석 가능한 언어 기반 선호도 표현을 기반으로 하는 경쟁력 있는 근접 콜드 스타트 추천 시스템을 제공한다는 것을 관찰합니다. 2 관련 연구 항목 기반 추천. 기존 추천 시스템은 항목 평가에 의존합니다. 새 사용자의 경우 사용자가 추천자와 상호 작용함에 따라 시간이 지남에 따라 이를 제공할 수 있지만 이는 초기 성능이 좋지 않음을 의미합니다. 따라서 선호도는 종종 새 사용자를 위한 설문지를 통해 요청됩니다[22, 39, 41]. 항목 간의 상대적 선호도[10, 39]와 같은 다른 형태의 항목 기반 선호도를 살펴보는 작업도 있었지만 개별 항목 평가에 의존하는 접근 방식이 문헌을 지배합니다. 사용자-항목 평가 코퍼스가 주어지면 매우 많은 추천 알고리즘이 존재합니다. 이러한 범위는 기존 사용자와의 간단한 유사성을 활용하는 항목 기반 k-최근접 이웃[40]과 같은 방법부터 사용자에 대한 벡터 표현을 학습하는 행렬 분해 접근 방식[23, 34], 사용자 및 항목 벡터 임베딩을 공동으로 학습하는 딥 러닝 및 오토인코더 접근 방식[8, 19, 28]에 이르기까지 다양합니다. 흥미롭게도 EASE 알고리즘[42]은 훨씬 더 복잡한 최신 접근 방식과 동등한 성능을 보이는 오토인코더 접근 방식입니다. 추천에서의 자연어. 선호도를 이해하기 쉬운 자연어로만 모델링하려는 [2, 37]의 제안에 따라 최근 작업에서는 유망한 결과를 보이는 NL 설명의 대용어로 태그를 사용하는 방법을 탐구했습니다[31]. 이는 예를 들어 Hou et al.[20]과 대조되는데, 이들은 자연어 항목 설명의 (시퀀스)를 LLM에 입력하여 추천을 위한 (이해하기 어려운) 사용자 표현을 생성합니다. 영어: 다른 최근 작업에서는 풍부한 LLM을 사용하여 추천의 기반으로 설명적 자연어를 사용하려고 했습니다.한 극단에서는 특정 맥락적 요구 사항에 대한 매우 자세한 설명을 가정하는 내러티브 기반 추천[4]이 있습니다.마찬가지로 추천에서 NL 사용에 대한 사용자 연구[26]는 추천 의도에 대한 풍부한 분류법을 식별하고 음성 기반 유도가 일반적으로 텍스트 기반 유도보다 더 자세하고 설명적이라는 점을 지적합니다.그러나 이 작업에서는 [37]의 제안으로 돌아가 사용자가 추천 목적을 위해 선호도와 비선호도에 대한 보다 일반적인 목적의 언어 기반 설명을 제공한다고 가정합니다.최근 연구자들은 추천 작업에 언어 모델(LM)을 사용하는 것을 탐구하기 시작했습니다[13].Radlinski et al. [37]은 LLM이 추천에 유용할 수 있는 이유에 대한 이론적 동기를 제시하고 예시 프롬프트를 제공하지만 정량적 평가를 수행하지 않습니다.Mysore et al. [32]은 평가 및 리뷰에서 선호도 내러티브를 생성하여 보류된 항목에서 추천하는 내러티브를 사용합니다.Penha 및 Hauff [36]는 기성형 사전 학습된 BERT [12]에 추천할 항목에 대한 협업 및 콘텐츠 기반 지식이 모두 포함되어 있음을 보여줍니다.또한 BERT가 언어 기반 설명에서 추천을 위한 정보 검색(IR) 기준선보다 성능이 우수함을 보여줍니다.그러나 LM에서 언어 기반 대 항목 기반 추천의 상대적 성능을 평가하지 않으며(이를 위해 특별히 데이터 세트를 큐레이팅함) BERT의 인코더 전용 LM은 여기에서 살펴보는 통합 프롬프트 프레임워크에서 이를 쉽게 허용하지 않습니다.RecoBERT [30]는 텍스트 기반 항목과 설명 쌍 간의 유사성을 도출하기 위해 사용자 지정 학습된 LM을 활용하며, 저자는 이것이 기존 IR 방법보다 성능이 우수하다는 것을 발견했습니다. 영어: Hou et al. [21]은 우리의 아이템 전용 few-shot 접근 방식과 정신이 비슷한 맥락 내 학습(ICL) 접근 방식으로 아이템 기반 추천에 중점을 둡니다.마찬가지로 Kang et al. [27]은 LLM을 사용하여 대상 아이템의 평가를 예측합니다.마지막으로 ReXPlug [17]는 사전 학습된 LM을 활용하여 사용자를 대신하여 합성 리뷰를 생성하여 설명 가능한 추천을 생성합니다.그러나 이러한 작업 중 어느 것도 아이템 기반 접근 방식과 직접 비교하여 실제 자연어 선호도를 새로운 추천으로 변환하기 위해 대규모 LM에서 프롬프트 전략을 탐구하지 않습니다.또한 자연어로 사용자의 자세한 선호도를 포착하고 보이지 않는 아이템에 대한 추천을 평가하려는 데이터 세트를 알지 못합니다.[2,7]과 같은 기존 데이터 세트는 훨씬 더 간단한 특성화에 의존하는 경향이 있습니다.대규모 언어 모델의 프롬프트.대규모 언어 모델(LLM)은 수많은 흥미로운 응용 프로그램을 갖춘 확장되는 연구 분야입니다. 요약, 관계 매핑 또는 질의 응답과 같은 기존 자연어 이해 작업을 넘어 LLM은 코드 생성, 합성 데이터 생성 및 다국어 작업과 같은 많은 작업에도 능숙함이 입증되었습니다[1, 5, 9]. 이러한 모델이 최상의 결과를 생성하도록 촉구하는 방법은 지속적인 연구 주제입니다. 초기 프롬프트 접근 방식은 소수의 훈련 입력-출력 쌍이 실제 입력에 미리 추가되는 소수 샷 프롬프트에 의존했습니다[6]. 지침을 통해 설명된 작업에 대한 사전 훈련된 모델의 추가 조정을 통해 LLM은 또한 제로 샷 설정(즉, 모델에 이전 훈련 예제 없이 작업과 입력이 제공됨)에서도 인상적인 성능을 달성합니다[44]. Geng et al.[16]은 추천 작업 모음에서 훈련된 비교적 작은(매개변수 10억 개 미만) LLM으로 다양한 프롬프트 기술을 테스트하여 주로 항목 평가를 입력으로 사용하여 여러 작업과 도메인에서 유망한 결과를 찾았습니다. 3 실험 설정 항목 기반 및 언어 기반 선호도 간의 관계와 추천에 대한 유용성을 연구하기 위해 최대한 일관성 있는 두 유형의 정보를 제공하는 동일한 평가자의 병렬 코퍼스가 필요합니다. 이러한 성격의 기존 병렬 코퍼스가 부족하므로 작업의 핵심 기여는 이러한 일관된 정보를 수집할 수 있는 실험 설계입니다. 구체적으로, 평가자에게 (1) 항목을 평가하고 자연어로 선호도를 설명하도록 요청한 다음 (2) 두 유형의 선호도에 따라 생성된 추천을 평가자가 균일하게 평가하는 2단계 사용자 연구를 설계했습니다. 따라서 영화 추천이 수많은 사용자 연구 참여자에게 익숙하기 때문에 영화 도메인에서 실험을 수행합니다.RecSys &#39;23, 2023년 9월 18-22일, 싱가포르, 싱가포르 Scott Sanner, Krisztian Balog, Filip Radlinski, Ben Wedin, Lucas Dixon. 이러한 성격의 병렬 코퍼스에서 중요한 우려 사항은 사람들이 특정 특성을 가진 품목을 좋아한다고 말하지만, 실제로는 완전히 다른 품목을 소비하고 긍정적으로 반응할 수 있다는 것입니다. 예를 들어, 사람들이 열망을 표시(예: 특정 팟캐스트 구독)하지만 실제로는 완전히 다른 품목을 소비(예: 다른 사람의 말 듣기)하는 경우가 관찰되었습니다[33]. 일반적으로 의도(예: 건강한 음식을 선택하려는 의도)가 실제 행동으로 이어지지 않는 경우가 많습니다[43]. 코퍼스 간의 이러한 불일치로 인해 추천 작업에 대한 특정 정보의 유용성에 대한 예측이 부정확해질 수 있습니다. 따라서 우리의 주요 고려 사항 중 하나는 일관성을 극대화하는 것이었습니다. 3. 1단계: 선호도 유도 우리의 선호도 유도 설계는 설문지의 시작과 끝에 모두 평가자 관심사에 대한 자연어 설명을 수집했습니다. 구체적으로, 평가자는 먼저 좋아하는 영화 종류와 싫어하는 영화 종류를 설명하는 짧은 문단을 쓰도록 요청받았습니다(자유형 텍스트, 최소 150자). 평가자 r에 대한 이러한 초기 좋아함(+) 및 싫어함(-) 자기 설명은 각각 desc¼ 및 desc로 표시됩니다.다음으로 평가자에게 좋아하는 예시 항목 5개(여기서는 영화)를 말해 달라고 요청했습니다.이는 평가자가 영화 이름을 입력하기 시작하면 특정(전체 그림) 영화로 완성되는 온라인 쿼리 자동 완성 시스템(현대 검색 엔진과 유사)을 사용하여 가능했습니다.자동 완성에는 MovieLens 25M 데이터 세트[18]의 평점 수에 따라 순위가 매겨진 상위 10,000개 영화가 포함되어 흔하지 않은 영화도 포함되도록 했습니다.평가자가 선택하면 이러한 선택 사항이 목록에 추가되어 수정할 수 있습니다.그런 다음 각 평가자에게 이 프로세스를 반복하여 싫어하는 영화 예시 5개를 선택하도록 요청했습니다.평가자 r에 대한 이러한 좋아함(+) 및 싫어함(-) 항목 선택과 항목 선택 인덱스 j = {1,..., 5}는 각각 항목 및 항목으로 표시됩니다. r,j 마지막으로 평가자에게 좋아하는 영화 5개를 보여주고 좋아하는 영화 종류를 설명하는 짧은 문단을 다시 쓰도록 요청했습니다(최종 설명이라고 함). 싫어하는 영화 5개에 대해서도 이 과정을 반복했습니다. 3. 2단계: 추천 피드백 수집 항목 기반 및 언어 기반 추천 알고리즘을 공정하게 비교할 수 있도록, 사용자 연구의 두 번째 단계에서는 평가자에게 1단계에서 수집한 정보를 기반으로 여러 추천 알고리즘이 내린 추천의 품질을 평가하도록 요청했습니다. 특히, 이전 연구에서는 근본적으로 다른 알고리즘을 안정적으로 비교하기 위해서는 레이블의 완전성이 중요하다는 사실을 확인했습니다[2, 25]. 추천자 선택에 대한 요구 사항: 항목 기반, 언어 기반 및 편향 없는 추천을 혼합하는 것을 목표로 했습니다. 따라서 우리는 4개의 샘플 풀에서 추출한 40개의 영화(썸네일과 짧은 줄거리 요약 모두 표시)의 셔플 세트에 대한 사용자 피드백(봤는지 또는 볼까, 그리고 어느 경우든 1~5점 평가)을 수집했습니다.• SP-RandPop, 인기 있는 항목의 편향 없는 샘플: 무작위로 선택한 10개의 최고 인기 항목(MovieLens 평가 수 측면에서 1~1000위) ⚫ SP-RandMidPop, 덜 인기 있는 항목의 편향 없는 샘플: 무작위로 선택한 10개의 덜 인기 있는 항목(MovieLens 평가 수 측면에서 1001~5000위) • SP-EASE, 개인화된 항목 기반 추천: 15명의 사용자의 보류된 파일럿 데이터 세트를 기반으로 조정된 하이퍼파라미터 λ = 5000.0을 사용하는 강력한 기준 EASE[42] 협업 필터링 추천기의 상위 10개 • SP-BM25-Fusion, 개인화된 언어 기반 추천: [3]과 마찬가지로 Amazon Movie Review 코퍼스(v2) [45]의 모든 항목 리뷰와 평가자의 자연어 선호도(desc+) 간의 BM25 일치를 계산하여 최대 BM25 점수 리뷰에 따라 항목을 순위 지정하는 Sparse Review 기반 Late Fusion Retrieval의 상위 10개.LLM은 Cold-start 추천자 근처에서 경쟁력이 있습니다.RecSys &#39;23, 2023년 9월 18-22일, 싱가포르, 싱가포르 SP-RandPop과 SP-RandMidPop은 평가자마다 10개의 다른 영화를 제공하며, 이는 완전히 편향되지 않습니다(사용자 정보를 활용하지 않으므로 더 명확한 추천 또는 기타 잠재적 편향 소스인 항목을 평가하는 데 대한 선호도가 없을 수 있음). 반면, SP-EASE는 EASE 추천(사용자 항목 선호도 기반)으로 구성되어 있으며, 우리는 이를 추천자로 평가합니다. 따라서 이 세트를 사용할 때 약간의 편향이 있습니다. 따라서 우리는 분석에서 SP-RandPop과 SP-RandMidPop의 병합 세트를 편향되지 않은 세트라고 하며, 이 세트에서의 성과가 우리의 핵심입니다.
--- CONCLUSION ---
s. 3.3 설계 결과 가장 중요한 점은 언어 기반 및 항목 기반 접근 방식을 최대한 공정하게 비교하기 위해 두 가지 유형의 선호도의 일관성이 데이터 수집 접근 방식에서 핵심이라는 것입니다. 따라서 평가자로부터 두 가지 유형의 선호도를 순서대로 직접 크라우드소싱했으며, 자체 선택 항목 평가 전후에 두 번 텍스트 설명을 수집했습니다. 이러한 필수 제어는 평가자당 데이터 양이 적어야 함을 의미합니다. 또한 거의 콜드 스타트 대화 환경에서 추천 수신자에게 필요할 수 있는 현실적인 양의 선호도 정보입니다. 필요한 수동 작업의 결과로, 모집된 평가자 수는 알고리즘 비교의 필요한 힘도 고려했으며, 데이터 규모가 아니라 개발된 프로토콜에 주요 기여를 했습니다. 따라서 우리의 접근 방식은 [4, 32]와 유사하게 온라인 콘텐츠에서 대량으로 리뷰나 선호도 설명을 추출하는 대안과 대조됩니다(선호도가 반드시 사람의 관심을 완전히 포착하지는 않음) 및/또는 시간이 지남에 따라 명시적 또는 암묵적으로 표현된 항목 선호도에 의존하는 대안(시간 동안 선호도가 변경될 수 있음).4 방법 언어 기반 및 항목 기반 선호도와 평가자당 40개 항목의 평가를 병행하여 다양한 방법을 비교하여 연구 질문에 답합니다.항목 또는 언어 기반 선호도를 사용하여 기존 기준선을 제시한 다음 항목만 사용하거나 언어만 사용하거나 항목과 언어를 조합하여 사용하는 새로운 LLM 접근 방식을 제시합니다. 4.1 기준선 1단계에서 이끌어낸 항목 및 언어 선호도를 활용하기 위해 CF 방법과 이전에 특히 효과적이라고 밝혀진 언어 기반 기준선을 평가합니다[2, 11].¹ 대부분의 기준선 항목 기반 CF 방법은 MyMediaLite[14]의 기본 구성을 사용합니다. 여기에는 데이터 세트의 평점 수에 따라 항목을 순위 지정하는 MostPopular, 항목 기반 k-최근접 이웃[40], 특이값 분해의 정규화된 버전인 WR-MF: 가중 정규화 행렬 분해[23], 그리고 정규화된 최적화 접근 방식을 통해 평점이 매겨진 항목에 대한 희소 가중치 벡터를 학습하는 희소 선형 방법(SLIM)인 BPR-SLIM[34, 38]이 포함됩니다. 또한 최신 최첨단 항목 기반 EASE 추천 도구[42]에 대한 자체 구현과도 비교합니다. 언어 기반 기준선으로서 섹션 3.2에 설명된 BM25-Fusion과 비교합니다. 마지막으로, 우리는 또한 평가자 풀(무작위)에서 항목의 무작위 순서를 평가하여 이 무지한 기준선에 대해 보정합니다.4.2 프롬프트 방법 우리는 PaLM 모델(크기 620억 개의 매개변수, 1조 4,000억 개의 토큰 이상 학습) [9]의 변형을 사용하여 다양한 프롬프트 전략을 실험합니다.이를 간단히 LLM으로 표시합니다.기호적으로, 우리는 t가 추천에 대한 특정 대상 평가자라고 가정하고 r은 일반 평가자를 나타냅니다.모든 프롬프트는 두 부분으로 표시됩니다.접두사 뒤에 접미사가 오는데, 접미사는 항상 대상 사용자를 위해 점수를 매길 항목(영화)의 이름입니다.¹특히 Dacrema et al. [11] 신경망 방법이 이러한 기준선보다 성능이 뛰어나지 않음을 관찰했습니다.RecSys &#39;23, 2023년 9월 18-22일, 싱가포르, 싱가포르 Scott Sanner, Krisztian Balog, Filip Radlinski, Ben Wedin 및 Lucas Dixon은 (항목)으로 표시합니다.점수는 접미사의 로그 우도로 계산되며 모든 후보 항목 권장 사항을 순위 지정하는 데 사용됩니다.² 따라서 데이터 수집의 2단계에서 수집한 40개 항목의 대상 세트에 있는 모든 항목에 LLM이 부여한 점수를 평가할 수 있습니다.이 표기법을 고려하여 항목만, 언어만 및 다음과 같이 정의된 결합된 언어+항목의 경우에 대한 완료, 제로샷 및 퓨샷 프롬프트 템플릿을 고안합니다.4.2.1 항목만.완료 접근 방식은 사용자 지정 학습된 변환기 대신 사전 학습된 LLM을 활용한다는 점을 제외하면 P5 모델[16]에 사용된 방식과 유사합니다. 이 작업에서는 나머지 접근 방식을 고안했습니다.• 완성: 항목 +1, 항목 +2, 항목³, 항목+4, 항목 +5, (항목) r,• 제로 샷: 다음 영화를 좋아합니다: 항목 41, 항목², 항목³, 항목 4, 항목. 그런 다음 (항목)도 원합니다.사용자 영화 기본 설정: 항목 41, 항목 42, 항목³, 항목 추가 사용자 영화 기본 설정: 항목• 퓨 샷(k): 반복 r € {1,...,k} { 사용자 영화 기본 설정: 항목 +1, 항목 +2, 항목³, 항목, 항목, و 추가 사용자 영화 기본 설정: (항목) 4.2.2 언어만.• 완성: desc (항목) • 제로 샷: 좋아하는 영화를 다음과 같이 설명합니다: desct. 그러면 (항목)도 원합니다. • 퓨샷(k): 반복 r = {1,...,k} { 사용자 설명: desc 사용자 영화 기본 설정: 항목 1, 항목 2, 항목³, 항목, 항목 사용자 설명: desc 사용자 영화 기본 설정: (항목(4) 4.2.3 언어 + 항목. • 완성: desc 항목 41, 항목 42, 항목²³, 항목, 항목 45, (항목) • 제로샷: 제가 좋아하는 영화를 다음과 같이 설명합니다: desc¼ . 저는 다음 영화를 좋아합니다: 항목+1, 항목²², 항목³, t,항목, 항목. 그러면 (항목)도 원합니다. 사용자 설명: desc • 퓨샷(k): 반복 r = {1,..., k} 사용자 영화 기본 설정: 항목 41, 항목 42, 항목™³, 항목 추가 사용자 영화 기본 설정: 항목 r., 사용자 설명: desc¼ 사용자 영화 기본 설정: 항목 +421, 항목 422, item³, item+4, item, 추가 사용자 영화 선호도: (item) 4.2.4 부정적 언어 변형. 제로샷 사례의 경우, 우리는 또한 &quot;나는 다음 영화를 싫어한다: item²,1, itemt,², itemt,³, itemt,4, item²,5&quot;라는 문장을 항목 프롬프트에 삽입하고 &quot;나는 내가 싫어하는 영화를 다음과 같이 설명한다: desct_&quot;라는 문장을 언어 프롬프트에 삽입하여 긍정적 대응물을 Pos+Neg로 레이블을 붙인 프롬프트에 삽입하는 부정적 언어 변형을 실험했습니다. 2 전체 대상 문자열은 영화 이름 뒤에 문자열 끝 토큰이 오는 형식으로, 긴 영화 이름을 처벌하는 잠재적 편향을 완화합니다. LLM은 콜드 스타트 추천자 평가자 ###RecSys &#39;23, 2023년 9월 18-22일, 싱가포르, 싱가포르 표 1. 세 명의 평가자가 제공한 초기 자기 설명의 예. 좋아하는 영화 코미디 영화를 좋아하는 이유는 볼 때마다 기분이 좋아지기 때문입니다. 우리는 그 영화들을 사람들과 함께 볼 수 있습니다. 저는 코미디 영화를 보는 것을 좋아하는데, 왜냐하면 재미있고 오락거리가 많기 때문입니다. 친구나 가족과 함께 보는 것은 매우 신나는 일입니다. 그래서 저는 시간이 날 때마다 항상 코미디 영화를 봅니다. 판타지 영화는 종종 마법, 신화, 경이로움, 그리고 비범함의 요소를 가지고 있습니다. 특정 영화에 따라 어린이와 어른 모두에게 어필할 수 있습니다. 판타지 영화에서 주인공은 종종 어떤 종류의 신비로운 경험을 겪습니다. 저는 코미디 장르의 영화를 좋아하는데, 코미디 영화를 볼 때 매우 행복하고 편안함을 느낄 것입니다. 코미디 영화는 관객을 웃게 하기 위해 고안되었습니다. 공포 코미디, 로맨틱 코미디, 코미디 스릴러, 뮤지컬 코미디와 같이 코미디 장르에는 다양한 종류의 카테고리가 있습니다. 싫어하는 영화 저는 공포 영화를 보는 데 전혀 관심이 없습니다. 왜냐하면 제가 외로움을 느낄 때마다 항상 영화 속 캐릭터들과 어울리지 않기 때문입니다. 그것은 항상 꿈과 기분에 영향을 받을 것입니다. 그래서 대부분 저는 집에 혼자 있을 때는 공포 영화를 보지 않습니다. 공포는 무섭습니다. 저는 무서워하는 느낌을 좋아하지 않습니다. 어떤 사람들은 서스펜스, 피 또는 무서운 이미지에 민감하거나, 공포가 실제처럼 느껴지는 삶의 경험을 했을 수도 있습니다. 저는 액션 장르 영화를 싫어합니다. 싸움을 보면 머리가 아프고 지루하기 때문입니다. 이런 종류의 영화는 주로 폭력과 신체적 묘기에 집중합니다. 표 2. 모든 평가자의 완전히 레이블이 지정된 항목 풀에 있는 항목의 기준 평가 통계. 5개 결과 5. 데이터 분석 영화 분수 평균 평가 샘플 풀 평가자당 본 영화 본 영화 보지 않은 영화 SP-RandPop22% 4.| 2. SP-RandMidPop16% 4.2. SP-EASE46% 4.3. SP-BM25-Fusion24% 4.3. SP-Full27% 4.3. 이제 선호도 도출 및 평가 프로세스의 일환으로 153명의 평가자로부터 수집한 데이터를 간략하게 분석합니다. 평가자들은 자신이 좋아하는 것을 요약한 초기 설명을 쓰는 데 중간값 67초가 걸렸고, 싫어하는 것에는 38초가 걸렸습니다(중간값 길이: 각각 241자와 223자). 좋아하는 것과 싫어하는 것 5개를 제공하는 데는 중간값 174초와 175초가 걸렸습니다. 그 후 좋아하는 것과 싫어하는 것에 대한 최종 설명을 쓰는 데는 중간값 152초와 161초가 걸렸습니다(중간값 길이: 각각 205자와 207자). 초기 설명은 5개의 예시 항목을 제공하는 것보다 3~4배 더 빠르게 생성되었으며, 약 1분 정도 걸렸습니다. 아래에서 볼 수 있듯이, 이러한 노력의 차이는 항목 기반 추천과 설명 기반 추천이 성능 면에서 비슷하기 때문에 특히 중요합니다. 초기 설명의 샘플은 표 1에 나와 있습니다. 다음으로, 섹션 3에 설명된 4개 풀에서 수집된 영화에 대한 평가를 분석합니다. 표 2에서 다음을 관찰합니다. (1) EASE 추천기는 평가자가 이미 본 추천의 비율을 거의 두 배로 높이는 것으로, 평가자가 본 것만 평가하는 훈련된 감독 데이터를 반영합니다. (2) 평가자가 이미 본 영화에 대해 높은 평가를 제공하려는 내재적인 긍정적 편향이 있으며, 이 경우 평균 4.29의 평가에서 입증됩니다. (3) 반면에 평균 평가는 보지 못한 항목에 대해 중립적인 3.00으로 떨어집니다. 5. 추천 항목 주요 실험 결과는 표 3에 나와 있으며 지수 이득(평가 s &lt; 3의 경우 0의 이득, 그렇지 않은 경우 25-3의 이득)이 있는 NDCG@10을 사용합니다. 우리는 항목 및/또는 언어 기반 선호도(섹션 3.1에서 설명한 대로)를 사용하여 다양한 방법의 평균 성과를 비교하여 40개의 완전히 판단된 3개의 서로 다른 풀 기반 하위 집합을 순위를 매겼습니다.우리는 160명의 평가자를 모집했지만 데이터 수집의 두 단계를 모두 완료하지 못한 평가자(5)와 2단계에서 모든 항목 추천에 대해 균일한 평가를 제공한 평가자(2)는 제외했습니다.RecSys &#39;23, 2023년 9월 18-22일, 싱가포르, 싱가포르 Scott Sanner, Krisztian Balog, Filip Radlinski, Ben Wedin, Lucas Dixon 표 3. 모든 추천 방법에 대한 평가자에 대한 평균 NDCG@10(± 95% 표준 오차)을 비교하는 주요 실험 결과.각 경우에 완전히 판단된 평가자별 평가 세트는 제공된 추천 알고리즘에 의해 순위가 매겨집니다.평균 평가 세트 크기는 첫 번째 행에 있습니다.실제 추천 설정에서 보이지 않는 항목 세트의 성과가 가장 중요하다는 점에 유의하십시오. 평가 집합 전체 집합 SP-FullUnbiased 집합 SP-Rand{Pop,MidPop}보이는 항목 10.보이지 않음 29.평균 평가 집합 크기 추천 알고리즘 임의 기준선 인기도 기준선(항목) EASE(항목) WRMF(항목) BPR-SLIM(항목) KNN 항목(언어) BM25-Fusion LLM 항목 완료 LLM 항목 제로샷 LLM 항목 Few-shot(3) LLM 언어 완료 LLM 언어 제로샷 LLM 언어 Few-shot(3) LLM 항목+언어 완료 LLM 항목+언어 제로샷 LLM 항목+언어 Few-shot(3) LLM 항목 제로샷 Pos+Neg LLM 언어 제로샷 Pos+Neg LLM 항목+언어 제로샷 Pos+Neg 0.504 ± 0.0.595±0.0.673±0.0.644±0.0.672±0.0.646±0.0.519±0.0.649±0.0.659 0.0.664±0.0.617 0.0.612±0.0.640±0.0.654± 0.0.660±0.0.532 0.0.6170.0.6100.0.623±0.0.610±0.0.631 0.0.624±0.0.592±0.0.644 0.0.876 0.023 | 0.511 0.0.894±0.0.899 0.0.897 ± 0.0.902 ± 0.0.889 0.0.534 ± 0.0.559 ± 0.I 0.573 ± 0.0.577 ± 0.0.565 0.| 0.868±0.0.542±0.0.636±0.0.6170.0.663±0.0.626 0.0.650±0.0.639 0.0.634±0.0.640±0.0.889 0.0.895±0.0.897±0.0.889± 0.0.885±0.0.891 ± 0.0.893 0.0.897 0.0.563 0.0.571 0.0.572 ± 0.0.559 0.| 0.563 0.| 0.571 ± 0.0.568 0.0.647 0.0.612 0.0.662 ± 0.0.629 0.0.626 0.0.626 ± 0.0.899±0.0.892 ± 0.0.885 ± 0.0.897 ± 0.0.582 ± 0.0.570 ± 0.0.569 0.0.563 ± 0.0.577 ± 0.테스트 추천 항목(섹션 3.2에서 설명한 대로)을 사용하여 각 평가자의 풀이 해당 평가자에게 개인화된다는 점을 상기합니다. 언어 기반 결과는 평가자가 좋아하거나 싫어하는 항목 선택 또는 최종 설명보다 훨씬 빠르게 생성한 초기 자연어 설명만 사용하지만 최종 설명과 동일한 성과를 보입니다. 우리는 일반적인 관찰로 시작합니다. 첫째, 각 항목 하위 집합 내의 NDCG@10 점수 범위가 일반적으로 더 큰 평가 집합 크기에 따라 증가하는 NDCG 정규화기와 각 풀의 평균 평가 모두로 인해 상당히 다르다는 점에 유의합니다. 후자의 경우, 이전에 표 2의 Seen 추천 하위 집합이 가장 작은 항목 풀과 높은 긍정적 평가 편향을 가지고 있어 이 하위 집합에서 추천자를 차별화하기 어렵다는 것을 관찰했습니다. 그러나 [35]에서 최근에 주장했듯이 항목이 일반적으로 한 번만 소비되는 추천 설정(예: 영화)에서는 Seen 하위 집합보다 Unseen 하위 집합의 추천 성과에 훨씬 더 관심을 갖습니다. 마찬가지로, 이 하위 집합은 광범위한 인기를 탐구하고 항목 기반 협업 필터링(CF) 방법에 편향되지 않기 때문에 Unbiased 집합의 성과에도 관심을 갖습니다. 섹션 1의 원래 연구 질문에 답하기 위해: RQ1: 언어 기반 선호도가 항목 기반 선호도를 대체하거나 개선할 수 있습니까? 초기 긍정적 답변은 LLM 언어 Few-shot(3) 방법이 이 근접 콜드 스타트 설정에서 대부분의 기존 항목 기반 CF 방법과 경쟁력이 있다는 것을 관찰한 데서 나옵니다.이것은 섹션 5.1에서 관찰한 바와 같이 언어 기반 선호도가 항목 기반 선호도보다 이끌어내는 데 시간이 덜 걸렸기 때문에 중요합니다.또한 언어 기반 선호도는 LLM이 경쟁력 있는 근접 콜드 스타트 추천자 RecSys &#39;23, 2023년 9월 18-22일, 싱가포르, 싱가포르 투명하고 검토 가능합니다[37].그러나 항목+언어 LLM 방법이 성능을 향상시키는 것으로 보이지 않기 때문에 언어 및 항목 기반 선호도를 결합하는 데 이점이 거의 없는 것 같습니다.RQ2: LLM 기반 방법 대 CF?RQ1은 LLM 기반 방법이 일반적으로 LLM의 언어 변형에 대해 항목 기반 CF 방법과 경쟁력이 있다는 것을 이미 확립했습니다. 그러나 많은 경우 LLM 기반 방법은 항목 기반 선호도(즉, 선호하는 영화의 이름)만 있는 CF 방법보다 비교적 우수한 성능을 보일 수 있다는 점도 유의해야 합니다. 여기서 중요하고 놀라운 결과는 사전 학습된 LLM이 CF 방법을 학습하는 데 사용된 방대한 양의 감독 데이터 없이도 경쟁력 있는 추천자가 된다는 것입니다. RQ3: 최상의 프롬프팅 방법론? Few-shot(3) 프롬프팅 방법은 일반적으로 Zero-shot 및 Completion 프롬프팅 방법보다 성능이 뛰어납니다. Zero-shot과 Completion 프롬프팅의 차이는 덜 두드러집니다. 공간 제약으로 인해 표시하지 않았지만 Few-shot 예제 수를 늘려도 성능이 향상되지 않았습니다. RQ4: 선호도 포함이 도움이 됩니까? 표 3의 아래 세 행에서 LLM 기반 추천자에 대한 부정적 항목 또는 언어 선호도를 포함하는 영향을 보여줍니다. 이러한 LLM 구성에서 긍정적 선호도만 포함하는 것보다 긍정적 및 부정적 선호도(Pos+Neg)를 모두 포함하는 것이 의미 있는 개선 사항은 없습니다. 공간 제약으로 인해 표시되지는 않았지만, 긍정적 선호도를 생략하고 부정적 선호도만 사용하면 인기 기준선에서 또는 그 이하의 성과를 낼 수 있습니다. 6 윤리적 고려 사항 잠재적인 윤리적 고려 사항을 간략히 살펴보겠습니다. 첫째, 추천 항목의 편향을 고려하는 것이 중요합니다. 예를 들어, 언어 기반 추천자가 고전적 추천자보다 의도치 않은 편향을 더 많이 보이는지 또는 덜 보이는지 측정하는 방법을 연구하는 것이 가치가 있을 것입니다. 예를 들어, 특정 클래스의 항목을 다른 항목보다 선호하는 경우가 있습니다. 저희의 과제는 고정된 항목 집합을 순위를 매기는 것으로 구성되었습니다. 따라서 모든 항목이 모델에 의해 고려되고 점수가 매겨졌습니다. 강한 편향이 있었다면 전반적인 성과 수치가 떨어졌을 것이지만, 실험 규모를 감안할 때 편향의 존재를 배제할 수는 없습니다. 존재하는 모든 가능한 편향을 제한하려면 더 큰 규모의 연구가 필요할 것입니다. 또한 저희의 결론은 비교적 작은 153명의 평가자 풀의 선호도에 기반합니다. 규모가 작고 영어로만 선호도가 제한되어 있기 때문에 다른 언어나 문화에서도 동일한 결과를 얻을 수 있는지 평가할 수 없습니다. 마지막으로 선호도 데이터는 유료 계약자가 제공했다는 점에 유의하십시오. 그들은 고용 국가의 생계임금보다 높은 표준 계약 임금을 받았습니다.결론 이 논문에서 우리는 평가자의 항목 기반 및 언어 기반 선호도와 독립적인 항목 추천 세트에 대한 평가를 모두 포함하는 데이터 세트를 수집했습니다.대규모 언어 모델(LLM)에서 다양한 프롬핑 전략을 활용하여 이 데이터 세트를 통해 순수 항목 또는 언어 기반 선호도와 이들의 조합에서 추천의 효능을 공정하고 정량적으로 비교할 수 있었습니다.실험 결과에서 LLM의 제로샷 및 퓨어샷 전략은 콜드 스타트 사례에서 순수 언어 기반 선호도(항목 선호도 없음)에 대한 추천 성능에서 항목 기반 협업 필터링 방법과 비교할 때 놀라울 정도로 경쟁력이 있음을 발견했습니다.특히 LLM은 범용임에도 불구하고 항목 기반 또는 언어 기반 선호도를 활용할 때 완전 감독 항목 기반 CF 방법과 경쟁력 있는 성능을 보입니다. 마지막으로, 이 LLM 기반 추천 접근 방식이 RecSys &#39;23, 2023년 9월 18-22일, 싱가포르, 싱가포르 Scott Sanner, Krisztian Balog, Filip Radlinski, Ben Wedin, Lucas Dixon 설명 가능하고 분석 가능한 언어 기반 선호도 표현을 기반으로 경쟁력 있는 근접 콜드 스타트 추천 시스템을 제공하여 언어 기반 선호도를 사용하는 효과적이고 새로운 LLM 기반 추천에 대한 진전을 제공한다는 것을 관찰했습니다. 참고문헌 [1] Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, Charles Sutton. 2021. 대규모 언어 모델을 사용한 프로그램 합성. arXiv:2108.07732 [cs.PL] [2] Krisztian Balog, Filip Radlinski, Shushan Arakelyan. 2019. 개인화된 추천을 위한 투명하고, 분석 가능하며, 설명 가능한 사용자 모델. 정보 검색 연구 및 개발에 관한 제42회 국제 ACM SIGIR 컨퍼런스(SIGIR &#39;19)의 회의록에서. 265–274. [3] Krisztian Balog, Filip Radlinski, Alexandros Karatzoglou. 2021. 추천을 위한 소프트 속성의 해석 및 측정. 정보 검색 연구 및 개발에 관한 제44회 국제 ACM SIGIR 컨퍼런스(SIGIR &#39;21)의 회의록에서. 890–899. [4] Toine Bogers and Marijn Koolen. 2017. 내러티브 기반 추천 정의 및 지원. 추천 시스템(RecSys &#39;17)에 관한 제11회 ACM 컨퍼런스의 회의록에서. 238–242. [5] Vadim Borisov, Kathrin Seßler, Tobias Leemann, Martin Pawelczyk 및 Gjergji Kasneci. 2023. 언어 모델은 현실적인 표형 데이터 생성기입니다. arXiv:2210.06280 [cs.LG] [6] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei. 2020. 언어 모델은 몇 번의 학습이 필요합니다. arXiv:2005.14165 [cs.CL] [7] Arun Tejasvi Chaganty, Megan Leszczynski, Shu Zhang, Ravi Ganti, Krisztian Balog, Filip Radlinski. 2023. 단일 항목을 넘어서: 대화형 재생 목록 큐레이션 데이터 세트를 사용하여 항목 세트에서 사용자 기본 설정 탐색. 정보 검색 연구 및 개발에 관한 ACM SIGIR 컨퍼런스(SIGIR &#39;23)의 회의록에 실림. 2754-2764. [8] Huiyuan Chen, Yusan Lin, Menghai Pan, Lan Wang, Chin-Chia Michael Yeh, Xiaoting Li, Yan Zheng, Fei Wang, Hao Yang. 2022. 자체 주의 순차 추천의 노이즈 제거. 추천 시스템(RecSys &#39;22)에 관한 제16회 ACM 컨퍼런스의 회의록에 실림. 92-101. [9] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, 정형원, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, 현택 임, 바렛 조프, 알렉산더 Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason 웨이, 캐시 마이어-헬스턴, 더글러스 에크, 제프 딘, 슬라브 페트로프, 노아 피델. 2022. PaLM: 경로를 통한 언어 모델링 확장. arXiv:2204.02311 [cs.CL] [10] Konstantina Christakopoulou, Filip Radlinski 및 Katja Hofmann. 2016. 대화형 추천 시스템을 향하여. ACM SIGKDD 국제 지식 발견 및 데이터 마이닝 컨퍼런스(KDD &#39;16)의 회의록에서. 815-824. [11] Maurizio Ferrari Dacrema, Paolo Cremonesi, Dietmar Jannach. 2019. 우리는 정말 많은 진전을 이루고 있는가?최근 신경 추천 접근법에 대한 걱정스러운 분석.제13회 ACM 추천 시스템 컨퍼런스(RecSys &#39;19)의 회의록에서. 101-109. [12] Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. 2019. BERT: 언어 이해를 위한 딥 양방향 변환기의 사전 학습.2019년 북미 계산 언어학 협회: 인간 언어 기술, 제1권(긴 논문 및 짧은 논문)(NAACL &#39;19)의 회의록에서. 4171-4186. [13] Luke Friedman, Sameer Ahuja, David Allen, Zhenning Tan, Hakim Sidahmed, Changbo Long, Jun Xie, Gabriel Schubiner, Ajay Patel, Harsh Lara, Brian Chu, Zexi Chen, Manoj Tiwari. 2023. 대화형 추천 시스템에서 대규모 언어 모델 활용. arXiv:2305.07961 [cs.IR] [14] Zeno Gantner, Steffen Rendle, Christoph Freudenthaler, Lars Schmidt-Thieme. 2011. MyMediaLite: 무료 추천 시스템 라이브러리. 제5회 ACM 추천 시스템 컨퍼런스(RecSys &#39;11) 회의록. 305–308. [15] Chongming Gao, Wenqiang Lei, Xiangnan He, Maarten de Rijke, Tat-Seng Chua. 2021. 대화형 추천 시스템의 발전과 과제: 조사. AI Open 2(2021), 100-126. [16] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, Yongfeng Zhang. 2022. 언어 처리(RLP)로서의 추천: 통합 사전 학습, 개인화된 프롬프트 및 예측 패러다임(P5). 제16회 ACM 추천 시스템 컨퍼런스(RecSys &#39;22) 회의록. 299-315. [17] Deepesh V Hada 및 Shirish K Shevade. 2021. ReXPlug: 플러그 앤 플레이 언어 모델을 사용한 설명 가능한 추천. 정보 검색 연구 및 개발에 관한 제44회 국제 ACM SIGIR 컨퍼런스(SIGIR &#39;21)의 회의록에서. 81-91. [18] F. Maxwell Harper 및 Joseph A. Konstan. 2015. MovieLens 데이터 세트: 역사 및 맥락. ACM 대화형 지능형 시스템 거래 5, 4, 기사 19(2015). [19] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu 및 Tat-Seng Chua. 2017. 신경 협력 필터링. 제26회 월드 와이드 웹 국제 컨퍼런스(WWW &#39;17)의 회의록에서. 173–182.LLM은 콜드 스타트 추천기 근처에서 경쟁력이 있습니다.RecSys &#39;23, 2023년 9월 18-22일, 싱가포르, 싱가포르 [20] Yupeng Hou, Shanlei Mu, Wayne Xin Zhao, Yaliang Li, Bolin Ding, Ji-Rong Wen. 2022. 추천 시스템을 위한 범용 시퀀스 표현 학습을 향하여. 지식 발견 및 데이터 마이닝(KDD &#39;22)에 관한 제28회 ACM SIGKDD 컨퍼런스의 회의록. 585–593. [21] Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian McAuley, Wayne Xin Zhao. 2023. 대규모 언어 모델은 추천 시스템을 위한 제로샷 랭커입니다. arXiv:2305.08845 [cs.IR] [22] Fangwei Hu 및 Yong Yu. 2013. Top-N 추천을 위한 인터뷰 프로세스 학습. ACM 추천 시스템 컨퍼런스(RecSys &#39;13)의 회의록에서. 331-334. [23] Yifan Hu, Yehuda Koren 및 Chris Volinsky. 2008. 암묵적 피드백 데이터 세트를 위한 협업 필터링. 2008년 제8회 IEEE 국제 데이터 마이닝 컨퍼런스(ICDM &#39;08)의 회의록에서. 263–272. [24] Dietmar Jannach, Ahtsham Manzoor, Wanling Cai 및 Li Chen. 2021. 대화형 추천 시스템에 대한 설문 조사. Comput. 설문 조사 54,(2021). [25] Marius Kaminskas 및 Derek Bridge. 2016. 다양성, 우연, 참신함 및 적용 범위: 추천 시스템에서 정확도를 넘어서는 목표에 대한 조사 및 실증적 분석. ACM Transactions on Interactive Intelligent Systems 7, 1(2016), 1–42. [26] Jie Kang, Kyle Condiff, Shuo Chang, Joseph A. Konstan, Loren Terveen 및 F. Maxwell Harper. 2017. 사람들이 자연어를 사용하여 추천을 요청하는 방법 이해. 제11회 ACM 추천 시스템 컨퍼런스(RecSys &#39;17) 회의록. 229–237. [27] Wang-Cheng Kang, Jianmo Ni, Nikhil Mehta, Maheswaran Sathiamoorthy, Lichan Hong, Ed Chi 및 Derek Zhiyuan Cheng. 2023. LLM이 사용자 선호도를 이해합니까? LLM의 사용자 평가 예측 평가.arXiv:2305.06474 [cs.IR] [28] Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, Tony Jebara. 2018. 협업 필터링을 위한 변분 자동 인코더.2018년 World Wide Web 컨퍼런스(WWW &#39;18) 회의록.689–698. [29] Pasquale Lops, Marco De Gemmis, Giovanni Semeraro.2011. 콘텐츠 기반 추천 시스템: 최신 기술 및 추세.추천 시스템 핸드북.Springer, 73-105. [30] Itzik Malkiel, Oren Barkan, Avi Caciularu, Noam Razin, Ori Katz, Noam Koenigstein. 2020. RecoBERT: 텍스트 기반 추천을 위한 카탈로그 언어 모델. arXiv:2009.13292 [cs.IR] [31] Sheshera Mysore, Mahmood Jasim, Andrew McCallum 및 Hamed Zamani. 2023. 제어 가능한 텍스트 추천을 위한 편집 가능한 사용자 프로필. arXiv:2304.04250 [cs.IR] [32] Sheshera Mysore, Andrew McCallum, Hamed Zamani. 2023. 대형 언어 모델 증강 내러티브 기반 권장 사항. arXiv:2306.02250 [cs.IR] [33] Zahra Nazari, Praveen Chandar, Ghazal Fazelnia, Catherine M. Edwards, Benjamin Carterette 및 Mounia Lalmas. 2022. 암묵적 신호의 선택이 중요합니다: 팟캐스트 추천에서 사용자 열망 고려. ACM 웹 컨퍼런스 2022(WWW &#39;22)의 회의록에서. 2433-2441. [34] Xia Ning 및 George Karypis. 2011. SLIM: 상위 N 추천 시스템을 위한 희소 선형 방법. 2011년 IEEE 11th 국제 데이터 마이닝 컨퍼런스(ICDM &#39;11)의 회의록에서. 497–506. [35] Roberto Pellegrini, Wenjie Zhao 및 Iain Murray. 2022. 당연한 것을 추천하지 마세요: 확률 비율 추정. ACM 추천 시스템 컨퍼런스(RecSys &#39;22)의 회의록에서. 188–197. [36] Gustavo Penha 및 Claudia Hauff. 2020. BERT는 책, 영화 및 음악에 대해 무엇을 알고 있습니까? 대화형 추천을 위한 BERT 탐색. 제14회 ACM 추천 시스템 컨퍼런스(RecSys &#39;20)에서. 388–397. [37] Filip Radlinski, Krisztian Balog, Fernando Diaz, Lucas Dixon 및 Ben Wedin. 2022. 투명하고 검토 가능한 추천을 위한 자연어 사용자 프로필. 정보 검색 연구 및 개발에 관한 제45회 국제 ACM SIGIR 컨퍼런스(SIGIR &#39;22)의 회의록에서. 2863-2874. [38] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner 및 Lars Schmidt-Thieme. 2009. BPR: 암묵적 피드백을 통한 베이지안 개인화 순위. 인공지능 불확실성에 관한 제25차 회의록(UAI &#39;09). 452-461. [39] Lior Rokach 및 Slava Kisilevich. 2012. 쌍별 비교를 사용한 추천 시스템에서의 초기 프로필 생성. IEEE 시스템, 인간 및 사이버네틱스 저널, C편(응용 및 리뷰) 42, 6(2012), 1854-1859. [40] Badrul Sarwar, George Karypis, Joseph Konstan 및 John Riedl. 2001. 항목 기반 협업 필터링 추천 알고리즘. 월드 와이드 웹에 관한 제10차 국제 회의록(WWW &#39;01). 285–295. [41] Anna Sepliarskaia, Julia Kiseleva, Filip Radlinski, Maarten de Rijke. 2018. 최적화 문제로서의 선호도 유발. ACM 추천 시스템 컨퍼런스(RecSys &#39;18)의 회의록. 172-180. [42] Harald Steck. 2019. 희소 데이터를 위한 당혹스러울 정도로 얕은 자동 인코더. World Wide Web 컨퍼런스(WWW &#39;19)에서. 3251-3257. [43] Bas Verplanken 및 Suzanne Faes. 1999. 좋은 의도, 나쁜 습관 및 건강한 식습관에 대한 구현 의도 형성의 영향. 유럽 사회 심리학 저널 29, 5-6(1999), 591-604. [44] Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai 및 Quoc V. Le. 2022. 미세 조정된 언어 모델은 제로샷 학습자입니다. arXiv:2109.01652 [cs.CL] [45] Yury Zemlyanskiy, Sudeep Gandhe, Ruining He, Bhargav Kanagal, Anirudh Ravula, Juraj Gottweis, Fei Sha 및 Ilya Eckstein. 2021. DOCENT: 대규모 문서 컬렉션에서 자체 감독 엔터티 표현 학습. 전산 언어학 협회 유럽 지부 제16차 회의 진행: 주요 볼륨(EACL &#39;21). 2540-2549.
