--- ABSTRACT ---
이전 연구에서는 ReLU와 같은 점별 활성화로 어텐션 소프트맥스를 대체할 때 정확도가 저하되는 것을 관찰했습니다. 비전 변환기의 맥락에서, 우리는 시퀀스 길이로 나누면 이러한 저하가 완화되는 것을 발견했습니다. ImageNet-21k에서 작은 것부터 큰 것까지의 비전 변환기를 훈련하는 실험에서 ReLU-어텐션은 컴퓨팅의 함수로서 스케일링 동작 측면에서 소프트맥스-어텐션의 성능에 근접하거나 일치할 수 있음을 나타냈습니다. 이 보고서에서는 반드시 확률 분포를 출력하지 않는 소프트맥스 연산에 대한 점별 대안을 살펴봅니다. 하이라이트로, 시퀀스 길이로 나눈 ReLU를 사용한 어텐션은 비전 변환기에 대한 컴퓨팅의 함수로서 스케일링 동작 측면에서 기존 소프트맥스 어텐션에 근접하거나 일치할 수 있음을 관찰했습니다. 이 결과는 병렬화에 대한 새로운 기회를 제공하는데, ReLU-어텐션은 기존 어텐션보다 수집 연산이 적은 시퀀스 길이 차원에서 병렬화될 수 있기 때문입니다.
--- INTRODUCTION ---
변압기 아키텍처[26]는 최신 머신 러닝에서 널리 사용됩니다. 변압기의 핵심 구성 요소인 주의[2]에는 토큰에 대한 확률 분포를 생성하는 소프트맥스가 포함됩니다. 소프트맥스는 지수 계산과 합 시퀀스 길이로 인해 비용이 많이 들기 때문에 병렬화가 어렵습니다[24, 7].
--- RELATED WORK ---
이전 연구에서는 softmax를 ReLU[25, 14] 또는 제곱 ReLU[15]로 대체하는 것을 살펴보았습니다. 그러나 이러한 접근 방식은 시퀀스 길이로 나누지 않는데, 이는 softmax와 비슷한 정확도에 도달하는 데 중요하다는 것을 실험적으로 발견했습니다. 또한 이전 연구[21]에서는 softmax를 대체하면서도 시퀀스 길이 축에 대한 정규화를 요구하여 0.softmax relu/seqlen 0.S/S/0.. B/× B/L/0.ImageNet-1k 정확도(%) 0.0.0.0.0.0.0.0.0.Avg. 8개 데이터 세트에 대한 10샷 선형 전송 0.0.0.TPU 코어 시간 10² TPU 코어 시간을 보장했습니다. 그림 1: softmax를 relu/seqlen으로 대체하면 qk-layernorm[8]을 사용하여 비전 변환기[10]에 대한 기존 어텐션의 스케일링 성능에 접근하거나 일치합니다. 이 그림은 ImageNet-21k [9]에서 30개 에포크 동안 학습된 소형에서 대형 비전 변환기에 대한 결과를 보여줍니다. 미세 조정 없이 ImageNet-1k에 있는 모델 중 최상위 클래스를 취하여 ImageNet-21k 모델에 대한 ImageNet-1k 정확도를 보고합니다. ReLU를 사용한 어텐션은 소프트맥스 어텐션보다 수집 작업이 적은 시퀀스 길이 차원에서 병렬화할 수 있습니다.ImageNet-1k 정확도(%) ImageNet-1k 정확도(%) 0.0.0.7500.0.0.0.0.학습 데이터 세트 i21k. 모델 S/32. 0.1.1.0.학습 데이터 세트 i21k. 모델 S/16. ImageNet-1k 정확도(%) 0.0.0.0.0.0.0.2.0. 역 seqlen을 확장하기 위한 지수 a 학습 데이터 세트 ilk. 모델 S/32. 0.0.7750.0.0.7000.0.0.0.1.1.0.1.0.0.1.0.0.학습 데이터 세트 i21k. 모델 S/8. ImageNet-1k 정확도(%) 0.0.0.0.0.2.0.역 seqlen을 확장하기 위한 지수 a 학습 데이터 세트 ilk. 모델 S/16. 0.1.1.2.역 seqlen을 확장하기 위한 지수 a 학습 데이터 세트 ilk. 모델 S/8. ImageNet-1k 정확도(%) 0.0.0.0.0.0.0.675€ 0.ImageNet-1k 정확도(%) 0.0.0.0.0.0.0.0.2.0.0.1.1.2.0.squared relu 지수 a는 역 seqlen gelu softplus identity를 확장하기 위한 것입니다. 0.1.1.2. 지수 a는 역 seqlen softmax relu를 확장하기 위한 것입니다. 지수 a는 역 seqlen relusigmoid를 확장하기 위한 것입니다. 그림 2: softmax를 L¯ah로 대체하기 여기서 h = {relu, relu², gelu, softplus, identity, relu6, sigmoid}이고 L은 시퀀스 길이입니다. 일반적으로 a가 1에 가까울 때 가장 좋은 결과를 관찰합니다. a ≈ 1에서 가장 좋은 비선형성은 명확하지 않으므로 주요 실험에서는 속도를 위해 ReLU를 사용합니다. 어텐션 가중치의 합은 1입니다. 이는 수집이 필요하다는 단점을 유지합니다. 이 노트의 초기 버전을 작성한 후, 우리가 연구하는 ReLU-어텐션의 변형도 이론적 동기로 탐구되었다는 사실이 우리의 주의를 끌었습니다[3, 12]. 게다가 활성화 함수를 완전히 제거하여 어텐션이 선형이 되도록 하는 광범위한 문헌이 있는데[16, 22, 18], 이는 긴 시퀀스 길이에 유용합니다. 우리의 실험에서 활성화를 완전히 제거하면 정확도가 감소했습니다.3
--- METHOD ---
주의. 주의는 2단계 절차를 통해 d차원 쿼리, 키 및 값 {qi, ki, vi}/11을 변환합니다. 먼저, 주의 가중치 a¿j는 αij =&gt;[q₁k1, KL ( Di (1) 1을 통해 생성됩니다. 구체적으로 선형 주의의 경우 행렬 곱셈의 순서를 (gk)v에서 q(kv)로 전환할 수 있으며, 이는 필요한 계산을 O(dL²)에서 O(d² L)로 변경합니다. 여기서 q, k, v € RL xd는 쿼리, 키 및 값이고 L은 시퀀스 길이입니다. 여기서 는 일반적으로 소프트맥스입니다. 다음으로, 주의 가중치는 출력 o; = -1 αijvj를 계산하는 데 사용됩니다. 이 보고서는 . ReLU-주의에 대한 점별 대안을 살펴봅니다. 우리는 = L-¹ relu가 방정식 1에서 소프트맥스에 대한 유망한 대안임을 관찰합니다. 우리는 o = Lrelu인 주의를 ReLUattention이라고 합니다. = 확장된 점별 주의. 보다 일반적으로, 우리의
--- EXPERIMENT ---
영어: ImageNet-21k에서 작은 것에서 큰 것까지의 비전 변환기를 훈련하는 s는 ReLU-어텐션이 컴퓨팅의 함수로서 스케일링 동작 측면에서 소프트맥스-어텐션의 성능에 접근하거나 맞먹을 수 있음을 나타냅니다. 이 보고서에서는 반드시 확률 분포를 출력하지 않는 소프트맥스 연산에 대한 점별 대안을 살펴봅니다. 하이라이트로, 시퀀스 길이로 나눈 ReLU를 사용한 어텐션이 비전 변환기에 대한 컴퓨팅의 함수로서 스케일링 동작 측면에서 기존 소프트맥스 어텐션에 접근하거나 맞먹을 수 있음을 관찰합니다. 이 결과는 ReLU-어텐션이 기존 어텐션보다 수집 연산이 적은 시퀀스 길이 차원에서 병렬화될 수 있으므로 병렬화에 대한 새로운 기회를 제공합니다. 서론 트랜스포머 아키텍처[26]는 최신 머신 러닝에서 널리 사용됩니다. 트랜스포머[2]의 핵심 구성 요소인 어텐션에는 토큰에 대한 확률 분포를 생성하는 소프트맥스가 포함됩니다. 소프트맥스는 지수 계산과 합 시퀀스 길이로 인해 비용이 많이 들기 때문에 병렬화가 어렵습니다[24, 7]. 영어: over관련 작업 이전 연구에서는 softmax를 ReLU[25, 14] 또는 제곱 ReLU[15]로 대체하는 것을 살펴보았습니다. 그러나 이러한 접근 방식은 시퀀스 길이로 나누지 않는데, 이는 softmax와 비슷한 정확도에 도달하는 데 중요하다는 것을 실험적으로 발견했습니다. 또한 이전 연구[21]에서는 시퀀스 길이 축에 대한 정규화가 필요하면서도 softmax를 대체하여 0.softmax relu/seqlen 0.S/S/0.. B/× B/L/0.ImageNet-1k 정확도(%) 0.0.0.0.0.0.0.0.0.Avg. 8개 데이터 세트에 대한 10샷 선형 전송 0.0.0.TPU 코어 시간 10² TPU 코어 시간을 보장합니다. 그림 1: softmax를 relu/seqlen으로 대체하면 qk-layernorm[8]을 사용하여 비전 변환기[10]에 대한 기존 어텐션의 스케일링 성능에 접근하거나 일치합니다. 이 그림은 ImageNet-21k [9]에서 30개 에포크 동안 학습된 소형에서 대형 비전 변환기에 대한 결과를 보여줍니다. 미세 조정 없이 ImageNet-1k에 있는 모델 중 최상위 클래스를 취하여 ImageNet-21k 모델에 대한 ImageNet-1k 정확도를 보고합니다. ReLU를 사용한 어텐션은 소프트맥스 어텐션보다 수집 작업이 적은 시퀀스 길이 차원에서 병렬화할 수 있습니다.ImageNet-1k 정확도(%) ImageNet-1k 정확도(%) 0.0.0.7500.0.0.0.0.학습 데이터 세트 i21k. 모델 S/32. 0.1.1.0.학습 데이터 세트 i21k. 모델 S/16. ImageNet-1k 정확도(%) 0.0.0.0.0.0.0.2.0. 역 seqlen을 확장하기 위한 지수 a 학습 데이터 세트 ilk. 모델 S/32. 0.0.7750.0.0.7000.0.0.0.1.1.0.1.0.0.1.0.0.학습 데이터 세트 i21k. 모델 S/8. ImageNet-1k 정확도(%) 0.0.0.0.0.2.0.역 seqlen을 확장하기 위한 지수 a 학습 데이터 세트 ilk. 모델 S/16. 0.1.1.2.역 seqlen을 확장하기 위한 지수 a 학습 데이터 세트 ilk. 모델 S/8. ImageNet-1k 정확도(%) 0.0.0.0.0.0.0.675€ 0.ImageNet-1k 정확도(%) 0.0.0.0.0.0.0.0.2.0.0.1.1.2.0.squared relu 지수 a는 역 seqlen gelu softplus identity를 확장하기 위한 것입니다. 0.1.1.2. 지수 a는 역 seqlen softmax relu를 확장하기 위한 것입니다. 지수 a는 역 seqlen relusigmoid를 확장하기 위한 것입니다. 그림 2: softmax를 L¯ah로 대체하기 여기서 h = {relu, relu², gelu, softplus, identity, relu6, sigmoid}이고 L은 시퀀스 길이입니다. 일반적으로 a가 1에 가까울 때 가장 좋은 결과를 관찰합니다. a ≈ 1에서 가장 좋은 비선형성은 명확하지 않으므로 주요 실험에서는 속도를 위해 ReLU를 사용합니다. 어텐션 가중치의 합은 1입니다. 이는 수집이 필요하다는 단점을 유지합니다. 이 노트의 초기 버전을 작성한 후, 우리가 연구하는 ReLU-어텐션의 변형도 이론적 동기로 탐구되었다는 사실이 우리의 주의를 끌었습니다[3, 12]. 게다가 활성화 함수를 완전히 제거하여 어텐션이 선형이 되도록 하는 광범위한 문헌이 있는데[16, 22, 18], 이는 긴 시퀀스 길이에 유용합니다. 우리의 실험에서 활성화를 완전히 제거하면 정확도가 떨어졌습니다.3 방법 어텐션. 어텐션은 2단계 절차를 통해 d차원 쿼리, 키 및 값 {qi, ki, vi}/11을 변환합니다. 먼저, 어텐션 가중치 a¿j는 αij =&gt;[q₁k1, KL ( Di (1) 1을 통해 생성됩니다. 구체적으로 선형 어텐션을 사용하면 행렬 곱셈의 순서를 (gk)v에서 q(kv)로 전환할 수 있으며, 이를 통해 필요한 계산이 O(dL²)에서 O(d² L)로 변경됩니다. 여기서 q, k, v € RL xd는 쿼리, 키, 값이고 L은 시퀀스 길이입니다. 여기서 는 일반적으로 소프트맥스입니다. 다음으로, 어텐션 가중치는 출력 o; = -1 αijvj를 계산하는 데 사용됩니다. 이 보고서는 . ReLU-어텐션에 대한 점별 대안을 살펴봅니다. 우리는 = L-¹ relu가 방정식 1에서 소프트맥스에 대한 유망한 대안임을 관찰했습니다. 우리는 o = Lrelu인 어텐션을 ReLUattention. = 스케일된 점별 어텐션이라고 합니다. 보다 일반적으로, 우리의 실험은 € [0,1] 및 h = {relu, relu², gelu, softplus, identity, relu6, sigmoid} [6, 13]. 시퀀스 길이 스케일링. 시퀀스 길이 L을 포함하는 항목으로 스케일링하는 것이 높은 정확도에 유익하다는 것을 관찰했습니다. 이 스케일링은 softmax를 제거하는 이전 작업에는 없습니다 [15, 18]. 시퀀스 길이 스케일링에 대한 중심적인 정당성은 경험적이지만 간략한 분석적 동기를 제공합니다. 변환기는 현재 Σ=1αij 1인 softmax 어텐션으로 설계되었습니다. 이는 Ej[αij] = L-¹임을 의미합니다. 이것이 필요 조건일 가능성은 낮지만 = L-1 relu는 Ej[αij]가 초기화 시 O(L-¹)임을 보장합니다. 이 조건을 유지하면 다른 hy=ImageNet-1k 정확도(%) 0.0.0.0.0.0.0.0.0.Training 데이터 세트 i21k를 변경할 필요성이 완화될 수 있습니다. 모델 S/32. 역 seqlen relu 0.Training 데이터 세트 i21k를 스케일링하기 위한 0.1.1. 지수 a. 모델 S/16. 0.0.ImageNet-1k 정확도(%) 0.0.0.0.0.74학습 데이터 세트 i21k. 모델 S/8. 0.72ImageNet-1k 정확도(%) 0.0.0.0.0.2.0.0.1.1.2.0.0.1.1.2.squared relu qk-layernorm 없이 역 seqlen relu를 확장하기 위한 지수 a qk-layernorm 없이 역 seqlen -squared relu를 확장하기 위한 지수 a 그림 3: ReLU와 L이 시퀀스 길이인 La로 확장된 제곱 ReLU를 사용한 주의에 대한 qk-layernorm[8] 제거 효과. ImageNet-21k에서 학습된 S/32, S/16 및 S/8 비전 변환기 모델[10, 4]에 대한 결과가 나와 있습니다. 학습 데이터 세트 i21k. 모델 S/32. 학습 데이터 세트 i21k. 모델 S/16. 0.0.0.ImageNet-1k 정확도(%) 0.0.0.0.0.0.1.1.Exponent a는 역 seqlen relu를 확장하기 위한 것입니다.0.0.72ImageNet-1k 정확도(%) 0.0.0.0.Training dataset i21k.Model S/8.0.0.740.0.700.68ImageNet-1k 정확도(%) 0.0.0.2.0.0.1.1.2.0.0.1.1.2.squared relu 게이팅을 사용한 역 seqlen relu를 확장하기 위한 Exponent a 게이팅을 사용한 역 seqlen squared relu를 확장하기 위한 Exponent a 그림 4: ReLU와 L로 확장된 제곱 ReLU를 사용한 어텐션에 대한 게이트 어텐션 유닛[15] 사용 효과 여기서 L은 시퀀스 길이입니다. ImageNet-21k에서 학습한 S/32, S/16 및 S/8 비전 변환기 모델[10, 4]에 대한 결과가 나와 있습니다. softmax를 대체할 때의 매개변수입니다. √d 초기화 시 q와 k의 요소는 O(1)이므로 (k)도 O(1)이 됩니다. ReLU와 같은 활성화 함수는 O(1)을 유지하므로 Ej[αij]가 O(L-¹)이 되려면 요소 L-1이 필요합니다. 4 실험 ImageNet-21k에서 30에포크 동안 학습하고, 우리의 실험에서 결과적으로 두 학습 실행 모두 ImageNet-1k에서 300에포크 동안 학습합니다. 약 9e5의 단계 수입니다. 모델 크기를 조정할 때 불안정성을 방지하기 위해 필요한 것으로 이전에 관찰되었기 때문에 qk-layernorm[8]이 있는 ViT를 사용합니다. 그러나 이것이 우리가 테스트하는 규모에서 중요한 구성 요소가 아니라는 것을 알 수 있습니다. 우리는 i21k와 ilk를 각각 ImageNet-21k와 ImageNet-1k로 의미하고, 미세 조정 없이 ImageNet-1k에 있는 것들 중 최상위 클래스를 취하여 ImageNet-21k 모델에 대한 ImageNet-1k 정확도를 보고합니다. 다운스트림 작업에서 전송 성능을 평가할 때 big_vision/configs/vit_ilk.py를 사용합니다. ImageNet21k의 경우 3을 사용합니다. ImageNet1k의 경우 기본 구성 https: 기본 구성 https://github.com/google-research/big_ //github.com/google-research/big_vision/blob/main/을 사용합니다. 실험 설정. 우리의 실험은 하이퍼파라미터를 수정하지 않고 BigVision 코드베이스 [4]의 ImageNet-21k 및 ImageNet-1k [9] 교육 구성을 사용합니다. 2 제곱 ReLU를 제외하고. vision/blob/main/big_vision/configs/vit_i21k.py.use는 3개 시드에 대해 평균화된 10샷 선형 프로브입니다. 우리는 탐구하지 않습니다. 다운스트림 작업은 Caltech Birds[27], Caltech101[11], Stanford Cars[19], CIFAR-100[20], DTD[5], 감사의 말 ColHsit[17], Pets[23], UC Merced[28]입니다. 주요 실험. 그림 1은 ReLUattention이 ImageNet-21k 학습을 위한 softmax attention의 스케일링 추세와 일치함을 보여줍니다. x축에는 실험에 필요한 총 코어 시간을 표시합니다. 이점으로 ReLU-attention은 softmax attention보다 수집 작업이 적은 시퀀스 길이 차원에서 병렬화를 가능하게 합니다. 시퀀스 길이 스케일링의 효과. 그림 2는 softmax에 대한 다양한 지점별 대안에 대한 시퀀스 길이 스케일링의 효과를 살펴봅니다. 구체적으로, 우리는 € [0,1] 및 h = {relu, relu², gelu, softplus, identity}에 대해 softmax를 L-ah로 대체합니다. x축에는 a를 표시합니다. y축은 S/32, S/16 및 S/8 비전 변환기 모델에 대한 정확도를 표시합니다[10, 4]. 일반적으로 a가 1에 가까울 때 최상의 결과를 얻습니다. 최상의 비선형성이 명확하지 않기 때문에 주요 실험에서는 더 빠른 ReLU를 사용합니다. qk-layernorm의 효과. 주요 실험에서는 qk-layernorm[8]을 사용하는데, 여기서 쿼리와 키는 어텐션 가중치를 계산하기 전에 Layer Norm[1]을 거칩니다. 모델 크기를 확장할 때 불안정성을 방지하는 데 필요한 것으로 밝혀졌으므로 qk-layernorm을 기본적으로 사용합니다[8]. 그림 3은 qk-layernorm을 제거한 효과를 보여줍니다. 결과에 따르면 qk-layernorm은 이러한 모델에 큰 영향을 미치지 않지만 규모에 따라 달라질 수 있습니다. 게이트를 추가한 효과. 이전 작업에서 소프트맥스를 제거하면 게이트된 유닛이 추가되고 시퀀스 길이에 따라 스케일링되지 않습니다[15]. 구체적으로, 게이트된 어텐션 유닛[15]에서 추가 투영은 출력이 생성되고 출력은 아웃 투영 전에 요소별 곱셈을 통해 결합됩니다. 그림 4에서 게이트가 있으면 시퀀스 길이 스케일링이 필요 없어지는지 조사합니다. 전반적으로 게이트가 있든 없든 시퀀스 길이 스케일링으로 최상의 정확도가 달성됩니다. 게이팅은 ReLU가 있는 S/8 모델의 실험에 필요한 핵심 시간을 약 9.3% 증가시킵니다.
--- CONCLUSION ---
이 보고서는 많은 미해결 문제를 남겼습니다. 특히, 요인 L-1이 성능을 개선하는 이유나 이 용어를 학습할 수 있는지 여부는 확실하지 않습니다. 게다가 더 나은 활성화 함수가 있을 가능성이 높습니다. 도움이 되는 의견과 제안을 해주신 Lucas Beyer, Mostafa Dehghani, David Fleet에게 감사드립니다. 우리는 이 노력을 지원해준 Google DeepMind PAGI팀 멤버인 Jascha Sohldickstein, Noah Fiedel, Aaron Parisi, Abhishek Kumar, Alex Alemi, Alex Rizkowsky, Avi Singh, Azade Nova, Ben Adlam, Bernd Bohnet, Daniel Freeman, Gamaleldin Elsayed, Gaurav Mishra, Hanie Sedghi, Isabelle Simpson, Izzeddin Gur, JD Co-Reyes, James Harrison, Jeffrey Pennington, Jiri Hron, Kathleen Kenealy, Kelvin Xu, Kevin Swersky, Kshiteej Mahajan, Laura Culp, Lechao Xiao, Max Bileschi, Merrie Morris, Roman Novak, Rosanne Liu, Sharad Vikram, Tris Warkentin, Yundi Qian에게 감사드립니다. 참고문헌 [1] Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E Hinton. 계층 정규화. arXiv 사전 인쇄본 arXiv:1607.06450, 2016. [2] Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio. 정렬 및 변환을 공동으로 학습하여 신경망 기계 번역. arXiv 사전 인쇄본 arXiv:1409.0473, 2014. [3] Yu Bai, Fan Chen, Huan Wang, Caiming Xiong, Song Mei. 통계학자로서의 변환기: 컨텍스트 내 알고리즘 선택을 통한 증명 가능한 컨텍스트 내 학습. arXiv 사전 인쇄본 arXiv:2306.04637, 2023. [4] Lucas Beyer, Xiaohua Zhai, Alexander Kolesnikov. imagenet1k를 위한 더 나은 일반 vit 기준선. arXiv 사전 인쇄본 arXiv:2205.01580, 2022. URL https://arxiv.org/abs/2205.01580. [5] Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, Andrea Vedaldi. 야생에서의 텍스처 설명. 컴퓨터 비전 및 패턴 인식 컨퍼런스(CVPR), 2014. https://arxiv.org/abs/1311.3618. [6] George E Dahl, Tara N Sainath, Geoffrey E Hinton. 정류 선형 유닛과 드롭아웃을 사용하여 lvcsr에 대한 딥 신경망 개선. IEEE 음향, 음성 및 신호 처리 국제 컨퍼런스, 8609-8613페이지. IEEE, 2013. [7] Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, Christopher Ré. Flashattention: io-awareness를 갖춘 빠르고 메모리 효율적인 정확한 어텐션. Advancesin Neural Information Processing Systems, 35:16344– 16359, 2022. [8] Mostafa Dehghani, Josip Djolonga, Basil Mustafa, Piotr Padlewski, Jonathan Heek, Justin Gilmer, Andreas Steiner, Mathilde Caron, Robert Geirhos, Ibrahim Alabdulmohsin, et al. 비전 변환기를 220억 매개변수로 확장. arXiv 사전 인쇄본 arXiv:2302.05442, 2023. [17] 기계 학습, 기계 학습 연구 논문집 119권, 5156-5165페이지. PMLR, 2020년 7월 13일 18일. URL https://proceedings.mlr.press/v119/katharopoulos 20a.html. Jakob Nikolas Kather, Frank Gerrit Zöllner, Francesco Bianconi, Susanne M Melchers, Lothar R Schad, Timo Gaiser, Alexander Marx, Cleo-Aron Weis. 대장암 조직학의 텍스처 수집. Zenodo https://doi. org/10, 5281, 2016. [9] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, [18] Soroush Abbasi Koohpayegani 및 Hamed Pirsiavash. 및 Li Fei-Fei. Imagenet: 대규모 계층적 이미지 데이터베이스. 컴퓨터 비전 및 패턴 인식 컨퍼런스, 2009. https://ieeexplore. ieee.org/document/5206848. [10] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby. 이미지는 16x단어의 가치가 있습니다: 대규모 이미지 인식을 위한 변환기. 국제 학습 표현 컨퍼런스(ICLR), 2021. https://arxiv.org/abs/2010. 11929. [11] Li Fei-Fei, Rob Fergus, Pietro Perona. 몇 가지 학습 예제에서 생성적 시각 모델 학습: 객체 범주에서 테스트된 증분 베이지안 접근 방식. 2004년 컴퓨터 비전 및 패턴 인식 워크숍 컨퍼런스, 178-178페이지. IEEE, 2004. [12] Hengyu Fu, Tianyu Guo, Yu Bai, Song Mei. 단일 어텐션 레이어는 무엇을 배울 수 있을까? 랜덤 피처 렌즈를 통한 연구. arXiv 사전 인쇄본 arXiv:2307.11353, 2023. [13] Dan Hendrycks 및 Kevin Gimpel. 가우시안 오차 선형 단위(gelus). arXiv 사전 인쇄본 arXiv:1606.08415, 2016. [14] Jiri Hron, Yasaman Bahri, Jascha Sohl-Dickstein 및 Roman Novak. 무한 어텐션: 딥 어텐션 네트워크를 위한 Nngp 및 ntk. 국제 학술 대회 Sima: 비전 변환기를 위한 간단한 소프트맥스 없는 어텐션. arXiv 사전 인쇄본 arXiv:2206.08898, 2022. [19] Jonathan Krause, Michael Stark, Jia Deng 및 Li FeiFei. 세밀한 분류를 위한 3D 객체 표현. 2013년 컴퓨터 비전 국제 컨퍼런스(ICCV) 워크숍에서. https://ieeexplore.ieee.org/document/6755945. Learn[20] Alex Krizhevsky, Geoffrey Hinton, et al. 작은 이미지에서 여러 계층의 특징 추출, 2009. https://www.cs.toronto.edu/~kriz/ [21] [22] [23] learning-features-2009-TR.pdf. Zhiyuan Li, Srinadh Bhojanapalli, Manzil Zaheer, Sashank Reddi, Sanjiv Kumar. 규모 불변 아키텍처를 사용한 신경망의 강력한 학습. 기계 학습 국제 컨퍼런스에서, 12656-12684페이지. PMLR, 2022. Jiachen Lu, Jinghan Yao, Junge Zhang, Xiatian Zhu, Hang Xu, Weiguo Gao, Chunjing Xu, Tao Xiang, and Li Zhang. Soft: 선형 복잡도를 가진 Softmax 없는 변환기. 신경 정보 처리 시스템의 발전, 34:21297-21309, 2021. Omkar M Parkhi, Andrea Vedaldi, Andrew Zisserman, and CV Jawahar. 고양이와 개. 2012년 IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스, 3498-3505페이지. IEEE, 2012. [24] Markus N Rabe and Charles Staats. 셀프 어텐션은 o(n²) 메모리가 필요하지 않습니다. arXiv 사전 인쇄본 arXiv:2112.05682, 2021. 머신 러닝에 관하여, 4376-4386페이지. PMLR, 2020. [25] Kai Shen, Junliang Guo, Xu Tan, Siliang Tang, Rui [15] Weizhe Hua, Zihang Dai, Hanxiao Liu, Quoc Le. 선형 시간의 변압기 품질. 기계 학습 국제 컨퍼런스, 9099-9117페이지. PMLR, 2022. [16] Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, François Fleuret. 변압기는 RNN입니다: 선형 주의가 있는 빠른 자기 회귀 변압기. Hal Daumé III 및 Aarti Singh 편집자, 제37회 국제 컨퍼런스 회의록 [26] Wang, Jiang Bian. 변압기의 relu 및 softmax에 대한 연구. arXiv 사전 인쇄본 arXiv:2302.06461, 2023. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin. 주의만 있으면 됩니다. 신경 정보 처리 시스템의 발전, 30, 2017. [27] Peter Welinder, Steve Branson, Takeshi Mita, Catherine Wah, Florian Schroff, Serge Belongie, Pietro Perona. Caltech-ucsd birds 200. 2010.[28] Yi Yang 및 Shawn Newsam. 토지 이용 분류를 위한 시각적 단어 가방 및 공간 확장. 지리 정보 시스템의 발전에 관한 제18회 SIGSPATIAL 국제 컨퍼런스 회의록, 270-279쪽, 2010.
