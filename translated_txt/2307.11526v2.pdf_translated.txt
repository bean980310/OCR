--- ABSTRACT ---
Neural Radiance Fields(NeRF)는 미디어의 주요 표현이 될 잠재력이 있습니다. NeRF를 훈련하는 것은 결코 쉬운 일이 아니기 때문에, NeRF 모델의 저작권 보호가 우선순위가 되어야 합니다. 이 논문에서는 가능한 저작권 보호 솔루션의 장단점을 분석하여 NeRF의 원래 색상 표현을 워터마크가 있는 색상 표현으로 대체하여 NeRF 모델의 저작권을 보호할 것을 제안합니다. 그런 다음, 왜곡 방지 렌더링 방식을 설계하여 NeRF의 2D 렌더링에서 강력한 메시지 추출을 보장합니다. 제안하는 방법은 옵션 솔루션과 비교했을 때 높은 렌더링 품질과 비트 정확도를 유지하면서 NeRF 모델의 저작권을 직접 보호할 수 있습니다. 프로젝트 페이지: https://luo-ziyuan.github.io/copyrnerf. 1.
--- INTRODUCTION ---
Neural Radiance Fields(NeRF) [23]가 디지털 미디어 표현의 주류가 될 수 있는 잠재력을 가지고 있지만 NeRF 모델을 학습하는 것은 결코 쉬운 일이 아니었습니다.악의적인 사용자가 NeRF 모델을 도용한 경우 해당 지적 재산을 어떻게 식별할 수 있습니까?모든 디지털 자산(예: 3D 모델, 비디오 또는 이미지)과 마찬가지로 저작권은 자산에 저작권 메시지를 임베드하여 보호할 수 있으며, 이를 디지털 워터마킹이라고 하며 NeRF 모델도 예외는 아닙니다.직관적인 솔루션은 기성형 워터마킹 방식(예: HiDDEN [50] 및 MBRS [14])을 사용하여 렌더링된 샘플에 직접 워터마크를 표시하는 것입니다.그러나 이것은 렌더링된 샘플의 저작권만 보호하고 핵심 모델은 보호되지 않습니다.핵심 모델이 도용된 경우 악의적인 사용자가 새로운 샘플을 렌더링할 수 있습니다.*연락처.이 작업은 홍콩 침례교 대학교 컴퓨터 과학부의 Renjie 연구 그룹에서 수행되었습니다. 비밀 메시지 00100110... 새로운 뷰 추출된 메시지 00100110... 다양한 설정에 따른 재구성 품질 실제 PSNR/비트 정확도. 우리의 CopyRNERF 32.69/100% 00100110... 00100110... HIDDEN + NERF 메시지가 있는 NERF 27.71/51% 22.83/69% 그림 1: NeRF 모델이 악의적인 사용자에 의해 도난당했을 때(D), CopyRNERF는 모델에 포함된 저작권 메시지를 렌더링 샘플로 전송하여 모델 소유권을 주장하는 데 도움이 될 수 있습니다(②). HIDDEN [50] + NeRF [23] 및 메시지가 있는 NeRF [23]과 몇 가지 비교를 보여줍니다. 각 예 아래에 PSNR/비트 정확도가 나와 있습니다. 다른 렌더링 전략을 사용하여 모델 작성자가 기대하는 외부 워터마킹을 위한 여지를 남기지 않습니다. 게다가 워터마킹 시 렌더링에 필요한 요소를 고려하지 않고 렌더링된 샘플에 직접 워터마킹을 하면 기하 값이 낮은 영역에 쉽게 감지할 수 있는 흔적이 남을 수 있습니다.저작권 메시지는 일반적으로 명시적 3D 모델의 경우 3D 구조(예: 메시)에 포함됩니다[43].이러한 구조는 모두 NeRF의 다층 퍼셉트론(MLP) 가중치에 암묵적으로 인코딩되므로 저작권 보호는 모델 가중치를 워터마킹하여 수행해야 합니다.NeRF로 인코딩된 정보는 보호된 모델의 2D 렌더링을 통해서만 액세스할 수 있으므로 렌더링된 샘플에서 워터마크를 추출하는 동안 두 가지 일반적인 표준을 고려해야 합니다[1, 15, 41, 45].1) 포함된 메시지로 인해 심각한 시각적 왜곡이 발생하지 않아야 하는 비가시성, 2) 다양한 왜곡이 발생하더라도 견고한 메시지 추출을 보장하는 견고성.한 가지 옵션은 워터마크가 있는 이미지를 사용하여 NeRF 모델을 만드는 반면, 2D 이미지의 인기 있는 보이지 않는 워터마크는 NeRF 모델로 효과적으로 전송할 수 없습니다. 그림 1에 설명된 대로(HiDDEN [50] + NeRF [23]), 렌더링된 결과의 품질이 높더라도 비밀 메시지를 견고하게 추출할 수 없습니다. 또한 비밀 메시지를 입력 좌표와 직접 연결하여 더 높은 비트 정확도를 생성할 수 있습니다(그림 1의 NeRF와 메시지). 그러나 렌더링된 샘플의 PSNR 값이 낮으면 눈에 띄는 시각적 왜곡이 있음을 나타내며, 이는 비가시성 표준을 위반합니다. 비가시성은 워터마킹 시스템에 중요하지만 견고성에 대한 요구가 더 높기 때문에 워터마킹은 고유합니다[50]. 따라서 비가시성 외에도 NeRF 모델을 보다 견고하게 보호하는 데 중점을 둡니다. 위의 설정에서와 같이 전체 모델에 메시지를 임베드하는 것과 달리 그림 2에 표시된 것처럼 모델의 하위 집합을 기반으로 렌더링하기 위한 워터마크 색상 표현을 만듭니다. 이 방법은 기본 표현을 변경하지 않음으로써 보이지 않는 워터마크가 있는 렌더링 샘플을 생성할 수 있습니다. 워터마크 색상 표현에 공간 정보를 통합함으로써 임베드된 메시지는 NERF 모델에서 렌더링된 다양한 관점에서 일관성을 유지할 수 있습니다. 모델 최적화 중에 왜곡 방지 렌더링을 사용하여 워터마크 추출의 견고성을 더욱 강화합니다. 왜곡 레이어는 렌더링된 샘플이 심하게 왜곡된 경우(예: 흐림, 노이즈 및 회전)에도 견고한 워터마크 추출을 보장하도록 설계되었습니다. 렌더링 중에 보호된 모델을 다양한 샘플링 전략에 견고하게 만들기 위해 랜덤 샘플링 전략이 추가로 고려됩니다. 왜곡 방지 렌더링은 핵심 모델의 최적화 중에만 필요합니다. 핵심 모델이 도난당한 경우 다른 렌더링 방식과 샘플링 전략을 사용하더라도 저작권 메시지를 여전히 견고하게 추출할 수 있습니다. 저희의 기여는 다음과 같이 요약할 수 있습니다. • 저작권이 포함된 NeRF 모델을 생성하는 방법. • 보이지 않고 높은 렌더링 품질을 보장하기 위한 워터마크 색상 표현. 다양한 렌더링 전략 또는 2D 왜곡에 대한 견고성을 보장하기 위한 왜곡 방지 렌더링. 2.
--- RELATED WORK ---
신경 광도장. 다양한 신경 암묵적 장면 표현 방식이 최근 도입되었습니다[25, 42, 48]. 장면 표현 네트워크(SNR)[32]는 세계 좌표를 2D 이미지와 카메라 포즈에서 학습할 수 있는 로컬 피처에 매핑하는 다층 퍼셉트론(MLP)으로 장면을 표현합니다. DeepSDF[27]와 DIST[20]는 학습된 네트워크를 사용하여 모양 클래스의 연속 부호 거리 함수를 표현합니다. PIFu[30]는 단일 입력 이미지에서 각각 옷을 입은 사람의 표면과 질감을 추론하기 위해 두 개의 픽셀 정렬 암묵적 함수를 학습했습니다. 점유 네트워크[21, 28]는 3D 감독을 통해 3D 객체 또는 장면의 3D 기하학에 대한 암묵적 표현으로 제안되었습니다. 특히 NeRF[23, 49]는 MLP를 통해 3D 위치와 2D 시야 방향을 색상과 기하학에 직접 매핑하고 볼륨 렌더링을 통해 새로운 뷰를 합성합니다. 최근 몇 년 동안 이러한 암묵적 표현의 개선 및 응용 프로그램이 급속히 증가해 왔으며 여기에는 NeRF 가속[9, 24], 희소 재구성[44, 6], 생성 모델[31, 5]이 포함됩니다. NeRF 모델은 학습하기 쉽지 않고 비공개 데이터를 사용할 수 있으므로 저작권을 보호하는 것이 중요해집니다. 2D용 디지털 워터마킹. 초기 2D 워터마킹 접근 방식은 이미지 픽셀의 최하위 비트에 정보를 인코딩합니다[35]. 다른
--- METHOD ---
영어: 옵션 솔루션과 비교했을 때 높은 렌더링 품질과 비트 정확도를 유지하면서 NeRF 모델의 저작권을 직접 보호할 수 있습니다.프로젝트 페이지: https://luo-ziyuan.github.io/copyrnerf. 1. 서론 Neural Radiance Fields(NeRF)[23]가 디지털 미디어 표현의 주류가 될 가능성이 있지만 NeRF 모델을 학습하는 것은 결코 쉬운 일이 아니었습니다.악의적인 사용자가 NeRF 모델을 도용한 경우 해당 지적 재산을 어떻게 식별할 수 있습니까?모든 디지털 자산(예: 3D 모델, 비디오 또는 이미지)과 마찬가지로 저작권은 자산에 저작권 메시지를 임베드하여 보호할 수 있으며, 이를 디지털 워터마킹이라고 하며 NeRF 모델도 예외는 아닙니다.직관적인 솔루션은 기성형 워터마킹 방식(예: HiDDEN[50] 및 MBRS[14])을 사용하여 렌더링된 샘플에 직접 워터마킹을 하는 것입니다.그러나 이렇게 하면 렌더링된 샘플의 저작권만 보호되고 핵심 모델은 보호되지 않습니다.핵심 모델이 도용된 경우 악의적인 사용자가 새로운 샘플을 렌더링할 수 있습니다.*연락 저자. 이 작업은 홍콩 침례교 대학 컴퓨터 과학부의 Renjie 연구 그룹에서 수행되었습니다.비밀 메시지 00100110... 새로운 뷰 추출된 메시지 00100110... 다양한 설정에서의 재구성 품질 실제 PSNR/비트 정확도.저희의 CopyRNERF 32.69/100% 00100110... 00100110... HIDDEN + NERF 메시지가 있는 NERF 27.71/51% 22.83/69% 그림 1: 악의적인 사용자가 NeRF 모델을 도용한 경우(D), CopyRNERF는 모델에 포함된 저작권 메시지를 렌더링 샘플로 전송하여 모델 소유권을 주장하는 데 도움이 될 수 있습니다(②). HIDDEN [50] + NeRF [23] 및 메시지가 있는 NeRF [23]과 몇 가지 비교를 보여줍니다. 각 예 아래에 PSNR/비트 정확도가 나와 있습니다. 다른 렌더링 전략을 사용하여 모델 제작자가 기대하는 외부 워터마킹을 위한 여지를 남기지 않습니다. 게다가 워터마킹 중 렌더링에 필요한 요소를 고려하지 않고 렌더링된 샘플에 직접 워터마킹을 하면 기하 값이 낮은 영역에 쉽게 감지할 수 있는 흔적이 남을 수 있습니다. 저작권 메시지는 일반적으로 명시적 3D 모델의 경우 3D 구조(예: 메시)에 포함됩니다[43]. 이러한 구조는 모두 NeRF의 다층 퍼셉트론(MLP) 가중치에 암묵적으로 인코딩되므로 모델 가중치에 워터마킹을 하여 저작권 보호를 수행해야 합니다. NeRF로 인코딩된 정보는 보호된 모델의 2D 렌더링을 통해서만 액세스할 수 있으므로 렌더링된 샘플에서 워터마크를 추출하는 동안 두 가지 공통적인 표준을 고려해야 합니다[1, 15, 41, 45]. 1) 포함된 메시지로 인해 심각한 시각적 왜곡이 발생하지 않아야 하는 비가시성, 2) 다양한 왜곡이 발생하더라도 견고한 메시지 추출을 보장하는 견고성. 한 가지 옵션은 워터마크가 있는 이미지를 사용하여 NeRF 모델을 만드는 것입니다. 반면 2D 이미지의 인기 있는 보이지 않는 워터마크는 NeRF 모델로 효과적으로 전송할 수 없습니다. 그림 1에 설명된 대로(HiDDEN [50] + NeRF [23]), 렌더링된 결과는 고품질이지만 비밀 메시지를 견고하게 추출할 수 없습니다. 또한 비밀 메시지를 입력 좌표와 직접 연결하여 더 높은 비트 정확도를 생성할 수 있습니다(그림 1의 메시지가 있는 NeRF). 그러나 렌더링된 샘플의 낮은 PSNR 값은 눈에 띄는 시각적 왜곡이 있음을 나타내며, 이는 보이지 않음에 대한 표준을 위반합니다. 보이지 않음은 워터마킹 시스템에 중요하지만 견고성에 대한 더 높은 요구 사항은 워터마킹을 독특하게 만듭니다[50]. 따라서 보이지 않음 외에도 NeRF 모델의 보다 견고한 보호에 중점을 둡니다. 위의 설정에서처럼 전체 모델에 메시지를 내장하는 것과는 달리, 그림 2에 표시된 것처럼 모델의 하위 집합을 기반으로 렌더링하기 위한 워터마크 색상 표현을 만듭니다. 기본 표현을 변경하지 않으면 이 접근 방식은 보이지 않는 워터마크가 있는 렌더링 샘플을 생성할 수 있습니다. 워터마크 색상 표현에 공간 정보를 통합하면 내장된 메시지는 NERF 모델에서 렌더링된 다양한 관점에서 일관성을 유지할 수 있습니다. 모델 최적화 중에 왜곡 방지 렌더링을 사용하여 워터마크 추출의 견고성을 더욱 강화합니다. 왜곡 계층은 렌더링된 샘플이 심하게 왜곡된 경우(예: 흐림, 노이즈 및 회전)에도 견고한 워터마크 추출을 보장하도록 설계되었습니다. 렌더링 중에 보호된 모델을 다양한 샘플링 전략에 견고하게 만들기 위해 무작위 샘플링 전략도 추가로 고려합니다. 왜곡 방지 렌더링은 핵심 모델의 최적화 중에만 필요합니다. 핵심 모델이 도난당하더라도 렌더링 방식과 샘플링 전략이 다르더라도 저작권 메시지를 여전히 견고하게 추출할 수 있습니다. 저희의 기여는 다음과 같이 요약할 수 있습니다. • 저작권 내장 NeRF 모델을 생성하는 방법. • 투명성과 높은 렌더링 품질을 보장하기 위한 워터마크 색상 표현. 다양한 렌더링 전략 또는 2D 왜곡에 대한 견고성을 보장하기 위한 왜곡 방지 렌더링. 2. 관련 작업 신경 광도장. 다양한 신경 암묵적 장면 표현 방식이 최근 도입되었습니다[25, 42, 48]. 장면 표현 네트워크(SNR)[32]는 세계 좌표를 로컬 피처에 매핑하는 다층 퍼셉트론(MLP)으로 장면을 표현하며, 이는 2D 이미지와 카메라 포즈에서 학습할 수 있습니다. DeepSDF[27]와 DIST[20]는 학습된 네트워크를 사용하여 모양 클래스의 연속 부호 거리 함수를 표현합니다. PIFu[30]는 단일 입력 이미지에서 각각 옷을 입은 사람의 표면과 질감을 추론하기 위해 픽셀 정렬된 두 개의 암묵적 함수를 학습했습니다. 점유 네트워크[21, 28]는 3D 감독을 통해 3D 객체 또는 장면의 3D 기하학에 대한 암묵적 표현으로 제안됩니다. NeRF[23, 49]는 특히 MLP를 통해 3D 위치와 2D 시야 방향을 색상과 기하학에 직접 매핑하고 볼륨 렌더링을 통해 새로운 뷰를 합성합니다. 이 암묵적 표현의 개선 및 응용 프로그램은 최근 몇 년 동안 NeRF 가속[9, 24], 희소 재구성[44, 6] 및 생성 모델[31, 5]을 포함하여 빠르게 성장해 왔습니다. NeRF 모델은 학습하기 쉽지 않고 비공개 데이터를 사용할 수 있으므로 저작권을 보호하는 것이 중요해집니다. 2D용 디지털 워터마킹. 초기 2D 워터마킹 접근 방식은 이미지 픽셀의 최하위 비트에 정보를 인코딩합니다[35]. 대신 다른 일부 방법은 변환 도메인에서 정보를 인코딩합니다[17]. 이미지 워터마킹을 위한 딥 러닝 기반 방법은 상당한 진전을 이루었습니다. HiDDEN[50]은 기존 워터마킹 접근 방식에 비해 우수한 성능을 달성한 최초의 딥 이미지 워터마킹 방법 중 하나였습니다. RedMark[1]는 변환 도메인에 이진 이미지를 임베드하기 위한 강도 계수가 있는 잔여 연결을 도입했습니다. 그 이후로 딥 워터마킹은 비디오에도 일반화되었습니다[37, 46]. 더 복잡하고 사실적인 이미지 왜곡을 모델링하면 적용 범위도 넓어졌습니다[38, 34]. 그러나 이러한 방법 모두 3D 모델의 저작권을 보호할 수는 없습니다. 3D용 디지털 워터마킹. 기존의 3D 워터마킹 접근 방식[26, 29, 39]은 삼각형 또는 다각형 메시에 대한 푸리에 또는 웨이블릿 분석을 활용했습니다. 최근 Hou et al.[11]은 3D 인쇄 객체의 레이어링 아티팩트를 사용하는 3D 워터마킹 방법을 도입했습니다. Son et al.[33]은 메시 돌출성을 지각적 척도로 사용하여 정점 왜곡을 최소화했습니다. Hamidi et al.[10]은 웨이블릿 변환으로 메시 돌출성을 더욱 확장하여 3D 워터마킹을 강력하게 만들었습니다. Jing et al.[19]은 정점 곡률을 분석하여 포인트 클라우드에 대한 워터마킹을 연구했습니다. 최근, 딥러닝 기반 접근법[43]은 3D 메시에 메시지를 성공적으로 내장하고 2D 렌더링에서 이를 추출합니다. 그러나 기존 방법은 명시적 3D 모델을 위한 것으로, 암묵적 속성이 있는 NeRF 모델에는 사용할 수 없습니다. 렌더링... (b) 왜곡 방지 렌더링 Sec 4.2. +|+-메시지 추출--| (c) 메시지 추출기 Sec 4.3. Hy ☑ ... 핵심 모델 (a) 워터마크 색상 표현 구축 Sec 4.1. 11010... 특징 융합 + 랜덤 샘플링/ M 메시지 DoOc d Εξ 메시지 특징 필드 Σ 노이즈 회전 스케일링 왜곡 계층 M →추출된 메시지 메시지 손실 Ст 레이 캐스팅 색상 특징 필드 색상 특징 인코더 Εξ 워터마크 색상 M 11010... 메시지 좌표 d 시청 방향 메시지 특징 인코더 Do 특징 융합 모듈 Gab 콘텐츠 손실 L콘텐츠 x σ: 기하 Cm: 워터마크 색상 그림 2: 제안하는 방법의 그림.(a) 주어진 비밀 메시지로 워터마크 색상 표현을 얻었으며, 렌더링을 위해 워터마크 색상을 생성할 수 있습니다.(b) 학습하는 동안 왜곡 방지 렌더링을 배포하여 기하(σ)와 워터마크 색상 표현을 여러 왜곡이 있는 이미지 패치에 매핑합니다.(c) 마지막으로 비밀 메시지는 CNN 기반 메시지 추출기로 밝혀낼 수 있습니다. 3. 예비 C NERF [23]는 MLP O 및 Oc를 사용하여 3D 위치 x = R³ 및 시야 방향 d = R²를 색상 값 C = R³ 및 기하학적 값 σ = R+에 매핑합니다. [0,2] = ☹o (¼x(x)), c = Оc (z, Yd(d)), (1) (2) 여기서 Yx 및 Yd는 각각 위치 및 시야 방향에 대한 고정 인코딩 함수입니다. 중간 변수 z는 첫 번째 MLP σ에서 출력하는 특징입니다. 광도장 O 및 c에서 2D 이미지를 렌더링하기 위해 수치적 적분을 사용하여 체적 투영 적분을 근사합니다. 형식적으로, Np 포인트는 색상 및 기하 값 {(c,o)}을 갖는 카메라 광선 r을 따라 샘플링됩니다. RGB 색상 값 Ĉ(r)은 알파 구성을 사용하여 얻습니다. N Np Ĉ(r) = Tri (1 = exp (−σ²ð²))c², i=(3) 여기서 T = ПI (exp (−0.8%)), 8%는 인접한 샘플 포인트 사이의 거리입니다. MLP 。 및 Oc는 관측치 C와 예측 Ĉ a 사이의 재구성 손실을 NrLrecon Nr Σ ||Ĉ(rm) – C(rm)||³, m=(4)로 최소화하여 최적화됩니다. 여기서 Nr은 샘플링 픽셀 수입니다. O。 및 c가 주어지면 각 광선에 대해 볼륨 렌더링을 호출하여 새로운 뷰를 합성할 수 있습니다. 새로운 뷰를 렌더링하고 다양한 장면을 표현하는 NeRF의 뛰어난 기능을 고려할 때 악의적인 사용자가 이를 도용할 때 어떻게 저작권을 보호할 수 있을까요? 4. 제안하는 방법 N 그림 2에 설명된 대로, 2D 이미지 {In}_1과 길이가 No인 이진 메시지 M = {0, 1}№의 컬렉션을 사용하여 최적화 중에 워터마크가 있는 색상 표현을 구축하여 섹션 3에서 제기한 문제를 해결합니다. 학습 시, 왜곡 방지 렌더링을 추가로 적용하여 2D 왜곡이나 다른 렌더링 방식이 발생할 때 견고성을 개선합니다. 위의 설계를 사용하면 심각한 왜곡이나 다른 렌더링 전략이 발생하더라도 테스트 중에 비밀 메시지를 견고하게 추출할 수 있습니다. 4.1. 워터마크가 있는 색상 표현 구축 방정식(3)의 렌더링은 NeRF에서 해당 표현에 의해 생성된 색상과 기하학에 의존합니다. 저작권 메시지가 렌더링된 결과에 전송되도록 하기 위해 메시지를 해당 표현에 임베드하는 것을 제안합니다. 방정식(2)에서 정의된 Oc를 기반으로 워터마크가 있는 색상 표현을 생성하여 메시지의 비가시성과 관점 간 일관성을 보장합니다. 기하 구조의 표현은 또한 워터마킹의 잠재력이지만 기하 구조에 대한 외부 정보는 렌더링 품질을 떨어뜨릴 수 있습니다[36, 12, 7]. 따라서 기하 구조는 우리의 첫 번째 옵션이 되지 않지만
--- EXPERIMENT ---
s도 이 설정을 검증하기 위해 수행됩니다. 방정식(1)의 기하 표현을 변경하지 않고 워터마크 색상 표현 ☺m을 구성하여 다음과 같이 메시지 내장 색상 cm을 생성합니다.Ст Om(C, Yx(x), Yd(d), M), (5) 여기서 M은 내장할 메시지를 나타내고 Om에는 신뢰할 수 있는 메시지 내장을 보장하기 위한 여러 MLP가 포함됩니다.입력 c는 방정식(2)을 사용하여 ☺를 쿼리하여 얻습니다.여러 이전 방법에서는 복합 정보를 특성화하기 위해 분산 피처가 필요할 때 3D 피처 필드를 구축하는 것의 중요성을 지적했습니다[40, 4].따라서 이러한 정보를 직접 융합하는 대신 먼저 해당 피처 필드를 구성한 다음 점진적으로 결합합니다.색상 피처 필드.이 단계에서는 공간 정보와 색상 표현을 융합하여 관점에서 메시지 일관성과 견고성을 보장하는 것을 목표로 합니다.다음과 같이 색상, 공간 위치 및 시야 방향을 동시에 고려하여 색상 피처 필드를 채택합니다.fc = Eε(c, x(x), Yd(d)). (6) 3D 좌표 x와 시야 방향 d가 주어지면, 먼저 색상 표현 Oc(Z, Yd(d))를 쿼리하여 c를 구한 다음, 이를 x와 d와 연결하여 공간 기술자 v를 입력으로 얻습니다. 그런 다음 색상 특징 인코더 Eş는 v를 차원 Ne의 고차원 색상 특징 필드 fe로 변환합니다. 특징 추출 전에 x와 d에 푸리에 특징 인코딩을 적용합니다. 메시지 특징 필드. 메시지 특징 필드를 추가로 구성합니다. 구체적으로, 비밀 메시지를 더 높은 차원으로 변환하여 디지털 워터마킹의 고전적 설정을 따릅니다[2, 3]. 이를 통해 원하는 메시지를 더 간결하게 인코딩할 수 있습니다[2]. 그림 2에서 볼 수 있듯이 메시지 특징 인코더를 적용하여 메시지를 해당 고차원에 매핑합니다. fM = Do(M). (7) 방정식(7)에서 길이가 Nɩ인 메시지 M이 주어지면 메시지 특징 인코더 Do는 입력 메시지에 MLP를 적용하여 차원 Nm의 메시지 특징 필드 fм을 생성합니다. 그런 다음 워터마크 색상은 다음과 같이 색상 특징 필드와 메시지 특징 필드를 모두 통합하는 특징 융합 모듈 G₁을 통해 생성될 수 있습니다.Ст Gy(fc, fm, c). (8) 구체적으로, 최종 결과를 보다 안정적으로 만들기 위해 여기서도 c가 사용됩니다.Cm은 c와 동일한 차원을 가지므로 이 표현이 현재 렌더링 방식에 쉽게 적용될 수 있습니다.4.2. 왜곡 방지 렌더링 볼륨 렌더링에 워터마크 표현을 직접 사용하면 이미 뷰포인트 전체에서 비가시성과 견고성을 보장할 수 있었습니다.그러나 섹션 1에서 설명한 대로 렌더링된 2D 이미지에 다양한 왜곡이 발생하더라도 메시지는 견고하게 추출되어야 합니다.또한 콘텐츠를 표시하기 위해 렌더링에 의존하는 암묵적 모델의 경우 다른 렌더링 전략을 사용하는 경우에도 견고성이 보장되어야 합니다.이러한 견고성에 대한 요구 사항은 기존 NeRF 학습 프레임워크에서 워터마크 표현을 사용하는 것만으로는 달성할 수 없습니다.예를 들어, 픽셀 단위 렌더링 전략은 더 넓은 범위에서만 의미가 있는 왜곡(예: 흐림 및 자르기)을 효과적으로 모델링할 수 없습니다. 따라서 무작위 샘플링 전략과 왜곡 계층을 사용하여 견고성을 강화함으로써 왜곡 저항 렌더링을 제안합니다.대부분의 2D 왜곡은 특정 영역에서만 명확하게 관찰할 수 있으므로 패치 수준에서 렌더링 프로세스를 고려합니다[16, 8].임의 위치의 창은 특정 높이와 너비로 입력 이미지에서 잘라낸 다음 이러한 창에서 픽셀을 균일하게 샘플링하여 더 작은 패치를 형성합니다.패치의 중심은 u = (u, v)R2로 표시되고 패치의 크기는 K = R+로 결정됩니다.이미지 도메인에서 균일 분포 u ~ U()에서 패치 중심 u를 무작위로 추출합니다.패치 P(u, K)는 P(u, K) = {(x + u,y+v) | x, y ≤ {–&#39; KK 1}}인 2D 이미지 좌표 집합으로 표시할 수 있습니다.이러한 패치 기반 방식은 더 넓은 범위에서 정보를 캡처하는 이점 덕분에 왜곡 저항 렌더링의 중추를 구성합니다. 특히, 렌더링 중 다양한 왜곡을 수용하기 위해 가변 패치 크기를 사용하여 메시지 추출에서 더 높은 견고성을 보장할 수 있습니다. 이는 작은 패치가 자르기 공격에 대한 견고성을 높이고 큰 패치는 비트 인코딩에서 더 높은 중복성을 허용하여 무작위 노이즈에 대한 회복성이 증가하기 때문입니다[8]. 해당 3D 광선은 P(u, K), 카메라 포즈 및 내장 함수에 의해 고유하게 결정되므로 포인트 샘플링 및 렌더링 후에 이미지 패치 P를 얻을 수 있습니다. 섹션 3의 샘플링 포인트를 기반으로 무작위 샘플링 방식을 사용하여 모델의 견고성을 더욱 개선합니다. 이는 다음과 같이 설명됩니다. 무작위 샘플링. 볼륨 렌더링 중에 NeRF[23]는 픽셀 색상의 RGB 값을 계산하기 위해 광선을 따라 3D 점을 샘플링해야 합니다. 그러나 샘플링 전략은 렌더러가 변경됨에 따라 달라질 수 있습니다[24, 18]. 다른 샘플링 전략에서도 메시지 추출을 보다 견고하게 만들기 위해 샘플링 포인트에 이동하는 값을 추가하여 무작위 샘플링 전략을 사용합니다. 구체적으로, 레이 r을 따라 원래 Np 샘플링 포인트는 시퀀스로 표시되며, 이는 X(x1, x2, x³)로 결론지을 수 있습니다. 여기서 xr, i 1,2,, Np는 렌더링 중의 샘플링 포인트를 나타냅니다. 무작위 샘플 시퀀스 Xrandom은 이동하는 = = 값을 추가하여 Xrandom = (x² + z¹‚ x² + z², №p + z№p), (10) Np z² ~N(0, ẞ²), i = = 1,2로 표시할 수 있습니다. 여기서 N(0, 32)는 평균이 0이고 표준 편차가 B인 가우시안 분포입니다. Xrandom의 No 포인트에서 워터마크 색상 표현과 기하 값을 쿼리하면 렌더링 연산자를 적용하여 렌더링된 이미지에서 워터마크 색상 Cm을 생성할 수 있습니다. Np Cm(r) = T(1 = exp(−σ8))cm, i=(11) 여기서 Tr과 8은 방정식(3)의 대응 항목과 동일한 정의를 갖습니다. 좌표 P에서 얻은 모든 색상은 K × K 이미지 패치 P를 형성할 수 있습니다.3D 표현의 콘텐츠 손실 콘텐츠는 워터마크 패치 P와 P 사이에서 계산되며, 여기서 P는 동일한 좌표 P에 의해 워터마크가 없는 표현에서 렌더링됩니다.자세히 말하면, 콘텐츠 손실 콘텐츠는 픽셀 단위 MSE 손실과 지각적 손실의 두 가지 구성 요소를 갖습니다.Lcontent = ||Ñ – Ĥ||¾+λ||¥(Ñ) – ч(Ĥ)||¾½, (12) 여기서 (.)은 VGG-16 네트워크에서 얻은 특징 표현을 나타내고 X는 손실 함수를 균형 잡기 위한 하이퍼파라미터입니다.왜곡 계층.워터마킹 시스템을 2D 왜곡에 강건하게 만들기 위해 패치 P가 렌더링된 후 워터마킹 학습 파이프라인에 왜곡 계층을 사용합니다.일반적으로 사용되는 몇 가지 왜곡을 고려합니다.1) 평균 μ와 표준 편차 v가 있는 가산 가우시안 잡음;2) 매개변수 a가 있는 무작위 축-각 회전;3) 매개변수 s가 있는 무작위 스케일링; 4) 커널 k를 사용한 가우시안 블러. 이러한 모든 왜곡은 미분 가능하므로 네트워크를 종단 간에 학습할 수 있습니다. 왜곡 방지 렌더링은 학습 중에만 적용됩니다. 핵심 모델의 일부가 아닙니다. 핵심 모델이 도난당하더라도 악의적인 사용자가 다른 렌더링 전략을 사용하더라도 예상되는 견고성을 확보할 수 있습니다. 4.3. 메시지 추출기 K × K 렌더링된 패치 P에서 메시지 M을 검색하기 위해 종단 간에 학습되는 메시지 추출기 HX가 제안됩니다. Hx : RK×K → RN, P↔ Â, (13) 여기서 X는 학습 가능한 매개변수입니다. 구체적으로 배치 정규화 및 ReLU 함수[13]가 있는 2D 합성곱 계층 시퀀스를 사용합니다. 그런 다음 평균 풀링을 수행한 다음 고정된 출력 차원 №ɩ(메시지 길이)를 갖는 최종 선형 계층을 추가하여 연속 예측 메시지 M을 생성합니다. 평균 풀링을 사용하기 때문에 메시지 추출기는 모든 패치 크기와 호환되므로 무작위 스케일링과 같은 크기 변경 왜곡을 적용할 때 네트워크 구조가 변경되지 않을 수 있습니다. 그런 다음 예측 메시지 M과 기준 진실 메시지 M 사이의 이진 교차 엔트로피 오류를 계산하여 메시지 손실 Lm을 얻습니다.Ст = mean[-(M log M + (1 − M) log(1 – M))], (14) 여기서 mean[]은 모든 비트에 대한 평균값을 나타냅니다. 테스트 중 비트 정확도를 평가하기 위해 이진 예측 메시지 M은 반올림하여 얻을 수 있습니다.M₁ = clamp(sign(M), 0, 1), (15) 여기서 clamp와 sign은 [43]에서 동일한 정의입니다. 학습 프로세스에서는 연속 결과 M을 사용하는 반면 이진 결과 M은 테스트 프로세스에서만 채택된다는 점에 유의해야 합니다. 따라서 저작권 보호 신경 복사장을 훈련하기 위한 전체 손실은 L = 1 content + 12Lm, (16)으로 얻을 수 있습니다. 여기서 1과 2는 손실 함수를 균형 잡기 위한 하이퍼파라미터입니다. 4.4. 구현 세부 정보 = PyTorch를 사용하여 방법을 구현합니다. 256개 채널과 다음 두 개의 MLP 분기가 있는 8층 MLP를 사용하여 각각 원래 색상 c와 불투명도 σ를 예측합니다. 중요도 샘플링을 위해 &quot;미세&quot; 네트워크와 함께 &quot;거친&quot; 네트워크를 훈련합니다. 거친 모델에서 각 광선을 따라 점을 샘플링하고 미세 모델에서 64개 점을 샘플링합니다. 다음으로 패치 크기를 150 × 150으로 설정합니다. 방정식 (12)와 방정식 (16)의 하이퍼파라미터는 1 = 0.01, 1 및 Y2 = 5.00으로 설정됩니다. 우리는 기본값 ẞ₁ = 0.9, ẞ2 0.999, f = 10−8, 최적화 중에 지수 스케줄러에 따라 감소하는 학습률 5 × 10−4를 갖는 Adam 최적화 프로그램을 사용합니다. 실험에서 우리는 방정식(7)의 Nm을 256으로 설정했습니다. 먼저 Blender 데이터 세트[23]와 LLFF 데이터 세트[22]에 대해 별도로 200K 및 100K 반복에 대해 손실 함수 방정식(4)를 사용하여 MLP O 및 O를 최적화한 다음 8개의 NVIDIA Tesla V100 GPU에서 모델 Eε, Do 및 HX를 학습합니다. 학습하는 동안 서로 다른 비트 길이와 형식의 메시지를 고려했습니다. 메시지에 4비트가 있는 경우 학습 중에 24가지 상황을 모두 고려합니다. 모델 생성자는 학습에서 고려한 메시지 하나를 원하는 메시지로 선택할 수 있습니다. Groundtruth 제안된 방법 HIDDEN+NeRF MBRS+NeRF NeRF with message CopyRNERF in geometry 정확도 100% / PSNR 30. 정확도 50.25% / PSNR 27. 정확도 51.38% / PSNR 29. 정확도 63.19% / PSNR 20. 정확도 68.00% / PSNR 17. 정확도 100% / PSNR 32. 정확도 50.94% / PSNR 27. 정확도 51.04% / PSNR 28. 정확도 69.28% / PSNR 22. 정확도 61.50% / PSNR 18. 그림 3: 각 기준선의 시각적 품질 비교. 각 방법 옆에 합성된 결과와 ground truth 사이의 차이(×10)를 표시합니다. 제안된 CopyRNeRF는 재구성 품질과 비트 정확도 사이에서 좋은 균형을 이룰 수 있습니다. 표 1: 기준선과 비교한 다른 길이의 비트 정확도. 결과는 모든 모든 예에서 평균화됩니다. 4비트 제안된 CopyRNERF 100% HIDDEN [45]+NeRF[23] 50.31% MBRS [14]+NeRF [23] 53.25% NeRF[23] 기하 구조에 CopyRNERF 메시지가 포함되어 있음 72.50% 76.75% 8비트 16비트 32비트 48비트 100% 91.16% 78.08% 60.06% 50.25% 50.19% 50.11% 50.04% 51.38% 50.53% 49.80% 50.14% 63.19% 52.22% 50.00% 51.04% 68.00% 60.16% 54.86% 53.36% 5. 실험 5.1. 실험 설정 데이터 세트. 방법을 평가하기 위해 NeRF에 일반적으로 사용되는 데이터 세트인 Blender 데이터 세트[23]와 LLFF 데이터 세트[22]에서 모델을 학습하고 테스트합니다. Blender 데이터 세트에는 안쪽을 향한 반구에 배치된 가상 카메라에서 촬영한 100개의 이미지가 있는 8개의 세부적인 합성 객체가 포함되어 있습니다. NeRF[23]에서와 같이 각 장면에 대해 학습을 위해 100개의 뷰를 입력합니다. LLFF 데이터 세트는 주로 앞을 향한 이미지가 포함된 8개의 실제 장면으로 구성됩니다. 각 장면에는 20~62개의 이미지가 포함됩니다. 이 데이터 세트의 데이터 분할도 NERF[23]를 따릅니다. 각 장면에 대해 테스트 데이터 세트에서 20개의 이미지를 선택하여 시각적 품질을 평가합니다. 비트 정확도를 평가하기 위해 각 장면에 대해 200개의 뷰를 렌더링하여 다양한 관점에서 메시지를 효과적으로 추출할 수 있는지 테스트합니다. 실험에서 모든 테스트 관점에 대한 평균값을 보고합니다. 기준선. 저희가 아는 한 NeRF 모델의 저작권을 보호하기 위한 구체적인 방법은 없습니다. 따라서 공정한 비교를 보장하기 위해 4가지 전략을 비교합니다.1) HiDDEN[50]+NeRF[23]: NeRF 모델을 학습하기 전에 기존 2D 워터마킹 방법 HIDDEN[50]으로 이미지를 처리합니다.2) MBRS[14]+NeRF[23]: NeRF 모델을 학습하기 전에 최신 2D 워터마킹 방법 MBRS[14]로 이미지를 처리합니다.3) 메시지가 있는 NeRF: 위치 x와 시야 방향 d를 NeRF의 입력으로 사용하여 메시지 M을 연결합니다.4) 기하 구조의 CopyRNeRF: 기하 구조가 메시지 임베딩에 적합한 옵션인지 평가하기 위해 메시지를 기하 구조와 융합하여 CopyRNERF를 변경합니다.평가 방법론.우리는 비가시성, 견고성 및 용량에 대한 디지털 워터마킹 표준을 따라 다른 방법과 비교하여 제안하는 방법의 성능을 평가합니다. 비가시성의 경우, PSNR, SSIM 및 LPIPS[47]를 사용하여 메시지 임베딩 후 렌더링된 결과의 시각적 품질을 비교하여 성능을 평가합니다.견고성의 경우, 다양한 왜곡에 대한 비트 정확도를 측정하여 인코딩된 메시지를 효과적으로 추출할 수 있는지 조사합니다.일반적인 상황 외에도 메시지 추출을 위해 다음과 같은 왜곡을 고려합니다.1) 가우시안 노이즈, 2) 회전, 3) 스케일링 및 4) 가우시안 흐림.용량의 경우, 명시적 3D 모델의 워터마킹에 대한 이전 작업[43]의 설정에 따라 №₁ = {4, 8, 16, 32, 48}인 다양한 메시지 길이에서 비가시성과 견고성을 조사합니다.이는 3D 모델을 보호하는 데 효과적인 것으로 입증되었습니다[43].각 장면에 대한 실험에 다양한 관점을 포함했기 때문에 평가는 평가된 방법이 관점 전체에서 견고성과 일관성을 보장할 수 있는지 여부를 충실하게 반영할 수 있습니다.5.2. 실험 결과 정성적 결과. 우리는 먼저 모든 기준선에 대해 시각적으로 재구성 품질을 비교하고 그 결과를 그림 3에 표시합니다. 실제로, 메시지를 사용한 NeRF와 기하학의 CopyRNeRF를 제외한 모든 방법은 높은 재구성 품질을 달성할 수 있습니다. HiDDEN[50] + NeRF[23]의 경우 표 2: 기준선과 비교한 비트 정확도 및 재구성 품질. ↑(↓)는 더 높을수록(낮을수록) 더 좋음을 의미합니다. 우리는 Nb = 16비트에 대한 결과를 보여줍니다. 결과는 모든 예제에서 평균화됩니다. 가장 좋은 성능은 굵은 글씨로 강조 표시됩니다. MBRS Residual(X10)로 워터마크 처리된 비트 정확도↑ PSNR ↑ SSIM ↑ LPIPS↓ 제안된 CopyRNeRF 91.16% 26.0.0.HIDDEN [50]+NeRF[23] 50.19% 26.0.0.MBRS [14]+NeRF [23] 지오메트리에 CopyRNERF 메시지가 포함된 NeRF 50.53% 28.0.0.52.22% 22.0.0.60.16% 20.0.0.MBRS+NeRF Residual(X10)의 결과 그림 4: MBRS [14]+NeRF 실패 분석. 표 3: 왜곡 방지 렌더링(DRR)이 없는 CopyRNeRF와 각 기준선과 비교한 다양한 왜곡 유형의 비트 정확도. N = 16비트에 대한 결과를 보여줍니다. 모든 예제에서 결과를 평균화합니다. 왜곡 없음 가우시안 노이즈 회전(v=0.1) 제안된 CopyRNERF 91.16% 90.44% (±π/6) 88.13% 89.33% 스케일링(25%) (편차 가우시안 흐림 = 0.1) 90.06% HIDDEN [50]+NeRF[23] 50.19% 49.84% 50.12% 50.09% 50.16% MBRS [14]+NeRF [23] 50.53% 51.00% 51.03% 50.12% 50.41% 메시지가 포함된 NeRF 52.22% 50.53% 50.22% 50.19% 51.34% 기하 구조의 CopyRNERF 60.16% 58.00% 56.94% 60.09% 59.38% CopyRNERF W/O DRR 91.25% 89.12% 75.81% 87.44% 87.06% 및 MBRS[14]+NeRF[23]는 2D 워터마킹에서 효율적인 접근 방식이지만 렌더링된 이미지의 비트 정확도 값이 모두 낮아서 NeRF 모델 학습 후 메시지가 효과적으로 내장되지 않았음을 증명합니다.그림 4에 표시된 결과에서 NeRF의 뷰 합성은 2D 워터마킹 방법으로 내장된 정보를 변경하여 실패로 이어집니다.메시지가 있는 NeRF의 경우 이전 논의에서 가정했듯이 비밀 메시지를 입력으로 직접 사용하면 출력의 모양이 변경되어 PSNR 값이 낮아집니다.게다가 비트 정확도가 낮아서 이것이 효과적인 내장 방식이 아님을 증명합니다.기하학에서 CopyRNERF의 경우 모든 방법 중에서 최악의 시각적 품질을 달성합니다. 렌더링된 결과는 흐릿해 보이는데, 이는 지오메트리가 메시지 임베딩에 적합한 옵션이 아니라는 가정을 확인시켜 줍니다.비트 정확도 대 메시지 길이. 각 메시지 길이에 대해 5개의 실험을 시작하고 비트 정확도와 메시지 길이 간의 관계를 표 1에 보여줍니다. 비트 수가 증가하면 비트 정확도가 떨어지는 것을 분명히 볼 수 있습니다. 그러나 CopyRNeRF는 모든 설정에서 가장 좋은 비트 정확도를 달성하여 메시지를 효과적으로 임베딩하고 견고하게 추출할 수 있음을 증명합니다.지오메트리의 CopyRNeRF는 모든 설정 중에서 두 번째로 좋은 결과를 달성하여 지오메트리에 메시지를 임베딩하는 것도 워터마킹에 대한 잠재적인 옵션이 될 수 있음을 보여줍니다. 그러나 제안된 CopyRNERF의 더 높은 성능은 색상 표현이 더 나은 선택임을 보여줍니다.비트 정확도 대 재구성 품질. 비트 정확도와 재구성 품질 간의 관계를 평가하기 위해 더 많은 실험을 수행합니다. 결과는 표 2¹에 나와 있습니다. 제안된 CopyRNERF는 비트 정확도와 오류 메트릭 값 간에 좋은 균형을 이룹니다. 시각적 품질 값은 가장 높지 않지만 비트 정확도는 모든 설정 중에서 가장 좋습니다. HiDDeN[50] + NeRF[23] 및 MBRS[14] + NeRF[23]가 더 나은 시각적 품질 값을 생성할 수 있지만, 낮은 비트 정확도는 비밀 메시지가 효과적으로 내장되지 않고 견고하게 추출되지 않음을 나타냅니다. 메시지가 있는 NeRF도 비트 정확도에서 성능이 저하되고 시각적 품질 값도 낮습니다. 이는 내장된 메시지가 재구성 품질을 떨어뜨린다는 것을 나타냅니다. 구체적으로, 기하 구조에서 CopyRNERF의 낮은 시각적 품질 값은 메시지를 색상으로 숨기면 기하 구조에서 메시지를 숨기는 것보다 더 나은 재구성 품질로 이어질 수 있음을 나타냅니다. 2D 왜곡에 대한 모델 견고성. 여러 가지 기존 2D 왜곡을 적용하여 방법의 견고성을 평가합니다. 구체적으로, 표 3에 표시된 것처럼 노이즈, 회전, 크기 조정 및 자르기를 포함한 여러 유형의 2D 왜곡을 고려합니다. 우리 방법이 다양한 2D 왜곡에 매우 견고하다는 것을 알 수 있습니다. 구체적으로, DRR이 없는 CopyRNeRF는 왜곡이 발생하지 않을 때 전체 CopyRNERF와 유사한 성능을 달성합니다. 그러나 ¹다른 길이의 원시 비트에 대한 결과는 보충 자료에서 찾을 수 있습니다.Groundtruth 32 ASP + 32 ISP 64 ASP 32 ASP 16 ASP 64 RSP 비트 정확도 90.06% 비트 정확도 89.22% 비트 정확도 88.06% 비트 정확도 85.81% 비트 정확도 88.41% 그림 5: 추론 단계에서 다양한 렌더링 저하에 대한 비교.메시지 길이는 16으로 설정되었습니다.다양한 렌더링 전략에서 평균 샘플링 포인트(ASP), 중요도 샘플링 포인트(ISP), 임의 샘플링 포인트(RSP)를 사용합니다.&quot;32 ASP + 32 ISP&quot;는 학습 프로세스에 사용된 전략이며, 메시지 추출도 가장 높은 비트 정확도를 보여줍니다.추론 중에 샘플링 전략을 다른 것으로 변경해도 메시지 추출은 여전히 비슷한 성능을 보이며, 이는 왜곡 방지 렌더링의 효과를 검증합니다. 표 4: 전체 모델, 메시지 피처 필드(MFF)가 없는 모델, 색상 피처 필드(CFF)가 없는 모델에 대한 비교. 마지막 행은 테스트 중에 다른 렌더링 방식(DRS)을 적용하더라도 방법이 일관된 성능을 달성한다는 것을 보여줍니다. 비트 Acc↑ PSNR ↑ SSIM ↑ Ours MFF 없음 100% 32.0.82.69% 20.0.LPIPS↓ 0.0.CFF 없음 DRS 80.69% 21.0.0.100% 32.0.0. 다른 왜곡에 관해서는, 낮은 비트 정확도가 학습 중에 왜곡에 강한 렌더링의 효과를 보여줍니다. 피처 필드에 대한 분석. 이 섹션에서는 색상 피처 필드와 메시지 피처 필드의 효과를 추가로 평가합니다. 먼저 색상 피처 필드를 구축하기 위한 모듈을 제거하고 색상 표현을 메시지 피처와 직접 결합합니다. 이 경우 모델은 렌더링된 결과의 시각적 품질을 보존하는 데 있어 성능이 좋지 않습니다. 우리는 또한 메시지 특징 필드를 구축하기 위한 모듈을 제거하고 메시지를 색상 특징 필드와 직접 결합합니다.표 4의 결과는 이것이 낮은 비트 정확도로 이어질 수 있음을 나타내며, 이는 메시지가 효과적으로 내장되지 않았음을 증명합니다.렌더링에 대한 모델 견고성.우리는 추론을 위해 일반적인 볼륨 렌더링 전략을 적용하지만, 훈련 단계에서 사용된 왜곡 렌더링을 사용하여 메시지를 효과적으로 추출할 수도 있습니다.표 4의 마지막 행에 표시된 것처럼, 왜곡 렌더링을 사용한 정량적 값은 여전히 표 4의 첫 번째 행에 있는 원래 결과와 유사하며, 이는 제안하는 방법의 견고성을 더욱 확인합니다.다양한 샘플링 방식에 대한 결과는 그림 5에 나와 있습니다.우리의 왜곡 방지 렌더링은 훈련 중에 평균 샘플링 포인트와 32개의 중요도 샘플링 포인트를 사용합니다.유추 단계에 다른 샘플링 전략을 적용하면, 우리 방법은 또한 No message Ours NeRF+HIDDEN NeRF+MBRS를 달성할 수 있습니다.그림 6: 렌더링 후 워터마킹에 대한 비교. 왼쪽 하단 모서리의 패치는 단순히 인수 30을 곱하여 증가 결과를 보여줍니다.우리는 더 나은 시각화를 위해 높은 비트 정확도의 이미지 반전을 사용하는데, 이는 다양한 샘플링 전략을 참조하여 우리 방법의 견고성을 검증할 수 있습니다.NeRF+HiDDEN/MBRS [50, 14]와의 비교.또한 렌더링된 이미지에 2D 워터마킹 방법을 직접 적용하는 접근 방식인 NeRF+HiDDEN [50] 및 NeRF+MBRS [14]과 우리 방법을 비교하기 위한 실험을 수행합니다.이러한 방법은 그림 6에서 볼 수 있듯이 논문에 보고된 대로 높은 비트 정확도에 도달할 수 있지만, 이러한 방법은 워터마킹 중에 3D 정보를 고려하지 않기 때문에 특히 지오메트리 값이 낮은 영역에서 쉽게 감지 가능한 흔적을 남길 수 있습니다.게다가 2D 도메인의 미디어만 고려하며 NeRF 모델 가중치를 보호할 수 없습니다.6.
--- CONCLUSION ---
s 이 논문에서는 메시지를 모델 가중치에 임베드하여 저작권이 포함된 3D 암묵적 표현을 만드는 프레임워크를 제안합니다. 임베드된 정보의 비가시성을 보장하기 위해 지오메트리는 변경하지 않고 워터마크가 있는 색상 표현을 구성하여 메시지 임베드 색상을 생성합니다. 임베드된 메시지는 높은 재구성 품질을 유지하면서 모든 관점에서 렌더링된 이미지에서 CNN 기반 추출기로 추출할 수 있습니다. 또한, 고전적인 2D 저하 및 다양한 렌더링 전략을 포함한 다양한 유형의 왜곡에서 모델의 견고성을 향상시키기 위해 왜곡 방지 렌더링 방식을 도입합니다. 제안된 방법은 실험적 평가에서 비트 정확도와 높은 시각적 품질 사이에서 유망한 균형을 이룹니다. 제한 사항. 우리 방법은 신경 복사장의 소유권을 주장하는 데 유망한 성과를 보였지만 NeRF 모델을 학습하는 데는 시간이 많이 걸립니다. 향후 작업에서 학습 프로세스를 가속화하는 방법을 고려할 것입니다. 게다가 시스템 견고성을 강화하기 위한 여러 가지 설계를 고려했지만 악의적인 사용자가 모델 가중치를 직접 공격할 때(즉, 모델 가중치가 손상될 때) 이 표준이 여전히 훼손될 수 있습니다. 우리는 모델 매개변수에 가우시안 노이즈(std = 0.01)를 직접 추가하여 간단한 실험을 수행했고, 정확도는 93.97%(№ 8)로 약간 감소했습니다. 이는 렌더링 품질에도 영향을 미칠 수 있으므로, 이러한 모델 가중치 손상은 콘텐츠를 표시하려는 악의적인 사용자에게는 우선순위가 아닐 수 있습니다. 우리는 향후 작업에서 이러한 공격을 처리하는 방법을 적극적으로 고려할 것입니다. 감사의 말. Renjie Wan은 HKBU의 Blue Sky Research Fund에서 Grant No. BSRF/2122/16으로, Guangdong Basic and Applied Basic Research Foundation에서 Grant No. 2022A1515110692로 지원을 받았습니다. Qing Guo는 A*STAR Centre for Frontier AI Research와 싱가포르의 National Research Foundation, 그리고 AI Singapore Programme(AISG Award No: AISG2-GC-2023-008)에 따라 DSO National Laboratories에서 지원을 받았습니다. 참고문헌 [1] Mahdi Ahmadi, Alireza Norouzi, Nader Karimi, Shadrokh Samavi, Ali Emami. Redmark: 딥 네트워크 기반 잔여 확산 워터마킹 프레임워크. Expert Systems with Applications, 2020. [2] Shumeet Baluja. 평범한 시야에 이미지 숨기기: 딥 스테가노그래피. 신경 정보 처리 시스템의 발전, 2017. [3] Shumeet Baluja. 이미지 내에 이미지 숨기기. IEEE 패턴 분석 및 머신 인텔리전스 트랜잭션, 2019. [4] Eric R Chan, Connor Z Lin, Matthew A Chan, Koki Nagano, Boxiao Pan, Shalini De Mello, Orazio Gallo, Leonidas J Guibas, Jonathan Tremblay, Sameh Khamis, et al. 효율적인 기하학 인식 3D 생성적 적대 네트워크. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2022. [5] Eric R Chan, Marco Monteiro, Petr Kellnhofer, Jiajun Wu 및 Gordon Wetzstein. pi-GAN: 3D 인식 이미지 합성을 위한 주기적 암묵적 생성적 적대 네트워크. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2021. [6] Anpei Chen, Zexiang Xu, Fuqiang Zhao, Xiaoshuai Zhang, Fanbo Xiang, Jingyi Yu 및 Hao Su. MVSNeRF: 다중 뷰 스테레오에서 빠르게 일반화 가능한 광도장 재구성. IEEE/CVF 국제 컴퓨터 비전 컨퍼런스 논문집, 2021. [7] Pei-Ze Chiang, Meng-Shiun Tsai, Hung-Yu Tseng, WeiSheng Lai, Wei-Chen Chiu. 암묵적 표현과 하이퍼네트워크를 통한 3D 장면 스타일 지정. IEEE/CVF 컴퓨터 비전 응용 프로그램 동계 컨퍼런스 논문집, 2022. [8] Daniel Cotting, Tim Weyrich, Mark Pauly, Markus Gross. 포인트 샘플링된 지오메트리의 강력한 워터마킹. Shape Modeling Applications 논문집, 2004., 2004. [9] Sara Fridovich-Keil, Alex Yu, Matthew Tancik, Qinhong Chen, Benjamin Recht, Angjoo Kanazawa. 플레녹셀: 신경망이 없는 광채 필드. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2022. [10] Mohamed Hamidi, Aladine Chetouani, Mohamed El Haziti, Mohammed El Hassouni, Hocine Cherifi. 저작권 보호를 위한 메시 샐리언시 및 웨이블릿 변환을 기반으로 한 블라인드 견고한 3D 메시 워터마킹. 정보, 2019. [11] Jong-Uk Hou, Do-Gon Kim, Heung-Kyu Lee. 레이어링 아티팩트를 분석하여 3D 인쇄 모델을 위한 블라인드 3D 메시 워터마킹. IEEE 정보 포렌식 및 보안 저널, 2017. [12] Yi-Hua Huang, Yue He, Yu-Jie Yuan, Yu-Kun Lai, Lin Gao. 양식화된 NeRF: 2D-3D 상호 학습을 통한 양식화된 NeRF로서 일관된 3D 장면 양식화. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2022. [13] Sergey Ioffe 및 Christian Szegedy. 배치 정규화: 내부 공변량 이동을 줄여 딥 네트워크 학습 가속화. 기계 학습 국제 컨퍼런스, 2015. [14] Zhaoyang Jia, Han Fang 및 Weiming Zhang. MBRS: 실제 및 시뮬레이션된 jpeg 압축의 미니 배치를 통해 DNN 기반 워터마킹의 견고성 향상. 제29회 ACM 멀티미디어 국제 컨퍼런스 회의록, 2021. [15] Junpeng Jing, Xin Deng, Mai Xu, Jianyi Wang 및 Zhenyu Guan. HiNet: 가역 네트워크를 통한 딥 이미지 은닉. IEEE/CVF 국제 컴퓨터 비전 컨퍼런스 논문집, 2021. [16] Ki-Ryong Kwon, Seong-Geun Kwon, Suk-Hawn Lee, TaeSu Kim, and Kuhn-Il Lee. 각 패치의 정규 벡터 분포를 사용한 3D 다각형 메시의 워터마킹. 2003 국제 영상 처리 컨퍼런스 논문집, 2003. [17] Chih-Chin Lai and Cheng-Chih Tsai. 이산 웨이블릿 변환과 특이값 분해를 사용한 디지털 이미지 워터마킹. IEEE 계측 및 측정 저널, 2010. [18] David B Lindell, Julien NP Martel, and Gordon Wetzstein. Autoint: 빠른 신경 볼륨 렌더링을 위한 자동 적분. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2021. [19] Jing Liu, Yajie Yang, Douli Ma, Wenjuan He, Yinghui Wang. 정점 곡률을 기반으로 하는 3차원 포인트 클라우드 모델을 위한 새로운 워터마킹 알고리즘. 국제 분산 센서 네트워크 저널, 2019. [20] Shaohui Liu, Yinda Zhang, Songyou Peng, Boxin Shi, Marc Pollefeys, Zhaopeng Cui. DIST: 미분 가능 구면 추적을 사용한 딥 암묵적 부호 거리 함수 렌더링. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2020. [21] Lars Mescheder, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, Andreas Geiger. 점유 네트워크: 함수 공간에서 3D 재구성 학습. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2019. [22] Ben Mildenhall, Pratul P Srinivasan, Rodrigo Ortiz-Cayon, Nima Khademi Kalantari, Ravi Ramamoorthi, Ren Ng, Abhishek Kar. 로컬 라이트 필드 융합: 처방적 샘플링 지침을 사용한 실용적 뷰 합성. ACM 그래픽스 트랜잭션(TOG), 2019. [23] Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, Ren Ng. NeRF: 뷰 합성을 위한 신경 광도 필드로 장면 표현. 유럽 컴퓨터 비전 컨퍼런스의 진행 사항, 2020. [24] Thomas Neff, Pascal Stadlbauer, Mathias Parger, Andreas Kurz, Joerg H. Mueller, Chakravarty R. Alla Chaitanya, Anton S. Kaplanyan, Markus Steinberger. DONERF: Depth Oracle Networks를 사용한 컴팩트 신경 복사장의 실시간 렌더링을 향해. 컴퓨터 그래픽 포럼, 2021. [25] Michael Niemeyer, Lars Mescheder, Michael Oechsle, Andreas Geiger. 미분 가능한 체적 렌더링: 3D 감독 없이 암묵적 3D 표현 학습. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스의 진행 사항, 2020. [26] Ryutarou Ohbuchi, Akio Mukaiyama, Shigeo Takahashi. 3D 모양에 워터마킹을 하는 주파수 영역 접근 방식. Computer Graphics Forum, 2002. [27] Jeong Joon Park, Peter Florence, Julian Straub, Richard Newcombe, Steven Lovegrove. DeepSDF: 모양 표현을 위한 연속 부호 거리 함수 학습. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2019. [28] Songyou Peng, Michael Niemeyer, Lars Mescheder, Marc Pollefeys, Andreas Geiger. 합성곱 점유 네트워크. 유럽 컴퓨터 비전 컨퍼런스 회의록, 2020. [29] Emil Praun, Hugues Hoppe, Adam Finkelstein. 견고한 메시 워터마킹. 1999년 제26회 컴퓨터 그래픽 및 대화형 기술 연례 회의록.[30] Shunsuke Saito, Zeng Huang, Ryota Natsume, Shigeo Morishima, Angjoo Kanazawa, Hao Li.Pifu: 고해상도 옷을 입은 인간 디지털화를 위한 픽셀 정렬 암시적 함수.IEEE/CVF 컴퓨터 비전 국제 회의록, 2019.[31] Katja Schwarz, Yiyi Liao, Michael Niemeyer, Andreas Geiger.GRAF: 3D 인식 이미지 합성을 위한 생성적 광도장.신경 정보 처리 시스템의 발전, 2020.[32] Vincent Sitzmann, Michael Zollhöfer, Gordon Wetzstein.장면 표현 네트워크: 연속적인 3D 구조 인식 신경 장면 표현. 신경 정보 처리 시스템의 발전, 2019. [33] Jeongho Son, Dongkyu Kim, Hak-Yeol Choi, Han-Ul Jang, Sunghee Choi. 메시 돌출성을 이용한 지각적 3D 워터마킹. 국제 정보 과학 및 응용 컨퍼런스, 2017. [34] Matthew Tancik, Ben Mildenhall, Ren Ng. Stegastamp: 실제 사진의 보이지 않는 하이퍼링크. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2020. [35] RG van Schyndel, AZ Tirkel, CF Osborne. 디지털 워터마크. 제1회 국제 영상 처리 컨퍼런스 회의록, 1994. [36] Can Wang, Ruixiang Jiang, Menglei Chai, Mingming He, Dongdong Chen, Jing Liao. NeRF-Art: 텍스트 기반 신경 광도 필드 스타일화. arXiv 사전 인쇄본 arXiv:2212.08070, 2022. [37] Xinyu Weng, Yongzhi Li, Lu Chi 및 Yadong Mu. 시간적 잔여 모델링을 사용한 대용량 합성곱 비디오 스테가노그래피. 국제 멀티미디어 검색 컨퍼런스 회의록, 2019. [38] Eric Wengrowski 및 Kristin Dana. 심층 사진 스테가노그래피를 사용한 광장 메시징. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2019. [39] Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang 및 Jianxiong Xiao. 3D ShapeNets: 체적 모양에 대한 심층 표현. IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2015. [40] Yinghao Xu, Sida Peng, Ceyuan Yang, Yujun Shen, Bolei Zhou. 구조적 및 질감적 표현 학습을 통한 3D 인식 이미지 합성. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2022. [41] Peng Yang, Yingjie Lao, Ping Li. 2단계 최적화를 통한 딥 신경망을 위한 강력한 워터마킹. IEEE/CVF 컴퓨터 비전 국제 컨퍼런스 회의록, 2021. [42] Lior Yariv, Yoni Kasten, Dror Moran, Meirav Galun, Matan Atzmon, Basri Ronen, Yaron Lipman. 기하학과 모양을 풀어서 다중 뷰 신경 표면 재구성. 신경 정보 처리 시스템의 발전, 2020. [43] Innfarn Yoo, Huiwen Chang, Xiyang Luo, Ondrej Stava, Ce Liu, Peyman Milanfar, Feng Yang. 딥 3D-2D 워터마킹: 3D 메시에 메시지를 임베딩하고 2D 렌더링에서 추출. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2022. [44] Alex Yu, Vickie Ye, Matthew Tancik, Angjoo Kanazawa. PixelNeRF: 하나 또는 몇 개의 이미지에서 신경 광도장. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2021. [45] Chaoning Zhang, Philipp Benz, Adil Karjauv, Geng Sun, In So Kweon. Udh: 스테가노그래피, 워터마킹 및 라이트 필드 메시징을 위한 범용 딥 은닉. 신경 정보 처리 시스템의 발전, 2020. [46] Kevin Alex Zhang, Lei Xu, Alfredo Cuesta-Infante 및 Kalyan Veeramachaneni. 주의가 있는 견고한 보이지 않는 비디오 워터마킹. arXiv 사전 인쇄본 arXiv:1909.01285, 2019. [47] Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman 및 Oliver Wang. 지각적 지표로서 딥 피처의 비합리적인 효과. IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2018. [48] Chengxuan Zhu, Renjie Wan 및 Boxin Shi. 신경 전달 광도장. 신경 정보 처리 시스템의 발전, 2022. [49] Chengxuan Zhu, Renjie Wan, Yunkai Tang 및 Boxin Shi. 신경 광도장을 통한 폐색 없는 장면 복구. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2023. [50] Jiren Zhu, Russell Kaplan, Justin Johnson 및 Li Fei-Fei. HIDDEN: 딥 네트워크를 사용한 데이터 숨기기. 유럽 컴퓨터 비전 컨퍼런스 회의록, 2018.
