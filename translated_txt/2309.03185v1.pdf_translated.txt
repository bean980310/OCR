--- ABSTRACT ---
NeRF(Neural Radiance Fields)는 뷰 합성 및 깊이 추정과 같은 응용 분야에서 유망한 것으로 나타났지만, 다중 뷰 이미지에서 학습하는 것은 본질적인 불확실성에 직면합니다. 이를 정량화하는 현재의 방법은 휴리스틱하거나 계산적으로 까다롭습니다. 우리는 학습 프로세스를 수정하지 않고 사전 학습된 NeRF의 불확실성을 평가하는 사후 프레임워크인 베이즈 레이를 소개합니다. 우리의 방법은 공간적 섭동과 베이지안 라플라스 근사를 사용하여 체적 불확실성 필드를 설정합니다. 우리는 통계적으로 알고리즘을 도출하고 주요 지표와 응용 분야에서 뛰어난 성능을 보여줍니다. 추가 결과는 https://bayesrays.github.io에서 확인할 수 있습니다. 1.
--- INTRODUCTION ---
Neural Radiance Fields(NeRFs)는 새로운 뷰 합성 및 깊이 추정과 같은 응용 분야에서 성공하면서 인기가 폭발적으로 증가한 학습된 체적 암묵적 장면 표현의 한 종류입니다.다중 뷰 이미지의 이산 세트에서 NERF를 학습하는 과정은 불확실성으로 인해 어려움을 겪습니다.완벽한 실험 조건에서도 폐색 및 누락된 뷰는 모델이 장면에 대해 얻을 수 있는 인식적 지식을 제한합니다.NeRF의 인식적 불확실성을 연구하는 것은 이상치 탐지[21] 및 차선책 뷰 계획[31]과 같은 작업에 기본이 되며, 이는 NeRF의 성능과 응용 분야를 자율 주행[11]과 같은 중요한 영역으로 확장합니다.그러나 NeRF 모델에 포함된 불확실성을 정량화하는 것은 비교적 새로운 연구 분야이며, 기존 방법은 이론적 보장이 없는 휴리스틱 프록시[14, 58] 또는 비용이 많이 드는 계산 능력[47] 및/또는 기존 NeRF 학습 파이프라인에 대한 정교한 변경이 필요한 확률적 기술을 제안합니다[41, 42]. 우리는 고전적 사진측량법[45]의 삼각 측량 문제에서 영감을 얻었습니다. 여기서 불확실성은 종종 이미지 공간에서 특징점 위치의 분포를 통해 모델링되고, 그런 다음 3D로 투영됩니다(그림 2 참조). 직관적으로 이 분포는 다중 뷰 일관성을 유지하면서 특징의 위치가 얼마나 교란될 수 있는지 측정합니다. 우리는 NeRF에 비슷한 직관을 적용하여 재구성 손실에 최소한의 영향을 미치면서 공간적으로 교란될 수 있는 광도장의 영역을 식별합니다. 전통적 사진측량법 OO 우리의 NeRF 불확실성 그림 2. 고전적 사진측량법(왼쪽)의 불확실성 정량화에서 영감을 얻어 NeRF(오른쪽)에서 인식적 불확실성을 발견했습니다. 우리는 임의의 사전 학습된 NeRF의 불확실성을 정량화하기 위한 사후 프레임워크인 BayesRays를 제안합니다. 주어진 NeRF에서 사용 중인 아키텍처와 관계없이, 학습 파이프라인을 변경할 필요 없이(그림 3 참조), 저희 방법은 공간적으로 매개변수화된 광도장의 섭동을 시뮬레이션하고 베이지안 라플라스 근사를 사용하여 추가 색상 채널처럼 렌더링할 수 있는 체적 불확실성장을 생성합니다. 이 작업에서 저희는 계산된 불확실성이 통계적으로 의미가 있을 뿐만 아니라 재구성된 깊이 오류와의 상관관계와 같은 주요 지표에서 이전 작업보다 성능이 우수하다는 것을 보여줍니다. 나아가 NeRF에서 플로터 아티팩트를 제거하거나 최신 기술을 일치시키거나 개선하는 것과 같은 중요한 응용 프로그램을 위한 프레임워크를 제공합니다(그림 1 참조). 요약하자면, 저희의 주요 기여는 다음과 같습니다. • 저희는 사전 학습된 신경 광도장의 불확실성을 아키텍처와 독립적으로 정량화하고 학습 이미지나 비용이 많이 드는 추가 학습이 필요하지 않은 플러그 앤 플레이 확률적 방법을 소개합니다. • 1분 남짓 만에 추가 색상 채널로 렌더링할 수 있는 공간 불확실성장을 계산합니다. • 우리는 사전에 훈련된 NeRF에서 실시간으로 대화형으로 아티팩트를 제거하기 위해 불확실성 필드에 임계값을 설정하는 것을 제안합니다. 2.
--- RELATED WORK ---
불확실성 정량화는 측정 가능한 입력 변수 집합에 따라 조건화된 시스템의 응답 분포를 연구합니다[43]. 통계 분야로서 물리학[13], 화학[39] 또는 기상학[30]과 같은 분야에서 과학적 예측의 정확도를 측정해야 할 필요성에서 수십 년에 걸쳐 성장했습니다. 컴퓨터 비전의 불확실성. 우리의 응용 프로그램에 더 가깝게, 컴퓨터 비전 시스템의 불확실성을 추정하는 것은 딥 러닝 혁명이 일어나기 훨씬 전부터 연구 주제였습니다. 예를 들어, 동작으로부터의 구조와 번들 조정[45, 섹션 11.4][51]에서 말입니다. 이러한 고전적 사진 측량법의 문제에서 장면 기하학과 카메라 매개변수는 불확실성으로 가득 찬 프로세스[46, 54]에서 공동으로 최적화되며, 종종 3D로 투영된 2D 이미지 공간 가우시안을 통해 모델링됩니다[8, 26, 45, 51](그림 2 참조). 딥 러닝의 불확실성. 신경망을 관찰된 데이터에 맞추는 프로세스에는 일반적으로 근본적으로 다른 두 가지 불확실성 소스가 포함됩니다[1, 17]. 우연적 불확실성은 데이터에 포함된 내재적 무작위성(예: 계측 오류 또는 통제되지 않은 영향으로 인해)을 나타내며 종종 하나의 함수가 아닌 매개변수 분포(예: 가우시안)를 데이터에 맞춰서 포착합니다[4, 17, 25]. 반면, 인식적 불확실성은 모델이 복제하려는 시스템에 대한 지식이 부족한 것을 정량화합니다.예를 들어, 누락된 데이터로 인해 발생합니다.일반적으로 이는 Train Mip NeRF &#39;Nerfacto Instant NGP의 사후 분포를 추정하는 베이지안 프레임워크를 통해 달성됩니다.아키텍처에 독립적인 불확실성 정량화 그림 3. 다양한 NeRF 아키텍처에 적용된 BayesRays. &quot;Lego&quot;[24]는 좌반구에 있는 카메라로만 학습되었습니다.관찰된 데이터가 주어진 모델입니다. 이를 달성하는 가장 간단하면서도 비싼 방법은 동일한 데이터에서 여러 동일하지만 다르게 초기화된 네트워크를 학습한 후 최적화된 매개변수의 차이를 정량화하는 딥 앙상블을 사용하는 것입니다[19, 57].앙상블에 대한 인기 있는 대안은 각 네트워크 매개변수를 각 학습 반복에서 샘플링하고 KL 손실을 통해 조정하여 진정한 모델 사후 모델을 근사하는 독립적인 분포로 모델링하는 변형 베이지안 신경망입니다[9, 28].학습 파이프라인에 대한 이러한 중요한 변경에는 계산 비용이 수반되며, 최근 연구에서는 파생 정보를 사용하여 이미 학습된 값 근처에서 네트워크 가중치 사후 모델만 추정하는 사후 라플라스 근사(컴퓨터 비전 애플리케이션의 경우 [12, 37] 또는 [50] 참조)를 사용하여 이를 우회하는 것이 제안되었습니다.신경 광도장의 불확실성.NeRF[23]는 여러 카메라 뷰에서 생성된 이미지와 일치하도록 최적화된 신경 체적 인코딩을 통해 3D 장면을 나타냅니다. 이 과정에서 우연적 불확실성은 장면에 순간적인 물체가 존재하거나 조명과 카메라 사양이 변경됨으로써 나타납니다.이러한 현상은 선구적인 작업인 NeRF-W [22]와 이후의 후속 작업 [16, 31, 35]에서 표준 우연적 딥 러닝 기술 [1]과 학습된 모양 잠재 임베딩 [10]을 결합하여 정량화합니다.특히, 우리는 종종 폐색, 모호성 및 제한된 카메라 뷰로 인해 데이터가 누락되는 신경 복사장의 인식적 불확실성에 관심을 갖습니다.이 불확실성을 정량화하기 위한 일반적인 딥 러닝 기술 중 다수가 NeRF에 적용되었지만 성공률은 제한적입니다.[47]과 같은 연구에서는 앙상블 학습을 통한 불확실성 추정을 제안하는데, 이는 시간과 메모리를 많이 소모할 수 있습니다.Shen et al. [41]과 그 후속 [42]은 변형 추론과 KL 발산 최적화를 통해 문제를 모델링하는데, 그 원리는 크게 다르지 않지만 표준 변형 베이지안 신경망보다 더 뛰어난 것으로 나타났습니다.
--- METHOD ---
영어: 추가 학습이 필요 없으며 가려지거나 불완전한 데이터로 인해 발생하는 NeRF 아티팩트를 정리하는 데 사용할 수 있습니다.초록 신경 복사장(NeRF)은 뷰 합성 및 깊이 추정과 같은 응용 프로그램에서 유망한 것으로 나타났지만 다중 뷰 이미지에서 학습하는 것은 본질적인 불확실성에 직면합니다.현재 이를 정량화하는 방법은 휴리스틱하거나 계산적으로 까다롭습니다.학습 프로세스를 수정하지 않고 사전 학습된 NeRF의 불확실성을 평가하는 사후 프레임워크인 베이즈 레이를 소개합니다.저희 방법은 공간 섭동과 베이지안 라플라스 근사를 사용하여 체적 불확실성장을 설정합니다.저희는 알고리즘을 통계적으로 도출하고 주요 지표와 응용 프로그램에서 뛰어난 성능을 보여줍니다.추가 결과는 https://bayesrays.github.io에서 확인할 수 있습니다.1. 소개 신경 복사장(NeRF)은 새로운 뷰 합성 및 깊이 추정과 같은 응용 프로그램에서 성공하여 인기가 폭발적으로 증가한 학습된 체적 암묵적 장면 표현 클래스입니다. 다중 뷰 이미지의 개별 세트에서 NERF를 학습하는 프로세스는 불확실성으로 인해 어려움을 겪습니다. 완벽한 경우에도 마찬가지입니다.
--- EXPERIMENT ---
모든 조건, 폐색 및 누락된 뷰는 모델이 장면에 대해 얻을 수 있는 인식적 지식을 제한합니다.NeRF의 인식적 불확실성을 연구하는 것은 이상치 탐지[21] 및 다음 최적 뷰 계획[31]과 같은 작업에 기본이 되며, 이는 NeRF의 성능과 응용 분야를 자율 주행[11]과 같은 중요한 영역으로 확장합니다.그러나 NeRF 모델에 포함된 불확실성을 정량화하는 것은 비교적 새로운 연구 분야이며, 기존 방법은 이론적 보장이 없는 휴리스틱 프록시[14, 58] 또는 비용이 많이 드는 계산 능력[47] 및/또는 기존 NeRF 학습 파이프라인에 대한 정교한 변경이 필요한 확률적 기술을 제안합니다[41, 42].우리는 고전적 사진 측량[45]의 삼각 측량 문제에서 영감을 얻었는데, 여기서 불확실성은 종종 이미지 공간에서 특징점 위치의 분포를 통해 모델링되어 3D로 투영됩니다(그림 2 참조).직관적으로 이 분포는 다중 뷰 일관성을 유지하면서 특징의 위치를 얼마나 교란할 수 있는지 측정합니다. 우리는 NeRF에 비슷한 직관을 적용하여 재구성 손실에 최소한의 영향을 미치면서 공간적으로 교란될 수 있는 광도장 영역을 식별합니다.전통적인 사진 측량법 OO 우리의 NeRF 불확실성그림 2. 고전적 사진 측량법(왼쪽)의 불확실성 정량화에서 영감을 받아 NeRF에서 인식적 불확실성을 발견했습니다(오른쪽).우리는 임의의 사전 학습된 NeRF의 불확실성을 정량화하기 위한 사후 프레임워크인 BayesRays를 제안합니다.학습 파이프라인을 변경하지 않고 주어진 NeRF에서 사용 중인 아키텍처와 관계없이(그림 3 참조), 우리의 방법은 광도장의 공간적으로 매개변수화된 교란을 시뮬레이션하고 베이지안 라플라스 근사를 사용하여 추가 색상 채널처럼 렌더링할 수 있는 체적 불확실성장을 생성합니다.이 작업에서 우리는 계산된 불확실성이 통계적으로 의미가 있을 뿐만 아니라 재구성된 깊이 오류와의 상관 관계와 같은 주요 지표에 대한 이전 작업보다 성능이 우수함을 보여줍니다. 또한 NeRF에서 플로터 아티팩트를 제거하고 최신 기술을 일치시키거나 개선하는 것과 같은 중요한 애플리케이션을 위한 프레임워크를 제공합니다(그림 1 참조).요약하면, 우리의 주요 기여는 다음과 같습니다.• 우리는 아키텍처와 독립적으로 사전 훈련된 신경 복사장의 불확실성을 정량화하는 플러그 앤 플레이 확률적 방법을 소개하며, 훈련 이미지나 비용이 많이 드는 추가 훈련이 필요하지 않습니다.• 1분 남짓 만에 추가 색상 채널로 렌더링할 수 있는 공간 불확실성 필드를 계산합니다.• 우리는 불확실성 필드에 임계값을 설정하여 실시간으로 대화형으로 사전 훈련된 NeRF에서 아티팩트를 제거할 것을 제안합니다.2. 관련 연구 불확실성 정량화는 측정 가능한 입력 변수 집합에 따라 조건화된 시스템의 응답 분포를 연구합니다[43]. 통계 분야로서 물리학[13], 화학[39] 또는 기상학[30]과 같은 분야에서 과학적 예측의 정확도를 측정해야 할 필요성에서 수십 년에 걸쳐 성장했습니다.컴퓨터 비전의 불확실성. 영어: 우리의 응용 프로그램에 더 가깝게, 컴퓨터 비전 시스템의 불확실성을 추정하는 것은 딥 러닝 혁명이 일어나기 훨씬 전부터 연구 주제였습니다.예를 들어, Structure from Motion and Bundle Adjustment[45, Section 11.4][51]에서 말입니다.이러한 고전적 사진측량법의 문제에서 장면 기하학과 카메라 매개변수는 불확실성으로 가득 찬 프로세스[46, 54]에서 공동으로 최적화되며, 이는 종종 3D로 투영된 2D 이미지 공간 가우시안을 통해 모델링됩니다[8, 26, 45, 51](그림 2 참조).딥 러닝의 불확실성.신경망을 관찰된 데이터에 맞추는 프로세스에는 일반적으로 근본적으로 다른 두 가지 불확실성 소스가 포함됩니다[1, 17].우연적 불확실성은 데이터에 포함된 내재적 무작위성(예: 계측 오류 또는 통제되지 않은 영향으로 인해)을 말하며, 종종 하나의 함수가 아닌 매개변수 분포(예: 가우시안)를 데이터에 맞춰서 포착합니다[4, 17, 25]. 반면, 인식적 불확실성은 모델이 복제하려는 시스템에 대한 지식의 부족을 정량화합니다.예를 들어, 누락된 데이터 때문입니다.일반적으로 이는 관찰된 데이터가 주어진 Train Mip NeRF &#39;Nerfacto Instant NGP 모델의 사후 분포를 추정하는 베이지안 프레임워크를 통해 달성됩니다.그림 3. 다양한 NeRF 아키텍처에 적용된 BayesRays. &quot;Lego&quot;[24]는 좌반구에만 카메라를 설치하여 학습했습니다.이를 달성하는 가장 간단하면서도 비싼 방법은 동일한 데이터에서 여러 동일하지만 다르게 초기화된 네트워크를 학습한 후 최적화된 매개변수의 차이를 정량화하는 딥 앙상블을 사용하는 것입니다[19, 57].앙상블에 대한 인기 있는 대안은 각 네트워크 매개변수를 각 학습 반복에서 샘플링하고 KL 손실을 통해 조정하여 진정한 모델 사후 분포를 근사하는 독립적인 분포로 모델링하는 변형 베이지안 신경망입니다[9, 28]. 학습 파이프라인에 대한 이러한 중요한 변경은 계산 비용이 수반되며, 최근 연구에서는 파생 정보를 사용하여 이미 학습된 값 근처에서 네트워크 가중치 사후만을 추정하는 사후 라플라스 근사(컴퓨터 비전 애플리케이션의 경우 [12, 37] 또는 [50] 참조)를 사용하여 이를 우회하는 것이 제안되었습니다.신경 광도장의 불확실성.NeRF[23]는 여러 카메라 뷰에서 생성된 이미지와 일치하도록 최적화된 신경 체적 인코딩을 통해 3D 장면을 나타냅니다.이 과정에서는 장면에 일시적인 객체가 존재하거나 조명과 카메라 사양이 변경되어 우연적 불확실성이 나타납니다.이러한 현상은 선구적인 작업인 NeRF-W[22]와 이후의 후속 작업[16, 31, 35]에서 표준 우연적 딥 러닝 기술[1]과 학습된 모양 잠재 임베딩[10]을 결합하여 정량화합니다. 특히, 우리는 종종 폐색, 모호성 및 제한된 카메라 뷰로 인해 누락된 데이터인 신경 복사장의 인식적 불확실성에 관심을 둡니다. 이 불확실성을 정량화하기 위한 일반적인 딥 러닝 기술 중 다수가 NeRF에 적용되었지만 성공률은 제한적입니다. [47]과 같은 연구는 앙상블 학습을 통한 불확실성 추정을 제안하는데, 이는 시간과 메모리를 많이 소모할 수 있습니다. Shen et al. [41]과 그 후속 연구 [42]는 변분 추론과 KL 발산 최적화를 통해 문제를 모델링하는데, 이는 원리적으로 크게 다르지 않지만 표준 변분 베이지안 신경망보다 우수한 것으로 나타났습니다. 이러한 모든 방법은 NeRF 학습 파이프라인에 복잡한 변경이 필요합니다. 이와 대조적으로, 우리는 NeRF 불확실성 정량화를 위해 라플라스 근사를 사용할 수 있게 해주는 최초의 프레임워크인 BayesRays를 소개하고, 변분 최적화를 피하며, 따라서 임의의 파이프라인의 사전 학습된 NeRF에 적용할 수 있습니다. 영어: 기존의 딥 러닝 불확실성 정량화 프레임워크에서 벗어나 다른 연구에서는 불확실성에 NeRF 특정 프록시를 사용하는 것을 제안합니다.예를 들어, Zhan et al. [58]은 NeRF 모델에서 광선 종료의 엔트로피로 불확실성을 계산하는 것을 제안합니다.높은 엔트로피는 고체 물체를 모델링할 때 불확실성의 좋은 지표가 될 수 있지만, [7]에서 제안된 왜곡 손실과 같은 밀도 정규화기를 사용하는 동안 이러한 가정은 실패할 수 있습니다.Hoffman et al. [14]은 부분 관찰에 따라 조건화될 때 생성 모델에서 생성된 장면의 분산으로 불확실성을 정량화하는 것을 제안하며, 특정 모델의 사전에 크게 의존합니다.다른 관련 연구.4장에서 보여 주듯이, 불확실성 정량화는 훈련된 NeRF의 섭동에 대한 민감도에 의존하는데, 이 개념은 최근 Yan et al. [55]의 미공개 사전 인쇄본에서 NeRF 외부의 응용 프로그램과 지속적인 학습 프레임워크를 통해 탐구되었습니다. 우리 방법을 계산적으로 다루기 쉽고 아키텍처에 독립적으로 만들기 위해 [32, 33]에서 제안한 것과 유사한 공간 변형 필드를 도입하지만, 대신 불확실성을 정량화하기 위한 라플라스 근사를 수행할 NeRF 모델의 재매개변수화로 해석합니다.우리가 출력 공간 불확실성 필드에 대해 제안하는 많은 용도 중 하나는 일반적인 공간 NeRF 아티팩트를 피하는 것입니다.정규화자를 추가하여 훈련 시간에 최적화를 변경하는 대신 [7, 29, 34, 36], 사후 처리 단계에서 사전 훈련된 NeRF에서 이를 제거하는 것을 제안합니다.이 작업은 최근 Nerfbusters [52]와 같은 확산 기반 작업에서 해결했습니다.섹션 5에서 보여 주듯이 우리 알고리즘은 추가 훈련이 필요하지 않고 더 일반적이면서도 이 특정 응용 프로그램에서 Nerfbusters의 성능과 일치하거나 향상됩니다.3. 배경 우리는 사전 훈련된 NeRF의 인식적 불확실성을 정량화하기 위해 라플라스 근사를 적용하기 위한 일반적인 프레임워크를 제안합니다. 우리는 이 두 개념을 순진하게 결합하려고 할 때 마주치는 어려움을 살펴보기 전에 두 개념을 간략히 검토할 것이며, 이것이 4.3.1절에 기술된 섭동 기반 접근 방식의 동기가 됩니다. 신경 광도장 기존 NeRF[23]는 3D 공간의 각 지점을 뷰 종속 광도와 뷰 독립 밀도 값에 매핑하는 방법을 학습합니다.센추리 피카츄 꽃 기본 Nerfacto 불확실성 우리의 Nerfbusters 방법 Nerfacto(기본) Nerfbusters PSNR ↑ SSIM↑ LPIPS↓ 적용 범위 ↑ 16.0.0.0.17.0.0.0.Bayes Rays-0.17.0.0.0.Bayes Rays-0.17.0.0.0.Bayes Rays-best 18.0.0.0.그림 4. 우리는 계산된 불확실성을 기반으로 임계값을 설정하여 학습된 장면을 정리하고 훨씬 낮은 계산 및 메모리 비용으로 최신 기술과 일치하거나 능가하는 것을 제안합니다.여기서 &gt;는 신경 필드에서 학습할 수 있는 매개변수를 나타냅니다. 이미지의 각 픽셀 색상은 볼륨 렌더링[48]을 사용하여 광선 r = or + t dr을 따라 일련의 점 {t}의 밀도와 색상을 합성하여 렌더링할 수 있습니다.Σαν - Σ) Co (r) = Σ expΣ Tj dj (1-exp(-Tidi))Ci, (2) 여기서 S는 각 연속 점 쌍 사이의 거리를 나타냅니다.네트워크 매개변수는 학습 세트 이미지 I = {I}0의 이미지 In에서 샘플링한 각 광선 r에 대한 예측 색상 C(r)과 기준 진실 Cº 사이의 제곱 거리로 정의된 재구성 손실을 최소화하도록 최적화됩니다. 베이지안 관점에서 이는 가우시안 가능도 p(C4|4) ~ N(C, 1/2)를 가정하고 사후 분포 N*의 모드인 *를 찾는 것과 같습니다.= arg max p(T) &amp; (3) 이는 베이즈 법칙에 따라 음의 로그 가능도 c4(x,d), T$(x) = R(x, d; ø) (1)* = arg min E¿ Er~I || Cø (r) – Cgt (r) || (4) 3.2. 신경 라플라스 근사 어떤 데이터 I에 대해 학습된 신경망의 인식적 불확실성을 정량화하기 위한 일반적인 전략은 데이터 p(0|I)에 따라 네트워크 매개변수 0의 사후 분포를 연구하는 것입니다. 영어: 이 분포를 추정하기 위해 베이즈 규칙과 변분 최적화를 사용하는 것을 제안하는 변분 베이지안 신경망과 대조적으로, 라플라스 근사[12, 37]는 수렴할 때까지 기존의 수단으로 네트워크를 간단히 학습하는 것에 의존합니다.즉, 가장 가능성 있는 네트워크 가중치 0* – p(0|I)의 모드를 얻는 것에 의존합니다.그런 다음 사후분포는 얻은 모드 p(0|I) ~ N(0*, Σ)를 중심으로 하는 다변량 가우시안 분포로 근사됩니다.이 분포의 공분산 Σ는 0*에 대한 음의 로그 가능도 h(0) = log p(0|1)의 2차 테일러 확장을 통해 계산됩니다.h(0) ≈ h(0*) + (0—0*)˜H(0*) (0–0*), (5) 여기서 0*가 h(0)의 최대값이고 H(0*)가 0*에서 평가된 h(0)의 2차 도함수의 헤시안 행렬이므로 1차 항은 삭제됩니다. 방정식의 항을 N(0*, Σ)의 일반적인 로그 제곱 지수 가우시안 가능도로 식별하면 Σ = − H(0*)¯¹ (6)을 얻습니다.안타깝게도, ¤를 ☀로 식별하여 NeRF에 이 프레임워크를 순진하게 적용하는 것은 세 가지 치명적인 결함이 있기 때문에 비실용적입니다.• • • 첫째, 섹션 4.4에서 보여주듯이 NeRF의 매개변수는 서로 강력하게 상관되어 있어 비용이 많이 드는 역전 단계를 수행하기 전에 네트워크 가중치 수와 차원이 일치하는 (잠재적으로 완전하거나 적어도 블록-) 밀집 행렬인 H의 모든 항목을 계산(및 저장)하지 않고는 사후 분포를 어떠한 보장도 없이 정확하게 추정하기 어렵습니다.둘째, Σ를 완벽하게 계산하더라도 매개변수 상관관계와 네트워크 비선형성으로 인해 이 분포를 밀도 또는 픽셀 값에 대한 분포와 같은 기하학적으로 의미 있는 분포로 옮기려면 전체 N(*, Σ)에서 반복적이고 비용이 많이 드는 샘플을 추출해야 합니다. 마지막으로, 계산적 제약을 넘어 NeRF 매개변수에 대한 불확실성을 직접 추정하려면 알고리즘이 사용된 특정 내부 NeRF 아키텍처에 대한 지식(그리고 잠재적으로 이에 대한 종속성)을 가져야 합니다. 아래에서 라플라스 근사를 수행할 매개변수 섭동 필드를 도입하여 이러한 모든 문제를 해결합니다. 알고리즘은 사용된 특정 NeRF 아키텍처와 완전히 독립적이며 매개변수 간의 최소한의 상관 관계를 보장할 수 있으므로 분포 샘플을 그릴 필요 없이 의미 있는 공간 불확실성 필드를 계산할 수 있습니다. 4. 방법 입력으로, 광도 함수 c, 밀도 7 및 최적화된 매개변수 *와 N개의 학습 이미지에 해당하는 기준 진실 카메라 매개변수 {T}를 갖는 사전 학습된 광도 필드 R이 주어진다고 가정합니다. 이 방법은 R의 특정 아키텍처에 대한 가정을 하지 않으며 학습된 밀도 76* 및 광도 co*를 생성하는 임의의 프레임워크에 맞게 설계되었으며, 이를 미분 가능한 블랙박스로 취급합니다. 우리는 신경망 가중치 &amp;가 훈련 중에 R의 유용한 매개변수화로 사용될 수 있지만, 분포 p(0|Z)의 모드를 아는 한 모든 매개변수 집합 0 € ☺에 대한 모든 재매개변수화 Re에 라플라스 근사를 공식화할 수 있다는 점에 주목하면서 시작합니다. 우리는 NeRF 자체의 핵심 통찰력에서 영감을 얻습니다. 즉, 체적 필드를 통해 3D 장면을 명시적으로 모델링함으로써 2D 작업에서도 인상적인 성능을 얻을 수 있다는 것입니다. 또한 컴퓨터 그래픽에서 영감을 얻습니다. 컴퓨터 그래픽에서는 전역적 체적 변형 필드가 암묵적으로 표현된 객체를 조작하기 위한 도구로 제안되었습니다[40, 44]. 마지막으로 사진 측량에서 영감을 얻습니다. 사진 측량에서는 재구성 불확실성이 종종 식별된 특징점의 공간적 위치에 가우시안 분포를 배치하여 모델링됩니다(그림 2 참조). 4.1. 직관 재매개변수화의 직관은 삽화에 표시된 간단한 장면에서 더 잘 볼 수 있습니다. 2D 평면에 녹색 중심이 포함된 단일 솔리드 블루 세그먼트를 고려합니다. 이 물체가 60도 원뿔 모양으로 광선을 포착하는 두 대의 단순화된 카메라에 의해 관찰된다고 가정하고, 이제 이 작은 데이터 세트에 명시된 NeRF 재구성 문제를 고려해 보겠습니다. &quot;완벽한&quot; 재구성 사소하게도, 이 문제는 미확정된 것입니다. 삽화에서 볼 수 있듯이, 녹색 세그먼트는 여러 가능한 곡선으로 대체될 수 있지만, 데이터 세트의 4개 픽셀에 따르면 &quot;완벽한&quot; 광도 재구성이 가능합니다. 실제로 재구성 손실에 영향을 미치지 않고 녹색 세그먼트를 교란할 수 있는 솔루션의 전체 널 공간(녹색 음영 영역)이 있으며, 이 데이터 세트에서 학습된 NeRF는 학습 시드에 따라 이러한 구성 중 하나로 수렴할 수 있습니다. 따라서 &quot;재구성 정확도를 해치지 않고 얼마나 교란할 수 있는가?&quot;라는 질문을 통해 학습된 NeRF의 불확실성을 정량화할 수 있습니다. &#39;참고로 이것은 섹션 1에서 논의된 사진측량법의 근거리/원거리 삼각 측량의 조건 번호와 유사합니다.중요하게도 이 양은 공간적으로 다양합니다.공간의 일부 영역은 훈련 세트에 의해 더 제한을 받고 손실에 불리한 덜 불확실한 영향을 미치기 전에 제한된 섭동만 허용합니다(예: 세그먼트의 가장자리, 인셋의 주황색).반면 다른 영역은 훨씬 더 불확실합니다(예: 세그먼트의 중간, 인셋의 보라색).따라서 &quot;재구성 정확도를 해치지 않고 어떤 영역을 섭동시킬 수 있습니까?&quot;라고 묻는 것으로 훈련된 NeRF의 공간적 불확실성을 정량화할 수 있습니다. 앞면 이 양은 단순한 교훈적 예를 넘어서 도움이 될 것입니다. 실제로, 삽화에 있는 것과 같은 일반적인 3D 장면조차도 모든 훈련 카메라 뷰에서 픽셀 단위로 완벽하게 재구성된 것처럼 보일 수 있습니다(이 경우, 우리는 노트북의 40개 앞면과 뒷면 뷰로 30,000개 에포크 동안 Nerfacto[49] 모델을 훈련했습니다). 그러나 다른 각도에서 볼 때 큰 기하학적 아티팩트가 드러납니다. 4.2. 섭동 모델링 위의 모든 고려 사항에서 영감을 얻어, NeRF 네트워크 전에 입력 좌표에서 실행되는 블록으로 해석할 수 있는 변형 필드 D : RD → RD를 도입합니다. 우리는 길이가 M인 그리드의 정점에 저장된 벡터 변위의 형태로 공간적으로 의미 있는 매개변수화를 선택하여 0을 행렬 ЄRMD XD로 표현하고 삼선형 보간 De(x) = Trilinear(x, 0)을 통해 모든 공간 좌표에 대한 변형을 정의합니다. 그림 5. 매우 낮은 해상도는 불확실성을 과소평가하게 만들 수 있으며, M &gt; 256의 경우 수익이 감소합니다.그리고 음의 로그 가능도 h(0)이 h(0) = EnEr~1„ || Če(r) – Cgt (r)||| + \||0||² . = = (10)인 사후 p(0|I)를 공식화합니다.(10)의 최소값은 0 = 0일 때 얻어야 합니다.이 경우 70(x) To* (x), čo (x) Co* (x, d)이고 따라서 Čo(r) = Cô(r)입니다.따라서 0은 분포 p(0|I)의 모드이고 마침내 0* 0 주변의 라플라스 근사에 대한 이상적인 조건에 있게 됩니다.Sec.에 따라 3.2, 이 결과는 ~ N(0, Σ) 분포를 나타냅니다. 여기서 = Σ = -H(0)=(11)이고, 여기서 H는 h(0)의 2차 도함수의 헤시안 행렬로 0에서 평가됩니다. 이러한 2차 도함수를 계산하는 것은 계산 집약적인 작업이지만, 아래에서 보여드리듯이 통계적 도구와 NeRF 전용 도구를 결합하면 1차 도함수만으로 근사할 수 있습니다. 4.3. H 근사화 통계적 분포 pe의 매개변수 패밀리에 대해 매개변수에 대한 로그 가능도의 헤시안은 Fisher 정보로도 알려져 있습니다.(7) I(0) = -Ex~pe 20] Ꮎ = -H(0), (12) 이제 이미 최적화된 NeRF 신경망을 적용하기 전에 각 좌표 x를 교란하여 광도장 R을 0으로 다시 매개변수화할 수 있습니다.[ð²h(X; 0)] 이는 (합리적인 정규성 가정 하에) 매개변수 점수의 분산으로도 정의할 수 있습니다.[20, 5.3] TI(0) = Ex~pe 70(x) = To* (x + Do(x)), čo (x) = C++ (x + De(x), d), (8) Əh(X; 0) ǝh(X; 0) ae Ꮎ (13) (9) 예측된 픽셀 색상이 생성됩니다. 이제 난수 쌍을 다음과 같이 표시하겠습니다. 변수는 광선과 예측된 색상(r, y)에 대응하는데, 여기서 r ~ {In}이고 y = C(r)입니다. 우리의 경우 (13)은 Cale)-Σexp(-Σ5%) (= i Σjd; (1 exp(-ñidi)) či · j <i We proceed by assuming a likelihood of the same form as with the NeRF parametrization, Co|0 ~ N(C, ½). Under our assumption that * are the optimal parameters obtained from NeRF training, it would be unreasonable to expect any non-trivial deformation to decrease the reconstruction loss; thus, it makes sense to place a regularizing independent Gaussian prior 0 ~ N(0, -¹) on our new parameters which can easily be computed via backpropagation. 1(0) = E(r,y) [4 €o(r) Jø(r)˜Jø(r)] +where (r) is the ray residual error (14) €(r) = ||Ñø(r) – Cgt (r)||and Jo (r) is the Jacobian of first derivatives ace(r) Jø(r) (15)Further, as we typically do not have multiple observations of ray color for a single ray r, we can further simplify the above using the definition of conditional expectation 1(0) = Er [4 Eyr [€o(r)] Jø(r)˜Jø(r)] +2XI, (16) noting that Eyr [€ (r)] is nothing more than 1, the variance of our stated likelihood N(C¾, ½), 1(0) = Er [2 Jo(r)¯Jo(r)] +2\I. (17) Combining (17) with (12) and approximating the expectation via sampling of R rays, we have our final expression for H: H(0) ≈ // Jo(r) Jo(r) – 2XI, (18) r It is worth remarking that, while H contains in it all the information that we will need to quantify the epistemic uncertainty of the given radiance field, its computation in (18) does not explicitly rely on the data from the training images but only on information contained in the pre-trained model and the training camera parameters. 4.4. Spatial uncertainty H(o) H(0) We can now fully take advantage of our proposed reparametrization. First, since each vector entry in 0 corresponds to a vertex on our grid, its effect will be spatially limited to the cells containing it, making H(0) necessarily sparse and minimizing the number of correlated parameters (see inset, which compares the sparsity of H(0) to the that of an NeRF's MLP parameters ). In fact, thanks to this low number of correlations, we will proceed like Ritter et al. [37] and approximate Σ only through the diagonal entries of H: Σdiag Σ Je(r) Jo(r) + 2AI r = -(19) Secondly, by measuring the variance of our deformation field (intuitively, how much one could change the NeRF geometry without harming reconstruction quality), Σ critically encodes the spatial uncertainty of the radiance field. We can formalize this by considering the (root) diagonal entries of Σ, which define a marginal variance vector σ (σx, y, oz). Much like in the photogrammetry works discussed in Section 2 and Figure 2, at each grid vertex, σ defines a spatial ellipsoid within which it can be deformed to minimal reconstruction cost. The norm of this vector σ = ||0|| 2 is then a positive scalar that measures the local spatial uncertainty of the radiance field at each grid vertex. Through it, we can define our spatial uncertainty field U: R³ → R+ given by U(x) = Trilinear(x, σ), (20) which intuitively encodes how much the positioning of geometric region in our reconstruction can be trusted. Strictly speaking, as defined above, U measures the uncertainty at (1+Dė)¯¹ (x), not x; however, we note that these are equivalent for the trained NeRF for which Do* = 0. The uncertainty field U is the main output of our algorithm and serves to illustrate the success of our approach. It is a first-of-its-kind theoretically derivated spatial measure of uncertainty that can be computed on any NeRF architecture, without the need for additional training, expensive sampling or even access to the training images. We will now validate it experimentally and show potential applications. 5. Experiments & Applications We validate our theoretically-derived algorithm through our uncertainty field's correlation with the depth prediction error in a given NeRF (Section 5.1), show a prototypical application to a NeRF clean-up task (Section 5.2) and justify our parametric choices through ablation studies (Section 5.3). = Implementation. Unless specified otherwise, all NeRFs used throughout this paper use Nerfstudio's Nerfacto [49] as the base architecture and are pre-trained for 30,000 steps. We extract our uncertainty field U using 1,000 random batches of 4,096 rays each sampled from a scene's training cameras, with M 256 and = 10-4/M3, in a process that takes around 90 seconds on an NVIDIA RTX 6000. Once computed for a given scene, our derived uncertainty field conveniently functions as an additional color channel that can be volumetrically rendered in a form (and cost) analogous to the usual RGB. For visualization clarity, all our results use a logarithmic scale, rendering logu instead of U. 5.1. Uncertainty Evaluation – FiguresWe evaluate the estimated uncertainty of BayesRays by showing its correlation with the NeRF depth error. We choose the error in predicted depth as the best signal that conveys NeRF's unreliability in geometric prediction, as RGB error has been shown to not be representative of true uncertainty due to radiance accumulation and model biases [47]. Metric. We measure correlation through the Area Under Sparsification Error (AUSE) [5, 15]. The pixels in each test image are removed gradually ("sparsified") twice: first, according to their respective depth error; second, by their uncertainty measure. The difference between the Mean Absolute depth Error (AMAE) of the remaining pixels in both processes, at each stage, provides the sparsification curves. Data. In Figure 6, we use 4 ScanNet scenes (#0000-001, #0079-000, #0158-000, #0316-000) with groundtruth depths provided. Each scene employs 40 images split into 5 test and 35 train images, following NerfingMVS [53]. Additionally, we use 4 scenes from the Light Field dataset [56, 59] (torch, statue, basket, africa), with the same train-test split and pseudo-ground-truth depth map approach as CF-NeRF [42].AMAE 2.1.statue 1.0.AMAE 1.CF-NeRF 0.0.0.scene #CF-NeRF Ours Ensemble 0.Ours 0.Ensemble Most uncertain pixel 50% percentile Most certain Most uncertain pixel pixel 50% percentile Most certain pixel Scene africa basket statue torch ####Method Ensemble 0.0.0.0.0.0.0.0.CF-NeRF 0.0.0.0.0.0.0.0.Ours 0.0.0.0.0.0.0.0.Figure 6. The uncertainties computed with our algorithm on the ScanNet and Light Field dataset are significantly more calibrated to the real NeRF depth error than the previous state-of-the-art CF-NeRF [42], even matching the performance of extremely costly ensembles. Images are colored by uncertainty / depth error percentile instead of value to be comparable. Baselines. For Figure 6, we display sparsification curves derived from our uncertainty field, with the previous stateof-the-art CF-NeRF [42] and with the standard deviations obtained by the costly process of training an ensemble of ten identical yet differently seeded NeRFs. Next to each graph, we visualize the depth error together with the (ascending) per-pixels rank produced by each method (i.e., the ordering that produces the curves). It is worth noting that, unlike CF-NeRF [42], we do not measure disparity error due to its heightened sensitivity to low-range depth errors and significant underestimation of errors in distant points. Results. The results are consistent across Figure 6. BayesRays's uncertainty shows significant improvement in correlation with depth error compared to CF-NeRF [42], both quantitatively and qualitatively. Further, our uncertainty is extremely close to the standard deviation of a costly ensemble in both AUSE and sparsification plots, while requiring no additional trained NeRFs, saving time and memory. 5.2. NeRF Clean Up – Figures 1 andA common reconstruction artifact in NeRFs are "Floaters", often caused by a lack of information in training data. These inherently correspond to regions of high uncertainty; therefore, we propose removing them by thresholding the scene according to our uncertainty field U during rendering. In Figure 4, we compare our algorithm's performance to the current state of the art for post-hoc floater removal, Nerfbusters [52], which employs a 3D diffusion model and a "visibility mask" to guide additional training steps during which some floaters are removed. For our comparison, we use the same dataset proposed by Nerfbusters along with their proposed metric of Coverage, together with more common measures of image quality. An ideal clean-up would boost image quality while keeping pixel coverage high. When using fixed threshold values like 0.9 or 0.4, BayesRays obtains similar PSNR values to Nerfbusters while allowing for a higher coverage. If one selects the best possible threshold value for each scene out of ten equally spaced ones, BayesRays outperforms Nerfbusters in both PSNR and coverage. It is worth noting that BayesRays achieves with a significantly lower computational footprint: unlike Nerfbusters, we do not require storing and evaluating a 3D diffusion model, we are faster (96 seconds vs 20 minutes) by eliminating the need for additional training and we circumvent the use of a “visibility mask" altogether by storing all necessary information in our computed Hessian H. Our qualitative results in Figure 4 show that our method can filter floaters that are missed by Nerfbusters (Century), is not prone to sampling artifacts caused by floater removal (Flowers) and provides the parametric flexibility necessary to avoid over-filtering (Pikachu). 5.3. Algorithmic ablations – Figures 3, 5 andIn Section 4, we justified our introduction of the perturbation field D partly through the desire to make our algorithm independent to the specific NeRF architecture used. In Figure 3, we show that this is indeed the case, as we obtain qualitatively similar results for three representatively different architectures (Mip NeRF [6], Instant NGP [27] and Nerfacto [49]) on the "Lego" scene from the NeRF Synthetic dataset [24] with 60 training views from its left hemisphere.Inconsistent Floater Low Uncertainty Train Views Novel View RGB 0.Novel View Uncertainty Figure 7. BayesRays quantifies only epistemic uncertainty in NeRF and is thus unable to capture aleatoric effects like those stemming from training inconsistencies. This success introduces an algorithmic choice; namely, the discretization of the deformation field. In Section 4, we propose storing it in a uniform spatial grid of size M³ from which deformation values can be trilinearly interpolated. The value of M thus becomes an algorithmic parameter, which we explore for the same example in Figure 5. We find that surface uncertainty can be missed for small values of M, resulting in a generally more certain map that is only activated on points of very high uncertainty, with diminishing returns being obtained for larger, more costly M >256의 형태를 취합니다. 마지막으로, NeRF 아티팩트 제거에 대한 알고리즘의 주력 응용 프로그램에는 불확실성 임계값 형태의 매개변수 선택도 포함됩니다. 그림 8에서 볼 수 있듯이 이 매개변수를 줄이면 플로터가 많은 장면을 점진적으로 정리하여 대상 객체를 플로터 없이 깨끗하게 캡처할 수 있습니다. 불확실성 필드는 한 번만 계산하면 되므로 이 임계값이 Nerfstudio [49]와 같은 대화형 NeRF 설정에서 실시간 사용자 제어 역할을 할 수 있다고 제안합니다. 6.</i>
--- CONCLUSION ---
s 우리는 BayesRays를 소개했습니다.이 알고리즘은 아키텍처와 무관하게, 추가 학습 없이, 원래 학습 이미지에 대한 액세스 없이 훈련된 신경 복사장의 불확실성을 정량화하는 알고리즘입니다.우리의 알고리즘은 NeRF 깊이 오류와 의미 있게 상관 관계가 있고 NeRF 정리와 같은 애플리케이션에서 사용하기 위해 임계값을 설정할 수 있는 공간 불확실성 필드를 출력합니다.우리는 균일한 그리드를 사용하여 공간 변형 필드를 이산화하는데, 이는 기하학적 관심이 거의 없는 영역에서 높은 메모리 비용이 발생할 수 있습니다.향후 작업에서는 옥트리와 같은 더 복잡한 계층적 데이터 구조를 고려하여 성능을 크게 개선할 수 있습니다.별도로, 알고리즘 도출에서 우리는 (최소한의) 매개변수 간 상관 관계를 무시하고 H의 대각선에만 초점을 맞춥니다.향후 애플리케이션에서는 낮은 순위 행렬 분해를 통해 이를 포함해야 할 수 있습니다[2, 3].더 높은 수준에서, 우리 알고리즘의 명시된 목표는 종종 누락되거나 가려진 데이터를 통해 나타나는 NeRF의 인식적 불확실성만 포착하는 것입니다. 따라서 우리의 방법은 뷰 간의 노이즈나 불일치로 인해 발생하는 우연적 불확실성을 포착하지 못합니다(그림 7 참조). 우리는 NeRF 정리를 위한 0.8, 0.0.0.PSNR15.Uncertainty 임계값에 대한 현재 프레임워크와 우리의 작업을 결합할 것이라고 낙관하고 있습니다.14.% 적용 범위 그림 8. Nerfbusters 데이터 세트의 &quot;쓰레기&quot; 장면에서 NeRF 정리 작업에 대한 불확실성에 다른 임계값 적용 [52]. 가장 오른쪽 이미지(임계값=00)는 원본을 보여줍니다. [22, 38]과 같은 무작위 정량화는 NeRF의 모든 불확실성 소스에 대한 완전한 연구를 가져올 것입니다. 더 광범위하게, 우리의 알고리즘은 NeRF의 불확실성을 정량화하는 데 국한되며 다른 프레임워크로 간단히 변환할 수 없습니다. 그럼에도 불구하고, 우리는 3D 가우시안 스플래팅 [18]과 같은 최근의 공간 표현을 위해 유사한 변형 기반 라플라스 근사가 공식화되기를 기대합니다. 딥 러닝 혁명이 컴퓨터 비전 알고리즘을 성능과 점점 더 중요한 응용 분야의 새로운 지평으로 이끌면서, 우리는 우리와 같은 작업이 우리 모델이 알고 있는 것을 이해하는 데 도움이 되기를 바랍니다. 추측의 신뢰도만큼 잘 알지 못합니다.감사의 말 도움이 되는 토론과 피드백을 주신 Alireza Mousavi-Hosseini, Agustinus Kristiadi, Towaki Takikawa, Kevin Swersky, Richard Szeliski, Aaron Hertzmann, Georgios Kopanas, Vladimir Kim, Nathan Carr에게 감사드립니다.세 번째 저자는 NSERC Vanier 장학금과 Adobe Research Fellowship의 지원을 받았습니다.참고문헌 [1] Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li Liu, Mohammad Ghavamzadeh, Paul Fieguth, Abbas Khosravi, U Rajendra Acharya, Vladimir Makarenkov, Saeid Nahavandi.심층 학습의 불확실성 정량화에 대한 검토: 기술, 응용 프로그램 및 과제. arXive 사전 인쇄본 arXiv:2011.06225, 2021.[2] Sivaram Ambikasaran 및 Eric Darve. 부분 계층적 반분리 행렬을 위한 An\mathcal o (n\log n) o (n log n) 고속 직접 솔버: 방사형 기저 함수 보간에 적용. Journal of Scientific Computing, 2013.[3] Sivaram Ambikasaran, Michael O&#39;Neil 및 Karan Raj Singh. 응용 프로그램을 사용한 계층적 행렬의 고속 대칭적 인수분해. arXiv 사전 인쇄본 arXiv:1405.0223, 2014.[4] Murat Seckin Ayhan 및 Philipp Berens. 딥 신경망에서 이분산성 우연 불확실성 추정을 위한 테스트 시간 데이터 증가. 딥 러닝을 통한 의료 영상, 2022.[5] Gwangbin Bae, Ignas Budvytis, and Roberto Cipolla. 표면 정규 추정에서 우연적 불확실성 추정 및 활용. ICCV, 2021.[6] Jonathan T. Barron, Ben Mildenhall, Matthew Tancik, Peter Hedman, Ricardo Martin-Brualla, and Pratul P. Srinivasan. Mip-nerf: 앤티앨리어싱 신경 광도장을 위한 다중 스케일 표현. ICCV, 2021.[7] Jonathan T. Barron, Ben Mildenhall, Dor Verbin, Pratul P. Srinivasan, and Peter Hedman. Mip-nerf 360: 무제한 앤티앨리어싱 신경 광도장. CVPR, 2021.[8] Adrien Bartoli. 게이지 불변 번들 조정을 향해: 게이지 종속 감쇠를 기반으로 하는 솔루션. ICCV, 2003.[9] Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, Daan Wierstra. 신경망의 가중치 불확실성. ICML, 2015.[10] Piotr Bojanowski, Armand Joulin, David Lopez-Paz, Arthur Szlam. 생성 네트워크의 잠재 공간 최적화. ICML, 2019.[11] Kashyap Chitta, Aditya Prakash, Andreas Geiger. Neat: 엔드투엔드 자율 주행을 위한 신경 어텐션 필드. ICCV, 2021.[12] Erik Daxberger, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, Philipp Hennig. Laplace redux - 간편한 베이지안 딥 러닝. NeuRIPS, 2021. 2,[13] John Ellis, Mary K Gaillard, Dimitri V Nanopoulos, Serge Rudaz. 양성자 수명의 불확실성. Nuclear Physics B, 1980.[14] Matthew D. Hoffman, Tuan Anh Le, Pavel Sountsov, Christopher Suter, Ben Lee, Vikash K. Mansinghka, Rif A. Saurous. Probnerf: 2D 이미지에서 3D 모양의 불확실성 인식 추론. AISTATS, 2022. 1,[15] Eddy Ilg, Özgün Çiçek, Silvio Galesso, Aaron Klein, Osama Makansi, Frank Hutter, Thomas Brox. 광학 흐름을 위한 불확실성 추정 및 다중 가설 네트워크. ECCV, 2018.[16] Liren Jin, Xieyuanli Chen, Julius Rückin, Marija Popovic. Neu-nbv: 이미지 기반 신경 렌더링에서 불확실성 추정을 사용한 차선책 뷰 계획. IROS, 2023.[17] Alex Kendall 및 Yarin Gal. 컴퓨터 비전을 위한 베이지안 딥 러닝에서 필요한 불확실성은 무엇인가? NeuRIPS, 2017.[18] Bernhard Kerbl, Georgios Kopanas, Thomas Leimkühler 및 George Drettakis. 실시간 광도장 렌더링을 위한 3차원 가우시안 스플래팅. ACM Trans. Graph., 2023.[19] Balaji Lakshminarayanan, Alexander Pritzel 및 Charles Blundell. 딥 앙상블을 사용한 간단하고 확장 가능한 예측 불확실성 추정. NeuRIPS, 2016.[20] Erich L. Lehmann 및 George Casella. 점 추정 이론. Springer-Verlag, 2판, 1998.[21] Sergio Naval Marimont 및 Giacomo Tarroni. 의료 이미지에서 비지도 이상 탐지를 위한 암묵적 필드 학습. MICCAI, 2021.[22] Ricardo Martin-Brualla, Noha Radwan, Mehdi Sajjadi, Jonathan T. Barron, Alexey Dosovitskiy, Daniel Duckworth. NeRF in the Wild: 제약 없는 사진 컬렉션을 위한 신경 광도장. CVPR, 2020. 2,[23] Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, Ren Ng. NeRF: 뷰 합성을 위한 신경 광도장으로 장면 표현. ECCV, 2020. 2,[24] Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, Ren Ng. Nerf: 뷰 합성을 위한 신경 광도장으로 장면 표현. ECCV, 2020. 2,[25] Miguel Monteiro, Loïc Le Folgoc, Daniel Coelho de Castro, Nick Pawlowski, Bernardo Marques, Konstantinos Kamnitsas, Mark van der Wilk, Ben Glocker. 확률적 분할 네트워크: 공간적으로 상관관계가 있는 우연적 불확실성 모델링. 신경 정보 처리 시스템의 발전, 2020.[26] Daniel Morris, Kenichi Kanatani, Takeo Kanade. 동작에서 최적의 구조를 위한 불확실성 모델링. 비전 알고리즘 워크숍, 1999.[27] Thomas Müller, Alex Evans, Christoph Schied, Alexander Keller. 다중 해상도 해시 인코딩을 사용한 인스턴트 신경 그래픽 원시. SIGGRAPH, 2022.[28] Radford M. Neal. 신경망을 위한 베이지안 학습. Springer-Verlag, 1995.[29] Michael Niemeyer, Jonathan T. Barron, Ben Mildenhall, Mehdi SM Sajjadi, Andreas Geiger, Noha Radwan. Regnerf: 희소 입력에서 뷰 합성을 위한 신경 광도장 정규화. CVPR, 2021.[30] Tim N Palmer. 날씨 및 기후 예보의 불확실성 예측. 물리학 진전 보고서, 2000.[31] Xuran Pan, Zihang Lai, Shiji Song, Gao Huang. Activenerf: 불확실성 추정으로 볼 곳 학습. ECCV, 2022. 1,[32] Keunhong Park, Utkarsh Sinha, Jonathan T. Barron, Sofien Bouaziz, Dan B. Goldman, Steven M. Seitz, Ricardo Martin-Brualla. 변형 가능한 신경 광도장. ICCV, 2020.[33] Keunhong Park, Utkarsh Sinha, Peter Hedman, Jonathan T. Barron, Sofien Bouaziz, Dan B Goldman, Ricardo MartinBrualla, Steven M. Seitz. Hypernerf: 위상적으로 변하는 신경 광도장을 위한 고차원 표현. ACM Trans. Graph., 2021.[34] Keunhong Park, Philipp Henzler, Ben Mildenhall, Jonathan T. Barron, Ricardo Martin-Brualla. Camp: 신경 광도장을 위한 카메라 사전 조정, 2023.[35] Yunlong Ran, Jing Zeng, Shibo He, Jiming Chen, Lincheng Li, Yingfeng Chen, Gimhee Lee, Qi Ye. NeurAR: 암묵적 신경 표현을 사용한 자율적 3D 재구성을 위한 신경 불확실성. IEEE Robotics and Automation Letters, 2023.[36] Daniel Rebain, Mark Matthews, Kwang Moo Yi, Dmitry Lagun, Andrea Tagliasacchi. Lolnerf: 한 번 보면 배우다. CVPR, 2022.[37] Hippolyt Ritter, Aleksandar Botev, David Barber. 신경망을 위한 확장 가능한 라플라스 근사. ICLR, 2018. 2, 4,[38] Sara Sabour, Suhani Vora, Daniel Duckworth, Ivan Krasin, David J. Fleet, Andrea Tagliasacchi. Robustnerf: 강력한 손실로 방해 요소 무시. CVPR, 2023.[39] William D Schecher, Charles T Driscoll. 산성화 모델 내 평형 계산 평가: 측정된 화학 성분의 불확실성 효과. Water Resources Research, 1988.[40] Dario Seyb, Alec Jacobson, Derek Nowrouzezahrai, Wojciech Jarosz. 변형된 부호 거리 필드 렌더링을 위한 비선형 구면 추적. ACM Trans. Graph., 2019.[41] Jianxiong Shen, Adria Ruiz, Antonio Agudo, Francesc Moreno-Noguer. 확률적 신경 광도장: 암묵적 3차원 표현의 불확실성 정량화. 3DV, 2021. 1,[42] Jianxiong Shen, Antonio Agudo, Francesc Moreno-Noguer, Adria Ruiz. 조건부 흐름 너프: 신뢰할 수 있는 불확실성 정량화를 통한 정확한 3차원 모델링. ECCV, 2022. 1, 2, 6,[43] Ralph C Smith. 불확실성 정량화: 이론, 구현 및 응용 프로그램. Siam, 2013.[44] Masamichi Sugihara, Brian Wyvill, Ryan Schmidt. Warpcurves: 암묵적 표면의 명시적 조작을 위한 도구. Computers &amp; Graphics, 2010.[45] Richard Szeliski. 컴퓨터 비전: 알고리즘 및 응용 프로그램. Springer Nature, 2022. 1,[46] Richard Szeliski와 Sing Bing Kang. 동작에서 구조의 모양 모호성. 패턴 분석 및 머신 인텔리전스, IEEE Transactions on, 1997.[47] Niko Sünderhauf, Jad Abou-Chakra, Dimity Miller. 밀도 인식 nerf 앙상블: 신경 광도장에서 예측 불확실성 정량화. ICRA, 2023. 1,2,[48] Andrea Tagliasacchi와 Ben Mildenhall. 볼륨 렌더링 다이제스트(nerf용). arXiv 사전 인쇄본 arXiv:2209.02417, 2022.[49] Matthew Tancik, Ethan Weber, Evonne Ng, Ruilong Li, Brent Yi, Terrance Wang, Alexander Kristoffersen, Jake Austin, Kamyar Salahi, Abhik Ahuja, David Mcallister, Justin Kerr, Angjoo Kanazawa. Nerfstudio: 신경 광도장 개발을 위한 모듈식 프레임워크. 컴퓨터 그래픽 및 대화형 기술 컨퍼런스에 대한 특별 관심 그룹 컨퍼런스 회의록, 2023. 5,6,7,[50] Anastasia Tkach, Andrea Tagliasacchi, Edoardo Remelli, Mark Pauly, Andrew Fitzgibbon. 손 추적을 위한 온라인 생성 모델 개인화. ACM Trans. Graph., 2017.[51] Bill Triggs, Philip F. McLauchlan, Richard I. Hartley, Andrew William Fitzgibbon. 번들 조정 - 현대적 합성. 비전 알고리즘 워크숍, 1999.[52] Frederik Warburg, Ethan Weber, Matthew Tancik, Aleksander Holynski, Angjoo Kanazawa. Nerfbusters: 캐주얼하게 캡처한 nerf에서 유령 유물 제거. ICCV, 2023. 3,7,[53] Yi Wei, Shaohui Liu, Yongming Rao, Wang Zhao, Jiwen Lu, Jie Zhou. Nerfingmvs: 실내 다중 뷰 스테레오를 위한 신경 광도장의 유도 최적화. ICCV, 2021.[54] Kyle Wilson 및 Scott Wehrwein. 스펙트럼 번들 조정 불확실성 시각화. 2020 국제 3D 비전 컨퍼런스(3DV), 2020.[55] Zike Yan, Haoxiang Yang, Hongbin Zha. 활성 신경 매핑. arXiv 사전 인쇄본 arXiv:2308.16246, 2023.[56] Kaan Yücer, Alexander Sorkine-Hornung, Oliver Disney. 3D 재구성에 응용된 고밀도 샘플링된 광장에서 효율적인 3D 객체 분할. ACM TOG, 2016.[57] Sheheryar Zaidi, Arber Zela, Thomas Elsken, Christopher C. Holmes, Frank Hutter, Yee Whye Teh. 불확실성 추정 및 데이터 세트 이동을 위한 신경 앙상블 검색. NeuRIPS, 2021.[58] Huangying Zhan, Jiyang Zheng, Yi Xu, Ian Reid, Hamid Rezatofighi. Activermap: 활성 매핑 및 계획을 위한 Radiance 필드. arXiv 사전 인쇄본 arXiv:2211.12656, 2022. 1,[59] Kai Zhang, Gernot Riegler, Noah Snavely, Vladlen Koltun. Nerf++: 신경 광휘장 분석 및 개선. 사전 인쇄본 arXiv:2010.07492, 2020.
