--- ABSTRACT ---
―대규모 언어 모델을 사용하여 코드 생성 기능이 최근 개선되면서 주로 범용 프로그래밍 언어가 혜택을 받았습니다. IT 자동화에 사용되는 것과 같은 도메인별 언어는 많은 활성 개발자를 포함하고 현대 클라우드 플랫폼의 필수 구성 요소임에도 불구하고 훨씬 덜 주목을 받았습니다. 이 작업은 IT 자동화에 널리 사용되는 마크업 언어인 Ansible-YAML 생성에 중점을 둡니다. IT 자동화 생산성을 개선하는 것을 목표로 하는 Ansible-YAML 자연어 코드 생성 도구인 Ansible Wisdom을 제시합니다. Ansible Wisdom은 Ansible-YAML을 포함하는 새로운 데이터 세트로 학습하여 확장된 변환기 기반 모델입니다. 또한 이 도메인의 특정 특성을 포착하기 위해 YAML 및 Ansible에 대한 두 가지 새로운 성능 지표도 개발합니다. 결과에 따르면 Ansible Wisdom은 기존 최첨단 코드 생성 모델과 동등하거나 더 나은 성능으로 자연어 프롬프트에서 Ansible 스크립트를 정확하게 생성할 수 있습니다. 몇 가지 샷 설정에서 Ansible, YAML 데이터로 학습한 영향을 평가하고 Codex-Davinci002를 포함한 다양한 기준과 비교합니다. 또한 미세 조정 후 Ansible 특정 모델(BLEU: 66.67)이 몇 가지 샷 설정에서 평가된 훨씬 더 큰 CodexDavinci-002(BLEU: 50.4) 모델보다 성능이 더 우수하다는 것을 보여줍니다. 색인 용어-생성 모델, Ansible, 코드 생성 I.
--- INTRODUCTION ---
최근 몇 년 동안 대규모 언어 모델(LLM)은 자연어, 비전, 비디오 및 오디오 처리를 포함한 여러 도메인에서 상당한 콘텐츠 생성 기능을 보여주었습니다[1]. 최근 LLM은 프로그래머의 생산성[2] 및 소프트웨어 보안[3]과 같은 측면을 개선하는 목표로 소프트웨어 엔지니어링 분야에 적용되었습니다. 범용 프로그래밍 언어 분야에서 점점 더 많은 연구가 대규모 언어 모델의 기능을 활용하여 코드 생성, 복제본 감지, 코드 복구 및 기타 작업을 수행하고 있습니다[4], [5]. 이는 개발자 작업 속도를 높이고 모델을 학습시키기 위해 오픈 소스 코드 기반의 가용성을 활용할 수 있는 차세대 코딩 어시스턴트 제품에 활력을 불어넣고 있습니다. AI 지원 코딩 어시스턴트 분야는 초기 단계이지만 소프트웨어 엔지니어링 분야에 미칠 수 있는 잠재적 영향을 과소평가할 수 없습니다. 이러한 기술을 IT에 적용하면 *균등한 기여. 연락처: saurabh.pujar@ibm.com YAML과 같은 도메인 특정 언어는 광범위한 분야에 중요함에도 불구하고 그다지 주목받지 못했습니다. 이 연구에서는 LLM을 IT 자동화의 중요한 영역에 적용하는 방법을 살펴봅니다. IT 자동화는 수동 IT 관리 작업을 도메인 특정 스크립트의 자동 실행으로 대체합니다. 이 접근 방식은 클라우드 인프라 보안, 비용 효율성, 안정성 및 확장성을 획기적으로 개선합니다. YAML 파일은 종종 IT 인프라의 주요 측면을 정의하고 구성하는 데 사용됩니다. Ansible은 YAML 기반 구성을 사용하는 IT 자동화에 가장 널리 사용되는 애플리케이션 중 하나이며, 수천 개의 회사가 이 기술을 사용하여 IT 인프라를 관리합니다. Java 및 C++와 같은 범용 프로그래밍 언어보다 작성하기 쉽지만 Ansible-YAML은 능숙하게 사용하려면 상당한 전문 지식이 필요합니다. 많은 회사의 경우 Ansible 도입을 가속화하면 IT 인프라 관리를 위한 보다 안전하고 비용 효율적인 접근 방식으로 디지털 전환이 더 빨라질 것입니다. 이 논문은 LLM을 사용하여 Ansible-YAML 코드를 생성하는 방법을 조사하여 Ansible-YAML 사용자를 위한 AI 어시스턴트를 구축하고 생산성을 개선하는 것을 목표로 합니다. 자연어 프롬프트가 주어진 Ansible-YAML 코드 생성 작업에 트랜스포머 기반 모델을 사용하는 것을 제안합니다. 일반적으로 대량의 YAML 및 Ansible-YAML 데이터에서 학습하여 대규모 도메인별 사전 학습된 디코더 기반 모델의 네 가지 버전을 학습하는 것으로 시작합니다. 그런 다음 다운스트림 자연어에서 Ansible-YAML 생성 작업에 대한 미세 조정을 수행합니다. 이는 일반적으로 YAML 및 특히 Ansible-YAML에 대한 LLM을 살펴보는 첫 번째 작업입니다. 이 작업의 기여는 다음과 같습니다. • Ansible-YAML에 코드 생성을 적용하는 것의 의미를 탐구하고 문제에 대한 공식적인 정의를 제공합니다. 코드 생성에서 사전 학습 및 미세 조정 작업을 위해 YAML 및 Anisible-YAML 데이터 세트를 빌드합니다. • 우리는 YAML 데이터의 고유한 특징을 활용하여 Ansible-YAML 생성 문제를 새로운 프롬프트를 통한 코드 완성으로 이론적으로 재구성하고, 많은 우수성을 보여주는 일련의 변환기 기반 모델을 실제적으로 훈련했습니다. • 우리는 Ansible-YAML을 위해 특별히 설계된 두 가지 새로운 평가 지표를 제안하고, 최신 LLM과 모델을 비교하고, 한계점을 강조합니다. II.
--- RELATED WORK ---
A. 코드를 위한 사전 훈련된 언어 모델 가장 최근에 언어 모델은 코드 완성, 코드 생성 및 코드 요약과 같은 다운스트림 작업에서 탁월한 소스 코드 합성의 오랜 과제[6], [7]에 대한 진전을 촉진했습니다. Xu et al.[8]에 따르면 사전 훈련
--- METHOD ---
소스 코드 모델링을 위한 s는 세 가지 범주로 나뉩니다.(i) 첫 번째 범주는 왼쪽에서 오른쪽으로 언어 모델을 기반으로 합니다. 즉, 자기 회귀 디코더 기반 모델입니다. 이러한 모델은 이전 토큰을 기준으로 토큰의 확률을 예측합니다. 예를 들어, CodeGPT[9], CodeParrot[10], Codex[6], AlphaCode[11] 및 CodeGen[12]은 모두 이 범주에 속하며 코드 생성 및 완성 작업에 매우 유용합니다.(ii) 두 번째 범주는 양방향 정보를 사용하여 전체 문장 표현을 학습할 수 있는 마스크 언어 모델을 기반으로 합니다. CodeBERT[13] 및 CuBERT[14]와 같습니다. 이 사전 학습된 모델 계열은 코드 분류 및 감지 작업에 적합한 성능을 보입니다.(iii) 세 번째 범주의 모델은 마스크된 스팬 예측 및 노이즈 제거 시퀀스 재구성과 같은 사전 학습 목표를 통합하는 인코더-디코더 모델을 기반으로 합니다. CodeT5[15], PLBART[16], PolyCoder[8]는 세 번째 범주에 속하며 코드 주석 및 코드 간 변환과 같은 시퀀스 간 다운스트림 작업에서 좋은 성능을 발휘합니다. 이러한 모델 중 CodeGen은 The Pile[17]과 Google BigQuery의 데이터에서 학습되었으므로 자연어, 코드 및 일부 YAML 데이터에 노출되었습니다. B. 코드 생성 소스 코드 생성(또는 프로그램 합성)은 자연어 사양에서 시작하여 프로그램 또는 코드 조각을 생성하는 것으로 정의할 수 있습니다. 기존 방법은 확률적 컨텍스트 자유 문법(PCFG)을 사용하여 소스 코드의 추상 구문 트리(AST)를 생성합니다[6], [18]. Yin et al.[18]은 추상 구문 트리를 생성하기 위해 전환 시스템과 결합한 신경 모델을 제안했습니다. 최근 대규모 언어 모델이 개발됨에 따라 대규모 Transformers도 이 문제에 적용되었습니다. Transformers는 일반적으로 코드를 텍스트로 처리합니다. Feng et al. [13]은 CodeSearchNet 챌린지 [19]에서 이중 모드 텍스트가 있는 마스크 언어 모델의 사용을 제안했습니다. [6], [20] 두 작품에서는 대량의 소스 코드와 웹 데이터로 학습된 디코더 언어 모델의 사용을 제안합니다. 나아가 Xu et al. [8]은 이러한 모델에 대한 체계적인 평가를 수행하여 학습 코퍼스에 자연어가 있으면 일반적인 코드 언어 모델링에 도움이 된다는 것을 발견했습니다. 많은 변환기 모델이 Python [14] 및 C [3]와 같은 특정 프로그래밍 언어에 초점을 맞춘 소프트웨어 엔지니어링 작업을 위해 개발되었습니다. PLBART [16], CODEGEN [12] 및 Codex [6]와 같은 다국어 LLM은 여러 프로그래밍 언어로 학습되었지만 대부분의 데이터는 C, C++, Java, Python 등과 같은 일반적으로 사용되는 언어로 구성됩니다. YAML과 같은 널리 사용되는 도메인 특정 언어는 훨씬 덜 주목을 받았습니다. Ansible, OpenShift 및 기타 여러 도구는 구성 파일을 관리하기 위해 YAML에 의존합니다. Codex [6] 또는 CODEGEN [12]과 같은 최신 모델은 주로 범용 프로그래밍 언어에서 평가됩니다. Codex 또는 CODEGEN은 매우 방대하고 이기종적인 학습 데이터 세트로 인해 Ansible-YAML을 포함한 YAML을 생성하는 데 사용할 수 있지만 이 기능을 평가하는 작업은 찾지 못했습니다. 저희가 아는 한, 이는 대규모 언어 모델을 사용하여 YAML 코드 생성 문제를 다룬 최초의 작업입니다. III. 배경 Red Hat Ansible Automation Platform은 오픈소스 [21], [22] IT 자동화 시스템입니다. 구성 관리, 애플리케이션 배포, 클라우드 프로비저닝, 임시 작업 실행, 네트워크 자동화 및 다중 노드 오케스트레이션을 처리합니다. Ansible은 로드 밸런서를 사용한 제로다운타임 롤링 업데이트와 같은 복잡한 변경 사항을 더 간단하게 만듭니다. Ansible을 실행하는 시스템에는 제어 노드와 하나 이상의 관리 노드가 있습니다. 제어 노드는 Ansible이 실행되는 곳이고 관리 노드는 Linux 및 Windows 서버 머신과 같이 자동화되는 장치입니다. Ansible Playbook(또는 playbook)은 Ansible이 관리되는 노드에서 수행할 Ansible 작업(또는 작업들) 세트를 설명하는 YAML 파일입니다. 플레이북은 관리되는 노드의 원하는 상태를 정의하고, 작업은 노드를 원하는 상태로 만드는 단계를 지정합니다. 예를 들어, 플레이북은 특정 애플리케이션을 설치하고 구성하거나 특정 시스템 구성을 설정하는 작업 세트를 정의할 수 있습니다. 플레이북은 순서대로 실행되는 일련의 플레이로 구성됩니다. 각 플레이는 관리되는 노드 그룹과 해당 노드에서 수행할 작업 세트를 지정합니다. 플레이북에는 변수와 조건문이 포함될 수도 있으며, 이를 통해 보다 유연하고 동적으로 실행할 수 있습니다. 이를 통해 복잡한 구성을 쉽게 정의하고 여러 서버에 일관되게 배포할 수 있습니다. 그림 1은 Ansible 플레이북의 예를 보여줍니다. 그림의 플레이북은 서버 그룹의 모든 관리되는 노드를 대상으로 하는 단일 플레이로 구성됩니다. 이 연극에는 두 가지 작업이 포함됩니다. &quot;SSH 서버 설치&quot;라는 작업은 ansible.builtin.apt 모듈을 사용하여 openssh-server 패키지를 설치하고, &quot;SSH 서버 시작&quot;이라는 작업은 ansible.builtin.service 모듈을 사용하여 ssh 서비스를 시작합니다. 각 작업의 &quot;이름&quot; 필드는 사용자가 작업의 의도를 설명하도록 사용자 정의할 수 있습니다. IV. 방법론 A. 문제 공식화 작업 Ansible-YAML 생성을 다음과 같이 정의합니다. 프롬프트 X로 자연어(NL)와 컨텍스트 스크립트로 Ansible YAML을 모두 포함하는 작업 설명이 주어지면 호스트: 서버 작업: 이름: SSH 서버 설치 ansible.builtin .apt: 이름: openssh- 서버 상태: 현재 이름: SSH 서버 시작 ansible.builtin .service: 이름: ssh 상태: 시작됨 그림 1: Ansible 플레이북 YAML 사용 예 Туре 소스 파일 수 Galaxy 112K Ansible FT GitLab 64K Ansible PT GitHub GBQ 1.1M Ansible PT 2.2M Generic PT GitHub GBQ 표 I: 데이터 소스당 추출된 파일 수. 이 데이터는 Wisdom 모델의 사전 학습(PT) 또는 미세 조정(FT)에 사용됩니다. C, X와 C의 의도에 따라 Ansible 작업 또는 플레이북 스니펫 Y를 생성합니다. X와 C는 모두 토큰 시퀀스로 표현됩니다. 스니펫 코드 Y는 Ansible 언어 시퀀스(AL)로도 공식화됩니다. 또한 X와 C가 주어진 Ansible 스니펫 Y의 분포를 p(Y|X, C)로 모델링하는 확률적 생성 모델을 정의합니다. 그러면 최상의 Ansible 작업 스니펫은 = arg max p(Y|X, C)로 주어집니다. B. 데이터 세트 구성 C. 사전 학습 사전 학습된 모델은 SalesForce[12]에서 출시한 디코더 기반 모델인 CODEGEN과 동일한 아키텍처로 구현됩니다. CODEGEN은 여러 데이터 세트에서 사전 학습되었습니다.(1) Pile[24], 약 3,500억 개의 자연어 토큰과 310억 개의 코드 토큰;(2) BigQuery, 6가지 프로그래밍 언어로 된 약 1,190억 개의 코드 토큰;(3) BigPython, 약 710억 개의 Python 코드 토큰. CODEGEN은 많은 양의 자연어를 보았지만 Ansible-YAML은 제한된 수만 보았습니다.예를 들어, Pile에는 약 25,000개의 Ansible-YAML과 600,000개의 일반 YAML 파일만 포함됩니다.YAML의 의미론과 구문에 대한 사전 학습된 모델의 이해도를 높이기 위해 Ansible-YAML 파일만 포함된 데이터 세트와 Ansible-YAML 및 일반 YAML 파일이 포함된 데이터 세트로 CODEGEN 체크포인트에서 학습된 WISDOMANSIBLE-MULTI 및 WISDOM-YAML-MULTI를 빌드합니다(자세한 내용은 표 I 참조). Ansible-YAML과 일반 YAML 파일은 총 약 11억 개의 학습 토큰을 차지합니다. 또한 CODEGEN 체크포인트를 초기화로 사용하는 것의 효과를 탐색하는 것 외에도 위에서 언급한 두 데이터 세트로 처음부터 학습하는 WISDOM-ANSIBLE과 WISDOM-YAML을 제안합니다. Wisdom은 Ansible 프로그래머를 실시간으로 지원하도록 설계되었으므로 대기 시간은 고려해야 할 중요한 매개변수입니다. 이것이 처리량이 낮은 매우 큰 모델보다는 초당 토큰 처리량이 높은 적당한 크기의 모델을 선택하는 이유입니다. CODEGEN 350M과 CODEGEN 2.7B의 아키텍처를 테스트했습니다. 두 모델 모두에 대해 단일 GPU에서 생성 처리량을 벤치마킹한 결과 350M 모델이 (1) 2.7B보다 약 1.9배 빠르다는 것을 발견했습니다. 우리는 GitHub, Google BigQuery, GitLab 및 Ansible Galaxy[23]를 포함한 여러 데이터 소스에서 YAML 데이터 세트를 큐레이션했습니다. 각 데이터 소스에 맞는 데이터 추출 로직을 사용하는 동시에 해당 API 엔드포인트를 쿼리하여 YAML 파일과 관련 메타데이터를 추출합니다. Google BigQuery의 경우 유효한 YAML 확장자(&#39;.yml&#39;, &#39;.yaml&#39;)가 있는 모든 파일을 다운로드했습니다. GitHub 및 GitLab의 경우 이름이나 설명에 &quot;Ansible&quot;이 포함된 모든 리포지토리를 고려했습니다. 간단한 정확한 일치 기준을 사용하여 데이터 세트의 중복을 제거했습니다. 일반 YAML 외에도 데이터 세트에는 Ansible 역할, 컬렉션, 작업 및 플레이북 간의 상호 작용을 보존하도록 적절하게 태그가 지정된 Ansible 특정 YAML이 포함되어 있습니다. 큐레이션된 데이터 세트에는 약 1.1M개의 Ansible 작업 및 플레이북 YAML과 약 2.2M개의 다른 일반 YAML 파일이 포함되어 있습니다. 표 I은 데이터 소스, 파일 수, YAML 유형 및 데이터를 사용하는지 여부를 요약합니다. 영어: 사전 학습(PT)의 미세 조정(FT). *https://cloud.google.com/bigquery에서 게시한 공개적으로 사용 가능한 데이터 세트 Google, 당사의 학습 코드는 CODEGEN 체크포인트와 토크나이저를 제공하는 Huggingface Transformers 라이브러리[25]를 기반으로 합니다. 80GB 메모리가 있는 16개의 A100 GPU를 사용하여 9개 에포크 동안 YAML 데이터 세트를 사용하여 모델을 학습했습니다. 학습 속도를 높이기 위해 bf16 데이터 유형을 사용했습니다. 효과적인 배치 크기는 32이고 학습률은 선형 감소 일정으로 5 × 10−5였습니다. 사전 학습 중에 YAML 파일은 1024의 컨텍스트 창을 채우도록 압축되었으며 특수 구분 기호 토큰을 사용하여 파일을 구분했습니다. D. 미세 조정 1) 데이터 세트: 이 데이터 세트는 Ansible 커뮤니티에서 만들고 검증한 양질의 파일 모음이므로 Ansible Galaxy 데이터를 사용하여 위에서 언급한 사전 학습된 모델을 Ansible-YAML 생성 다운스트림 작업에서 미세 조정했습니다. Galaxy에는 많은 유형의 Ansible 파일이 있지만, 작업이 포함된 플레이북과 역할의 작업 목록만 추출했습니다. PyYAML(https://pyyaml.org)을 사용하여 유효한 YAML과 올바른 플레이북 또는 작업 구문을 확인하고 Ansible 팀에서 권장하는 스타일과 일치하도록 형식을 표준화했습니다. Galaxy 데이터 파일은 무작위로 학습(80%), 검증(10%) 및 테스트(10%) 세트로 분할되었습니다. 모든 분할에서 파일 수준과 샘플 수준에서 정확한 일치 중복 제거가 수행됩니다. 2) 생성 유형: 섹션 IV-A에서 설명한 대로 목표는 전체 플레이북(PB) 또는 자연어(NL) 요구 사항을 고려한 작업(T)의 두 가지 종류의 Ansible 출력을 생성하는 것입니다. 작업(T)은 플레이북의 일부이거나 역할의 일부일 수 있습니다. 따라서 미세 조정 데이터 세트에서 4가지 유형의 입력-출력 조합을 가질 수 있습니다. • NL→PB: 컨텍스트가 비어 있으므로 유일한 입력은 자연어 프롬프트입니다. 우리는 예상되는 출력 플레이북을 1개 또는 2개의 작업만 포함하는 예로 제한했습니다.이것은 대부분의 플레이북을 형성합니다.2개 이상의 작업을 포함하는 플레이북은 다음 유형의 샘플을 생성하는 데 사용됩니다.• PB+NL→T: 모델은 플레이북에서 다음 작업을 예측할 것으로 예상되며, 컨텍스트는 최소 1개의 작업이 있는 플레이북입니다.• NL→T: 컨텍스트가 비어 있고 모델은 역할의 첫 번째 작업인 1개의 작업만 생성할 것으로 예상됩니다.• T+NL→T: 모델은 자연어 프롬프트를 기반으로 역할의 다음 작업을 예측할 것으로 예상되며, 여기서 컨텍스트는 이전 작업입니다. 3) 입력 프롬프트 공식화: Ansible 언어의 유용한 기능은 각 플레이북 또는 작업에 종종 &quot;이름&quot; 필드가 포함되어 있다는 것입니다. 이 필드의 값은 그림 1에서와 같이 플레이북 또는 작업의 목표에 대한 자연어 설명입니다. 따라서 대상 출력은 Y = {YNL, YAL}로 표현할 수 있습니다. 여기서 YNL은 Ansible 스크립트의 &quot;이름&quot; 줄을 나타내고 YAL은 스크립트의 나머지 부분을 나타냅니다. 또한 YNL은 섹션 IV-A의 원래 문제 공식화에서 NL 시퀀스 X와 정확히 동일합니다. 따라서 이 기능을 활용하고 사전 학습된 디코더 기반 모델에 가장 잘 맞게 하기 위해 섹션 IV-A의 텍스트-코드 생성 문제를 코드 완성 문제로 재구성합니다. 구체적으로, Eq.1은 ŷ = arg max p(YNL, YAL |X, C)로 공식화할 수 있습니다. = P(YNL|X, C)p(YAL |X, C) = p(X|X,C)p(YAL | YNL, C) = P(YAL |YNL, C) = (2) YAL과 YNL은 X와 C, X YNL이 주어졌을 때 조건부로 독립적이라고 가정합니다. 따라서 &quot;name&quot; 라인 YNL의 값을 프롬프트로 사용할 수 있습니다. 출력이 플레이북인 경우 플레이북의 &quot;name&quot; 필드 값과 해당 작업을 결합하여 프롬프트를 만듭니다. 우리는
--- EXPERIMENT ---
ally는 이 재구성이 모든 종류의 지표에 대한 전반적인 성능을 크게 개선할 수 있음을 검증했습니다. 결과는 다음 섹션에 제공됩니다. 4) 학습: Galaxy 데이터 세트를 사용하여 8개 에포크 동안 사전 학습된 모델을 미세 조정했습니다. 효과적인 배치 크기는 이고 학습률은 코사인 감소 일정을 사용하여 5 × 10-5였습니다. 검증 세트에서 BLEU 점수를 사용하여 최상의 체크포인트를 결정했습니다. E. 데모/플러그인 GRPC 및 REST API 기반 인터페이스를 모델 예측에 노출하여 GRPC 및 REST 클라이언트를 사용하여 추론을 호출할 수 있습니다. ansible 파일에 대해 활성화되고 사용자가 바인딩 키를 누르면 트리거되는 사용자 지정 Visual Studio Code 플러그인을 작성했습니다. 이렇게 하면 API에 대한 호출이 트리거되어 예측이 수행되고 포맷되어 편집기에 다시 붙여넣습니다. 현재 설정에서 사용자가 작업에 대한 프롬프트(예: &quot;- name: install nginx on RHEL&quot;)를 작성하고 Enter 키를 누르면 API를 호출하여 예측을 수행한 다음 결과를 가져와 편집기에 다시 붙여 넣습니다. 사용자는 Tab 키를 눌러 제안을 수락하거나 Esc 키를 눌러 제안을 거부할 수 있습니다. 향후 구현에서는 편집기의 작업 영역에서 추가 정보를 활용하여 추천의 품질 측면에서 사용자 경험을 개선하고 캐싱과 같은 기술을 사용하여 대기 시간을 개선할 계획입니다. V. 실험 A. 평가 지표 생성된 ansible 작업 또는 작은 플레이북은 항상 외부 리소스에 대한 종속성이 높기 때문에 작업을 실행하여 작업의 정확성을 평가하는 것은 실용적이지 않습니다. 예를 들어 Ansible로 여러 원격 호스트에 패키지를 설치하는 작업을 실행하고 결과가 예상대로인지 확인하여 평가하는 것은 비현실적입니다. 따라서 평가 지표는 생성된 ansible 작업 또는 플레이북과 실제 결과 간의 유사성을 기반으로 합니다. 이 논문에서 설명하는 실험에서는 정확한 일치, BLEU [26], [27]*, Ansible 인식 및 스키마 정확의 4가지 비교 메트릭을 사용했습니다.이 중 Ansible 인식 및 스키마 정확은 Ansible 작업 또는 플레이북을 위해 특별히 설계된 두 가지 새로운 메트릭입니다.Ansible 인식: 이상적으로 메트릭은 결과에 대한 사용자의 견해, 즉 수정하기 위해 얼마나 많은 변경을 해야 하는지를 반영해야 합니다.Ansible 인식 메트릭의 목적은 Ansible YAML 구문에 대한 지식을 사용하여 Ansible 작업 또는 플레이북을 구성하는 모듈, 키워드 및 매개변수를 비교하는 것입니다.Ansible 작업 또는 플레이북은 매핑(사전)이므로 키-값 쌍의 순서는 중요하지 않습니다.작업의 일반적인 키 순서는 이름, 모듈, 키워드입니다.&quot;이름&quot;은 선택 사항이며 값은 작업에 대한 자연어 설명입니다.모듈 키는 수행할 작업을 식별하는 반면 값은 모듈의 매개변수를 보유하는 사전입니다. 선택 키워드는 작업 실행에 영향을 미치는 조건(예: 환경, 상승된 권한, 원격 사용자 ID, 오류 처리, 조건문, 루프)을 정의합니다. 키워드 값은 스칼라, 목록 또는 사전일 수 있습니다. 작업의 점수는 대상에서 찾은 최상위 키-값 쌍과 예측된 YAMLS의 점수 평균에서 계산됩니다. *Ansible YAML 파일의 토큰 시퀀스는 중요하지만 일부 재정렬은 허용되지만 BLEU 점수의 n-gram 커버리지 기반은 유용한 메트릭이 될 수 있음을 시사합니다.# NL 프롬프트에서 작업 생성(L18)# 플레이북을 컨텍스트로 사용(L1- L17)호스트: alltasks:# 모델 예상 출력(L19- L20) - 이름: 네트워크 설정 플레이북 연결: ansible.netcommon.network_cli gather_facts false 이름: VyOS 장치 vyos.vyos에 대한 구성 가져오기. vyos_facts: gather_subset: all name: 호스트 이름 vyos.vyos.vyos_config를 업데이트합니다. # NL 프롬프트에서 플레이북을 생성합니다. (L5)-tasks:backup: yeslines: 시스템 호스트 이름 vyos를 변경합니다. name: VyOS 장치 vyos.vyos에 대한 변경된 구성을 가져옵니다. vyos_facts:% 컨텍스트 없음 # 모델은 (L6- L17)에서 예상 출력 name: 네트워크 설정 플레이북 connection: ansible.netcommon.network_cli gather_facts false hosts: all name: VyOS 장치 vyos.vyos에 대한 구성을 가져옵니다. vyos_facts: gather_subset: all - name: 호스트 이름 vyos.vyos.vyos_config를 업데이트합니다. backup: yes lines: set system host- name vyos- changed gather_subset all (a) PB+NL→T (b) NL→PB# NL 프롬프트에서 작업 생성 (L9)# 작업을 컨텍스트로 사용 (L1- L8)# NL 프롬프트에서 작업 생성 (L5)# model expected output in (L10- L12)state latestname: Apache가 최신 버전인지 확인하세요. builtin .yum: name: httpd name: Apache 구성 파일을 작성합니다-# 컨텍스트 없이 # 모델 예상 출력 (L6- L8) name: Apache가 최신 버전인지 확인합니다 ansible builtin .yum: name: httpd state latestansible builtin .template: src: /srv/httpd.jdest: /etc/httpd.conf (c) T+NL→T (d) NL→T 그림 2: IV-D2에 정의된 Ansible 생성 유형. 각 코드 조각에는 NL 프롬프트, 모델에 제공된 컨텍스트 및 예상 출력을 강조하는 주석(빨간색)이 포함되어 있습니다. 주석은 여기에서 설명 목적으로만 사용되며 학습 또는 추론 중에 모델에 제공되지 않습니다. 스키마 정확성: 이 메트릭은 결과의 정확성, 즉 Ansible 스키마를 충족하는지 여부를 측정하도록 설계되었습니다. 예측에만 적용되므로 모델의 정확성을 반영하지 않습니다. Ansible linter에서 사용하는 Ansible 플레이북과 작업 스키마는 매우 엄격하며 Ansible 자체에서 여전히 허용하는 일부 이전 형식을 허용하지 않습니다. 따라서 점수가 낮다고 해서 반드시 Ansible에서 결과가 거부되는 것은 아닙니다. 이러한 스키마로 학습 데이터를 필터링하지 않았으므로 완벽한 정확한 일치 점수를 가진 샘플은 스키마 정확 점수를 가질 수 있습니다. 마찬가지로 플레이북의 경우 최상위 키-값의 점수는 삽입 페널티를 포함하는 영향을 조사할 계획입니다. 쌍은 평균화되며 각 작업의 점수는 위와 같이 계산됩니다. &quot;name&quot; 키와 해당 값은 작업 실행에 영향을 미치지 않으므로 무시할 수 있습니다. 각 키-값 쌍의 점수는 키와 값 점수의 평균입니다. 현재 예측에서 누락된 키는 점수 0이 주어지고 예측에 삽입된 키는 무시됩니다. 키의 값이 목록이나 사전인 경우 각 사전 항목 또는 목록 항목의 점수를 평균화하여 점수가 재귀적으로 계산됩니다. 모듈 이름을 비교할 때 필요한 경우 먼저 완전히 정규화된 컬렉션 이름(FQCN)으로 바꿉니다. 예를 들어 copy는 ansible.builtin.copy로 변경됩니다. 적용되는 또 다른 정규화는 모듈 매개변수에 대한 이전의 ki k2 = v2 구문을 dict로 변환하는 것입니다. 거의 동등한 일부 모듈이 있습니다(예: command | shell, copy template, package/apt, dnf, yum). 이러한 모듈은 동일한 인수를 많이 허용하고 어떤 경우에는 교환할 수 있으므로 이러한 모듈 차이에는 인수 점수와 평균화된 부분 키 점수가 제공됩니다. = V1, 삽입을 무시하는 동기는 쉽게 제거할 수 있기 때문에 삭제보다 비용이 적게 들기 때문이지만 0. B. 결과 1) 사전 학습: 비교를 위한 사전 학습된 모델 모든 CODEGEN이지만 다른 데이터 세트에서 사전 학습되었습니다. 표 II 모델은 모델 이름과 사전 학습된 데이터 세트를 소개하는 것과 동일한 아키텍처로 구현됩니다. 첫 번째 세 모델은 Salesforce에서 릴리스한 원래 CODEGEN 체크포인트에 해당합니다[12]. 모델 Pile BigQuery 데이터 세트 BigPython Ansible YAML 일반 YAML CODEGEN-NL ✓ CODEGEN-MULTI CODEGEN-MONO WISDOM-ANSIBLE WISDOM-YAML WISDOM-ANSIBLE-MULTI ✓ 표 II: WISDOM-YAML-MULTI 모델 이름과 연관된 사전 학습 데이터 세트. Pile, BigQuery 및 BigPython은 Salesforce에서 사용되었으며[12], Ansible YAML 및 일반 YAML은 이 작업에서 소개되었습니다. CODEGEN-NL, CODEGEN-MULTI 및 CODEGEN-MONO. 마지막 네 행은 이 논문에서 YAML 데이터에 대해 제안한 도메인별 사전 학습된 WISDOM 모델입니다. WISDOM-ANSIBLE은 Ansible YAML에서만 사전 학습된 반면 WISDOM-YAML은 Ansible YAML과 Generic YAML 모두에서 사전 학습되었습니다. WISDOM-ANSIBLE-MULTI는 CODEGEN-MULTI의 가중치로 초기화되었으며 Ansible YAML을 사용하여 사전 학습을 확장했습니다. WISDOM-YAML-MULTI도 CODEGEN-MULTI의 가중치로 초기화되었으며 Ansible YAML과 Generic YAML을 모두 사용하여 사전 학습을 확장했습니다. 실험 설정 먼저 이전에 설명한 4가지 생성 작업인 PB+NL→T, NL→PB, T+NL→T, NL→T의 분포를 포함하는 Ansible 테스트 세트에서 few-shot 설정으로 모델을 평가합니다. 여기서의 주요 목표는 사전 학습에 Ansible과 일반 YAML을 추가하면 모델 성능이 얼마나 향상되는지 이해하는 것입니다. 표 III은 모든 CODEGEN 및 WISDOM 모델과 OpenAI Codex에 대한 결과를 보여줍니다. 각 행에 대해 모델의 크기(즉, 매개변수 수)와 추론 컨텍스트 창의 크기를 나타냅니다. 모델 {YNL, C}(IV-D3 참조)에 대한 입력이 컨텍스트 창보다 큰 경우 왼쪽에서 잘립니다. 컨텍스트가 없는 작업(NL→PB 및 NL→T)의 경우 프롬프트 앞에 문자열 &quot;Ansible\n&quot;을 추가하면 CODEGEN 모델과 Codex의 성능이 모두 향상되는 것을 발견했습니다. WISDOM 모델의 경우 상당한 변화를 관찰하지 못했기 때문에 컨텍스트를 비워 두었습니다. 모든 모델은 섹션 VA에 설명된 네 가지 메트릭, 즉 스키마 정확함, 정확한 일치(EM), BLEU 및 Ansible 인식을 사용하여 평가되었습니다. 이러한 메트릭에 대해 올바르게 평가하기 위해 Ansible 작업 생성의 경우 모델 출력 예측을 잘라서 처음 생성된 작업만 유지했습니다. 플레이북 생성(NL→PB)의 경우 잘림을 적용하지 않았습니다. 마지막으로, 그 이후에 제시된 모든 결과는 탐욕적 디코딩을 사용하여 얻었습니다. 임의 샘플링이나 빔 검색 디코딩을 사용하면 어느 정도 개선될 것으로 예상합니다. Ansible 생성에서의 CODEGEN 비교 처음 세 행은 Salesforce에서 릴리스한 CODEGEN 모델을 나타냅니다. 표 III에서 볼 수 있듯이 The Pile과 BigQuery에서 학습한 CODEGEN-MULTI는 세 CODEGEN 모델 중에서 가장 좋은 성능을 보입니다. 구체적으로, CODEGEN-NL 350M은 BLEU가 24이고 Ansible Aware 점수가 6.24로 모든 지표에서 가장 나쁜 성능을 보입니다. Schema Correct는 71.26입니다. 이 다소 높은 값은 Pile에 있는 YAML의 작은 하위 집합만으로도 모델이 YAML 구문을 잘 이해하기에 충분하다는 것을 보여줍니다. 그러나 이 지표는 어떤 대상과도 비교되지 않으며, CODEGEN-NL이 ~71%의 시간 동안 올바른 Ansible YAML을 생성할 수 있음을 나타낼 뿐입니다. CODEGEN-MULTI 350M 점수가 더 높고, 특히 Ansible Aware 점수가 약 28포인트 향상되었습니다. 이러한 향상은 주로 BigQuery에 있는 매우 많은 양의 코드(약 120B 학습 토큰)에 기인합니다. 추가 코드 샘플은 모델이 Schema Correct가 12포인트 상승한 것에서 볼 수 있듯이 구조와 구문(예: 들여쓰기)을 더 잘 이해하는 데 도움이 됩니다. CODEGEN-MONO의 결과는 CODEGEN-MULTI와 유사하며, 더 많은 PYTHON 코드를 추가해도 Ansible 생성 작업에 도움이 되지 않는다는 것을 보여줍니다. 모델 크기의 효과를 측정하기 위해 표 III에 표시된 대로 CODEGEN-MULTI 350M, 2.7B 및 6B를 추가로 비교했습니다. 더 큰 모델은 성능이 약간 더 좋지만 향상 정도는 눈에 띄지 않습니다. 350M 기준과 비교할 때 2.7B 모델은 Ansible Aware 점수를 약 1.8포인트, 6B 모델은 약 4.9포인트 향상시킵니다. Ansible 생성을 위한 Codex 또한 표 III에 표시된 대로 Ansible 생성 작업에서 Codex(Codex-Davinci-002)를 평가했습니다. Codex의 Schema Correct 및 BLEU 점수는 CODEGENMULTI 350M과 동일한 수준이지만 Ansible Aware는 상당히 높습니다(48.78). 또한 정확한 일치가 테스트된 모든 모델 중에서 가장 높은데, 이는 Codex가 Galaxy 데이터 세트의 상당 부분을 보았을 가능성이 있음을 나타냅니다. Ansible 생성을 위한 WISDOM 모델 표 III의 마지막 네 행에 표시된 대로 WISDOM 모델은 CODEGEN 및 Codex 기준선보다 현저히 뛰어나 YAML 사전 학습이 성능을 향상시켰음을 보여줍니다. 마지막 두 행은 YAMLS로만 사전 학습된 두 WISDOM 모델을 보여줍니다. 두 모델 모두 Codex와 유사한 Ansible Aware 점수에 도달하고 BLEU 점수는 CODEGEN-MULTI 6B와 비슷합니다. WISDOM-ANSIBLE-MULTI 350M은 가장 높은 Ansible Aware 점수를 받았으며 Codex보다 약 6점, CODEGEN-MULTI 6B보다 약 15점 높습니다. BLEU 점수도 CODEGEN-MULTI 6B보다 약 6점 더 높습니다. 이러한 결과는 기존 모델의 사전 학습을 확장하거나 사전 학습을 사전 학습하기 위해 많은 YAML 컬렉션을 추가하면 Ansible 작업 생성의 성능이 크게 향상됨을 보여줍니다. 또한 WISDOM 모델은 매개변수가 적기 때문에 CODEGEN 및 Codex보다 성능이 뛰어나 빠른 추론이 필요한 이 애플리케이션에 유리합니다. 2) 미세 조정: IV-D1에 설명된 Galaxy 데이터 세트에서 CODEGEN 및 WISDOM 모델을 미세 조정하고 평가했습니다. 표 IV에서 볼 수 있듯이 지정된 Ansible 생성 작업에 대한 미세 조정이 필요하며 표 III의 few-shot 결과에 비해 성능이 크게 향상됩니다. 예를 들어, 몇 개의 샷에서 2048 컨텍스트 윈도우를 사용한 CODEGEN-MULTI와 동일한 컨텍스트 윈도우를 사용한 미세 조정된 CODEGEN-MULTI를 비교하면 두 BLEU Ansible 인식 점수가 모두 약 30포인트 증가합니다. 다양한 실험적 요인이 미세 조정된 모델에 어떤 영향을 미치는지 더 잘 이해하기 위해 프롬프트 형식, 사전 학습된 모델, 모델 크기, 컨텍스트 윈도우 크기 및 데이터 세트 크기에 대한 절제 연구를 수행했습니다. 프롬프트 공식화의 효과 섹션 IV-D3에서 언급했듯이 AnsibleYAML 데이터의 기능을 활용하기 위해 &quot;이름&quot; 필드의 일부로 자연어 프롬프트를 활용하여 코드 생성 문제를 코드 완성 프로세스로 재구성했습니다. 효과를 검증하기 위해 컨텍스트 정보 앞에 접두사 용어 &quot;컨텍스트 코드&quot;와 자연어 부분 앞에 &quot;프롬프트&quot;가 포함된 일반적인 접두사 기반 CODEGEN 모델(CODEGEN-prefix라고 함)과 비교합니다. 표 IV에 나타난 결과에 따르면, 윈도우 크기 1024에서 제안된 프롬프트 형식을 사용한 CODEGEN은 CODEGEN-prefix보다 성능이 크게 뛰어납니다.예를 들어, BLEU에서 10%, SCHEMA CORRECT에서 26%, EM에서 16% 더 높습니다.다양한 사전 학습된 모델에 대한 분석 사전 학습된 모델은 미세 조정된 모델의 성능에서 중요한 역할을 합니다.표 IV에서 미세 조정된 CODEGEN-MULTI와 WISDOM-ANSIBLE-MULTI(둘 다 윈도우 크기와 모델 크기 350M)를 비교하면 Ansible 데이터에 대한 사전 학습이 대규모 언어 모델이 Ansible의 구문과 구조를 더 잘 이해하는 데 도움이 될 수 있음을 보여줍니다.특히, WISDOM-ANSIBLE-MULTI는 Schema Correct, EM 및 Ansible Aware와 관련하여 1% 증가를 얻었습니다.컨텍스트 윈도우 크기에 대한 분석 먼저 다양한 컨텍스트 윈도우 크기를 가진 미세 조정된 CODEGEN-MULTI 모델을 비교합니다. 더 많은 컨텍스트는 추론 시점에 모델 예측을 개선하지만, 학습을 위해 더 많은 컴퓨팅 리소스도 필요합니다. 또한 Ansible 특정 생성 작업의 경우 매우 큰 컨텍스트가 모델 출력을 개선하는지 여부는 명확하지 않습니다. 표 V에서 처음 세 행은 각각 512, 1024 및 2048의 컨텍스트 창 크기에 대한 결과를 보여줍니다. 512 컨텍스트 창은 BLEU가 61이고 Ansible Aware 점수는 64.84입니다. 컨텍스트 크기를 1024로 두 배로 늘리면 BLEU는 66으로 올라가고 Ansible Aware 점수는 69.77로 올라갑니다. 그러나 결과에서 볼 수 있듯이 1024를 넘어서도 개선이 관찰되지 않습니다. 이 관찰은 현재 데이터 세트를 기반으로 하며, 다른 테스트 세트가 더 큰 컨텍스트에서 더 많은 이점을 얻을 수 있다는 점에 유의하세요. 그럼에도 불구하고 현재 설정에서는 1024 컨텍스트 창이 적절하다는 결론을 내립니다. 학습 데이터 수에 대한 분석 학습 데이터의 영향을 조사하기 위해 미세 조정을 위해 다양한 양의 데이터(학습 데이터의 10%, 20%, 50%)를 사용합니다. 비교 결과는 표 IV의 마지막 세 줄에 나와 있습니다. 학습 데이터가 증가함에 따라 성능도 그에 따라 향상되었습니다. 예를 들어 BLUE는 61.68%에서 66.67%로 향상되었습니다. 그러나 향상 속도는 데이터의 10%당 1.7%에서 데이터의 50%당 1.2%로 감소합니다. 이는 현재 학습 데이터 크기가 거의 수렴되었으며 현재 미세 조정 데이터 크기가 높은 성능 비용 비율로 선택되었음을 보여줍니다. 약간의 데이터로 미세 조정을 수행하더라도 AnsibleYAML 생성 작업에서 Wisdom 모델 성능이 모든 지표에서 CodexDavinci-002(몇 가지 샷 설정에서)보다 훨씬 좋아진다는 점이 흥미롭습니다. 표 III과 IV에서 볼 수 있듯이, 100% 미세 조정 데이터로 학습한 가장 우수한 Wisdom 모델인 WISDOM-ANSIBLE-MULTI는 fewshot 설정에서 Codex-Davinci-002보다 약 15 BLEU 포인트와 약 16 EM 포인트 더 우수했습니다.생성 유형에 대한 분석 섹션 IV-D2에서 논의했듯이 Ansible-YAML 생성에는 4가지 유형의 생성 문제가 있습니다.제안된 모델이 이 4가지 유형을 어떻게 처리하는지 검증하기 위해 표 V에 표시된 대로 각각에 대해 평가했습니다.학습 데이터에서 T+NL→T의 수가 지배적이기 때문에 제안된 모델이 이 작업에서 가장 우수한 성능을 보였습니다.PB+NL→T 유형의 경우 미세 조정 샘플만 있더라도 성능은 T+NL→T와 비슷합니다.이는 T+NL→T와 PB+NL→T가 모두 자연어와 컨텍스트 ansible 데이터가 주어진 작업을 생성하는 데 사용되어 미세 조정하는 동안 서로에게 도움이 될 수 있기 때문일 수 있습니다. 제안된 모델은 표의 두 번째 줄에 표시된 것처럼 플레이북을 생성하는 데 어려움이 있는데, 이는 NL→T에 대한 학습 데이터의 수가 제한되어 있기 때문입니다(즉, 550개 카운트). 또한 PB+NL→T와 NL→T의 성능을 비교하여 생성에 컨텍스트 정보를 활용하는 필요성을 검증합니다. NL→T가 PB+NL→T보다 학습 데이터가 더 많지만 NL→T의 성능은 PB+NL→T에 비해 크게 떨어집니다(예: BLEU VI에서 33% 감소).
--- CONCLUSION ---
이 작업에서는 사용자가 제공한 자연어 프롬프트에서 시작하여 Ansible-YAML 생성에 대한 트랜스포머 기반 모델의 적용을 설명합니다. 이 모델의 목적은 Ansible 사용자를 위한 AI 어시스턴트를 구축하고 생산성을 개선하는 것입니다. 우리는 문제에 대한 공식적인 정의를 제공하고 기존의 사전 학습된 디코더 기반 모델에서 시작합니다. 우리는 커뮤니티와 공유될 코드 생성을 위한 Ansible 데이터로 새로운 학습 데이터 세트를 구축했습니다. 우리는 데이터 세트로 기본 모델의 학습을 확장하고 결과를 평가합니다. 우리의 결과에 따르면 Wisdom은 우리의 접근 방식을 통해 코드 생성을 위한 최첨단 모델과 동등하거나 더 나은 Ansible 생성을 수행합니다. 모델 크기 컨텍스트 스키마 EM BLEU Ansible Window Correct Aware CODEGEN-NL 350M71.1.24.6.CODEGEN-MONO 350M82.6.34.34.CODEGEN-MULTI 350M83.6.34.34.CODEGEN-MULTI 2.7B78.7.37.36.CODEGEN-MULTI 6B85.7.39.39.Codex-Davinci-175B88.13.50.55.WISDOM-ANSIBLE-MULTI 350M96.7.46.54.WISDOM-YAML-MULTI 350M95.7.45.53.WISDOM-ANSIBLE WISDOM-YAML 350M 350M95.4.39.48.94.4.40.47.표 III: few-shot 설정에서 CODEGEN, Codex 및 WISDOM 모델에 대한 평가 결과. 첫 번째 섹션은 Salesforce에서 출시한 CODEGEN 모델을 참조하고, 두 번째 섹션은 OpenAI Codex를 참조하고, 세 번째 섹션은 WISDOM 모델을 참조합니다. 모델 크기 컨텍스트 스키마 EM BLEU Ansible Window Correct Aware CODEGEN-MULTI 350M97.22.61.64.CODEGEN-MULTI 350M98.28.66.69.CODEGEN-MULTI 350M98.27.66.69.CODEGEN-MULTI 2.7B98.28.65.69.CODEGEN-MULTI-prefix 350M72.12.56.45.WISDOM-ANSIBLE-MULTI 350M98.29.66.70.WISDOM-YAML-MULTI 350M98.28.65.69.WISDOM-ANSIBLE 350M97.23.61.66.WISDOM-YAML 350M97.23.61.65.WISDOM-ANSIBLE-MULTI 350M98.27.65.69.-WISDOM-ANSIBLE-MULTI 350M98.25.63.67.-WISDOM-ANSIBLE-MULTI 350M98.22.61.66.-표 IV: 미세 조정된 모델의 평가 결과. 첫 번째 섹션은 컨텍스트 창의 크기와 매개변수 수를 변경하여 Galaxy에서 미세 조정된 CODEGEN-MULTI의 결과를 보여줍니다. 두 번째 섹션은 고정된 1024 컨텍스트 창에 대해 Galaxy에서 미세 조정된 WISDOM 모델을 보여줍니다. 마지막 섹션은 데이터 양(데이터 세트의 10%, 20%, 50%)을 변경하여 Galaxy에서 미세 조정된 WISDOM-ANSIBLE-MULTI에 해당합니다. 세대 유형 개수 스키마 정확 EM BLEU Ansible 인식 전체 NL→PB NL→T98.28.66.69.93.0.22.23.96.5.45.49.PB+NL→TT+NL→T98.98.46.79.82.31.69.72.표 V: Galaxy에서 미세 조정된 CODEGEN-MULTI에 대한 세대 유형별 평가 메트릭 분석(IV-D2 참조). &quot;전체&quot;는 모든 세대 유형을 합친 것을 나타냅니다. 제한 사항 많은 Ansible 개발이 플레이북에서 이루어집니다. 그러나 Ansible Galaxy에서 허용 가능한 플레이북 샘플을 거의 찾지 못했기 때문에 미세 조정 데이터 세트에 플레이북이 제대로 표현되지 않았습니다. 포함된 대부분의 플레이북은 두 개 이하의 작업이 있는 작은 크기입니다. 작업의 논리적 그룹인 Ansible 블록도 특별히 훈련 및 테스트하지 않은 것입니다. 이는 앞으로 확장하기를 희망하는 부분입니다. 또한 프롬프트에 대한 모델 민감도와 들여쓰기, 따옴표 및 대소문자 변경에 대한 견고성에 대한 추가 분석을 수행하기를 바랍니다.현재는 자연어에서 Ansible 생성 작업에 중점을 두고 있습니다.이것은 사용자가 코드 개발의 모든 단계에서 모델을 프롬프트할 수 있는 보다 일반적인 완성 작업으로 확장될 수 있습니다.윤리 성명 A. 법적 의미 Wisdom은 공개적으로 사용 가능하고 오픈 소스 라이선스가 있는 코드 저장소에서 학습됩니다.GitHub과 같은 공개 저장소에서 ML 알고리즘을 학습하는 것은 공정 사용으로 간주됩니다[28].학습이 완료되면 드물게 발생하더라도 Wisdom은 잠재적으로 학습 세트 샘플과 동일한 코드를 생성할 수 있습니다.이 경우 생성된 코드는 복사본의 결과가 아니라 Ansible에서 매우 일반적인 패턴일 가능성이 큽니다.또한 Wisdom은 권장 사항을 제공하지만 사용자가 이를 수락하고 코드베이스에서 사용할지 여부는 사용자의 선택입니다. B. 공격적인 언어 많은 양의 공개 저장소에는 여러 그룹에 공격적이거나 차별적인 언어가 주석이나 코드 형태로 포함될 수 있습니다. 이는 주로 제품 사용을 목적으로 하지 않는 연구 작업이지만, 원치 않는 표현이 생성되는 것을 방지하기 위해 모델의 제품 준비 버전은 주요 데이터 정리 및 정규화 프로세스를 거칩니다. C. 보안 및 안전 위험 Wisdom은 양질의 데이터로 학습되지만 보안 취약성을 포함하거나 시스템을 손상시킬 수 있는 Ansible을 생성할 상당한 위험이 있습니다. 이 모델은 안전하거나 안전한 Ansible을 생성하도록 학습되지 않고 테스트 세트와 관련하여 메트릭을 최적화하도록만 학습됩니다. 보안 취약성을 완전히 제거할 수는 없지만 학습 데이터의 보안 및 안전을 명시적으로 개선하고 가장 일반적인 취약성을 방지하기 위해 기본적인 후처리 분석을 수행하여 이 이벤트를 줄일 수 있습니다. 두 가지 접근 방식 모두 모델의 제품 준비 버전에서 고려됩니다. D. 경제 및 노동 시장 영향 AI 알고리즘에 의한 경제 및 노동 시장 혼란이라는 주제는 광범위한 논쟁의 주제였습니다. 특히, AI 코딩 어시스턴트는 잠재적으로 소프트웨어 개발 인력에 대한 위협으로 간주될 수 있습니다. 이러한 코딩 어시스턴트가 어떻게 사용되어야 하고 사용되고 있는지에 대한 심층적인 고찰[6]은 인간 전문가의 존재가 대체될 수 없다는 점을 분명히 강조할 것입니다. 실제로 현재의 ML 모델은 권장 사항을 이해하고 코드베이스에 통합하는 데 필요한 심층적인 의미적 이해를 제공할 수 없습니다. 참고문헌[1] OpenAI, &quot;Gpt-4 기술 보고서,&quot; 2023. [2] N. Jain, S. Vaidyanath, A. Iyer, N. Natarajan, S. Parthasarathy, S. Rajamani, R. Sharma, &quot;Jigsaw: 대규모 언어 모델이 프로그램 합성을 충족하다,&quot; 44회 국제 소프트웨어 엔지니어링 컨퍼런스 회의록, 2022, 1219-1231쪽. [3] L. Buratti, S. Pujar, M. Bornea, S. McCarley, Y. Zheng, G. Rossiello, A. Morari, J. Laredo, V. Thost, Y. Zhuang et al., &quot;신경 언어 모델을 통한 소프트웨어 자연성 탐색&quot;, arXiv 사전 인쇄 arXiv:2006.12641, 2020. [4] R. Puri, DS Kung, G. Janssen, W. Zhang, G. Domeniconi, V. Zolotov, J. Dolby, J. Chen, M. Choudhury, L. Decker, V. Thost, L. Buratti, S. Pujar, S. Ramji, U. Finkler, S. Malaika 및 F. Reiss, &quot;Codenet: 다양한 코딩 작업을 학습하기 위한 코드 데이터세트용 대규모 AI&quot;, 2021. [5] S. Greengard, &quot;Ai가 다시 쓴다 영어: 코딩,&quot; Commun. ACM, vol. 66, no. 4, p. 12-14, 2023년 3월. [온라인]. 사용 가능: https://doi.org/10.1145/[6] M. Chen, J. Tworek, H. Jun, Q. Yuan, HP d. O. Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman et al., &quot;코드로 학습된 대규모 언어 모델 평가,&quot; arXiv 사전 인쇄본 arXiv:2107.03374, 2021. [7] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar et al., &quot;Llama: 개방적이고 효율적인 기반 언어 모델,&quot; arXiv 사전 인쇄본 arXiv:2302.13971, 2023. [8] FF Xu, U. Alon, G. Neubig, 및 VJ Hellendoorn, &quot;코드의 대규모 언어 모델에 대한 체계적 평가,&quot; 기계 프로그래밍에 대한 제6회 ACM SIGPLAN 국제 심포지엄 회의록, 2022, pp. 1-10. [9] S. Lu, D. Guo, S. Ren, J. Huang, A. Svyatkovskiy, A. Blanco, C. Clement, D. Drain, D. Jiang, D. Tang 등, &quot;Codexglue: 코드 이해 및 생성을 위한 머신 러닝 벤치마크 데이터 세트,&quot; 제35회 신경 정보 처리 시스템 데이터 세트 및 벤치마크 트랙(라운드 1) 컨퍼런스, 2021. [10] L. Tunstall, L. von Werra, T. Wolf, 변압기를 사용한 자연어 처리. &quot;O&#39;Reilly Media, Inc.&quot;, 2022. [11] Y. Li, D. Choi, J. Chung, N. Kushman, J. Schrittwieser, R. Leblond, T. Eccles, J. Keeling, F. Gimeno, A. Dal Lago 등, &quot;alphacode를 사용한 경쟁 수준 코드 생성,&quot; Science, vol. 378, 아니. 6624, pp. 1092-1097, 2022. [12] E. Nijkamp, B. Pang, H. Hayashi, L. Tu, H. Wang, Y. Zhou, S. Savarese 및 C. Xiong, &quot;프로그램 합성을 위한 대화형 패러다임&quot;, arXiv 사전 인쇄 arXiv:2203.13474, 2022. [13] Z. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L. Shou, B. Qin, T. Liu, D. Jiang 외, &quot;Codebert: 프로그래밍 및 자연어에 대한 사전 훈련된 모델&quot;, 컴퓨터 언어학 협회 조사 결과: EMNLP 2020, 2020, pp. 1536-1547. [14] A. Kanade, P. Maniatis, G. Balakrishnan, 및 K. Shi, &quot;소스 코드의 컨텍스트 임베딩 학습 및 평가&quot;, 국제 기계 학습 컨퍼런스.PMLR, 2020, 5110-5121쪽. [15] Y. Wang, W. Wang, S. Joty, 및 SC Hoi, &quot;Codet5: 코드 이해 및 생성을 위한 식별자 인식 통합 사전 학습 인코더-디코더 모델&quot;, 2021 자연어 처리 경험적 방법에 관한 컨퍼런스 논문집, 2021, 8696-8708쪽. [16] W. Ahmad, S. Chakraborty, B. Ray, 및 K.-W. Chang, &quot;프로그램 이해 및 생성을 위한 통합 사전 학습&quot;, 2021년 북미 컴퓨터 언어학 협회 회의록: 인간 언어 기술, 2021, 2655-2668쪽. [17] L. Gao, S. Biderman, S. Black, L. Golding, T. Hoppe, C. Foster, J. Phang, H. He, A. Thite, N. Nabeshima 외, &quot;파일: 언어 모델링을 위한 다양한 텍스트의 800gb 데이터 세트,&quot; arXiv 사전 인쇄본 arXiv:2101.00027, 2020. [18] P. Yin 및 G. Neubig, &quot;일반 용도 코드 생성을 위한 구문 신경 모델,&quot; 55회 연례 회의록(제1권: 장문 논문), 2017, 440-450쪽. [19] H. Husain, H.-H. Wu, T. Gazit, M. Allamanis 및 M. Brockschmidt, &quot;Codesearchnet 챌린지: 의미 코드 상태 평가 검색,&quot; arXiv 사전 인쇄본 arXiv:1909.09436, 2019. [20] J. Austin, A. Odena, M. Nye, M. Bosma, H. Michalewski, D. Dohan, E. Jiang, C. Cai, M. Terry, Q. Le et al., &quot;대규모 언어 모델을 사용한 프로그램 합성,&quot; arXiv 사전 인쇄본 arXiv:2108.07732, 2021. [21] RH Ansible, &quot;Red Hat Ansible, 모든 사람을 위한 자동화,&quot; https://www.ansible.com/. [22] A. Github, &quot;Ansible Github 프로젝트,&quot; https://github.com/ansible/ansible. [23] Ansible, Inc, “Ansible Galaxy,&quot; https://galaxy.ansible.com/. [24] S. Black, S. Biderman, E. Hallahan, Q. Anthony, L. Gao, L. Golding, H. He, C. Leahy, K. McDonell, J. Phang et al., “Gpt-neox-20b: 오픈소스 자기회귀 언어 모델,&quot; BigScience 에피소드 5-대규모 언어 모델 생성의 과제 및 관점 워크숍 회의록, 2022, 95-136쪽. [25] T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac, T. Rault, R. Louf, M. Funtowicz, J. Davison, S. Shleifer, P. von Platen, C. Ma, Y. Jernite, J. Plu, C. Xu, T. Le Scao, S. Gugger, M. Drame, Q. Lhoest, A. Rush, &quot;Transformers: State-of-the-art natural language processing,&quot; 2020 자연어 처리 경험적 방법에 관한 컨퍼런스 회의록: 시스템 데모. 온라인: Association for Computational Linguistics, 2020년 10월, 3845쪽. [온라인]. 사용 가능: https://aclanthology.org/2020.emnlp-demos.[26] K. Papineni, S. Roukos, T. Ward, W.-J. Zhu, &quot;Bleu: 기계 번역의 자동 평가를 위한 방법,&quot; IBM Research Report RC22176(W0109-022), 2001. [27] C.-Y. Lin, FJ Och, &quot;Orange: 기계 번역의 자동 평가 지표를 평가하는 방법,&quot; COLING 2004: 제20회 국제 계산 언어학 컨퍼런스 회의록, 2004, 501-507쪽. [28] C. O&#39;Keefe, D. Lansky, J. Clark, C. Payne, &quot;미국 특허 및 상표청 상무부에서 인공지능 혁신을 위한 지적 재산권 보호에 대한 의견 요청에 대한 의견,&quot; 2019, https://perma.cc/ZS7G-2QWF.
