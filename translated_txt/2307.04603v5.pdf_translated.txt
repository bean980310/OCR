--- ABSTRACT ---
일관성과 신뢰성은 AI 연구를 수행하는 데 필수적입니다. 객체 감지와 같은 많은 유명 연구 분야가 견고한 벤치마크 프레임워크와 비교되고 검증되었습니다. AlphaFold2 이후 단백질 폴딩 작업은 새로운 단계에 접어들었고, AlphaFold2의 구성 요소를 기반으로 많은 방법이 제안되었습니다. 단백질 폴딩에서 통합 연구 프레임워크의 중요성에는 다양한 접근 방식을 일관되고 공정하게 비교하기 위한 구현 및 벤치마크가 포함됩니다. 이를 달성하기 위해 최신 모델의 중요한 구성 요소를 기성품 인터페이스 방식으로 지원하는 단백질 폴딩 프레임워크인 Solvent를 제시합니다. Solvent에는 통합 코드베이스에 구현된 다양한 모델이 포함되어 있으며 동일한 데이터 세트에서 정의된 모델에 대한 교육 및 평가를 지원합니다. 잘 알려진 알고리즘과 그 구성 요소를 벤치마킹하고 단백질 구조 모델링 분야에 대한 유용한 통찰력을 제공하는 실험을 제공합니다. Solvent가 제안된 모델의 신뢰성과 일관성을 높이고 속도와 비용 모두에서 효율성을 제공하여 단백질 폴딩 모델링 연구를 가속화하기를 바랍니다. 코드는 https://github.com/kakaobrain/solvent에서 사용할 수 있으며 프로젝트는 계속 개발될 것입니다. 1
--- METHOD ---
s는 AlphaFold2의 구성 요소를 기반으로 제안됩니다. 단백질 접힘에서 통합 연구 프레임워크의 중요성에는 다양한 접근 방식을 일관되고 공정하게 비교하기 위한 구현 및 벤치마크가 포함됩니다. 이를 달성하기 위해 우리는 기성품 인터페이스 방식으로 최첨단 모델의 중요한 구성 요소를 지원하는 단백질 접힘 프레임워크인 Solvent를 제시합니다. Solvent는 통합 코드베이스에 구현된 다양한 모델을 포함하고 동일한 데이터 세트에서 정의된 모델에 대한 교육 및 평가를 지원합니다. 우리는 잘 알려진 알고리즘과 그 구성 요소를 벤치마킹하고 제공합니다.
--- EXPERIMENT ---
단백질 구조 모델링 분야에 대한 유용한 통찰력을 제공하는 s입니다. Solvent가 제안된 모델의 신뢰성과 일관성을 높이고 속도와 비용 면에서 효율성을 제공하여 단백질 접힘 모델링 연구를 가속화하기를 바랍니다. 코드는 https://github.com/kakaobrain/solvent에서 사용할 수 있으며 프로젝트는 계속 개발될 것입니다. 1 서론 Alphafold2[1]의 목격 이후 딥러닝 기반 단백질 구조 예측 작업은 필수적인 연구 분야가 되었습니다. 또한 ESMFold[2] 및 OmegaFold[3]와 같은 다중 시퀀스 정렬(MSA) 입력이 없는 단백질 접힘 방법이 생성 MSA를 제거하여 고속으로 일반 단백질을 모델링하기 위해 제안되었습니다. 특히 이러한 모델은 항체 구조 및 de-novo 구조 IgFold[4] 및 tFold-Ab[5]를 포함한 특정 응용 프로그램에서 유망한 결과를 보여주었습니다. 각 방법은 논문을 발표하고 사전 학습된 모델을 사용하여 추론 코드를 출시했습니다. 그러나 Kyeongtak Han이 카카오브레인에서 인턴으로 일한 적이 있는 MSA에 의존하는 방법과 비교했을 때, 사전 인쇄본. 오픈소스 학습 프레임워크인 OpenFold [6], 언급된 MSA 없는 폴딩 프레임워크의 공개된 코드에는 입력 데이터 준비 파이프라인을 포함하여 학습 코드가 포함되어 있지 않습니다. 이에 더하여, 그들이 사용한 다른 구현은 동일한 구성 요소에 대해 약간 다른 결과를 생성할 수 있어 명확한 비교를 어렵게 만듭니다. 더욱이, 다른 데이터 세트를 학습하고 평가하면 방법을 공정하게 비교하기 어렵습니다. 연구를 통합된 방식으로 재현하고 다른 방법과 비교하면 연구자에게 통찰력을 제공하고 단백질 폴딩에서 쉽게 접근할 수 없는 새로운 방법을 제안할 수 있습니다. 인공 지능 분야에서도 비슷한 어려움이 있었기 때문에 연구자들이 어떻게 어려움을 극복했는지 연구하는 것이 도움이 됩니다. 잘 확립된 프레임워크가 해당 분야에 대한 일반화와 공정한 비교를 달성하기 때문에 객체 감지를 대표적인 예로 들었습니다. Faster R-CNN[7]이 개발된 후, 다양한 R-CNN 기반 객체 감지 방법이 제안되었습니다. 개별 방법은 출판물과 소스 코드로서의 기여를 검증했습니다. 그러나 서로 다른 코드베이스에서 수행된 연구에서 이를 비교하는 것은 쉽지 않았습니다. 다행히도 Detectron2[8] 및 MMDetection[9]과 같은 프레임워크가 제안된 이후로 실험의 일반화 및 일관성이 해결되었습니다. 벤치마킹은 다양한 모델 변형에 대해 동일한 프레임워크 내에서 일관되고 사용자 친화적으로 수행되었습니다. 이 프레임워크는 통합된 데이터 세트, 평가 메트릭 및 모듈 구현을 제공했습니다. 다른 모든 조건이 고정된 상태에서 프레임워크가 사실상의 기반으로 사용되었으므로 주요 기여의 효과가 명확하고 확실하게 평가되었습니다. 또한 이 프레임워크는 다양한 모델을 추상화된 구성 요소로 구성된 메타 아키텍처로 일반화했습니다. 이는 객체 감지 파이프라인을 이해하는 데 따른 복잡성을 줄이고 고품질 연구로 이어졌으며, 연구자는 아이디어에 집중할 수 있었고, 결국 이 분야를 가속화했습니다. 단백질 접힘 분야는 객체 감지와 같은 방향으로 성숙해야 합니다. 객체 감지에서 Faster R-CNN이 등장한 것처럼 AlphaFold2는 단백질 구조 예측에서 등장했습니다. Alphafold2의 모듈을 기반으로 단일 시퀀스 기반 구조 예측 모델이 활발하게 탐구되고 있습니다. Detectron2 또는 MMDetection과 같은 단백질 폴딩 연구를 가속화하기 위해 최신 모델의 주요 부분인 주요 신경망을 포함하는 단백질 폴딩 프레임워크인 Solvent를 제시합니다. Solvent에서 여러 메서드는 통합된 코드베이스로 구현되고 메타 아키텍처로 표현됩니다. 또한 모델의 학습 및 검증을 위해 잘 정의된 데이터 세트가 제공됩니다. Solvent를 프레임워크로 작동시키기 위해 Solvent에서 일관성과 일반화를 보장하는 Detectron2[8]의 파이프라인을 차용합니다. 프레임워크에서 가장 신뢰할 수 있고 잘 알려진 Alphafold2 재구현 프로젝트인 OpenFold[6]의 구현을 사용하여 개별 메서드를 표현합니다. 단일 시퀀스 기반 폴딩 메서드를 세 개의 Embedder, Trunk 및 Folding 모듈 구성 요소로 추상화합니다. ESMFold[2], OmegaFold[3], IgFold[4]의 한 모델을 Embedder, Trunk, Folding 모듈의 특정 유형에 따라 호출할 수 있는 메타 아키텍처를 설계합니다. 또한, 각 구성 요소의 특정 알고리즘을 선택하여 상호 교환 가능하고 사용자 친화적으로 결합할 수 있으므로 새로운 모델 변형을 쉽게 정의할 수 있습니다. 나아가, 연구자는 새로운 유형의 구성 요소를 구현하여 Solvent의 다른 기본 제공 구성 요소와 결합할 수 있습니다. 예를 들어, 제안된 새로운 단백질 언어 모델을 Embedder로 적용하여 Solvent의 기존 Trunk 및 Folding 모듈로 실험하여 연구자가 연구 효율성을 높일 수 있습니다. 이 외에도 Solvent는 모델 성능을 벤치마킹하기 위해 여러 학습 및 테스트 데이터 세트에 대한 기본 제공 지원을 제공합니다. 단일 체인 기반 일반 단백질 및 다중 체인 기반 항체 데이터 세트는 적절한 메트릭으로 지원됩니다. 특히 학습 및 추론 효율성을 극대화하기 위해 최근 제안된 최적화 기술인 xformers[10]의 힘을 활용했습니다. 또한, Solvent의 학습 속도가 원래 구현에 비해 약 30% 최적화되도록 다른 최적화를 사용합니다. Solvent가 어떻게 작동하는지 확인하고 보여주기 위해, 우리는 먼저 ESMFold를 재생산하여 Solvent의 재현성을 확인하는 실험을 했습니다. 또한 메타 아키텍처를 구성하는 구성 요소에 대한 방법 조합을 실험하여 어떤 Embedder와 어떤 Trunk가 더 효과적인지 평가했습니다. 나아가, 항체 특정 언어 모델을 일반 단백질 언어 모델로 대체할 수 있는지, Evoformer가 얼마나 효과적인지와 같은 구조 예측 연구에 유용한 통찰력을 제공하는 실험을 수행합니다. Solvent는 단일 시퀀스 단백질 폴딩을 넘어 더 많은 알고리즘과 더 광범위한 개념을 지원하도록 확장될 것입니다.Embedder 메타 아키텍처 ✓ SSPF ✓ IGFold Trunk 폴딩 헤드 ✓ ESM ✔ OMEGAPLM ✓ Antiberty ✓ Evoformer GeoformerLite ✓ IgFoldTrunk AlphafoldStructure IgFoldStructure AlphafoldHeads ✓ IgFoldHeads 그림 1: Solvent는 모델을 메타 아키텍처로 일반화합니다. 메타 아키텍처의 구성 요소는 추상화되고 해당 세부 정보는 폴딩 알고리즘을 결정합니다. 표 1: 모델 추상화 방법 Embedder Trunk 폴딩 헤드 ESMFold ESM Evoformer OmegaFold-lite IgFold OmegaPLM Antiberty GeoformerLite IgFoldTrunk AlphafoldStructure | AlphafoldHeads AlphafoldStructure AlphafoldHeads IgFoldStructure IgFoldHeads 2 지원 구성 요소 Solvent는 모델과 데이터가 독립적인 파이프라인으로 관리되는 임의의 데이터에 대한 임의의 모델을 학습하고 평가하도록 설계되었습니다.이 섹션에서는 각각에 대해 더 자세히 설명합니다.2.1 모델 Solvent는 여러 가지 단백질 접힘 모델을 지원하지만 각 모델은 메타 아키텍처로 추상화됩니다.메타 아키텍처는 다음 구성 요소로 구성됩니다.Embedder Embedder는 시퀀스를 입력으로 사용하여 ESM-2와 같은 사전 학습된 단백질 언어 모델(PLM)에서 계산된 쌍 표현을 사용하여 시퀀스 임베딩을 출력합니다.Solvent는 내장 임베더로 ESM-2[11], OmegaPLM[3], Antiberty[12]를 지원합니다.트렁크 트렁크는 구조 예측의 주요 구성 요소입니다. 시퀀스 임베딩과 이전 구성 요소인 Embedder에서 계산한 쌍 표현 간에 정보를 교환하며, 이전 사이클에서 예측된 원자 위치를 활용하는 재활용 임베더를 포함합니다.Evoformer[1], GeoformerLite 및 IgFoldTrunk[4]는 Solvent에서 지원되는 기본 제공 기능입니다.GPU 메모리 제약으로 인해 Geoformer [3]의 간소화된 버전인 GeoformerLite를 제공합니다.원래 Geoformer의 전체 성능을 보여주지 않는다는 점에 유의하세요.폴딩 폴딩 모듈은 이전 구성 요소인 Trunk에서 계산된 단일 표현 및 쌍 표현을 사용하여 구조의 3D 좌표를 직접 예측합니다.AlphafoldStructure[1], IgfoldStructure[4]는 Solvent에서 지원됩니다.헤드 헤드는 Trunk 및 Folding 모듈(예: pLDDT, 디스토그램)에서 얻은 기능을 기반으로 작업별 예측 및 손실 계산을 수행합니다.Solvent에는 Alphafold2[1] 및 IgFold[4]에서 사용되는 모든 보조 헤드가 포함되어 있습니다. 언급된 모든 구성 요소는 표 1에 나열되어 있습니다. 연구자는 구성 요소의 특정 방법을 변경하여 쉽게 모델 변형을 만듭니다. 예를 들어, ESM-2 Embedder와 GeoformerLite Trunk와 같은 기성품 구성 요소를 결합하여 새 모델을 정의하여 새 모델 변형을 빠르게 만들고 Evoformer와 GeoformerLite를 정확하게 비교할 수 있습니다. 기본 제공 방법 외에도 연구자는 새 사용자 정의 방법을 구성 요소로 추가하고 기본 제공 모듈로 새 모델을 정의할 수 있습니다. 2.2 데이터 세트 Solvent는 단일 사슬 기반 일반 단백질 데이터 세트와 다중 사슬 항체 데이터 세트를 지원합니다. 아래에 설명된 데이터 세트입니다. 2.2.1 일반 단백질 데이터 세트 PDB 데이터 세트는 Protein Data Bank[13]에서 가져온 것이며 ESMFold[2] 논문과 마찬가지로 2020년 5월 이전의 데이터를 사용합니다. Uniref 데이터 세트는 기본적으로 Alphafold predicted dataset(afdb)[1]에서 가져온 것이며 Uniref50에 해당하는 데이터만 사용합니다. 평균 pLDDT가 70 이상인 샘플을 사용합니다. CAMEO 데이터 세트는 CAMEO[14]에서 가져온 것이며 우리는 주로 평가용으로 사용합니다. 우리는 2022년 6월 25일 이전의 3개월에 대한 데이터만 사용합니다. 2.2.2 항체 데이터 세트 SAbDab_20210331 SAbDab[15]을 기반으로 한 항체 데이터 세트로 2021년 3월 이전의 데이터를 사용합니다. 중쇄-경쇄 쌍 샘플과 중쇄만 있는 나노바디 샘플이 데이터 세트에 포함됩니다. SAbDab_igfold 벤치마크를 위해 IgFold[4] 논문에서 선택한 데이터 세트는 많은 논문에서 일반적으로 사용되는 세트입니다. 우리는 주로 평가용으로 사용합니다. 기본 제공 데이터 세트를 제외하고 사용자 정의 데이터 세트를 Solvent에 쉽게 추가하여 기본 제공 데이터 세트로 모델을 학습하는 데 사용할 수 있습니다. 잘 등록된 데이터 세트로 모든 모델을 학습하고 평가할 수 있습니다. 3 벤치마크 먼저 ESMFold[2]의 재현성을 벤치마킹하여 Solvent의 재현성을 확인합니다. 그런 다음 다양한 유형의 Embedder와 Trunk를 조합하여 실험하여 Solvent의 편리함과 간단한 모델 변형의 벤치마킹을 경험합니다. 나아가 단백질 구조 예측에 도움이 되는 통찰력을 얻기 위해 추가 실험을 수행합니다. 3.1 실험 설정 데이터 세트 일반 단백질의 경우 모델을 훈련하는 데 pdb와 af2_uniref50을 사용합니다. 평가에는 cameo 데이터 세트를 사용합니다. 항체 특이적 모델의 경우 각각 모델을 훈련하고 평가하는 데 sabdab_20210331 데이터 세트와 sabdab_igfold 데이터 세트를 사용합니다. 훈련 세부 정보 일반 단백질의 경우 ESMFold[2]의 훈련 체계를 따랐습니다. 시퀀스의 자르기 크기는 초기 훈련의 경우 256으로 고정되고 미세 조정의 경우 384로 고정됩니다. 실험하는 모델의 Trunk 깊이가 낮기 때문에 미세 조정 시에도 위반 손실을 적용하지 않습니다. 배치 크기는 AlphaFold2와 마찬가지로 128로 고정되고 GPU당 배치 크기는 모델 크기에 따라 달라집니다. 평가 지표 TMscore[16]는 일반 단백질을 평가하는 데 사용됩니다. 시퀀스 정렬은 기본 옵션으로 사용됩니다. 항체 모델의 경우 PyRosetta[17]를 사용하여 영역별 RMSD를 측정합니다. 3.2 기존 모델 벤치마킹 3.2. 용매의 재현성 우리는 용매를 통해 ESMFold를 정의하고 재현성을 확인하기 위한 성능을 벤치마킹합니다. 48개의 Evoformer로 ESMFold 전체 모델을 재현하는 대신 Trunk-off 모델을 사용합니다. 실험에는 다양한 크기(35M, 150M, 650M)의 ESM-2를 사용합니다. 표 2에 보고된 대로 일부 모델은 약간 낮은 TMscore로 재현되고 일부는 약간 더 나은 성능으로 재현되지만 논문[2]과 비슷한 수준으로 재현됩니다. 재현성 실험에 대해서만 미세 조정 단계까지 모델을 훈련하고 다른 실험에 대해서는 초기 훈련까지 모델을 훈련합니다.표 2: ESMFold 논문에서 보고한 TM점수와 용매로 재현된 ESMFold 모델과의 비교.방법 용매 논문에서 보고한 ESM-2(35M) 0.0.ESM-2(150M) 0.0.ESM-2(650M) 0.0.표 3: 두 가지 다른 방법의 구성 요소를 결합하여 만든 간단한 모델 변형. 방법 Embedder Trunk TMscore ESMFold ESM-2(650M) 2 Evoformer 0.OmegaFold-lite 조합 조합 OMEGAPLM(670M) 2 GeoformerLite 0.OMEGAPLM(670M) 2 Evoformer ESM-2(650M) 2 GeoformerLite 0.0.3.2.2 모델 조합 Solvent에서는 다양한 구조 예측 모델의 구성 요소를 쉽게 결합할 수 있어 방법 간 성능 비교가 가능합니다. 이러한 편의성을 활용하여 ESMFold와 OmegaFold-lite라는 두 가지 방법의 Embedder와 Trunk에 대한 조합 연구를 수행합니다. 원래 OmegaFold[3]는 구조 모듈의 IPA 가중치를 공유하지 않지만, 견고한 비교를 위해 가중치 공유 IPA를 실험했습니다. 이전 섹션에서 언급했듯이 리소스 제약으로 인해 단순화된 Geoformer인 Geoformer-lite를 사용합니다. 즉, OmegaFold-lite는 원래 OmegaFold의 완전히 재현된 버전이 아닙니다.표 3은 두 가지 다른 방법의 구성 요소를 순열하여 다양한 모델 변형의 성능을 보여줍니다.이러한 실험은 연구자에게 Embedder 또는 Trunk 중 어느 것이 더 나은지 평가할 수 있는 엄격한 비교 프레임워크를 제공합니다.3.3 추가 연구 Solvent는 다양한 실험을 객관적으로 수행하는 쉬운 방법을 제공합니다.이를 통해 연구자는 방법 간에 의미 있는 비교를 할 수 있습니다.우리는 몇 가지 추가 연구를 수행했으며 그 결과가 구조 예측 연구에 대한 통찰력을 제공하기를 바랍니다.3.3.1 학습 가능한 언어 모델을 사용하여 Trunk 수 최소화 Evoformer와 같은 Trunk 모듈은 구조 예측에서 성능을 개선하는 데 필수적입니다.그러나 컴퓨팅 비용이 많이 들고 대용량 GPU 메모리가 필요합니다.따라서 효율성을 달성하기 위해 다양한 엔지니어링 방법[18]이 제안되었습니다.트렁크에는 단일 표현과 구조 정보를 포함하는 쌍 표현 간의 정보 교환 프로세스가 포함되며 많은 블록(예: ESMFold의 경우 48개 블록)을 통해 반복적으로 수행됩니다. 한편, ESMFold, OmegaFold, IgFold와 같은 대부분 알고리즘은 PLM 계층을 동결하고 Trunk만 학습 데이터에서 구조를 학습하게 합니다. PLM의 매개변수를 동결 해제하고 구조 정보를 언어 모델로 역전파하면 Trunk의 블록 수를 줄일 수 있습니다. 이를 증명하기 위해 PLM 유형과 Trunk 수에 따라 네 가지 ESMFold 변형을 정의합니다. 표 4에서 변형 1과 변형 2를 비교하면 학습 가능한 PLM의 효과가 나타납니다. 변형 1과 변형 3은 Evoformer의 효과를 보여줍니다. 학습 가능한 PLM은 TMscore 성능이 7% 향상되고 단일 Evoformer를 사용하면 TMscore 성능이 10% 향상됩니다. 학습 가능한 PLM 모델(변형 2)에 단일 Evoformer를 추가하면 성능이 약간 향상됩니다. 변형 4가 가장 좋은 모델일 것으로 예상하지만 Evoformer가 있는 학습 가능한 PLM은 성능이 저하됩니다. 모든 실험은 ESM-2(35M)을 Embedder로 사용하여 수행되었다.3.3.2 항체 구조 예측에 일반 단백질 언어 모델 사용 일반 단백질에 대한 다양한 대규모 언어 모델이 존재하는데, 예를 들어 ESM-2(최대 15B) 및 OmegaPLM(670M)이 있다.그러나 항체 특이적 모델은 Antiberty(25M)로 표현되는데, 이는 일반 단백질에 비해 작고, 이를 학습시키기 위한 데이터 집합의 크기도 표 4: Embedder 상태 및 Trunk 수에 따른 모델 변형.Trunk 방법 Embedder 상태 TMscore 변형1 동결 변형학습 가능 0 Evoformer 0.0 Evoformer 0.변형3 동결 변형학습 가능 1 Evoformer 0.1 Evoformer 0.표 5: 더 많은 데이터 집합을 등록하여 테스트 집합으로 사용할 수 있다. 방법 CASPDe-novo Orphan variant1 0.0.0.variant2 0.0.0.variant3 0.0.0.variant4 0.0.0.표 6: PLM 기반 항체 모델 변형 및 해당 상태. 방법 IgFold(재생성) IgFold-variantl IgFold-variantIgFold-variantEmbedder Embedder Status Meta-arch Antiberty(25M) Freeze IGFold ESM-2(35M) Freeze IGFold ESM-2(650M) Freeze IGFold ESM-2(35M) Trainable IGFold 방법 표 7: 다양한 항체 모델의 성능. IDDT-Ca IgFold(종이) IgFold(재생산) 0.IgFold-변형0.IgFold-변형IgFold-변형0.0.OCD H Fr H1 H2 H3 L Fr L1 L3.77 0.45 0.80 0.75 2.99 0.45 0.83 0.51 1.3.74 0.57 0.92 0.80 3.09 0.67 1.12 0.55 1.3.76 0.62 0.87 0.94 3.06 0.49 0.90 0.51 1.3.77 0.48 0.91 0.94 3.20 0.48 0.94 0.49 1.3.88 0.51 0.89 0.85 3.14 0.51 1.00 0.50 1.Lto ESM-2 및 OmegaPLM. 현재 일반 단백질 언어 모델은 공개적으로 사용 가능하고 사용하기 쉽습니다. 항체 특정 언어 모델인 Antiberty가 일반 PLM에 비해 항체 구조 예측에 여전히 특히 고유한지 조사할 가치가 있습니다. 항체 모델 변형의 세부 정보는 표 6에 나와 있습니다. 나열된 모델의 성능은 표 7에 보고되어 있습니다. IgFold(reproduced)와 Igfold-variant1을 비교하면 Antiberty와 ESM-2(35M)를 사용하는 것 사이의 성능 차이는 크게 눈에 띄지 않습니다. Antiberty 모델은 일부 CDR에서 더 나은 성능을 보이지만 크게 그렇지는 않습니다. 사실, 큰 일반 단백질 언어 모델(IgFold-variant2) 모델을 사용하는 것이 항체 특정 언어 모델을 사용하는 것보다 더 효과적인 것으로 보입니다. 학습 가능한 매개변수를 가진 일반 언어 모델(IgFold-variant3)을 사용해도 대부분 CDR에서 성능 향상이 나타나지 않는다. 3.4 사용자 정의 데이터 세트를 추가하고 다양한 모델에서 평가 가능 Solvent에서는 모든 데이터 세트를 등록하여 모델을 학습하고 평가하는 데 사용할 수 있다. 예를 들어, CASP14 데이터 세트, de-novo 단백질, orphan 단백질을 등록한다. CASP14의 경우 공개적으로 공개된 샘플 33개를 사용했다. T1044는 메모리 제약으로 인해 포함되지 않았다. de-novo 및 orphan 단백질의 경우 RGN2[19] 저장소에서 제공하는 타겟 목록을 참조하고 2020년 5월 이후에 공개된 샘플을 사용했다. 이러한 샘플은 ESM-2를 학습할 때 사용될 수 있으며, 이는 de novo 단백질에 높은 성능을 가져온다. 모든 샘플은 부록에 나와 있다. 표 4에 나열된 모델 변형은 이 세 가지 다른 데이터 세트에서 평가할 수 있다(표 5).4
--- CONCLUSION ---
일관되고 사용하기 쉬운 연구 프레임워크를 지원하기 위해, 우리는 단백질 접힘 연구를 위한 Solvent를 제안합니다. 우리는 Solvent를 기반으로 한 효율적이고 엄격한 실험을 통해 각 알고리즘의 강점과 약점을 더욱 입증하고 궁극적으로 구조적 예측 연구를 가속화하기를 바랍니다. 현재 Solvent는 MSA 없는 단백질 구조 예측 모델에 집중하고 있습니다. 우리는 Solvent를 MSA와 템플릿을 입력으로 사용하고 고아 단백질 및 de-novo 단백질과 같은 더 많은 검증 데이터를 지원하는 보다 일반적인 방식으로 확장할 것입니다. 감사의 말 Solvent를 최적화한 Kakao Brain의 언어 모델 엔지니어링 팀의 기여에 감사드립니다. 이러한 최적화를 통해 Solvent는 학습 속도와 메모리 측면에서 효율적이 되어 연구자들은 더 큰 모델을 쉽게 활용할 수 있습니다. 그들의 지원은 이 작업에서 제시된 결과를 달성하는 데 필수적이었습니다. 참고문헌 [1] John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Žídek, Anna Potapenko, Alex Bridgland, Clemens Meyer, Simon AA Kohl, Andrew J Ballard, Andrew Cowie, Bernardino Romera-Paredes, Stanislav Nikolov, Rishub Jain, Jonas Adler, Trevor Back, Stig Petersen, David Reiman, Ellen Clancy, Michal Zielinski, Martin Steinegger, Michalina Pacholska, Tamas Berghammer, Sebastian Bodenstein, David Silver, Oriol Vinyals, Andrew W Senior, Koray Kavukcuoglu, Pushmeet Kohli, Demis Hassabis. AlphaFold를 사용한 매우 정확한 단백질 구조 예측. Nature, 596(7873):583–589, 2021. [2] Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Nikita Smetanin, Robert Verkuil, Ori Kabeli, Yaniv Shmueli, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Salvatore Candido, Alexander Rives. 언어 모델을 사용한 원자 수준 단백질 구조의 진화적 규모 예측. bioRxiv, 2022. [3] Ruidong Wu, Fan Ding, Rui Wang, Rui Shen, Xiwen Zhang, Shitong Luo, Chenpeng Su, Zuofan Wu, Qi Xie, Bonnie Berger, Jianzhu Ma, Jian Peng. 1차 시퀀스에서 고해상도 de novo 구조 예측. bioRxiv, 2022. [4] Jeffrey A Ruffolo, Lee-Shin Chu, Sai Pooja Mahajan, Jeffrey J Gray. 방대한 자연 항체 세트에서 딥 러닝을 통한 빠르고 정확한 항체 구조 예측. Nature communications, 14(1):2389, 2023. [5] Jiaxiang Wu, Fandi Wu, Biaobin Jiang, Wei Liu, Peilin Zhao. tfold-ab: 서열 상동체 없이 빠르고 정확한 항체 구조 예측. bioRxiv, 2022. [6] Gustaf Ahdritz, Nazim Bouatta, Sachin Kadyan, Qinghui Xia, William Gerecke, Timothy J O&#39;Donnell, Daniel Berenberg, Ian Fisk, Niccolò Zanichelli, Bo Zhang, et al. Openfold: alphafold2를 재교육하면 학습 메커니즘과 일반화 능력에 대한 새로운 통찰력을 얻을 수 있습니다. bioRxiv, 2022-11, 2022쪽. [7] Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun. 더 빠른 r-cnn: 영역 제안 네트워크를 사용한 실시간 객체 감지를 향해. C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, R. Garnett 편집자, 신경 정보 처리 시스템의 발전, 28권. Curran Associates, Inc., 2015. [8] Yuxin Wu, Alexander Kirillov, Francisco Massa, Wan-Yen Lo, Ross Girshick. Detectron2. https://github.com/facebookresearch/Detectron2, 2019. [9] Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, Yu Xiong, Xiaoxiao Li, Shuyang Sun, Wansen Feng, Ziwei Liu, Jiarui Xu, Zheng Zhang, Dazhi Cheng, Chenchen Zhu, Tianheng Cheng, Qijie Zhao, Buyu Li, Xin Lu, Rui Zhu, Yue Wu, Jifeng Dai, Jingdong Wang, Jianping Shi, Wanli Ouyang, Chen Change Loy 및 Dahua Lin. MmDetection: mmlab 감지 도구 상자 및 벤치마크를 엽니다. CoRR, ABS/1906.07155, 2019.[10] Benjamin Lefaudeux, Francisco Massa, Diana Liskovich, Wenhan Xiong, Vittorio Caggiano, Sean Naren, Min Xu, Jieru Hu, Marta Tintore, Susan Zhang, Patrick Labatut 및 Daniel Haziza. xformers: 해킹 가능한 모듈식 변압기 모델링 라이브러리입니다. https://github.com/facebookresearch/xformers, 2022. [11] Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Nikita Smetanin, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido 등. 진화 규모의 단백질 서열에 대한 언어 모델은 정확한 구조 예측을 가능하게 합니다. bioRxiv, 2022. [12] Jeffrey A Ruffolo, Jeffrey J Gray 및 Jeremias Sulam. 언어 모델과 약한 감독 학습을 통한 항체 친화도 성숙 해독. arXiv, 2021. [13] Helen M. Berman, John Westbrook, Zukang Feng, Gary Gilliland, TN Bhat, Helge Weissig, Ilya N. Shindyalov, Philip E. Bourne. 단백질 데이터 뱅크. 핵산 연구, 28(1):235–242, 01 2000. [14] J&#39;urgen Haas, Alessandro Barbato, Dario Behringer, Gabriel Studer, Steven Roth, Martino Bertoni, Khaled Mostaguir, Rafal Gumienny, Torsten Schwede. casp12에서 구조 예측의 중요한 평가를 보완하는 지속적인 자동화된 모델 평가(카메오). Proteins, 86(S1):387–398, 2018. [15] James Dunbar, Konrad Krawczyk, Jinwoo Leem, Terry Baker, Angelika Fuchs, Guy Georges, Jiye Shi, Charlotte M. Deane. SAbDab: 구조적 항체 데이터베이스. Nucleic Acids Research, 42(D1):D1140-D1146, 11 2013. [16] Y. Zhang 및 J. Skolnick. 단백질 구조 템플릿 품질의 자동 평가를 위한 채점 기능. Proteins, 57(4):702-710, 2004. [17] Sidhartha Chaudhury, Sergey Lyskov, Jeffrey J. Gray. Pyrosetta: rosetta를 사용하여 분자 모델링 알고리즘을 구현하기 위한 스크립트 기반 인터페이스. Bioinformatics, 26(5):689–691, 2010. [18] Shenggan Cheng, Ruidong Wu, Zhongming Yu, Binrui Li, Xiwen Zhang, Jian Peng, and Yang You. Fastfold: Reducing alphafold training time from 11 days to 67 hours, 2022. [19] Ratul Chowdhury, Nazim Bouatta, Surojit Biswas, Charlotte Rochereau, George M. Church, Peter K. Sorger, and Mohammed AlQuraishi. 딥 러닝의 언어 모델을 사용한 단일 시퀀스 단백질 구조 예측. bioRxiv, 2021. A 부록 A.1 Table A.1.CASP에 사용된 샘플 목록 공개적으로 발표된 샘플 33개를 사용했습니다. T1044는 포함되지 않습니다. T1024, T1025, T1026, T1027, T1029, T1030, T1031, T1032, T1033, T1035, T1036s1, T1037, T1038, T1039, T1040, T1041, T1042, T1043, T1046s1, T1046s2, T1049, T1050, T1054, T1056, T1064, T1067, T1073, T1074, T1079, T1080, T1082, T1090, T1099. A.1.2 De novo 단백질 RGN2 저장소 대상 목록에서 2020년 5월 이후에 공개된 111개 샘플을 사용했습니다.7BQS_A, 6X1K_A, 6W6X_A, 7A4Y_E, 7BQR_A, 7RX5_A, 7BQC_A, 7BQQ_A, 7DNS_A, 7BQB_A, 6YPI_A, 6Z35 A, 7BQE_A, 6ZOF_D, 7CZ0_E, 7BPN_A, 7BQD_A, 7CX4_N, 7BPM_A, 6WXO_B, 6XT4_A, 6XEH_A, 7BPL_A, 7BQN_A, 6XSS_A, 6WMK_A, 7AWY_A, 7AVA_A, 7A4D_E, 7B09_C, 7DI0_A, 6YB2_A, 7B08_B, 6YB1_A, 6VG7_A, 7BIM_A, 7BEY_A, 7AWZ_A, 6YB0_A, 7A8S_A, 7BQM_A, 6RLH_A, 6WXP_A, 6W9Y_A, 6UIB_C, 6RLI_A, 6UIS_A, 7RGR_B, 6WVS_A, 7BPP_A, 6W9Z_D, 7ARR_A, 6ZLI_C, 7AX0_A, 7ARS_A, 6X16_A, 6ZT1_A, 6WRV_D, 7AX2_A, 6Y7N_A, 6VFL_B, 6WRW_C, 6VGA_A, 6VFK_B, 6Z3X_B, 7BNT_B, 7CUV_A, 7N8J_B, 6VFJ_B, 7KBQ_A, 7CD8_A, 6YAZ_E, 6VFI_B, 6X8N_A, 6VGB_A, 6VFH_A, 6W70_A, 7BAU_E, 6ZIE_A, 6ZOL_A, 6REO_A, 6ZV9_B, 6W90_A, 7BAT_A, 7JH6_A, 6Z0M_A, 7A50_B, 7JH5_A, 7BAW_A, 6YWC_C, 6WA0_B, 7DDR_A, 6Z2I_A, 7BWW_A, 7A48_B, 7BAV_C, 6WRX_C, 6V67_B, 6X9Z_A, 6YWD_C, 6XR1_A, 6XNS_B, 6VL5_D, 6VEH_A, 7AIT_C, 6XR2_E, 6VL6_A, 7BAS_B, 7CBC_A, 6XH5_B, 7B0A_C A.1.3 고아 단백질 RGN2 저장소 대상 목록에서 2020년 5월 이후에 공개된 6개 샘플을 사용했습니다. 6M64_F, 6YNS_O, 7ALO_A, 7DGU_A, 7KEI_C, 70SC_A.
