--- ABSTRACT ---
실제 응용 프로그램에서 언어 모델을 사용하는 데 있어 주요 위험은 잘못된 진술을 환각하는 경향입니다. 환각은 종종 LM의 지식 격차에 기인하지만, 우리는 어떤 경우에 이전에 생성된 환각을 정당화할 때 LM이 별도로 잘못된 것으로 인식할 수 있는 거짓 주장을 출력한다고 가정합니다. 우리는 ChatGPT와 GPT-가 종종 잘못된 답변을 말하고 적어도 하나의 잘못된 주장이 있는 설명을 제공하는 세 가지 질의응답 데이터 세트를 구성합니다. 중요한 점은 ChatGPT와 GPT-4가 각각 자신의 실수의 67%와 87%를 식별할 수 있다는 것을 발견했습니다. 우리는 이 현상을 환각 눈덩이 현상이라고 부릅니다. LM이 초기 실수에 과도하게 집착하여 그렇지 않으면 하지 않았을 더 많은 실수를 저지릅니다.¹ 1
--- INTRODUCTION ---
언어 모델은 개방형 정보 탐색 및 문제 해결 환경에서 인간과 인터페이스하기 위해 점점 더 많이 사용되고 있습니다. 다양한 능력과 극도의 유창함에도 불구하고 주요 개방형 과제는 LM이 여전히 사실을 만들어내거나 존재하지 않는 출처를 인용하여 환각을 보인다는 것입니다(Maynez et al., 2020; Liu et al., 2023, ia). 종종 매우 그럴듯하게 들리기도 합니다. 환각은 일반적으로 LM의 지식 격차에 기인하며(Zheng et al., 2023), 지식 기반을 통한 검색을 통한 완화 전략의 동기를 부여합니다(Lewis et al., 2020; Shuster et al., 2021; Peng et al., 2023). 하지만 LM은 사실을 &quot;알지 못할&quot; 때만 환각을 보일까요? 우리는 LM이 종종 고립된 형태로 제시될 때 잘못된 것으로 즉시 인식하는 환각을 생성하는 환경을 제시합니다. 구체적으로, LM이 질문에 잘못 답한 후, 일반적으로 별도로 잘못되었다고 인정하는 잘못된 주장을 함으로써 해당 답변을 정당화합니다(그림 1). ¹저희 데이터와 코드는 https://github.com/Nanami18/Snowballed_Hallucination에서 확인할 수 있습니다. 9677은 소수인가요? 아니요, 9677은 소수가 아닙니다. 9677은 13 x 745이므로 745로 인수분해할 수 있습니다. 9677은 13으로 나누어떨어집니까? 잘못된 주장이 없습니다. 별도의 세션에서 환각을 눈덩이처럼 굴렸고, GPT-4는 해당 주장을 잘못된 것으로 인식합니다! 그림 1: GPT-4는 9677이 소수가 아니라고 잘못 주장한 다음, 13 × 745 = 9677이라는 잘못된 설명을 합니다. GPT-4가 13이 9677의 인수가 아니라는 것을 따로 질문했을 때 &quot;알고&quot; 있는 것처럼 보이기 때문에 우리는 이 인수분해를 눈덩이 환각이라고 부릅니다. 따라서 환각은 반드시 모델의 &quot;지식&quot; 부족을 반영하는 것은 아니지만 일관성을 위해 이전 환각으로 인해 유발될 수 있습니다. 이러한 행동을 경험적으로 연구하기 위해 세 가지 질문-답변(QA) 데이터 세트를 자동으로 구성합니다. 이러한 데이터 세트는 숫자가 소수인지, 두 가지 주어진 제약 조건을 충족하는 미국 상원 의원이 있는지, 도시 간 항공편 세트가 주어졌을 때 두 도시가 연결되어 있는지 여부를 판별하는 등 다양한 도메인에 걸쳐 있습니다. 경험적으로 ChatGPT(OpenAI, 2022)와 GPT-4(OpenAI, 2023)는 95% 이상의 시간 동안 첫 번째 토큰(예/아니요) 내에서 답을 확정합니다. 이러한 답변은 종종 틀리고 그 다음에 잘못된 설명이 뒤따릅니다. 그러나 잘못된 설명만 제시되면 LM이 그것을 틀렸다고 인식할 가능성이 있음을 알게 되었습니다. 이 현상을 환각 눈덩이 현상이라고 합니다. LM이 이전 환각과의 일관성을 위해( 영어: 모델의 &quot;지식 격차&quot;로), snowDataset Original Question Primality Testing User: 10733은 소수입니까? GPT-4: 아니요... 3 × 3577로 인수분해될 수 있습니다. 검증 질문 사용자: 10733은 3으로 나누어떨어집니까? 예 또는 아니요로 답하세요. GPT-4: 아니요 상원의원 검색 до 그래프 연결성 사용자: 뉴햄프셔주를 대표하고 모교가 펜실베이니아 대학교인 미국 상원의원이 있었습니까? GPT-4: 네... 그의 이름은 존 P. 헤일 사용자: 현재 항공편 정보(다음 항공편은 편도만 가능하며, 이용 가능한 모든 항공편은 아래에 포함되어 있습니다): 도시 F에서 도시 K로 가는 항공편이 있습니다 도시 H에서 도시 A로 가는 항공편이 있습니다 [... 공간을 위해 잘라낸 다른 10가지 규칙 ...] 사용자: 존 P. 헤일의 모교는 펜실베이니아 대학교였습니까? GPT-4: 아니요... [그것은] Bowdoin 사용자였습니다: [...맥락에서 주어진 항공편 정보...] 위의 항공편 정보를 기반으로, City K에서 City G까지의 항공편은 유효한 항공편입니까?GPT-4: 아니요, 위의 질문을 기반으로: 도시 B에서 도시 항공편 정보로 가는 일련의 항공편이 있습니까?직행 E는 없습니다.GPT-4: 네... 경로는 다음과 같습니다: ... 도시 K에서 도시 G까지... 도시 K에서 도시 G까지의 항공편.표 1: 원래 질문: 각 데이터 세트의 예와 GPT-4의 (잘못된) 응답.눈덩이 모양의 환각에 밑줄이 그어져 있습니다.검증 질문: GPT-4가 주장이 잘못되었는지 여부를 조사하는 데 사용된 해당 쿼리.눈덩이 모양의 환각에 대한 반박에 밑줄이 그어져 있습니다.눈덩이 모양의 환각은 고립된 상태(즉, 별도의 상호 작용 세션)에서 제시될 경우 잘못된 것입니다. LM이 대답을 하기 전에 추론하도록 장려하는 전략을 촉발하면 작업의 정확도가 향상되지만, 우리의 연구는 잘못된 맥락에 조건을 붙이면 LMS가 그렇지 않으면 하지 않을 극히 간단한 실수를 하게 된다는 더 광범위한 문제를 지적합니다. 실제로 &quot;단계적으로 생각해 보자&quot;(Kojima et al., 2023)라는 프롬프트를 사용할 때, 모델이 올바르게 대답하지 못하는 경우의 95%에서 눈덩이 환각이 여전히 발생합니다. 우리는 때때로 &quot;단계적으로 생각해 보자&quot;가 올바른 답으로 이어지는 경우에도 잘못된 추론 체인을 사용한다는 것을 관찰했습니다. 이 논문에서 우리는 최근 LM이 답을 진술하고 정당화하는 경향을 활용하여 환각 눈덩이 현상을 보여줍니다. 우리는 LM이 이전에 생성된 맥락에 과도하게 전념하는 대신, 초기 실수를 인정한 다음 답을 수정해야 한다고 믿습니다. 우리는 실제로 GPT-4가 제한된 수의 사례에서 이를 수행하는 것을 관찰했습니다. 이러한 동작을 확대하는 것은 유익할 뿐만 아니라 LM이 후퇴할 수 있는 새로운 방법을 개발하는 것도 유익할 것입니다. 2 우리는 왜 환각 눈덩이 현상을 예상합니까? 이 섹션에서 우리는 LM이 환각 눈덩이 현상에 취약하다고 가정하는 이유를 설명합니다. 우리는 눈덩이 현상이 두 가지 핵심 속성이 있는 질문에서 발생할 것으로 예측합니다. 1. 초기 커밋: 프롬프트는 LM이 먼저 답을 말하도록 이끈다(설명을 출력하기 전에). 이는 많은 예/아니요 질문에 적용된다. 2. 본질적으로 순차적: 변압기는 한 타임스텝 내에서 추론 능력이 제한되어 있기 때문에 한 타임스텝 내에서 답을 찾을 수 없다. 이제 이러한 속성이 어떻게 눈덩이 환각으로 이어질 수 있는지 논의한다. 초기 커밋. 영어와 다른 많은 언어에서 화자는 종종 답을 설명하기 전에 질문에 대한 최종 예/아니요 답을 말한다. 따라서 LM, 특히 명령어 조정 LM(Wei et al., 2021; Sanh et al., 2021; Ouyang et al., 2022; Wang et al., 2022)은 설명보다 답이 먼저 나오는 이 답변 형식을 반영할 것이라고 가설을 세웠다. 실제로, 저희 데이터 세트(§3.1에 제시됨)에서 GPT-4와 ChatGPT가 질문에 대한 답변을 즉시 확정한다는 것을 관찰했습니다. 첫 번째 토큰은 GPT-4와 ChatGPT의 경우 각각 95.67%와 98.40%의 시간 동안 예 또는 아니요입니다. 나머지 사례에서 모델은 종종 응답의 처음 몇 토큰 내에서 답변을 확정합니다(예: &quot;미국 상원의원에 대한 기록이 없습니다...&quot;). 중요한 점은 LM이 예 또는 아니요를 생성하면 해당 토큰이 맥락에 남아 있고 일관성을 위해서는 후속 정당화를 통해 해당 선택에 대한 확정이 필요하다는 것입니다. 따라서 모델은 단일 타임스텝에서 복잡한 질문에 대한 답변을 생성한 다음 해당 답변에 대한 설명을 생성하여 계속 진행하는데, 이는 필연적으로 틀릴 것입니다. 본질적으로 순차적입니다. 더욱이 변환기는 최근 이론적 결과(Merrill 및 Sabharwal, 2023)에 기록된 대로 단일 타임스텝 내에서 소수성 테스트 또는 그래프 연결성과 같은 본질적으로 순차적인 추론 문제를 해결할 수 없습니다.² 그래프 연결성과 소수성 데이터 세트는 이러한 문제의 구체적인 사례입니다. 변환기는 정답에 답하기 위해 여러 타임스텝이 필요한 질문에 답하기 위해 한 단계를 사용해야 하기 때문에 때로는 필연적으로 틀린 답을 하게 됩니다. 이로 인해 LM이 그렇지 않으면 생성하지 않았을 잘못된 사실을 뒷받침하는 환각을 하게 된다는 가설을 세웠습니다. 3 실험 §2에 설명된 속성을 가진 세 개의 QA 데이터 세트를 설계하여 환각 스노우볼링을 조사하고 ChatGPT와 GPT-4를 평가합니다. 먼저 LM이 주어진 질문에 대한 정답을 반환하는지 확인하고 모델이 틀린 답을 반환할 때 해당 틀린 답에 대한 잘못된 설명을 자주 제공한다는 것을 보여줍니다. 설명에서 틀린 주장을 자동으로 추출하여 동일한 LM에 해당 주장이 맞는지 확인하도록 요청합니다. 각 데이터 세트의 대표적인 예는 표 1을 참조하십시오. 3.1 데이터 세트 각각 변환기가 한 타임스텝에서 답할 수 없을 것으로 예상되는 예/아니요 질문이 포함된 세 개의 QA 데이터 세트를 설계합니다. 평가를 돕기 위해, 질문은 틀린 답변이 쉽게 검증 가능한 주장으로 정당화되도록 설계되었습니다.2 기술적으로 이는 특정 경도 수준, 즉 소수 검정을 위한 소수의 크기 또는 그래프 연결성을 위한 그래프의 크기를 초과하는 입력에만 해당됩니다.3 Merrill과 Sabharwal(2023)은 단일 생성 단계로 제한된 정밀도 변환기가 복잡도 클래스 TC 외부의 문제를 해결할 수 없음을 보여줍니다.TC는 L(로그 공간)과 P(다항식 시간)의 매우 병렬화 가능한 하위 클래스에 해당합니다.그래프 연결성은 L-완전 문제이므로 TC = L이 아니면 TC에 포함될 수 없습니다.즉, 모든 L을 놀라울 정도로 높은 수준으로 병렬화할 수 있습니다.소수 검정은 P에 있는 것으로 나타났지만(Agrawal et al., 2004) L에도 없으면 TC에 포함될 수 없습니다.즉, 모든 n은 O(log log n) 비트의 오버헤드로 인수분해할 수 있습니다. 요약하자면, 표준 복잡도 이론적 추측이 거짓이 아니라면 그래프 연결성과 소수 검정은 TC° 범위를 벗어나므로 변환기가 단일 세대에서 풀기에는 본질적으로 너무 순차적입니다(참조: Merrill 및 Sabharwal, 2023). 각 데이터 세트에 대해 모든 예에 대해 하나의 특정 레이블을 고정하여 모델이 잘못된 답(예: 9677이 소수가 아님)을 선택하는 경우 이를 뒷받침하는 특정 주장(예: 잘못된 인수분해)을 생성합니다. 이를 통해 잘못된 답에 대한 모델 작성 정당화를 체계적으로 검토할 수 있습니다. 소수 검정 이 데이터 세트의 경우 1,000~20,000 사이에서 무작위로 선택한 500개의 소수의 소수를 쿼리합니다. 정답은 항상 &#39;예&#39;입니다. 모델이 틀린 답을 하면 틀린 인수분해로 답을 정당화할 것으로 예상합니다. 상원 의원 검색 이 데이터 세트는 &quot;x 주를 대표하고 모교가 y인 미국 상원 의원이 있었습니까?&quot;라는 형식의 질문으로 구성되어 있습니다. 여기서 x는 미국 주이고 y는 미국 대학입니다. 이러한 질문에 대한 정답은 항상 아니요입니다. 모델이 틀린 답을 하는 경우 특정 상원 의원이 x를 대표하고 y에 다녔다고 거짓으로 주장할 것으로 예상합니다. 데이터 세트를 만들기 위해 모든 미국 주와 수동으로 구성된 12개의 인기 있는 미국 대학 목록을 고려합니다(전체 목록은 §A 참조). 가능한 각 쌍에 대해 템플릿을 따라 질문을 생성하고 답이 예인 쌍을 수동으로 제거합니다. 그래프 연결성 이 데이터 세트의 500개 질문 각각에 대해 도시 간 항공편 12개를 제시하고 특정 도시에서 다른 도시로 가는 항공편 시퀀스가 있는지 묻습니다. 문제는 항상 동일한 기본 방향 그래프 구조(§A.1 참조)에 해당합니다. 여기서 항공편은 모서리이고 도시는 노드입니다. 데이터 세트의 각 인스턴스에 대해 영어 알파벳에서 무작위로 문자를 할당하여 노드의 이름을 지정합니다. 질의를 공식화하기 위해 서로 다른 하위 그래프에서 출발 도시 s와 목적지 도시 t를 샘플링합니다. 여기서 추가 제약 사항은 s가 출발 노드에 해당하고 ta가 잎 노드에 해당하므로 1단계 휴리스틱을 사용하여 문제를 해결할 수 없습니다. 문제를 자연어로 된 항공편 찾기 질문으로 공식화하여 더 자연스럽게 들리도록 했습니다. 프롬프트에서 12개 항공편을 나열했습니다(&quot;도시 F에서 도시 K로 가는 항공편이 있습니다. 도시 G에서 도시 N으로 가는 항공편이 있습니다...&quot;). 그 다음에 &quot;s에서 t로 가는 일련의 항공편이 있습니까?&quot;라는 질문이 나옵니다. 정답은 항상 아니요입니다. 모델이 틀린 답을 하면 존재하지 않는 항공편으로 답을 정당화할 것으로 예상합니다. 데이터 집합의 비율(%)오답(환각) 모델은 자신이 틀렸다는 것을 알고 있습니다(눈덩이 환각)우선성 테스트 상원 의원 검색 그래프 연결성우선성 테스트 상원 의원 검색 그래프 연결성 (a) ChatGPT (b) GPT-그림 2: ChatGPT와 GPT-4에 대한 환각 백분율과 눈덩이 환각 백분율(둘 다 전체 데이터 집합을 기준으로 계산). 이 플롯의 정확한 숫자는 부록의 표 6과 표 7에서 확인할 수 있습니다. 3.2 추론 언어 모델 설정. ChatGPT(gpt-3.5-turbo) 및 GPT-4에서 탐욕적 디코딩을 사용하여 모든 실험을 실행합니다. 실험은 제로샷(즉, 프롬프트에서 모델에 예제 QA 쌍을 표시하지 않음)입니다. 사용자가 LM과 상호 작용하는 가장 일반적인 방법인 직접 프롬프트에서의 모델 동작에 초점을 맞춥니다(전체 예는 §A 참조). 제로샷 체인 오브 생각 스타일 프롬프트 방법을 사용한 실험은 §4를 참조하세요. 각 데이터 세트에 대해 2단계 평가를 수행합니다. 먼저 모델의 정확도(즉, 모델이 올바르게 답하는 질문 수)를 평가합니다. 두 모델 중 하나가 틀렸을 때 경험적으로 항상 정당화를 생성합니다. 두 번째 단계에서는 모델이 설명에서 틀린 단계를 식별할 수 있는지 평가합니다. 주어진 질문에 대해 출력이 예 또는 아니요로 시작하는지 검토하여 모델의 응답을 평가합니다. 응답이 이러한 범주에 속하지 않는 경우 모델이 전달하는 답변을 수동으로 결정합니다. 3.3 LM의 눈덩이 환각 인식 우리는 LM이 출력에서 모델의 잘못된 주장을 모델 자체와 비교하여 검증함으로써 눈덩이 환각을 인식하는지 여부를 조사합니다. 우리의 인식 절차는 모델 출력의 수동 검사에서 얻은 휴리스틱에 의존하며, 이러한 휴리스틱은 다른 모델에서는 작동하지 않을 수 있습니다(예: 다른 모델은 숫자가 소수가 아니라는 주장을 뒷받침할 때 인수를 제공하지 않을 수 있음). 그래프 연결성 모델이 일련의 연결 항공편이 있다고 생각하는 각 샘플(답변이 예로 시작)에 대해 모델의 출력에서 항공편 목록을 수동으로 추출하고 유효하지 않거나 불연속적인 항공편을 식별합니다. 그런 다음 새 세션에서 모델에 추출된 항공편이 항공편 정보를 기반으로 유효한지, 연속된 항공편이 실제로 연결되어 있는지 확인하도록 요청합니다. 모델이 오류를 올바르게 감지하는지 확인하기 위해 수동으로 검증 출력을 평가합니다. 모델을 프롬프트하는 방법과 성공적인 검증의 예는 부록 표 3을 참조하세요. 소수성 테스트 모델이 숫자가 소수가 아니라고 답하는 각 샘플에 대해 모델이 이를 정당화하는 데 사용하는 인수를 추출합니다. 추출은 출력을 맥락에 넣고 &quot;위의 텍스트에서 제안된 인수는 무엇인가? 나열해 보세요.&quot;라고 묻는 방식으로 수행합니다. 원샷 데모(빠른 추론 속도)를 사용하여 추출에 ChatGPT를 사용합니다. 30개의 예를 수동으로 확인한 결과 항상 올바른 인수를 추출할 수 있음을 확인했습니다. 그런 다음 새 세션에서 모델에 추출된 각 인수를 개별적으로 검증하도록 요청합니다. 성공적인 검증의 예는 부록 표 4를 참조하십시오. 데이터 집합(%) 비율 소수성 테스트 원래 프롬프트 단계별 프롬프트 데이터 집합(%) LILIL 상원 의원 검색 그래프 연결 비율 소수성 테스트 상원 의원 검색(b) GPT-그래프 연결 (a) ChatGPT 그림 3: 원래 프롬프트를 사용할 때와 &quot;단계별로 생각해 봅시다&quot;를 사용할 때 ChatGPT 및 GPT-4의 오류율 및 눈덩이 환각율(해치 패턴) 정확한 숫자는 부록 표 8과 표 9를 참조하십시오.상원 의원 검색 모델이 그러한 상원 의원이 있다고 생각하는 각 샘플에 대해 모델이 상원 의원의 존재를 정당화하는 데 사용하는 상원 의원의 이름을 추출합니다.출력을 맥락에 넣고 &quot;위의 텍스트에서 언급된 상원 의원은 무엇입니까? 이름만 알려주십시오&quot;라고 질문합니다.다시 한번, ChatGPT를 사용하고 예제에서 수동으로 관찰된 완벽한 추출을 수행합니다.그런 다음 새 세션에서 모델에 해당 상원 의원의 모교가 문제의 단과대학이고 문제의 주를 나타내는지 묻습니다.성공적인 감지의 예는 부록 표 5를 참조하십시오.3.4 결과 질의-응답 정확도 그림 2는 ChatGPT와 GPT-4 모두 전반적으로 매우 낮은 정확도를 경험함을 보여줍니다.상원 의원 검색 데이터 세트의 ChatGPT를 제외하고 모든 모델은 50% 미만의 정확도를 달성합니다. (데이터 세트별 오류율 분석은 부록 표 6 참조) GPT-4는 일반적으로 ChatGPT보다 우수한 것으로 간주되지만(OpenAI, 2023) 모든 데이터 세트에서 ChatGPT보다 성능이 떨어지는 것을 관찰했습니다. ChatGPT의 평균 정확도는 39.87%인 반면 GPT-4는 16.6%에 불과합니다. 환각 감지 여기서는 모델이 잘못된 주장이 단독으로 제시될 때 잘못된 주장임을 식별할 수 있는지 확인합니다. 그림 2에서 볼 수 있듯이 ChatGPT는 설명에서 잘못된 주장의 67.37%(즉, 눈덩이 모양의 환각)을 감지하고 GPT-4는 87.03%를 감지합니다. 모델이 검증에 실패하는 경우(부록 표 12의 예) 눈덩이 모양의 환각으로 간주하지 않는다는 점에 유의하세요. 전반적으로 ChatGPT와 GPT-4는 모두 환각 눈덩이 현상에 매우 취약하여 매우 간단한 실수로 이어집니다. 4 눈덩이 모양의 환각을 예방할 수 있을까요? 우리는 LM이 현재 맥락(주어진 프롬프트와 이전 출력)과 일치하는 연속을 모델링하도록 훈련되었기 때문에 환각 눈덩이 현상이 발생한다고 가설을 세웠습니다. 근본적인 문제를 해결하려면 추론 시간 수정 이상이 필요할 수 있지만, 이 섹션에서는 두 가지 추론 전략, 즉 프롬프트(§4.1)와 디코딩 또는 훈련 방법(§4.2)의 효과를 연구하여 환각 눈덩이 현상을 완화합니다. 4.1 더 나은 프롬프트 엔지니어링 이 섹션에서는 모델이 답변 전에 추론 체인을 생성하도록 장려하는 다른 제로샷 프롬프트를 사용하여 눈덩이 현상 환각을 예방하는 더 나은 프롬프트의 효과를 살펴봅니다. 이러한 프롬프트에서 생성된 출력은 덜 구조화되어 있으므로 수동으로 검사하여 정확성과 눈덩이 현상 환각의 존재 여부를 확인합니다. 각 작업의 경우 원래 질문의 끝에 &quot;단계별로 생각해 봅시다&quot;를 추가합니다(표 1 참조). 그림 3에서 볼 수 있듯이 이 모델은 상원 의원 검색 작업을 완벽하게 풀고, 소수성 검정에서 &lt;10% 오류율, 그래프 연결성에서 ≤30%를 달성할 수 있습니다. 정확도가 크게 향상되었음에도 불구하고, 잠재적인 문제를 식별했습니다. 모델이 추론 체인을 출력하는 동안 때때로 환각을 보이는데, 이로 인해 이후 단계에서 환각이 눈덩이처럼 불어납니다. 예를 들어, 아래 출력에서 [....이전 단계 생략] 3단계: 도시 E에서 도시 N으로 가는 항공편, 도시 B로 가는 항공편, 도시 C로 가는 항공편의 세 가지 옵션이 있습니다.4단계: 도시 M으로 이어질 수 있는 유일한 옵션은 도시 E에서 도시 C로 가는 항공편입니다.[....나머지 출력 생략] ChatGPT는 3단계에 세 가지 옵션이 있다고 잘못 설명합니다(두 가지만 있음).이로 인해 눈덩이 환각 &quot;또는 도시 C로 가는 항공편&quot;이 유도됩니다(ChatGPT는 별도 세션에서 E → C가 유효한 항공편이 아님을 확인할 수 있음).그림 3에서 볼 수 있듯이 GPT-4는 여전히 작업 전체에서 평균 94.90%로 높은 전반적인 눈덩이 환각 비율을 보이고 ChatGPT도 비슷하게 높은 눈덩이 환각 비율을 얻습니다. 마지막으로, 우리의 실험은 단계별로 분해하기에 적합한 간단한 다단계 문제에 초점을 맞추었지만, 우리는 환각 눈덩이 현상이 더 광범위하게 개방형 텍스트 생성에서 나타나며, 생성에서 한 가지 실수가 더 많은 실수를 유발한다고 가설을 세웠습니다(Arora et al., 2022). 이런 경우 더 나은 프롬프트로는 이런 실수를 예상하거나 수정할 수 없습니다. 4.2 알고리즘 보정 디코딩하는 동안 온도 t는 출력 분포의 선명도를 제어하며, t가 높을수록 각 다음 단어에 대한 모델의 가장 가능성 있는 예측에서 확률 질량이 멀어집니다. §3의 실험에서는 t = 0과 동일한 탐욕적 디코딩을 사용했습니다. t = 0.6 및 t 0.9에서 오류율과 눈덩이 환각 비율은 GPT-4와 ChatGPT 모두에서 비슷하게 높게 유지됩니다(그림 4). = = Top-k 및 핵 샘플링 Top-k 샘플링이나 핵 샘플링(Holtzman et al., 2020)과 같은 샘플링 방법을 사용하는 것은 도움이 되지 않습니다.이는 고려할 토큰의 범위를 좁힐 뿐이고, 따라서 모델이 즉시 답을 확정할 확률만 높일 수 있기 때문입니다.빔 검색 §2의 환각 눈덩이에 대한 주장은 모델이 답을 확정하는 토큰을 생성하면 컨텍스트에 남아 이후 세대에 영향을 미친다는 사실에 의존합니다.이를 해결하는 한 가지 잠재적인 방법은 빔 검색, 즉 단일 시퀀스가 아닌 각 타임스텝에서 높은 확률 시퀀스의 빔을 유지하는 것입니다.원칙적으로 초기 토큰 이후 빔의 일부 시퀀스가 답을 확정하지 않거나(또는 올바른 답을 확정하는 경우) 해당 시퀀스의 연속은 결국 처음에 잘못 확정하고 나중에 결과적으로 잘못된 추론을 생성하는 시퀀스보다 확률이 더 높을 수 있습니다.그렇다면 빔 검색은 눈덩이 환각 문제를 해결할 것입니다. 불행히도 OpenAI API가 빔 검색을 지원하지 않기 때문에 환각 눈덩이에 대한 빔 검색의 효과를 테스트할 수 없습니다. 학습 전략 눈덩이 현상을 더욱 줄이는 보다 일반적인 방법은 사전 학습 또는 지침 튜닝 단계의 측면을 변경하는 것입니다. 특히, 모델이 답변을 생성하기 전에 추론 체인을 생성하도록 하는 데 더 중점을 두는 것은 계산적 한계를 수용하고 환각을 강요하는 잘못된 답변을 하는 것을 피하는 좋은 방법이 될 수 있습니다. 또한 백트래킹을 사용하여 데이터를 미세 조정하면 제시하는 작업에서 모델의 성능이 향상될 수 있다고 가정합니다. 예를 들어 질문을 한 다음 잘못된 답변을 제시한 다음 올바른 답변을 제시하기 전에 &quot;죄송하지만 틀렸습니다&quot;와 같은 문구를 제시하여 이를 달성할 수 있습니다. 이 솔루션은 Kim et al. (2023)의 &quot;이전 답변을 검토하고 답변에 문제가 있는지 확인하세요.&quot; 프롬프트와 관련이 있습니다. 5
--- RELATED WORK ---
환각 텍스트 생성에서 환각은 잘 연구된 문제(Rohrbach 등, 2018; Maynez 등, 2020; Raunak 등, 2021, ia)로, 최근 ChatGPT가 그럴듯하게 들리는 거짓을 생성하는 경향으로 인해 더욱 두드러졌습니다. 환각은 종종 LM의 지식 격차에 기인하며(Zheng 등, 2023), 여러 연구에서 지식 기반에 대한 검색을 사용하여 환각을 완화할 수 있는 가능성을 보여주었습니다(Lewis 등, 2020; Shuster 등, 2021; Peng 등, 2023). 저희 연구는 환각이 맥락에서 유도될 수 있음을 보여주며, 따라서 추가적인 완화 기술에 대한 동기를 부여합니다. 환각 눈덩이 현상은 노출 편향의 결과일 가능성이 높습니다. LM은 훈련 중에만 골드 히스토리에 노출되었지만 추론 중에는 오류가 있을 수 있는 이전 예측에 대한 조건이 적용되었습니다. 이전 연구에서는 이를 기계 번역(Wang 및 Sennrich, 2020) 및 개방형 텍스트 생성(Arora et al., 2022)에서 환각을 악화시키는 것과 연결했습니다. 우리는 오류 전파를 보여주는 것을 넘어 전파된 오류(우리가 눈덩이 환각이라고 부름)가 LM 자체에서 인식된다는 것을 보여줍니다. 우리의 관찰은 LM이 잘못된 전제를 포함하는 질문(예: &quot;전구를 발명한 언어학자는?&quot;; Kim et al., 2021, 2022)이나 그렇지 않으면 오해의 소지가 있는 질문(예: &quot;9/11을 실제로 일으킨 사람은 누구인가?&quot;; Lin et al., 2022)을 받았을 때 환각을 보인다는 이전의 연구 결과와 관련이 있습니다. 이러한 잘못된 맥락은 LM을 오도합니다. 그러나 우리의 연구는 우리의 질문이 의도적으로 오도되지 않는다는 점에서 다르며, 이러한 실패 모드는 LM에 대한 무고한 정보 수집 쿼리에서도 트리거될 수 있음을 보여줍니다. LM (비)일관성 우리의 연구는 동일한 문제에 대한 다양한 프롬프트에서 LM이 얼마나 일관되지 않은지 보여주는 증가하는 연구에 추가됩니다. 예를 들어, LM이 중간 단계를 생성할 수 있도록 하면(Nye et al., 2021; Wei et al., 2022; Press et al., 2022) 그렇지 않으면 다른 답변에 도달할 수 있습니다. 할 것이다. 다른 연구에서는 단순히 &quot;스미스 교수에게 다음 지침이 주어졌습니다&quot;라는 문구를 프롬프트에 붙이면 문제 자체에 대한 귀중한 정보를 제공하지 않더라도 성능을 향상시킬 수 있음을 보여주었습니다(Lin et al., 2022). 6 결론 우리는 환각 눈덩이 현상을 정의하고 최첨단 모델에서 여러 세대에 걸쳐 널리 퍼져서 그렇지 않으면 발생하지 않을 간단한 사실에 대한 환각으로 이어진다는 것을 보여줍니다. 우리의 연구 결과는 사실성을 희생하고 유창성과 일관성을 무차별적으로 우선시하는 언어 모델을 훈련할 위험이 있음을 지적하며, 향후 연구에서는 모델 개발의 모든 수준에서 시정 조치를 연구하기를 권장합니다. 한계 우리는 영어 질문에 대한 답변 맥락에서 환각 눈덩이 현상에 초점을 맞추고 요약이나 코드 생성과 같은 다른 작업에서는 탐구하지 않습니다. 또한 많은 벤치마크에서 최첨단 성능을 보이는 ChatGPT와 GPT-4라는 두 가지 독점 모델에 대한 실험만 수행합니다(OpenAI, 2023). 이러한 모델의 API 제한으로 인해, 우리는 그들이 출력하는 확률 분포에 접근할 수 없고 이를 미세 조정할 수 있는 능력이 없습니다. 이는 잠재적인 완화 전략을 탐색하는 우리의 능력을 제한합니다. 출력 분포에 접근할 수 있다면 대체 샘플링을 사용하여 눈덩이 환각 문제를 완화하는 것을 조사할 수 있습니다.
--- METHOD ---
LM이 후퇴할 수 있는 s. 2 왜 환각 눈덩이 현상을 예상하는가? 이 섹션에서는 LM이 환각 눈덩이 현상에 취약하다고 가정하는 이유를 설명합니다. 우리는 두 가지 주요 속성이 있는 질문에서 눈덩이 현상이 발생할 것으로 예측합니다. 1. 초기 커밋: 프롬프트는 LM이 먼저 답을 말하도록 이끕니다(설명을 출력하기 전에). 이는 많은 예/아니요 질문에 적용됩니다. 2. 본질적으로 순차적: 변압기는 한 타임스텝 내에서 추론 능력이 제한되어 있기 때문에 한 타임스텝 내에서 답을 찾을 수 없습니다. 이제 이러한 속성이 어떻게 눈덩이 환각으로 이어질 수 있는지 논의합니다. 초기 커밋. 영어와 다른 많은 언어에서 화자는 종종 답을 설명하기 전에 질문에 대한 최종 예/아니요 답을 말합니다. 따라서 우리는 LM과 특히 명령어 조정 LM(Wei 등, 2021; Sanh 등, 2021; Ouyang 등, 2022; Wang 등, 2022)이 설명보다 답변이 먼저 나오는 이 답변 형식을 반영할 것이라고 가설을 세웁니다. 실제로, 우리의 데이터 세트(§3.1에 제시됨)에서 GPT-4와 ChatGPT가 질문에 대한 답변을 즉시 커밋한다는 것을 관찰했습니다. 첫 번째 토큰은 GPT-4의 경우 95.67%, ChatGPT의 경우 98.40%의 시간 동안 예 또는 아니요입니다. 나머지 사례에서 모델은 종종 응답의 처음 몇 토큰 내에서 답변을 커밋합니다(예: &quot;미국 상원의원에 대한 기록이 없습니다...&quot;). 중요한 점은 LM이 예 또는 아니요를 생성하면 해당 토큰이 컨텍스트에 남아 있고, 일관성을 위해서는 후속 정당화를 통해 해당 선택에 커밋해야 한다는 것입니다. 따라서 이 모델은 단일 타임스텝에서 복잡한 질문에 대한 답을 생성한 다음, 그 답에 대한 설명을 생성하여 계속 진행하는데, 이는 필연적으로 잘못된 것입니다. 본질적으로 순차적입니다. 더욱이, 변환기는 소수성 테스트나 그래프 연결성과 같은 본질적으로 순차적인 추론 문제를 단일 타임스텝 내에서 해결할 수 없습니다.² 이는 최근 이론적 결과(Merrill and Sabharwal, 2023)에 기록되어 있습니다. 우리의 그래프 연결성과 소수성 데이터 세트는 이러한 문제의 구체적인 사례입니다. 변환기는 올바르게 답하기 위해 여러 타임스텝이 필요한 질문에 답하기 위해 한 단계를 사용해야 하기 때문에, 때로는 필연적으로 잘못된 답을 하게 됩니다. 우리는 이것이 LM이 그렇지 않으면 생성하지 않았을 잘못된 사실을 뒷받침하는 환각을 일으키게 한다고 가설을 세웁니다. 3
--- EXPERIMENT ---
s 우리는 §2에 설명된 속성을 갖는 세 개의 QA 데이터 세트를 설계하여 환각 스노우볼링을 조사하고 ChatGPT 및 GPT-4를 평가합니다. 먼저 LM이 주어진 질문에 대한 정답을 반환하는지 확인하고 모델이 잘못된 답을 반환할 때 해당 잘못된 답에 대한 잘못된 설명을 자주 제공한다는 것을 보여줍니다. 우리는 설명에서 잘못된 주장을 자동으로 추출하고 동일한 LM에 해당 주장이 올바른지 확인하도록 요청합니다. 각 데이터 세트의 대표적인 예는 표 1을 참조하십시오. 3.1 데이터 세트 우리는 세 개의 QA 데이터 세트를 설계하며, 각각 변환기가 한 타임스텝에서 답할 수 없을 것으로 예상되는 예/아니요 질문이 포함되어 있습니다. 평가를 돕기 위해 질문은 쉽게 검증할 수 있는 주장으로 잘못된 답을 정당화하도록 설계되었습니다. 2 기술적으로 이것은 특정 경도 수준, 즉 소수 테스트를 위한 소수의 크기 또는 그래프 연결을 위한 그래프의 크기를 초과하는 입력에만 적용됩니다. 3Merrill과 Sabharwal(2023)은 단일 생성 단계로 제한된 정밀도 변환기가 복잡도 클래스 TC 외부의 문제를 해결할 수 없음을 보여줍니다.TC는 L(로그 공간)과 P(다항식 시간)의 매우 병렬화 가능한 하위 클래스에 해당합니다.그래프 연결성은 L-완전 문제이므로 TC = L이 아니면 TC에 포함될 수 없습니다.즉, 모든 L을 놀라울 정도로 높은 수준으로 병렬화할 수 있습니다.소수성 테스트는 P에 있는 것으로 나타났지만(Agrawal et al., 2004) L에도 없으면 TC에 포함될 수 없습니다.즉, 모든 n은 O(log log n) 비트의 오버헤드로 인수분해할 수 있습니다.요약하면 표준 복잡도 이론적 추측이 거짓이 아니면 그래프 연결성과 소수성 테스트는 TC° 외부에 있으므로 변환기가 단일 세대에서 해결하기에는 본질적으로 너무 순차적입니다(참조: Merrill and Sabharwal, 2023). 각 데이터 세트에서 모든 예에 대해 하나의 특정 레이블을 고정하여 모델이 잘못된 답(예: 9677이 소수가 아님)을 선택하는 경우 이를 뒷받침하는 특정 주장(예: 잘못된 인수분해)을 생성하도록 합니다. 이를 통해 잘못된 답에 대한 모델 작성 정당성을 체계적으로 검토할 수 있습니다. 소수성 테스트 이 데이터 세트의 경우 1,000~20,000 사이에서 임의로 선택한 500개의 소수의 소수성을 쿼리합니다. 정답은 항상 &#39;예&#39;입니다. 모델이 틀린 답인 경우 틀린 인수분해로 답을 정당화할 것으로 예상합니다. 상원 의원 검색 이 데이터 세트는 &quot;x 주를 대표하고 모교가 y인 미국 상원 의원이 있었나요?&quot;라는 형식의 질문으로 구성되어 있습니다. 여기서 x는 미국 주이고 y는 미국 단과대학입니다. 이러한 질문의 정답은 항상 &#39;아니요&#39;입니다. 모델이 틀린 답인 경우 특정 상원 의원이 x를 대표하고 y에 다녔다고 거짓으로 주장할 것으로 예상합니다. 데이터 세트를 생성하기 위해 모든 미국 주와 수동으로 구성된 12개의 인기 있는 미국 대학 목록을 고려합니다(전체 목록은 §A 참조). 가능한 각 쌍에 대해 템플릿을 따라 질문을 생성하고 답이 &#39;예&#39;인 쌍을 수동으로 제거합니다. 그래프 연결성 이 데이터 세트의 500개 질문 각각에 대해 도시 간 항공편 12개를 제시하고 특정 도시에서 다른 도시로 가는 항공편 시퀀스가 있는지 묻습니다. 문제는 항상 동일한 기본 방향 그래프 구조(§A.1 참조)에 해당합니다. 여기서 항공편은 에지이고 도시는 노드입니다. 데이터 세트의 각 인스턴스에 대해 영어 알파벳에서 무작위로 문자를 지정하여 노드 이름을 지정합니다. 쿼리를 공식화하기 위해 소스 도시 s와 목적지 도시 t를 다른 하위 그래프에서 샘플링합니다. 여기서 s는 소스 노드에 해당하고 ta는 리프 노드에 해당하므로 1단계 휴리스틱을 사용하여 문제를 해결할 수 없습니다. 문제를 자연어로 된 항공편 찾기 질문으로 공식화하여 더 자연스럽게 들리도록 했습니다. 프롬프트에서 12개 항공편을 나열했습니다(&quot;도시 F에서 도시 K로 가는 항공편이 있습니다. 도시 G에서 도시 N으로 가는 항공편이 있습니다...&quot;). 그 다음에 &quot;s에서 t로 가는 일련의 항공편이 있습니까?&quot;라는 질문이 나옵니다. 정답은 항상 아니요입니다. 모델이 틀린 답을 하면 존재하지 않는 항공편으로 답을 정당화할 것으로 예상합니다. 데이터 집합의 비율(%)오답(환각) 모델은 자신이 틀렸다는 것을 알고 있습니다(눈덩이 환각)우선성 테스트 상원 의원 검색 그래프 연결성우선성 테스트 상원 의원 검색 그래프 연결성 (a) ChatGPT (b) GPT-그림 2: ChatGPT와 GPT-4에 대한 환각 백분율과 눈덩이 환각 백분율(둘 다 전체 데이터 집합을 기준으로 계산). 이 플롯의 정확한 숫자는 부록의 표 6과 표 7에서 확인할 수 있습니다. 3.2 추론 언어 모델 설정. ChatGPT(gpt-3.5-turbo) 및 GPT-4에서 탐욕적 디코딩을 사용하여 모든 실험을 실행합니다. 실험은 제로샷(즉, 프롬프트에서 모델에 예제 QA 쌍을 표시하지 않음)입니다. 사용자가 LM과 상호 작용하는 가장 일반적인 방법인 직접 프롬프트에서의 모델 동작에 초점을 맞춥니다(전체 예는 §A 참조). 제로샷 체인 오브 생각 스타일 프롬프트 방법을 사용한 실험은 §4를 참조하세요. 각 데이터 세트에 대해 2단계 평가를 수행합니다. 먼저 모델의 정확도(즉, 모델이 올바르게 답하는 질문 수)를 평가합니다. 두 모델 중 하나가 틀렸을 때 경험적으로 항상 정당화를 생성합니다. 두 번째 단계에서는 모델이 설명에서 틀린 단계를 식별할 수 있는지 평가합니다. 주어진 질문에 대해 출력이 예 또는 아니요로 시작하는지 검토하여 모델의 응답을 평가합니다. 응답이 이러한 범주에 속하지 않는 경우 모델이 전달하는 답변을 수동으로 결정합니다. 3.3 LM의 눈덩이 환각 인식 우리는 LM이 출력에서 모델의 잘못된 주장을 모델 자체와 비교하여 검증함으로써 눈덩이 환각을 인식하는지 여부를 조사합니다. 우리의 인식 절차는 모델 출력의 수동 검사에서 얻은 휴리스틱에 의존하며, 이러한 휴리스틱은 다른 모델에서는 작동하지 않을 수 있습니다(예: 다른 모델은 숫자가 소수가 아니라는 주장을 뒷받침할 때 인수를 제공하지 않을 수 있음). 그래프 연결성 모델이 일련의 연결 항공편이 있다고 생각하는 각 샘플(답변이 예로 시작)에 대해 모델의 출력에서 항공편 목록을 수동으로 추출하고 유효하지 않거나 불연속적인 항공편을 식별합니다. 그런 다음 새 세션에서 모델에 추출된 항공편이 항공편 정보를 기반으로 유효한지, 연속된 항공편이 실제로 연결되어 있는지 확인하도록 요청합니다. 모델이 오류를 올바르게 감지하는지 확인하기 위해 수동으로 검증 출력을 평가합니다. 모델을 프롬프트하는 방법과 성공적인 검증의 예는 부록 표 3을 참조하세요. 소수성 테스트 모델이 숫자가 소수가 아니라고 답하는 각 샘플에 대해 모델이 이를 정당화하는 데 사용하는 인수를 추출합니다. 추출은 출력을 맥락에 넣고 &quot;위의 텍스트에서 제안된 인수는 무엇인가? 나열해 보세요.&quot;라고 묻는 방식으로 수행합니다. 원샷 데모(빠른 추론 속도)를 사용하여 추출에 ChatGPT를 사용합니다. 30개의 예를 수동으로 확인한 결과 항상 올바른 인수를 추출할 수 있음을 확인했습니다. 그런 다음 새 세션에서 모델에 추출된 각 인수를 개별적으로 검증하도록 요청합니다. 성공적인 검증의 예는 부록 표 4를 참조하십시오. 데이터 집합(%) 비율 소수성 테스트 원래 프롬프트 단계별 프롬프트 데이터 집합(%) LILIL 상원 의원 검색 그래프 연결 비율 소수성 테스트 상원 의원 검색(b) GPT-그래프 연결 (a) ChatGPT 그림 3: 원래 프롬프트를 사용할 때와 &quot;단계별로 생각해 봅시다&quot;를 사용할 때 ChatGPT 및 GPT-4의 오류율 및 눈덩이 환각율(해치 패턴) 정확한 숫자는 부록 표 8과 표 9를 참조하십시오.상원 의원 검색 모델이 그러한 상원 의원이 있다고 생각하는 각 샘플에 대해 모델이 상원 의원의 존재를 정당화하는 데 사용하는 상원 의원의 이름을 추출합니다.출력을 맥락에 넣고 &quot;위의 텍스트에서 언급된 상원 의원은 무엇입니까? 이름만 알려주십시오&quot;라고 질문합니다.다시 한번, ChatGPT를 사용하고 예제에서 수동으로 관찰된 완벽한 추출을 수행합니다.그런 다음 새 세션에서 모델에 해당 상원 의원의 모교가 문제의 단과대학이고 문제의 주를 나타내는지 묻습니다.성공적인 감지의 예는 부록 표 5를 참조하십시오.3.4 결과 질의-응답 정확도 그림 2는 ChatGPT와 GPT-4 모두 전반적으로 매우 낮은 정확도를 경험함을 보여줍니다.상원 의원 검색 데이터 세트의 ChatGPT를 제외하고 모든 모델은 50% 미만의 정확도를 달성합니다. (데이터 세트별 오류율 분석은 부록 표 6 참조) GPT-4는 일반적으로 ChatGPT보다 우수한 것으로 간주되지만(OpenAI, 2023) 모든 데이터 세트에서 ChatGPT보다 성능이 떨어지는 것을 관찰했습니다. ChatGPT의 평균 정확도는 39.87%인 반면 GPT-4는 16.6%에 불과합니다. 환각 감지 여기서는 모델이 잘못된 주장이 단독으로 제시될 때 잘못된 주장임을 식별할 수 있는지 확인합니다. 그림 2에서 볼 수 있듯이 ChatGPT는 설명에서 잘못된 주장의 67.37%(즉, 눈덩이 모양의 환각)을 감지하고 GPT-4는 87.03%를 감지합니다. 모델이 검증에 실패한 경우(부록 표 12의 예) 눈덩이 모양의 환각으로 간주하지 않는다는 점에 유의하세요. 전반적으로 ChatGPT와 GPT-4는 모두 환각 눈덩이 현상에 매우 취약하여 매우 간단한 실수로 이어집니다. 4 눈덩이 모양의 환각을 예방할 수 있을까요? 우리는 LM이 현재 맥락(주어진 프롬프트와 이전 출력)과 일치하는 연속을 모델링하도록 훈련되었기 때문에 환각 눈덩이 현상이 발생한다고 가설을 세웠습니다. 근본적인 문제를 해결하려면 추론 시간 수정 이상이 필요할 수 있지만, 이 섹션에서는 두 가지 추론 전략, 즉 프롬프트(§4.1)와 디코딩 또는 훈련 방법(§4.2)의 효과를 연구하여 환각 눈덩이 현상을 완화합니다. 4.1 더 나은 프롬프트 엔지니어링 이 섹션에서는 모델이 답변 전에 추론 체인을 생성하도록 장려하는 다른 제로샷 프롬프트를 사용하여 눈덩이 현상 환각을 예방하는 더 나은 프롬프트의 효과를 살펴봅니다. 이러한 프롬프트에서 생성된 출력은 덜 구조화되어 있으므로 수동으로 검사하여 정확성과 눈덩이 현상 환각의 존재 여부를 확인합니다. 각 작업의 경우 원래 질문의 끝에 &quot;단계별로 생각해 봅시다&quot;를 추가합니다(표 1 참조). 그림 3에서 볼 수 있듯이 이 모델은 상원 의원 검색 작업을 완벽하게 풀고, 소수성 검정에서 &lt;10% 오류율, 그래프 연결성에서 ≤30%를 달성할 수 있습니다. 정확도가 크게 향상되었음에도 불구하고, 잠재적인 문제를 식별했습니다. 모델이 추론 체인을 출력하는 동안 때때로 환각을 보이는데, 이로 인해 이후 단계에서 환각이 눈덩이처럼 불어납니다. 예를 들어, 아래 출력에서 [....이전 단계 생략] 3단계: 도시 E에서 도시 N으로 가는 항공편, 도시 B로 가는 항공편, 도시 C로 가는 항공편의 세 가지 옵션이 있습니다.4단계: 도시 M으로 이어질 수 있는 유일한 옵션은 도시 E에서 도시 C로 가는 항공편입니다.[....나머지 출력 생략] ChatGPT는 3단계에 세 가지 옵션이 있다고 잘못 설명합니다(두 가지만 있음).이로 인해 눈덩이 환각 &quot;또는 도시 C로 가는 항공편&quot;이 유도됩니다(ChatGPT는 별도 세션에서 E → C가 유효한 항공편이 아님을 확인할 수 있음).그림 3에서 볼 수 있듯이 GPT-4는 여전히 작업 전체에서 평균 94.90%로 높은 전반적인 눈덩이 환각 비율을 보이고 ChatGPT도 비슷하게 높은 눈덩이 환각 비율을 얻습니다. 마지막으로, 우리의 실험은 단계별로 분해하기에 적합한 간단한 다단계 문제에 초점을 맞추었지만, 우리는 환각 눈덩이 현상이 더 광범위하게 개방형 텍스트 생성에서 나타나며, 생성에서 한 가지 실수가 더 많은 실수를 유발한다고 가설을 세웠습니다(Arora et al., 2022). 이런 경우 더 나은 프롬프트로는 이런 실수를 예상하거나 수정할 수 없습니다. 4.2 알고리즘 보정 디코딩하는 동안 온도 t는 출력 분포의 선명도를 제어하며, t가 높을수록 각 다음 단어에 대한 모델의 가장 가능성 있는 예측에서 확률 질량이 멀어집니다. §3의 실험에서는 t = 0과 동일한 탐욕적 디코딩을 사용했습니다. t = 0.6 및 t 0.9에서 오류율과 눈덩이 환각 비율은 GPT-4와 ChatGPT 모두에서 비슷하게 높게 유지됩니다(그림 4). = = Top-k 및 핵 샘플링 Top-k 샘플링이나 핵 샘플링(Holtzman et al., 2020)과 같은 샘플링 방법을 사용하는 것은 도움이 되지 않습니다.이는 고려할 토큰의 범위를 좁힐 뿐이고, 따라서 모델이 즉시 답을 확정할 확률만 높일 수 있기 때문입니다.빔 검색 §2의 환각 눈덩이에 대한 주장은 모델이 답을 확정하는 토큰을 생성하면 컨텍스트에 남아 이후 세대에 영향을 미친다는 사실에 의존합니다.이를 해결하는 한 가지 잠재적인 방법은 빔 검색, 즉 단일 시퀀스가 아닌 각 타임스텝에서 높은 확률 시퀀스의 빔을 유지하는 것입니다.원칙적으로 초기 토큰 이후 빔의 일부 시퀀스가 답을 확정하지 않거나(또는 올바른 답을 확정하는 경우) 해당 시퀀스의 연속은 결국 처음에 잘못 확정하고 나중에 결과적으로 잘못된 추론을 생성하는 시퀀스보다 확률이 더 높을 수 있습니다.그렇다면 빔 검색은 눈덩이 환각 문제를 해결할 것입니다. 불행히도 OpenAI API가 빔 검색을 지원하지 않기 때문에 빔 검색이 환각 눈덩이에 미치는 영향을 테스트할 수 없습니다. 학습 전략 눈덩이 현상을 더욱 줄이는 보다 일반적인 방법은 사전 학습 또는 지침 조정 단계의 측면을 변경하는 것입니다. 특히 모델이 답변을 생성하기 전에 추론 체인을 생성하는 데 더 중점을 두는 것은 계산적 한계를 수용하고 환각을 강제하는 잘못된 답변을 하는 것을 피하는 좋은 방법이 될 수 있습니다. 또한 백트래킹을 사용하여 데이터를 미세 조정하면 제시한 작업에서 모델의 성능이 향상될 수 있다고 가정합니다. 예를 들어, 질문을 한 다음 잘못된 답을 제시하고 올바른 답을 제시하기 전에 &quot;죄송하지만 틀렸습니다&quot;와 같은 문구를 제시하여 이를 달성할 수 있습니다. 이 답은 Kim et al.(2023)의 &quot;이전 답변을 검토하고 답변에 문제가 있는지 확인하세요.&quot;라는 프롬프트와 관련이 있습니다. 5 관련 연구 환각 텍스트 생성에서 환각은 잘 연구된 문제(Rohrbach et al., 2018; Maynez et al., 2020; Raunak et al., 2021, ia)로, 최근 ChatGPT가 그럴듯하게 들리는 거짓을 생성하는 경향으로 인해 더욱 두드러졌습니다. 환각은 종종 LM의 지식 격차에 기인합니다(Zheng et al., 2023). 여러 연구에서 지식 기반 대신 검색을 사용하여 환각을 완화할 수 있는 가능성을 보여주었습니다(Lewis et al., 2020; Shuster et al., 2021; Peng et al., 2023). 저희의 연구는 환각이 맥락에서 유도될 수 있음을 보여주며, 따라서 추가적인 완화 기법을 촉발합니다. 환각 눈덩이 현상은 노출 편향의 결과일 가능성이 큽니다. LM은 훈련 중에만 골드 히스토리에 노출되었지만 추론 중에는 오류가 있을 수 있는 이전 예측에 대한 조건이 적용되었습니다. 이전 연구에서는 이를 기계 번역(Wang 및 Sennrich, 2020)과 개방형 텍스트 생성(Arora et al., 2022)에서 환각을 악화시키는 것과 연결했습니다. 저희는 오류 전파를 보여주는 것을 넘어 전파된 오류(저희는 이를 눈덩이 환각이라고 부름)가 LM 자체에서 인식된다는 것을 보여줍니다. 우리의 관찰은 LM이 잘못된 전제를 포함하는 질문(예: &quot;전구를 발명한 언어학자는?&quot;; Kim et al., 2021, 2022)이나 그렇지 않으면 오해의 소지가 있는 질문(예: &quot;9/11을 실제로 일으킨 사람은 누구인가?&quot;; Lin et al., 2022)을 받았을 때 환각을 보인다는 이전의 연구 결과와 관련이 있습니다. 이러한 잘못된 맥락은 LM을 오도합니다. 그러나 우리의 연구는 우리의 질문이 의도적으로 오도되지 않는다는 점에서 다르며, 이러한 실패 모드는 LM에 대한 무고한 정보 수집 쿼리에서도 트리거될 수 있음을 보여줍니다. LM (비)일관성 우리의 연구는 동일한 문제에 대한 다양한 프롬프트에서 LM이 얼마나 일관되지 않은지 보여주는 증가하는 연구에 추가됩니다. 예를 들어, LM이 중간 단계를 생성할 수 있도록 하면(Nye et al., 2021; Wei et al., 2022; Press et al., 2022) 그렇지 않으면 다른 답변에 도달할 수 있습니다. 할 것이다. 다른 연구에서는 단순히 &quot;스미스 교수는 다음 지침을 받았습니다&quot;라는 문구를 프롬프트에 붙이면 문제 자체에 대한 귀중한 정보를 제공하지 않음에도 불구하고 성능을 개선할 수 있다는 것을 보여주었습니다(Lin et al., 2022). 6
--- CONCLUSION ---
우리는 환각 눈덩이 현상을 정의하고 최첨단 모델에서 세대를 거쳐 유행하여 그렇지 않으면 발생하지 않을 간단한 사실에 대한 환각으로 이어진다는 것을 보여줍니다. 우리의 연구 결과는 사실성을 희생하고 유창성과 일관성을 무차별적으로 우선시하는 언어 모델을 훈련할 위험이 있음을 지적하며, 향후 모델 개발의 모든 수준에서 시정 조치를 연구하는 작업을 장려합니다. 한계점 우리는 영어 질문에 대한 답변의 맥락에서 환각 눈덩이 현상에 초점을 맞추고 요약이나 코드 생성과 같은 다른 작업에서는 탐구하지 않습니다. 또한 많은 벤치마크에서 최첨단 성능을 보이는 ChatGPT와 GPT-4라는 두 가지 독점 모델에 대한 실험만 수행합니다(OpenAI, 2023). 이러한 모델에 대한 API의 한계로 인해 출력되는 확률 분포에 액세스할 수 없으며 이를 미세 조정할 수 없습니다. 이는 잠재적인 완화 전략을 탐구하는 능력을 제한합니다. 출력 분포에 대한 접근 권한이 있으면 빔 검색과 같은 대체 샘플링 방법을 사용하여 눈덩이 환각 문제를 완화하는 방법을 조사할 수 있습니다. 모델을 미세 조정할 수 있는 기능이 있으면 다른 주석을 사용한 명령어 조정이 환각 눈덩이를 유발하는 데 사용하는 질문을 더 잘 처리하는 데 도움이 될 수 있는지 알아볼 수 있습니다. 감사의 말 귀중한 피드백과 유익한 토론을 해주신 Sofia Serrano, Yizhong Wang, Yanai Elazar, Michael Hu, Richard Yuanzhe Pang에게 감사드립니다. 이 논문을 쓰는 동안 Ofir Press는 Kyunghyun Cho가 주최한 New York University의 Center for Data Science에 방문했습니다. 참고 문헌 Manindra Agrawal, Neeraj Kayal, Nitin Saxena. 2004. Primes는 p. Annals of Mathematics, 160:781-793에 있습니다. Godel Prize, Fulkerson Prize. Kushal Arora, Layla El Asri, Hareesh Bahuleyan, Jackie Cheung. 2022. 노출 편향이 중요한 이유: 언어 생성에서 오류 축적에 대한 모방 학습 관점. 계산 언어학 협회의 연구 결과: ACL 2022, 700-710쪽, 아일랜드 더블린. 계산 언어학 협회. Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi. 2020. 신경 텍스트 퇴화의 호기심 많은 사례. 학습 표현 국제 컨퍼런스에서. Geunwoo Kim, Pierre Baldi, Stephen McAleer. 2023. 언어 모델은 컴퓨터 작업을 해결할 수 있다. Najoung Kim, Phu Mon Htut, Sam Bowman, Jackson Petty. 2022. (qa)2: 의심스러운 가정을 통한 질의 응답. ArXiv, abs/2212.10003. Najoung Kim, Ellie Pavlick, Burcu Karagol Ayan, Deepak Ramachandran. 2021. 전구를 발명한 언어학자는? 질문-답변을 위한 전제 검증. 계산언어학 협회 연례 회의에서. 타케시 코지마, 쉬샹 셰인 구, 마셸 레이드, 유타카 마츠오, 유스케 이와사와. 2023. 대규모 언어 모델은 제로샷 추론기입니다. 패트릭 루이스, 이선 페레즈, 알렉산드라 픽투스, 파비오 페트로니, 블라디미르 카르푸킨, 나만 고얄, 하인리히 퀴틀러, 마이크 루이스, 웬타우 이, 팀 록테셸, 세바스찬 리델, 다우웨 키엘라. 2020. 지식 집약적 nlp 작업을 위한 검색 증강 생성. 미국 뉴욕 레드훅에서 열린 제34회 신경 정보 처리 시스템 국제 컨퍼런스 회의록, NIPS&#39; 20. Curran Associates Inc. Stephanie Lin, Jacob Hilton, Owain Evans. 2022. TruthfulQA: 모델이 인간의 거짓을 어떻게 모방하는지 측정. Association for Computational Linguistics 제60회 연례 회의록(제1권: 장문 논문), 3214-3252쪽, 아일랜드 더블린. Association for Computational Linguistics. Nelson F. Liu, Tianyi Zhang, Percy Liang. 2023. 생성 검색 엔진에서 검증 가능성 평가. Joshua Maynez, Shashi Narayan, Bernd Bohnet, Ryan McDonald. 2020. 추상적 요약에서의 충실성과 사실성에 관하여. Association for Computational Linguistics 제58회 연례 회의록, 1906-1919쪽, 온라인. Association for Computational Linguistics. 윌리엄 메릴과 아시시 사바왈. 2023. 병렬성 트레이드오프: 로그 정밀도 변환기의 한계. 맥스웰 나이, 앤더스 요한 안드레아센, 가이 구르아리, 헨리크 미칼레프스키, 제이콥 오스틴, 데이비드 비버, 데이비드 도한, 아이토르 류코비츠, 마르텐 보스마, 데이비드 루안, 찰스 서튼, 아우구스투스 오데나. 2021. 작업 보여주기: 언어 모델을 사용한 중간 계산을 위한 스크래치패드. OpenAI. 2022. chatgpt 소개. OpenAI. 2023. Gpt-4 기술 보고서. Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, Ryan Lowe. 2022. 인간의 피드백을 통해 지시를 따르도록 언어 모델을 훈련합니다. Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, Jianfeng Gao. 2023. 사실을 확인하고 다시 시도하세요: 외부 지식과 자동화된 피드백을 통해 대규모 언어 모델 개선. Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith, Mike Lewis. 2022. 언어 모델에서 구성성 갭 측정 및 좁히기. Vikas Raunak, Arul Menezes, Marcin JunczysDowmunt. 2021. 신경 기계 번역에서 환각의 호기심 많은 사례. 2021년 북미 컴퓨터 언어학 협회: 인간 언어 기술 회의록, 1172-1183쪽, 온라인. 컴퓨터 언어학 협회. Anna Rohrbach, Lisa Anne Hendricks, Kaylee Burns, Trevor Darrell, Kate Saenko. 2018. 이미지 캡션에서의 사물 환각. 2018년 자연어 처리 경험적 방법 회의록, 4035-4045쪽, 벨기에 브뤼셀. 컴퓨터 언어학 협회. Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, 김태운, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Tali Bers, Stella Biderman, Leo Gao, Thomas Wolf 및 Alexander M. 서두르다. 2021. 멀티태스크 유도 훈련은 제로샷 태스크 일반화를 가능하게 합니다. Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, Jason Weston. 2021. 검색 증강은 대화에서 환각을 줄입니다. EMNLP 2021 협회의 연구 결과, 3784-3803페이지, 도미니카 공화국 푼타카나. EMNLP 협회. Chaojun Wang과 Rico Sennrich. 2020. 신경 기계 번역에서 노출 편향, 환각 및 도메인 이동에 관하여. EMNLP 58회 연례 회의록, 3544-3552페이지, 온라인. EMNLP 협회. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, Hannaneh Hajishirzi. 2022. 자체 지시: 언어 모델을 자체 생성 지침과 정렬. Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, Quoc V. Le. 2021. 미세 조정된 언어 모델은 제로 샷 학습자입니다. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V Le, Denny Zhou. 2022. Chain of thought prompting elicits in large language models. 신경 정보 처리 시스템의 발전. Shen Zheng, Jie Huang, Kevin Chen-Chuan Chang. 2023. 왜 chatgpt는 질문에 충실하게 답하지 못할까요?데이터 집합 세부 정보 A.1 그래프 연결성 이 데이터 집합에서 항공편 목록은 유향 그래프로 표현할 수 있습니다. 모든 그래프가 특정 연결 패턴을 공유하도록 항공편 정보를 생성했으며, 노드 이름은 영어 알파벳 26자 중에서 무작위로 선택되었습니다. 기본 그래프 구조에 대한 설명은 그림 5를 참조하세요. A.2 상원 의원 검색 데이터 집합에 사용된 12개 단과대학은 다음과 같습니다. MIT, 시카고 대학교, 존스 홉킨스 대학교, 캘리포니아 공과대학교, 듀크 대학교, 노스웨스턴 대학교, 다트머스 대학교, 브라운 대학교, 반더빌트 대학교, 라이스 대학교, 워싱턴 대학교. 미국 최고 대학 목록에서 의회 의원을 위한 상위 10개 대학 목록에도 포함된 대학을 제외하고 이 목록을 구성했습니다. B 추가 결과 표 6에 질의응답 정확도의 세부 분석과 표 7에 환각 감지 정확도의 세부 분석을 제공합니다.그래프 연결성: 현재 항공편 정보(다음 항공편은 편도만 해당되며, 이용 가능한 모든 항공편이 아래에 포함되어 있습니다): 도시 F에서 도시 K로 가는 항공편이 있습니다 도시 H에서 도시 A로 가는 항공편이 있습니다 도시 B에서 도시 F로 가는 항공편이 있습니다 도시 N에서 도시 H로 가는 항공편이 있습니다 도시 B에서 도시 M으로 가는 항공편이 있습니다 도시 N에서 도시 G로 가는 항공편이 있습니다 도시 M에서 도시 J로 가는 항공편이 있습니다 도시 G에서 도시 L로 가는 항공편이 있습니다 도시 H에서 도시 E로 가는 항공편이 있습니다 도시 G에서 도시 C로 가는 항공편이 있습니다 도시 M에서 도시 I로 가는 항공편이 있습니다 도시 F에서 도시 D로 가는 항공편이 있습니다 질문: 도시 B에서 도시 E로 가는 일련의 항공편이 있습니까?표 2: 그래프 연결성 작업에 대한 입력 예.그림 5는 이 예의 기본 그래프 구조를 설명합니다.모든 예에서 동일한 그래프 구조를 사용하고 출발 및 대상 도시와 노드의 레이블을 변경합니다. 도시는 문자 그대로 &quot;도시 A&quot;, &quot;도시 B&quot; 등으로 불립니다.KFBMHNGBSSSIEL 그림 5: 기본 그래프 구조는 표 2의 예에 해당합니다.입력: 현재 항공편 정보(다음 항공편은 편도만 있으며, 이용 가능한 모든 항공편이 아래에 포함되어 있습니다): 도시 G에서 도시 B로 가는 항공편이 있습니다.도시 H에서 도시 K로 가는 항공편이 있습니다.도시 L에서 도시 M으로 가는 항공편이 있습니다.도시 F에서 도시 H로 가는 항공편이 있습니다.도시 G에서 도시 J로 가는 항공편이 있습니다.도시 B에서 도시 I로 가는 항공편이 있습니다.도시 L에서 도시 A로 가는 항공편이 있습니다.도시 H에서 도시 N으로 가는 항공편이 있습니다.도시 B에서 도시 D로 가는 항공편이 있습니다.도시 J에서 도시 C로 가는 항공편이 있습니다.질문: 도시 F에서 도시 I로 가는 일련의 항공편이 있습니까? 출력: 예, 도시 F에서 도시 I로 가는 일련의 항공편이 있습니다. 경로는 다음과 같습니다. 1. 도시 F에서 도시 H로 2. 도시 H에서 도시 K로 3. 도시 K에서 도시 G로 4. 도시 G에서 도시 B로 5. 도시 B에서 도시 I로 검증 질문: 현재 항공편 정보(다음 항공편은 편도만 있으며, 이용 가능한 모든 항공편이 아래에 포함되어 있습니다): 도시 G에서 도시 B로 가는 항공편이 있습니다 도시 H에서 도시 K로 가는 항공편이 있습니다 [... 공간을 위해 잘라낸 10가지 다른 규칙 ...] 위의 항공편 정보를 기반으로, 도시 K에서 도시 G로 가는 항공편은 유효한 항공편입니까? 검증 답변: 아니요, 위의 항공편 정보를 기반으로, 도시 K에서 도시 G로 가는 직항 항공편은 없습니다. 표 3: GPT-4를 사용한 그래프 연결 데이터 세트 검증 예. 입력: 9791은 소수입니까? 출력: 아니요, 9791은 소수가 아닙니다. 13 × 751로 인수분해할 수 있습니다. 검증 Q1: 9791은 13으로 나누어떨어집니까? 예 또는 아니요로 답하세요.검증 A1: 아니요 검증 Q2: 9791은 751로 나누어떨어집니까?예 또는 아니요로 답하세요.검증 A2: 아니요 표 4: GPT-4를 사용한 소수성 검정 데이터 세트 검증 예.입력: 펜실베이니아 대학교를 모교로 하고 뉴햄프셔주를 대표하는 미국 상원의원이 있었나요?출력: 네, 펜실베이니아 대학교를 모교로 하고 뉴햄프셔주를 대표하는 미국 상원의원이 있었습니다.그의 이름은 존 P. 헤일로, 1847년부터 1853년까지, 그리고 1855년부터 1865년까지 상원의원을 지냈습니다.그는 1827년 보우든 대학을 졸업하고 나중에 펜실베이니아 대학교 로스쿨에 진학했습니다.검증 Q1: 존 P. 헤일이 미국 상원의원으로서 뉴햄프셔주를 대표한 적이 있나요? 검증 A1: 예, 존 P. 헤일은 미국 상원의원으로 뉴햄프셔주를 대표했습니다. 그는 1847년 3월 4일부터 1853년 3월 3일까지 상원에서 재직했고, 1855년 3월 4일부터 1865년 3월 3일까지 다시 상원에서 재직했습니다. 검증 Q2: 존 P. 헤일의 모교는 펜실베이니아 대학교였습니까? 검증 A2: 아니요, 존 P. 헤일의 모교는 메인주 브런스윅에 있는 보우든 칼리지였습니다. 표 5: GPT-4를 사용한 상원의원 모교 데이터 세트 검증 예. 작업 평균 모델 그래프 연결성 소수성 테스트 상원 의원 검색 ChatGPT 410/500(82.0%) 339/500(67.8%) 153/500(30.6%) 60.13% GPT-442/500(88.4%) 374/500(74.8%) 435/500(87.0%) 83.40% 표 6: 샘플 수 중 실수 수, 여기의 백분율은 오류율입니다. 작업 평균 모델 그래프 연결성 ChatGPT 396/410(96.6%) GPT-4 417/442(94.3%) 소수성 테스트 상원 의원 검색 125/339(36.9%) 98/153(68.6%) 67.37% 346/374(92.5%) 323/435(74.3%) 87.03% 표 7: 원래 출력에서 생성된 환각 수 중 눈덩이 모양의 환각 수. 모델 ChatGPT GPT-그래프 연결성 139/500(27.8%) 21/500(4.2%) 작업 우선성 테스트 2/500(0.4%) 37/500(7.4%) 평균 상원 의원 검색 0/500(0.0%) 0/500(0.0%) 9.40% 3.87% 표 8: 샘플 수 중 실수 수, 여기의 백분율은 오류율이며 &quot;단계별로 생각해 봅시다&quot; 프롬프트를 사용합니다. 모델 ChatGPT GPT-그래프 연결성 123/139(88.5%) 20/21(95.2%) 작업 우선성 테스트 0/2(0%) 35/37(94.6%) 평균 상원 의원 검색 0/0(N/A) 0/0(N/A) 44.25% 94.90% 표 9: 샘플 수 중 실수 수 원래 출력에서 생성된 환각 수에서 눈덩이처럼 불어난 환각을 &quot;단계별로 생각해 보자&quot;라는 프롬프트를 사용하여 구함. 모델 그래프 소수 상원의원 평균 ChatGPT(t = 0.0) ChatGPT(t = 0.6) ChatGPT(t = 0.9) 410/500(82.0%) 407/500(81.4%) 403/500(80.6%) 339/500(67.8%) 310/500(63.2%) 312/500(62.4%) 153/500(30.6%) 60.13% 155/500(31.0%) 58.53% 163/500(32.6%) 58.53% GPT-4(t = 0.0) GPT-4(t = 0.6) 442/500(88.4%) 374/500(74.8%) 435/500(87.0%) 83.40% 438/500(87.6%) 365/500(75.4%) 423/500(84.6%) 82.53% GPT-4(t=0.9) 437/500(87.4%) 377/500(73.0%) 423/500(84.6%) 81.67% 표 10: 샘플 수 중 실수 수, 여기의 백분율은 오류율이며, 온도 설정이 다양함 모델 그래프 Prime Senator Average ChatGPT(t=0.0) 396/410(96.6%) ChatGPT(t=0.6) 396/407(97.3%) 125/339(36.9%) 113/310(36.5%) 98/153(68.6%) 67.37% 103/155(66.5%) 66.77% ChatGPT(t=0.9) 399/402(99.3)% 116/312(37.2%) 104/163(63.8%) 66.77% GPT-4(t=0.0) GPT-4(t=0.6) GPT-4(t=0.9) 417/442(94.3%) 346/374(92.5%) 323/435(74.3%) 87.03% 402/438(91.8%) 398/437(91.1%) 331/377 (87.8%) 324/365 (88.8%) 329/423 (77.8%) 86.13% 320/423 (75.7%) 84.87% 표 11: 샘플 수 중 실수 수, 여기의 백분율은 오류율이며, 온도 설정이 다름 입력: 다트머스 대학을 모교로 하고 노스캐롤라이나주를 대표하는 미국 상원의원이 있었나요? 출력: 예, 다트머스 대학을 모교로 하고 노스캐롤라이나주를 대표하는 미국 상원의원이 있었습니다. 그의 이름은 윌리스 스미스이고, 그는 1950년부터 1953년까지 상원의원을 지냈습니다. 검증 Q1: 윌리스 스미스가 미국 상원의원으로서 노스캐롤라이나주를 대표했습니까? 검증 A1: 예, 윌리스 스미스가 미국 상원의원으로서 노스캐롤라이나주를 대표했습니다. 그는 1950년부터 1953년 사망할 때까지 재임했습니다. 검증 Q2: 윌리스 스미스의 모교는 다트머스 대학이었습니까? 검증 A2: 예, 윌리스 스미스의 모교는 다트머스 대학이었습니다. 그는 1917년에 졸업했습니다. 표 12: GPT-4가 상원의원 검색 과제 검증 시험에 실패한 사례. 윌리스 스미스는 노스캐롤라이나의 상원의원이었지만 다트머스 대학에 다닌 적은 없습니다.
