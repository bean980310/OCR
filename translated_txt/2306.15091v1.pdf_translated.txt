--- ABSTRACT ---
컨텍스트 내 학습(ICL)은 추론 시점에 소수의 예를 간단히 시연함으로써 다양한 NLP 작업에서 언어 모델의 성능을 개선합니다. 모델이 이러한 시연에 대해 특별히 훈련된 적이 없기 때문에 ICL 능력이 나타나는 이유는 잘 이해되지 않습니다. ICL의 암묵적 메커니즘을 탐구하는 이전 작업과 달리, 우리는 사전 훈련 데이터를 조사하여 ICL을 연구합니다. 구체적으로, 우리는 먼저 반복적이고 기울기 기반 접근 방식을 적용하여 ICL을 지원하는 사전 훈련 데이터의 작은 하위 집합을 찾습니다. 우리는 이 작은 하위 집합에 대한 지속적인 사전 훈련이 모델의 ICL 능력을 최대 18%까지 크게 향상시키는 것을 관찰합니다. 그런 다음 우리는 지원 하위 집합을 사전 훈련 데이터의 무작위 하위 집합과 대조적으로 비교하여 다음을 발견합니다. (1) ICL에 대한 지원 사전 훈련 데이터는 다운스트림 작업과 더 높은 도메인 관련성이 없습니다. (2) 지원 사전 훈련 데이터는 드물게 발생하는 롱테일 토큰의 질량이 더 높습니다. (3) 지원 사전 학습 데이터는 장거리 맥락에서 얻은 정보 이득이 평균 이하인 도전적인 사례로, 어려운 장거리 맥락을 통합하는 학습이 ICL을 장려한다는 것을 나타냅니다. 저희의 작업은 인스턴스 수준 사전 학습 데이터를 분석하여 ICL을 이해하기 위한 첫 걸음을 내딛습니다. 저희의 통찰력은 미래에 사전 학습 데이터 구성을 적극적으로 안내하여 언어 모델의 ICL 능력을 향상시킬 수 있는 잠재력이 있습니다.
--- INTRODUCTION ---
NLP에서 맥락 내 학습은 최근 엄청난 주목을 받았습니다(Dong et al., 2022). 훈련이나 미세 조정 모델에 의존하는 기존 학습 패러다임과 달리 맥락 내 학습은 테스트 입력에 대한 접두사로 언어 모델에 소수의 데모 사례만 제공하며 매개변수 업데이트는 없습니다. 맥락 내 학습은 다양한 NLP 작업에서 우수한 성과를 보였습니다(Brown et al., 2020; Zhang et al., 2022b; * Meta AI에서 인턴십을 하는 동안 수행한 작업. 사전 학습 데이터 맥락 내 학습 데이터 찰스가 쓰러지지 않으면 치프스가 경기에서 이기지 못하는 시나리오가 생각나지 않습니다. 무슨 일인가요? 러닝 게임에서 시간을 낭비해야 하나요? 올 프로 러닝 백이 있어서 얼마나 편리한지요! 찰스가 쓰러진 것이 경기 결과에 확실히 영향을 미쳤다는 데 동의하지만, 백업이 엉망진창인 것도 아닙니다. 나일 데이비스는 2개의 TD를 기록했기 때문에 찰스로 오해받지는 않겠지만 훌륭한 경기를 펼쳤습니다... 입력: Microsoft에서 OpenAl에 투자할 수도 있습니다... 범주: 기술. 입력: 목요일에 백악관에서... 범주: 정치. 입력: 금요일에 Apple에서 새로운... 범주: [MASK] 그림 1: OPT 사전 학습 데이터의 예 (Zhang et al., 2022b) 및 주제 분류의 설명적 맥락 내 학습 사례. 맥락 내 학습 과제 데이터는 내용과 형식 모두에서 사전 학습 인스턴스와 크게 다를 수 있습니다. Chowdhery et al., 2022; Hoffmann et al., 2022), 그러나 이 새로운 능력의 기원과 이유는 여전히 조사가 부족합니다. 언어 모델이 데모 사례에서 학습하도록 명시적으로 훈련되지 않았기 때문에 맥락 내 학습은 놀랍습니다(Xie et al., 2022). 그림 1의 설명적 시나리오에서 볼 수 있듯이 일반적인 사전 학습 데이터 인스턴스는 내용과 형식 모두에서 다운스트림 과제의 맥락 내 학습 사례와 크게 다릅니다. 이전 연구에서는 실증적 시범 사례의 유용하고 무관한 속성을 조사하거나(Min et al., 2022; Zhang et al., 2022a) 이론적으로 특정 합성 언어 모델이 실증으로 베이지안 추론을 암묵적으로 수행함을 증명함으로써(Xie et al., 2022) 맥락 내 학습이 무엇인지에 대한 답을 시도했습니다. 나아가 최근 연구에서는 맥락 내 학습 메커니즘과 회귀, 최근접 이웃, 경사 하강법(Olsson et al., 2022; Akyürek et al., 2022; Dai et al., 2022; von Oswald et al., 2022)과 같은 표준 학습 알고리즘 간의 연관성을 도출했습니다. 이와는 다르게 이 연구에서는 사전 학습 데이터의 관점을 통해 맥락 내 학습 능력이 어디에서 습득되는지 이해하는 데 관심이 있습니다. 많지는 않지만 최근 연구에서는 이 방향을 조사했습니다. 예를 들어, Shin et al. (2022)는 다양한 언어 모델을 서로 다른 코퍼스에서 사전 학습시켰습니다. 그들은 비교적 거친 데이터 세트 수준에서 사전 학습 데이터 세트의 속성과 맥락 내 학습 성능 간의 상관 관계를 연구했습니다. Chan et al. (2022)는 서로 다른 속성을 가진 사전 학습 데이터를 구성하고 데이터의 일부 분포 속성이 맥락 내 학습의 출현을 주도한다는 것을 발견했습니다. 그러나 그들의 실험은 이미지-레이블 쌍의 합성 데이터로 제한되었습니다. 이 작업에서 우리는 대규모 언어 모델 OPT(Zhang et al., 2022b)와 사전 학습 데이터를 조사했습니다. 우리는 먼저 모델의 맥락 내 학습 능력에 특히 도움이 되는 특정 사전 학습 데이터 인스턴스가 존재한다고 가정했습니다. 그러한 인스턴스를 찾기 위해 우리는 반복적이고 기울기 기반 방법인 ORCA(Han and Tsvetkov, 2022)를 적용하여 OPT의 사전 학습 코퍼스 내에서 검색했습니다. 이 프로세스는 다운스트림 작업의 컨텍스트 내 학습 데이터의 기울기에 따라 안내되며, 식별된 하위 집합을 Han 및 Tsvetkov(2022)에 따라 컨텍스트 내 학습에 대한 지원 사전 학습 데이터라고 합니다. 나아가, 섭동적 지속적 사전 학습을 통해 지원 하위 집합이 가짜 제로샷 성능에 영향을 미치지 않으면서 다운스트림 작업에서 모델의 컨텍스트 내 학습 성능을 개선한다는 것을 정량적으로 확인합니다(§2). 그런 다음 식별된 지원 데이터를 일반적인 사전 학습 데이터와 대조하여 분석하여 컨텍스트 내 학습과 특히 관련된 데이터 기능을 얻습니다. 특히 다운스트림 작업에 대한 도메인 관련성, 토큰 빈도 분포, 장거리 사전 학습 컨텍스트를 통합하는 정보 이득의 세 가지 측면에서 접근합니다. 주요 결과는 다음과 같습니다. (1) 일반적인 사전 학습 데이터와 비교할 때 지원 데이터는 다운스트림 작업에 대한 도메인 관련성이 더 높지 않습니다. (2) 지원 사전 학습 데이터에는 드물게 발생하는 롱테일 토큰이 비교적 많이 포함되어 있습니다. (3) 지원 사전 학습 데이터는 언어 모델링을 위한 장거리 맥락을 통합하는 데 있어 도전적인 예입니다(§3). 저희의 연구는 인스턴스 수준의 사전 학습 데이터를 분석하여 NLP 작업에서 맥락 내 학습을 해석하기 위한 첫 번째 단계를 제공합니다. 저희는 그것이 언어 모델의 맥락 내 학습 행동의 투명성과 해석성을 개선하는 데 도움이 될 수 있다고 믿습니다. 저희의 분석은 또한 사전 학습 데이터 구축을 알려줌으로써 미래에 맥락 내 학습을 개선하는 길을 열 수 있습니다. 2 맥락 내 학습을 위한 지원 사전 학습 데이터 찾기 Han과 Tsvetkov(2022)는 바닐라 제로샷 프롬프팅 설정에서 BERT(Devlin et al., 2019)의 지원 사전 학습 데이터를 찾기 위한 반복적이고 기울기 기반 방법인 ORCA를 제안합니다. 이 섹션에서는 몇 가지 배경 정보를 제공하고 맥락 내 학습(ICL) 설정에서 대규모 언어 모델에 ORCA를 적용하여 데모 예제와 함께 다운스트림 작업을 위한 지원 사전 학습 데이터를 찾습니다.¹ 2.1 방법론 사전 학습된 언어 모델(LM) ¤과 작업 Dtask의 입력과 기준 진실 출력을 나타내는 데이터 쌍(x, y)이 있다고 가정합니다. x와 y는 모두 자연어입니다. 분류 작업의 경우 대상 레이블은 동사화기를 통해 자연어로 변환할 수 있습니다(Schick 및 Schütze, 2021). 제로샷 프롬프팅 사전 학습된 언어 모델은 제로샷 프롬프팅을 통해 다운스트림 작업을 수행하는 데 적용될 수 있습니다(예: Petroni et al., 2019). 분류 작업의 경우 언어 모델은 최고 확률 argmaxy&#39; Po(y&#39; | x) argmax po(yt | x, y&#39; &lt;+)로 후보 답변을 출력합니다. 여기서 y에는 모든 후보 답변 y&#39;가 포함됩니다. 생성 작업의 경우, x에 따라 조건부로 자기 회귀적으로 샘플링하여 출력을 얻을 수 있습니다(예: Holtzman et al., 2019). 이는 데모 예제가 없는 제로샷 시나리오입니다. = 컨텍스트 내 학습 på(y | x)를 모델링하는 대신, ICL은 po(y | {(xdemo, Ydemo)}, x)를 추정하여 대상 작업 Dtask에서 샘플링한 여러 데모 예제(x demo, y demo)를 원래 모델 입력에 추가합니다. 언어 모델은 데모가 있는 작업 데이터에서 결코 학습되지 않습니다. 그러나 O의 &#39;에 대한 대용으로 컨텍스트 내 데이터에 대한 손실을 형성할 수 있습니다. 추론 시간 모델 출력에 대한 중요한 학습 데이터를 식별하는 것은 모델 해석성에서 확립된 주제이며, 다양한 사전 작업에서 그래디언트 유사도 변형을 통해 데이터 중요도를 측정합니다(Koh and Liang, 2017; Pruthi et al., 2020). 그러나 이러한 방법은 대규모 사전 학습 데이터에 적용하기에는 비용이 많이 듭니다. 우리의 작업과 동시에 Guu et al. (2023)은 훈련 실행을 시뮬레이션하여 개별 훈련 예제의 중요성을 모델링하는 흥미로운 방법을 제안했지만, 사전 훈련 대신 미세 조정의 규모에 있습니다. 이후 안내 단계에 사용될 ICL 성능, LICL(x, y) = = – log pe(y | t={(x demo, y demo)}, x) - logo({(x demo, y demo)}, x, Y
--- RELATED WORK ---
데모 예제 Min et al.(2022)은 데모 예제의 어떤 측면이 작업 성능에 기여하거나 관련이 없는지 분석하여 ICL을 이해합니다. 그들은 기준 진실 데모 레이블을 임의 레이블로 대체해도 작업 성능에 해가 되지 않는 반면 ICL은 데모 예제에 지정된 레이블 공간, 입력 분포 및 시퀀스 형식을 아는 것이 여전히 이점이 있다는 것을 발견했습니다.12 Zhang et al.(2022a)은 시퀀스 레이블 지정 작업에서 데모 길이와 토큰의 관련성이 ICL에 중요하다는 것을 추가로 보여줍니다.학습 메커니즘 Xie et al.(2022)은 ICL을 언어 모델이 추론 시점에 데모 예제에서 공유된 잠재 개념을 추론할 때 발생하는 암묵적 베이지안 추론으로 설명합니다. 그들은 언어 모델이 개념의 제어된 분포를 사용하여 합성 사전 학습 데이터를 구성하여 이러한 ICL 동작을 보인다는 것을 보여줍니다. Garg et al.(2022)은 Transformer 모델이 컨텍스트 내 데모 예제에서 보이지 않는 선형 함수를 학습하도록 학습될 수 있음을 경험적으로 보여줍니다. Olsson et al. (2022)는 다층 주의12 Wei 등(2023) 및 Pan 등(2023)과 같은 최근 연구에서는 관련 결과가 모델 척도에도 따라 달라질 수 있음을 보여줍니다. 기반 모델은 유도 헤드를 형성하고 접두사 컨텍스트에서 패턴 복사 동작으로 ICL을 수행합니다. Akyürek 등(2022), Dai 등(2022), von Oswald 등(2022)과 같은 최근 연구에서는 경사 하강법 및 회귀와 같은 데모 예제에 대한 일종의 표준 학습 알고리즘으로 Transformer 모델에서 ICL을 설명합니다. 사전 학습 데이터 Razeghi 등(2022)은 수치 추론 작업에서 언어 모델의 ICL 성능이 사전 학습 코퍼스의 입력 데이터의 용어 빈도와 높은 상관 관계가 있음을 발견했습니다. Shin 등(2022)은 사전 학습 데이터 세트가 다를 때 ICL에 어떤 영향을 미칠 수 있는지 조사했습니다. 그들은 ICL이 코퍼스 도메인 소스에 크게 의존하지만, 다운스트림 작업과 관련된 코퍼스로 사전 학습하는 것이 항상 해당 작업에서 경쟁력 있는 ICL 성능으로 이어지지는 않는다는 것을 발견했습니다. Chan et al. (2022)은 합성 이미지-레이블 쌍 데이터 세트에 대한 실험을 했습니다. 그들은 클래스의 버스트성과 드물게 발생하는 클래스의 대량과 같은 합성 사전 학습 데이터의 특정 분포적 속성이 ICL의 출현을 촉진한다는 것을 보여줍니다. 저희의 연구는 이 작업 라인에 속하지만 인스턴스 수준의 사전 학습 데이터를 분석하여 현실적인 NLP 작업에서 ICL을 이해하기 위한 첫 번째 단계를 제공합니다. 또한 저희의 작업과 동시에 Gu et al. (2023)은
--- METHOD ---
ORCA(Han 및 Tsvetkov, 2022)를 사용하여 OPT의 사전 학습 코퍼스 내에서 검색합니다. 이 프로세스는 다운스트림 작업의 컨텍스트 내 학습 데이터의 기울기에 따라 안내되며, 식별된 하위 집합을 Han 및 Tsvetkov(2022)에 따라 컨텍스트 내 학습에 대한 지원 사전 학습 데이터라고 합니다. 또한, 섭동적 지속적 사전 학습을 통해 지원 하위 집합이 가짜 제로샷 성능에 영향을 미치지 않으면서 다운스트림 작업에서 모델의 컨텍스트 내 학습 성능을 개선한다는 것을 정량적으로 확인합니다(§2). 그런 다음 식별된 지원 데이터를 일반적인 사전 학습 데이터와 대조하여 컨텍스트 내 학습과 특히 관련된 데이터 기능을 얻습니다. 특히 다운스트림 작업에 대한 도메인 관련성, 토큰 빈도 분포, 장거리 사전 학습 컨텍스트를 통합하는 정보 이득의 세 가지 측면에서 접근합니다. 주요 결과는 다음과 같습니다. (1) 일반적인 사전 학습 데이터와 비교할 때 지원 데이터는 다운스트림 작업에 대한 도메인 관련성이 높지 않습니다. (2) 지원 사전 학습 데이터에는 드물게 발생하는 롱테일 토큰이 비교적 많이 포함되어 있습니다. (3) 지원 사전 학습 데이터는 언어 모델링을 위해 장거리 컨텍스트를 통합하는 데 있어 어려운 예입니다(§3). 저희의 연구는 인스턴스 수준 사전 학습 데이터를 분석하여 NLP 작업에서 컨텍스트 내 학습을 해석하는 데 있어 첫 번째 단계를 제공합니다. 저희는 이것이 언어 모델의 컨텍스트 내 학습 행동에 대한 투명성과 해석 가능성을 개선하는 데 도움이 될 수 있다고 믿습니다. 저희의 분석은 또한 사전 학습 데이터 구성을 알려줌으로써 미래에 컨텍스트 내 학습을 개선하는 길을 열 수 있습니다. 2 컨텍스트 내 학습을 위한 지원 사전 학습 데이터 찾기 Han과 Tsvetkov(2022)는 바닐라 제로샷 프롬프팅 설정에서 BERT(Devlin et al., 2019)의 지원 사전 학습 데이터를 찾기 위해 반복적이고 기울기 기반 방법인 ORCA를 제안합니다. 이 섹션에서는 몇 가지 배경 정보를 제공하고 맥락 내 학습(ICL) 설정에서 대규모 언어 모델에 ORCA를 적용하여 데모 예제와 함께 다운스트림 작업을 위한 지원 사전 학습 데이터를 찾습니다.¹ 2.1 방법론 사전 학습된 언어 모델(LM) ¤과 작업 Dtask의 입력과 기준 진실 출력을 나타내는 데이터 쌍(x, y)이 있다고 가정합니다. x와 y는 모두 자연어입니다. 분류 작업의 경우 대상 레이블은 동사화기를 통해 자연어로 변환할 수 있습니다(Schick 및 Schütze, 2021). 제로샷 프롬프팅 사전 학습된 언어 모델은 제로샷 프롬프팅을 통해 다운스트림 작업을 수행하는 데 적용될 수 있습니다(예: Petroni et al., 2019). 분류 작업의 경우 언어 모델은 최고 확률 argmaxy&#39; Po(y&#39; | x) argmax po(yt | x, y&#39; &lt;+)로 후보 답변을 출력합니다. 여기서 y에는 모든 후보 답변 y&#39;가 포함됩니다. 생성 작업의 경우, x에 따라 조건부로 자기 회귀적으로 샘플링하여 출력을 얻을 수 있습니다(예: Holtzman et al., 2019). 이는 데모 예제가 없는 제로샷 시나리오입니다. = 컨텍스트 내 학습 på(y | x)를 모델링하는 대신, ICL은 po(y | {(xdemo, Ydemo)}, x)를 추정하여 대상 작업 Dtask에서 샘플링한 여러 데모 예제(x demo, y demo)를 원래 모델 입력에 추가합니다. 언어 모델은 데모가 있는 작업 데이터에서 결코 학습되지 않습니다. 그러나 O의 &#39;에 대한 대용으로 컨텍스트 내 데이터에 대한 손실을 형성할 수 있습니다. 추론 시간 모델 출력에 대한 중요한 학습 데이터를 식별하는 것은 모델 해석성에서 확립된 주제이며, 다양한 사전 작업에서 그래디언트 유사도 변형을 통해 데이터 중요도를 측정합니다(Koh and Liang, 2017; Pruthi et al., 2020). 그러나 이러한 방법은 대규모 사전 학습 데이터에 적용하기에는 비용이 많이 듭니다. 우리의 작업과 동시에 Guu et al. (2023)은 훈련 실행을 시뮬레이션하여 개별 훈련 예제의 중요성을 모델링하는 흥미로운 방법을 제안했지만, 사전 훈련 대신 미세 조정의 규모에 있습니다. 이후 안내 단계에 사용될 ICL 성능, LICL(x, y) = = – log pe(y | t={(x demo, y demo)}, x) - logo({(x demo, y demo)}, x, Y
--- EXPERIMENT ---
이미지-레이블 쌍의 합성 데이터로 제한됩니다. 이 작업에서 우리는 대규모 언어 모델 OPT(Zhang et al., 2022b)와 사전 학습 데이터를 조사합니다. 우리는 먼저 모델의 맥락 내 학습 능력에 특히 도움이 되는 몇 가지 특정 사전 학습 데이터 인스턴스가 존재한다고 가정합니다. 그러한 인스턴스를 찾기 위해 반복적이고 기울기 기반 방법인 ORCA(Han and Tsvetkov, 2022)를 적용하여 OPT의 사전 학습 코퍼스 내에서 검색합니다. 이 프로세스는 다운스트림 작업의 맥락 내 학습 데이터의 기울기에 따라 안내되며, 식별된 하위 집합을 Han and Tsvetkov(2022)에 따라 맥락 내 학습에 대한 지원 사전 학습 데이터라고 합니다. 또한, 우리는 섭동적 지속적 사전 학습을 통해 지원 하위 집합이 가짜 제로샷 성능에 영향을 미치지 않으면서 다운스트림 작업에서 모델의 맥락 내 학습 성능을 개선한다는 것을 정량적으로 확인합니다(§2). 그런 다음 식별된 지원 데이터를 일반적인 사전 학습 데이터와 대조하여 분석하여 특히 맥락 내 학습과 관련된 데이터 기능을 얻습니다. 우리는 특히 세 가지 측면에서 접근합니다. 다운스트림 작업에 대한 도메인 관련성, 토큰 빈도 분포, 장거리 사전 학습 맥락을 통합하는 정보 이득입니다. 우리의 주요 결과는 다음과 같습니다. (1) 일반적인 사전 학습 데이터와 비교할 때 지원 데이터는 다운스트림 작업에 대한 도메인 관련성이 더 높지 않습니다. (2) 지원 사전 학습 데이터에는 드물게 발생하는 롱테일 토큰이 비교적 많이 포함되어 있습니다. (3) 지원 사전 학습 데이터는 언어 모델링을 위해 장거리 맥락을 통합하는 데 있어 어려운 예입니다(§3). 우리의 연구는 인스턴스 수준 사전 학습 데이터를 분석하여 NLP 작업에서 맥락 내 학습을 해석하는 첫 번째 단계를 제공합니다. 우리는 그것이 언어 모델의 맥락 내 학습 행동의 투명성과 해석성을 개선하는 데 도움이 될 수 있다고 믿습니다. 우리의 분석은 또한 사전 학습 데이터 구성을 알려줌으로써 미래에 맥락 내 학습을 개선하는 길을 열 수 있습니다. 2 문맥 내 학습을 위한 지원 사전 학습 데이터 찾기 Han과 Tsvetkov(2022)는 바닐라 제로샷 프롬프팅 설정에서 BERT(Devlin et al., 2019)의 지원 사전 학습 데이터를 찾기 위해 반복적이고 기울기 기반 방법인 ORCA를 제안합니다. 이 섹션에서는 몇 가지 배경 정보를 제공하고 문맥 내 학습(ICL) 설정에서 대규모 언어 모델에 대한 ORCA를 조정하여 데모 예제와 함께 다운스트림 작업에 대한 지원 사전 학습 데이터를 찾습니다.¹ 2.1 방법론 사전 학습된 언어 모델(LM) ¤과 작업 Dtask의 입력과 기준 진실 출력을 나타내는 데이터 쌍(x, y)이 있다고 가정합니다. x와 y는 모두 자연어입니다. 분류 작업의 경우 대상 레이블은 동사화기를 통해 자연어로 변환될 수 있습니다(Schick and Schütze, 2021). 제로샷 프롬프팅 사전 학습된 언어 모델은 제로샷 프롬프팅을 통해 다운스트림 작업을 수행하는 데 적용될 수 있습니다(예: Petroni et al., 2019). 분류 작업의 경우 언어 모델은 최고 확률 argmaxy&#39; Po(y&#39; | x) argmax po(yt | x, y&#39; &lt;+)로 후보 답변을 출력합니다. 여기서 y는 모든 후보 답변 y&#39;를 포함합니다. 생성 작업의 경우 x에 따라 조건부로 자기 회귀적으로 샘플링하여 출력을 얻을 수 있습니다(예: Holtzman et al., 2019). 이는 데모 예제가 없는 제로샷 시나리오입니다. = 컨텍스트 내 학습 på(y | x)를 모델링하는 대신 ICL은 po(y | {(xdemo, Ydemo)}, x)를 추정하여 대상 작업 Dtask에서 샘플링한 여러 데모 예제(x demo, y demo)를 원래 모델 입력에 추가합니다. 언어 모델은 데모가 있는 작업 데이터로 학습되지 않습니다. 그러나 우리는 O의 &#39;추론 시간 모델 출력을 위한 중요한 학습 데이터를 식별하는 것은 모델 해석성에서 확립된 주제이며, 다양한 사전 작업에서 그래디언트 유사도의 변형을 통해 데이터 중요도를 측정합니다(Koh 및 Liang, 2017; Pruthi et al., 2020). 그러나 이러한 방법은 대규모 사전 학습 데이터에 적용하기에는 비용이 많이 듭니다. 저희의 작업과 동시에 Guu et al.(2023)은 학습 실행을 시뮬레이션하여 개별 학습 사례의 중요성을 모델링하는 흥미로운 방법을 제안했지만, 사전 학습 대신 미세 조정의 규모이기도 합니다. 이후 안내 단계에 사용될 ICL 성능, LICL(x, y) = = – log pe(y | t={(x demo, y demo)}, x) - logo({(x demo, y demo)}, x, Y
--- CONCLUSION ---
맥락 내 학습은 다양한 NLP 작업에서 우수한 성과를 보였지만, 언어 모델이 이 능력을 어디서 얻었는지는 여전히 불분명합니다. 우리는 언어 모델이 다운스트림 작업에서 맥락 내 학습을 수행하도록 특히 지원하는 사전 학습 데이터의 작은 하위 집합을 식별하여 문제에 접근합니다. 우리는 일반적인 사전 학습 데이터와 대조적으로 지원 인스턴스의 공통적인 특징을 분석하고 다음과 같은 사실을 발견했습니다. (1) 지원 사전 학습 데이터는 다운스트림 작업과 더 높은 도메인 관련성이 없습니다. (2) 지원 데이터에는 비교적 많은 양의 희귀하고 긴꼬리 토큰이 포함되어 있습니다. (3) 지원 사전 학습 데이터는 언어 모델링에 장거리 맥락을 통합하는 데 더 어려운 인스턴스입니다. 우리의 연구 결과는 기존 모델의 맥락 내 학습 성과를 적극적으로 개선하기 위해 사전 학습 데이터를 개선하거나 구성하는 향후 작업에 도움이 될 수 있습니다. 제한 사항 작업 전반에 걸쳐 조사한 지원 사전 학습 데이터는 현재 LM과 관련이 있으므로 지원 데이터를 사용한 섭동적 지속 사전 학습은 다운스트림 작업에 배포된 최종 LM 체크포인트를 개선할 것입니다. 지원으로 결정하지 않은 일부 데이터의 경우 LM의 초기 체크포인트와 관련하여 지원적일 수 있습니다. 더 많은 컴퓨팅 리소스를 사용하면 향후 작업에서 사전 학습 프로세스 전반에 걸쳐 LM의 여러 체크포인트에서 지원 패턴의 추세를 조사할 수 있습니다. 또한 작업의 또 다른 중요한 제한 사항은 관련된 컴퓨팅 리소스의 양입니다. ORCA-ICL 방법은 역전파가 필요한 기울기 기반입니다. 대량의 사전 학습 데이터를 반복하므로 계산 비용은 고려된 사전 학습 데이터에서 배치 크기 1로 언어 모델을 학습하는 것과 비슷합니다. 각각 8개의 Nvidia V100 GPU로 구성된 4개 노드에서 실험의 각 소스 작업에 대한 지원 사전 학습 데이터를 찾는 데 약 1주일이 걸립니다. 이러한 계산의 완화 측면 중 하나는 기울기 계산을 비동기적으로 수행할 수 있으므로 노드 클러스터에 분산된 유휴 남은 GPU를 사용할 수 있다는 것입니다. 향후 작업에서는 기울기 유사성의 효율적인 계산을 탐색하거나 지원 데이터 추출 패러다임에서 지원 데이터 생성으로 전환할 계획입니다. 감사의 말 도움이 되는 토론에 대해 Naman Goyal, Anjali Sridhar, Zeyu Liu, Victoria Lin, Mengzhou Xia, Weijia Shi, Jiacheng Liu, Hao Zhu, Tianxing He에게 감사드립니다. 또한 익명의 ACL 검토자와 TsvetShop의 모든 구성원에게 귀중한 피드백을 주셔서 감사드립니다. 이 연구는 HIATUS 프로그램 계약 #2022-22072200004를 통해 국가 정보국장실(ODNI), 정보 고급 연구 프로젝트 활동(IARPA)에서 부분적으로 지원합니다. 여기에 포함된 견해와 결론은 저자의 것이며 ODNI, IARPA 또는 미국 정부의 명시적 또는 묵시적 공식 정책을 반드시 나타내는 것으로 해석되어서는 안 됩니다. 미국 정부는 저작권 주석에도 불구하고 정부 목적으로 재인쇄본을 복제하고 배포할 권한이 있습니다. 참고문헌 Ekin Akyürek, Dale Schuurmans, Jacob Andreas, Tengyu Ma, Denny Zhou. 2022. What learning algorithm is in-context learning? investigations with linear models. arXiv 사전 인쇄본 arXiv:2211.15661. Tiago A Almeida, José María G Hidalgo, Akebo Yamakami. 2011. Contributions to the study of sms spam filtering: new collection and results. In Proceedings of the 11th ACM symposium on Document engineering, pages 259–262. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei. 2020. 언어 모델은 few-shot 학습자입니다. 신경 정보 처리 시스템의 발전, 33권, 1877-1901페이지. Curran Associates, Inc. Stephanie CY Chan, Adam Santoro, Andrew Kyle Lampinen, Jane X Wang, Aaditya K Singh, Pierre Harvey Richemond, James McClelland, Felix Hill. 2022. 데이터 분포 속성은 변압기에서 새로운 맥락 내 학습을 주도합니다. 신경 정보 처리 시스템의 발전. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: 경로로 언어 모델링 확장. arXiv 사전 인쇄본 arXiv:2204.02311. Damai Dai, Yutao Sun, Li Dong, Yaru Hao, Zhifang Sui, Furu Wei. 2022. gpt가 맥락 내 학습을 할 수 있는 이유는 무엇입니까? 언어 모델은 메타 최적화 도구로 비밀리에 경사 하강을 수행합니다. arXiv 사전 인쇄본 arXiv:2212.10559. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. 2019. BERT: 언어 이해를 위한 딥 양방향 변환기의 사전 학습. Proc. NAACL-HLT. Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Zhifang Sui. 2022. 컨텍스트 내 학습을 위한 설문 조사. arXiv 사전 인쇄본 arXiv:2301.00234. Shivam Garg, Dimitris Tsipras, Percy Liang, Gregory Valiant. 2022. 변환기는 컨텍스트 내에서 무엇을 학습할 수 있습니까? 간단한 함수 클래스에 대한 사례 연구. arXiv 사전 인쇄본 arXiv:2208.01066. Alec Go, Richa Bhayani, Lei Huang. 2009. 원격 감독을 사용한 Twitter 감정 분류. CS224N 프로젝트 보고서, Stanford, 1(12):2009. Yuxian Gu, Li Dong, Furu Wei, Minlie Huang. 2023. 맥락에서 학습하기 위한 사전 학습. Kelvin Guu, Albert Webson, Elizabeth-Jane Pavlick, Lucas Dixon, Ian Tenney, Tolga Bolukbasi. 2023. Simfluence: 학습 실행을 시뮬레이션하여 개별 학습 사례의 영향 모델링. ArXiv, abs/2303.08114. Xiaochuang Han과 Yulia Tsvetkov. 2022. Orca: 사전 학습 데이터의 바다에서 지원 데이터 증거를 찾아 프롬프트 언어 모델 해석. arXiv 사전 인쇄본 arXiv:2205.12600. Tianxing He, Jingyu Zhang, Tianle Wang, Sachin Kumar, Kyunghyun Cho, James Glass, and Yulia Tsvetkov. 2022. 텍스트 생성을 위한 모델 기반 평가 지표의 맹점에 관하여. arXiv 사전 인쇄본 arXiv:2212.10020. Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. 2022. 컴퓨팅 최적화 대규모 언어 모델 학습. arXiv 사전 인쇄본 arXiv:2203.15556. Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2019. 신경 텍스트 퇴화의 호기심 많은 사례. International Conference on Learning Representations에서. Diederik P Kingma and Jimmy Ba. 2014. Adam: 확률적 최적화를 위한 방법. arXiv 사전 인쇄본 arXiv:1412.6980. Pang Wei Koh와 Percy Liang. 2017. 영향 함수를 통한 블랙박스 예측 이해. Proc. ICML. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov. 2019. Roberta: 견고하게 최적화된 bert 사전 학습 접근 방식. arXiv 사전 인쇄본 arXiv:1907.11692. Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, Luke Zettlemoyer. 2022. 시범의 역할 재고: 맥락 내 학습을 작동시키는 요소는 무엇인가? EMNLP에서. Nasrin Mostafazadeh, Michael Roth, Annie Louis, Nathanael Chambers, and James Allen. 2017. Lsdsem 2017 공유 과제: 스토리 빈칸 채우기 테스트. 어휘, 문장 및 담화 수준 의미론의 연결 모델에 대한 2nd 워크숍 회의록, 46-51페이지. Catherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova DasSarma, Tom Henighan, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, et al. 2022. 맥락 내 학습 및 귀납 헤드. arXiv 사전 인쇄본 arXiv:2209.11895. Myle Ott, Sam Shleifer, Min Xu, Priya Goyal, Quentin Duval, and Vittorio Caggiano. 2021. 완전히 분할된 데이터 병렬: GPU가 적은 더 빠른 AI 학습. https://engineering.fb.com/2021/07/15/open-source/fsdp/. Jane Pan, Tianyu Gao, Howard Chen, Danqi Chen. 2023. 맥락 내 학습이 맥락 내에서 &quot;학습&quot;하는 것: 과제 인식과 과제 학습의 분리. Fabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander H. Miller, Sebastian Riedel. 2019. 지식 기반으로서의 언어 모델? Proc. EMNLP에서. Krishna Pillutla, Swabha Swayamdipta, Rowan Zellers, John Thickstun, Sean Welleck, Yejin Choi, Zaïd Harchaoui. 2021. Mauve: 발산 경계를 사용하여 신경 텍스트와 인간 텍스트 간의 격차 측정. Proc. NeurIPS에서. Garima Pruthi, Frederick Liu, Mukund Sundararajan, Satyen Kale. 2020. 경사 하강을 추적하여 학습 데이터 영향 추정. Proc. NeurIPS. Yasaman Razeghi, Robert L Logan IV, Matt Gardner, Sameer Singh. 2022. 사전 학습 용어 빈도가 few-shot 추론에 미치는 영향. Arxiv, abs/2202.07206. Timo Schick and Hinrich Schütze. 2021. few-shot 텍스트 분류 및 자연어 추론을 위해 빈칸 채우기 질문 활용. Proc. EACL. Seongjin Shin, Sang-Woo Lee, Hwijeen Ahn, Sungdong Kim, HyoungSeok Kim, Boseop Kim, Kyunghyun Cho, Gichang Lee, Woomyoung Park, Jung-Woo Ha, et al. 2022. 대규모 언어 모델에 의한 맥락 내 학습에 대한 사전 학습 코퍼스의 효과. arXiv 사전 인쇄본 arXiv:2204.13509. Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. 2019. Megatron-lm: 모델 병렬 처리를 사용하여 수십억 개의 매개변수 언어 모델 학습. arXiv 사전 인쇄본 arXiv:1909.08053. Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. 2013. 감정 트리뱅크에 대한 의미적 구성성을 위한 재귀적 심층 모델. 자연어 처리의 경험적 방법에 대한 2013년 컨퍼런스 회의록, 1631-1642쪽. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser 및 Illia Polosukhin. 2017. 관심만 있으면 됩니다. 신경 정보 처리 시스템의 발전, 30. Johannes von Oswald, Eyvind Niklasson, Ettore Randazzo, João Sacramento, Alexander Mordvintsev, Andrey Zhmoginov 및 Max Vladymyrov. 2022. 트랜스포머는 경사하강법을 통해 상황에 맞게 학습합니다. arXiv 사전 인쇄 arXiv:2212.07677. Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap 등 2022. 1,600개 이상의 언어 작업에 대한 상황별 지침을 통한 벤치마킹 일반화. arXiv 사전 인쇄 arXiv:2204.07705. Jerry W. Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson, Yifeng Lu, Xinyun Chen, Hanxiao Liu, Da Huang, Denny Zhou 및 Tengyu Ma. 2023. 더 큰 언어 모델은 상황 내 학습을 다르게 수행합니다. ArXiv, ABS/2303.03846. Sang Michael Xie, Aditi Raghunathan, Percy Liang, Tengyu Ma. 2022. 암묵적 베이지안 추론으로서의 맥락 내 학습에 대한 설명. 국제 학습 표현 컨퍼런스에서. Wenhan Xiong, Jiawei Wu, Hong Wang, Vivek Kulkarni, Mo Yu, Shiyu Chang, Xiaoxiao Guo, William Yang Wang. 2019. Tweetqa: 소셜 미디어 중심의 질의응답 데이터 세트. arXiv 사전 인쇄본 arXiv:1907.06292. Hongxin Zhang, Yanzhe Zhang, Ruiyi Zhang, Diyi Yang. 2022a. 제한된 데이터 시나리오에서 데모 기반 학습의 견고성. arXiv 사전 인쇄본 arXiv:2210.10693. Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022b. Opt: 사전 훈련된 변환기 언어 모델 열기.arXiv 사전 인쇄본 arXiv:2205.01068. Xiang Zhang, Junbo Jake Zhao, and Yann LeCun. 2015. 텍스트 분류를 위한 문자 수준 합성곱 네트워크.Proc. NeurIPS.A 정성적 예제 표 3에서 ICL에 대한 지원 사전 훈련 데이터와 무작위 사전 훈련 데이터의 몇 가지 정성적 예를 보여줍니다. 이는 결과를 더 잘 이해하기 위해 긴 사전 훈련 인스턴스(각 인스턴스는 2048개 토큰으로 구성됨)에서 추출한 설명적 예입니다. 이러한 데이터에 대한 수동 검사는 어렵기 때문에 본 논문에 설명된 정량적 분석을 제안합니다.ICL에 대한 지원 사전 훈련 데이터 삼성의 새로운 Odyssey+ 헤드셋이 혼란스러운 VR 비전을 수정할 수 있다 세계에서 가장 기술적으로 혁신적인 회사 중 하나인 삼성은 10년 동안 가장 혁신적인 기술 중 하나인 VR 분야에서 선두를 달려야 합니다. 대신, Microsoft와 Facebook이 VR 공간에서의 역할을 결정하도록 크게 내버려 두었고, 그 결과 현재는 2류로 전락했습니다. 제가 그것이 조만간 바뀔지 내기를 걸었다면, RoadtoVR에서 발견한 회사의 새로운 Odyssey+ VR 헤드셋에 대한 FCC 유출은 &quot;아니오&quot;를 가리킬 것입니다. 대부분의 사양은 이전의 Windows 종속 Odyssey 모델과 동일하게 유지됩니다. 각 눈은 여전히 1,440 x 1, 해상도의 3.5인치 화면을 갖추고 있어 110도 시야각을 제공하며, AMOLED 기술을 사용하여 진한 검은색과 풍부한 색상을 보장합니다. 새로운 사양에는 하나의 미스터리가 있는데, 바로 AMOLED 화면에 &quot;SFS&quot;라는 것이 포함되었다는 언급입니다. 무작위 사전 훈련 데이터 방글라데시 당국과 정보 당국은 오랫동안 많은 난민들이 불법 마약 거래, 밀수, 강도 및 몸값 요구 행위에 연루되어 있다고 말해 왔습니다. 화요일 초, 엘리트 보안 기관인 Rapid Action Battalion은 다양한 범죄 활동에 연루된 것으로 의심되는 난민 9명을 체포했습니다. Islam은 그들이 총기, 총알, 날카로운 무기를 소지하고 있었다고 말했습니다. 지역 언론은 화요일의 혼란이 용의자들이 체포된 후 한 그룹이 다른 그룹이 보안 기관이 그들을 구금하는 것을 도왔다고 비난하면서 시작되었다고 보도했습니다. 캠프에 연루된 인권 단체는 로힝야 난민들 사이에 범죄적 요소가 있다는 것을 인정합니다. 표 3: SMS 스팸 감지 작업에서 ICL에 대한 지원 사전 학습 데이터의 정성적 예. 또한 비교를 위해 무작위 사전 학습 데이터의 예를 보여줍니다. 도메인 관련성에 대한 우리의 발견에서 알 수 있듯이, 두 예 모두 SMS 스팸에 대한 것이 아니므로 언어 모델은 ICL에 대한 지원 사전 학습 데이터에서 작업에 대한 직접적인 지식을 학습하지 못할 수 있습니다. 무작위 데이터와 비교했을 때, ICL에 대한 지원 데이터는 비교적 낮은 빈도의 토큰이 여러 번 나타나는 경우가 있습니다(예: VR, Odyssey, AMOLED). 언어 모델은 이를 기반으로 ICL에 대한 일부 메타 지식(예: 컨텍스트에서 동작 복사)을 학습할 수 있습니다. 그러나 이러한 패턴은 희소하고 노이즈가 많으며 수동 검사를 통해 분석하기 어렵습니다. 따라서 본 논문에서는 정량적 분석을 제시합니다.
