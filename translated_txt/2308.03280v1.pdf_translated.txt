--- ABSTRACT ---
최근 Neural Radiance Fields(NeRF)는 새로운 뷰 합성, 표면 재구성 등에서 상당한 성공을 거두었습니다. 그러나 렌더링 파이프라인에서 물리적 반사가 고려되지 않기 때문에 NeRF는 거울의 반사를 별도의 가상 장면으로 오인하여 거울의 재구성이 부정확해지고 거울에서 다중 뷰 불일치 반사가 발생합니다. 이 논문에서는 MirrorNeRF라는 새로운 신경 렌더링 프레임워크를 제시합니다. 이 프레임워크는 거울의 정확한 기하학과 반사를 학습하고 새로운 객체나 거울을 장면에 추가하고 거울에서 이러한 새로운 객체의 반사를 합성하고 거울 거칠기를 제어하는 등 거울을 사용한 다양한 장면 조작 애플리케이션을 지원할 수 있습니다. 이 목표를 달성하기 위해 반사 확률을 도입하여 통합된 광도장을 제안합니다. *Junyi Zeng과 Chong Bao는 이 연구에 동등하게 기여했습니다. 저장 대학의 저자들은 CAD&amp;CG의 국가 핵심 연구실에도 소속되어 있습니다. *교신 저자: Zhaopeng Cui. 이 작품의 일부 또는 전부를 개인적 또는 교실용으로 디지털 또는 하드 카피로 만드는 허가는 이윤 또는 상업적 이익을 위해 사본을 만들거나 배포하지 않고 사본에 이 고지 사항과 첫 페이지에 전체 인용문을 표시하는 경우 무료로 부여됩니다. 저자가 아닌 다른 사람이 소유한 이 작품의 구성 요소에 대한 저작권은 존중해야 합니다. 출처를 명시한 초록은 허용됩니다. 그렇지 않은 방식으로 복사하거나, 재출판하거나, 서버에 게시하거나, 목록에 재배포하려면 사전에 구체적인 허가 및/또는 수수료가 필요합니다. permissions@acm.org로 허가를 요청하세요. MM &#39;23, 2023년 10월 29일-11월 3일, 캐나다 온타리오주 오타와 © 2023 저작권은 소유자/저자가 소유합니다. 출판권은 ACM에 라이선스되었습니다. ACM ISBN 979-8-4007-0108-5/23/10...$15.https://doi.org/10.1145/3581783.그리고 Whitted Ray Tracing의 광 전송 모델을 따르는 광선 추적, 그리고 학습 과정을 용이하게 하는 여러 기술을 개발합니다. 합성 및 실제 데이터 세트에 대한 실험과 비교는 우리 방법의 우수성을 보여줍니다. 코드와 보충 자료는 프로젝트 웹페이지에서 제공됩니다: https://zju3dv.github.io/Mirror-NeRF/. CCS 개념 ⚫ 컴퓨팅 방법론 → 컴퓨터 비전; 렌더링. 키워드 신경 렌더링; 광선 추적; 장면 재구성; 장면 편집 ACM 참조 형식: Junyi Zeng, Chong Bao, Rui Chen, Zilong Dong, Guofeng Zhang, Hujun Bao, Zhaopeng Cui. 2023. Mirror-NeRF: Whitted-Style Ray Tracing을 사용한 거울의 신경 복사장 학습. 제31회 ACM 국제 멀티미디어 컨퍼런스(MM &#39;23) 회의록, 2023년 10월 29일~11월 3일, 캐나다 온타리오주 오타와. ACM, 뉴욕, 뉴욕, 미국, 10페이지. https://doi.org/10.1145/3581783.
--- INTRODUCTION ---
3D 장면 재구성 및 렌더링은 VR 및 AR에 광범위하게 적용되는 컴퓨터 비전 및 그래픽 분야에서 오랜 문제입니다. 수십 년 동안 상당한 진전이 이루어졌지만 현실 세계에 널리 존재하는 거울로 장면을 재구성하고 다시 렌더링하는 것은 여전히 매우 어렵습니다. MM &#39;23, 2023년 10월 29일-11월 3일, 캐나다 온타리오주 오타와 Junyi Zeng 및 Chong Bao 외. 거울의 &quot;외관&quot;은 다중 시점과 일치하지 않으며 빛이 거울에서 대칭 방향을 따라 완전히 반사되는 물리적 반사 현상으로 인해 관찰자의 관점에 따라 상당히 달라집니다. 최근 Neural Radiance Fields(NeRF) [16]는 시점에 따라 달라지는 모양 변화를 모델링하는 기능 덕분에 새로운 시점 합성 및 표면 재구성에서 상당한 성공을 거두었습니다. 그러나 물리적 반사는 렌더링 파이프라인에서 고려되지 않기 때문에 NeRF는 거울의 반사를 별도의 가상 장면으로 오인하여 그림 2에서 설명한 대로 거울의 기하학을 부정확하게 재구성합니다.거울의 렌더링된 &quot;모양&quot;도 다중 뷰 불일치로 인해 어려움을 겪습니다.여러 기술[22, 26, 50]은 표면의 반사 효과를 모델링하기 위해 객체 재료와 조명을 분해하지만 모두 특정 확산 반사가 있는 표면을 가정하여 먼저 객체 표면을 복구한 다음 반사 구성 요소를 모델링합니다.따라서 거울의 잘못된 표면 추정으로 인해 순수한 반사가 있는 거울을 처리하는 데 어려움을 겪습니다.NeRFReN[9]은 장면의 반사 및 투과 부분을 두 개의 광도 필드로 분리하여 반사를 모델링하고 거울이 있는 장면의 렌더링 품질을 개선하지만 여전히 물리적 반사 프로세스를 모델링하지 못합니다. 따라서 그림 2에 표시된 것처럼 훈련 뷰에서 관찰되지 않는 반사를 렌더링할 수 없으며 장면에 새로 배치된 객체 또는 거울의 새로운 반사를 합성할 수 없습니다. 이 논문에서는 거울이 있는 장면에서 고충실도의 새로운 뷰 합성을 달성하고 여러 장면 조작 애플리케이션을 지원하는 Mirror-NeRF라는 새로운 신경 렌더링 프레임워크를 제안합니다. 명확성을 위해 광선을 빛의 역수로 지칭합니다. 카메라에서 방출되는 광선을 카메라 광선이라고 하고 표면에서 반사되는 광선을 반사 광선이라고 합니다. 실내 환경에서 철저히 광선 추적을 수행하는 것은 엄청나게 비쌉니다. 거울에서 반사를 물리적으로 정확하게 렌더링한다는 목표로 광선이 거울과 같은 표면에서 반사되어 확산 표면에서 종료되는 Whitted Ray Tracing[37]에서 영감을 얻었습니다. 구체적으로 말해서, 먼저 광선이 공간 지점에 부딪힐 때 반사될 확률을 반사 확률로 정의합니다. 반사 확률은 다층 퍼셉트론(MLP)에 의해 공간 공간에서 연속 함수로 매개변수화됩니다. 그런 다음 카메라에서 방출된 광선을 추적합니다. 물리적 반사는 광선이 높은 반사 확률로 표면에 부딪힐 때 발생합니다. 볼륨 렌더링 기술로 광선의 밀도와 광도를 축적하고 반사 확률에 따라 카메라 광선과 반사 광선의 색상을 혼합하여 이미지를 합성합니다. 정반사를 별도의 신경 필드로 간주하는 대신 신경 필드를 통합하여 새로운 관점에서 새로운 물리적 사운드 반사를 합성하는 것이 더 합리적입니다. 그림 1에서 볼 수 있듯이, 우리의 표현은 다양한 유형의 장면 조작을 추가로 지원합니다. 예를 들어, 장면에 새 객체나 거울을 추가하고 거울에서 이러한 새 객체의 반사를 합성하고 거울의 거칠기를 제어하고 반사 대체를 수행합니다. 그러나 제안된 새로운 표현으로 기하학적 및 반사 정확한 거울을 모두 학습하는 것은 사소한 일이 아닙니다. 첫째, 표면 지점에서의 반사는 표면 법선과 관련이 있습니다. 체적 밀도 기울기의 분석적 표면 법선은 밀도가 표면에 정확하게 집중될 수 없기 때문에 상당한 노이즈가 있습니다.GT NeRF NeRFReN Ours 그림 2: 다양한 방법으로 합성된 새로운 뷰 비교.NeRF[16]는 거울에 반사된 것을 별도의 가상 장면으로 오인하여 거울의 깊이를 부정확하게 만듭니다.NeRFReN[9]은 두 개의 광도장을 사용하여 거울 안과 밖의 색상을 별도로 학습합니다.기억된 반사를 보간하여 거울에 반사된 것을 합성하고 학습 뷰에서 관찰되지 않은 반사(예: 누락된 천장)를 유추할 수 없습니다.대신 레이 트레이싱 파이프라인 덕분에 거울의 정확한 깊이로 거울에 새로운 반사를 성공적으로 합성합니다.따라서 MLP를 활용하여 표면 법선의 부드러운 분포를 매개변수화합니다.둘째, 거울 표면의 재구성은 모호하고 어렵습니다.거울의 &quot;모양&quot;은 다른 객체에서 나온 것이고 다른 관점에서 일관되지 않기 때문입니다. 실제 세계의 거울은 일반적으로 평면 표면을 갖는다는 사실에 기초하여, 우리는 평면 일관성과 앞을 향한 법선 제약 조건을 공동 최적화 방식으로 활용하여 거울 기하학의 부드러움을 보장하고 반사의 모호성을 줄입니다.또한, 거울의 기하학 최적화를 안정화하기 위해 점진적인 훈련 전략을 제안합니다.우리의 기여는 다음과 같이 요약될 수 있습니다.1) 우리는 거울이 있는 장면에서 새로운 뷰 합성의 과제를 해결하는 Mirror-NeRF라는 새로운 신경 렌더링 프레임워크를 제안합니다.거울에서 별도의 가상 세계를 학습하는 경향이 있는 NeRF[16] 및 NeRFReN[9]과 달리 Mirror-NeRF는 반사 확률을 도입하고 Whitted Ray Tracing[37]의 광 전송 모델에 따라 광선을 추적하여 통합된 광도장에서 거울의 반사를 올바르게 렌더링할 수 있습니다.물리적으로 영감을 받은 렌더링 파이프라인은 정확한 기하학과 거울의 반사로 고충실도의 새로운 뷰 합성을 용이하게 합니다. 2) 거울의 정확한 기하학과 반사를 모두 학습하기 위해, 우리는 표면 법선의 매끄러운 분포를 얻기 위한 표면 법선 매개변수화, 거울의 정확한 기하학을 보장하기 위한 조인트 최적화를 통한 평면 일관성 및 전방 법선 제약, 그리고 학습의 안정성을 유지하기 위한 점진적 학습 전략을 포함한 여러 기술을 활용합니다. 3) 제안된 Mirror-NeRF는 그림 1에 표시된 것처럼 거울을 사용하여 객체 배치, 거울 거칠기 제어, 반사 대체 등과 같은 일련의 새로운 장면 조작 애플리케이션을 가능하게 합니다. 실제 및 합성 데이터 세트에 대한 광범위한 실험은 Mirror-NeRF가 사진처럼 사실적인 새로운 뷰 합성을 달성할 수 있음을 보여줍니다. 많은 수의 장면 조작 사례는 제안된 방법의 물리적 정확성과 유연성을 보여줍니다. 1 1Mirror-NeRF: Whitted 스타일 광선 추적을 사용한 거울의 신경 광도장 학습 기하학을 위한 Rayref 샘플 색상 X를 위한 샘플 γ(-) γ(-) 000Fgeo €000f geoFmFn Fo m MM &#39;23, 2023년 10월 29일-11월 3일, 캐나다 온타리오주 오타와 d 광선 참조 깊이 법선 Ô n 혼합 색상 참조 광선 cam 둘 다를 위한 샘플 광선 샘플링 Ĉ d FC 광선 거리 볼륨 렌더링 색상 최종 신경장 색상 광선 추적 마스크 그림 3: 프레임워크. 우리는 장면에서 물리적으로 광선을 추적하고 거울로 장면의 통합 광도장을 학습합니다. 신경장은 공간 위치 x, 시야 방향 d를 입력으로 받고 볼륨 밀도 ô, 광도 ĉ, 표면 법선 ĥ 및 반사 확률 ŵ를 출력합니다. 최종 색상은 반사 확률에 따라 카메라 광선의 색상과 반사 광선의 색상으로 혼합됩니다.2.
--- RELATED WORK ---
신경 렌더링 신경 렌더링의 목표는 3D 장면에서 빛의 전달을 계산하여 사실적인 이미지나 비디오를 합성하는 것입니다. 이 분야에서 렌더링 품질의 한계를 넓히기 위해 많은 연구[15, 21, 43]가 제안되었습니다. 가장 주목할 만한 접근 방식 중 하나는 MLP를 사용하여 장면의 광도장을 모델링하는 NeRF[16]입니다. 포즈를 취한 이미지 집합에서 학습함으로써 NeRF는 각 샘플링된 지점의 광도와 밀도를 유추하는 방법을 배우고 볼륨 렌더링 기술을 사용하여 광선을 따라 이를 축적하여 색상을 렌더링합니다. 이를 통해 NeRF는 새로운 관점에서 장면의 사실적인 이미지를 생성할 수 있습니다. 영어: NeRF를 장면 재구성[1, 8, 13, 29, 30, 32, 36, 38, 39, 44, 48], 일반화[24, 33], 새로운 뷰 외삽법[35, 45], 장면 조작[2, 28, 40-42], SLAM[23, 54], 분할[20, 53], 인체[18, 31] 등과 같은 더 어려운 문제에 적용하기 위해 여러 확장 및 개선 사항이 제안되었습니다. 또한 일부 NeRF 변형은 슈퍼 샘플링[29] 및 제어 가능한 피사계 심도 렌더링[39]과 같은 다양한 응용 프로그램을 제공합니다. 그러나 이러한 NeRF 변형은 장면의 모든 빛이 Lambertain 표면에서 반사된다고 가정하기 때문에 거울 반사를 모델링하는 데 어려움을 겪습니다. 2. 반사를 사용한 신경 렌더링 많은 연구[3, 5, 6, 10, 12, 17, 49, 51, 52]에서 NeRF가 물리적 반사를 이해하도록 하는 작업을 진행해 왔습니다.PhySG[46]는 구면 가우시안의 혼합으로 환경 조명과 재료 속성을 모델링하고 표면 반구에 들어오는 빛을 통합하여 빛 전달을 단순화합니다.InvRender[50]는 다른 표면에서 반사되는 빛을 캐시하기 위해 구면 가우시안의 또 다른 혼합을 사용하여 간접 빛을 모델링하기 위해 PhySG를 확장합니다.이러한 접근 방식은 표면이 간단한 BRDF로 확산되고 환경 조명이 장면에서 멀리 떨어져 있다고 가정합니다.거울이 있는 방의 경우 장면의 복잡한 반사와 재료 다양성을 처리할 수 없습니다.NeRF의 경우 거울의 반사를 실제 기하학으로 처리하여 거울의 부정확한 깊이를 재구성합니다. RefNeRF[26]는 빛을 확산 및 반사 구성요소로 분해하고 반사된 시야 방향에 의해 조건화된 광도 필드를 사용하여 반사를 학습합니다. NeRFReN[9]은 두 개의 광도 필드를 사용하여 거울 내부와 외부의 색상을 학습하고 깊이 제약 조건을 사용하여 거울의 깊이를 복구합니다. 그러나 이러한
--- METHOD ---
. 코드와 보충 자료는 프로젝트 웹페이지에서 제공됩니다: https://zju3dv.github.io/Mirror-NeRF/. CCS 개념 ⚫ 컴퓨팅 방법론 → 컴퓨터 비전; 렌더링. 키워드 신경 렌더링; 광선 추적; 장면 재구성; 장면 편집 ACM 참조 형식: Junyi Zeng, Chong Bao, Rui Chen, Zilong Dong, Guofeng Zhang, Hujun Bao, Zhaopeng Cui. 2023. Mirror-NeRF: Whitted 스타일 광선 추적을 사용한 거울의 신경 복사장 학습. 2023년 10월 29일~11월 3일, 캐나다 온타리오주 오타와에서 열린 제31회 ACM 국제 멀티미디어 컨퍼런스(MM &#39;23) 회의록. ACM, 뉴욕, 뉴욕, 미국, 10페이지. 한국어: https://doi.org/10.1145/3581783. 서 론 3D 장면 재구성 및 렌더링은 VR 및 AR에 광범위하게 적용되는 컴퓨터 비전 및 그래픽 분야에서 오랜 문제입니다. 수십 년 동안 상당한 진전이 이루어졌지만 현실 세계에 널리 존재하는 거울로 장면을 재구성하고 다시 렌더링하는 것은 여전히 매우 어렵습니다. MM &#39;23, 2023년 10월 29일-11월 3일, 캐나다 온타리오주 오타와 Junyi Zeng 및 Chong Bao 외. 거울의 &quot;모양&quot;은 다중 보기 일관성이 없으며 거울에서 대칭 방향을 따라 빛이 완전히 반사되는 물리적 반사 현상으로 인해 관찰자의 관점에 따라 상당히 달라집니다. 최근 Neural Radiance Fields(NeRF) [16]는 보기에 따라 달라지는 모양 변화를 모델링하는 기능 덕분에 새로운 보기 합성 및 표면 재구성에서 상당한 성공을 거두었습니다. 그러나 물리적 반사는 렌더링 파이프라인에서 고려되지 않기 때문에 NeRF는 거울의 반사를 별도의 가상 장면으로 오인하여 그림 2에서 설명한 대로 거울의 기하학을 부정확하게 재구성합니다.거울의 렌더링된 &quot;모양&quot;도 다중 뷰 불일치로 인해 어려움을 겪습니다.여러 기술[22, 26, 50]은 표면의 반사 효과를 모델링하기 위해 객체 재료와 조명을 분해하지만 모두 특정 확산 반사가 있는 표면을 가정하여 먼저 객체 표면을 복구한 다음 반사 구성 요소를 모델링합니다.따라서 거울의 잘못된 표면 추정으로 인해 순수한 반사가 있는 거울을 처리하는 데 어려움을 겪습니다.NeRFReN[9]은 장면의 반사 및 투과 부분을 두 개의 광도 필드로 분리하여 반사를 모델링하고 거울이 있는 장면의 렌더링 품질을 개선하지만 여전히 물리적 반사 프로세스를 모델링하지 못합니다. 따라서 그림 2에 표시된 것처럼 훈련 뷰에서 관찰되지 않는 반사를 렌더링할 수 없으며 장면에 새로 배치된 객체 또는 거울의 새로운 반사를 합성할 수 없습니다. 이 논문에서는 거울이 있는 장면에서 고충실도의 새로운 뷰 합성을 달성하고 여러 장면 조작 애플리케이션을 지원하는 Mirror-NeRF라는 새로운 신경 렌더링 프레임워크를 제안합니다. 명확성을 위해 광선을 빛의 역수로 지칭합니다. 카메라에서 방출되는 광선을 카메라 광선이라고 하고 표면에서 반사되는 광선을 반사 광선이라고 합니다. 실내 환경에서 철저히 광선 추적을 수행하는 것은 엄청나게 비쌉니다. 거울에서 반사를 물리적으로 정확하게 렌더링한다는 목표로 광선이 거울과 같은 표면에서 반사되어 확산 표면에서 종료되는 Whitted Ray Tracing[37]에서 영감을 얻었습니다. 구체적으로 말해서, 먼저 광선이 공간 지점에 부딪힐 때 반사될 확률을 반사 확률로 정의합니다. 반사 확률은 다층 퍼셉트론(MLP)에 의해 공간 공간에서 연속 함수로 매개변수화됩니다. 그런 다음 카메라에서 방출된 광선을 추적합니다. 물리적 반사는 광선이 높은 반사 확률로 표면에 부딪힐 때 발생합니다. 볼륨 렌더링 기술로 광선의 밀도와 광도를 축적하고 반사 확률에 따라 카메라 광선과 반사 광선의 색상을 혼합하여 이미지를 합성합니다. 정반사를 별도의 신경 필드로 간주하는 대신 신경 필드를 통합하여 새로운 관점에서 새로운 물리적 사운드 반사를 합성하는 것이 더 합리적입니다. 그림 1에서 볼 수 있듯이, 우리의 표현은 다양한 유형의 장면 조작을 추가로 지원합니다. 예를 들어, 장면에 새 객체나 거울을 추가하고 거울에서 이러한 새 객체의 반사를 합성하고 거울의 거칠기를 제어하고 반사 대체를 수행합니다. 그러나 제안된 새로운 표현으로 기하학적 및 반사 정확한 거울을 모두 학습하는 것은 사소한 일이 아닙니다. 첫째, 표면 지점에서의 반사는 표면 법선과 관련이 있습니다. 체적 밀도 기울기의 분석적 표면 법선은 밀도가 표면에 정확하게 집중될 수 없기 때문에 상당한 노이즈가 있습니다.GT NeRF NeRFReN Ours 그림 2: 다양한 방법으로 합성된 새로운 뷰 비교.NeRF[16]는 거울에 반사된 것을 별도의 가상 장면으로 오인하여 거울의 깊이를 부정확하게 만듭니다.NeRFReN[9]은 두 개의 광도장을 사용하여 거울 안과 밖의 색상을 별도로 학습합니다.기억된 반사를 보간하여 거울에 반사된 것을 합성하고 학습 뷰에서 관찰되지 않은 반사(예: 누락된 천장)를 유추할 수 없습니다.대신 레이 트레이싱 파이프라인 덕분에 거울의 정확한 깊이로 거울에 새로운 반사를 성공적으로 합성합니다.따라서 MLP를 활용하여 표면 법선의 부드러운 분포를 매개변수화합니다.둘째, 거울 표면의 재구성은 모호하고 어렵습니다.거울의 &quot;모양&quot;은 다른 객체에서 나온 것이고 다른 관점에서 일관되지 않기 때문입니다. 실제 세계의 거울은 일반적으로 평면 표면을 갖는다는 사실에 기초하여, 우리는 평면 일관성과 앞을 향한 법선 제약 조건을 공동 최적화 방식으로 활용하여 거울 기하학의 부드러움을 보장하고 반사의 모호성을 줄입니다.또한, 거울의 기하학 최적화를 안정화하기 위해 점진적인 훈련 전략을 제안합니다.우리의 기여는 다음과 같이 요약될 수 있습니다.1) 우리는 거울이 있는 장면에서 새로운 뷰 합성의 과제를 해결하는 Mirror-NeRF라는 새로운 신경 렌더링 프레임워크를 제안합니다.거울에서 별도의 가상 세계를 학습하는 경향이 있는 NeRF[16] 및 NeRFReN[9]과 달리 Mirror-NeRF는 반사 확률을 도입하고 Whitted Ray Tracing[37]의 광 전송 모델에 따라 광선을 추적하여 통합된 광도장에서 거울의 반사를 올바르게 렌더링할 수 있습니다.물리적으로 영감을 받은 렌더링 파이프라인은 정확한 기하학과 거울의 반사로 고충실도의 새로운 뷰 합성을 용이하게 합니다. 2) 거울의 정확한 기하학과 반사를 모두 학습하기 위해 우리는 표면 법선 매개변수화를 포함하여 표면 법선의 매끄러운 분포를 획득하고, 평면 일관성과 조인트 최적화를 통한 전방 법선 제약 조건을 통해 거울의 정확한 기하학을 보장하고, 점진적인 학습 전략을 통해 학습의 안정성을 유지하는 여러 가지 기술을 활용합니다. 3) 제안된 Mirror-NeRF는 그림 1에 표시된 것처럼 거울을 사용하여 객체 배치, 거울 거칠기 제어, 반사 대체 등과 같은 일련의 새로운 장면 조작 애플리케이션을 가능하게 합니다. 광범위한
--- EXPERIMENT ---
s 및 합성 및 실제 데이터 세트에 대한 비교는 우리 방법의 우수성을 입증합니다. 코드와 보충 자료는 프로젝트 웹페이지에서 제공됩니다: https://zju3dv.github.io/Mirror-NeRF/. CCS 개념 ⚫ 컴퓨팅 방법론 → 컴퓨터 비전; 렌더링. 키워드 신경 렌더링; 광선 추적; 장면 재구성; 장면 편집 ACM 참조 형식: Junyi Zeng, Chong Bao, Rui Chen, Zilong Dong, Guofeng Zhang, Hujun Bao 및 Zhaopeng Cui. 2023. Mirror-NeRF: Whitted 스타일 광선 추적을 사용한 거울에 대한 신경 복사장 학습. 2023년 10월 29일~11월 3일, 캐나다 온타리오주 오타와에서 열린 제31회 ACM 국제 멀티미디어 컨퍼런스(MM &#39;23) 회의록. ACM, 뉴욕, 뉴욕, 미국, 10페이지. 한국어: https://doi.org/10.1145/3581783. 서 론 3D 장면 재구성 및 렌더링은 VR 및 AR에 광범위하게 적용되는 컴퓨터 비전 및 그래픽 분야에서 오랜 문제입니다. 수십 년 동안 상당한 진전이 이루어졌지만 현실 세계에 널리 존재하는 거울로 장면을 재구성하고 다시 렌더링하는 것은 여전히 매우 어렵습니다. MM &#39;23, 2023년 10월 29일-11월 3일, 캐나다 온타리오주 오타와 Junyi Zeng 및 Chong Bao 외. 거울의 &quot;모양&quot;은 다중 보기 일관성이 없으며 거울에서 대칭 방향을 따라 빛이 완전히 반사되는 물리적 반사 현상으로 인해 관찰자의 관점에 따라 상당히 달라집니다. 최근 Neural Radiance Fields(NeRF) [16]는 보기에 따라 달라지는 모양 변화를 모델링하는 기능 덕분에 새로운 보기 합성 및 표면 재구성에서 상당한 성공을 거두었습니다. 그러나 물리적 반사는 렌더링 파이프라인에서 고려되지 않기 때문에 NeRF는 거울의 반사를 별도의 가상 장면으로 오인하여 그림 2에서 설명한 대로 거울의 기하학을 부정확하게 재구성합니다.거울의 렌더링된 &quot;모양&quot;도 다중 뷰 불일치로 인해 어려움을 겪습니다.여러 기술[22, 26, 50]은 표면의 반사 효과를 모델링하기 위해 객체 재료와 조명을 분해하지만 모두 특정 확산 반사가 있는 표면을 가정하여 먼저 객체 표면을 복구한 다음 반사 구성 요소를 모델링합니다.따라서 거울의 잘못된 표면 추정으로 인해 순수한 반사가 있는 거울을 처리하는 데 어려움을 겪습니다.NeRFReN[9]은 장면의 반사 및 투과 부분을 두 개의 광도 필드로 분리하여 반사를 모델링하고 거울이 있는 장면의 렌더링 품질을 개선하지만 여전히 물리적 반사 프로세스를 모델링하지 못합니다. 따라서 그림 2에 표시된 것처럼 훈련 뷰에서 관찰되지 않는 반사를 렌더링할 수 없으며 장면에 새로 배치된 객체 또는 거울의 새로운 반사를 합성할 수 없습니다. 이 논문에서는 거울이 있는 장면에서 고충실도의 새로운 뷰 합성을 달성하고 여러 장면 조작 애플리케이션을 지원하는 Mirror-NeRF라는 새로운 신경 렌더링 프레임워크를 제안합니다. 명확성을 위해 광선을 빛의 역수로 지칭합니다. 카메라에서 방출되는 광선을 카메라 광선이라고 하고 표면에서 반사되는 광선을 반사 광선이라고 합니다. 실내 환경에서 철저히 광선 추적을 수행하는 것은 엄청나게 비쌉니다. 거울에서 반사를 물리적으로 정확하게 렌더링한다는 목표로 광선이 거울과 같은 표면에서 반사되어 확산 표면에서 종료되는 Whitted Ray Tracing[37]에서 영감을 얻었습니다. 구체적으로 말해서, 먼저 광선이 공간 지점에 부딪힐 때 반사될 확률을 반사 확률로 정의합니다. 반사 확률은 다층 퍼셉트론(MLP)에 의해 공간 공간에서 연속 함수로 매개변수화됩니다. 그런 다음 카메라에서 방출된 광선을 추적합니다. 물리적 반사는 광선이 높은 반사 확률로 표면에 부딪힐 때 발생합니다. 볼륨 렌더링 기술로 광선의 밀도와 광도를 축적하고 반사 확률에 따라 카메라 광선과 반사 광선의 색상을 혼합하여 이미지를 합성합니다. 정반사를 별도의 신경 필드로 간주하는 대신 신경 필드를 통합하여 새로운 관점에서 새로운 물리적 사운드 반사를 합성하는 것이 더 합리적입니다. 그림 1에서 볼 수 있듯이, 우리의 표현은 다양한 유형의 장면 조작을 추가로 지원합니다. 예를 들어, 장면에 새 객체나 거울을 추가하고 거울에서 이러한 새 객체의 반사를 합성하고 거울의 거칠기를 제어하고 반사 대체를 수행합니다. 그러나 제안된 새로운 표현으로 기하학적 및 반사 정확한 거울을 모두 학습하는 것은 사소한 일이 아닙니다. 첫째, 표면 지점에서의 반사는 표면 법선과 관련이 있습니다. 체적 밀도 기울기의 분석적 표면 법선은 밀도가 표면에 정확하게 집중될 수 없기 때문에 상당한 노이즈가 있습니다.GT NeRF NeRFReN Ours 그림 2: 다양한 방법으로 합성된 새로운 뷰 비교.NeRF[16]는 거울에 반사된 것을 별도의 가상 장면으로 오인하여 거울의 깊이를 부정확하게 만듭니다.NeRFReN[9]은 두 개의 광도장을 사용하여 거울 안과 밖의 색상을 별도로 학습합니다.기억된 반사를 보간하여 거울에 반사된 것을 합성하고 학습 뷰에서 관찰되지 않은 반사(예: 누락된 천장)를 유추할 수 없습니다.대신 레이 트레이싱 파이프라인 덕분에 거울의 정확한 깊이로 거울에 새로운 반사를 성공적으로 합성합니다.따라서 MLP를 활용하여 표면 법선의 부드러운 분포를 매개변수화합니다.둘째, 거울 표면의 재구성은 모호하고 어렵습니다.거울의 &quot;모양&quot;은 다른 객체에서 나온 것이고 다른 관점에서 일관되지 않기 때문입니다. 실제 세계의 거울은 일반적으로 평면 표면을 갖는다는 사실에 기초하여, 우리는 평면 일관성과 앞을 향한 법선 제약 조건을 공동 최적화 방식으로 활용하여 거울 기하학의 부드러움을 보장하고 반사의 모호성을 줄입니다.또한, 거울의 기하학 최적화를 안정화하기 위해 점진적인 훈련 전략을 제안합니다.우리의 기여는 다음과 같이 요약될 수 있습니다.1) 우리는 거울이 있는 장면에서 새로운 뷰 합성의 과제를 해결하는 Mirror-NeRF라는 새로운 신경 렌더링 프레임워크를 제안합니다.거울에서 별도의 가상 세계를 학습하는 경향이 있는 NeRF[16] 및 NeRFReN[9]과 달리 Mirror-NeRF는 반사 확률을 도입하고 Whitted Ray Tracing[37]의 광 전송 모델에 따라 광선을 추적하여 통합된 광도장에서 거울의 반사를 올바르게 렌더링할 수 있습니다.물리적으로 영감을 받은 렌더링 파이프라인은 정확한 기하학과 거울의 반사로 고충실도의 새로운 뷰 합성을 용이하게 합니다. 2) 거울의 정확한 기하학과 반사를 모두 학습하기 위해, 우리는 표면 법선의 매끄러운 분포를 얻기 위한 표면 법선 매개변수화, 거울의 정확한 기하학을 보장하기 위한 조인트 최적화를 통한 평면 일관성 및 전방 법선 제약, 그리고 학습의 안정성을 유지하기 위한 점진적 학습 전략을 포함한 여러 기술을 활용합니다. 3) 제안된 Mirror-NeRF는 그림 1에 표시된 것처럼 거울을 사용하여 객체 배치, 거울 거칠기 제어, 반사 대체 등과 같은 일련의 새로운 장면 조작 애플리케이션을 가능하게 합니다. 실제 및 합성 데이터 세트에 대한 광범위한 실험은 Mirror-NeRF가 사진처럼 사실적인 새로운 뷰 합성을 달성할 수 있음을 보여줍니다. 많은 수의 장면 조작 사례는 제안된 방법의 물리적 정확성과 유연성을 보여줍니다. 1 1Mirror-NeRF: Whitted 스타일 광선 추적을 사용한 거울의 신경 광도장 학습 기하학을 위한 Rayref 샘플 색상 X를 위한 샘플 γ(-) γ(-) 000Fgeo €000f geoFmFn Fo m MM &#39;23, 2023년 10월 29일-11월 3일, 캐나다 온타리오주 오타와 d 광선 참조 깊이 법선 Ô n 혼합 색상 참조 광선 cam 둘 다를 위한 샘플 광선 샘플링 Ĉ d FC 광선 거리 볼륨 렌더링 색상 최종 신경장 색상 광선 추적 마스크 그림 3: 프레임워크. 우리는 장면에서 물리적으로 광선을 추적하고 거울로 장면의 통합 광도장을 학습합니다. 신경장은 공간 위치 x, 시야 방향 d를 입력으로 받고 볼륨 밀도 ô, 광도 ĉ, 표면 법선 ĥ 및 반사 확률 ŵ를 출력합니다. 최종 색상은 반사 확률을 기반으로 카메라 광선의 색상과 반사 광선으로 혼합됩니다.2. 관련 연구 신경 렌더링 신경 렌더링의 목표는 3D 장면에서 빛의 전달을 계산하여 사실적인 이미지나 비디오를 합성하는 것입니다. 이 분야에서 렌더링 품질의 한계를 넓히기 위해 많은 연구[15, 21, 43]가 제안되었습니다. 가장 주목할 만한 접근 방식 중 하나는 MLP를 사용하여 장면의 광도장을 모델링하는 NeRF[16]입니다. 포즈를 취한 이미지 세트에서 학습함으로써 NeRF는 각 샘플링된 지점의 광도와 밀도를 유추하는 방법을 학습하고 볼륨 렌더링 기술을 사용하여 광선을 따라 이를 축적하여 색상을 렌더링합니다. 이를 통해 NeRF는 새로운 관점에서 장면의 사실적인 이미지를 생성할 수 있습니다. 영어: NeRF를 장면 재구성[1, 8, 13, 29, 30, 32, 36, 38, 39, 44, 48], 일반화[24, 33], 새로운 뷰 외삽법[35, 45], 장면 조작[2, 28, 40-42], SLAM[23, 54], 분할[20, 53], 인체[18, 31] 등과 같은 더 어려운 문제에 적용하기 위해 여러 확장 및 개선 사항이 제안되었습니다. 또한 일부 NeRF 변형은 슈퍼 샘플링[29] 및 제어 가능한 피사계 심도 렌더링[39]과 같은 다양한 응용 프로그램을 제공합니다. 그러나 이러한 NeRF 변형은 장면의 모든 빛이 Lambertain 표면에서 반사된다고 가정하기 때문에 거울 반사를 모델링하는 데 어려움을 겪습니다. 2. 반사를 사용한 신경 렌더링 많은 연구[3, 5, 6, 10, 12, 17, 49, 51, 52]에서 NeRF가 물리적 반사를 이해하도록 하는 작업을 진행해 왔습니다.PhySG[46]는 구면 가우시안의 혼합으로 환경 조명과 재료 속성을 모델링하고 표면 반구에 들어오는 빛을 통합하여 빛 전달을 단순화합니다.InvRender[50]는 다른 표면에서 반사되는 빛을 캐시하기 위해 구면 가우시안의 또 다른 혼합을 사용하여 간접 빛을 모델링하기 위해 PhySG를 확장합니다.이러한 접근 방식은 표면이 간단한 BRDF로 확산되고 환경 조명이 장면에서 멀리 떨어져 있다고 가정합니다.거울이 있는 방의 경우 장면의 복잡한 반사와 재료 다양성을 처리할 수 없습니다.NeRF의 경우 거울의 반사를 실제 기하학으로 처리하여 거울의 부정확한 깊이를 재구성합니다. RefNeRF[26]는 빛을 확산 및 반사 구성 요소로 분해하고 반사된 뷰 방향에 의해 조건지어진 광도 필드를 사용하여 반사를 학습합니다.NeRFReN[9]은 두 개의 광도 필드를 사용하여 거울 안팎의 색상을 학습하고 깊이 제약 조건을 사용하여 거울의 깊이를 복구합니다.그러나 이러한 방법은 이전에 학습한 반사를 보간하여 새로운 관점에서 거울 반사를 생성하고 훈련 중에 관찰되지 않은 반사를 정확하게 추론하고 장면에 새로 추가된 객체나 거울에 대한 반사를 합성하는 데 제한이 있습니다.신경 렌더링 파이프라인에 물리적 광선 추적을 도입함으로써, 우리 방법은 거울의 반사를 올바르게 렌더링하고 여러 장면 조작 애플리케이션을 지원할 수 있습니다.MIRROR-NERF 우리는 거울이 있는 장면의 사실적인 새로운 뷰 합성을 지원하고 거울의 정확한 기하학과 반사를 재구성하는 물리적으로 영감을 받은 신경 렌더링 프레임워크인 Mirror-NeRF를 소개합니다. 그림 3에 도시된 바와 같이, 우리는 통합 신경장을 활용하여 거울 안팎의 체적 밀도, 법선, 반사 확률 및 광도를 학습합니다(3.1절). 거울에서 물리적으로 정확한 반사를 생성하려는 의도로, 우리는 Whitted Ray Tracing[37]의 빛 전달 모델을 사용하고 장면에서 체적 렌더링된 광선을 추적합니다(3.2절). 그 밖에, 거울 표면에 대한 몇 가지 정규화 제약 조건(3.3절)과 점진적 학습 전략(3.4절)을 제안하여 거울의 재구성 품질을 개선하고 학습을 안정화합니다. 3. 통합 신경장 우리는 거울 안팎의 부분에 대해 통합된 장면의 속성을 학습하기 위해 여러 신경장을 설계합니다(그림 3). 3.1.1 기하학 및 색상. NeRF[16]의 암묵적 표현에 따라, 우리는 임의의 공간 위치 x에서 기하학 특징 fgeo를 인코딩하기 위해 기하학 MLP Fgeo를 사용합니다. 체적 밀도장은 fgeo를 입력으로 취하는 체적 밀도 MLP F에 의해 표현되고, 광도장은 fgeo와 시점 방향 d를 입력으로 취하는 광도 MLP Fc에 의해 표현됩니다. fgeo = Fgeo (Yx(x)), σ = Fo(fgeo), c = Fc (fgeo, Yd(d)), (1) 여기서 yx()와 yd (·)는 각각 공간 위치와 시점 방향의 위치 인코딩 함수입니다. σ와 c는 각각 체적 MM &#39;23, 2023년 10월 29일-11월 3일, 캐나다 온타리오주 오타와 Junyi Zeng과 Chong Bao, et al. 밀도와 광도입니다. 특정 시점에서 이미지를 렌더링하기 위해 NeRF의 체적 렌더링 기술을 따릅니다. 광선 r의 체적 렌더링 색상 Ĉ는 체적 밀도 σ;와 광도 c;를 누적하여 계산됩니다. 광선을 따라 샘플링된 지점 xi의 수: N Ĉ(r) = Σ Tiαici, i-T₁ = exp -Σojdj α =j=exp(-σidi), (2) 여기서 N은 광선 r의 샘플링된 지점 수이고, §;는 광선을 따라 인접한 지점 사이의 샘플링 거리입니다.3.1.2 매끄러운 표면 법선.이전 연구[4, 22]는 NeRF에서 표면 법선의 획득을 분석하여 x에 대한 체적 밀도의 음의 기울기가 실제 법선의 미분 가능한 근사치를 제공할 수 있음을 보여주었습니다.n = Vo(x) ||Vo(x)|| (3) 그러나 이러한 매개변수화는 체적 밀도가 표면에 정확하게 집중될 수 없기 때문에 매끄럽지 않은 표면 법선 분포를 생성하는 경향이 있습니다.표면 법선의 노이즈는 거울에서 반사된 광선의 올바른 방향을 추적하는 것을 심각하게 방해합니다. 표면 법선의 매끄러운 분포를 얻기 위해 fgeo를 입력으로 받고 매끄러운 표면 법선 n을 예측하는 MLP FÈ를 활용합니다: n = Fn(fgeo). (4) 분석적 표면 법선 n으로 F의 최적화를 감독합니다: Ln = ||ĥ – n||². (5) 광선 r과 표면의 교차점에서 표면 법선을 계산하기 위해 다음과 같이 Eq. (2)를 따릅니다: N Ñ(r) Σ Tiαini. i=(6) 3.1.3 반사 확률. 반사를 모델링하고 3.2절에서 설명한 Whitted 스타일 광선 추적을 수행하기 위해 MLP Fm을 사용하여 광선이 공간 지점에서 반사될 확률 m을 예측합니다: m = Fm (fgeo), (7) 여기서 m은 [0, 1]의 범위입니다. 광선 r이 고체 표면에 부딪히는 반사 확률 Ṁ를 결정하기 위해 다음과 같은 볼륨 렌더링을 수행합니다. (2): NM(r) = ΣTaimi. i=3.2 Whitted 스타일 광선 추적 (8) NERF [16]는 렌더링 파이프라인의 물리적 반사를 고려하지 않습니다. 거울이 있는 장면에 적용될 때 NERF는 거울의 기하학을 재구성할 수 없으며 거울의 반사를 별도의 가상 장면으로 처리합니다. 거울에서의 반사를 처리하기 위해 Whitted Ray Mirror Ray cam N Rayref에서 영감을 얻었습니다. (b) 참조 광선에 대한 전방 샘플링 전략 없이 광선 샘플링 모델을 사용한 결과 (c) (a) 우리의 광선 샘플링 모델 그림 4: 광선의 점을 샘플링하기 위한 우리의 전략은 (a)에 나와 있습니다. 우리는 카메라 광선과 반사 광선 모두에서 점을 샘플링합니다. 반사 광선의 경우 &quot;안개 낀&quot; 기하학으로 인해 반사 광선이 원점 근처에서 예기치 않게 끝나는 것을 방지하기 위해 원점에서 일정 거리를 전방으로 이동하여 샘플링 지점을 시작합니다. 이 디자인의 효과는 전방 샘플링 전략 없이 거울 반사가 손상되는 (b)와 (c)를 비교하여 입증됩니다. (b)와 (c)의 오른쪽 아래 이미지는 거울의 반사 깊이를 보여줍니다. 추적 [37] 여기서 광선은 거울과 같은 표면에서 반사되어 확산 표면에서 끝납니다. 그림 4에서 보듯이 광선이 반사되면 먼저 광선 r과 표면의 교차점의 위치 ✰을 다음과 같이 계산합니다. Â(r) = o(r) + Ô(r)d(r), ND(r) = Tiαiti, i=(9) 여기서 Ô, o 및 d는 각각 광선 r의 예상 종료 깊이, 원점 및 방향입니다. T; 및 α;는 Eq. (2)와 동일합니다. 광선 r의 반사 광선 rref를 추적하기 위해 Ŷ(r)을 원점으로 설정하고 방향을 다음과 같이 계산합니다. d(rref) = d(r) − 2 (Ñ(r) · d(r)) Ñ(r). (10) 여기서 모든 방향 벡터는 정규화됩니다. 그런 다음 볼륨 렌더링 기법을 사용하여 광선 r과 반사 광선 rref의 색상을 계산합니다. r과 rref의 샘플링된 지점의 광도는 동일한 신경 광도 필드를 쿼리하여 얻습니다. 밀도 기반 표현은 항상 &quot;안개 낀&quot; 기하학을 유도하므로 반사 광선은 그림 4(c)에 표시된 것처럼 원점 근처에서 예기치 않게 끝날 수 있습니다. 이 문제를 해결하기 위해 그림 4(a)에 표시된 것처럼 원점에서 떨어진 거리에서 반사 광선의 지점을 샘플링하기 시작합니다. 광선 M(r)의 볼륨 렌더링 반사 확률에 따라 광선 r과 반사 광선 rref의 색상을 다음과 같이 혼합합니다. Ĉ³ (r) = Ĉ(r) (1 − M(r)) + Ĉ³ (Fref)M(r). (11) CP가 재귀적으로 정의되고 M이 0이거나 지정된 최대 재귀 깊이에 도달하면 재귀가 종료됩니다. 각 픽셀에 대해 카메라에서 광선을 생성하여 장면에서 추적합니다. 이러한 카메라 광선 집합을 Ream으로 표시합니다. Mirror-NeRF: Whitted 스타일 광선 추적을 사용한 거울의 신경 복사장 학습 픽셀 색상은 r = Ream인 Eq. (11)에 의해 렌더링됩니다. 렌더링된 픽셀 색상을 광도 손실이 있는 기준 진실 픽셀 색상 C¹로 감독합니다. Lc = Σ ||C³ (r) - C¹ (r)||}. rЄRcam (12) 반사 확률 M의 최적화를 안내하기 위해 렌더링된 반사 확률 M과 거울 반사 마스크 M 사이의 이진 교차 엔트로피 손실을 계산합니다. Lm = Σ - (M(r) log M(r) + (1 - M(r)) log (1 – M(r))), rЄRcam (13) 여기서 M은 기준 진실 이미지에서 [11]과 같은 기성품 분할 도구를 사용하여 얻습니다. 3.3 정규화 우리는 거울을 위한 휘티드 레이 트레이싱을 기반으로 하는 새로운 렌더링 파이프라인을 설계하는 반면, 정규화 없이 단순하게 학습하면 거울의 &quot;모양&quot;이 흐릿해지는 거울에서의 불안정한 수렴으로 항상 이어진다. 우리는 거울의 울퉁불퉁한 표면이 거울의 밀도가 제약이 부족하여 반사 품질에 큰 영향을 미친다는 것을 발견했다. 따라서 우리는 최적화 프로세스에 여러 정규화 항을 도입한다. 3.3. 평면 일관성 제약. 우리가 관찰한 바에 따르면, 거울은 일반적으로 현실 세계에서 평면 표면을 갖는다. 이 속성을 최대한 활용하기 위해 [7]에서 제안한 평면 일관성 제약을 거울 표면에 적용한다. 구체적으로, 우리는 거울 표면에서 네 개의 점 A, B, C, D를 무작위로 샘플링하고 평면 ABC의 법선 벡터가 벡터 AD에 수직이 되도록 적용한다:Lpc = i=|AiBi × AiCi · AiDi], (14) 여기서 Np는 평면에서 무작위로 선택된 4개 점 세트의 수를 나타낸다. 3.3.2 앞을 향한 법선 제약. 반사 방정식 Eq. (10)과 관련하여 표면 법선이 180도 회전하여 표면 내부를 가리킬 때에도 여전히 유지됨을 알 수 있습니다. 이러한 모호성으로 인해 거울의 깊이가 잘못됩니다. 이 문제를 해결하기 위해 [26]에 따라 샘플링된 지점의 분석적 표면 법선 n이 카메라 광선 r의 방향 d와 둔각을 이루도록 강제합니다. 즉, 표면 법선은 카메라에 대해 앞을 향해야 합니다. Lnreg = max(0, ñ d(r))². (15) 3.3.3 공동 최적화. 실제로는 앞서 언급한 손실을 사용하여 모든 네트워크를 공동 최적화합니다. 즉, 각 손실은 결국 체적 밀도 필드와 광도 필드에 영향을 미칩니다. L = λcLc+λmLm+λpc£pc +AnLn+AnregLnreg&#39; (16) 여기서 는 각 손실 항의 계수입니다. 공동 최적화는 세 가지 주요 이점을 제공합니다. 첫째, 표면 법선 손실 Ln은 F에 영향을 미칠 뿐만 아니라 Fgeo가 MM &#39;23, 2023년 10월 29일-11월 3일, 캐나다 온타리오주 오타와에서 매끄러운 특징 분포를 생성하도록 장려하여 표면의 평탄성을 강화하기 위해 표면에 균일하게 볼륨 밀도가 집중되도록 합니다.둘째, 반사 확률 손실 Lm은 볼륨 밀도 필드가 거울에서 피크에 도달하도록 촉진하여 거울에 대한 편향되지 않은 깊이를 생성합니다.두 손실 모두 fgeo를 통해 Fgeo를 조절합니다.셋째, 평면 및 법선 제약 조건을 사용함에도 불구하고 표면 법선의 작은 오류는 반사 중에 증폭됩니다.공동 최적화를 통해 이러한 오류는 광도 손실 Lc가 미분 가능한 반사 방정식을 통해 표면 법선 Ñ을 원하는 방향으로 암묵적으로 조정하기 때문에 반복적으로 개선됩니다.3.4 점진적 훈련 전략 훈련의 초기 단계에서는 신경장이 불안정하고 쉽게 국소 최적값에 빠집니다. 우리는 퇴화 상황을 두 가지 경우로 결론지었습니다. 1) 거울에 비친 반사는 NeRF와 마찬가지로 색상이 기하학보다 빠르게 수렴하는 경우 부정확한 깊이를 가진 별도의 장면으로 학습될 수 있습니다. 2) 색상은 처음에 강력한 기하학적 정규화가 활성화된 경우 국소 최적에 갇혀 흐릿해질 수 있습니다. 학습을 안정적으로 만들기 위해 거울 안팎의 이미지 영역을 점진적으로 학습하고 학습의 다른 단계에서 손실 계수를 예약합니다. 초기 단계에서는 λc를 활성화하고 나머지 계수를 비활성화하여 신경계의 안정성을 유지하고 거울의 기하학이 망가지는 것을 방지합니다. 또한 Lc를 마스크된 광도 손실 Lcm로 대체합니다. Σ ||³ (r)-C(r)||+ Σ ||C³°³ (r)-K||2, Lcm = rЄRcam RM rЄRcam RM (17) 여기서 RM은 거울과 같은 표면에 부딪히는 광선 집합이고 RM은 RM의 보완 집합입니다. K는 상수 벡터로, 실험에서 (0, 0, 0)을 사용합니다.거울 내부의 이미지 영역에 K를 사용하는 것은 반사를 학습하지 않고 거울의 초기 대략적인 모양을 학습하기 위한 것이며, 이는 4.3.2절에서 설명합니다.Lem은 마지막 단계까지 사용됩니다.몇 번의 에포크 후에 Am, Apc, An, Anreg를 활성화하여 거울의 위치와 기하학을 정규화합니다.이 단계 후에 신경 필드가 거울의 정확한 깊이를 학습한 것으로 예상됩니다.마지막으로 Lem 대신 Le를 사용하여 반사 부분을 공동으로 최적화하고 거울의 기하학을 세부적으로 조정합니다.4.실험 데이터 세트 저희가 아는 한, 새로운 뷰 합성 작업에 공개적으로 사용할 수 있는 거울이 포함된 방 수준 데이터 세트는 없습니다.따라서 합성 데이터 세트 5개를 만들고 거울이 있는 실제 데이터 세트 4개를 캡처합니다.각 합성 데이터 세트는 BlendSwap [14]에서 다운로드한 거실, 회의실, 화장실, 침실, 사무실을 포함한 실내 방입니다. 실제 데이터 세트는 의류 매장, 라운지, 시장 및 토론실을 포함하여 iPad Pro를 사용하여 실제 실내 장면에서 캡처됩니다. 각 데이터 세트에서 이미지는 장면 주변에서 각도별로 캡처됩니다. 이미지를 훈련 및 테스트 세트로 분할하여 정량적 및 정성적 비교를 수행합니다. 기성품 분할 도구[11]를 사용하여 이미지의 거울 반사 마스크를 분할합니다. MM &#39;23, 2023년 10월 29일-11월 3일, 캐나다 온타리오주 오타와 GT 거실 회의실 세면실 침실 사무실 의류 매장 라운지 시장 토론실 ☑ NeRF 색상 심도 참조-NeRF 색상 심도 색상 거울 마스크 NeRFReN 깊이 참조 깊이 Junyi Zeng 및 Chong Bao 외. 우리의 색상 심도 거울 마스크 참조 깊이 그림 5: 거울이 있는 합성 장면과 실제 장면에서 새로운 뷰 합성의 정성적 비교. 4.2 비교 우리는 우리 방법을 NeRF [16] 및 반사를 처리하는 최첨단 신경 렌더링 방법, 즉 RefNERF [26] 및 NeRFReN [9]과 비교합니다. 우리 방법과 NeRFReN에 동일한 미러 마스크가 제공됩니다. 우리는 PSNR, SSIM [34] 및 LPIPS [47] 메트릭에 대한 새로운 뷰 합성의 정량적 비교를 수행합니다. 표 1에서 볼 수 있듯이 일반 테스트 관점에서 우리 방법은 합성 및 실제 데이터 세트에서 반사를 처리하는 SOTA 방법(즉, Ref-NeRF 및 NeRFReN)보다 성능이 뛰어나며 NeRF와 비슷합니다. NeRF는 새로운 뷰 합성을 수행할 때 거울의 물리적으로 건전한 기하학을 재구성하지 않고 기억된 반사만 보간하는 반면, 우리 방법은 거울의 올바른 깊이를 복구하고 물리적 광선 추적 파이프라인으로 인해 훈련 뷰와 여러 응용 프로그램에서 관찰되지 않는 반사를 합성할 수 있습니다. 위의 테스트 관점은 훈련 관점의 분포에 가깝기 때문에 NeRF는 근처 관점의 반사를 보간하여 시각적으로 합리적인 반사를 생성할 수 있습니다. 반사 모델링의 정확성을 비교하기 위해 훈련 관점에서 관찰되지 않은 반사가 더 많은 더 어려운 테스트 이미지 세트를 캡처합니다. 표 2에 표시된 대로 거울에서의 반사를 정량적으로 비교합니다. 장면에서 반사된 광선을 추적하여 반사를 충실하게 합성할 수 있기 때문에 우리의 방법은 비교된 모든 방법을 능가합니다. 자세한 내용은 보충 자료를 참조하십시오. 합성 및 실제 데이터 세트에 대한 정성적 비교는 그림 5에 나와 있습니다. NeRF는 장면을 빛을 차단하고 방출하는 입자의 볼륨으로 모델링하고[25] 관점 방향 입력에 따라 관점 종속 반사를 조절합니다. 이 가정은 램버시안 표면에는 적합하지만 거울에서의 반사를 해결하는 데는 실패합니다. 거울에 비일관적인 다중 뷰 반사는 NeRF가 거울에서 별도의 가상 장면을 학습하도록 오도합니다(예: 그림 5에 표시된 부정확한 깊이 결과).NeRF는 거울에 대한 신경 복사장 학습을 수행하지 않기 때문입니다.Mirror-NeRF: Whitted 스타일 레이 트레이싱을 사용한 거울에 대한 신경 복사장 학습 합성 데이터 세트 실제 데이터 세트 PSNR ↑ SSIM ↑ LPIPS ↓ PSNR ↑ SSIM ↑ LPIPS↓↓ 방법 NeRF 28.501 0.903 0.066 25.399 0.788 0.Ref-NeRF 28.703 0.905 0.079 24.544 0.730 0.NeRFReN 28.483 0.902 0.080 23.191 0.686 0.Ours 29.243 0.907 0.077 25.173 0.785 0.표 1: 거울이 있는 합성 장면과 실제 장면에서 일반 테스트 관점에서 새로운 뷰의 정량적 비교. 가장 좋은 것은 빨간색으로 표시되고 두 번째는 주황색으로 표시됩니다. MM &#39;23, 2023년 10월 29일-11월 3일, 캐나다 온타리오주 오타와 (a) 전체 모델 (b) 마스크 광도 손실 없음 (c) 평면 일관성 제약 없음 합성 데이터 세트 실제 데이터 세트 방법 PSNR ↑ SSIM ↑ LPIPS ↓ PSNR ↑ SSIM ↑ LPIPS↓ NeRF 23.326 0.Ref-NeRF 22.828 0.NeRFReN 23.542 0.Ours 0.25.677 0.19.749 0.0.0.028 20.188 0.897 0.0.030 19.174 0.871 0.0.021 22.705 0.912 0.(d) 공동 최적화 없음 표 2: 양적 영어: 훈련 세트 분포에서 벗어난 까다로운 새로운 관점에서 거울 내부의 반사를 합성 및 실제 장면에서 비교합니다.설정 PSNR ↑ w/o 표면 법선 매개변수 20.0.SSIM ↑ LPIPS↓ 0.w/o Lem 28.0.0.w/o 평면 일관성 30.0.0.w/o 전방.법선 정규화 31.0.0.w/o 공동 최적화 전체 모델 27.0.0.32.0.0.표 3: 합성 침실에서 모델 설계와 훈련 방식을 정량적으로 분석합니다.렌더링 파이프라인에서 물리적 반사를 고려합니다.Ref-NeRF가 반사된 광선 방향과 표면 재료를 사용하여 광도장을 재매개변수화하여 반사를 재현하려는 시도에도 불구하고 거울의 기하학을 재구성하는 데 NeRF와 동일한 한계에 부딪힙니다.NeRFReN은 각각 거울 내부와 외부의 장면을 모델링하기 위해 두 개의 신경 광도장을 사용하고 거울의 부드러운 깊이를 생성할 수 있습니다. 그러나 위의 방법은 기억된 반사를 보간하여 반사를 합성합니다. 이러한 방법의 일반적인 단점은 학습 세트에서 관찰되지 않은 반사를 새로운 관점에서 합성할 수 없다는 것입니다. 예를 들어, 그림 5에서 거실 거울에 있는 사라진 조각상, 화장실 거울에 있는 사라진 천장, 토론실 거울에 있는 깨진 캐비닛입니다. 물리적 광선 추적을 기반으로 하는 신경 렌더링 프레임워크를 사용하면 임의의 관점에서 장면에 있는 모든 객체의 반사를 합성할 수 있습니다. 더욱이 NeRF, Ref-NeRF 및 NeRFReN은 반사에 색상에 고주파 변화가 있는 객체의 반사를 생성하는 데 어려움을 겪습니다. 예를 들어, 그림 5에서 회의실 거울에 걸린 왜곡된 그림, 사무실과 라운지 거울에 있는 흐릿한 커튼, 의류 매장 거울에 있는 &quot;안개가 낀&quot; 옷입니다. 이와 대조적으로, 우리의 방법은 반사된 광선을 추적하여 객체의 자세한 반사를 렌더링합니다. NeRFReN과 비교했을 때, 우리의 방법은 거울의 더 매끄러운 깊이를 복구할 수 있습니다.예를 들어, NeRFReN의 거울 깊이는 사무실에서 먼 빛이 반사되어 손상되는 반면, 우리의 방법은 거울 깊이를 정확하게 복구합니다.(f) 표면 법선 매개변수화 없음(e) 전방 법선 제약 조건 없음 그림 6: 절제 연구.우리는 모델 설계와 훈련 계획을 정성적으로 분석합니다.각 하위 그림의 오른쪽 위와 오른쪽 아래 이미지는 각각 깊이와 법선 맵을 보여줍니다.4. 절제 연구 이 섹션에서는 그림 6과 표 3에 표시된 것처럼 합성 침실에 대한 모델 설계와 훈련 계획을 정성적, 정량적으로 분석합니다.추가 절제 연구에 대해서는 보충 자료를 참조하십시오.4.3.1 매끄러운 표면 법선 매개변수화.먼저 식 (3)의 분석적 표면 법선을 사용하여 반사된 광선의 방향을 계산하여 표면 법선 매개변수화(3.1절)의 효과를 검사합니다. 그림 6(f)와 표 3에 나와 있듯이, 거울의 분석적 표면 법선에 불가피한 노이즈가 있어 거울의 반사가 붕괴됩니다. 대신, 우리의 매개변수화는 노이즈가 적은 매끄러운 표면 법선을 제공하여 거울의 반사를 최적화합니다. 4.3.2 마스크 광도 손실 Lem. 초기 단계에서 Lem을 사용하지 않으면(3.4절), 그림 6(b)에 나와 있는 것처럼 거울의 깊이가 잘못 복구됩니다. 그 이유는 거울 내부의 색상 감독으로 인해 거울 형상의 최적화가 거울 형상이 아직 수렴하지 않은 초기 단계에서 국소 최적에 갇힐 수 있기 때문입니다. 4.3. 정규화. 그런 다음 학습 중에 각 정규화 항(3.3절)을 끄고 그 효능을 분석합니다. 그림 6(c)와 표 3에서 보여 주듯이 평면 일관성 제약이 없으면 거울 깊이에 불연속성이 발생하여 이미지 품질이 떨어집니다. 그림 6(e)에 표시된 것처럼 앞을 향한 법선 제약 조건에도 비슷한 효과가 발생합니다. 이 법선 정규화는 표면을 방에 대해 법선으로 올바르게 배향하여 이미지 품질을 개선할 수 있습니다. 조인트 최적화 전략이 없으면 그림 6(d)에 표시된 것처럼 거울의 부정확한 기하학으로 인해 거울의 반사가 흐릿해집니다. 모든 정규화 용어가 활성화되면 가장 높은 이미지 품질로 거울의 정확한 반사를 성공적으로 학습합니다. 4. 응용 프로그램 거울 반사의 물리적 모델링으로 인해 제안된 Mirror-NeRF는 그림 7과 같이 거울을 사용한 다양한 새로운 장면 조작 응용 프로그램을 지원합니다.MM &#39;23, 2023년 10월 29일-11월 3일, 캐나다 온타리오주 오타와 원래 장면 배치된 거울(정점으로 지정) ViewDepth 거울 마스크 &amp; 반사 깊이 View(a) 새 거울 배치 원래 장면 대체 장면 ViewU 깊이 거울 마스크 &amp; 반사 깊이 ViewViewOriginal 장면 + 거울 마스크 &amp; 원래 장면 배치된 개체 RGB 깊이 반사 깊이 + + + (b) 새로 배치된 개체 반사 거울 거칠기(c) 반사 대체 (d) 거울 거칠기 제어 그림 7: 거울이 있는 합성 및 실제 장면에서의 응용 프로그램.4.4.1 새 거울 배치. 거울에서 반사된 광선을 재귀적으로 추적함으로써, 우리 방법은 새로운 거울을 원래 장면에 통합하는 것이 가능합니다. 그림 7(a)에 표시된 것처럼 새로 배치한 거울과 원래 거울 사이의 상호 반사를 포함하는 새로운 뷰의 합성을 활성화합니다.예를 들어, 처음 두 행의 새 거울과 원래 거울에 무한히 반사된 방과 마지막 행의 새로운 지면 반사입니다.4.4.2 새로 배치한 객체 반사.다중 신경 광도장의 구성을 지원하고 거울에서 합성 장면의 새로운 반사를 합성합니다.특히 추적된 각 광선에 대해 광선과 충돌하는 광도장에서 볼륨 렌더링 깊이를 비교하여 폐색을 감지합니다.광선은 최소 깊이로 표면에 부딪히고 표면에서 끝나거나 반사됩니다.여기서 그림 7(b)에서 우리 방법으로 모델링한 장면과 동적 광도장 D-NeRF[19]의 합성 결과를 보여줍니다.D-NeRF에서 반사된 객체는 거울에서 정확하게 합성됩니다.이 응용 프로그램은 VR 및 AR에 큰 도움이 될 수 있습니다.생생한 동적 합성 결과는 추가 비디오를 참조하세요. 4.4.3 반사 대체. 영화 및 게임 산업에서 아티스트는 거울에 반사되는 것을 다른 장면으로 대체하는 것과 같이 마법 같은 시각 효과를 만들고 싶어할 수 있습니다. 우리는 거울의 정확한 기하학을 배우므로 거울에서 반사된 광선을 다른 장면으로 변환하고 반사된 광선의 결과를 렌더링하여 쉽게 구현할 수 있습니다. 그림 7(c)에서 볼 수 있듯이 다중 뷰 일관성을 사용하여 거울에서 새 장면의 사진처럼 사실적인 뷰를 합성할 수 있습니다. 새 장면에서 반사된 광선을 추적한 결과 거울에 나타나는 모습이 새 장면과 반전된다는 점에 유의하세요. 4.4.4 거울의 거칠기 제어. 미세면 이론[27]에 따르면 표면이 거칠어 보이는 이유는 다양한 방향을 향하는 수많은 미세면으로 구성되어 있기 때문입니다. 우리는 미세면 이론을 시뮬레이션하여 거울의 거칠기를 수정하는 것을 지지합니다. 구체적으로, 우리는 표면 법선에 다른 랜덤 노이즈를 추가하여 Eq.10에 따라 카메라 광선을 여러 번 추적하고 볼륨 렌더링된 색상을 평균하여 이 광선의 최종 색상을 얻습니다. 거울의 거칠기는 노이즈의 크기와 추적 횟수에 의해 제어됩니다. 이 설계를 사용하면 그림 7(d)에 표시된 것처럼 다른 거칠기를 가진 합리적인 반사를 생성할 수 있습니다. 5
--- CONCLUSION ---
우리는 Whitted Ray Tracing에 따른 새로운 신경 렌더링 프레임워크를 제안했습니다.이 프레임워크는 장면에서 사진처럼 사실적인 새로운 뷰를 거울과 합성하고 거울의 정확한 기하학과 반사를 학습합니다.또한 거울을 사용한 다양한 장면 조작 애플리케이션을 지원합니다.제한적으로, 우리 방법은 실내에서 광원의 위치를 명시적으로 추정하지 않아 실내를 다시 조명할 수 없습니다.또한 현재 거울에 초점을 맞추고 있기 때문에 프레임워크에서 굴절을 모델링하지 않으며, 이는 자연스럽게 광선 추적 파이프라인과 호환되며 향후 작업으로 고려 중입니다.감사의 말 이 연구는 NSFC(No. 62102356)와 Ant Group의 지원을 받았습니다.Junyi Zeng 및 Chong Bao 외.Mirror-NeRF: Whitted 스타일 광선 추적을 사용한 거울의 신경 복사장 학습 참고문헌 [1] Dejan Azinović, Ricardo Martin-Brualla, Dan B Goldman, Matthias Nießner 및 Justus Thies. 2022. 신경 rgb-d 표면 재구성. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록. 6290-6301. [2] Chong Bao, Yinda Zhang, Bangbang Yang, Tianxing Fan, Zesong Yang, Hujun Bao, Guofeng Zhang, Zhaopeng Cui. 2023. SINE: 사전 안내 편집 필드를 사용한 의미 기반 이미지 기반 NeRF 편집. arXiv 사전 인쇄본 arXiv:2303.(2023). [3] Sai Bi, Zexiang Xu, Pratul Srinivasan, Ben Mildenhall, Kalyan Sunkavalli, Miloš Hašan, Yannick Hold-Geoffroy, David Kriegman, Ravi Ramamoorthi. 2020. 모양 획득을 위한 신경 반사 필드. arXiv 사전 인쇄본 arXiv:2008.03824(2020). [4] Mark Boss, Raphael Braun, Varun Jampani, Jonathan T Barron, Ce Liu, and Hendrik Lensch. 2021. Nerd: 이미지 컬렉션의 신경 반사 분해. IEEE/CVF 국제 컴퓨터 비전 컨퍼런스 회의록. 12684-12694. [5] Mark Boss, Andreas Engelhardt, Abhishek Kar, Yuanzhen Li, Deqing Sun, Jonathan Barron, Hendrik Lensch, and Varun Jampani. 2022. Samurai: 제약 없는 실제 세계 임의 이미지 컬렉션의 모양과 재료. 신경 정보 처리 시스템의 발전 35(2022), 26389-26403. [6] Mark Boss, Varun Jampani, Raphael Braun, Ce Liu, Jonathan Barron, Hendrik Lensch. 2021. Neural-pil: 반사 분해를 위한 신경 사전 통합 조명. 신경 정보 처리 시스템의 발전 34(2021), 10691-10704. [7] Zheng Chen, Chen Wang, Yuan-Chen Guo, Song-Hai Zhang. 2022. StructNeRF: 구조적 힌트가 있는 실내 장면의 신경 복사장. arXiv 사전 인쇄본 arXiv:2209.05277(2022). [8] Haoyu Guo, Sida Peng, Haotong Lin, Qianqian Wang, Guofeng Zhang, Hujun Bao, Xiaowei Zhou. 2022. 맨해튼월드 가정을 사용한 신경 3D 장면 재구성. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스의 진행 사항.5511-5520. [9] Yuan-Chen Guo, Di Kang, Linchao Bao, Yu He, Song-Hai Zhang.2022. Nerfren: 반사를 포함한 신경 복사장.IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스의 진행 사항.18409-18418. [10] Haian Jin, Isabella Liu, Peijia Xu, Xiaoshuai Zhang, Songfang Han, Sai Bi, Xiaowei Zhou, Zexiang Xu, Hao Su.2023. TensoIR: 텐서리얼 역 렌더링.arXiv 사전 인쇄본 arXiv:2304.12461(2023). [11] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C. Berg, Wan-Yen Lo, Piotr Dollár, Ross Girshick. 2023. Segment Anything. arXiv:2304.02643 [cs.CV] [12] Zhengfei Kuang, Kyle Olszewski, Menglei Chai, Zeng Huang, Panos Achlioptas, Sergey Tulyakov. 2022. NeROIC: 온라인 이미지 컬렉션의 객체에 대한 신경 렌더링. ACM Transactions on Graphics(TOG) 41, 4(2022), 1-12. [13] Hai Li, Xingrui Yang, Hongjia Zhai, Yuqian Liu, Hujun Bao, Guofeng Zhang. 2022. Vox-Surf: Voxel 기반 암묵적 표면 표현. IEEE 시각화 및 컴퓨터 그래픽스 저널(2022). [14] John Roper Matthew Muldoon. 2022. BlenderSwap. https://www.blenderswap. com/. 액세스: 2022-11-10. [15] Ben Mildenhall, Pratul P Srinivasan, Rodrigo Ortiz-Cayon, Nima Khademi Kalantari, Ravi Ramamoorthi, Ren Ng, Abhishek Kar. 2019. 로컬 라이트 필드 퓨전: 처방적 샘플링 지침을 사용한 실용적 뷰 합성. ACM 그래픽스 저널(TOG) 38, 4(2019), 1-14. [16] Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, Ren Ng. 2020. NeRF: 뷰 합성을 위한 신경 복사장으로 장면 표현. 유럽 컴퓨터 비전 컨퍼런스의 진행 중. 405-421. [17] Jacob Munkberg, Jon Hasselgren, Tianchang Shen, Jun Gao, Wenzheng Chen, Alex Evans, Thomas Müller, Sanja Fidler. 2022. 이미지에서 삼각형 3D 모델, 재료 및 조명 추출. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스의 진행 중. 8280-8290. [18] Sida Peng, Yuanqing Zhang, Yinghao Xu, Qianqian Wang, Qing Shuai, Hujun Bao, Xiaowei Zhou. 2021. 신경체: 동적 인간의 새로운 뷰 합성을 위한 구조화된 잠재 코드를 사용한 암묵적 신경 표현. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스의 진행 중.9054-9063. [19] Albert Pumarola, Enric Corona, Gerard Pons-Moll, Francesc Moreno-Noguer.2021. D-nerf: 동적 장면을 위한 신경 광도장.IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스의 진행 중.10318-10327. [20] Yawar Siddiqui, Lorenzo Porzi, Samuel Rota Buló, Norman Müller, Matthias Nießner, Angela Dai, Peter Kontschieder.2022. 신경장을 사용한 3D 장면 이해를 위한 파노라마 리프팅.arXiv 사전 인쇄본 arXiv:2212.09802(2022). [21] Vincent Sitzmann, Julien Martel, Alexander Bergman, David Lindell, Gordon Wetzstein. 2020. 주기적 활성화 함수를 사용한 암묵적 신경 표현. 신경 정보 처리 시스템의 발전 33(2020), 7462-7473. [22] Pratul P Srinivasan, Boyang Deng, Xiuming Zhang, Matthew Tancik, Ben Mildenhall, Jonathan T Barron. 2021. Nerv: 재조명 및 뷰 합성을 위한 신경 반사율 및 가시성 필드. 2023년 10월 29일-11월 3일, 캐나다 온타리오주 오타와에서 열린 IEEE/CVF MM &#39;23 컨퍼런스 회의록. 컴퓨터 비전 및 패턴 인식. 7495-7504. [23] Edgar Sucar, Shikun Liu, Joseph Ortiz, Andrew J Davison. 2021. iMAP: 실시간 암묵적 매핑 및 위치 지정. IEEE/CVF 컴퓨터 비전 국제 컨퍼런스 회의록. 6229-6238. [24] Mohammed Suhail, Carlos Esteves, Leonid Sigal, Ameesh Makadia. 2022. 일반화 가능한 패치 기반 신경 렌더링. Computer Vision-ECCV 2022: 제17회 유럽 컨퍼런스, 이스라엘 텔아비브, 2022년 10월 23-27일, 회의록, XXXII부. Springer, 156-174. [25] Ayush Tewari, Justus Thies, Ben Mildenhall, Pratul Srinivasan, Edgar Tretschk, Wang Yifan, Christoph Lassner, Vincent Sitzmann, Ricardo Martin-Brualla, Stephen Lombardi, et al. 2022. 신경 렌더링의 발전. Computer Graphics Forum, Vol. 41. Wiley Online Library, 703-735. [26] Dor Verbin, Peter Hedman, Ben Mildenhall, Todd Zickler, Jonathan T Barron, Pratul P Srinivasan. 2021. Ref-NeRF: 신경 복사장에 대한 구조화된 뷰 종속 모양. arXiv 사전 인쇄본 arXiv:2112.03907(2021). [27] Bruce Walter, Stephen R Marschner, Hongsong Li, Kenneth E Torrance. 2007. 거친 표면을 통한 굴절을 위한 미세면 모델. 렌더링 기술에 대한 제18회 Eurographics 컨퍼런스 회의록. 195-206. [28] Bing Wang, Lu Chen, Bo Yang. 2022. DM-NeRF: 2D 이미지에서 3D 장면 기하 분해 및 조작. arXiv 사전 인쇄본 arXiv:2208.(2022). [29] Chen Wang, Xian Wu, Yuan-Chen Guo, Song-Hai Zhang, Yu-Wing Tai, 및 Shi-Min Hu. 2022. NeRF-SR: 슈퍼 샘플링을 사용한 고품질 신경 복사장. 제30회 ACM 국제 멀티미디어 컨퍼런스 논문집. 6445-6454. [30] Jingwen Wang, Tymoteusz Bleja, 및 Lourdes Agapito. 2022. Go-surf: 빠르고 고품질의 rgb-d 표면 재구성을 위한 신경 특징 그리드 최적화. arXiv 사전 인쇄본 arXiv:2206.14735(2022). [31] Liao Wang, Ziyu Wang, Pei Lin, Yuheng Jiang, Xin Suo, Minye Wu, Lan Xu, 및 Jingyi Yu. 2021. ibutter: 인간의 자유 시점 렌더링을 위한 신경 상호 작용적 불릿 타임 생성기. 제29회 ACM 국제 멀티미디어 컨퍼런스 회의록. 4641-4650. [32] Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, Wenping Wang. 2021. Neus: 다중 시점 재구성을 위한 볼륨 렌더링을 통한 신경 암묵적 표면 학습. arXiv 사전 인쇄본 arXiv:2106.10689(2021). [33] Qianqian Wang, Zhicheng Wang, Kyle Genova, Pratul P Srinivasan, Howard Zhou, Jonathan T Barron, Ricardo Martin-Brualla, Noah Snavely, Thomas Funkhouser. 2021. Ibrnet: 다중 시점 이미지 기반 렌더링 학습. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록.4690-4699. [34] Zhou Wang, Alan C Bovik, Hamid R Sheikh 및 Eero P Simoncelli.2004. 이미지 품질 평가: 오류 가시성에서 구조적 유사성까지.IEEE 이미지 처리 거래 13, 4(2004), 600-612. [35] Frederik Warburg, Ethan Weber, Matthew Tancik, Aleksander Holynski 및 Angjoo Kanazawa.2023. Nerfbusters: 우연히 캡처한 NeRF에서 유령 아티팩트 제거.arXiv 사전 인쇄본 arXiv:2304.10532(2023). [36] Yi Wei, Shaohui Liu, Yongming Rao, Wang Zhao, Jiwen Lu 및 Jie Zhou. 2021. Nerfingmvs: 실내 멀티뷰 스테레오를 위한 신경 복사장의 가이드 최적화. IEEE/CVF 컴퓨터 비전 국제 컨퍼런스 논문집. 5610-5619. [37] Turner Whitted. 2005. 음영 디스플레이를 위한 개선된 조명 모델. ACM Siggraph 2005 Courses. 4-es. [38] Tong Wu, Jiaqi Wang, Xingang Pan, Xudong Xu, Christian Theobalt, Ziwei Liu, Dahua Lin. 2022. Voxurf: Voxel 기반 효율적이고 정확한 신경 표면 재구성. arXiv 사전 인쇄본 arXiv:2208.12697(2022). [39] Zijin Wu, Xingyi Li, Juewen Peng, Hao Lu, Zhiguo Cao, Weicai Zhong. 2022. Dof-nerf: 피사계 심도와 신경 복사장이 만납니다.제30회 ACM 국제 멀티미디어 컨퍼런스 논문집.1718-1729쪽. [40] Bangbang Yang, Chong Bao, Junyi Zeng, Hujun Bao, Yinda Zhang, Zhaopeng Cui, Guofeng Zhang.2022. Neumesh: 기하학 및 텍스처 편집을 위한 얽힘이 풀린 신경 메시 기반 암묵적 필드 학습.Computer Vision-ECCV 2022: 제17회 유럽 컨퍼런스, 이스라엘 텔아비브, 2022년 10월 23-27일, 논문집, 제16부.Springer, 597-614쪽. [41] Bangbang Yang, Yinda Zhang, Yijin Li, Zhaopeng Cui, Sean Fanello, Hujun Bao, Guofeng Zhang. 2022. 실내에서의 신경 렌더링: 사전 캡처된 객체로 구성된 폐쇄된 장면에 대한 비모달 3D 이해 및 자유 시점 렌더링. ACM 그래픽스 트랜잭션(TOG) 41, 4(2022), 1-10. [42] Bangbang Yang, Yinda Zhang, Yinghao Xu, Yijin Li, Han Zhou, Hujun Bao, Guofeng Zhang, Zhaopeng Cui. 2021. 편집 가능한 장면 렌더링을 위한 학습 객체-구성 신경 광도장. IEEE/CVF 컴퓨터 비전 국제 컨퍼런스 회의록. 13779-13788. [43] Lior Yariv, Yoni Kasten, Dror Moran, Meirav Galun, Matan Atzmon, Basri Ronen, Yaron Lipman. 2020. 기하학과 모양을 풀어서 다중 시점 신경 표면 재구성. 신경 정보 처리 시스템의 발전 33(2020), 2492-2502. [44] Zehao Yu, Songyou Peng, Michael Niemeyer, Torsten Sattler 및 Andreas Geiger. 2022. Monosdf: 신경 암묵적 표면 재구성을 위한 단안 기하학적 단서 탐색. arXiv 사전 인쇄본 arXiv:2206.00665(2022). MM &#39;23, 2023년 10월 29일-11월 3일, 캐나다 온타리오주 오타와 Junyi Zeng 및 Chong Bao 외. [45] Jian Zhang, Yuanqing Zhang, Huan Fu, Xiaowei Zhou, Bowen Cai, Jinchi Huang, Rongfei Jia, Binqiang Zhao 및 Xing Tang. 2022. 재투영을 통한 광선 사전: 새로운 관점 외삽을 위한 신경 광도 필드 개선. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록.1837618386. [46] Kai Zhang, Fujun Luan, Qianqian Wang, Kavita Bala 및 Noah Snavely.2021. Physg: 물리 기반 소재 편집 및 재조명을 위한 구면 가우시안을 사용한 역 렌더링.IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록.5453-5462. [47] Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman 및 Oliver Wang.2018. 지각적 지표로서 딥 피처의 비합리적인 효과.IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록.586-595. [48] Xiaoshuai Zhang, Sai Bi, Kalyan Sunkavalli, Hao Su 및 Zexiang Xu. 2022. Nerfusion: 대규모 장면 재구성을 위한 광도 필드 융합. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록. 5449-5458. [49] Xiuming Zhang, Pratul P Srinivasan, Boyang Deng, Paul Debevec, William T Freeman 및 Jonathan T Barron. 2021. Nerfactor: 알려지지 않은 조명 하에서 모양 및 반사도의 신경 인수분해. ACM Transactions on Graphics(TOG) 40, 6(2021), 1-18. [50] Yuanqing Zhang, Jiaming Sun, Xingyi He, Huan Fu, Rongfei Jia 및 Xiaowei Zhou. 2022. 역 렌더링을 위한 간접 조명 모델링. 컴퓨터 비전 및 패턴 인식에 관한 IEEE/CVF 회의 진행 중. 1864318652. [51] Youjia Zhang, Teng Xu, Junqing Yu, Yuteng Ye, Junle Wang, Yanqing Jing, Jingyi Yu 및 Wei Yang. 2023. NeMF: 신경 마이크로플레이크 필드를 사용한 역볼륨 렌더링. arXiv 사전 인쇄 arXiv:2304.00782(2023). [52] Boming Zhao, Bangbang Yang, Zhenyang Li, Zuoyue Li, Guofeng Zhang, Jiashu Zhao, Dawei Yin, Zhaopeng Cui 및 Hujun Bao. 2022. 사진 추정을 위한 야외 장면의 인수분해 및 제어 가능한 신경 재렌더링. 제30회 ACM 국제 멀티미디어 컨퍼런스 진행 중. 1455-1464. [53] Shuaifeng Zhi, Tristan Laidlow, Stefan Leutenegger 및 Andrew J Davison. 2021. 암묵적 장면 표현을 통한 현장 장면 레이블링 및 이해. IEEE/CVF 컴퓨터 비전 국제 컨퍼런스 회의록. 1583815847. [54] Zihan Zhu, Songyou Peng, Viktor Larsson, Weiwei Xu, Hujun Bao, Zhaopeng Cui, Martin R Oswald 및 Marc Pollefeys. 2022. Nice-slam: slam을 위한 신경 암묵적 확장 가능 인코딩. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록. 12786-12796.
