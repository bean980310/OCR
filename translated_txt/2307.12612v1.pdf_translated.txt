--- ABSTRACT ---
DETR과 유사한 모델은 탐지기의 성능을 크게 향상시켰고 심지어 고전적인 합성곱 모델보다 더 나은 성과를 보였습니다. 그러나 모든 토큰은 차별 없이 동등하게 처리되어 기존 인코더 구조에 중복된 계산 부담을 초래합니다. 최근의 희소화 전략은 희소 인코더를 통해 성능을 유지하면서 주의 복잡성을 줄이기 위해 정보 토큰의 하위 집합을 활용합니다. 그러나 이러한 방법은 신뢰할 수 없는 모델 통계에 의존하는 경향이 있습니다. 게다가 토큰 개체 수를 줄이는 것만으로는 탐지 성능이 크게 저하되어 이러한 희소 모델의 적용이 제한됩니다. 우리는 계산 효율성과 모델 정확도 간의 더 나은 균형을 위해 더 많은 정보 토큰에 주의를 집중시키는 Focus-DETR을 제안합니다. 구체적으로, 다중 스케일 피처 맵에서 객체의 로컬라이제이션과 범주 의미 정보를 모두 고려하는 토큰 스코어링 메커니즘을 포함하는 이중 주의를 사용하여 인코더를 재구성합니다. 우리는 백그라운드 쿼리를 효율적으로 폐기하고 점수에 따라 세분화된 객체 쿼리의 의미적 상호 작용을 향상시킵니다. 동일한 설정에서 최첨단 희소 DETR 유사 감지기와 비교했을 때, 저희 Focus-DETR은 COCO에서 50.4AP(+2.2)를 달성하는 동시에 비슷한 복잡성을 얻습니다. 코드는 torch-version 및 mindspore-version에서 제공됩니다. 1.
--- INTRODUCTION ---
객체 감지는 그림 1(a)에 표시된 것처럼 이미지에서 경계 상자와 객체 클래스를 예측하는 것을 목표로 하는 컴퓨터 비전의 기본적인 작업으로, 실제 응용 프로그램에서 매우 중요합니다.Carion 등이 제안한 DETR[1]은 학습 가능한 쿼리를 사용하여 Transformer 인코더의 출력에서 이미지 기능을 조사하고 이분 그래프 매칭을 사용하여 집합 기반 상자 예측을 수행합니다.DETR과 유사한 모델[18, 36, 14, 32, 21, 26, 2, 30, 37]은 주목할 만한 진전을 이루었고 점차적으로 격차를 메웠습니다.*연락처 저자 (a) 이미지 (b) 희소 DETR (c) Focus-DETR (d) Focus-DETR 전경 전경 객체 토큰 그림 1: 희소 DETR[26]과 당사의 Focus-DETR에서 선택한 토큰의 시각화 및 비교.(a)는 원본 이미지이고, (b)와 (c)는 모델에서 선택한 전경을 나타냅니다. (d)는 보다 세분화된 범주 의미론을 가진 객체 토큰을 나타냅니다. 더 작은 크기의 패치는 상위 레벨 기능에서 나옵니다. 합성 신경망을 기반으로 하는 검출기로. DETR의 글로벌 어텐션은 검출 성능을 개선하지만 모든 토큰에 대한 명시적 구별 없이 중복 계산으로 인해 계산 부담과 비효율성이 발생합니다. 이 문제를 해결하기 위해 Deformable DETR[37]은 주요 희소화를 통해 이차 복잡도를 선형 복잡도로 줄였으며 다중 스케일 기능을 활용하는 이점으로 인해 주류 패러다임으로 발전했습니다. 여기서는 이러한 모델에서 구성 요소의 계산 부담과 대기 시간을 추가로 분석합니다(그림 2). 그림 2에서 볼 수 있듯이 Deformable DETR[37]에서는 인코더의 계산 비용이 디코더의 8.8배이고 DINO[36]에서는 7.0배인 것을 관찰했습니다. 또한, 인코더의 지연 시간은 Deformable DETR 및 DINO에서 디코더의 약 4~8배로, 이는 인코더 모듈의 효율성을 개선할 필요성을 강조합니다. 이와 관련하여 이전 연구에서는 일반적으로 변압기 인코더에서 토큰을 압축하는 가능성을 논의했습니다. 예를 들어, PnP-DETR[29]은 전체 피처를 미세한 전경 객체 피처 벡터와 소수의 거친 배경 맥락적 피처 벡터로 추상화합니다. IMFA[34]는 디코더 계층의 예측을 기반으로 주요 포인트를 검색하여 다중 스케일 피처를 샘플링하고 샘플링된 피처를 단일 스케일 피처와 통합합니다. Sparse DETR[26]은 쿼리 희소성을 통해 토큰의 2D 공간 구조를 보존하는 것을 제안하며, 이는 Deformable DETR[37]에 적용하여 다중 스케일 피처를 활용할 수 있게 합니다. 디코더의 교차 주의 맵을 토큰 중요도 점수로 활용함으로써 Sparse DETR은 인코더에서 쿼리의 30%만 사용하여 Deformable DETR과 비슷한 성능을 달성합니다. 모든 진전에도 불구하고, 현재 모델[29, 26]은 여전히 최적이 아닌 토큰 선택 전략에 의해 어려움을 겪고 있습니다.그림 1(b)에서 볼 수 있듯이, 선택된 토큰에는 많은 노이즈가 포함되어 있으며, 일부 필수적인 객체 토큰은 명백히 간과됩니다.특히, 전경 예측자에 대한 Sparse DETR의 감독은 디코더의 교차 주의 맵(DAM)에 크게 의존하는데, 이는 인코더 사전에서 전적으로 디코더의 쿼리를 기반으로 계산됩니다.예비 실험은 DAM과 유지된 전경 토큰 간의 상관 관계가 약하기 때문에 학습 가능한 쿼리를 사용하여 Sparse DETR을 모델에 임베드할 때 심각한 성능 저하를 보여줍니다.그러나 DINO[36]와 같은 최신 DETR 유사 모델은 선택된 피처가 추가 정제 없이 예비 콘텐츠 피처이며 디코더에 모호하고 오해의 소지가 있을 수 있음을 증명했습니다.이 경우 DAM의 감독은 비효율적입니다. 게다가 이 단조로운 희소 인코더에서 유지된 전경 토큰의 수는 여전히 많고, 계산 비용 제한으로 인해 더 세분화된 선택 없이 쿼리 상호 작용을 수행하는 것은 불가능합니다. 이러한 문제를 해결하기 위해 로컬리제이션 및 범주 의미 정보를 쌓아 더 많은 정보가 있는 토큰에 주의를 할당하는 Focus-DETR을 제안합니다. 먼저 토큰의 의미 수준을 결정하기 위한 스코어링 메커니즘을 설계합니다. 전경 토큰 선택기(FTS)는 다중 스케일 피처에 걸친 상향식 점수 변조를 기반으로 배경 토큰을 포기하는 것을 목표로 합니다. 기준 진실을 참조하여 백본의 모든 토큰에 {1,0} 레이블을 지정하고 전경 확률을 예측합니다. 다중 스케일 피처 맵의 상위 토큰의 점수는 하위 토큰의 점수를 변조하여 선택의 유효성을 부과합니다. 토큰 선택 프로세스에 의미 정보를 도입하기 위해 다중 범주 점수 예측기를 설계합니다. 전경 및 범주 점수는 그림 1(d)에 표시된 것처럼 강력한 범주 의미론을 가진 더 세분화된 토큰을 공동으로 결정합니다. 신뢰할 수 있는 점수와 다양한 의미 수준에서의 선택을 기반으로, 우리는 이중 주의가 있는 인코더에 전경 토큰과 더 세분화된 객체 토큰을 공급합니다. 따라서 먼 정보 혼합에서 변형 가능한 주의의 제한이 해결되고, 그런 다음 세분화된 토큰 업데이트로 전경 쿼리의 의미 정보가 향상됩니다. 요약하자면, Focus-DETR은 인코더의 cal-84.Latency(ms) GFLOPS 142.encoder decoderencoder decoder 27.49.20.20.9.Deformable DINO Focus-DETR DETR Deformable DETR DINO Focus-DETR 16.8.8.그림 2: DETR 유사 모델의 Transformer 부분에서 계산 비용과 지연 분포, 예: Deformable DETR [37], DINO [36] 및 Focus-DETR. 점진적으로 의미 정보를 도입하여 더 정확한 전경 정보를 얻고 세분화된 토큰에 초점을 맞추는 이중 어텐션을 사용한 계산 프로세스로, 최소한의 계산 비용으로 세분화된 토큰을 더욱 향상시킵니다. 광범위한 실험을 통해 FocusDETR의 성능이 검증되었습니다. 나아가 Focus-DETR은 다양한 쿼리 구성 전략을 사용하는 DETR 유사 모델에 일반적입니다. 예를 들어, 우리의 방법은 동일한 설정에서 비슷한 계산 비용으로 COCO에서 Sparse DETR과 비교했을 때 50.4AP (+2.2)를 달성할 수 있습니다.
--- RELATED WORK ---
Transformer 기반 감지기. 최근 Carion et al.[1]은 Vision Transformer[7]에 기반한 DETR(Detection Transformer)이라는 종단간 객체 감지기를 제안했습니다. DETR은 백본, 인코더, 디코더를 통해 객체 감지를 설정된 예측 작업으로 변환하고 헝가리안 매칭 알고리즘을 통해 학습 프로세스를 감독합니다. 많은 최근 연구[18, 14, 37, 36, 21, 3, 35, 2, 4]는 학습 수렴을 가속화하고 감지 정확도를 개선하는 관점에서 Transformer 기반 감지기의 성능을 향상시켰습니다. 대표적으로 DINO[36]는 새로운 종단간 감지 최적화뿐만 아니라 뛰어난 성능으로 DETR과 유사한 모델을 주류 감지 프레임워크로 확립했습니다. Fang et al.[8]은 YOLOS를 제안하고 최소한의 추가 귀납적 편향으로 순수한 시퀀스 간 방식으로 객체 감지를 달성할 수 있음을 보여줍니다. Li et al.[15] 영어: ViTDet을 제안하여 객체 감지를 위한 백본으로 일반적이고 비계층적 ViT를 탐색합니다.Dai et al.[5]은 객체 감지를 위해 비지도 사전 학습 DETR(UP-DETR)을 위한 임의 쿼리 패치 감지라는 사전 작업입니다.IA-RED²[22]는 중복 패치를 동적으로 삭제하기 위한 해석 가능한 모듈을 도입합니다.경량 비전 변환기.우리 모두가 알다시피, 비전 변환기(ViT)는 높은 계산 복잡도와 메모리 비용으로 어려움을 겪습니다.Lu et al.[23]은 추론 프로세스를 가속화하기 위해 동적 희소 토큰을 사용하는 효율적인 ViT를 제안합니다.Yin et al.[33]은 다양한 입력 이미지의 복잡도에 따라 ViT의 추론 비용을 적응적으로 조정합니다.Xu et al.[31]은 네트워크 구조를 변경하지 않고도 모델 성능을 크게 개선하기 위해 구조 보존 토큰 선택 전략과 이중 스트림 토큰 업데이트 전략을 제안합니다.Tang et al.[28]은 사전 학습된 비전 변환기에서 계산 비용을 줄이기 위해 위에서 아래로 계층별 패치 슬리밍 알고리즘을 제시합니다. 이러한 알고리즘과 다른 유사한 작업[11, 13, 19]의 핵심 전략은 중복 토큰을 포기하여 모델의 계산 복잡성을 줄이는 것입니다. 분류 작업에 적용된 희소성 백본 구조에 초점을 맞춘 위의 모델 외에도 일부 작업[26, 29]은 DETR 유사 모델에서 중복 계산을 줄이는 데 있습니다. 효율적인 DETR[32]은 성능을 그대로 유지하면서 구조를 최적화하여 인코더 및 디코더의 계층 수를 줄입니다. PnPDETR 및 Sparse DETR은 약한 의미론을 가진 배경 토큰을 포기하여 DETR 또는 Deformable과 비슷한 성능을 달성했습니다. 그러나 이러한
--- METHOD ---
s는 신뢰할 수 없는 모델 통계에 의존하는 경향이 있습니다. 게다가 토큰 인구를 단순히 줄이는 것은 탐지 성능을 크게 방해하여 이러한 희소 모델의 적용을 제한합니다. 우리는 계산 효율성과 모델 정확도 간의 더 나은 균형을 위해 더 많은 정보가 있는 토큰에 주의를 기울이는 Focus-DETR을 제안합니다. 구체적으로, 우리는 다중 스케일 피처 맵에서 객체의 로컬라이제이션과 범주 의미 정보를 모두 고려하는 토큰 스코어링 메커니즘을 포함하는 이중 주의를 사용하여 인코더를 재구성합니다. 우리는 백그라운드 쿼리를 효율적으로 포기하고 점수에 따라 세분화된 객체 쿼리의 의미적 상호 작용을 향상시킵니다. 동일한 설정에서 최첨단 희소 DETR 유사 탐지기와 비교할 때, 우리의 Focus-DETR은 COCO에서 50.4AP(+2.2)를 달성하는 동시에 비슷한 복잡성을 얻습니다. 이 코드는 torch-version 및 mindspore-version에서 사용할 수 있습니다. 1. 서론 객체 감지는 그림 1(a)에 표시된 것처럼 이미지에서 경계 상자와 객체 클래스를 예측하는 것을 목표로 하는 컴퓨터 비전의 기본적인 작업으로, 실제 응용 프로그램에서 매우 중요합니다.Carion 등이 제안한 DETR[1]은 학습 가능한 쿼리를 사용하여 Transformer 인코더의 출력에서 이미지 특징을 조사하고 이분 그래프 매칭을 사용하여 집합 기반 상자 예측을 수행합니다.DETR과 유사한 모델[18, 36, 14, 32, 21, 26, 2, 30, 37]은 주목할 만한 진전을 이루었고 점차적으로 격차를 메웠습니다.*연락처 저자 (a) 이미지 (b) 희소 DETR (c) Focus-DETR (d) Focus-DETR 전경 전경 객체 토큰 그림 1: 희소 DETR[26]과 당사의 Focus-DETR에서 선택한 토큰의 시각화 및 비교.(a)는 원본 이미지이고, (b)와 (c)는 모델에서 선택한 전경을 나타냅니다. (d)는 보다 세분화된 범주 의미론을 가진 객체 토큰을 나타냅니다. 더 작은 크기의 패치는 상위 레벨 기능에서 나옵니다. 합성 신경망을 기반으로 하는 검출기로. DETR의 글로벌 어텐션은 검출 성능을 개선하지만 모든 토큰에 대한 명시적 구별 없이 중복 계산으로 인해 계산 부담과 비효율성이 발생합니다. 이 문제를 해결하기 위해 Deformable DETR[37]은 주요 희소화를 통해 이차 복잡도를 선형 복잡도로 줄였으며 다중 스케일 기능을 활용하는 이점으로 인해 주류 패러다임으로 발전했습니다. 여기서는 이러한 모델에서 구성 요소의 계산 부담과 대기 시간을 추가로 분석합니다(그림 2). 그림 2에서 볼 수 있듯이 Deformable DETR[37]에서는 인코더의 계산 비용이 디코더의 8.8배이고 DINO[36]에서는 7.0배인 것을 관찰했습니다. 또한, 인코더의 지연 시간은 Deformable DETR 및 DINO에서 디코더의 약 4~8배로, 이는 인코더 모듈의 효율성을 개선할 필요성을 강조합니다. 이와 관련하여 이전 연구에서는 일반적으로 변압기 인코더에서 토큰을 압축하는 가능성을 논의했습니다. 예를 들어, PnP-DETR[29]은 전체 피처를 미세한 전경 객체 피처 벡터와 소수의 거친 배경 맥락적 피처 벡터로 추상화합니다. IMFA[34]는 디코더 계층의 예측을 기반으로 주요 포인트를 검색하여 다중 스케일 피처를 샘플링하고 샘플링된 피처를 단일 스케일 피처와 통합합니다. Sparse DETR[26]은 쿼리 희소성을 통해 토큰의 2D 공간 구조를 보존하는 것을 제안하며, 이는 Deformable DETR[37]에 적용하여 다중 스케일 피처를 활용할 수 있게 합니다. 디코더의 교차 주의 맵을 토큰 중요도 점수로 활용함으로써 Sparse DETR은 인코더에서 쿼리의 30%만 사용하여 Deformable DETR과 비슷한 성능을 달성합니다. 모든 진전에도 불구하고 현재 모델[29, 26]은 여전히 최적이 아닌 토큰 선택 전략에 의해 어려움을 겪고 있습니다. 그림 1(b)에서 볼 수 있듯이 선택된 토큰에는 많은 노이즈가 포함되어 있으며 일부 필수적인 객체 토큰은 분명히 간과됩니다. 특히, 전경 예측자에 대한 Sparse DETR의 감독은 디코더의 교차 주의 맵(DAM)에 크게 의존하는데, 이는 인코더 사전에서 전적으로 디코더의 쿼리를 기반으로 계산됩니다. 예비
--- EXPERIMENT ---
영어: s는 DAM과 유지된 전경 토큰 간의 상관 관계가 약하기 때문에 학습 가능한 쿼리를 사용하여 Sparse DETR이 모델에 내장될 때 심각한 성능 저하를 보입니다. 그러나 DINO[36]와 같은 최신 DETR 유사 모델은 선택된 피처가 추가 정제 없이 예비 콘텐츠 피처이며 디코더에 모호하고 오해의 소지가 있을 수 있음을 증명했습니다. 이 경우 DAM의 감독은 비효율적입니다. 게다가 이 단조로운 희소 인코더에서 유지된 전경 토큰의 수는 여전히 많고 계산 비용 제한으로 인해 더 세분화된 선택 없이 쿼리 상호 작용을 수행하는 것은 불가능합니다. 이러한 문제를 해결하기 위해 로컬리제이션 및 범주 의미 정보를 쌓아 더 많은 정보가 있는 토큰에 주의를 할당하는 Focus-DETR을 제안합니다. 먼저 토큰의 의미 수준을 결정하기 위한 스코어링 메커니즘을 설계합니다. 전경 토큰 선택기(FTS)는 다중 스케일 피처에서 상향식 점수 변조를 기반으로 백그라운드 토큰을 포기하는 것을 목표로 합니다. 우리는 지상 진실을 참조하여 백본의 모든 토큰에 {1,0} 레이블을 지정하고 전경 확률을 예측합니다. 다중 스케일 피처 맵의 상위 토큰의 점수는 하위 토큰을 변조하여 선택의 타당성을 부과합니다. 토큰 선택 프로세스에 의미 정보를 도입하기 위해 다중 범주 점수 예측기를 설계합니다. 전경 및 범주 점수는 그림 1(d)에 표시된 것처럼 강력한 범주 의미론을 가진 보다 세분화된 토큰을 공동으로 결정합니다. 신뢰할 수 있는 점수와 다양한 의미 수준에서의 선택을 기반으로 전경 토큰과 보다 세분화된 객체 토큰을 이중 주의가 있는 인코더에 공급합니다. 따라서 먼 정보 혼합에서 변형 가능한 주의의 제한이 해결되고, 그런 다음 세분화된 토큰 업데이트로 전경 쿼리의 의미 정보가 향상됩니다. 요약하자면, Focus-DETR은 인코더의 cal-84.Latency(ms) GFLOPS 142.encoder decoderencoder decoder 27.49.20.20.9.Deformable DINO Focus-DETR DETR Deformable DETR DINO Focus-DETR 16.8.8.그림 2: DETR 유사 모델의 Transformer 부분에서 계산 비용과 지연 분포, 예: Deformable DETR [37], DINO [36] 및 Focus-DETR. 점진적으로 의미 정보를 도입하여 더 정확한 전경 정보를 얻고 세분화된 토큰에 초점을 맞추는 이중 어텐션을 사용한 계산 프로세스로, 최소한의 계산 비용으로 세분화된 토큰을 더욱 향상시킵니다. 광범위한 실험을 통해 FocusDETR의 성능이 검증되었습니다. 나아가 Focus-DETR은 다양한 쿼리 구성 전략을 사용하는 DETR 유사 모델에 일반적입니다. 예를 들어, 우리의 방법은 동일한 설정에서 비슷한 계산 비용으로 Sparse DETR과 비교하여 COCO에서 50.4AP (+2.2)를 달성할 수 있습니다.2. 관련 연구 Transformer 기반 감지기.최근 Carion et al.[1]은 Vision Transformer[7]에 기반한 DETR(Detection Transformer)이라는 종단간 객체 감지기를 제안했습니다.DETR은 백본, 인코더, 디코더를 통해 객체 감지를 설정된 예측 작업으로 변환하고 헝가리안 매칭 알고리즘을 통해 학습 프로세스를 감독합니다.최근의 많은 연구[18, 14, 37, 36, 21, 3, 35, 2, 4]는 학습 수렴을 가속화하고 감지 정확도를 개선하는 관점에서 Transformer 기반 감지기의 성능을 향상시켰습니다.대표적으로 DINO[36]는 새로운 종단간 감지 최적화뿐만 아니라 뛰어난 성능으로 인해 DETR과 유사한 모델을 주류 감지 프레임워크로 확립했습니다.Fang et al. [8]은 YOLOS를 제안하고 최소한의 추가 귀납적 편향으로 순수한 시퀀스 간 방식으로 객체 감지를 달성할 수 있음을 보여줍니다.Li et al.[15]은 객체 감지의 백본으로 일반적이고 비계층적 ViT를 탐색하기 위해 ViTDet을 제안합니다.Dai et al.[5]은 객체 감지를 위해 DETR(UP-DETR)을 비지도 사전 학습하기 위한 랜덤 쿼리 패치 감지라는 사전 작업입니다.IA-RED²[22]는 중복 패치를 동적으로 삭제하기 위한 해석 가능한 모듈을 소개합니다.경량 비전 변환기.우리 모두가 알다시피, 비전 변환기(ViT)는 높은 계산 복잡도와 메모리 비용으로 어려움을 겪습니다.Lu et al.[23]은 추론 프로세스를 가속화하기 위해 동적 희소 토큰을 사용하는 효율적인 ViT를 제안합니다.Yin et al.[33]은 다양한 입력 이미지의 복잡도에 따라 ViT의 추론 비용을 적응적으로 조정합니다.Xu et al.[31] 영어: 네트워크 구조를 변경하지 않고도 모델 성능을 크게 개선하기 위해 구조 보존 토큰 선택 전략과 듀얼 스트림 토큰 업데이트 전략을 제안합니다.Tang et al. [28]은 사전 훈련된 Vision Transformers에서 계산 비용을 줄이기 위해 상향식 레이어별 패치 슬리밍 알고리즘을 제시합니다.이러한 알고리즘과 기타 유사한 작업[11, 13, 19]의 핵심 전략은 모델의 계산 복잡성을 줄이기 위해 중복 토큰을 포기하는 것입니다.분류 작업에 적용된 희소성 백본 구조에 초점을 맞춘 위의 모델 외에도 일부 작업[26, 29]은 DETR 유사 모델에서 중복 계산을 줄이는 데 있습니다.효율적인 DETR[32]은 성능을 그대로 유지하면서 구조를 최적화하여 인코더 및 디코더의 레이어 수를 줄입니다.PnPDETR 및 Sparse DETR은 약한 의미론을 가진 배경 토큰을 포기하여 DETR 또는 Deformable과 비슷한 성능을 달성했습니다.그러나 이러한 방법은 배경 정보를 판단하는 데 최적이 아니며 더 세분화된 기능에 대한 주의가 부족합니다. 3. 방법론 먼저 FocusDETR의 전체 아키텍처를 설명합니다. 그런 다음 핵심 기여에 대해 설명합니다. (a) 다중 스케일 피처에서 로컬라이제이션과 범주 의미 정보를 모두 고려하는 스코어링 메커니즘을 구축합니다. 따라서 전경 및 세분화된 개체 토큰에 대한 2단계 명시적 구별을 얻습니다. (b) 스코어링 메커니즘을 기반으로 서로 다른 의미 수준의 토큰을 이중 주의가 있는 인코더에 공급하여 쿼리의 의미 정보를 향상시키고 모델 성능과 계산 비용의 균형을 맞춥니다. 계산 복잡도에 대한 자세한 분석을 제공합니다. 3.1. 모델 아키텍처 그림 3과 같이 Focus-DETR은 백본, 이중 주의가 있는 인코더 및 디코더로 구성됩니다. 백본에는 ResNet[10] 또는 Swin Transformer[20]를 장착할 수 있습니다. 백본에서 다중 스케일 피처 {fi}\/\_₁ (L = 4)를 활용하기 위해 fi Є RC×H₁×W₁인 경우, 세 가지 다른 스케일(즉, 1/8, 1/16, 1/32)의 피처 맵 {ƒ1, ƒ2, ƒ3}을 얻고 ƒ³를 다운샘플링하여 ƒ4(즉, 1/64)를 얻습니다. 이중 어텐션을 사용하여 인코더에 입력되기 전에 다중 스케일 피처 맵 {fi}\/\₁는 먼저 일련의 탑다운 점수 변조를 사용하여 토큰이 전경에 속하는지 여부를 나타내는 전경 토큰 선택기(섹션 3.2)를 거칩니다. 그런 다음 각 계층의 선택된 전경 토큰은 다중 범주 점수 예측기를 거쳐 전경 및 의미 정보를 활용하여 객관성 점수가 더 높은 토큰을 선택합니다(섹션 3.2). 이러한 객체 토큰은 서로 더욱 상호 작용하고 제안된 이중 어텐션(섹션 3.3)을 통해 전경 쿼리의 의미적 제한을 보완합니다.3.2. 스코어링 메커니즘 전경 토큰 선택기.Sparse DETR[26]은 인코더에 대한 토큰 하위 집합만 포함하면 비슷한 성능을 얻을 수 있음을 보여주었습니다.그러나 그림 4에서 볼 수 있듯이 Sparse DETR[26]이 제공하는 토큰 선택에는 많은 단점이 있습니다.특히 많은 보존된 토큰이 전경 객체와 일치하지 않습니다.Sparse DETR의 과제는 토큰 선택에 대한 감독이 DAM에 의존한다는 점에 있다고 생각합니다.학습 가능한 쿼리로 인해 DAM과 유지된 전경 토큰 간의 상관 관계가 줄어들어 학습 중에 오류가 발생합니다.가짜 기준 진실[26]을 예측하는 대신, [17]에서 영감을 받아 기준 진실 상자와 레이블을 활용하여 전경 선택을 감독합니다. 각 토큰에 대해 전경에 나타나는지 여부에 대한 이진 레이블을 적절하게 제공하기 위해 우리는 서로 다른 스케일을 가진 객체에 대한 다중 스케일 피처를 활용하기 위한 레이블 할당 프로토콜을 설계합니다. 특히, 우리는 먼저 서로 다른 피처 맵의 경계 상자에 대한 크기 범위를 설정하고 인접 간격의 중첩을 50% 추가하여 경계 근처의 예측을 향상시킵니다. 형식적으로, 스케일 레벨의 인덱스이고 피처 맵의 위치인 스트라이드 sı를 가진 각 토큰 t(i,j)에 대해, 우리는 원본 이미지에서 해당 좌표 (x, y)를 ([ ¾ ] + i · 81, | ¾⁄1 ] + j · 81)로 표시합니다. 인접한 특징 맵을 고려할 때, 프로토콜은 다음 규칙에 따라 레이블 ((i,j)를 결정합니다. 즉, Ть l(i,j) = S1, 10. (x, y) &amp; D Bbox V d) [] (x, y) = D Bbox Ad(i,j) = [rb, re] ¢ =²+= = ∞. (1) 여기서 DBbox (x, y, w, h)는 기준 진실 상자를 나타내고, d(i,j) = max(1,2) = [rf, rl]은 (x, y)와 경계 상자 중심 사이의 최대 체커보드 거리를 나타내고, [r, r]은 l-계층 특징에 의해 예측된 객체의 간격을 나타내고, r &lt; rob+1 &lt; r &lt; r²+1 및 +1 (r₁+r²), 1 = {0, 1, 2, 3}, ro O 및 r³ DETR 희소 방법의 또 다른 단점은 다중 스케일 특징의 활용이 부족하다는 것입니다. 특히, 의미적 연관성과 다른 스케일 간의 토큰 선택 결정의 불일치는 무시됩니다. 이 갭을 메우기 위해, 우리는 탑다운 스코어 변조를 사용하여 FTS 모듈을 구성합니다. 우리는 먼저 각 피처 맵에서 전경 스코어를 예측하기 위해 멀티 레이어 퍼셉트론(MLP)에 기반한 스코어 모듈을 설계합니다. 상위 레벨 피처 맵이 더 높은 해상도의 하위 레벨 피처보다 더 풍부한 의미를 포함한다는 점을 고려하여, 우리는 상위 레벨 의미의 전경 스코어를 보완 정보로 활용하여 인접한 하위 레벨 의미의 피처 맵을 변조합니다. 그림 5에서 볼 수 있듯이, 우리의 탑다운 스코어 변조는 업샘플링을 통해 전경 스코어를 레이어별로만 전송합니다. 형식적으로, l = {2, 3, 4}인 피처 맵 fɩ가 주어졌을 때, Si-= MLPF (fi−1(1+ UP(αɩ * S₁))), (2) 상향식 점수 변조 = {~ XN 인코더 이미지 전경 토큰 선택기 상위 K(계층별) 이중 주의 상자 클래스 변형 가능 주의 XN 디코더 업데이트 자기 주의) 다중 범주 상위 K 점수 예측기 쿼리 선택 FFN 교차 주의 자기 주의 COCO-O 그림 3: 제안된 Focus-DETR의 아키텍처 개요. Focus-DETR은 백본 네트워크, Transformer 인코더, Transformer 디코더로 구성됩니다. 다중 스케일 피처에 걸친 상향식 점수 변조를 기반으로 하는 전경 토큰 선택기(FTS)를 설계합니다. 그리고 다중 범주 점수 예측기와 전경 토큰에 의해 선택된 토큰은 먼 정보 혼합에서 변형 가능 주의의 한계를 해결하기 위해 이중 주의가 있는 인코더를 거칩니다. 희소 DETR Ours fffffi MLP S₁ 요소별 곱셈 숫자 곱셈 S1-UP 샘플 κα 그림 4: 희소 DETR과 Focus-DETR의 다른 피처 맵에 보존된 전경 토큰. 빨간색 점은 스트라이드를 기반으로 원본 이미지에 해당하는 예약된 토큰의 위치를 나타냅니다. 여기서 S는 1번째 피처 맵의 전경 점수를 나타내고, UP()는 선형 보간을 사용하는 업샘플링 함수이고, MLPF(.)는 모든 피처 맵의 토큰에 대한 전역 점수 예측기이고, {a} //--¹³는 학습 가능한 변조 계수 세트이고, L은 다중 스케일 피처 맵의 레이어를 나타냅니다. 다른 피처 맵의 현지화 정보는 이런 방식으로 서로 상관 관계가 있습니다. 다중 범주 점수 예측기. 전경에 속할 확률이 높은 토큰을 선택한 후 최소한의 계산 비용으로 쿼리 향상을 위해 보다 세분화된 토큰을 결정하는 효율적인 작업을 찾습니다. 직관적으로, 이 시나리오에서는 보다 세분화된 카테고리 정보를 도입하는 것이 유익할 것입니다. 이러한 동기에 따라, 토큰 피처를 보다 잘 활용하기 위해 전경 토큰 선택과 결합된 새로운 보다 세분화된 토큰 선택 메커니즘을 제안합니다. 그림 3에서 볼 수 있듯이, 배경 토큰의 무의미한 계산을 피하기 위해, 지역화 정보와 카테고리 의미 정보를 모두 고려하는 스태킹 전략을 채택합니다. 구체적으로, 예측자 MLPC(·)에 의해 계산된 전경 점수와 카테고리 점수의 곱은 fl-→MLP → 그림 5: 상향식 점수 변조의 작동으로 사용됩니다. 다중 스케일 피처 맵의 경우, 공유 MLP를 사용하여 {S1, S2, ...}를 계산합니다. S₁는 동적 계수 a와 피처 맵 fi-1에 의해 S1-1의 계산에 통합됩니다. 주의 계산에 관련된 세분화된 토큰을 결정하기 위한 최종 기준 på, 즉, Pj = 8; × Cj = 8; × MLPc(T³½³), (3) 여기서 및 Sj c;는 각각 T의 전경 점수와 범주 확률을 나타냅니다. 인코더 출력의 2단계 변형 가능 DETR [37]의 쿼리 선택 전략과 달리, 다중 범주 확률에는 배경 범주(Ø)가 포함되지 않습니다. 우리는 pj를 기반으로 향상된 계산을 위한 토큰을 결정할 것입니다. 3.3. 이중 주의의 계산 과정 제안된 신뢰할 수 있는 토큰 점수 매기기 메커니즘을 통해 보다 세밀하고 차별적인 계산을 수행할 수 있습니다. 전경 및 세분화된 객체 토큰이 점수 매기기 메커니즘에 따라 점진적으로 선택된 후, 먼저 세분화된 객체 토큰과 해당 위치 인코딩 알고리즘 1의 상호작용 정보를 활용합니다.이중 주의 입력이 있는 인코더: 모든 토큰 Ta, 전경 토큰 Tƒ, 위치 임베딩 PEf, 객체 토큰 번호 k, 전경 점수 Sf, 전경 토큰 인덱스 If 출력: 한 인코더 계층 이후의 모든 토큰 T와 전경 토큰 T&#39;½: 범주 점수 Cf ← MLPc (Tƒ) 2: 범주 점수 S의 최대값 + max (Cf) 3: 객체 토큰 점수 Sp obj = 4: Idx TopK(Sp, k) Se Sf 5: To Tƒ[Idxº¹³], PE。 ← PEƒ[Idxobj] 6: q = k = PE。 + To, v = To 7: TMHSA(q, k, v) 8: ToNorm(v + To) 9: Idxobj에 따라 Tƒ에서 T를 업데이트합니다.10: qq = T&#39;ƒ, k = Ta + PEƒ, v =^ 11: TMSDeformAttn(q, k, v) 12: 향상된 셀프 어텐션을 통해 If Ta에 따라 To에서 T를 업데이트합니다.그러면 향상된 객체 토큰이 원래 포그라운드 토큰으로 다시 흩어집니다.이런 식으로 Focus-DETR은 향상된 의미 정보가 있는 포그라운드 쿼리를 활용할 수 있습니다.또한 신뢰할 수 있는 세분화된 토큰 스코어링 덕분에 Encoder의 듀얼 어텐션은 정교하지 않은 쿼리 스파스 전략에 비해 계산 비용이 무시할 만큼만 증가하면서 성능을 효과적으로 향상시킵니다.우리는 알고리즘 1을 사용하여 듀얼 어텐션이 있는 인코더에서 세분화된 기능 선택 및 향상 프로세스를 설명합니다.3.4. 복잡도 분석우리는 그림 2의 결과와 세분화된 토큰이 향상된 계산이 수학적으로 무시할 만한 계산 비용만 추가한다는 우리의 주장을 추가로 분석합니다. 우리는 인코더와 디코더에서 변형 가능한 주의의 계산 복잡도를 각각 {GDA, GA)로 표시합니다. 우리는 다음과 같이 변형 가능한 DETR [37]을 참조하여 GDA를 계산합니다. GDA = O(KC +3MK +C+5K)NC, = (4) 여기서 N₁ (N₁ ≤ HW hiwi)는 인코더 또는 디코더의 쿼리 수이고, K는 샘플링 수이고, C는 임베딩 dims입니다. 인코더의 경우 Ne를 HW로 설정합니다. 여기서 y는 보존된 전경 토큰의 비율입니다. 디코더의 경우 Nad를 상수로 설정합니다. 또한 디코더의 셀프 어텐션 모듈의 복잡도는 O(2NqdC² + NC)입니다. 토큰 수가 약 1 × 104인 이미지의 경우 공통 설정 {K {K = 4, C = 256, Ngd = 900, y = GODA 1}에서 GDA는 약 7입니다. y가 0.3일 때, Transformer 부분의 계산 비용은 60% 이상 감소합니다. 이 직관적인 비교는 인코더가 주로 중복 컴퓨팅을 담당한다는 것을 보여줍니다. 그런 다음 세분화된 토큰 향상 계산의 계산 비용을 GOEC로 정의합니다. GOECO(2NC² + NC), (5) 여기서 No는 스코어링 메커니즘을 통해 얻은 세분화된 토큰의 수를 나타냅니다. No = 300일 때, GOEC는 0.025보다 작을 뿐이며, 이는 전체 모델 계산에 (GDA+GA) 영향을 미치지 않습니다. 3.5. 최적화 DETR과 같은 감지기와 마찬가지로, 우리 모델은 종단간 방식으로 학습되고 손실 함수는 다음과 같이 정의됩니다.L = \mÊmatch + \dÂdn + λƒÂƒ + λeÊenc, (6) 여기서 match는 헝가리안 알고리즘을 기반으로 한 쌍별 매칭에 대한 손실이고, Ian은 노이즈 제거 모델의 손실이고, Ef는 전경 토큰 선택기의 손실이고, Lenc는 마지막 인코더 계층의 출력을 통한 보조 최적화에 대한 손실이고, Am, λd, λf, λa는 스케일링 인수입니다.특징 점수 매기기 메커니즘에 대한 손실입니다.Focus-DETR은 FTS 모듈에 의해 전경 토큰을 얻습니다. 영어: Focal Loss[17]는 다음과 같이 FTS를 훈련하는 데 적용됩니다. f = -aƒ(1 - p)&quot;log(pƒ), = (7) 여기서 pf는 전경 확률을 나타내고 af 0.25 및 Y = 2는 경험적 하이퍼 매개변수입니다. 4. 실험 4.1. 실험 설정 데이터 세트: 117K 훈련 이미지와 5K 검증 이미지가 포함된 까다로운 COCO 2017[16] 감지 데이터 세트에 대한 실험을 수행합니다. 일반적인 관행에 따라 COCO 검증 데이터 세트에 대한 표준 평균 정밀도(AP) 결과를 보고합니다. 구현 세부 정보: Focus-DETR의 구현 세부 정보는 대부분 detrex[25]의 원래 모델과 일치합니다. ImageNet[6]을 백본으로 사용하여 사전 훈련된 ResNet-50[10]을 채택하고 AdamW[12] 최적화 프로그램을 사용하여 8xNvidia V100 GPU로 모델을 훈련합니다. 또한 ResNet-101 및 Swin Transformer로 실험을 수행합니다. 백본으로. 초기 학습률은 백본의 경우 1 × 10-5로, Transformer 인코더-디코더 프레임워크의 경우 1 × 10-4로 설정되며 가중치 감소는 1 × 10-4입니다. 학습률은 나중에 0.1만큼 감소합니다. GPU당 배치 크기는 2로 설정됩니다. 스코어링 메커니즘의 경우 FTS의 손실 가중치 계수는 1.5로 설정됩니다. MLP c()는 디코더 계층의 해당 매개변수와 매개변수를 공유하며 전체 네트워크의 학습과 함께 최적화됩니다. 또한, Model Epochs Faster-RCNN[24]42.62.DETR(DC5)[1]43.3 63.AP AP50 AP44.45.9 22.APS APM APL Params GFLOPS FPS 20.45.61.42M25.47.61.41M11.Efficient-DETR[32]44.2 62.48.28.4 47.56.32MAnchor-DETR-DC5[30]44.64.47.24.48.60.19.PnP-DETR(a = = 0.33)[29]42.62.45.22.4를 감소시킵니다. 46.42.Conditional-DETR-DC5[21]45.65.48.25.49.62.44M11.Conditional-DETR-V2[3]44.8 65.48.25.48.62.46M동적 DETR(5단계) [4]47.65.51.28.49.59.58M DAB-변형 가능-DETR[18]46.66.50.30.50.62.44M14.UP-DETR[5]42.63.45.20.47.61.SAM-DETR[35]45.0 65.47.26.49.63.58M24.변형 가능 DETR[37]46.65.50.28.49.61.40M19.Sparse DETR(a = 0.3)[26]46.65.49.29.49.60.41M23.DN-Deformable-DETR[14]48.67.52.31.52.63.48M18.DINO[36] + Sparse DETR(a = = 0.3) 또는 + Focus-DETR(저희)(a = 0.3)50.69.55.34.54.64.47M14.48.65.52.30.51.63.47M20.50.4 68.55.34.53.64.48M20.표 1: ResNet50 백본을 사용한 Focus-DETR 및 기타 감지 모델에 대한 결과 COCO val2017. 여기서 a는 백그라운드 토큰을 제거하는 방법에 대한 유지 비율을 나타냅니다. 보고된 모든 FPS는 NVIDIA V100에서 측정됩니다. 대략적인 산술 시퀀스에 의한 캐스케이드 비율이며, 하한값은 0.1입니다. 부록 A.1.1에서 더 자세한 하이퍼 매개변수 설정을 제공하며, 여기에는 캐스케이드 구조의 예약된 토큰 비율과 각 계층의 개체 스케일 간격이 포함됩니다. Epochs AP AP 50 AP75 |Params GFLOPS 모델 더 빠르게 RCNN-FPN [24] DETR-DC5 [1] Anchor-DETR* [30] DN DETR [14] DN DETR-DC5 [14]108 44.0 63.9 47.500 44.9 64.7 47.45.1 65.45.2 65.60M 60M48.8 58M 48.63M 50 47.3 67.50.63M조건부 DETR-DC5 [21] DAB DETR-DC5 [18] Focus-DETR (당사)50 46.6 67.0 50.45.9 66.8 49.63M63M36 51.4 70.0 55.7 67M 표 2: Focus-DETR(DINO 버전)과 ResNet101 백본이 있는 다른 모델의 비교. Focus-DETR은 백본 뒤에 30% 토큰을 보존합니다. 상위 첨자 *가 있는 모델은 3개의 패턴 임베딩을 사용합니다. 모델 변형 가능 DETR(사전) + 희소 DETR(a = 0.3) 또는 + Focus-DETR(a = 0.3) 변형 가능 DETR(학습 가능) + 희소 DETR(a = 0.3) 또는 Focus-DETR(a = 0.3) DN-변형 가능 DETR(학습 가능) + 희소 DETR(a = 0.3) 또는 + Focus-DETR(a = 0.3) DINO(혼합) + 희소 DETR(a = 0.3) 또는 + Focus-DETR(a = 0.3) АР 46.Corr 46.0 0.7211±0.GFLOPS FPS23.46.23.45.43.5 0.5081±0.45.24.23.48.18.47.4 0.5176 0.23.48.23.50.14.48.2 0.5784±0.50.20.20.표 3: Corr: DAM과 유지된 전경의 상관 관계(5k 검증 세트). &quot;priori&quot;: 위치 및 콘텐츠 쿼리(인코더 선택); &quot;learnable&quot;: 위치 및 콘텐츠 쿼리(초기화); &quot;혼합&quot;: 위치 쿼리(인코더 선택), 콘텐츠 쿼리(초기화). 4.2. 주요 결과 전경 및 더 세분화된 개체 토큰에 대한 잘 설계된 스코어링 메커니즘의 이점을 활용하여 Focus-DETR은 더 세분화된 기능에 주의를 집중할 수 있으며, 이는 중복 계산을 줄이는 동시에 DETR 유사 모델의 성능을 더욱 향상시킵니다. 표 1은 제안된 Focus-DETR(DINO 버전)과 다른 DETR 유사 감지기[1, 32, 37, 30, 29, 21, 3, 9, 27, 4, 18, 14, 5, 35, 26], 그리고 Faster R-CNN[24]의 철저한 비교를 보여줍니다. 우리는 우리 모델을 효율적인 DETR 기반 감지기[29, 26]와 비교하는데, 유지 비율이 0.3인 Focus-DETR은 PnP-DETR[29]보다 성능이 우수합니다(+7.AP). 우리는 견고한 기준선을 구축하기 위해 Sparse DETR을 DINO에 적용합니다. Focus-DETR은 DINO에 포함되면 Sparse DETR(+2.AP)보다 성능이 뛰어납니다. DINO[36]에 적용하여 원래 DINO와 비교했을 때 0.5 AP만 손실되지만 계산 비용은 45% 감소하고 추론 속도는 40.8% 향상됩니다. 그림 7에서 GFLOPS로 AP를 표시하여 정확도와 계산 비용 간의 상충 관계를 명확하게 보여줍니다. 전반적으로 Focus-DETR(DINO 버전)은 다른 DETR 유사 검출기와 비교했을 때 최첨단 성능을 달성합니다. Focus-DETR이 더 강력한 백본 ResNet-101[10]에 적응할 수 있는지와 보존된 전경의 비율이 모델 성능에 미치는 영향을 확인하기 위해 일련의 광범위한 실험을 수행합니다. 표 2에 표시된 대로 다른 DETR 유사 모델[18, 14, 30, 1, 9, 27, 24]과 비교할 때 Focus-DETR(DINO 버전)은 더 적은 GFLOP로 더 높은 AP를 달성합니다. 더욱이 ImageNet에서 사전 학습된 Swin Transformer를 백본으로 사용하여 부록 A.2.1에 표시된 대로 우수한 성능도 달성했습니다. ImgImgImgfall f1 f2 ₤3 ₤ImgImglayerlayerforeground score layerlayerlayerlayer(a) (b) 그림 6: (a)에 표시된 대로 다중 스케일 피처 맵에서 보존된 전경 토큰 분포의 시각화 결과와 (b)에 표시된 대로 다른 인코더 레이어에서 k 객체 토큰 진화. {Img1, Img2, Img3, Img4}는 4개의 테스트 이미지를 나타내고, {ƒ1, ƒ2, ƒ³, ƒ4}는 4개의 피처 맵에서 전경 토큰을 나타내고, {layer 1, layer 2 ...}는 다른 인코더 계층을 나타냅니다.R101, 30% R50, 50% R50◆ R50, 30%R50, 10% * RR50, 30% R50, 50% +R50, 10% Swin-T R50, 50% DCE-RR50, 30% RDCSRRR50, 10% DCE-RRRRRRGFLOPS DCE-RDCS-RDC-R조건부 DETR DAB DETR DN DETR 희소 DETR 변형 가능 DETR DINO 희소 DETR+DINO 초점 DETR그림 7: 평균 정밀도(AP) 및 GFLOP 측면에서 최근 객체 감지기의 성능. GFLOPS는 100개의 검증 이미지를 사용하여 측정됩니다.4.3. 광범위한 비교 희소 DETR은 가벼운 DETR 유사 모델에 대한 최첨단 기술입니다.앞서 언급했듯이 희소 DETR은 학습 가능한 쿼리를 사용할 때 상당한 성능 저하를 일으킵니다.Focus-DETR의 보편성을 확인하기 위해 Deformable DETR[37], DN-DETR[14] 및 DINO[36]를 포함하여 희소 DETR이 장착된 우수하고 대표적인 DETR 유사 모델과 모델을 비교합니다.희소 DETR 외에도 Deformable DETR(2단계 꺼짐), DNDeformable DETR 및 DINO에 희소 DETR을 적용하여 세 가지 기준선을 구성합니다.보조 인코더 손실 및 관련 손실 가중치를 포함하여 충분히 공정한 비교를 위해 모든 희소 DETR의 설계를 유지합니다.또한 최상의 성능을 달성하기 위해 하이퍼파라미터를 조정하여 이러한 기준선을 최적화합니다. 표 3에서 보듯이, 2단계가 없는 변형 가능한 DETR, DN-Deformable-DETR 및 DINO에 Sparse DETR을 적용할 때 AP가 1.9, 1.2 및 2.7 감소합니다. DAM과 선택된 전경 토큰 간의 상관 관계를 나타내는 Sparse DETR에서 제안한 Corr을 계산하고, 갭을 보다 직관적으로 비교하기 위해 상위 10% 토큰을 계산합니다. 표 3에서 보듯이, 이들의 Corr은 원래 Sparse DETR보다 훨씬 낮아 전경 선택기가 DAM을 효과적으로 학습하지 못한다는 것을 의미합니다. Sparse DETR과 비교할 때, Focus-DETR은 Deformable DETR(2단계 꺼짐), DN-Deformable DETR 및 DINO에서 유사한 지연 시간으로 1.7, 1.1 및 2.2 더 높은 AP를 달성합니다. 그림 3에서 보듯이 이중 어텐션을 사용하는 인코더는 Sparse DETR 또는 다른 DETR 유사 모델에 독립적으로 내장될 수 있는 것으로 보입니다. 그러나 정밀한 스코어링 메커니즘은 이중 어텐션에 중요합니다. 부록 A.2.3에서 Sparse DETR에 이중 주의를 적용한 인코더의 실험을 추가했습니다. 결과에 따르면 세분화된 토큰은 상당한 성능 향상을 가져오지 않습니다. 4.4. 절제 연구 제안된 구성 요소의 효과를 검증하기 위해 절제 연구를 수행합니다. 실험은 36개 에포크를 사용하여 ResNet-50을 백본으로 사용하여 수행됩니다. 전경 토큰 선택 전략의 효과. 첫째, 감독 없이 전경 점수 예측기를 사용하여 토큰 점수를 얻는 것은 47.8 AP만 달성하며 Sparse DETR로 가지친 DINO의 점수(48.2 AP)보다 낮습니다. 표 4의 두 번째 행에서 볼 수 있듯이 개선된 레이블 할당 전략에 감독을 추가함으로써 Focus-DETR은 +1.0 AP의 상당한 개선을 가져옵니다. 또한, 상향식 점수 변조는 다중 스케일 피처 맵 간의 점수 상호 작용을 향상시켜 FTS의 성능을 최적화합니다. 표 4의 세 번째 행에 표시된 대로, 탑다운 스코어 변조를 갖춘 Focus-DETR은 +0.4 AP를 달성합니다.그림 6(a)에 표시된 시각화와 같이, 우리의 방법이 전경 토큰을 정확하게 선택한다는 것을 관찰할 수 있습니다.또한, 다른 레벨의 피처 맵은 다른 스케일의 객체에 초점을 맞추는 경향이 있습니다.또한, 우리의 스케일 오버랩 설정으로 인해 인접한 피처 맵에서 예측한 객체 스케일 간에 오버랩이 있음을 발견했습니다.부록 A.1.2에서 더 자세한 오버랩 설정 세부 정보를 제공합니다.FTS 스코어 예측자 감독 변조 V 캐스케이드 듀얼 어텐션 AP |AP50 AP75 FPS 47.8 65.2 52.1 20.20.20.20.50.4 68.5 55.0 20.표 4: FTS 및 듀얼 어텐션에 대한 절제 연구.FTS는 전경 토큰 선택기입니다.듀얼 어텐션은 우리의 인코더 구조를 나타냅니다.감독은 기준 진실 상자에서 레이블 할당을 나타냅니다.캐스케이드 토큰 선택의 효과. 인코더에서 고정된 수의 토큰을 유지할 때 사전 선택 오류가 계층별로 축적되면 감지 성능에 해롭습니다. 스코어링 메커니즘의 장애 허용 범위를 높이기 위해 인코더에 대한 캐스케이드 구조를 설계하여 전경 토큰의 수를 계층별로 줄였습니다(섹션 3.2). 그림 6(b)에서 볼 수 있듯이 선택 범위가 감소함에 따라 인코더에서 세분화된 토큰 포커싱 프로세스가 나타나는 것을 볼 수 있으며, 이는 모델의 장애 허용 범위를 향상시키고 모델의 성능을 더욱 개선합니다. 표 4의 네 번째 행에 나와 있듯이 캐스케이드 구조를 갖춘 Focus-DETR은 +0.5 AP를 달성합니다. 이중 주의의 효과. 배경 토큰만 버리는 것과 달리 우리의 기여 중 하나는 무시할 수 있는 계산 비용으로 이중 주의를 사용하여 인코더를 재구성하는 것입니다. 향상된 계산 후 얻은 토큰은 먼 토큰 혼합의 제한으로 인해 전경 쿼리의 의미적 약점을 보완합니다. 이중 주의가 있는 인코더의 효과를 추가로 분석합니다. 표 4의 다섯 번째 행에 표시된 대로 이중 어텐션이 있는 인코더는 +0.8 AP 개선을 가져옵니다. 이러한 결과는 세분화된 토큰을 향상시키는 것이 그림 1에 표시된 대로 탐지 성능과 세분화된 기능 선택을 위한 스택된 위치 및 의미 정보의 효율성을 높이는 데 유익하다는 것을 보여줍니다. 상향식 하향식 AP APAP49.66.54.50.68.55.50.68.54.표 5: 다중 스케일 기능 맵의 점수 간 연관 방법. 상향식 및 하향식 변조를 시도합니다. 상향식 점수 변조의 효과. 방법에서 다중 스케일 점수 안내 메커니즘의 효과를 추가로 분석합니다. 표 5에서 볼 수 있듯이 점수 예측에 다중 스케일 정보를 활용하면 일관된 개선(+0.5 또는 +0.7 AP)이 발생한다는 것을 알 수 있습니다. 또한 다양한 점수 변조 방법에 대한 절제 실험을 수행합니다. 제안된 탑다운 스코어 가이드 전략(섹션 3.2)은 바텀다운 전략보다 0.2 더 높은 AP를 달성하는데, 이는 고수준 스코어를 사용하여 저수준 전경 확률을 조절하는 것이 최종 성능에 유익하다는 우리의 동기를 정당화합니다. 가지치기 비율의 효과. 표 6에서 볼 수 있듯이, 우리는 다양한 방법으로 유지되는 전경 토큰의 비율을 변경할 때 감지 성능과 모델 복잡도를 분석합니다. Focus-DETR은 동일한 비율을 유지할 때 최적의 성능을 달성합니다. 구체적으로, FocusDETR은 128 GFLOPS에서 유사한 계산 비용으로 Sparse DETR보다 +2.7 AP, Sparse DETR의 전략을 갖춘 DINO보다 +1.4AP를 달성합니다. 모델 희소 DETR [26] (epoch=50) DINO [36] α AP APS APM APL GFLOPS FPS 0.1 45.3 28.48.60.25.0.2 45.6 28.48.60.24.0.3 46.29.49.60.23.0.4 46.2 28.49.61.21.0.5 46.3 29.49.60.20.0.1 47.5 29.50.62.23.0.2 47.9 30.51.62.21.0.3 48.2 30.51.63.20.0.4 48.4 30.51.63.18.0.5 48.4 30.51.63.18.0.1 48.9 32.52.64.23.0.2 49.8 32.52.64.21.Focus-DETR 0.3 50.33.53.64.20.(epoch=36) 0.4 50.4 34.0 53.0.5 50.5 34.4 53.64.18.64.17.+ Sparse DETR [26] (epoch=36) 표 6: FocusDETR, Sparse DETR 및 DINO+Sparse DETR에서 유지하는 포그라운드 토큰의 비율을 변경할 때 성능 및 계산 비용의 실험 결과.4.5. 제한 사항 및 미래 방향 Focus-DETR은 섬세한 토큰 스코어링 메커니즘과 세분화된 피처 강화 방법을 설계했지만, 객체 경계나 중심과 같은 더 계층적인 의미적 등급 전략은 여전히 탐구할 가치가 있습니다. 또한, 향후 작업은 Transformer 전체에 걸쳐 통합된 피처 의미적 스코어링 메커니즘과 세분화된 피처 강화 알고리즘을 구축하는 것입니다. 5.
--- CONCLUSION ---
이 논문은 계산 효율성과 모델 정확도 간의 더 나은 균형을 위해 더 많은 정보가 있는 토큰에 초점을 맞추는 Focus-DETR을 제안합니다. Focus-DETR의 핵심 구성 요소는 위치와 의미 정보를 모두 고려하는 스코어링 메커니즘을 활용하는 피처 의미론에 대한 다중 레벨 판별 전략입니다. Focus-DETR은 향상을 위해 전경 및 세분화된 토큰을 정확하게 선택하여 계산 효율성과 모델 정확도 간의 더 나은 균형을 달성합니다. 실험 결과에 따르면 Focus-DETR은 DETR 유사 모델의 토큰 가지치기에서 SOTA 방법이 되었습니다. 저희의 작업은 변압기 기반 감지기 설계에 유익합니다. 참고문헌 [1] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov 및 Sergey Zagoruyko. 변압기를 사용한 종단 간 객체 감지. European Conference of Computer Vision, 2020. 1, 2,[2] Qiang Chen, Xiaokang Chen, Gang Zeng 및 Jingdong Wang. 그룹 DETR: 분리된 일대다 레이블 할당을 통한 빠른 학습 수렴.CORR, abs/2207.13085, 2022. 1,[3] Xiaokang Chen, Fangyun Wei, Gang Zeng, and Jingdong Wang. 조건부 DETR V2: 상자 쿼리를 사용한 효율적인 감지 변환기.CoRR, abs/2207.08914, 2022. 2,[4] Xiyang Dai, Yinpeng Chen, Jianwei Yang, Pengchuan Zhang, Lu Yuan, and Lei Zhang. 동적 detr: 동적 주의를 사용한 종단 간 객체 감지. International Conference on Computer Vision, 2968-2977페이지, 2021. 2,[5] Zhigang Dai, Bolun Cai, Yugeng Lin, and Junying Chen. Up-detr: 변환기를 사용한 객체 감지를 위한 비지도 사전 학습. Computer Vision and Pattern Recognition, 1601-1610페이지, 2021. 2,[6] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei. Imagenet: 대규모 계층적 이미지 데이터베이스. Computer Vision and Pattern Recognition, 248-255페이지, 2009. 5,[7] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby. 이미지는 16x16 단어의 가치가 있습니다: 대규모 이미지 인식을 위한 변압기. AAAI 인공지능 컨퍼런스. OpenReview.net, 2021.[8] Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu 및 Wenyu Liu. 단 하나의 시퀀스만 살펴봅니다. 객체 감지를 통해 비전의 변환기를 다시 생각해 봅니다. arXiv 사전 인쇄 arXiv:2106.00666, 2021.[9] Peng Gao, Minghang Zheng, Xiaogang Wang, Jifeng Dai 및 Hongsheng Li. 공간적으로 변조된 공동 주의를 통한 detr의 빠른 수렴. 컴퓨터 비전에 관한 국제 회의, 페이지 3601-3610, 2021.[10] Kaiming He, Xiangyu Zhang, Shaoqing Ren 및 Jian Sun. 이미지 인식을 위한 심층 잔여 학습. Computer Vision and Pattern Recognition, 770-778쪽, 2016. 3, 5,[11] Sehoon Kim, Sheng Shen, David Thorsley, Amir Gholami, Woosuk Kwon, Joseph Hassoun, Kurt Keutzer. 변압기에 대한 학습된 토큰 가지치기. Aidong Zhang 및 Huzefa Rangwala 편집자, Knowledge Discovery and Data Mining, 784-794쪽. ACM, 2022.[12] Diederik P. Kingma 및 Jimmy Ba. Adam: 확률적 최적화 방법. Yoshua Bengio 및 Yann LeCun 편집자, International Conference on Learning Representations, 2015.[13] Zhenglun Kong, Peiyan Dong, Xiaolong Ma, Xin Meng, Wei Niu, Mengshu Sun, Bin Ren, Minghai Qin, Hao Tang, Yanzhi Wang. Spvit: 소프트 토큰 프루닝을 통해 더 빠른 비전 변환기 활성화. ArXiv, abs/2112.13890, 2021.[14] Feng Li, Hao Zhang, Shilong Liu, Jian Guo, Lionel M Ni, Lei Zhang. Dn-detr: 쿼리 노이즈 제거를 도입하여 detr 학습 가속화. Computer Vision and Pattern Recognition, 2022. 1, 2, 6, 7,[15] Yanghao Li, Hanzi Mao, Ross Girshick, Kaiming He. 객체 감지를 위한 일반 비전 변환기 백본 탐색. arXiv 사전 인쇄본 arXiv:2203.16527, 2022.[16] Tsung-Yi Lin, Michael Maire, Serge J. Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, C. Lawrence Zitnick. Microsoft COCO: 컨텍스트 내 일반 객체. David J. Fleet, Tomás Pajdla, Bernt Schiele, Tinne Tuytelaars 편집, European Conference of Computer Vision, Lecture Notes in Computer Science, 8693권, 740-755쪽. Springer, 2014.[17] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, Piotr Dollar. 밀집 객체 감지를 위한 초점 손실. IEEE Transactions on Pattern Analysis and Machine Intelligence, 42(2):318–327, 2020. 3,[18] Shilong Liu, Feng Li, Hao Zhang, Xiao Yang, Xianbiao Qi, Hang Su, Jun Zhu, Lei Zhang. DAB-DETR: 동적 앵커 상자는 DETR에 더 나은 쿼리입니다. 학습 표현에 관한 국제 회의에서, 2022. 1, 2,[19] Xiangcheng Liu, Tianyi Wu 및 Guodong Guo. 적응형 희소 비트: self-attention을 완전히 활용하여 학습 가능한 적응형 토큰 가지치기를 지향합니다. CoRR, ABS/2209.13802, 2022.[20] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin 및 Baining Guo. Swin 변환기: 이동된 창을 사용하는 계층적 비전 변환기입니다. 컴퓨터 비전에 관한 국제 컨퍼런스(ICCV), 2021. 3,[21] Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun 및 Jingdong Wang. 빠른 훈련 수렴을 위한 조건부 detr. International Conference on Computer Vision(ICCV), 2021. 1, 2,[22] Bowen Pan, Yifan Jiang, Rameswar Panda, Zhangyang Ia-red²: Wang, Rogério Feris, Aude Oliva. 비전 변환기를 위한 해석 가능성 인식 중복 감소. CoRR, abs/2106.12620, 2021.[23] Yongming Rao, Wenliang Zhao, Benlin Liu, Jiwen Lu, Jie Zhou, Cho-Jui Hsieh. Dynamicvit: 동적 토큰 희소화를 갖춘 효율적인 비전 변환기. 신경 정보 처리 시스템의 발전, 2021.[24] Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun. 더 빠른 r-cnn: 영역 제안 네트워크를 사용한 실시간 객체 감지를 향해. C. Cortes, N. Lawrence, D. Lee, M. Sugiyama 및 R. Garnett, 편집자, 신경 정보 처리 시스템의 발전, 28권. Curran Associates, Inc., 2015.[25] Tianhe Ren, Shilong Liu, Feng Li, Hao Zhang, Ailing Zeng, Jie Yang, Xingyu Liao, Ding Jia, Hongyang Li, He Cao, Jianan Wang, Zhaoyang Zeng, Xianbiao Qi, Yuhui Yuan, Jianwei Yang 및 Lei Zhang. detrex: 벤치마킹 감지 변환기, 2023.[26] 노병석, 신재웅, 신우현, 김세훈. 희소 DETR: 학습 가능한 희소성을 통해 효율적인 엔드투엔드 객체 감지입니다. International Conference on Learning Representations, 2022. 1, 2, 3, 6, 8, 11, 12,[27] Zhiqing Sun, Shengcao Cao, Yiming Yang, and Kris Kitani. 객체 감지를 위한 트랜스포머 기반 세트 예측 재고. International Conference on Computer Vision, 3591-3600페이지, 2021.[28] Yehui Tang, Kai Han, Yunhe Wang, Chang Xu, Jianyuan Guo, Chao Xu, and Dacheng Tao. 효율적인 비전 트랜스포머를 위한 패치 슬리밍. Computer Vision and Pattern Recognition (CVPR), 12155-12164페이지, 2022.[29] Tao Wang, Li Yuan, Yunpeng Chen, Jiashi Feng, and Shuicheng Yan. Pnp-detr: 트랜스포머를 사용한 효율적인 시각 분석을 향해. 컴퓨터 비전에 관한 국제 회의에서, 2021. 1, 2, 3,[30] Yingming Wang, Xiangyu Zhang, Tong Yang 및 Jian Sun. Anchor detr: 변환기 기반 감지기에 대한 쿼리 설계입니다. AAAI 인공 지능 회의에서 2022. 1,[31] Yifan Xu, Zhijie Zhang, Mengdan Zhang, Kekai Sheng, Ke Li, Weiming Dong, Liqing Zhang, Changsheng Xu 및 Xing Sun. Evo-vit: 다이나믹 비전 변환기를 위한 느리고 빠른 토큰 진화. AAAI 인공 지능 회의, 36권, 2964~2972페이지, 2022.[32] Zhuyu Yao, Jiangbo Ai, Boxun Li 및 Chi Zhang. 효율적인 DETR: 조밀한 사전 분석으로 엔드투엔드 객체 감지기를 개선합니다. CORR, abs/2104.01318, 2021. 1, 3,[33] Hongxu Yin, Arash Vahdat, Jose M. Alvarez, Arun Mallya, Jan Kautz, Pavlo Molchanov. A-vit: 효율적인 비전 변환기를 위한 적응형 토큰. Computer Vision and Pattern Recognition(CVPR)에서, 10799-10808페이지, 2022.[34] Gongjie Zhang, Zhipeng Luo, Zichen Tian, Jingyi Zhang, Xiaoqin Zhang, Shijian Lu. 변환기 기반 객체 감지기에서 다중 스케일 기능을 효율적으로 사용하기 위해. CVPR에서, 2023.[35] Gongjie Zhang, Zhipeng Luo, Yingchen Yu, Kaiwen Cui, Shijian Lu. 의미적으로 정렬된 매칭을 통해 detr 수렴 가속화. Computer Vision and Pattern Recognition(CVPR), 939-948페이지, 2022. 2,[36] Hao Zhang, Feng Li, Shilong Liu, Lei Zhang, Hang Su, Jun Zhu, Lionel M. Ni, Heung-Yeung Shum. Dino: 엔드투엔드 객체 감지를 위한 개선된 노이즈 제거 앵커 상자를 갖춘 Detr, 2022. 1, 2, 6, 7, 8, 11,[37] Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai. 변형 가능한 detr: 엔드투엔드 객체 감지를 위한 변형 가능한 변압기. In International Conference on Learning Representations, 2021. 1, 2, 4, 5, 6, 7,fi H/SxW/s ☑ max Bax-(w,h) HxW |₤1-H/SL-1 XW/SL-HXW (0.0) 모델 그림 8: 레이블 지정 프로세스의 시각화.fi, fi-는 다른 스케일(s1, S1-1)의 피처 맵입니다.A. 부록 A.1. 추가 구현 세부 정보 A.1.1 계단식 구조 모델의 장애 허용 범위를 높이기 위해 계단식 구조를 통해 전경 영역의 범위를 점진적으로 줄입니다.섹션 3.4에서 보듯이 변형 가능한 주의[37]의 계산 복잡도는 보존된 토큰의 수에 선형적입니다. 따라서 짝수 구조(예: {0.4,0.4,0.4,0.4,0.4,0.4})와 캐스케이드 구조(예: {0.65,0.55,0.45,0.35,0.25,0.15}) 사이에는 복잡도에 큰 차이가 없습니다. 표 7은 이 논문에서 설계한 다양한 레이어의 다양한 평균 유지 비율과 해당 비율을 나열합니다. 평균 유지 비율 0.0.0.0.0.0. 비율 {0.1, 0.1, 0.1, 0.1, 0.1} {0.3, 0.3, 0.2, 0.2, 0.1, 0.1} {0.5, 0.4, 0.3, 0.3, 0.2, 0.1} {0.65,0.55,0.45,0.35,0.25,0.15} {0.75,0.65,0.55,0.45,0.35,0.25} 표 7: Focus-DETR에서 설계한 세부적인 계단식 유지 비율.A.1.2 레이블 할당 다중 스케일 피처 맵에 대한 기존 레이블 할당 방식과 달리 경계 근처의 예측을 향상시키기 위해 두 개의 인접한 피처 스케일 사이에서 범위가 겹칠 수 있습니다.이 전략은 다중 스케일 피처 맵이 객체 이질성을 예측하는 동시에 전경 샘플의 수를 늘립니다.직관적으로, 우리는 간격 경계를 2의 정수 거듭제곱의 시리즈로 할당합니다.표 8에서 볼 수 있듯이, 우리의 겹치는 간격 설정은 유사한 간격 경계를 사용하는 겹치지 않는 설정과 비교했을 때 모델의 감지 정확도를 향상시킵니다.그림 8에서 볼 수 있듯이, 우리는 원본 이미지의 기준 진실 상자와 다른 스케일을 가진 피처 맵의 토큰 간의 매핑을 시각화합니다. 간격 AP AP50 AP{[-1, 64], [64, 128], [128, 256], [256, ∞]} |50.2 68.2 54.중첩되지 않음 {[-1, 128], [128,256], [256,512], [512, ∞]} 50.2 68.1 54.55.중첩 {[-1, 64], [64, 256], [128, 512], [256, ∞]} |50.4 68.표 8: 실험 성능에 대한 다중 스케일 특징 맵의 사전 설정 스케일 간격의 효과. 간격은 다중 스케일 특징 맵의 다양한 스케일 간격을 나타내고 실험에서는 ∞ = 999999입니다.A.2. 보충 실험 A.2.1 Swin Transformer를 백본으로 사용하기 Swin Transformer[20]를 백본으로 사용할 경우 FocusDETR도 우수한 성능을 달성합니다.아래 표에서 보듯이 Focus-DETR이 Swin-T를 백본으로 사용할 때 AP는 51.9에 도달하고 Swin-B-224-22K를 사용하면 56.0AP, Swin-B-38422K를 사용하면 55.9AP를 달성합니다.Deformable DETR[37] 및 Sparse DETR[26]과 비교할 때, 표 9에서 보듯이 우리 모델은 상당한 성능 향상을 달성합니다.A.2.2 수렴 분석 학습 시대에 따른 모델 성능의 변화를 더 잘 관찰하기 위해 Focus-DETR 테스트 지표의 변화를 측정하고 DINO와 비교했습니다. 실험 결과에 따르면 Focus-DETR은 표 10에서 보듯이 백본으로 ResNet50을 사용할 때 12에포크에서도 DINO보다 성능이 우수합니다.또한 Focus-DETR은 특수한 전경 선택과 세밀한 기능 향상으로 인해 에포크마다 최적의 학습 상태에 도달했음을 발견했습니다.A.2.3 다른 모델에 이중 주의 적용 본문의 섹션 4.3에서 언급했듯이 정확한 스코어링 메커니즘은 제안된 이중 주의에 중요합니다.이중 주의가 있는 인코더를 적용하는 실험을 변형 가능 DETR[37], DN DETR[14] 및 DINO[36]와 같은 희소 DETR이 장착된 모델에 추가합니다. 표 11에서 볼 수 있듯이, 세분화된 토큰 향상을 위해 제안된 이중 주의는 변형 가능한 DETR(2단계)에서 +0.3AP, 변형 가능한 DETR(2단계 없음)에서 0.0AP, DNDeformable-DETR에서 -0.1AP, DINO에서 +0.3 AP만 제공합니다. 결과에 따르면 신뢰할 수 없는 세분화된 토큰은 상당한 성능 향상을 가져오지 못하며, 여전히 Focus-DETR과 비교했을 때 비효율적입니다. A.3. 시각화 그림 10에서와 같이 다양한 범주, 복잡한 배경, 겹치는 tarModel Epochs Backbone AP APAPAPS APM APL Params GFLOPS FPS Deformable-DETR Swin-T48.68.52.30.51.63.41MSparse DETR Swin-T49.69.53.31.52.65.41M18.Swin-T52.70.57.34.55.67.49M15.Focus-DETR Swin-B-224-22K56.74.61.40.59.72.109M15.Swin-B-384-22K56.75.61.38.60.72.109M8을 갖는 8개의 테스트 이미지를 시각화합니다.표 9: Swin Transformer를 백본으로 사용한 Focus-DETR의 결과. 여기서 Swin-T는 ImageNet-1K [6]에서 사전 학습된 작은 버전을 나타냅니다.Swin-B-224-22K는 ImageNet-22K [6]에서 사전 학습된 기본 버전을 나타내며 학습 세트의 해상도는 224입니다.보고된 모든 FPS는 NVIDIA V100 GPU에서 측정되었습니다.모델 백본 |에포크 |AP |AP50 |AP75 |APS |APM | APL DINO [36] RR-Focus-DETR R-Swin-T 2222ELIEFIE 24 504 683 548 34.3 53.7 64.24 50.3 68.4 55.1 33.24 51.2 69.7 55.9 32.53.5 64.54.865.12 49.9 68.2 54.3 32.9 52.8 65.24 51.9 70.4 56.6 35.4 54.9 67.36 52.5 70.9 57.5 34.8 55.8 67.표 10: Focus-DETR은 다른 교육 기간에 다른 백본을 사용하고 DINO [36]와 비교 결과를 제공합니다. R-101은 ResNet 백본이고, Swin-T는 작은 버전의 Swin Transformer를 나타냅니다. 모델 변형 가능 DETR(선험적) 에포크 AP GFLOPS FPS46.+ 희소 DETR(a = 0.3)46.23.+ 희소 DETR(이중 주의)(a = 0.3)46.23.or + 초점-DETR(a = 0.3)46.23. 변형 가능 DETR(학습 가능)45.+ 희소 DETR(a = 0.3)43.24.+ 희소 DETR(이중 주의) (a = 0.3)43.23.or + 초점-DETR (a = 0.3)45.23.DN-Deformable-DETR (학습 가능)48.18.+ 희소 DETR (a = 0.3)47.23.+ 희소 DETR(이중 주의) (a = 0.3)47.23.or + 초점-DETR(a = 0.3) DINO(혼합)48.23.50.14.+ 희소 DETR(a = 0.3)48.20.+ 희소 DETR(이중 주의)(a = 0.3)48.20.또는 + Focus-DETR(a = 0.3)50.20.표 11: 희소 DETR이 장착된 클래식 모델에 이중 주의를 적용하고 Focus-DETR과 비교합니다. gets, 그리고 다른 스케일. 우리는 다른 인코더 레이어에 의해 유지된 전경 피처를 분석합니다. 시각화 결과에 따르면 전경 영역은 인코더에서 레이어별로 더욱 정제된 영역에 초점을 맞춥니다. 구체적으로, 레이어 6의 결과는 더 적은 토큰으로 더 정확한 전경을 포착합니다. 첫 번째 열에 표시된 것처럼 Focus-DETR의 최종 테스트 결과도 제시합니다. 또한 레이블 할당 전략으로 인한 다중 스케일 피처 맵 유지 개체 토큰의 차이를 비교합니다. 또한 성능을 보여주기 위해 Sparse DETR[26]을 시각화합니다. 그림 9의 첫 번째 열에 표시된 것처럼 Focus-DETR은 Sparse DETR보다 더 정확한 전경을 얻을 수 있습니다. {f1, f2, f3, f4}의 결과에 따르면 FocusDETR의 다중 스케일 피처 맵은 다른 객체 스케일에 따라 토큰을 유지할 수 있으며, 이는 태그 할당과 상향식 점수 변조 전략의 장점을 더욱 입증합니다. Focus DETR Sparse DETR Focus DETR Sparse DETR Focus DETR Sparse DETR fall fifz f3fxerc xerc 그림 9: 다른 피처 맵에 예약된 전경 토큰의 시각화된 비교 결과. 우리는 명확한 객체 스케일 차이가 있는 세 개의 이미지를 사용하여 FocusDETR과 Sparse DETR[26]의 차이를 분석합니다. fall은 모든 피처 맵에서 유지되는 토큰이고, {ƒ1, f2, ƒ3, ƒ4}는 다른 피처 맵을 나타냅니다. 이미지 레이어-레이어-2 레이어-레이어-4 레이어-5 레이어-N 그림 10: 각 인코더 레이어에 예약된 전경 토큰의 시각화 결과와 최종 감지 결과가 제공됩니다. 레이어{1, 2, 3, ...}는 다른 인코더 레이어를 나타냅니다.
