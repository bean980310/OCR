--- ABSTRACT ---
오디오북은 문학 작품의 접근성을 획기적으로 개선하고 독자 참여를 개선할 수 있습니다. 그러나 오디오북을 만들고, 편집하고, 출판하는 데는 수백 시간의 인간의 노력이 필요할 수 있습니다. 이 연구에서는 온라인 전자책에서 고품질 오디오북을 자동으로 생성할 수 있는 시스템을 제시합니다. 특히 신경망 텍스트-음성의 최근 발전을 활용하여 Project Gutenberg 전자책 컬렉션에서 수천 개의 인간 품질의 오픈 라이선스 오디오북을 만들고 출시합니다. 저희 방법은 다양하게 구성된 광범위한 책 컬렉션에서 읽을 전자책 콘텐츠의 적절한 하위 집합을 식별할 수 있으며 수백 권의 책을 병렬로 처리할 수 있습니다. 저희 시스템을 사용하면 사용자가 오디오북의 말하기 속도와 스타일, 감정적 억양을 사용자 정의할 수 있으며 소량의 샘플 오디오를 사용하여 원하는 음성과 일치시킬 수도 있습니다. 이 작업에서는 5천 개가 넘는 오픈 라이선스 오디오북과 사용자가 빠르게 자신만의 맞춤형 오디오북을 만들 수 있는 대화형 데모를 제공했습니다. 오디오북 컬렉션을 들으려면 https://aka.ms/audiobook을 방문하세요. 1.
--- INTRODUCTION ---
오디오북은 문학, 뉴스 및 기타 출판물을 소비하는 인기 있는 방법이 되었습니다. 오디오북은 기존 독자가 이동 중에도 콘텐츠를 즐길 수 있게 해줄 뿐만 아니라 어린이, 시각 장애인 및 새로운 언어 학습자와 같은 커뮤니티가 콘텐츠를 이용할 수 있도록 도울 수 있습니다. 전문적인 인간 내레이션이나 LibriVox와 같은 자원봉사자 주도 프로젝트와 같은 기존의 오디오북 제작 방법은 시간이 많이 걸리고 비용이 많이 들며 녹음 품질이 다양할 수 있습니다. 이러한 요소로 인해 끊임없이 증가하는 도서 출판 속도를 따라가기 어렵습니다. 반면 자동 오디오북 생성은 훨씬 빠르고 저렴하며 일관성이 있지만 역사적으로 텍스트-음성 시스템의 로봇적 특성과 어떤 텍스트를 소리 내어 읽어서는 안 되는지 결정하는 문제(예: 목차, 페이지 번호, 그림 및 각주)로 어려움을 겪었습니다. 우리는 이질적인 온라인 전자책 컬렉션에서 고품질 오디오북을 생성하여 앞서 언급한 두 가지 과제를 모두 극복하는 시스템을 제시합니다. 특히, 저희 시스템은 신경 텍스트-음성 변환, 감정적 판독, 확장 가능한 컴퓨팅, 관련 텍스트의 자동 감지 분야의 최신 진전을 결합하여 수천 개의 합리적으로 들리는 오디오북을 만듭니다. 저희는 오픈 소스에 약 35,000시간 분량의 음성을 합친 5,000개 이상의 오디오북을 제공합니다. 저희는 또한 컨퍼런스 참석자가 몇 초 분량의 예시 사운드만 사용하여 컬렉션의 모든 책에서 자신의 목소리로 큰 소리로 읽는 맞춤형 오디오북을 만들 수 있는 데모 앱을 제공합니다. 2.
--- RELATED WORK ---
LibriVox는 인간 자원봉사자를 사용하여 오픈 라이선스 오디오북을 만드는 잘 알려진 프로젝트입니다. 오디오북의 접근성에 상당한 기여를 했지만, 자원봉사자의 기술과 녹음 환경이 다양하기 때문에 제작된 오디오북의 품질이 일관되지 않을 수 있습니다. 게다가, 이 프로젝트의 확장성은 자원봉사자의 가용성과 단일 오디오북을 녹음하고 편집하는 데 걸리는 시간에 의해 제한됩니다. Audible과 같은 개인 플랫폼은 고품질 오디오북을 만들지만 작품을 공개적으로 공개하지 않고 사용자에게 오디오북에 대한 요금을 청구합니다. Project Gutenberg는 광범위한 무료 전자책 컬렉션과 몇 가지 오디오북을 호스팅합니다. 기존 오디오북은 청취 가능성을 제한하는 로봇 텍스트 음성 변환 음성을 특징으로 합니다. 텍스트 음성 변환은 잘 연구된 문제이며 최근 딥 러닝
--- CONCLUSION ---
s 이 작업에서 우리는 이기종 전자책에서 고품질 오디오북을 만드는 것을 자동화하는 새로운 파이프라인을 제시합니다. 우리 시스템은 신경 텍스트 음성 변환, 감정 인식, 사용자 지정 음성 복제 및 분산 컴퓨팅의 새로운 발전을 사용하여 매력적이고 생생한 오디오북을 만듭니다. 우리는 이 시스템을 적용하여 오픈소스 커뮤니티에 5,000개가 넘는 오디오북을 기부하고, 컨퍼런스 참석자가 사용자 지정 오디오북을 만들 수 있도록 하여 이 시스템을 시연하는 것을 목표로 합니다. 우리는 이 작업이 오디오북의 접근성과 가용성을 크게 향상시킬 수 있는 잠재력이 있다고 믿습니다. 7. 참고문헌 [1] A. van den Oord 등, &quot;Wavenet: 원시 오디오를 위한 생성 모델,&quot; 2016. [2] Y. Wang 등, &quot;Tacotron: 종단간 음성 합성을 향하여,&quot; Proc. INTERSPEECH 2017 국제 음성 커뮤니케이션 협회 연례 컨퍼런스, 2017, pp. 4006-4010. [3] Y. Ren 등, &quot;Fastspeech: 빠르고 견고하며 제어 가능한 텍스트 음성 변환,&quot; Advances in Neural Information Processing Systems, 2019, pp. 3165—3174. [4] SB Bodapati 외, &quot;전자책의 읽기 시작 위치 감지를 위한 머신 러닝 접근법&quot;, 2018 IEEE 국제 데이터 마이닝 워크숍(ICDMW). IEEE, 2018, pp. 1522-1529. [5] M. Hamilton 외, &quot;mmlspark를 통한 유연하고 확장 가능한 딥 러닝&quot;, 제4회 예측 애플리케이션 및 API 국제 컨퍼런스 논문집, ser. Proceedings of Machine Learning Research, vol. 82. PMLR, 2018년 10월 24-25일, pp. 11-22. [6] Y. Wu 외, &quot;Adaspeech 4: 제로샷 시나리오에서의 적응형 텍스트 음성 변환&quot;, 2022년 국제 음성 커뮤니케이션 협회 연례 컨퍼런스 논문집, INTERSPEECH 2022, pp. 2568-2572. [7] &quot;표현력 있는 음성 합성을 위한 자체 감독 컨텍스트 인식 스타일 표현&quot;, Proc. INTERSPEECH 2022 국제 음성 커뮤니케이션 협회 연례 컨퍼런스, 2022, 5503--5507쪽. [8] H. Guo 외, &quot;음성 에이전트를 위한 대화형 엔드투엔드 TTS&quot;, Proc. SLT 2021 IEEE 음성 언어 기술 워크숍, 2021, 403-409쪽.
