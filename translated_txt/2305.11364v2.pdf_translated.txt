--- ABSTRACT ---
대규모 언어 모델(LLM)은 벤치마킹, 미세 조정 또는 기타 사용 사례를 위한 몇 가지 샷 프롬프팅을 통해 더 작고 정제된 데이터 세트를 생성하는 데 사용할 수 있습니다. 그러나 이러한 데이터 세트를 이해하고 평가하는 것은 어렵고 LLM에서 생성된 데이터의 실패 모드는 아직 잘 이해되지 않았습니다. 구체적으로, 데이터는 의미적으로뿐만 아니라 구문적으로나 어휘적으로도 놀라운 방식으로 반복될 수 있습니다. LLM에서 생성된 데이터 세트의 구문적 다양성을 이해하고 분석하기 위한 새로운 대화형 시각화 도구인 LinguisticLens를 소개합니다. LinguisticLens는 구문적, 어휘적 및 의미적 축을 따라 텍스트를 클러스터링합니다. 텍스트 데이터 세트의 계층적 시각화를 지원하여 사용자가 개요를 빠르게 스캔하고 개별 예를 검사할 수 있습니다. 라이브 데모는 https://shorturl.at/zHOUV에서 제공됩니다. 색인 용어: Visualization-Text-MLStatsModel*e-mails: ereif|kahng|petridis@google.com 1
--- INTRODUCTION ---
대규모 언어 모델(LLM)은 추가 모델 학습이 필요 없이 프롬프트를 통해 광범위한 언어 작업을 해결할 수 있는 능력으로 인해 널리 사용되고 있습니다[1,6,22]. 이 기능을 통해 미세 조정[13, 25,27], 벤치마킹[29], 리소스가 부족한 작업이나 언어[4, 15], 반사실적 테스트(예: 종교나 성별 기반 정체성이 다를 뿐 동일한 예[12])를 위해 더 작고 정제된 데이터 세트를 생성할 수도 있습니다. 중요한 과제는 이러한 생성된 데이터 세트를 이해하고 그 품질을 평가하는 데 있습니다. 원하는 작업이 종종 새롭고 정의상 기존 데이터 세트나 기준 진실이 없기 때문에 특정 지표를 사용하여 이러한 생성된 예의 품질을 자동으로 평가하는 것은 간단하지 않습니다. 군중 작업자가 개별 예의 품질을 평가할 수는 있지만 비용이 많이 들고 방대한 양의 텍스트 예에서 패턴을 찾는 것은 여전히 어려운 일입니다. 게다가 LLM의 특정 실패 모드를 이해하는 것은 여전히 진화하는 분야이며, 이러한 바람직하지 않은 생성된 출력 추세는 발견하기 어려울 수 있습니다. 특히 생성된 예제는 종종 예상치 못한 방식으로 시드 예제에 과적합됩니다. 그러한 병리 중 하나는 구문적 과적합으로, 생성된 예제가 시드 데이터와 문법적으로 유사하거나 동일합니다. 단일 과적합 예제는 문제가 되지 않지만 데이터 세트의 더 큰 부분이 동일한 구문 구조를 가지고 있는 경우 데이터 세트 다양성에 중요한 문제가 되므로 찾기 어려울 수 있습니다. 어휘적 과적합도 마찬가지인데, 특정 단어가 원하는 것보다 더 자주 생성된 데이터 세트에 나타납니다. 이 논문에서는 합성적으로 생성된 텍스트 데이터 세트를 이해하기 위한 새로운 대화형 시각화 도구인 LinguisticLens를 제시합니다. LinguisticLens는 특히 데이터 세트의 구문적 및 어휘적 다양성을 분석하는 데 중점을 둡니다. 사용자는 구문적 구조와 어휘적 중복을 기반으로 클러스터링된 예제 그룹을 탐색할 수 있습니다. 클러스터는 임베딩 유사성을 포함한 다른 텍스트 유사성 방법을 기반으로 할 수도 있으며, 우리는 우리의 접근 방식이 합성 데이터 세트의 다양성을 분석하는 데 더 효과적이라는 것을 발견했습니다. LinguisticLens는 웹 브라우저에서 실행되며 사용자는 CSV 파일로 데이터 세트를 제공하기만 하면 됩니다. 라이브 데모는 https://shorturl.at/zHOUV에서 찾을 수 있습니다. 소스 코드는 https://github.com/PAIR-code/interpretability에서 사용할 수 있습니다. 2 배경: LLMS를 사용하여 데이터 세트 합성 이 섹션에서는 사람들이 LLM을 사용하여 데이터 세트를 생성하는 방법에 대한 간략한 배경을 제공합니다. 사용자가 제공한 짧은 쿼리를 기반으로 아티스트 세트를 반환하는 음악 추천 모델을 미세 조정하기 위해 작은 음악 추천 데이터 세트를 만들고 싶다고 가정합니다. 예시 데이터 포인트에는 &#39;oldies but goodies&#39;라는 쿼리와 &#39;Aretha Franklin, The Beach Boys, Stevie Wonder, The Supremes, Bill Withers&#39;라는 레이블이 있을 수 있습니다. 프롬프트 내에서 모델이 유사한 데이터 포인트를 생성하는 데 사용할 수 있는 몇 가지 예를 제공할 수 있습니다. 이를 few-shot 또는 in-context 학습이라고 합니다. 예를 들어 프롬프트는 다음과 같습니다. 쿼리: {oldies but goodies} 추천 아티스트: {Aretha Franklin, Madonna} 쿼리: {춤추고 싶게 만드는 음악} 추천 아티스트: {Kraftwerk, The Cure, B-52s} 쿼리: {모델은 이 패턴(예: 아래 참조)에 따라 텍스트를 계속 진행하고, 여기에서 새로운 예제 세트를 구문 분석할 수 있습니다. 이 접근 방식을 사용하면 LLM은 이러한 합성 예제를 수백 개 또는 수천 개 만들 수 있습니다. 저희의 목표는 이를 이해하는 것입니다. chill out music} 추천 아티스트: {Bonobo, Massive Attack} 쿼리: {female vocalists} 추천 아티스트: {Carole King, Joni Mitchell} 3
--- RELATED WORK ---
3.1 LLM에서 생성된 데이터 세트 평가 LLM에서 생성된 데이터 세트를 평가하는 것은 간단한 작업이 아닙니다. 가장 좋은 경우 해당 데이터로 학습된 모델의 다운스트림 성능을 측정할 수 있습니다[4, 25]. 이것이 불가능한 경우(예: 벤치마크 또는 새 작업) 정의된 메트릭을 사용하여 데이터 세트 품질을 평가해야 합니다[13]. 자동
