--- ABSTRACT ---
이 논문은 &quot;평범한&quot; 특성을 유지하는 개선된 DETR 감지기를 제시합니다. 즉, 특정 지역성 제약 없이 단일 스케일 피처 맵과 글로벌 교차 어텐션 계산을 사용하는 반면, 디코더에 다중 스케일 및 지역성의 구조적 유도적 편향을 다시 도입하는 이전의 주요 DETR 기반 감지기와는 대조적입니다. 두 가지 간단한 기술이 다중 스케일 피처 맵과 지역성 제약의 부족을 보완하기 위해 일반 설계 내에서 놀라울 정도로 효과적임을 보여줍니다. 첫 번째는 교차 어텐션 공식에 추가된 박스-픽셀 상대 위치 편향(BoxRPB) 항으로, 각 쿼리가 해당 객체 영역에 주의를 기울이도록 잘 안내하는 동시에 인코딩 유연성도 제공합니다. 두 번째는 마스크 이미지 모델링(MIM) 기반 백본 사전 학습으로, 세분화된 지역화 능력으로 표현을 학습하는 데 도움이 되며 다중 스케일 피처 맵에 대한 종속성을 해결하는 데 중요한 것으로 입증되었습니다. 이러한 기술과 최근의 학습 및 문제 형성의 발전을 통합함으로써 개선된 &quot;평범한&quot; DETR은 원래 DETR 감지기보다 뛰어난 개선을 보였습니다. 사전 학습을 위해 Object365 데이터 세트를 활용하여 Swin-L 백본을 사용하여 63.mAP 정확도를 달성했으며, 이는 다중 스케일 피처 맵과 지역 기반 피처 추출에 크게 의존하는 최첨단 감지기와 매우 경쟁력이 있습니다. 코드는 https://github.com/impiga/Plain-DETR에서 제공됩니다. 1.
--- INTRODUCTION ---
자연어 처리 분야의 최근 혁신적 발전은 작업별 헤드 또는 디코더를 가능한 한 일반적이고 간단하며 가볍게 유지하고 주요 노력을 보다 강력한 대규모 기초 모델 구축으로 전환하는 것의 중요성을 강조합니다[37, 11, 2]. 그러나 컴퓨터 비전 커뮤니티는 종종 작업별 헤드의 튜닝과 복잡성에 계속해서 중점을 두고 있으며, 그 결과 점점 더 무겁고 복잡한 디자인이 탄생합니다. *동등한 기여. ☑ {yuhui.yuan, hanhu} @microsoft.com 변형 가능 DETR(로컬 + ms).50.+13.37.Swin 소형 일반 DETR(전역 + ss) 개선된 일반 DETR(전역 + ss) 54.50.+13.42.Swin 대형 55.그림 1: Swin-S 및 Swin-L 백본을 모두 사용하여 전역 교차 주의 계산 및 단일 스케일(ss) 기능 맵에 의존하는 일반 DETR 감지기를 엄청난 폭으로 개선했습니다. 그것은 지역 교차 주의 및 다중 스케일(ms) 특징 맵을 기반으로 하는 현재 선도적인 DETR 감지기만큼 경쟁력 있는 일반 DETR을 만듭니다. DETR 기반 객체 감지 방법의 개발은 이 궤적을 따릅니다. 원래 DETR 접근 방식[4]은 특정 객체 감지 문제에 대한 전담된 이해가 필요한 다중 스케일 특징 맵 및 영역 기반 특징 추출과 같은 복잡하고 도메인별 설계를 버렸다는 점에서 인상적입니다. 그러나 이 분야의 후속 개발[55, 54]은 이러한 설계를 다시 도입하여 학습 속도와 정확도를 개선했지만 &quot;귀납적 편향 감소&quot;의 원칙[13]에도 위배됩니다. 이 작업에서 우리는 원래 DETR 감지기를 개선하는 동시에 다중 스케일 피처 맵이 없고 교차 주의 계산을 위한 지역성 디자인이 없는 &quot;평범한&quot; 특성을 유지하는 것을 목표로 합니다. 객체 감지기는 다양한 스케일과 위치의 객체를 처리해야 하므로 이는 어렵습니다. 표 1에 표시된 대로 학습 및 문제 공식화의 최신 개선에도 불구하고 일반 DETR 방법은 다중 스케일 피처 맵과 지역적 피처 추출 디자인을 활용하는 최첨단 감지기에 비해 여전히 크게 뒤처져 있습니다. 그렇다면 다중 스케일 및 임의로 위치한 객체를 처리할 때 이러한 구조적 &quot;귀납적 편향&quot;을 어떻게 보상할 수 있을까요? 우리의 탐구 결과 완전히 새로운 것은 아니지만 이 맥락에서 놀랍도록 효과적인 두 가지 간단한 기술인 박스 대 픽셀 상대 위치 편향(BoxRPB)과 마스크 이미지 모델링(MIM) 사전 학습이 발견되었습니다. BoxRPB는 픽셀 간의 기하학적 관계를 인코딩하고 변환 불변성을 향상시키는 비전 트랜스포머[34, 33]의 상대 위치 편향(RPB) 항에서 영감을 받았습니다. BoxRPB는 RPB를 확장하여 4d 박스와 2d 픽셀 간의 기하학적 관계를 인코딩합니다. 또한 전체 항을 사용하는 것과 비교하여 정확도가 손실되지 않는 효율적인 계산을 위한 축 분해 접근 방식을 제시합니다. 우리의 실험은 BoxRPB 항이 교차 주의 계산을 개별 객체에 잘 전담하도록 잘 안내할 수 있음을 보여줍니다(그림 4 참조, COCO 벤치마크에서 37.2mAP의 일반 DETR 기준선보다 +8.9mAP만큼 탐지 정확도를 극적으로 향상시킵니다(표 2 참조). MIM 사전 학습 활용은 일반 DETR의 성능을 향상시키는 또 다른 중요한 기술입니다. 우리의 결과는 또한 일반 DETR 기준선보다 +7.4mAP의 상당한 개선을 보여줍니다(표 2 참조). 이는 세밀한 위치 지정 기능 때문일 수 있습니다[49]. MIM 사전 학습은 다른 탐지기의 성능을 적당히 향상시키는 것으로 나타났지만[20, 50] 일반 설정에서의 영향은 엄청납니다. 더욱이 이 기술은 백본에서 다중 스케일 피처 맵을 사용할 필요성을 없애는 데 중요한 요인임이 입증되었으며, [28, 15]의 결과를 계층적 백본이나 단일 스케일 헤드를 활용하는 탐지기로 확장했습니다. 이러한 기술과 최신 기술을 통합하여 훈련과 문제 공식화 모두에서 개선된 우리의 개선된 &quot;일반&quot; DETR은 그림 1에서 볼 수 있듯이 원래 DETR 감지기에 비해 뛰어난 개선을 보였습니다. 나아가, 우리의 방법은 사전 훈련을 위해 Object365 데이터 세트를 활용할 때 63.9mAP의 정확도를 달성하여 다중 스케일 피처 맵과 캐스케이드 R-CNN[33] 및 DINO[54]와 같은 영역 기반 피처 추출 기술에 의존하는 최첨단 객체 감지기와 매우 경쟁력이 있습니다. 이러한 결과 외에도, 우리의 방법론은 탐지 특정 다중 스케일 및 로컬화된 디자인에 의존하는 것과 달리 효과적인 작업별 헤드 또는 디코더를 설계할 때 구조적 &quot;귀납적 편향&quot;을 최소화하는 방법을 보여줍니다. 우리의 연구는 최소한의 노력으로 더 광범위한 시각 문제에 대해 DETR과 같은 일반적인 일반 디코더를 사용하는 것에 대한 미래 연구에 영감을 주어, 이 분야가 자연어 처리 분야에서 발생하는 것과 유사한 대규모 기초 시각 모델을 개발하는 데 더 많은 에너지를 쏟을 수 있기를 바랍니다. 2. 현대화된 일반 DETR 기준선 2.1. 원래 DETR 검토 원래 DETR 감지기[4]는 3개의 하위 네트워크로 구성됩니다.· 이미지에서 이미지 특징을 추출하는 백본 네트워크 F₁. 입력 이미지를 IЄRH H ×W×³¸로 표시합니다.· 백본 네트워크는 기존 ConvNet(예: ResNet[22])을 사용하는 경우 다중 스케일 특징 맵 C² 3, C4, C5를 제공할 수 있습니다.· 공간 해상도는 일반적으로 입력 이미지의 1/42, 1/82, 1/162, 1/32²입니다.· 원래 DETR 감지기는 당시 주류 백본 아키텍처인 ResNet을 백본 네트워크로 사용했으며, 원래 ResNet 또는 확장된 5단계 네트워크가 있는 변형을 사용했습니다.· 이제 주류 백본 네트워크는 실험에 사용될 비전 Transformers(예: Swin Transformer[34])로 발전했습니다. • 이미지 특징을 강화하기 위한 Transformer 인코더 Fe. C5에서 선형 투영을 통해 얻은 P5 ERXC(C=256)에 적용됩니다. Transformer 인코더는 일반적으로 여러 개의 스태킹 Transformer 블록(즉, 원래 DETR의 6개)으로 구성됩니다. = • 임의로 초기화된 객체 쿼리 Q{q0, q1, qn} 세트를 사용하여 이미지 특징 맵에서 객체 경계 상자를 디코딩하는 글로벌 Transformer 디코더 Få. Transformer 디코더는 또한 일반적으로 여러 계층으로 구성되며 각 계층에는 셀프 어텐션 블록, 크로스 어텐션 블록 및 피드 포워드 블록이 포함됩니다. 각 디코더 계층은 집합 일치 손실에 의해 구동되는 레이블과 경계 상자가 있는 객체 집합을 생성합니다. DETR 프레임워크는 다음을 포함하여 여러 가지 장점이 있습니다. 1) 개념적으로 간단하고 적용성이 일반적입니다. 이것은 객체 감지를 이미지 픽셀을 문제 대상으로 디코딩하는 일반적인 개념과 함께 픽셀에서 객체로의 &quot;변환&quot; 작업으로 봅니다. 2) 엔드투엔드 세트 매칭 손실을 사용하기 때문에 사용자 정의 레이블 할당 및 수작업으로 설계된 비최대 억제와 같은 최소한의 도메인 지식이 필요합니다. 3) 단순하여 도메인별 다중 스케일 피처 맵 및 영역 기반 피처 추출을 피합니다. 다음에서 먼저 위의 좋은 장점을 유지하면서 훈련 및 문제 공식화와 관련된 최근의 발전을 통합하여 향상된 DETR 기반 감지기를 빌드합니다. 2.2. 향상된 일반 DETR 기준 기본 설정. 기본 설정은 다음과 같은 조정을 제외하고 대부분 원래 DETR 프레임워크를 따릅니다. 1) 원래 ResNet50 백본 대신 더 강력한 Swin-T 백본을 사용합니다. 2) 단순성을 위해 백본의 마지막 단계에 팽창 연산을 추가하는 대신 디컨볼루션을 통해 C5에서 P4의 피처 맵을 만듭니다. 3) 우리는 쿼리는 300이고 Transformer 디코더의 드롭아웃 비율은 0입니다. 4) 효율적인 절제 연구를 위해 1× 스케줄러 설정(12 에포크)을 사용합니다. 표 1에서 볼 수 있듯이 이 기본 설정은 COCO val에서 22.5 mAP를 생성합니다. 다음에서 기본 설정에 최근의 훈련 및 문제 공식화의 몇 가지 진전을 통합하고 표 1에서 볼 수 있듯이 탐지 정확도를 점차적으로 37.mAP로 개선합니다. Transformer 인코더를 백본에 병합. 백본 네트워크와 Transformer 인코더는 이미지 특징을 인코딩하는 동일한 목적을 제공합니다. Vision Transformer 백본을 활용하면 Transformer 인코더의 계산 예산을 백본에 통합할 수 있으며 약간의 개선이 있었습니다. 아마도 더 많은 매개변수가 사전 훈련되었기 때문일 것입니다. 구체적으로 Swin-S 백본을 사용하고 Transformer 인코더를 제거했습니다. 이 방법은 원래 Swin-T와 6계층 Transformer 인코더와 비교할 때 유사한 계산 FLOPS를 보였습니다. 이 접근 방식은 전체 DETR 프레임워크를 단순화하여 백본(인코더)과 디코더 네트워크로만 구성합니다.더 나은 분류를 위한 초점 손실. [55]에 따라 기본 교차 엔트로피 손실을 대체하기 위해 초점 손실 [30]을 활용하여 감지 정확도를 23.1mAP에서 31.6mAP로 크게 향상시킵니다.반복적 정제. 반복적 정제 방식 [43, 55, 3]에 따라 각 디코더 계층이 이전 디코더 계층에서 생성된 최신 바운딩 박스에 대한 박스 델타를 예측하도록 하는 반면, 각 Transformer 디코더 계층 내에서 독립적인 예측을 사용하는 원래 DETR과 다릅니다.이 전략은 감지 정확도를 +1.mAP만큼 향상시켜 33.1mAP에 도달합니다.콘텐츠 관련 쿼리. [55]에 따라 이미지 콘텐츠를 기반으로 개체 쿼리를 생성합니다.가장 신뢰도가 높은 상위 300개 예측이 후속 디코딩 프로세스에 대한 쿼리로 선택됩니다.객체 쿼리 생성에는 집합 일치 손실이 사용되므로 도메인별 레이블 할당 전략이 없다는 장점이 유지됩니다. 이 수정으로 감지 정확도가 +0.9 mAP 향상되어 34.0 mAP에 도달했습니다. 두 번 탐색. 이전 Transformer 디코더 계층의 정제된 상자 정보를 활용하기 위해 두 번 탐색 탐색 방식[54, 26]을 통합하여 인접한 Transformer 디코더 계층에서 매개변수를 보다 효과적으로 최적화합니다. 이 수정으로 +0.8 mAP 향상이 발생합니다. 혼합 쿼리 선택. 이 방법[54]은 정적 콘텐츠 쿼리와 이미지 적응 위치 쿼리를 결합하여 더 나은 쿼리 표현을 형성합니다. +0.4 mAP 향상이 발생합니다. 하이브리드 매칭. 원래 일대일 세트 매칭은 양성 샘플을 훈련하는 데 효과가 떨어집니다. MTE FL IR TS LFT MQS HM AP ✓ XXXX 22.☑ X 23.X ☑ 31.X 33.☑ 34.34.Χ 35.37이 있었습니다.표 1: 일반 DETR을 현대화하는 데 사용되는 각 요소의 효과에 대한 예비적 절제 결과. MTE: Transformer 인코더 병합. FL: 초점 손실로서의 분류 손실.IR: 반복적 정제.TS: 2단계.LFT: 두 번 기대.MQS: 혼합 쿼리 선택.HM: 하이브리드 매칭.보조적인 일대다 세트 매칭 손실을 통해 효능을 개선하는 여러 방법[26, 6, 27].우리는 추가적인 수동 레이블링 노이즈 또는 할당 설계가 필요하지 않다는 이점을 유지하기 때문에 하이브리드 매칭 접근 방식[26]을 선택했습니다.이 수정으로 감지 정확도가 +2.mAP 향상되어 최종 37.2mAP를 달성했습니다.3. 상자 대 픽셀 상대 위치 바이어스 이 섹션에서는 다중 스케일 기능의 부족과 명시적 로컬 교차 주의 계산을 보상하는 데 중요한 것으로 입증된 간단한 기술인 상자 대 픽셀 상대 위치 바이어스(BoxRPB)를 소개합니다.원래의 DETR 디코더는 표준 교차 주의 계산을 채택합니다.= Softmax(QKT)V+X, (1) 여기서 X와 O는 각각 각 객체 쿼리의 입력 및 출력 기능입니다. Q, K 및 V는 각각 쿼리, 키 및 값 특징입니다.그림 4에서 볼 수 있듯이 원래의 교차 주의 공식화는 종종 일반 DETR 프레임워크 내의 무관한 이미지 영역에 주의를 기울입니다.이것이 다중 스케일 및 명시적 지역성 디자인보다 정확도가 훨씬 낮은 이유일 수 있다고 추측합니다.Vision Transformer 아키텍처[34, 33]에 대한 픽셀 간 상대 위치 바이어스의 성공에서 영감을 받아 교차 주의 계산에 상자 간 상대 위치 바이어스(BoxRPB)를 사용하는 방법을 살펴봅니다.= (2) = Softmax(QKT + B)V + X, 여기서 B는 상자와 픽셀 간의 기하학적 관계에 의해 결정되는 상대 위치 바이어스입니다.2d 상대 위치에서 정의된 원래의 상대 위치 바이어스(RPB)와 달리 BoxRPB는 더 큰 4d 기하학적 공간을 처리해야 합니다.다음에서 두 가지 구현 변형을 소개합니다.Naive BoxRPB 구현. 우리는 4d-박스-픽셀 상대 위치 바이어스를 계산하기 위해 연속 RPB 방법[33]을 적용합니다. 원래 연속 RPB 방법[33]은 해당 2d-상대 좌표에 적용된 메타 네트워크에 의해 각 상대 위치 구성에 대한 바이어스 항을 생성합니다. 이 방법을 BoxRPB에 확장할 때 우리는 왼쪽 위와 오른쪽 아래 모서리를 사용하여 상자를 나타내고 이러한 모서리 점과 이미지 픽셀 점 사이의 상대 위치를 메타 네트워크의 입력으로 사용합니다. 상대 좌표를 (Ax1, Ayı) € RK×H×W×2 및 (Ax2, Ay2) € RKXHXWX2로 표시하면 상자 대 픽셀 상대 위치 편향은 다음과 같이 정의할 수 있습니다. (3) B MLP(Ax1, Ay1, Ax2, Ay2), 여기서 B는 RKXWHXM 모양이고 M은 어텐션 헤드 수를 나타내고 K는 예측된 바운딩 박스 수를 나타내고 W, H는 출력 피처 맵의 너비와 높이를 나타냅니다. MLP 네트워크는 두 개의 선형 레이어로 구성됩니다. 선형 → ReLU 선형. 이 두 선형 레이어의 입력/출력 모양은 각각 K×H×W×4→KxHxWx×256 및 KxHxWx256→K×H×W×M입니다. 실험 결과 이러한 단순한 구현이 표 3a에서 볼 수 있듯이 이미 매우 효과적으로 수행된다는 것을 보여줍니다. 그러나 많은 GPU 계산과 메모리 예산을 소모하므로 실용적이지 않습니다. 이제 우리는 분해된 BoxRPB 구현을 제시합니다.BoxRPB의 보다 효율적인 구현을 제시합니다.4d 입력에 대한 바이어스 항을 직접 계산하는 대신 바이어스 계산을 두 항으로 분해하는 것을 고려합니다.(4) B = unsqueeze (Bx, 1) + unsqueeze (By, 2), 여기서 BÃ € Rк×W×M과 By Є RK×H×M은 각각 x축과 y축에 대한 바이어스입니다.다음과 같이 계산합니다.Bx = MLP1(Ax1, Ax2), By MLP2 (Ay1, Ay2), (5) 분해된 BoxRPB 구현의 전체 프로세스도 그림 2에 나와 있습니다.MLP1 내의 두 선형 계층의 입력/출력 모양은 각각 KXWX2→K×W×256과 K×W×256→K×W×M입니다.마찬가지로 MLP2 내의 두 선형 계층에 대한 입력/출력 모양은 동일한 패턴을 따릅니다. 분해를 통해 계산 FLOPS와 메모리 소비가 모두 크게 감소하는 반면 정확도는 거의 유지됩니다(표 3a 참조). 이 분해 기반 구현은 실험에서 기본적으로 사용됩니다. 그림 4는 교차 주의 계산을 위한 이 추가 BoxRPB 항의 효과를 보여줍니다. 일반적으로 BoxRPB 항은 주의를 객체와 상자 경계에 더 집중시키는 반면 BoxRPB가 없는 교차 주의는 많은 무관한 영역에 주의를 기울일 수 있습니다. 이는 표 2에 표시된 대로 BoxRPB 항에 의해 정확도가 크게 향상된(+8.9 mAP) 이유를 설명할 수 있습니다. 4. 추가 개선 사항 이 섹션에서는 일반 DETR 프레임워크를 추가로 개선할 수 있는 두 가지 다른 기술을 소개합니다. MIM 사전 학습. 더 나은 지역성[49]을 보여준 마스크 이미지 모델링 사전 학습[1, 20, 51, 28]의 최근 발전을 활용합니다. 구체적으로, 레이블 없이 ImageNet에서 학습한 SimMIM 사전 학습된 가중치로 Swin 변환기 백본을 초기화합니다([51] 참조). 표 2에 표시된 대로 MIM 사전 학습은 일반 DETR 기준선보다 +7.mAP 향상을 가져옵니다. 다른 감지기보다 일반 DETR 프레임워크에서 MIM 사전 학습의 엄청난 이득은 일반 DETR 프레임워크에 대한 학습된 현지화 기능의 중요성을 강조할 수 있습니다. BoxRPB가 관련된 더 높은 기준선에서 MIM 사전 학습은 여전히 +2.6 mAP 이득을 낼 수 있어 48.7 mAP에 도달할 수 있습니다. 게다가 MIM 사전 학습은 표 5b 및 5c에서 볼 수 있듯이 정확도 손실 없이 다중 스케일 백본 기능을 포기하는 데도 중요하다는 점에 유의합니다. 재매개변수화를 사용한 경계 상자 회귀. 강조하고 싶은 또 다른 개선 사항은 경계 상자 회귀를 수행할 때 경계 상자 재매개변수화입니다. 원래 DETR 프레임워크[4]와 대부분의 변형은 상자 중심과 크기를 [0,1]로 직접 조정합니다. 손실 계산을 지배하는 큰 개체로 인해 작은 개체를 감지하는 데 어려움이 있습니다. 대신, 우리는 상자 중심과 1번째 디코더 계층의 크기를 다음과 같이 재매개변수화합니다.t₁₂ = (9x − P²x² ¹³)/Pw &quot; 1-&quot; (6) ty = (gy - Py¹)/Ph tw = log(9w/Pw¹), t = log(gh/Ph¹) พ 1-여기서 p /p/p/1//Ph는 (1-1)번째 디코더 계층의 예측된 비정규화된 상자 위치 및 크기입니다.표 2는 이러한 수정이 전체 감지 성능을 +2.2 AP만큼 향상시킬 수 있음을 보여줍니다.특히, 작은 객체에서 더 큰 +2.9 AP 개선을 달성합니다.HBox 쿼리 W 축 분해 4-3-2-14--7 -6 --4 -3 -2 -1MLP 7 AX34 AxBa -N-1-NM. ↑ MLP Ду1 ДуBy Box-RPB Attention B 그림 2: 제안된 BoxRPB 방식의 세부 사항을 설명합니다. (왼쪽): 검은색 격자는 입력 이미지를 나타냅니다. 파란색 스케치 영역은 예측된 경계 상자를 나타냅니다. 상자의 왼쪽 위와 오른쪽 아래 모서리를 빨간색 별로 표시합니다. (가운데): BoxRPB는 모든 위치와 x축과 y축을 따라 두 모서리 사이의 오프셋을 계산합니다. 그런 다음 각 축을 따라 오프셋 벡터를 연결하여 (Ax1, Ax2)와 (Ayı, Ay2)를 형성하고 독립적인 MLP를 적용하여 상대적 위치 바이어스 항 Bx와 By를 얻습니다. (오른쪽): B를 브로드캐스트하고 By에 추가하여 2D 상대적 바이어스 항 B를 얻습니다. 주의 값이 더 높은 위치는 빨간색으로, 그렇지 않으면 파란색으로 채색합니다. BoxRPB MIM reparam. AP X ✓ X APS APM APL AP50 AP37.2 63.7 37.6 17.8 40.5 55.46.1 67.6 49.1 27.2 50.5 64.44.6 67.0 48.3 26.9 49.1 59.46.3 68.2 51.1 30.7 51.0 58.48.7 67.7 53.0 31.3 53.1 63.50.9 69.3 55.5 34.2 55.1 65.표 2: 제안된 구성 요소의 코어 절제 결과. 이러한 구성 요소를 장착하면 일반 DETR이 경쟁력 있는 성능을 달성할 수 있습니다. 5. 절제 연구 및 분석 5.1. 상자 상대적 위치 편향의 중요성 표 3에서 우리는 BoxRPB 체계 내의 각 요인의 효과를 연구하고 다음 논의에서 자세한 비교 결과를 보고합니다.축 분해의 효과.분해 없이 2D 상대적 위치를 모델링하는 것은 우리의 축 분해 체계와 비교하면 순진한 기준선이며, (Ax1, Ay1, Ax2, Ay2) Є RK×H×W×로 매개변수화할 수 있습니다.이 기준선은 2차 계산 오버헤드와 메모리 소비가 필요하지만 분해된 기준선은 선형 복잡도에 대한 비용을 줄입니다.표 3a에서 우리는 두 가지 접근 방식을 비교하고 축 분해 체계가 비슷한 성능(50.vs. 50.8)을 달성하는 반면 훨씬 낮은 메모리 풋프린트(9.5G 대 26.8G)와 더 작은 계산 오버헤드(5.8G FLOPS 대 265.4G FLOPs)가 필요하다는 것을 발견했습니다.상자 지점의 효과.표 3b는 중심점만 사용하거나 두 개의 모서리 지점을 사용하는 것을 비교한 것입니다. 중심점만 적용하면 기준선(표 2의 네 번째 행)이 +1.7 AP만큼 향상되는 것을 발견했습니다. 그러나 두 개의 모서리점을 사용하는 것보다 성능이 나쁩니다. 특히 두 방법이 비슷한 AP 결과를 얻는 반면 모서리점을 사용하면 AP 75가 +2.2만큼 향상될 수 있습니다. 이는 쿼리 상자의 위치(중앙)뿐만 아니라 크기(높이와 너비)도 상대적 위치 편향을 정확하게 모델링하는 데 중요하다는 것을 보여줍니다. 숨겨진 차원의 효과. 방정식 5에서 숨겨진 차원의 효과를 연구합니다. 표 3c에서 볼 수 있듯이 숨겨진 차원이 128로 작을수록 성능이 0.5만큼 떨어지므로 위치 관계가 사소하지 않으며 모델링하려면 더 높은 차원의 공간이 필요함을 나타냅니다. 다른 방법과의 비교. 우리는 방정식 2에서 변조 항 B를 계산하기 위해 다른 방식을 선택하는 효과를 연구합니다. 다음과 같이 여러 대표적인 방법과 비교했습니다. (i) 조건부 교차 주의 방식[35]은 조건부 공간(위치) 쿼리 임베딩과 공간 키 임베딩 간의 내적을 기반으로 변조 항을 계산합니다. (ii) DAB 교차 주의 방식[31]은 조건부 교차 주의에 기반하고 상자 너비와 높이 정보를 사용하여 위치 주의 맵을 추가로 변조합니다. (iii) 공간 변조 교차 주의 방식(SMCA)[16]은 2D 가우시안 유사 가중치 맵으로 구현된 수작업 쿼리 공간 사전 확률을 설계하여 주의된 특징이 객체 쿼리의 초기 추정치 주변에 있도록 제한합니다. 표 3d는 자세한 비교 결과를 보고합니다. 우리의 접근 방식은 모든 방법 중에서 가장 좋은 성능을 달성합니다. 구체적으로, 조건부 교차 주의 모듈은 우리의 중심 전용 설정(표 3b의 첫 번째 행)으로 유사한 성능을 달성합니다. DAB 교차 어텐션과 SMCA는 조건부 교차 어텐션 모듈보다 약간 더 나았지만, 여전히 BoxRPB보다 각각 2.5 AP와 2.2 AP 뒤처져 있습니다. 또한 BoxRPB를 공식 오픈소스 코드를 기반으로 DAB 교차 어텐션과 비교합니다. DAB 위치 모듈을 BoxRPB로 대체하면 +1.8 mAP 성능 향상을 달성합니다. 5.2. 로컬 어텐션 스키마와의 비교 이 섹션에서는 글로벌 어텐션 스키마를 다른 대표적인 로컬 교차 어텐션 메커니즘인 hidden dim. AP AP 50 APmethod AP AP 50 APdecomp. mem.과 비교했습니다. GFLOPS AP AP 50 APbox 포인트 AP AP 50 APX 26.8G 265.4 50.8 69.3 55.center ✓ 48.0 69.0 53.2x corners 50.9 69.3 55.9.5G 5.8 50.9 69.3 55.(a) 축 분해.(b) 박스 포인트.(d) 교차 주의 변조.표 3: 박스 상대 위치 바이어스 계획의 제거.(a) 축 분해는 계산 오버헤드와 GPU 메모리 사용량을 크게 줄일 수 있습니다.(b) 코너 포인트는 중심 포인트보다 성능이 좋습니다.(c) 숨겨진 차원이 높을수록 성능이 더 좋습니다. (d) 우리의 접근 방식은 교차 주의 맵을 조절하도록 설계된 다른 관련 방법보다 훨씬 더 나은 성과를 보입니다.50.4 69.1 55.50.9 69.4 55.50.9 69.3 55.표준 교차 주의.조건부 교차 주의.DAB 교차 주의.SMCA 교차 주의.46.3 68.2 51.48.3 68.8 52.48.4 68.9 53.48.7 69.2 53.우리의 50.9 69.3 55.(c) 숨겨진 희미함. 1/1/1/1/(a) (C³‚Cª,C5) → (P³, Pª, P5) Transformer Decoder 1/1/1/1/三十三 1/1/1/1/(b) (C3, C4, C5)→ P (c) C→P1/Transformer Decoder 그림 3: 백본에서 출력하여 Transformer 디코더로 전송한 다른 피처 맵을 사용할 때의 아키텍처 설계를 비교합니다. (a)에서 (b)로, 다중 스케일 피처 맵을 Transformer 디코더로 전송하는 것에 대한 종속성을 단순화합니다. (b)에서 (c)로, 백본에서 출력한 다중 스케일 피처를 융합하는 것에 대한 종속성을 제거합니다. (c)를 기본 아키텍처 설정으로 채택합니다. MIM AP AP 50 AP75 APS APM APL 방법 변형 가능 교차 주의. RolAlign Rol 샘플링 박스 마스크 Ours AP AP 50 AP75 APS APM 50.2 68.5 54.8 34.1 54.4 63.49.6 68.3 54.1 31.9 54.63.49.3 68.2 53.8 33.1 53.2 63.48.6 68.7 52.9 31.8 52.7 63.50.9 69.3 55.5 34.2 55.1 65.APL 백본 디코더 (C3, C4, C5) (P3, P4, P5) (C3, C4, C5)→ (P³, P4, P5) X 49.6 69.2 53.8 31.5 53.4 65.▼ 51.1 69.3 56.0 34.8 55.4 65.(a) 백본 디코더 MIM → PX PX 49.6 69.8 53.4 31.표 4: 로컬 크로스 어텐션 방식과의 비교. BoxRPB를 사용한 글로벌 크로스 어텐션은 모든 로컬 크로스 어텐션 대응책보다 성능이 뛰어나고 대형 객체에서 상당한 이득을 얻습니다. X → P✓ → PC5) → P³ ✓ AP AP 50 AP75 APS APM APL 47.0 68.2 50.4 28.0 51.5 64.53.7 65.49.7 69.8 53.9 32.7 53.5 65.50.3 69.3 54.9 33.4 54.7 64.51.0 69.4 55.7 34.5 55.1 65.50.9 69.2 55.4 34.4 55.0 64.(b) 변형 가능한 교차 주의[55], RoIAlign[21], RoI 샘플링(관심 영역 내의 고정 포인트 샘플링) 및 [7]에서 영감을 받은 상자 마스크 포함. 보충 자료에서 이러한 방법 간의 주요 차이점을 설명합니다. 표 4에 표시된 것처럼, 우리의 방법은 모든 로컬 교차 주의 변형을 능가합니다.또한, 우리는 큰 객체가 우리 방법에 대한 개선 사항이 더 크다는 것을 관찰했습니다.DETR[4]에서도 유사한 관찰 결과가 보고되었는데, 이는 글로벌 주의 체계를 기반으로 한 보다 효과적인 장거리 컨텍스트 모델링 때문일 수 있습니다.5.3. MIM 사전 학습에 관하여 우리는 MIM 사전 학습이 있거나 없는 백본 및 디코더 피처 맵을 사용하는 다양한 방법을 탐구합니다.그림 3에 나와 있는 세 가지 다른 아키텍처 구성의 성능을 평가합니다.우리는 다음과 같이 결과를 논의하고 분석합니다. 백본 디코더 MIM → PC5 → PPC→ PC→P→ PAP AP 50 AP75 APS APM APL 46.4 67.7 49.7 26.9 50.5 64.48.0 68.7 51.8 30.4 52.2 64.48.7 69.1 52.6 30.7 52.9 64.50.2 69.1 55.0 33.5 54.5 64.50.9 69.3 55.5 34.2 55.1 65.50.9 69.2 55.7 34.6 54.9 65.(c) 표 5: MIM 사전 학습의 삭제. (a) 백본에서 출력한 다중 스케일 특징 맵 + Transformer 디코더용 다중 스케일 특징 맵. (b) 백본에서 출력한 다중 스케일 피처 맵 + Transformer 디코더용 단일 스케일 피처 맵.(c) 백본에서 출력한 단일 스케일 피처 맵 + Transformer 디코더용 단일 스케일 피처 맵.MIM 사전 학습은 일관된 이득을 제공합니다.동일한 아키텍처 config-method Cascade Mask R-CNN[3]에서 실험 결과를 비교하면 당사 AP AP50 AP75 APS APM APL 53.7 71.9 58.7 36.9 57.4 69.53.8 73.4 58.9 35.9 57.0 68.표 6: MIM 사전 학습된 ViT-Base 백본을 사용한 개선된 일반 DETR과 Cascade Mask R-CNN의 비교. 글로벌 교차 주의가 적용된 당사 일반 DETR은 영역 기반 다중 스케일 Cascade Mask R-CNN보다 약간 더 좋습니다. 기린의 실험에서 MIM 사전 학습을 사용하면 지속적으로 더 나은 성능을 얻을 수 있음을 발견했습니다. 예를 들어, 표 5에서 볼 수 있듯이 MIM 사전 학습을 사용하면 (C3, C4, C5) → (P3, P4, P5) 구성에서 1.5 AP, C5 → Pª 구성에서 2.9 AP만큼 감독 사전 학습을 사용하는 것보다 성능이 우수합니다. 디코더의 다중 스케일 피처 맵을 제거할 수 있습니다. 표 5a와 표 5b의 결과를 비교하여 고해상도 피처 맵을 사용하면 다중 스케일 피처 맵을 사용하는 성능과 동일하거나 더 뛰어날 수 있음을 발견했습니다. 예를 들어, (C3, C4, C5) → P³는 MIM 사전 학습을 사용하거나 사용하지 않고도 (C3, C4, C5) → (P3, P4, P5)와 비슷한 성능을 얻습니다. 이러한 관찰은 대부분의 기존 감지 헤드가 여전히 입력으로 다중 스케일 피처가 필요하기 때문에 사소한 것이 아니며 경쟁력 있는 단일 스케일 일반 DETR을 구축하는 것이 가능합니다. 우리는 이 발견이 미래의 탐지 프레임워크 설계를 용이하게 할 수 있기를 바랍니다.백본에서 다중 스케일 특징 맵은 불필요합니다.표 5b와 표 5c의 결과를 비교하여 백본에서 다중 스케일 특징 맵을 제거하는 효과를 분석합니다.지도 학습된 사전 훈련된 백본을 사용하는 경우 백본에서 마지막 특징 맵 C5만 채택하면 성능이 저하됩니다.예를 들어, 지도 학습된 사전 훈련된 백본을 사용하는 경우 C5 P5는 46.4 AP에 도달하여 (C3, C4, C5) P5(47.0 AP)보다 0.6 AP만큼 나쁩니다.그러나 MIM 사전 훈련된 백본을 사용하는 경우 C5 → P5는 50.2 mAP에 도달하여 (C3, C4, C5) P5(50.3 AP)의 성능과 비슷합니다.이러한 결과는 MIM 사전 훈련이 다중 스케일 특징 맵에 대한 의존도를 줄일 수 있음을 보여줍니다. → 백본의 단일 스케일 피처 맵과 디코더의 단일 스케일 피처 맵이면 충분합니다.위의 관찰 결과를 바탕으로 제안된 BoxRPB 방식과 MIM 사전 학습을 사용하여 백본과 Transformer 디코더 모두에서 다중 스케일 피처 맵의 필요성을 완전히 없앨 수 있다는 놀라울 정도로 간단하지만 중요한 결론에 도달할 수 있습니다.5.4. 일반 ViT에 대한 응용 이 섹션에서는 접근 방식을 적용하여 간단하고 효과적인 완전 일반 객체 감지 시스템을 구축합니다.그림 4: BoxRPB가 있거나 없는 모델의 교차 어텐션 맵 시각화.각 그룹의 첫 번째 열은 입력 이미지와 객체 쿼리를 보여줍니다.첫 번째 행은 BoxRPB가 있는 모델의 어텐션 맵을 나타내고 두 번째 행은 BoxRPB가 없는 모델의 어텐션 맵을 표시합니다.BoxRPB는 교차 어텐션이 개별 객체에 집중하도록 안내합니다.일반 ViT에 [13].우리 시스템은 다중 스케일 설계나 처리 없이 일반 Transformer 인코더-디코더 아키텍처 전체에서 단일 해상도 피처 맵만 사용합니다. 우리는 COCO 데이터 세트에서 최첨단 Cascade Mask R-CNN [3, 28]과 우리의 접근 방식을 비교합니다. 공정한 비교를 위해 우리는 MAE [20] 사전 학습된 ViT-Base를 백본으로 사용하고 ~50에포크 동안 객체 감지기를 학습합니다. 표 8에서 볼 수 있듯이, 우리의 방법은 다양한 객체 스케일에서 더 나은 로컬라이제이션을 위해 다중 스케일 피처 맵을 사용하는 Cascade Mask R-CNN과 비슷한 결과를 얻습니다. 주목할 점은 우리의 방법이 일반적으로 객체 감지에 유익하다고 여겨지는 인스턴스 마스크 주석으로 학습하지 않는다는 것입니다. 5.5. 교차 주의 맵의 시각화 그림 4는 BoxRPB가 있거나 없는 모델의 교차 주의 맵을 보여줍니다. BoxRPB가 있는 모델의 경우 교차 주의는 개별 객체에 집중합니다. 반대로 BoxRPB가 없는 모델의 교차 주의는 비슷한 모양을 가진 여러 객체에 주의를 기울입니다. 6. 시스템 수준 결과 이 섹션에서는 우리의 방법을 다른 최첨단 방법과 비교합니다. 표 7은 결과를 보여주며, 이 표에 보고된 모든 실험은 Swin-Large를 백본으로 활용했습니다. 다른 작업에서는 일반적으로 백본 기능을 향상시키기 위해 인코더를 적용하므로, 우리도 12개의 창 기반 단일 스케일 변환기 레이어(기능 차원 방법 프레임워크 추가 데이터 #params #epoch AP AP50 AP75 APS APM APL Swin [34] HTC 284M57.76.63.33.52.64.DETA [36] DETR 218M58.76.64.38.62.73.DINO-DETR [54] DETR 218M58.76.64.39.61.73.Ours* DETR 228M60.78.66.42.62.73.DETA [36] DETR218M 24 +63.80.70.46.66.76.DINO-DETR [54]* DETR218M 26 +63.Ours* DETR228M 24 +63.82.70.48.66.76.표 7: COCO 테스트 개발에서 최신 결과와 시스템 수준 비교. 모든 방법은 Swin-Large 백본을 채택합니다. 결과는 테스트 시간 증가로 표시됩니다. 공정한 비교를 위해 백본 위에 256의 시간당 평균(AP)을 적용합니다. 36개의 학습 에포크에서 모델은 COCO 테스트 개발 세트에서 60.0 AP를 달성하여 DINO-DETR보다 1.4 AP 더 우수합니다. 사전 학습 데이터 세트로 Objects365[40]를 추가로 도입하여 방법은 테스트 개발 세트에서 63.9 AP에 도달하여 DINO-DETR 및 DETA보다 상당한 차이로 더 우수합니다. 이러한 강력한 결과는 일반 DETR 아키텍처가 고성능을 달성하는 데 방해가 되는 본질적인 단점이 없음을 확인합니다. 7.
--- RELATED WORK ---
DETR 기반 객체 감지. DETR[4]은 개념적으로 간단하고 적용성이 일반적이며, 사용자 지정 레이블 할당과 비최대 억제를 피하는 최소한의 도메인 지식이 필요하고 단순하다는 등 여러 장점으로 이 분야에 깊은 인상을 남겼습니다. 원래 DETR은 단순한 디자인을 유지하지만 수렴 속도가 느리고 감지 정확도가 낮다는 단점이 있습니다. [35, 16, 9, 47, 55, 53, 52, 17, 54]를 포함한 많은 후속 작업이 있었고, 이제 다중 스케일 및 지역성 디자인의 재도입 덕분에 이 작업 라인을 기반으로 많은 최고 객체 감지기가 구축되었습니다. [54, 14, 46]. 이러한 주요 작업과 달리, 우리는 다중 스케일 특징과 지역 교차 주의 계산 없이 &quot;단순한&quot; 특성을 유지하는 개선된 DETR 프레임워크를 목표로 합니다. 영역 기반 객체 감지. DETR 프레임워크 이전에는 객체 탐지기가 일반적으로 영역 기반 방식으로 구축되었습니다. 알고리즘은 전체 이미지의 모든 영역을 로컬하게 분석하고 객체 탐지는 각 영역의 결과를 순위를 매기고 필터링하여 얻습니다. 지역적 특성으로 인해 객체 탐지를 위해 전역 정보를 유연하게 활용하기 어렵습니다. 게다가 일부 초기 시도에서는 머리에 단일 스케일 피처 맵을 사용하지만[19, 38, 18, 39, 32], 나중에는 선두
--- METHOD ---
s는 이 궤적을 따릅니다. 원래 DETR 접근 방식[4]은 다중 스케일 기능 맵 및 특정 객체 감지 문제에 대한 전담 이해가 필요한 영역 기반 기능 추출과 같은 복잡하고 도메인별 설계를 버렸다는 점에서 인상적입니다. 그러나 이 분야의 후속 개발[55, 54]은 이러한 설계를 다시 도입하여 학습 속도와 정확도를 개선했지만 &quot;귀납적 편향 감소&quot;의 원칙[13]에도 위배됩니다. 이 작업에서 우리는 원래 DETR 감지기를 개선하는 동시에 다중 스케일 피처 맵이 없고 교차 주의 계산을 위한 지역성 디자인이 없는 &quot;평범한&quot; 특성을 유지하는 것을 목표로 합니다. 객체 감지기는 다양한 스케일과 위치의 객체를 처리해야 하므로 이는 어렵습니다. 표 1에 표시된 대로 학습 및 문제 공식화의 최신 개선에도 불구하고 일반 DETR 방법은 다중 스케일 피처 맵과 지역적 피처 추출 디자인을 활용하는 최첨단 감지기에 비해 여전히 크게 뒤처져 있습니다. 그렇다면 다중 스케일 및 임의로 위치한 객체를 처리할 때 이러한 구조적 &quot;귀납적 편향&quot;을 어떻게 보상할 수 있을까요? 우리의 탐구 결과 완전히 새로운 것은 아니지만 이 맥락에서 놀랍도록 효과적인 두 가지 간단한 기술인 박스 대 픽셀 상대 위치 편향(BoxRPB)과 마스크 이미지 모델링(MIM) 사전 학습이 발견되었습니다. BoxRPB는 픽셀 간의 기하학적 관계를 인코딩하고 변환 불변성을 향상시키는 비전 트랜스포머[34, 33]의 상대 위치 편향(RPB) 항에서 영감을 받았습니다. BoxRPB는 RPB를 확장하여 4d 상자와 2d 픽셀 간의 기하학적 관계를 인코딩합니다. 또한 전체 항을 사용하는 것과 비교하여 정확도가 손실되지 않는 효율적인 계산을 위한 축 분해 접근 방식을 제시합니다.
--- EXPERIMENT ---
s는 BoxRPB 항이 교차 주의 계산을 개별 객체에 잘 전담하도록 잘 안내할 수 있음을 보여줍니다(그림 4 참조, COCO 벤치마크에서 37.2mAP의 일반 DETR 기준선보다 +8.9mAP만큼 탐지 정확도를 극적으로 향상시킵니다(표 2 참조). MIM 사전 학습 활용은 일반 DETR의 성능을 향상시키는 또 다른 중요한 기술입니다. 저희의 결과는 또한 일반 DETR 기준선보다 +7.4mAP의 상당한 개선을 보여줍니다(표 2 참조). 이는 세밀한 위치 지정 기능 때문일 수 있습니다[49]. MIM 사전 학습은 다른 탐지기의 성능을 적당히 향상시키는 것으로 나타났지만[20, 50] 일반 설정에서의 영향은 엄청납니다. 더욱이 이 기술은 백본에서 다중 스케일 피처 맵을 사용할 필요성을 없애는 데 중요한 요인임이 입증되었으며, [28, 15]의 결과를 계층적 백본이나 단일 스케일 헤드를 활용하는 탐지기로 확장했습니다. 이러한 기술과 최신 기술을 통합하여 훈련과 문제 공식화 모두에서 개선된 우리의 개선된 &quot;일반&quot; DETR은 그림 1에서 볼 수 있듯이 원래 DETR 감지기에 비해 뛰어난 개선을 보였습니다. 나아가, 우리의 방법은 사전 훈련을 위해 Object365 데이터 세트를 활용할 때 63.9mAP의 정확도를 달성하여 다중 스케일 피처 맵과 캐스케이드 R-CNN[33] 및 DINO[54]와 같은 영역 기반 피처 추출 기술에 의존하는 최첨단 객체 감지기와 매우 경쟁력이 있습니다. 이러한 결과 외에도, 우리의 방법론은 탐지 특정 다중 스케일 및 로컬화된 디자인에 의존하는 것과 달리 효과적인 작업별 헤드 또는 디코더를 설계할 때 구조적 &quot;귀납적 편향&quot;을 최소화하는 방법을 보여줍니다. 우리의 연구는 최소한의 노력으로 더 광범위한 시각 문제에 대해 DETR과 같은 일반적인 일반 디코더를 사용하는 것에 대한 미래 연구에 영감을 주어, 이 분야가 자연어 처리 분야에서 발생하는 것과 유사한 대규모 기초 시각 모델을 개발하는 데 더 많은 에너지를 쏟을 수 있기를 바랍니다. 2. 현대화된 일반 DETR 기준선 2.1. 원래 DETR 검토 원래 DETR 감지기[4]는 3개의 하위 네트워크로 구성됩니다.· 이미지에서 이미지 특징을 추출하는 백본 네트워크 F₁. 입력 이미지를 IЄRH H ×W×³¸로 표시합니다.· 백본 네트워크는 기존 ConvNet(예: ResNet[22])을 사용하는 경우 다중 스케일 특징 맵 C² 3, C4, C5를 제공할 수 있습니다.· 공간 해상도는 일반적으로 입력 이미지의 1/42, 1/82, 1/162, 1/32²입니다.· 원래 DETR 감지기는 당시 주류 백본 아키텍처인 ResNet을 백본 네트워크로 사용했으며, 원래 ResNet 또는 확장된 5단계 네트워크가 있는 변형을 사용했습니다.· 이제 주류 백본 네트워크는 실험에 사용될 비전 Transformers(예: Swin Transformer[34])로 발전했습니다. • 이미지 특징을 강화하기 위한 Transformer 인코더 Fe. C5에서 선형 투영을 통해 얻은 P5 ERXC(C=256)에 적용됩니다. Transformer 인코더는 일반적으로 여러 개의 스태킹 Transformer 블록(즉, 원래 DETR의 6개)으로 구성됩니다. = • 임의로 초기화된 객체 쿼리 Q{q0, q1, qn} 세트를 사용하여 이미지 특징 맵에서 객체 경계 상자를 디코딩하는 글로벌 Transformer 디코더 Få. Transformer 디코더는 또한 일반적으로 여러 계층으로 구성되며 각 계층에는 셀프 어텐션 블록, 크로스 어텐션 블록 및 피드 포워드 블록이 포함됩니다. 각 디코더 계층은 집합 일치 손실에 의해 구동되는 레이블과 경계 상자가 있는 객체 집합을 생성합니다. DETR 프레임워크는 다음을 포함하여 여러 가지 장점이 있습니다. 1) 개념적으로 간단하고 적용성이 일반적입니다. 이것은 객체 감지를 이미지 픽셀을 문제 대상으로 디코딩하는 일반적인 개념과 함께 픽셀에서 객체로의 &quot;변환&quot; 작업으로 봅니다. 2) 엔드투엔드 세트 매칭 손실을 사용하기 때문에 사용자 정의 레이블 할당 및 수작업으로 설계된 비최대 억제와 같은 최소한의 도메인 지식이 필요합니다. 3) 단순하여 도메인별 다중 스케일 피처 맵 및 영역 기반 피처 추출을 피합니다. 다음에서 먼저 위의 좋은 장점을 유지하면서 훈련 및 문제 공식화와 관련된 최근의 발전을 통합하여 향상된 DETR 기반 감지기를 빌드합니다. 2.2. 향상된 일반 DETR 기준 기본 설정. 기본 설정은 다음과 같은 조정을 제외하고 대부분 원래 DETR 프레임워크를 따릅니다. 1) 원래 ResNet50 백본 대신 더 강력한 Swin-T 백본을 사용합니다. 2) 단순성을 위해 백본의 마지막 단계에 팽창 연산을 추가하는 대신 디컨볼루션을 통해 C5에서 P4의 피처 맵을 만듭니다. 3) 우리는 쿼리는 300이고 Transformer 디코더의 드롭아웃 비율은 0입니다. 4) 효율적인 절제 연구를 위해 1× 스케줄러 설정(12 에포크)을 사용합니다. 표 1에서 볼 수 있듯이 이 기본 설정은 COCO val에서 22.5 mAP를 생성합니다. 다음에서 기본 설정에 최근의 학습 및 문제 공식화 진전을 통합하고 표 1에서 볼 수 있듯이 탐지 정확도를 점차적으로 37.mAP로 개선합니다. Transformer 인코더를 백본에 병합. 백본 네트워크와 Transformer 인코더는 이미지 특징을 인코딩하는 동일한 목적을 제공합니다. Vision Transformer 백본을 활용하면 Transformer 인코더의 계산 예산을 백본에 통합할 수 있으며 약간의 개선이 있었습니다. 아마도 더 많은 매개변수가 사전 학습되었기 때문일 것입니다. 구체적으로 Swin-S 백본을 사용하고 Transformer 인코더를 제거했습니다. 이 방법은 원래 Swin-T와 6계층 Transformer 인코더에 비해 유사한 계산 FLOPS를 보였습니다. 이 접근 방식은 전체 DETR 프레임워크를 단순화하여 백본(인코더)과 디코더 네트워크로만 구성합니다.더 나은 분류를 위한 초점 손실. [55]에 따라 기본 교차 엔트로피 손실을 대체하기 위해 초점 손실 [30]을 활용하여 감지 정확도를 23.1mAP에서 31.6mAP로 크게 향상시킵니다.반복적 정제. 반복적 정제 방식 [43, 55, 3]에 따라 각 디코더 계층이 이전 디코더 계층에서 생성된 최신 바운딩 박스에 대한 박스 델타를 예측하도록 하는 반면, 각 Transformer 디코더 계층 내에서 독립적인 예측을 사용하는 원래 DETR과 다릅니다.이 전략은 감지 정확도를 +1.mAP만큼 향상시켜 33.1mAP에 도달합니다.콘텐츠 관련 쿼리. [55]에 따라 이미지 콘텐츠를 기반으로 개체 쿼리를 생성합니다.가장 신뢰도가 높은 상위 300개 예측이 후속 디코딩 프로세스에 대한 쿼리로 선택됩니다.객체 쿼리 생성에는 집합 일치 손실이 사용되므로 도메인별 레이블 할당 전략이 없다는 장점이 유지됩니다. 이 수정으로 감지 정확도가 +0.9 mAP 향상되어 34.0 mAP에 도달했습니다. 두 번 탐색. 이전 Transformer 디코더 계층의 정제된 상자 정보를 활용하기 위해 두 번 탐색 탐색 방식[54, 26]을 통합하여 인접한 Transformer 디코더 계층에서 매개변수를 보다 효과적으로 최적화합니다. 이 수정으로 +0.8 mAP 향상이 발생합니다. 혼합 쿼리 선택. 이 방법[54]은 정적 콘텐츠 쿼리와 이미지 적응 위치 쿼리를 결합하여 더 나은 쿼리 표현을 형성합니다. +0.4 mAP 향상이 발생합니다. 하이브리드 매칭. 원래 일대일 세트 매칭은 양성 샘플을 훈련하는 데 효과가 떨어집니다. MTE FL IR TS LFT MQS HM AP ✓ XXXX 22.☑ X 23.X ☑ 31.X 33.☑ 34.34.Χ 35.37이 있었습니다.표 1: 일반 DETR을 현대화하는 데 사용되는 각 요소의 효과에 대한 예비적 절제 결과. MTE: Transformer 인코더 병합. FL: 초점 손실로서의 분류 손실.IR: 반복적 정제.TS: 2단계.LFT: 두 번 기대.MQS: 혼합 쿼리 선택.HM: 하이브리드 매칭.보조적인 일대다 세트 매칭 손실을 통해 효능을 개선하는 여러 방법[26, 6, 27].우리는 추가적인 수동 레이블링 노이즈 또는 할당 설계가 필요하지 않다는 이점을 유지하기 때문에 하이브리드 매칭 접근 방식[26]을 선택했습니다.이 수정으로 감지 정확도가 +2.mAP 향상되어 최종 37.2mAP를 달성했습니다.3. 상자 대 픽셀 상대 위치 바이어스 이 섹션에서는 다중 스케일 기능의 부족과 명시적 로컬 교차 주의 계산을 보상하는 데 중요한 것으로 입증된 간단한 기술인 상자 대 픽셀 상대 위치 바이어스(BoxRPB)를 소개합니다.원래의 DETR 디코더는 표준 교차 주의 계산을 채택합니다.= Softmax(QKT)V+X, (1) 여기서 X와 O는 각각 각 객체 쿼리의 입력 및 출력 기능입니다. Q, K 및 V는 각각 쿼리, 키 및 값 특징입니다.그림 4에서 볼 수 있듯이 원래의 교차 주의 공식화는 종종 일반 DETR 프레임워크 내의 무관한 이미지 영역에 주의를 기울입니다.이것이 다중 스케일 및 명시적 지역성 디자인보다 정확도가 훨씬 낮은 이유일 수 있다고 추측합니다.비전 트랜스포머 아키텍처[34, 33]에 대한 픽셀 간 상대 위치 바이어스의 성공에서 영감을 받아 교차 주의 계산에 상자 간 상대 위치 바이어스(BoxRPB)를 사용하는 방법을 살펴봅니다.= (2) = Softmax(QKT + B)V + X, 여기서 B는 상자와 픽셀 간의 기하학적 관계에 의해 결정되는 상대 위치 바이어스입니다.2d 상대 위치에서 정의된 원래의 상대 위치 바이어스(RPB)와 달리 BoxRPB는 더 큰 4d 기하학적 공간을 처리해야 합니다.다음에서 두 가지 구현 변형을 소개합니다.Naive BoxRPB 구현. 우리는 4d-박스-픽셀 상대 위치 바이어스를 계산하기 위해 연속 RPB 방법[33]을 적용합니다. 원래 연속 RPB 방법[33]은 해당 2d-상대 좌표에 적용된 메타 네트워크에 의해 각 상대 위치 구성에 대한 바이어스 항을 생성합니다. 이 방법을 BoxRPB에 확장할 때 우리는 왼쪽 위와 오른쪽 아래 모서리를 사용하여 상자를 나타내고 이러한 모서리 점과 이미지 픽셀 점 사이의 상대 위치를 메타 네트워크의 입력으로 사용합니다. 상대 좌표를 (Ax1, Ayı) € RK×H×W×2 및 (Ax2, Ay2) € RKXHXWX2로 표시하면 상자 대 픽셀 상대 위치 편향은 다음과 같이 정의할 수 있습니다. (3) B MLP(Ax1, Ay1, Ax2, Ay2), 여기서 B는 RKXWHXM 모양이고 M은 어텐션 헤드 수를 나타내고 K는 예측된 바운딩 박스 수를 나타내고 W, H는 출력 피처 맵의 너비와 높이를 나타냅니다. MLP 네트워크는 두 개의 선형 레이어로 구성됩니다. 선형 → ReLU 선형. 이 두 선형 레이어의 입력/출력 모양은 각각 K×H×W×4→KxHxWx×256 및 KxHxWx256→K×H×W×M입니다. 실험 결과 이러한 단순한 구현이 표 3a에서 볼 수 있듯이 이미 매우 효과적으로 수행된다는 것을 보여줍니다. 그러나 많은 GPU 계산과 메모리 예산을 소모하므로 실용적이지 않습니다. 이제 우리는 분해된 BoxRPB 구현을 제시합니다.BoxRPB의 보다 효율적인 구현을 제시합니다.4d 입력에 대한 바이어스 항을 직접 계산하는 대신 바이어스 계산을 두 항으로 분해하는 것을 고려합니다.(4) B = unsqueeze (Bx, 1) + unsqueeze (By, 2), 여기서 BÃ € Rк×W×M과 By Є RK×H×M은 각각 x축과 y축에 대한 바이어스입니다.다음과 같이 계산합니다.Bx = MLP1(Ax1, Ax2), By MLP2 (Ay1, Ay2), (5) 분해된 BoxRPB 구현의 전체 프로세스도 그림 2에 나와 있습니다.MLP1 내의 두 선형 계층의 입력/출력 모양은 각각 KXWX2→K×W×256과 K×W×256→K×W×M입니다.마찬가지로 MLP2 내의 두 선형 계층에 대한 입력/출력 모양은 동일한 패턴을 따릅니다. 분해를 통해 계산 FLOPS와 메모리 소비가 모두 크게 감소하는 반면 정확도는 거의 유지됩니다(표 3a 참조). 이 분해 기반 구현은 실험에서 기본적으로 사용됩니다. 그림 4는 교차 주의 계산을 위한 이 추가 BoxRPB 항의 효과를 보여줍니다. 일반적으로 BoxRPB 항은 주의를 객체와 상자 경계에 더 집중시키는 반면 BoxRPB가 없는 교차 주의는 많은 무관한 영역에 주의를 기울일 수 있습니다. 이는 표 2에 표시된 대로 BoxRPB 항에 의해 정확도가 크게 향상된(+8.9 mAP) 이유를 설명할 수 있습니다. 4. 추가 개선 사항 이 섹션에서는 일반 DETR 프레임워크를 추가로 개선할 수 있는 두 가지 다른 기술을 소개합니다. MIM 사전 학습. 더 나은 지역성[49]을 보여준 마스크 이미지 모델링 사전 학습[1, 20, 51, 28]의 최근 발전을 활용합니다. 구체적으로, 레이블 없이 ImageNet에서 학습한 SimMIM 사전 학습된 가중치로 Swin 변환기 백본을 초기화합니다([51] 참조). 표 2에 표시된 대로 MIM 사전 학습은 일반 DETR 기준선보다 +7.mAP 향상을 가져옵니다. 다른 감지기보다 일반 DETR 프레임워크에서 MIM 사전 학습의 엄청난 이득은 일반 DETR 프레임워크에 대한 학습된 현지화 기능의 중요성을 강조할 수 있습니다. BoxRPB가 관련된 더 높은 기준선에서 MIM 사전 학습은 여전히 +2.6 mAP 이득을 낼 수 있어 48.7 mAP에 도달할 수 있습니다. 게다가 MIM 사전 학습은 표 5b 및 5c에서 볼 수 있듯이 정확도 손실 없이 다중 스케일 백본 기능을 포기하는 데도 중요하다는 점에 유의합니다. 재매개변수화를 사용한 경계 상자 회귀. 강조하고 싶은 또 다른 개선 사항은 경계 상자 회귀를 수행할 때 경계 상자 재매개변수화입니다. 원래 DETR 프레임워크[4]와 대부분의 변형은 상자 중심과 크기를 [0,1]로 직접 조정합니다. 손실 계산을 지배하는 큰 개체로 인해 작은 개체를 감지하는 데 어려움이 있습니다. 대신, 우리는 상자 중심과 1번째 디코더 계층의 크기를 다음과 같이 재매개변수화합니다.t₁₂ = (9x − P²x² ¹³)/Pw &quot; 1-&quot; (6) ty = (gy - Py¹)/Ph tw = log(9w/Pw¹), t = log(gh/Ph¹) พ 1-여기서 p /p/p/1//Ph는 (1-1)번째 디코더 계층의 예측된 비정규화된 상자 위치 및 크기입니다.표 2는 이러한 수정이 전체 감지 성능을 +2.2 AP만큼 향상시킬 수 있음을 보여줍니다.특히, 작은 객체에서 더 큰 +2.9 AP 개선을 달성합니다.HBox 쿼리 W 축 분해 4-3-2-14--7 -6 --4 -3 -2 -1MLP 7 AX34 AxBa -N-1-NM. ↑ MLP Ду1 ДуBy Box-RPB Attention B 그림 2: 제안된 BoxRPB 방식의 세부 사항을 설명합니다. (왼쪽): 검은색 격자는 입력 이미지를 나타냅니다. 파란색 스케치 영역은 예측된 경계 상자를 나타냅니다. 상자의 왼쪽 위와 오른쪽 아래 모서리를 빨간색 별로 표시합니다. (가운데): BoxRPB는 모든 위치와 x축과 y축을 따라 두 모서리 사이의 오프셋을 계산합니다. 그런 다음 각 축을 따라 오프셋 벡터를 연결하여 (Ax1, Ax2)와 (Ayı, Ay2)를 형성하고 독립적인 MLP를 적용하여 상대적 위치 바이어스 항 Bx와 By를 얻습니다. (오른쪽): B를 브로드캐스트하고 By에 추가하여 2D 상대적 바이어스 항 B를 얻습니다. 주의 값이 더 높은 위치는 빨간색으로, 그렇지 않으면 파란색으로 채색합니다. BoxRPB MIM reparam. AP X ✓ X APS APM APL AP50 AP37.2 63.7 37.6 17.8 40.5 55.46.1 67.6 49.1 27.2 50.5 64.44.6 67.0 48.3 26.9 49.1 59.46.3 68.2 51.1 30.7 51.0 58.48.7 67.7 53.0 31.3 53.1 63.50.9 69.3 55.5 34.2 55.1 65.표 2: 제안된 구성 요소의 코어 절제 결과. 이러한 구성 요소를 장착하면 일반 DETR이 경쟁력 있는 성능을 달성할 수 있습니다. 5. 절제 연구 및 분석 5.1. 상자 상대적 위치 편향의 중요성 표 3에서 우리는 BoxRPB 체계 내의 각 요인의 효과를 연구하고 다음 논의에서 자세한 비교 결과를 보고합니다.축 분해의 효과.분해 없이 2D 상대적 위치를 모델링하는 것은 우리의 축 분해 체계와 비교하면 순진한 기준선이며, (Ax1, Ay1, Ax2, Ay2) Є RK×H×W×로 매개변수화할 수 있습니다.이 기준선은 2차 계산 오버헤드와 메모리 소비가 필요하지만 분해된 기준선은 선형 복잡도에 대한 비용을 줄입니다.표 3a에서 우리는 두 가지 접근 방식을 비교하고 축 분해 체계가 비슷한 성능(50.vs. 50.8)을 달성하는 반면 훨씬 낮은 메모리 풋프린트(9.5G 대 26.8G)와 더 작은 계산 오버헤드(5.8G FLOPS 대 265.4G FLOPs)가 필요하다는 것을 발견했습니다.상자 지점의 효과.표 3b는 중심점만 사용하거나 두 개의 모서리 지점을 사용하는 것을 비교한 것입니다. 중심점만 적용하면 기준선(표 2의 네 번째 행)이 +1.7 AP만큼 향상되는 것을 발견했습니다. 그러나 두 개의 모서리점을 사용하는 것보다 성능이 나쁩니다. 특히 두 방법이 비슷한 AP 결과를 얻는 반면 모서리점을 사용하면 AP 75가 +2.2만큼 향상될 수 있습니다. 이는 쿼리 상자의 위치(중앙)뿐만 아니라 크기(높이와 너비)도 상대적 위치 편향을 정확하게 모델링하는 데 중요하다는 것을 보여줍니다. 숨겨진 차원의 효과. 방정식 5에서 숨겨진 차원의 효과를 연구합니다. 표 3c에서 볼 수 있듯이 숨겨진 차원이 128로 작을수록 성능이 0.5만큼 떨어지므로 위치 관계가 사소하지 않으며 모델링하려면 더 높은 차원의 공간이 필요함을 나타냅니다. 다른 방법과의 비교. 우리는 방정식 2에서 변조 항 B를 계산하기 위해 다른 방식을 선택하는 효과를 연구합니다. 다음과 같이 여러 대표적인 방법과 비교했습니다. (i) 조건부 교차 주의 방식[35]은 조건부 공간(위치) 쿼리 임베딩과 공간 키 임베딩 간의 내적을 기반으로 변조 항을 계산합니다. (ii) DAB 교차 주의 방식[31]은 조건부 교차 주의에 기반하고 상자 너비와 높이 정보를 사용하여 위치 주의 맵을 추가로 변조합니다. (iii) 공간 변조 교차 주의 방식(SMCA)[16]은 2D 가우시안 유사 가중치 맵으로 구현된 수작업 쿼리 공간 사전 확률을 설계하여 주의된 특징이 객체 쿼리의 초기 추정치 주변에 있도록 제한합니다. 표 3d는 자세한 비교 결과를 보고합니다. 우리의 접근 방식은 모든 방법 중에서 가장 좋은 성능을 달성합니다. 구체적으로, 조건부 교차 주의 모듈은 우리의 중심 전용 설정(표 3b의 첫 번째 행)으로 유사한 성능을 달성합니다. DAB 교차 어텐션과 SMCA는 조건부 교차 어텐션 모듈보다 약간 더 나았지만, 여전히 BoxRPB보다 각각 2.5 AP와 2.2 AP 뒤처져 있습니다. 또한 BoxRPB를 공식 오픈소스 코드를 기반으로 DAB 교차 어텐션과 비교합니다. DAB 위치 모듈을 BoxRPB로 대체하면 +1.8 mAP 성능 향상을 달성합니다. 5.2. 로컬 어텐션 스키마와의 비교 이 섹션에서는 글로벌 어텐션 스키마를 다른 대표적인 로컬 교차 어텐션 메커니즘인 hidden dim. AP AP 50 APmethod AP AP 50 APdecomp. mem.과 비교했습니다. GFLOPS AP AP 50 APbox 포인트 AP AP 50 APX 26.8G 265.4 50.8 69.3 55.center ✓ 48.0 69.0 53.2x corners 50.9 69.3 55.9.5G 5.8 50.9 69.3 55.(a) 축 분해.(b) 박스 포인트.(d) 교차 주의 변조.표 3: 박스 상대 위치 바이어스 계획의 제거.(a) 축 분해는 계산 오버헤드와 GPU 메모리 사용량을 크게 줄일 수 있습니다.(b) 코너 포인트는 중심 포인트보다 성능이 좋습니다.(c) 숨겨진 차원이 높을수록 성능이 더 좋습니다. (d) 우리의 접근 방식은 교차 주의 맵을 조절하도록 설계된 다른 관련 방법보다 훨씬 더 나은 성과를 보입니다.50.4 69.1 55.50.9 69.4 55.50.9 69.3 55.표준 교차 주의.조건부 교차 주의.DAB 교차 주의.SMCA 교차 주의.46.3 68.2 51.48.3 68.8 52.48.4 68.9 53.48.7 69.2 53.우리의 50.9 69.3 55.(c) 숨겨진 희미함. 1/1/1/1/(a) (C³‚Cª,C5) → (P³, Pª, P5) Transformer Decoder 1/1/1/1/三十三 1/1/1/1/(b) (C3, C4, C5)→ P (c) C→P1/Transformer Decoder 그림 3: 백본에서 출력하여 Transformer 디코더로 전송한 다른 피처 맵을 사용할 때의 아키텍처 설계를 비교합니다. (a)에서 (b)로, 다중 스케일 피처 맵을 Transformer 디코더로 전송하는 것에 대한 종속성을 단순화합니다. (b)에서 (c)로, 백본에서 출력한 다중 스케일 피처를 융합하는 것에 대한 종속성을 제거합니다. (c)를 기본 아키텍처 설정으로 채택합니다. MIM AP AP 50 AP75 APS APM APL 방법 변형 가능 교차 주의. RolAlign Rol 샘플링 박스 마스크 Ours AP AP 50 AP75 APS APM 50.2 68.5 54.8 34.1 54.4 63.49.6 68.3 54.1 31.9 54.63.49.3 68.2 53.8 33.1 53.2 63.48.6 68.7 52.9 31.8 52.7 63.50.9 69.3 55.5 34.2 55.1 65.APL 백본 디코더 (C3, C4, C5) (P3, P4, P5) (C3, C4, C5)→ (P³, P4, P5) X 49.6 69.2 53.8 31.5 53.4 65.▼ 51.1 69.3 56.0 34.8 55.4 65.(a) 백본 디코더 MIM → PX PX 49.6 69.8 53.4 31.표 4: 로컬 크로스 어텐션 방식과의 비교. BoxRPB를 사용한 글로벌 크로스 어텐션은 모든 로컬 크로스 어텐션 대응책보다 성능이 뛰어나고 대형 객체에서 상당한 이득을 얻습니다. X → P✓ → PC5) → P³ ✓ AP AP 50 AP75 APS APM APL 47.0 68.2 50.4 28.0 51.5 64.53.7 65.49.7 69.8 53.9 32.7 53.5 65.50.3 69.3 54.9 33.4 54.7 64.51.0 69.4 55.7 34.5 55.1 65.50.9 69.2 55.4 34.4 55.0 64.(b) 변형 가능한 교차 주의[55], RoIAlign[21], RoI 샘플링(관심 영역 내의 고정 포인트 샘플링) 및 [7]에서 영감을 받은 상자 마스크 포함. 보충 자료에서 이러한 방법 간의 주요 차이점을 설명합니다. 표 4에 표시된 것처럼, 우리의 방법은 모든 로컬 교차 주의 변형을 능가합니다.또한, 우리는 큰 객체가 우리 방법에 대한 개선 사항이 더 크다는 것을 관찰했습니다.DETR[4]에서도 유사한 관찰 결과가 보고되었는데, 이는 글로벌 주의 체계를 기반으로 한 보다 효과적인 장거리 컨텍스트 모델링 때문일 수 있습니다.5.3. MIM 사전 학습에 관하여 우리는 MIM 사전 학습이 있거나 없는 백본 및 디코더 피처 맵을 사용하는 다양한 방법을 탐구합니다.그림 3에 나와 있는 세 가지 다른 아키텍처 구성의 성능을 평가합니다.우리는 다음과 같이 결과를 논의하고 분석합니다. 백본 디코더 MIM → PC5 → PPC→ PC→P→ PAP AP 50 AP75 APS APM APL 46.4 67.7 49.7 26.9 50.5 64.48.0 68.7 51.8 30.4 52.2 64.48.7 69.1 52.6 30.7 52.9 64.50.2 69.1 55.0 33.5 54.5 64.50.9 69.3 55.5 34.2 55.1 65.50.9 69.2 55.7 34.6 54.9 65.(c) 표 5: MIM 사전 학습의 삭제. (a) 백본에서 출력한 다중 스케일 특징 맵 + Transformer 디코더용 다중 스케일 특징 맵. (b) 백본에서 출력한 다중 스케일 피처 맵 + Transformer 디코더용 단일 스케일 피처 맵.(c) 백본에서 출력한 단일 스케일 피처 맵 + Transformer 디코더용 단일 스케일 피처 맵.MIM 사전 학습은 일관된 이득을 제공합니다.동일한 아키텍처 config-method Cascade Mask R-CNN[3]에서 실험 결과를 비교하면 당사 AP AP50 AP75 APS APM APL 53.7 71.9 58.7 36.9 57.4 69.53.8 73.4 58.9 35.9 57.0 68.표 6: MIM 사전 학습된 ViT-Base 백본을 사용한 개선된 일반 DETR과 Cascade Mask R-CNN의 비교. 글로벌 교차 주의가 적용된 당사 일반 DETR은 영역 기반 다중 스케일 Cascade Mask R-CNN보다 약간 더 좋습니다. 기린의 실험에서 MIM 사전 학습을 사용하면 지속적으로 더 나은 성능을 얻을 수 있음을 발견했습니다. 예를 들어, 표 5에서 볼 수 있듯이 MIM 사전 학습을 사용하면 (C3, C4, C5) → (P3, P4, P5) 구성에서 1.5 AP, C5 → Pª 구성에서 2.9 AP만큼 감독 사전 학습을 사용하는 것보다 성능이 우수합니다. 디코더의 다중 스케일 피처 맵을 제거할 수 있습니다. 표 5a와 표 5b의 결과를 비교하여 고해상도 피처 맵을 사용하면 다중 스케일 피처 맵을 사용하는 성능과 동일하거나 더 뛰어날 수 있음을 발견했습니다. 예를 들어, (C3, C4, C5) → P³는 MIM 사전 학습을 사용하거나 사용하지 않고도 (C3, C4, C5) → (P3, P4, P5)와 비슷한 성능을 얻습니다. 이러한 관찰은 대부분의 기존 감지 헤드가 여전히 입력으로 다중 스케일 피처가 필요하기 때문에 사소한 것이 아니며 경쟁력 있는 단일 스케일 일반 DETR을 구축하는 것이 가능합니다. 우리는 이 발견이 미래의 탐지 프레임워크 설계를 용이하게 할 수 있기를 바랍니다.백본에서 다중 스케일 특징 맵은 불필요합니다.표 5b와 표 5c의 결과를 비교하여 백본에서 다중 스케일 특징 맵을 제거하는 효과를 분석합니다.지도 학습된 사전 훈련된 백본을 사용하는 경우 백본에서 마지막 특징 맵 C5만 채택하면 성능이 저하됩니다.예를 들어, 지도 학습된 사전 훈련된 백본을 사용하는 경우 C5 P5는 46.4 AP에 도달하여 (C3, C4, C5) P5(47.0 AP)보다 0.6 AP만큼 나쁩니다.그러나 MIM 사전 훈련된 백본을 사용하는 경우 C5 → P5는 50.2 mAP에 도달하여 (C3, C4, C5) P5(50.3 AP)의 성능과 비슷합니다.이러한 결과는 MIM 사전 훈련이 다중 스케일 특징 맵에 대한 의존도를 줄일 수 있음을 보여줍니다. → 백본의 단일 스케일 피처 맵과 디코더의 단일 스케일 피처 맵으로 충분합니다. 위의 관찰을 바탕으로 놀랍도록 간단하지만 중요한
--- CONCLUSION ---
우리는 제안된 BoxRPB 방식과 MIM 사전 학습을 사용하여 백본과 Transformer 디코더 모두에서 다중 스케일 피처 맵의 필요성을 완전히 제거할 수 있습니다.5.4. 일반 ViT에 대한 응용 이 섹션에서는 우리의 접근 방식을 적용하여 간단하고 효과적인 완전 일반 객체 감지 시스템을 구축합니다.그림 4: BoxRPB가 있거나 없는 모델의 교차 어텐션 맵 시각화.각 그룹의 첫 번째 열은 입력 이미지와 객체 쿼리를 보여줍니다.첫 번째 행은 BoxRPB가 있는 모델의 어텐션 맵을 표시하고 두 번째 행은 BoxRPB가 없는 모델의 어텐션 맵을 표시합니다.BoxRPB는 교차 어텐션이 개별 객체에 집중하도록 안내하는 데 도움이 됩니다.일반 ViT에 [13].우리의 시스템은 다중 스케일 설계나 처리 없이 일반 Transformer 인코더-디코더 아키텍처 전체에서 단일 해상도 피처 맵만 사용합니다.우리는 우리의 접근 방식을 COCO 데이터 세트에서 최신 Cascade Mask R-CNN [3, 28]과 비교합니다. 공정한 비교를 위해 MAE[20] 사전 학습된 ViT-Base를 백본으로 사용하고 ~50에포크 동안 객체 감지기를 학습합니다.표 8에서 볼 수 있듯이, 저희의 방법은 다양한 객체 스케일에서 더 나은 로컬라이제이션을 위해 다중 스케일 피처 맵을 사용하는 Cascade Mask R-CNN과 비슷한 결과를 얻습니다.놀랍게도 저희의 방법은 일반적으로 객체 감지에 유익하다고 여겨지는 인스턴스 마스크 주석으로 학습하지 않습니다.5.5. 교차 주의 맵의 시각화 그림 4는 BoxRPB가 있거나 없는 모델의 교차 주의 맵을 보여줍니다.BoxRPB가 있는 모델의 경우 교차 주의는 개별 객체에 집중합니다.반대로 BoxRPB가 없는 모델의 교차 주의는 비슷한 모양을 가진 여러 객체에 주의를 기울입니다.6. 시스템 수준 결과 이 섹션에서는 저희의 방법을 다른 최신 방법과 비교합니다.표 7은 이 표에 보고된 모든 실험이 Swin-Large를 백본으로 활용한 결과를 보여줍니다. 다른 작업에서는 일반적으로 백본 기능을 향상시키기 위해 인코더를 적용하므로, 우리도 12개의 창 기반 단일 스케일 변환기 레이어(기능 차원 방법 프레임워크 추가 데이터 #params #epoch AP AP50 AP75 APS APM APL Swin [34] HTC 284M57.76.63.33.52.64.DETA [36] DETR 218M58.76.64.38.62.73.DINO-DETR [54] DETR 218M58.76.64.39.61.73.Ours* DETR 228M60.78.66.42.62.73.DETA [36] DETR218M 24 +63.80.70.46.66.76.DINO-DETR [54]* DETR218M 26 +63.Ours* DETR228M 24 +63.82.70.48.66.76.표 7: COCO 테스트 개발에서 최신 결과와 시스템 수준 비교. 모든 방법은 Swin-Large 백본을 채택합니다. 결과는 테스트 시간 증가로 표시됩니다. 공정한 비교를 위해 백본 위에 256의 시간당 평균 밀도(%)를 적용합니다. 36개의 학습 에포크에서 모델은 COCO 테스트 개발 세트에서 60.0 AP를 달성하여 DINO-DETR보다 1.4 AP 더 우수합니다. 사전 학습 데이터 세트로 Objects365[40]를 추가로 도입하여 방법은 테스트 개발 세트에서 63.9 AP에 도달하여 DINO-DETR 및 DETA보다 상당한 차이로 더 우수합니다. 이러한 강력한 결과는 일반 DETR 아키텍처가 고성능을 달성하는 데 방해가 되는 본질적인 단점이 없음을 확인합니다. 7. 관련 작업 DETR 기반 객체 감지. DETR[4]은 개념적으로 간단하고 적용성이 일반적이며, 사용자 지정 레이블 할당과 비최대 억제를 피하는 최소한의 도메인 지식이 필요하고 단순하다는 등 여러 장점으로 이 분야에 깊은 인상을 남겼습니다. 원래 DETR은 단순한 디자인을 유지하지만 수렴 속도가 느리고 탐지 정확도가 낮다는 단점이 있습니다. [35, 16, 9, 47, 55, 53, 52, 17, 54]를 포함한 많은 후속 작업이 있었고, 이제 다중 스케일 및 지역성 디자인의 재도입 덕분에 많은 최고 객체 감지기가 이 작업 라인을 기반으로 구축되었습니다 [54, 14, 46]. 이러한 주요 작업과 달리 다중 스케일 기능 및 로컬 교차 주의 계산 없이 &quot;단순한&quot; 특성을 유지하는 개선된 DETR 프레임워크를 목표로 합니다. 영역 기반 객체 감지. DETR 프레임워크 이전에는 객체 감지기가 일반적으로 영역 기반 방식으로 구축되었습니다. 알고리즘은 전체 이미지의 모든 영역을 로컬하게 분석하고 객체 감지는 각 영역의 결과를 순위를 매기고 필터링하여 얻습니다. 지역적 특성으로 인해 객체 감지를 위해 전역 정보를 유연하게 활용하기 어렵습니다. 게다가 일부 초기 시도에서는 머리에 단일 스케일 피처 맵을 사용했지만[19, 38, 18, 39, 32], 이후 주요 방법은 거의 모두 FPN[29], BiFPN[42], Cascade R-CNN[3], HTC[5] 등과 같은 다중 스케일 피처로 구축되었습니다. 우리의 강력한 일반 DETR 감지기가 영역 기반 감지를 위한 단일 스케일 피처 맵을 탐색하는 연구에 영감을 줄 수 있을 것으로 기대합니다. 위치 인코딩. 이 논문은 또한 위치 인코딩 기술과 관련이 있습니다. 원래 Transformer[45]는 절대 위치 인코딩을 사용합니다. 초기 비전 Transformer[4, 12, 44]는 이 절대 위치 인코딩 설정을 상속합니다. Swin Transformers[34, 33]는 Transformer 기반 시각 인식에 대한 상대적 위치 편향의 중요성을 강조하는데, 여기서 일부 초기 변형은 언어 및 시각 도메인에서 모두 발견될 수 있다[23, 41, 24, 10, 25, 8, 48]. 이 논문은 이전 픽셀 대 픽셀 쌍 대신 상자 대 픽셀 쌍에 대한 상대적 위치 편향을 확장한다. 또한 RPB가 일반 DETR 감지기의 맥락에서 훨씬 더 중요한 영향을 미칠 수 있음을 보여준다. 사전 학습. 마스크 이미지 모델링 경로를 따르는 사전 학습 방법[20, 51, 1]은 객체 감지 및 의미 분할과 같은 다양한 핵심 시각 작업에서 강력한 성능을 보여 주목을 받고 있다. 최근의 몇몇 연구[28, 49]는 MIM이 기존의 지도 학습 사전 학습보다 성능이 뛰어난 몇 가지 이유를 밝히고 FPN을 단순화할 수 있음을 확인했지만 MIM 사전 학습된 백본을 기반으로 완전히 일반 객체 감지 헤드를 구축하려는 연구는 거의 없다. 실험 결과는 MIM 사전 학습이 완전 일반 객체 감지 아키텍처 설계에서 핵심 요소임을 보여줍니다.8. 결론 이 논문에서는 원래 일반 모델보다 뛰어난 개선을 이루고 Swin-L 백본을 사용하여 63.9 mAP 정확도를 달성하는 개선된 일반 DETR 감지기를 제시합니다.이 감지기는 다중 스케일 피처 맵과 영역 기반 피처 추출을 사용하여 강력하게 조정된 최첨단 감지기와 매우 경쟁력이 있습니다.이 개선된 일반 DETR 프레임워크를 위해 BoxRPB와 MIM 기반 사전 학습의 두 가지 기술의 중요성을 강조했습니다.최소한의 구조적 &quot;귀납적 편향&quot;으로 강화된 효과적인 감지기가 다른 비전 문제에서 일반적인 일반 디코더를 탐색하는 미래 연구를 장려할 수 있기를 바랍니다.참고 문헌 [1] H. Bao, L. Dong, S. Piao, and F. Wei. Beit: 이미지 변환기의 Bert 사전 학습. arXiv 사전 인쇄본 arXiv:2106.08254, 2021. 4,[2] T. Brown, B. Mann, N. Ryder, M. Subbiah, JD Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. 언어 모델은 few-shot 학습기입니다. 신경 정보 처리 시스템의 발전, 33:1877–1901, 2020.[3] Z. Cai 및 N. Vasconcelos. Cascade r-cnn: 고품질 객체 감지 탐구. CVPR, 6154–6162페이지, 2018. 3,7,[4] N. Carion, F. Massa, G. Synnaeve, N. Usunier, A. Kirillov 및 S. Zagoruyko. 변압기를 사용한 종단 간 객체 감지. 유럽 컴퓨터 비전 컨퍼런스, 213-229쪽.Springer, 2020. 1, 2, 4, 6,[5] K. Chen, J. Pang, J. Wang, Y. Xiong, X. Li, S. Sun, W. Feng, Z. Liu, J. Shi, W. Ouyang 등. 인스턴스 분할을 위한 하이브리드 작업 캐스케이드.CVPR, 4974-4983쪽, 2019.[6] Q. Chen, J. Wang, C. Han, S. Zhang, Z. Li, X. Chen, J. Chen, X. Wang, S. Han, G. Zhang 등. Group detr v2: 인코더-디코더 사전 학습을 통한 강력한 객체 감지기. 사전 인쇄본 arXiv:2211.03594, 2022. 3, arXiv [7] B. Cheng, I. Misra, AG Schwing, A. Kirillov, 및 R. Girdhar. 범용 이미지 분할을 위한 마스크된 주의 마스크 변환기. arXiv 사전 인쇄본 arXiv:2112.01527, 2021. 6,[8] X. Chu, B. Zhang, Z. Tian, X. Wei, 및 H. Xia. 비전 변환기에 대한 명시적 위치 인코딩이 정말 필요한가. arXiv 사전 인쇄본 arXiv:2102.10882, 3(8), 2021.[9] X. Dai, Y. Chen, J. Yang, P. Zhang, L. Yuan, 및 L. Zhang. 동적 detr: 동적 주의를 통한 종단 간 개체 감지. IEEE/CVF 국제 컴퓨터 비전 컨퍼런스 논문집, 2988-2997쪽, 2021.[10] Z. Dai, Z. Yang, Y. Yang, J. Carbonell, QV Le, R. Salakhutdinov. Transformer-xl: 고정 길이 컨텍스트를 넘어서는 주의 깊은 언어 모델. arXiv 사전 인쇄본 arXiv:1901.02860, 2019.[11] J. Devlin, M.-W. Chang, K. Lee, K. Toutanova. Bert: 언어 이해를 위한 딥 양방향 변환기의 사전 학습. arXiv 사전 인쇄본 arXiv:1810.04805, 2018.[12] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, et al. 이미지는 16x16 단어의 가치가 있습니다: 대규모 이미지 인식을 위한 변환기. arXiv 사전 인쇄본 arXiv:2010.11929, 2020.[13] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby. 이미지는 16x16 단어의 가치가 있습니다: 대규모 이미지 인식을 위한 변환기. ICLR, 2021. 1,[14] Y. Fang, W. Wang, B. Xie, Q. Sun, L. Wu, X. Wang, T. Huang, X. Wang, Y. Cao. Eva: 대규모로 마스크된 시각적 표현 학습의 한계 탐색. arXiv 사전 인쇄본 arXiv:2211.07636, 2022.[15] Y. Fang, S. Yang, S. Wang, Y. Ge, Y. Shan, X. Wang. 객체 감지를 위한 마스크된 이미지 모델링을 사용하여 바닐라 비전 변환기를 해제. arXiv 사전 인쇄본 arXiv:2204.02964, 2022.[16] P. Gao, M. Zheng, X. Wang, J. Dai, H. Li. 공간적으로 변조된 공동 주의와 detr의 빠른 수렴. ICCV, 3621-3630페이지, 2021. 5,[17] Z. Gao, L. Wang, B. Han, and S. Guo. Adamixer: 빠르게 수렴하는 쿼리 기반 객체 감지기. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 5364-5373페이지, 2022.[18] R. Girshick. 빠른 r-cnn. ICCV, 1440-1448페이지, 2015.[19] R. Girshick, J. Donahue, T. Darrell, and J. Malik. 정확한 객체 감지 및 의미 분할을 위한 풍부한 기능 계층. IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 580-587페이지, 2014.[20] K. He, X. Chen, S. Xie, Y. Li, P. Dollár, R. Girshick. Masked autoencoders are scalable vision learner. IEEE/CVF Conference on Computer Vision and Pattern Recognition의 회의록, 16000-16009쪽, 2022. 2, 4, 7, 8,[21] K. He, G. Gkioxari, P. Dollár, R. Girshick. Mask RCNN. ICCV, 2017. 6,[22] K. He, X. Zhang, S. Ren, J. Sun. Image Recognition을 위한 심층 잔여 학습. CVPR, 2016.[23] H. Hu, J. Gu, Z. Zhang, J. Dai, Y. Wei. 객체 감지를 위한 관계 네트워크. IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스 논문집, 3588-3597페이지, 2018.[24] H. Hu, Z. Zhang, Z. Xie, S. Lin. 이미지 인식을 위한 로컬 관계 네트워크. IEEE/CVF 컴퓨터 비전 국제 컨퍼런스 논문집, 34643473페이지, 2019.[25] Z. Huang, D. Liang, P. Xu, B. Xiang. 더 나은 상대적 위치 임베딩으로 변압기 모델 개선. arXiv 사전 인쇄본 arXiv:2009.13658, 2020.[26] D. Jia, Y. Yuan, H. He, X. Wu, H. Yu, W. Lin, L. Sun, C. Zhang, H. Hu. 하이브리드 매칭을 통한 Detrs. arXiv 사전 인쇄본 arXiv:2207.13080, 2022. 3,[27] F. Li, H. Zhang, S. Liu, J. Guo, LM Ni, L. Zhang. Dn-detr: 쿼리 노이즈 제거를 도입하여 detr 학습 가속화. arXiv 사전 인쇄본 arXiv:2203.01305, 2022.[28] Y. Li, H. Mao, R. Girshick, K. He. 객체 감지를 위한 일반 비전 변환기 백본 탐색. arXiv 사전 인쇄본 arXiv:2203.16527, 2022. 2, 4, 7,[29] T.-Y. Lin, P. Dollár, R. Girshick, K. He, B. Hariharan, S. Belongie. 객체 감지를 위한 피처 피라미드 네트워크. IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스 논문집, 2117-2125쪽, 2017년.[30] T.-Y. Lin, P. Goyal, R. Girshick, K. He, P. Dollár. 밀집 객체 감지를 위한 초점 손실. IEEE 컴퓨터 비전 국제 컨퍼런스 논문집, 2980-2988쪽, 2017년.[31] S. Liu, F. Li, H. Zhang, X. Yang, X. Qi, H. Su, J. Zhu, L. Zhang. Dab-detr: 동적 앵커 상자는 detr에 더 나은 쿼리입니다. arXiv 사전 인쇄본 arXiv:2201.12329, 2022.[32] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y. Fu, AC Berg. Ssd: 싱글 샷 멀티박스 검출기. ECCV, 21-37페이지. Springer, 2016.[33] Z. Liu, H. Hu, Y. Lin, Z. Yao, Z. Xie, Y. Wei, J. Ning, Y. Cao, Z. Zhang, L. Dong, et al. Swin transformer v2: 용량 및 해상도 확장. CVPR, 12009-12019페이지, 2022. 2, 3, 4,[34] Z. Liu, Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, and B. Guo. Swin transformer: 이동된 창을 사용하는 계층적 비전 변환기. ICCV, 10012-10022페이지, 2021. 2, 3, 8,[35] D. Meng, X. Chen, Z. Fan, G. Zeng, H. Li, Y. Yuan, L. Sun, J. Wang. 빠른 학습 수렴을 위한 조건부 detr. IEEE 국제 컴퓨터 비전 컨퍼런스(ICCV) 회의록, 2021. 5,[36] J. Ouyang-Zhang, JH Cho, X. Zhou, P. Krähenbühl. Nms가 반격한다. arXiv 사전 인쇄본 arXiv:2212.06137, 2022.[37] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever, et al. 생성적 사전 학습을 통한 언어 이해 향상. 2018.[38] J. Redmon, S. Divvala, R. Girshick, A. Farhadi. You only look once: Unified, real-time object detection. IEEE Conference on Computer Vision and Pattern Recognition(CVPR)의 회의록, 2016년 6월.[39] S. Ren, K. He, R. Girshick, J. Sun. Faster r-cnn: 영역 제안 네트워크를 사용한 실시간 객체 감지를 향해. 신경 정보 처리 시스템의 발전, 28, 2015.[40] S. Shao, Z. Li, T. Zhang, C. Peng, G. Yu, X. Zhang, J. Li, J. Sun. Objects365: 객체 감지를 위한 대규모 고품질 데이터 세트. IEEE/CVF 국제 컴퓨터 비전 컨퍼런스 논문집, 8430-8439페이지, 2019. 8,[41] P. Shaw, J. Uszkoreit, A. Vaswani. 상대적 위치 표현을 사용한 자기 주의. arXiv 사전 인쇄본 arXiv:1803.02155, 2018.[42] M. Tan, R. Pang, QV Le. Efficientdet: 확장 가능하고 효율적인 객체 감지. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 논문집, 10781-10790페이지, 2020.[43] Z. Teed, J. Deng. Raft: 광학 흐름을 위한 순환 모든 쌍 필드 변환. Computer Vision-ECCV 2020: 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part II 16, pages 402–419. Springer, 2020.[44] H. Touvron, M. Cord, M. Douze, F. Massa, A. Sablayrolles, and H. Jégou. Training data-efficient image transformer &amp; distillation through attention. International conference on machine learning, pages 10347-10357. PMLR, 2021.[45] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, AN Gomez, Ł. Kaiser, and I. Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.[46] W. Wang, J. Dai, Z. Chen, Z. Huang, Z. Li, X. Zhu, X. Hu, T. Lu, L. Lu, H. Li, et al. Internimage: 변형 가능한 합성곱을 사용하여 대규모 비전 기반 모델 탐색.arXiv 사전 인쇄본 arXiv:2211.05778, 2022.[47] Y. Wang, X. Zhang, T. Yang, J. Sun. Anchor detr: 변압기 기반 감지기를 위한 쿼리 디자인, 2021.[48] K. Wu, H. Peng, M. Chen, J. Fu, H. Chao. 비전 변압기를 위한 상대적 위치 인코딩 재고 및 개선.IEEE/CVF 컴퓨터 비전 국제 컨퍼런스 회의록, 10033-10041페이지, 2021.[49] Z. Xie, Z. Geng, J. Hu, Z. Zhang, H. Hu, Y. Cao. 마스크 이미지 모델링의 어두운 비밀을 밝힙니다.arXiv 사전 인쇄본 arXiv:2205.13543, 2022. 2, 4,[50] Z. Xie, Z. Zhang, Y. Cao, Y. Lin, J. Bao, Z. Yao, Q. Dai 및 H. Hu. Simmim: 마스크 이미지 모델링을 위한 간단한 프레임워크.arXiv 사전 인쇄본 arXiv:2111.09886, 2021.[51] Z. Xie, Z. Zhang, Y. Cao, Y. Lin, J. Bao, Z. Yao, Q. Dai 및 H. Hu. Simmim: 마스크 이미지 모델링을 위한 간단한 프레임워크. CVPR, 페이지 9653-9663, 2022. 4,[52] G. Zhang, Z. Luo, Y. Yu, J. Huang, K. Cui, S. Lu 및 EP Xing. 향상된 detr 수렴 및 다중 규모 기능 융합을 위한 의미 정렬 매칭. arXiv 사전 인쇄 arXiv:2207.14172, 2022.[53] G. Zhang, Z. Luo, Y. Yu, Z. Tian, J. Zhang 및 S. Lu. 변환기 기반 물체 감지기의 다중 규모 기능을 효율적으로 사용합니다. arXiv 사전 인쇄 arXiv:2208.11356, 2022.[54] H. Zhang, F. Li, S. Liu, L. Zhang, H. Su, J. Zhu, LM Ni 및 H.-Y. 쯧. Dino: 엔드투엔드 객체 감지를 위한 개선된 노이즈 제거 앵커 박스를 갖춘 Detr. arXiv 사전 인쇄본 arXiv:2203.03605, 2022. 1, 2, 3, 8,[55] X. Zhu, W. Su, L. Lu, B. Li, X. Wang, and J. Dai. 변형 가능한 detr: 엔드투엔드 객체 감지를 위한 변형 가능한 변환기. arXiv 사전 인쇄본 arXiv:2010.04159, 2020. 1, 3, 6, 8, 10,9. 보충 자료 A. 더 많은 일반 ViT 결과 표 8은 일반 ViT에 기반한 더 많은 비교 결과를 보고합니다. 본문의 섹션 5.4에 설명된 기본 설정을 사용하여 MAE [20] 사전 학습된 ViTBase를 백본으로 채택하고 모델을 약 50에포크 동안 학습합니다. 결과에 따르면 (i) 우리의 방법은 단일 스케일 피처 맵을 처리하기 위해 글로벌 교차 주의 방식만 사용할 때 일반 DETR 기준선을 46.5 AP에서 53.8 AP로 높인다는 점, (ii) 우리의 접근 방식은 다중 스케일 피처 맵의 이점을 활용하기 위해 로컬 교차 주의 방식을 사용하는 강력한 DETR 기반 객체 감지기(예: Deformable DETR [55])보다 성능이 우수하다는 점을 관찰했습니다. B. 다른 방법과의 런타임 비교 표 9에서 다양한 교차 어텐션 변조의 런타임 비용을 추가로 분석합니다.BoxRPB 약간 방법 내 일반 DETR 변형 가능 DETR[55] 당사 AP AP50 AP46.5 70.2 50.52.1 71.6 56.53.8 73.4 58.APS APM APL 26.3 50.2 65.33.5 55.2 69.35.9 57.0 68.표 8: 일반 DETR 베이스라인, 변형 가능 DETR 및 MIM 사전 훈련된 ViT-Base 백본을 사용한 개선된 일반 DETR의 비교. 글로벌 교차 어텐션을 사용한 일반 DETR은 베이스라인을 엄청난 마진으로 개선하고 다중 스케일 특징과 로컬 교차 어텐션에 의존하는 변형 가능 DETR보다 성능이 뛰어납니다. 방법 훈련(분/에포크) 추론(fps) 표준 교차 attn.9.조건부 교차 attn.9.DAB 교차 attn.9.SMCA 교차 attn.9.우리의 것9.표 9: 로컬 교차 주의 계획과의 런타임 비교.BoxRPB를 사용한 글로벌 교차 주의는 다른 위치 바이어스 방법과 비슷한 속도를 가지고 있습니다.표준 교차 주의와 비교하여 런타임이 단축되는 반면, 다른 위치 바이어스 방법과 비슷한 속도를 가지고 있습니다.C. 로컬 주의 계획에 대한 자세한 내용 그림 5는 우리 방법이 변형 가능 교차 주의[55], RolAlign[21], RoI 샘플링(관심 영역의 고정점), [7]의 박스 마스크와 같은 로컬 교차 주의 방법과 어떻게 다른지 보여줍니다.대부분 로컬 교차 주의 방법은 특수 샘플링 및 보간 메커니즘을 사용하여 희소 키-값 공간을 구성해야 합니다. 우리 방법은 모든 이미지 위치를 키-값 공간으로 사용하고 상자-픽셀 상대 위치 바이어스 항(e)의 그라데이션 핑크색 원형 영역)을 학습하여 어텐션 가중치를 조정합니다.이렇게 하면 우리 방법이 이전 방법보다 더 유연하고 일반적입니다.D. COCO val에 대한 시스템 수준 비교 표 10은 Swin-Large를 백본으로 사용할 때 우리 방법을 이전 최첨단 방법과 비교합니다.36개의 학습 에포크를 통해 우리 모델은 COCO val에서 59.8 AP를 달성하여 DINO-DETR보다 +1.3 AP 더 높은 성능을 보였습니다.Objects365[40] 사전 학습을 통해 우리 방법은 DINO-DETR보다 훨씬 높은 63.8 AP를 얻습니다. 이러한 결과는 우리의 접근 방식을 사용하면 개선된 일반 DETR이 내재적 제한 없이 경쟁력 있는 성능을 달성할 수 있음을 보여줍니다.방법 프레임워크 추가 데이터 #매개변수 #epoch AP APAPAPS APM APL Swin [34] HTC 없음 284M57.75.62.42.60.71.Group-DETR [6] DETR 없음 &gt;218M58.41.62.73.H-Deformable-DETR [26] DETR 없음 218M57.76.63.42.61.73.DINO-DETR [54] DETR 없음 218M58.77.64.41.62.74.Ours* DETR 없음 228M59.78.66.45.63.74.DINO-DETR [54]* DETR218M 26+63.Ours* DETR228M 24 +63.81.70.50.67.77.표 10: COCO val에 대한 최신 방법과의 시스템 수준 비교. 모든 방법은 Swin-Large 백본을 채택합니다. 상위 첨자는 테스트 시간 증가를 통한 결과를 표시합니다. (a) 변형 가능한 교차 어텐션. (b) RolAlign (c) RoI 샘플링 (d) 상자 마스크 (e) 우리의 그림 5: 다양한 로컬 교차 어텐션 메커니즘과 우리의 글로벌 교차 어텐션 스키마 간의 비교를 설명합니다. 샘플링 위치는 분홍색으로 표시합니다. 입력 이미지는 검은색 그리드로 표시되고 녹색 상자는 이전 계층에서 예측된 경계 상자입니다. 빨간색 별은 경계 상자 중심을 표시합니다. (a) 변형 가능한 교차 어텐션: 키-값 공간에 대한 예측된 경계 상자 주변의 중요한 위치를 샘플링하는 방법을 학습합니다. (b) RolAlign: 키-값 공간에 대한 각 RoI 빈의 각 샘플링 위치 값을 계산하기 위해 선형 보간을 사용합니다. (c) RoI 샘플링: 샘플링 위치를 이산 빈으로 양자화하고 이를 키-값 공간으로 사용합니다. (d) 박스 마스크: 녹색 경계 상자 내의 모든 위치를 키-값 공간으로 선택합니다. (e) 저희의 방법: 입력 이미지의 모든 위치를 키-값 공간으로 사용하는 BoxRPB로 글로벌 교차 어텐션을 개선합니다. 어텐션 값은 색상 강도로 표시됩니다.
