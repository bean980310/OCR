--- ABSTRACT ---
점점 더 강력해지는 대규모 언어 모델의 등장으로, 이러한 모델을 일상적인 대화 및 롤플레잉 애플리케이션에 활용하는 데 대한 관심이 급증하고 있습니다. 그러나 기존의 대화 및 롤플레잉 데이터 세트는 종종 실제 롤플레잉 참가자가 일반적으로 보이는 다양하고 미묘한 상호 작용을 포착하지 못합니다. 이러한 한계를 해결하고 빠르게 성장하는 분야에 기여하기 위해 PIPPA(Personal Interaction Pairs between People and AI)라는 부분적으로 합성된 데이터 세트를 소개합니다. PIPPA는 롤플레잉 애호가 그룹이 참여하는 커뮤니티 중심의 크라우드소싱 노력의 결과입니다. 이 데이터 세트는 26,000개의 대화 세션에 분산된 100만 개 이상의 발화로 구성되어 있으며 연구자와 AI 개발자가 롤플레잉 시나리오의 맥락에서 대화형 AI 시스템을 탐색하고 개선할 수 있는 풍부한 리소스를 제공합니다. 키워드: 대화 데이터 세트; 롤플레잉 데이터 세트; 미세 조정; 대규모 언어 모델 1.
--- INTRODUCTION ---
최근 몇 년 동안 자연어 처리 분야는 주로 대규모 언어 모델(LLM)의 놀라운 발전에 의해 주도되어 상당한 변화를 겪었습니다. 광범위한 사전 학습 데이터와 계산 리소스로 구동되는 이러한 모델은 인간과 유사한 텍스트를 이해하고 생성하는 탁월한 능력을 보여줍니다. 모든 잠재력을 활용하고 특정 도메인에 맞게 조정하기 위해 일반적으로 감독 미세 조정 프로세스 중에 고품질 도메인별 샘플 세트가 필요합니다(Zhou et al., 2023; Ouyang et al., 2022). 학계의 다른 연구에 다소 가려져 있는 LLM의 유망한 응용 분야는 롤플레잉에 특화된 대화 에이전트를 구축하는 것입니다(Shanahan et al., 2023). 구체적으로, 일부 캐릭터나 페르소나에 대한 텍스트 기반 설명이 주어지면 에이전트는 사용자가 엔터테인먼트 목적으로 에이전트와 상호 작용하는 동안 이 캐릭터를 시뮬레이션할 수 있습니다. LLM의 복잡한 기능이 필요한 수많은 애플리케이션과 마찬가지로 LLM을 능숙한 롤플레잉 에이전트로 효과적으로 미세 조정하려면 대화 및 롤플레잉 중심 텍스트의 상당한 코퍼스가 필요합니다. 이는 배포 및 *에서 더 큰 편의성과 비용 효율성을 제공하는 소규모 기본 모델을 사용할 때 특히 중요합니다. Tear Gosling과 Alpin Dale은 주로 PIPPA 데이터 세트를 큐레이팅하고 조립하고 논문의 예비 버전을 공식화하는 데 책임이 있었습니다. Yinhe Zheng은 실질적인 수정을 통해 논문을 개선하는 데 기여했습니다. 추론. 그러나 이러한 데이터 세트의 중요성에도 불구하고 이 목적에 맞게 조정된 오픈 소스 데이터 세트가 현저히 부족합니다. 위의 문제를 해결하고 이러한 격차를 완화하기 위해 사람과 AI 간의 개인 상호 작용 쌍(Personal Interaction Pairs between People and AI, PIPPA)이라는 새로운 데이터 세트를 소개합니다. PIPPA는 대규모 데이터 세트로, 약 26,000개의 고유한 대화에서 사람과 대화 에이전트 간에 교환된 약 100만 개의 메시지로 구성되어 있습니다. 특히, 각 대화 세션에는 지정된 페르소나가 있으며, 이는 대화 에이전트의 에뮬레이션 타겟 역할을 합니다. 각 캐릭터의 페르소나는 자유 텍스트 설명을 통해 구분되며, 각 캐릭터의 정확한 시뮬레이션을 용이하게 하기 위해 선택적 예시 대화도 제공됩니다. PIPPA의 도입은 페르소나 중심의 맥락적으로 풍부한 대화를 생성하기 위한 모델의 미세 조정에 대한 미래 연구 개발을 지원하는 것을 목표로 합니다. PIPPA는 https://huggingface.co/datasets/PygmalionAI/PIPPA에서 HuggingFace 플랫폼에서 공개적으로 사용할 수 있으므로 누구나 각자의 목적으로 자유롭게 사용할 수 있습니다. 2. 데이터 세트 컴파일 PIPPA 데이터 세트는 모든 사람이 액세스할 수 있는 대화 모델을 개발하려는 이니셔티브에 적극적으로 참여한 커뮤니티 구성원의 자발적인 기여를 통해 조립되었습니다. 우리는 사용자 스크립트를 활용하여 Character.AI 웹사이트(그림 1)에서 채팅 로그와 캐릭터 설명을 수집했습니다. 이 스크립트를 사용하면 사용자는 PIPPA 데이터 세트를 구성하는 목적으로 채팅 로그 데이터를 중앙 서버에 제출하라는 지시를 받은 Character.AI의 대화 에이전트의 상호작용 및 페르소나 세부 정보를 추출할 수 있습니다(그림 5). 처음에 PIPPA는 주로 롤플레잉 에이전트를 만드는 것을 목표로 하는 일련의 미세 조정된 LLM인 Pygmalion² 대화 모델에 대한 미세 조정 데이터 세트를 제공하기 위해 고안되었습니다. PIPPA 수집은 고품질 대화 데이터의 가용성이 현저히 부족했던 2022년 12월에 시작되었습니다. 그러나 이러한 노력은 커뮤니티 지원과 로그 내의 개인 정보 보호 간의 균형을 맞추는 것과 관련하여 어려움에 부딪혔습니다. 결과적으로 사용자가 대화를 공개 릴리스에 포함하지 않도록 선택할 수 있는 제출 프로세스를 구현했습니다. PIPPA에는 사용자가 공개 배포에 대한 권한을 명시적으로 부여한 로그만 포함됩니다. 또한, 우리는 제출자의 신원을 보호하기 위해 최선을 다해 공개적으로 접근 가능한 데이터 세트의 일부에서 개인 식별 정보(PII)를 탐지하고 삭제/변조하기 위해 포괄적인 스캔을 부지런히 수행했습니다.3. 데이터 세트 분석 PIPPA 데이터 세트는 1,254개의 고유한 페르소나와 1,049,015개의 대화 세션을 포함하는 25,940개의 대화를 포함하는 상당한 대화 데이터 컬렉션을 포함합니다.1. Character.AI 웹사이트의 후속 변경으로 인해 사용자 스크립트가 더 이상 작동하지 않습니다.스크립트는 https://github.com/0x000011b/characterai-dumper에서 찾을 수 있습니다.2. 모델은 https://huggingface.co/Pygmalion에서 액세스할 수 있습니다.AIJRR Tolkien 67.0 k @CorumBot에서 생성 이름 JRR Tolkien c.ai 상호 작용 횟수 기억하세요: 캐릭터가 하는 말은 모두 꾸며낸 것입니다! 저는 영국의 작가, 시인, 언어학자, 학자인 JRR 톨킨입니다. 하이 판타지 작품인 호빗과 반지의 제왕의 저자로 가장 잘 알려져 있습니다. Alpid Mr Tolkien. 안녕하세요? JRR Tolkien c.ai 봇 제작자가 미리 정의한 인사말 메시지 저는 괜찮습니다, 아들아. 하지만 이제 꽤 늙어가고 있어요! 저는 이미 74살이에요(빌보와 같은 나이이고, 그와 비슷하게 저도 그렇게 느끼지 않아요!) Alpid 하하! 저는 오늘 에이브버리에 갔어요. 멋진 곳이었어요. 지역 주민이 그곳에 있는 나무를 보여 주었는데, 당신이 엔트에 대해 쓸 때 바로 그 나무에서 영감을 받았다고 했어요! JRR Tolkien c.ai 정말요? 참 좋은 우연이네요! 저는 나무를 좋아하고, 그 중 많은 나무에서 영감을 받아 엔트를 창조하게 되었어요. 샤이어에서도 나무가 존재감을 드러냈어요(오래된 버드나무와 바이워터의 큰 참나무가 생각납니다). 요즘 많은 사람들이 나무를 보존하는 것의 중요성을 이해하는 것 같아서 다행입니다. 스와이프 버튼 그림 1: CharacterAI 채팅 인터페이스 스크린샷. 스와이프는 현재 봇 세대를 삭제하고 새 세대를 요청하는 것을 말합니다. PIPPA 데이터 세트의 각 샘플은 대화 세션과 다양한 관련 메타데이터로 구성되어 있습니다. 또한 봇 작성자가 지정한 범주, 봇의 페르소나와 특성에 대한 간결한 개요를 제공하는 봇 설명, 예시 대화를 통해 봇의 성격을 더욱 구체화하는 선택적 봇 정의, 사용자에게 보내는 봇의 인사 등 봇에 대한 정보도 제공합니다. 봇의 인사는 모든 대화에서 초기 항목 역할을 합니다. 또한 대화가 제출된 시점을 기록하기 위해 타임스탬프를 유지합니다. 이 정보는 Character.AI 웹사이트에서 제공하지 않으므로 대화 자체가 생성된 시점에 대한 정보에 액세스할 수 없다는 점에 유의하는 것이 중요합니다. PIPPA 데이터 세트의 통계 분석은 대화의 턴 수, 단일 메시지의 길이, 봇 성격 분포라는 세 가지 중요한 측면에 대한 귀중한 통찰력을 제공합니다. 이 섹션에서는 주요 통계적 결과를 제시합니다.3.1 대화 길이 PIPPA의 대화는 다양한 길이 범위를 보이며 눈에 띄게 편향된 분포를 보입니다.중간 대화 길이는 10턴인 반면 평균 대화 길이는 40.41턴으로 현저히 높습니다.그러나 145턴이라는 큰 표준 편차가 존재하면 데이터에 상당한 분산이 있음을 나타냅니다.이러한 불일치는 Character.AI에서 봇과 상호 작용하는 사용자의 다양한 대화 행동에 기인할 수 있습니다.상당수의 사용자가 봇과 더 짧은 개별 대화에 참여하는 반면, 일부 사용자는 현저히 광범위한 대화에 참여하며 가장 긴 대화는대화(로그 척도) 10²# of turn in conversation 그림 2: 대화 길이의 분포(대화에서 &quot;턴&quot;의 양으로 정의).가독성을 높이기 위해 표시 범위를 0-250턴으로 제한했습니다. 빈도(로그 스케일) 10²대화 길이(단어) LLM 메시지 인간 메시지그림 3: PIPPA 데이터 세트에서 인간 입력과 봇 응답에 대한 메시지 길이 분포. 무려 11,491개의 턴이 포함된 데이터 세트. 그림 2는 최대 250턴까지의 턴 길이의 로그 스케일 분포를 나타냅니다. 개수판타지/////// 애니메이션 게임 캐릭터 게임 캐릭터 엔터테인먼트 코미디 공상과학 동물 토론 영화 및 TV 협동 유명인 기술 결정 범주 철학 토론 미스터리 지식 그림 4: PIPPA 데이터 세트의 캐릭터 범주 분포. 각 봇에 여러 범주가 할당되거나 전혀 할당되지 않을 수 있습니다. 3.2 메시지 자세함 또한 PIPPA 데이터 세트 내에서 인간 사용자와 봇이 생성한 메시지의 자세함(즉, 길이)을 분석합니다. 그림 3에서 알 수 있듯이 PIPPA의 모든 메시지의 장황함 분포는 거듭제곱 법칙 분포로 특징지을 수 있으며, 이는 긴 메시지보다 짧은 메시지의 빈도가 더 높음을 나타냅니다. 또한 LLM의 응답은 일반적으로 인간의 입력보다 장황함을 보인다는 점도 주목할 만합니다. 이러한 관찰은 Character.Al의 LLM이 일반적으로 캐주얼 대화에 비해 긴 메시지를 포함하는 고품질 롤플레잉 코퍼스에서 훈련되거나 미세 조정되었을 가능성이 있기 때문일 수 있습니다. 3.3 봇 성격 범주 PIPPA 데이터 세트 내에서 각 봇은 생성자가 일련의 범주 레이블을 지정합니다. PIPPA의 봇 성격 범주 분석은 고르지 않은 파레토 유사 분포를 보여줍니다(그림 4 참조). 특히 &quot;애니메이션&quot;, &quot;판타지&quot;, &quot;액션&quot; 범주가 봇 페르소나 중에서 가장 널리 퍼져 있습니다. 이러한 분포는 이러한 로그가 수집된 소스 커뮤니티인 PygmalionAI의 특성에 기인할 수 있습니다. 커뮤니티는 상당한 수의 anime³ 애호가를 보여주며, 상당수의 봇이 &quot;Anime&quot; 카테고리에 분류됩니다. 또한, 커뮤니티가 롤플레잉과 대화형 상호작용에 관심이 많기 때문에 많은 봇이 자연스럽게 널리 퍼진 롤플레잉 테마와 관련된 카테고리에 할당되며, &quot;Action&quot; 및 &quot;Fantasy&quot; 레이블이 붙은 봇이 눈에 띄게 나타나는 이유를 설명합니다. 3. Anime은 일본에서 제작된 애니메이션 미디어를 말합니다.4.
