--- ABSTRACT ---
그러나 보고 믿는 것이 사실이지만, 인간의 시각 지각이 인지와 어떻게 얽혀 있는지에 대한 근본적인 메커니즘은 여전히 미스터리입니다. 신경 과학과 인공 지능의 최근 발전 덕분에 우리는 시각적으로 유발된 뇌 활동을 기록하고 계산적 접근 방식을 통해 시각 지각 능력을 모방할 수 있었습니다. 이 논문에서 우리는 휴대형으로 접근 가능한 뇌 신호, 즉 뇌파(EEG) 데이터를 기반으로 관찰된 이미지를 재구성하여 시각 자극 재구성에 주목합니다. EEG 신호는 시계열 형식에서 동적이고 노이즈가 많기 때문에 유용한 정보를 처리하고 추출하려면 더 많은 전담 노력이 필요합니다. 이 논문에서 우리는 EEG 신호에서 시각 자극 이미지를 재구성하기 위한 NEUROIMAGEN이라는 포괄적인 파이프라인을 제안합니다. 구체적으로, 우리는 주어진 EEG 데이터에서 다중 그레인 출력을 도출하기 위해 새로운 다중 레벨 지각 정보 디코딩을 통합합니다. 그런 다음 잠재 확산 모델이 추출된 정보를 활용하여 고해상도 시각 자극 이미지를 재구성합니다. 실험 결과는 이미지 재구성의 효과성과 제안된 방법의 뛰어난 정량적 성능을 보여주었습니다.
--- INTRODUCTION ---
인간의 시각 지각에 대한 피질 반응을 이해하는 것은 연구 핫스팟으로 부상했으며, 이는 신경 과학에 대한 지식을 바탕으로 계산 인지 시스템 개발을 크게 촉진할 수 있습니다(Palazzo et al. 2020). 기능적 자기 공명 영상(fMRI)이나 뇌파(EEG)와 같은 생리학적 기술의 급속한 발전과 함께 시각적으로 유발된 인간의 뇌 활동을 추가 분석을 위해 기록하는 것이 가능해졌습니다. 따라서 연구 커뮤니티는 이러한 복잡한 뇌 신호 데이터에 주의를 기울이고 실험에서 인간 피험자를 유발하는 데 사용된 자극 내용을 재구성하여 인간의 시각 지각을 이해하고 시뮬레이션하려고 시도합니다. 인간의 시각 지각을 연구하려는 주류 시도 중 하나는 인간의 주관적 감정을 유발하는 데 사용된 이미지(Takagi and Nishimoto 2023)나 비디오(Chen, Qing, and Zhou 2023)와 같은 보이는 내용을 재구성하는 것입니다. *Microsoft Research Asia에서 Yuting이 인턴으로 재직하는 동안 수행한 작업, Kan Ren, Yansen Wang, Weilong Zheng에게 보낸 서신. 자극 실험은 딥 뉴럴 네트워크와 같은 계산적 접근 방식을 통해 이루어집니다. 이러한 작업은 주로 fMRI 데이터(Allen et al. 2022)를 기반으로 하지만 이러한 영상 데이터를 수집하려면 값비싼 장치가 필요하고 실제 사용에 편의성이 부족합니다. 반면 EEG는 뇌 신호를 기록하고 분석하는 데 더 편리한 솔루션을 제공했지만 이러한 뇌 신호 데이터에 대한 시각 지각을 학습하는 작업은 거의 없습니다. EEG 데이터는 일반적으로 인간의 두피에 전극을 부착하여 기록한 시계열 전기 생리학적 신호이며, 피험자는 데이터에서 기록된 신호에 시간적으로 정렬된 이미지와 같은 일부 자극 내용을 보고 있습니다. EEG 신호에서 시각 자극을 재구성하는 것은 더 편리하지만 fMRI 데이터에서보다 더 어렵습니다. 첫째, EEG 신호는 시간 순서이고 정적 2D/3D 이미지와 상당히 다른 시계열 데이터 형식이므로 해당 뇌 신호 조각에 일치하는 자극이 어렵습니다. 둘째, 전극 오배치 또는 신체 움직임의 영향으로 인해 신호 대 잡음비(SNR)가 매우 낮은 데이터에 심각한 아티팩트가 발생하여 뇌 활동의 모델링과 이해에 큰 영향을 미쳤습니다. EEG 입력을 픽셀 도메인에 매핑하여 시각적 자극을 복구하는 것은 품질이 낮습니다. EEG에서 이미지를 재구성하는 기존 작업은 처음부터 기존 생성 모델(Kavasidis et al. 2017)을 사용하거나 덜 효율적인 대규모 생성 모델(Bai et al. 2023)을 미세 조정하거나 데이터 풀에서 유사한 이미지를 검색하는 것(Ye et al. 2022)입니다. 이러한 작업은 의미 정보를 포착하거나 고해상도 출력을 재구성하는 데 실패합니다. 이 작업에서 우리는 인간의 뇌 신호에서 신경 이미지 생성을 위한 포괄적인 파이프라인인 NEUROIMAGEN을 제안합니다. 이 작업에서 앞서 언급한 과제를 해결하기 위해 다양한 세분성으로 입력 신호에서 다른 의미 정보를 디코딩하는 다중 레벨 의미 추출 모듈을 통합합니다. 구체적으로, 추출된 정보에는 디코딩하기 쉬운 샘플 수준 의미론과 실루엣 정보의 돌출성 맵과 같이 디코딩이 더 어려운 경향이 있는 픽셀 수준 의미론이 포함됩니다. 다중 수준 출력은 생성 의미론의 제어를 통해 사전 학습된 확산 모델에 추가로 공급됩니다. 이러한 방식을 통해, 우리의 방법은 다양한 세분성과 난이도에서 의미 정보 추출 및 디코딩 문제를 유연하게 처리할 수 있으며, 이는 다양한 수준에서 고정된 다운스트림 확산 모델을 효과적으로 제어하여 생성을 용이하게 할 수 있습니다. 우리는 EEG 데이터에 대한 기존 이미지 재구성 솔루션으로 우리의 방법을 평가합니다. 결과는 EEG 이미지 데이터 세트에서 정량적 및 정성적 결과 모두에서 비교된 방법보다 NEUROIMAGEN이 우수함을 보여줍니다. 제안된 다양한 세분성에서 다중 수준 의미론 추출은 관찰된 시각적 자극을 사용하여 재구성된 이미지의 구조적 유사성과 의미적 정확도를 크게 높일 수 있습니다. 확산 모델
--- RELATED WORK ---
최근, 확산 모델은 이미지 합성, 비디오 생성, 분자 설계를 포함한 여러 작업을 위한 생성 모델 분야에서 최첨단 접근 방식으로 등장했습니다(Yang et al. 2022; Song, Meng, and Ermon 2020; Dhariwal and Nichol 2021). 잡음 제거 확산 확률 모델(DDPM)(Ho, Jain, and Abbeel 2020; Sohl-Dickstein et al. 2015)은 변분 추론을 사용하여 유한 시간 후에 샘플 매칭을 생성하는 매개변수화된 양방향 마르코프 체인입니다. 순방향 확산 프로세스는 일반적으로 모든 데이터 분포를 간단한 사전 분포(예: 등방성 가우시안)로 변환하는 목표로 설계되고, 역방향 잡음 제거 확산 프로세스는 U-Net과 같은 딥 신경망으로 매개변수화된 전이 커널을 학습하여 이전 분포를 역전합니다(Ronneberger, Fischer, and Brox 2015). 그러나 DDPM은 픽셀 공간에서 작동하고 평가 및 최적화를 거치므로 추론 속도가 느리고 학습 비용이 높아집니다. 이러한 한계를 해결하기 위해 Rombach 등(2022)은 잠재 확산 모델(LDM) 개념을 도입했습니다. LDM에서 확산 모델은 강력한 사전 학습된 자동 인코더의 잠재 공간 내에 적용됩니다. 이 접근 방식은 눈에 띄지 않는 세부 사항을 선택적으로 제거하는 별도의 압축 단계와 함께 효과적인 생성 모델임이 입증되었습니다. 잠재 공간에서 작동함으로써 LDM은 픽셀 공간 평가의 단점을 극복하여 추론 속도를 높이고 학습 비용을 절감합니다. fMRI에서 이미지 디코딩 뇌 활동에서 자극 내용을 재구성하는 가장 최근의 작업은 주로 fMRI 데이터에 초점을 맞추고 있습니다. 뇌의 혈액 산소 수준 의존(BOLD) 신호를 측정하는 fMRI는 뇌 신호 디코딩에서 상당한 발전을 이루었습니다. 기존의 시각적 디코딩
--- METHOD ---
. 서론 인간의 시각 지각에 대한 피질 반응을 이해하는 것은 연구 핫스팟으로 부상했으며, 이는 신경 과학에 대한 지식을 바탕으로 계산 인지 시스템 개발을 크게 촉진할 수 있습니다(Palazzo et al. 2020). 기능적 자기 공명 영상(fMRI)이나 뇌파(EEG)와 같은 생리학적 기술의 급속한 발전과 함께 시각적으로 유발된 인간의 뇌 활동을 추가 분석을 위해 기록하는 것이 가능해졌습니다. 따라서 연구 커뮤니티는 이러한 복잡한 뇌 신호 데이터에 주목하고 인간 피험자를 유발하는 데 사용된 자극 내용을 재구성하려고 시도합니다.
--- EXPERIMENT ---
모든 결과는 이미지 재구성의 효과성과 제안된 방법의 우수한 정량적 성능을 보여주었습니다. 서론 인간의 시각 인식에 대한 피질 반응을 이해하는 것은 연구 핫스팟으로 부상했으며, 이는 신경 과학에 대한 지식을 바탕으로 계산 인지 시스템 개발을 크게 촉진할 수 있습니다(Palazzo et al. 2020). 기능적 자기 공명 영상(fMRI)이나 뇌파(EEG)와 같은 생리학적 기술의 급속한 발전과 함께 시각적으로 유발된 인간의 뇌 활동을 추가 분석을 위해 기록하는 것이 가능해졌습니다. 따라서 연구 커뮤니티는 이러한 복잡한 뇌 신호 데이터에 주목하고 실험에서 인간 피험자를 유발하는 데 사용된 자극 내용을 재구성하여 인간의 시각 인식을 이해하고 시뮬레이션하려고 노력합니다. 인간의 시각 지각을 연구하려는 주류 시도 중 하나는 인간의 주관적 감정을 불러일으키는 데 사용된 이미지(Takagi and Nishimoto 2023)나 비디오(Chen, Qing, and Zhou 2023)와 같은 보이는 내용을 재구성하는 것입니다. *Microsoft Research Asia에서 Yuting이 인턴으로 재직하는 동안 수행한 작업, Kan Ren, Yansen Wang, Weilong Zheng에게 보낸 서신. 딥 뉴럴 네트워크와 같은 계산적 접근 방식을 통해 자극 실험에서. 이러한 작업은 주로 fMRI 데이터(Allen et al. 2022)를 기반으로 하는 반면, 이러한 영상 데이터를 수집하려면 값비싼 장치가 필요하고 실용적으로 사용하기에 편의성이 부족합니다. 반면, EEG는 뇌 신호를 기록하고 분석하는 데 더 편리한 솔루션을 제공했지만 이러한 뇌 신호 데이터에서 시각 지각을 학습하는 연구는 거의 없습니다. EEG 데이터는 일반적으로 인간의 두피에 붙인 전극을 통해 기록된 시계열 전기 생리학적 신호이며, 피험자는 데이터에서 기록된 신호에 시간적으로 정렬된 이미지와 같은 일부 자극 내용을 보고 있습니다. 비록 더 편리하지만, EEG 신호로부터 시각 자극을 재구성하는 것은 fMRI 데이터로부터 재구성하는 것보다 더 어렵습니다. 첫째, EEG 신호는 시간 순서이고 정적 2D/3D 이미지와 상당히 다른 시계열 데이터 형식이므로 자극을 해당 뇌 신호 조각에 일치시키는 것이 어렵습니다. 둘째, 전극 오배치 또는 신체 움직임의 영향으로 신호 대 잡음비(SNR)가 매우 낮은 데이터에 심각한 아티팩트가 발생하여 뇌 활동의 모델링과 이해에 큰 영향을 미쳤습니다. 단순히 EEG 입력을 픽셀 도메인에 매핑하여 시각 자극을 복구하는 것은 품질이 낮습니다. EEG로부터 이미지를 재구성하는 기존 작업은 처음부터 기존 생성 모델(Kavasidis et al. 2017)을 사용하거나 덜 효율적인 대규모 생성 모델(Bai et al. 2023)을 미세 조정하거나 데이터 풀에서 유사한 이미지를 검색하는 것(Ye et al. 2022)입니다. 그들은 의미 정보를 포착하거나 고해상도 출력을 재구성하는 데 실패합니다. 이 작업에서 우리는 인간의 뇌 신호에서 신경 이미지 생성을 위한 포괄적인 파이프라인인 NEUROIMAGEN을 제안합니다. 이 작업에서 앞서 언급한 과제를 해결하기 위해 다양한 세분성으로 입력 신호에서 다른 의미 정보를 디코딩하는 다중 레벨 의미 추출 모듈을 통합합니다. 구체적으로, 추출된 정보에는 디코딩하기 쉬운 샘플 레벨 의미와 디코딩이 더 어려운 실루엣 정보의 돌출 맵과 같은 픽셀 레벨 의미가 포함됩니다. 다중 레벨 출력은 생성 의미의 제어를 통해 사전 학습된 확산 모델에 추가로 공급됩니다. 이런 방식을 통해 우리의 방법은 다양한 세분성과 난이도에서 의미 정보 추출 및 디코딩 문제를 유연하게 처리할 수 있으며, 이후 다양한 레벨에서 고정된 다운스트림 확산 모델을 효과적으로 제어하여 생성을 용이하게 할 수 있습니다. 우리는 EEG 데이터에 대한 기존 이미지 재구성 솔루션으로 우리의 방법을 평가합니다. 결과는 EEG 이미지 데이터 세트에서 정량적 및 정성적 결과 모두에서 비교된 방법보다 NEUROIMAGEN이 우수함을 보여줍니다. 제안된 다양한 세분성에서 다중 레벨 의미론 추출은 관찰된 시각 자극과 재구성된 이미지의 구조적 유사성과 의미적 정확도를 크게 높일 수 있습니다. 확산 모델 관련 연구 최근 확산 모델은 이미지 합성, 비디오 생성, 분자 설계를 포함한 여러 작업에 대한 생성 모델 분야에서 최첨단 접근 방식으로 등장했습니다(Yang et al. 2022; Song, Meng, and Ermon 2020; Dhariwal and Nichol 2021). 잡음 제거 확산 확률 모델(DDPM)(Ho, Jain, and Abbeel 2020; Sohl-Dickstein et al. 2015)은 변분 추론을 사용하여 유한 시간 후에 샘플 매칭을 생성하는 매개변수화된 양방향 마르코프 체인입니다. 순방향 확산 프로세스는 일반적으로 모든 데이터 분포를 간단한 사전 분포(예: 등방성 가우시안)로 변환하는 것을 목표로 설계되고, 역방향 잡음 제거 확산 프로세스는 U-Net(Ronneberger, Fischer, and Brox 2015)과 같은 딥 신경망에 의해 매개변수화된 전이 커널을 학습하여 전자를 역전합니다. 그러나 DDPM은 픽셀 공간에서 작동하고 평가 및 최적화를 거치므로 추론 속도가 느리고 학습 비용이 높아집니다. 이러한 한계를 해결하기 위해 Rombach et al.(2022)은 잠재 확산 모델(LDM) 개념을 도입했습니다. LDM에서 확산 모델은 강력한 사전 학습된 자동 인코더의 잠재 공간 내에 적용됩니다. 이 접근 방식은 눈에 띄지 않는 세부 사항을 선택적으로 제거하는 별도의 압축 단계와 함께 효과적인 생성 모델임이 입증되었습니다. 잠재 공간에서 작동함으로써 LDM은 픽셀 공간 평가의 단점을 극복하여 추론 속도를 높이고 학습 비용을 줄입니다. fMRI로부터의 이미지 디코딩 뇌 활동으로부터 자극 내용을 재구성하는 가장 최근의 연구는 주로 fMRI 데이터에 초점을 맞추고 있습니다. 뇌의 혈중 산소 수치 의존적(BOLD) 신호를 측정하는 fMRI는 뇌 신호 디코딩에서 상당한 진전을 이루었습니다. fMRI의 기존 시각 디코딩 방법은 일반적으로 생성적 적대 신경망(GAN) 및 변형 자동 인코더(VAE)와 같은 딥 생성 신경망을 페어링된 뇌-이미지 데이터로 학습하는 데 의존합니다(Shen et al. 2019; Beliy et al. 2019). 그러나 이러한 기존 방법의 디코딩 성능은 일반적으로 제한적이며 고해상도의 시각 내용을 생성하는 데 어려움을 겪습니다. 딥 생성 모델을 처음부터 학습하는 것은 일반적으로 어렵고 뇌 신호의 데이터 세트가 비교적 작고 노이즈가 많기 때문입니다. 따라서 최근 연구에서는 뇌 신호를 신중하게 사전 학습된 잠재 공간에 직접 매핑하고 대규모 사전 학습된 모델을 미세 조정하여 다양하고 고해상도의 이미지를 생성하려고 시도합니다. Takagi와 Nishimoto는 뇌 활동을 잠재 공간에 매핑하고 LDM을 사용하여 자연스러운 이미지로 변환합니다.MinD-Vis(Chen et al. 2023)는 마스크 뇌 모델링과 LDM을 통합하여 의미 정보가 보존된 더욱 그럴듯한 이미지를 생성합니다.Zeng et al.은 뇌 신호의 실루엣 정보를 제어 가능한 확산 모델과 통합하여 원래 시각 자극과 일치하는 고품질 이미지를 재구성합니다.이러한 방법은 더욱 그럴듯하고 의미적으로 의미 있는 이미지를 생성합니다.EEG 신호에서 이미지 디코딩 EEG는 더 휴대성이 뛰어나지만 공간 해상도가 비교적 낮고 fMRI에 비해 노이즈가 더 커서 뇌 신호에서 시각적 경험을 디코딩하는 것이 어려운 문제입니다.Brain2Image(Kavasidis et al. 2017)는 GAN 및 VAE 기술을 스택한 장단기 메모리(LSTM)를 구현하여 EEG 신호(Kavasidis et al. 2017)에서 ImageNet(Krizhevsky, Sutskever, and Hinton 2012)의 보이는 이미지를 생성합니다. Neurovison(Khare et al. 2022)은 지각된 이미지를 개발하기 위해 GAN(CProGAN)의 조건부 진행적 성장을 제안하고 더 높은 개시 점수를 보였습니다. Ye et al.은 교차 모달 정렬에 초점을 맞추고 인스턴스 수준에서 이미지를 검색하여 EEG 신호에 대한 구별 가능한 모델 출력을 보장합니다. 또한 EEG 데이터와 Image CLIP 임베딩을 정렬하기 위한 보조 작업으로 확산 모델을 미세 조정하는 우리의 작업과 병행되는 DreamDiffusion(Bai et al. 2023)이 있다는 점에 유의합니다. 그러나 DreamDiffusion의 종단 간 학습 프레임워크는 EEG 신호에서 다중 레벨 의미 정보를 효과적으로 디코딩하고 활용하는 데 어려움을 겪어 고유한 노이즈 특성을 처리하는 능력이 제한됩니다. 또한 DreamDiffusion은 확산 모델을 미세 조정해야 하며, 이는 확장성과 효율성 측면에서 실질적인 어려움과 한계를 초래합니다. 방법론 이 섹션에서는 EEG 신호에서 다단계 의미를 추출한 다음 이를 사전 학습된 확산 모델에 통합하여 EEG 신호에서 관찰된 시각 자극을 재구성하는 방법인 NEUROIMAGEN을 설계합니다. NEUROIMAGEN에서 다단계 의미 추출의 직관을 간략히 소개합니다. EEG 신호는 비정상적 시계열 신호이며 신체 움직임과 같은 아티팩트에 의해 방해받기 쉬워 신호의 SNR이 낮습니다. 이 과제를 해결하기 위해 다양한 세분성으로 다른 의미 정보를 디코딩합니다. 구체적으로, 실루엣 정보의 돌출성 맵과 같은 픽셀 수준 의미는 관찰된 자극의 세밀한 색상, 위치 및 모양 세부 정보를 보존합니다. 샘플 수준 의미는 시각적 콘텐츠의 개념 또는 범주와 같은 시각적 자극에 대한 대략적인 설명을 제공합니다. 이러한 설계는 노이즈가 많은 시계열 EEG 데이터로 인해 발생하는 과제를 효과적으로 관리할 수 있는 능력을 보여주며, 결과적으로 고품질 시각적 자극의 재구성을 용이하게 합니다. 다음에서 먼저 문제를 공식화하고 NEUROIMAGEN에 대한 개요를 제공합니다. 그런 다음 NEUROIMAVisual Stimuli Multi-level Information Supervision Pixel Level EEG Signals Fine-grained Control M EldmDjdm Latent Diffusion Model t=Diffusion Process M의 다중 레벨 의미론 추출을 설명합니다. 캡션 샘플 레벨 노이즈 제거 프로세스 &quot;항공기 이미지&quot; CLIP 임베딩 EEG 신호 디코딩 Coarse-grained Control CLIP CLIP 임베딩 감독 재구성된 이미지 그림 1: NEUROIMAGEN 개요. 점선이 있는 모든 모듈, 즉 픽셀 레벨 감독 및 샘플 레벨 감독은 학습 단계에서만 사용되며 추론 단계에서 제거됩니다. GEN에는 픽셀 수준 의미론과 샘플 수준 의미론이 포함되며 디코딩 절차의 해당 학습 세부 정보가 포함됩니다. 마지막으로, 조대 및 세밀한 의미론을 사전 학습된 잠재 확산 모델과 통합하여 EEG 신호에서 관찰된 시각 자극을 재구성하는 NEUROIMAGEN의 이미지 재구성 절차를 자세히 설명합니다. 문제 진술 = 이 섹션에서는 문제를 공식화하고 NEUROIMAGEN에 대한 개요를 제공합니다. 쌍을 이룬 {(EEG, image)} 데이터 세트를 {(xi, Yi)}1로 두겠습니다. 여기서 Yi Є RH×W×³는 뇌 활동을 유발하는 시각 자극 이미지이고 x¿ € RC×T는 기록된 해당 EEG 신호를 나타냅니다. 여기서 C는 EEG 센서의 채널 번호이고 T는 관찰된 이미지와 관련된 시퀀스의 시간적 길이입니다. 이 연구의 일반적인 목적은 관찰된 시각 자극과 높은 수준의 유사성을 달성하는 데 초점을 맞춘 해당 EEG 신호 x를 사용하여 이미지 y를 재구성하는 것입니다. 다중 레벨 의미론 추출 프레임워크 그림 1은 NEUROIMAGEN의 아키텍처를 보여줍니다. 우리의 접근 방식에서 우리는 {M₁(x), M₂(x), · · ·‚ Mn(x)}로 표현되는 다중 레벨 의미론을 추출합니다. 이는 시각적 자극에 해당하는 EEG 신호에서 거친 입자 정보에서 세밀한 입자 정보까지 다양한 세분성 범위를 포착합니다. 거친 입자 의미론은 상위 레벨 개요 역할을 하여 시각적 자극의 기본 속성과 범주를 빠르게 이해하는 데 도움이 됩니다. 반면, 세밀한 의미론은 국소적 특징, 미묘한 변화, 소규모 패턴과 같은 더 자세한 정보를 제공합니다. 다중 레벨 의미론은 그런 다음 고품질 이미지 재구성 모듈 F에 공급되어 시각적 자극 ŷ F[M₁(x), M2(x), · · ·‚Mn(x)]을 재구성합니다. 구체적으로 다음과 같이 2단계 의미론을 제공합니다. Mp와 Ms를 각각 픽셀 수준 의미 추출기와 샘플 수준 의미 추출기라고 하자. 픽셀 수준 의미론 = 실루엣 정보의 돌출성 맵 Mp(x) = Rªp×Wp×³로 정의된다. 이 단계를 통해 픽셀 공간에서 EEG 신호를 분석하고 대략적인 구조 정보를 제공할 수 있다. 그런 다음 샘플 수준 의미론을 Ms(x) = RLXDs로 정의하여 이미지 범주나 텍스트 캡션과 같은 거친 정보를 제공한다. 2단계 의미론을 완전히 활용하기 위해 고품질 이미지 재구성 모듈 F는 잠재 확산 모델이다. 돌출성 맵 Mp(x)를 초기 이미지로 시작하여 샘플 수준 의미론 M,(x)를 활용하여 돌출성 맵을 다듬고 마지막으로 ŷ F(Mp(x), Ms(x))를 재구성한다. 픽셀 수준 의미 추출 = 이 섹션에서는 픽셀 수준 의미, 즉 실루엣 정보의 돌출성 맵을 디코딩하는 방법을 설명합니다. 이 픽셀 수준 의미 추출의 직관은 관찰된 시각적 자극의 색상, 위치 및 모양 정보를 캡처하는 것입니다. 이는 세밀하고 노이즈가 있는 EEG 신호에서 재구성하기가 매우 어렵습니다. 그러나 그림 3에서 볼 수 있듯이 낮은 이미지 해상도와 제한된 의미 정확도에도 불구하고 이러한 돌출성 맵은 노이즈가 있는 EEG 신호에서 시각적 자극의 대략적인 구조 정보를 성공적으로 캡처합니다. 구체적으로, 픽셀 수준 의미 추출기 Mp는 두 가지 구성 요소로 구성됩니다. (1) EEG 신호의 차별적 특징을 얻기 위한 대조적 특징 학습 및 (2) 학습된 EEG 특징을 기반으로 한 실루엣 정보의 돌출성 맵 추정. 대조적 특징 학습 우리는 사람들이 비슷한 시각적 자극을 받을 때, 즉 같은 종류의 이미지를 볼 때 EEG 신호의 임베딩을 결합하기 위해 대조 학습 기술을 사용합니다.삼중 손실(Schroff, Kalenichenko, and Philbin 2015)은 다음과 같이 활용됩니다.삼중 = max(0, ẞ+|| ƒfo(xª) — ƒo (x³)|| —||ƒfo(xª) — ƒo(x^)||2), (1) 여기서 fo는 EEG 신호를 특징 공간에 매핑하는 특징 추출 함수(Kavasidis et al. 2017)입니다. xa, xp, xn은 각각 샘플링된 앵커, 양성 및 음성 EEG 신호 세그먼트입니다. 방정식의 목적은 (1)은 동일한 레이블(시각적 자극의 클래스)을 갖는 xª와 xp 사이의 거리를 최소화하는 동시에 다른 레이블을 갖는 xa와 x&quot; 사이의 거리를 최대화하는 것입니다. 특징 추출 네트워크에 의해 데이터 표현이 작은 클러스터로 압축되는 것을 방지하기 위해 마진 항 ẞ가 트리플렛 손실에 통합되었습니다. 돌출성 맵 추정 EEG 신호 fo(x)의 특징을 얻은 후 이제 해당 신호와 무작위 샘플링된 잠재 z ~ N(0, 1)에서 실루엣 정보의 돌출성 맵을 생성할 수 있습니다. 즉, Mp(x) = G(z, fo(x)). G는 돌출성 맵 생성기를 나타냅니다. 이 논문에서는 생성적 적대 네트워크(GAN)(Goodfellow et al. 2020) 프레임워크의 생성기를 사용하여 돌출성 맵을 생성하고 적대적 손실은 다음과 같이 정의됩니다. D Lady = max(0, 1 – D(A(y), fø(x)))+ max(0,1 + D(A(M₁(x))), fø(x))), – D(A(Mp(x)), fø(x)). La adv 샘플 수준 의미 추출 앞서 언급했듯이, EEG 신호는 내재된 노이즈로 악명이 높아 정확한 정보와 세밀한 정보를 모두 추출하기 어렵습니다. 따라서 세밀한 픽셀 수준 의미 외에도 샘플 수준 의미 추출 방법을 사용하여 이미지 콘텐츠의 주요 객체 범주와 같은 일부 거친 정보를 도출합니다. 이러한 특징은 상대적으로 순위가 낮고 정렬하기가 더 쉽습니다. 이러한 특징은 덜 자세하지만 관찰된 시각적 자극을 재구성하는 데 의미가 있는 정확한 거친 정보를 제공할 수 있습니다. 구체적으로, 프로세스 Ms는 입력 EEG 신호에서 디코딩된 정보를 대조 언어 이미지 사전 학습(CLIP) 모델(Radford et al. 2021)과 같은 다른 추가 주석 모델에 의해 생성된 일부 생성된 이미지 캡션에 정렬하려고 시도합니다. 아래에서 정렬을 통한 이미지 캡션 기준 진실 생성 및 의미 디코딩 프로세스를 자세히 설명합니다. GT 이미지(2)(3) GAN에서 생성기 G 외에 생성기의 이미지와 기준 진실 이미지 x를 구별하기 위해 판별기 D가 도입되었습니다. 이것은 방정식(2)에서 정의된 힌지 손실(Lim and Ye 2017)을 최소화하여 최적화됩니다. A는 미분 가능 증강 함수(Zhao et al. 2020)입니다. 적대적 학습 프로세스를 안정화하고 모드 붕괴 문제를 완화하기 위해 모드 탐색 정규화(Mao et al. 2019)를 추가합니다. Lms , So(2)))), (4) ´ dx (G (z1, fø(x)), G (z2, fø(x)))` dz (21, 22) 여기서 d()는 이미지 공간 x 또는 잠재 공간 z의 거리 측정값을 나타내고 21, 22 N(0, 1)은 두 개의 서로 다른 샘플링된 잠재 벡터입니다. ~ 시각적 자극으로부터 생성된 돌출성 맵의 정확성을 강화하기 위해 관찰된 이미지를 감독으로 사용하고 구조적 유사성 지수 측정(SSIM)도 통합합니다. LSSIM(2μxμMp(x) + C₁) (20xσMp(x) + C2) (µ² + H²¾¼₂ (x) + C₁ ) ( 0² + 0% \p(x) + C2) (5) 여기서 μx, μMp(x), σx, σMp(x)는 생성기의 기준 진실 이미지와 재구성된 돌출성 맵의 평균 및 표준 값을 나타냅니다. C₁ 및 C2는 계산을 안정화하기 위한 상수입니다. 생성기의 최종 손실은 손실의 가중 합입니다. LG = α₁ · Lady + α₂ · Lms + α3 · LSSIM, . • (6) 및 ai{1,2,3}은 손실 항을 균형 잡기 위한 하이퍼파라미터입니다. 라벨 캡션 아프리카 코끼리 이미지 낙하산 이미지 데이지 이미지 산악 자전거 이미지 BLIP 캡션 큰 바위 옆에 서 있는 코끼리 배너를 들고 공중에서 낙하산을 날리는 사람 노란색 중심의 빨간색과 흰색 꽃 숲 속의 산길을 따라 산악 자전거를 타는 남자 그림 2: 각각의 기준 진실 이미지, 라벨 캡션 및 BLIP 캡션의 예.이미지 캡션 생성 EEG 신호에서 의미 정보의 디코딩 절차를 감독하는 데 도움이 되는 각 이미지에 대한 캡션을 생성하는 두 가지 방법을 제안합니다. 관찰된 이미지는 이미지의 클래스를 포함하는 ImageNet 데이터 세트에서 가져온 것이므로 그림 2의 가운데 열에 표시된 것처럼 각 이미지의 클래스 이름을 캡션으로 사용하는 간단하고 휴리스틱한 라벨 캡션 방법을 정의합니다. 두 번째 방법은 사전 훈련된 비전 모델과 대규모 언어 모델을 활용하는 일반적이고 계산 효율적인 비전 언어 사전 훈련(VLP) 모델인 이미지 캡션 모델 BLIP(Li et al. 2023)을 사용하는 것입니다. 우리는 BLIP 모델의 기본 매개변수 구성을 선택하여 이미지에 캡션을 붙입니다.예제는 그림 2의 오른쪽 열에 나와 있습니다.보시다시피, 레이블 캡션은 주로 클래스 수준 정보에 초점을 맞추는 경향이 있으며, BLIP에서 파생된 캡션은 이미지 수준에서 추가 세부 정보를 제공합니다.텍스트 CLIP 임베딩 예측 이미지 캡션 기준 진실을 생성한 후, 의미 디코딩의 목표는 캡션 정보를 정렬하기 위해 EEG 신호에서 정보를 추출하는 것입니다.이 절차는 잠재 공간에서 수행되며, 잠재 임베딩은 위에서 생성된 캡션의 CLIP 모델에서 처리됩니다.특히, 생성된 캡션에서 CLIP 임베딩 ĥclip을 추출하고 EEG 샘플 수준 인코더의 출력 hclip을 손실 함수와 정렬합니다.여기서 Lclip = ||hclip clip ||2, (7) {B,L}은 BLIP 캡션 임베딩 또는 레이블 캡션 임베딩을 나타냅니다. 다단계 EEG 의미론과 확산 모델 결합 이 섹션에서는 다단계 의미론이 시각적 자극 재구성을 위한 확산 모델에 효과적으로 통합되는 방법에 대한 포괄적인 설명을 제시합니다. 우리는 Mp(x)로 표시되는 픽셀 수준 의미론(G(z, f(x))를 사용하여 얻음)과 M¸(x)로 표시되는 샘플 수준 의미론(hclip을 사용하여 얻음)을 모두 활용하여 이미지 재구성 프로세스에 대한 다양한 세분성 제어를 가합니다. 재구성된 시각적 자극은 ŷ F(Mp(x), M¸(x)) = F(G(fø(x), hclip))로 정의됩니다. 구체적으로, 우리는 조건부 텍스트 프롬프트 임베딩의 안내에 따라 이미지 대 이미지 재구성을 수행하기 위해 잠재 확산 모델을 사용했습니다.(1) 먼저, 우리는 EEG 신호로부터 픽셀 수준 의미론 G(f(x))를 재구성하고 관찰된 시각 자극의 해상도로 크기를 조정합니다.(2) 그런 다음 G(f(x))는 잠재 확산 모델에서 자동 인코더의 인코더 Eldm에 의해 처리되고 확산 프로세스를 통해 노이즈가 추가됩니다.(3) 그런 다음, 우리는 노이즈 제거 프로세스를 안내하기 위해 U-Net의 교차 주의 입력으로 샘플 수준 의미론 hclip을 통합합니다.(4) 우리는 Didm을 사용하여 노이즈 제거 프로세스의 출력을 이미지 공간에 투영하고 마지막으로 고품질 이미지 ŷ를 재구성합니다.데이터 세트 실험 제안된 방법론의 효과는 EEG 이미지 데이터 세트(Spampinato et al. 2017)를 사용하여 검증됩니다. 이 데이터 세트는 공개적으로 접근 가능하며 6명의 피험자로부터 수집한 EEG 데이터로 구성되어 있습니다. 데이터는 피험자에게 시각적 자극을 제시하여 수집되었으며, ImageNet 데이터 세트(Krizhevsky, Sutskever, and Hinton 2012) 내 40개의 서로 다른 범주에서 50개의 이미지를 통합했습니다. 각 자극 세트는 25초 간격으로 표시되었으며, 시각 경로를 재설정하기 위한 10초의 블랙아웃 기간으로 구분되었습니다. 이 프로세스로 총 2000개의 이미지가 생성되었으며, 각 실험은 1,400초(약 23분 20초) 동안 지속되었습니다. EEG 이미지 데이터 세트는 동물(예: 판다) 및 사물(예: 항공사)을 포함한 다양한 이미지 클래스를 포함합니다. 영어: 일반적인 데이터 분할 전략(Kavasidis et al. 2017)에 따라 사전 처리된 원시 EEG 신호와 해당 이미지를 80%(1, 이미지), 10%(200개 이미지), 10%(200개 이미지)의 해당 비율로 훈련, 검증 및 테스트 세트로 나누고 모든 피험자에 대해 하나의 모델을 구축합니다. 데이터 세트는 이미지별로 분할되어 단일 이미지에 대한 모든 피험자의 EEG 신호가 분할에 퍼지지 않도록 합니다. 평가 지표 N-way Top-k 분류 정확도(ACC) (Chen et al. 2023)에 따라 N-way top-k 분류 정확도를 사용하여 재구성된 이미지의 의미적 정확성을 평가합니다. 구체적으로, 기준 진실 이미지 y와 재구성된 이미지 ŷ는 사전 훈련된 ImageNetlk 분류기(Dosovitskiy et al. 2020)에 입력되어 У와 ŷ가 같은 클래스에 속하는지 여부를 판별합니다. 그런 다음 재구성된 이미지에서 N개의 선택된 클래스에서 상위 k 분류가 기준 진실 이미지의 클래스와 일치하는지 확인합니다. 중요한 점은 이 평가 지표가 이미지에 대한 사전 정의된 레이블의 필요성을 없애고 기준 진실과 재구성된 이미지 간의 의미적 일관성을 나타내는 지표 역할을 한다는 것입니다. 이 논문에서는 50-way 상위 1 정확도를 평가 지표로 선택합니다. Inception Score(IS) (Salimans et al. 2016)에 의해 도입된 IS는 일반적으로 생성 모델에서 재구성된 이미지의 품질과 다양성을 평가하는 데 사용됩니다. IS를 계산하기 위해 사전 학습된 Inception-v3 분류기(Szegedy et al. 2016)를 사용하여 재구성된 이미지의 클래스 확률을 계산합니다. IS를 사용하여 방법과 기준선 간의 정량적 비교를 제공합니다. 구조적 유사성 지수 측정(SSIM) SSIM은 이미지 품질 평가를 위한 포괄적이고 지각적으로 관련성 있는 지표를 제공합니다. SSIM은 각각 휘도, 대비 및 구조 구성 요소에서 기준 진실 이미지와 해당 재구성 이미지의 여러 창에서 계산됩니다.결과 ImageNet 데이터 세트의 실험 결과 주요 결과는 그림 3에 나와 있습니다.빨간색 상자로 왼쪽에 배치된 이미지는 기준 진실 이미지를 나타냅니다.왼쪽에서 두 번째 이미지는 EEG 신호에서 재구성된 돌출성 맵을 나타냅니다.오른쪽의 세 이미지는 EEG 신호의 샘플 수준 의미론의 지침에 따라 주어진 픽셀 수준 돌출성 맵에 대한 세 가지 샘플링 결과를 보여줍니다.기준 진실 이미지와 재구성된 돌출성 맵과 비교한 결과, EEG 신호에서 픽셀 수준 의미론을 추출한 것이 제한된 의미 정확도에도 불구하고 보이는 이미지의 색상, 위치 및 모양 정보를 성공적으로 포착한다는 것을 검증합니다. GT 이미지와 세 개의 재구성된 샘플을 비교하면 잠재 확산 모델이 디코딩된 돌출성 맵 GT 이미지를 성공적으로 다듬는다는 것이 입증되었습니다. 돌출성 맵 샘플1 샘플2 샘플GT 이미지 돌출성 맵 샘플2 샘플Daser bay Indbly SCOTT그림 3: NEUROIMAGEN의 주요 결과. 빨간색 상자로 왼쪽에 배치된 이미지는 기준 진실 이미지를 나타냅니다. 왼쪽에서 두 번째 이미지는 EEG 신호에서 재구성된 픽셀 수준 돌출성 맵을 나타냅니다. 오른쪽의 세 이미지는 샘플 수준 의미론의 지침에 따라 주어진 돌출성 맵에 대한 세 가지 샘플링 결과를 보여줍니다. EEG 신호의 샘플 수준 의미론에 대한 거칠지만 정확한 지침이 있습니다. 뇌 신호에서 순수하게 재구성된 고품질 이미지는 시각적 이미지와 지각적, 의미적으로 유사합니다. 모델 Brain2Image ACC (%) NeuroVision IS SSIM 5.5.NEUROIMAGEN 85.33.50 0.대상 subjACC (%) IS 83.SSIM 32.64 0.subj84.32.33 0.subj86.32.93 0.subj86.32.40 0.subj87.32.97 0.subj85.31.76 0.표 1: EEG 영상 데이터 세트에 대한 NEUROIMAGEN, Brain2Image(Kavasidis et al. 2017) 및 NeuroVision(Khare et al. 2022)의 정량적 결과. 기준선과의 비교 NEUROIMAGEN과 기준선의 정량적 결과는 표 1에 나와 있습니다. 재구성된 영상의 품질을 예시하기 위해 관련 문헌에 보고된 IS를 소개했습니다. IS는 테스트 세트 내의 모든 피험자와 모든 클래스에서 재구성된 모든 이미지를 포함하여 계산됩니다.표 1에서 볼 수 있듯이, NEUROIMAGEN의 IS는 Brain2Image 및 NeuroVision보다 상당히 높습니다.또한 (Bai et al. 2023)에서 영감을 얻어 그림 4의 기준선과 정성적 비교를 제공합니다.볼 수 있듯이, NEUROIMAGEN으로 재구성된 이미지의 품질은 Brain2Image로 재구성된 이미지보다 현저히 높습니다.이러한 관찰된 향상은 제안된 방법론의 효과성과 우수성을 검증하는 데 도움이 됩니다.표 2: 다양한 피험자의 정량적 결과.다양한 피험자의 생성 일관성 EEG 신호는 피험자마다 상당히 다른 피험자별 인지 과정이므로 이 섹션에서는 다양한 개인에서 NEUROIMAGEN의 견고성과 실현 가능성을 검증합니다.그림 5에서 볼 수 있듯이.다양한 피험자의 정량적 측정 기준은 안정적이며, 이는 NEUROIMAGEN의 일반화 능력을 증명합니다. 그림 5에 정성적 결과가 나와 있습니다. 다른 피험자의 샘플링이 기준 진실 이미지와 의미적으로 유사한 것을 볼 수 있습니다. 절제 연구 우리는 또한 EEG 이미지 데이터 세트에 대한 실험을 수행하여 NEUROIMAGEN의 각 모듈의 효과를 분석합니다. B와 L을 BLIP 캡션을 감독으로 사용하거나 레이블 캡션을 감독으로 사용하여 EEG 신호의 샘플 수준 의미론으로 정의합니다. I를 EEG 신호의 픽셀 의미론으로 정의합니다. ACC, IS 및 SSIM을 사용하여 다양한 방법의 효과를 검증합니다. 우리의 Brain2Image Airliner Panda Jack-o&#39;-Lantern Jack-Knick 그림 4: 기준 Brain2Image(Kavasidis et al. 2017)와 제안한 NEUROIMAGEN을 &#39;Airliner&#39;, &#39;Panda&#39; 및 &#39;Jack-o&#39;-Lantern&#39;의 세 가지 클래스로 비교합니다. 첫 번째와 두 번째 행은 각각 Brain2Image와 우리의 NEUROIMAGEN의 결과를 보여줍니다. 모델 BLI 1 XX ✓X ✓ X 85.✓ XX 74.✓ ✓ ✓ 65.X ✓ ✓ 85.ACC(%) IS SSIM 4.16.31 0.34.12 0.29.87 0.25.86 0.33.50 0.표 3: 절제 연구의 정량적 결과.B와 L은 각각 EEG 신호에서 BLIP 캡션과 레이블 캡션을 사용한 의미 디코딩을 나타냅니다.I는 EEG 신호에서 지각 정보 디코딩을 나타냅니다.픽셀 수준 의미론 EEG 신호에서 픽셀 수준 의미론의 효과를 보여주기 위해 모델 2, 3, 4, 5에 대한 검증을 수행합니다.2와 5, 3과 4를 비교하여 픽셀 수준 의미론, 즉 돌출성 맵을 사용하면 재구성된 이미지와 기준 진실 이미지의 구조적 유사성을 크게 높일 수 있음을 발견했습니다. 샘플 수준 의미론 우리는 EEG 신호에서 샘플 수준 의미론 디코딩 모듈을 조사하여 잡음 제거 프로세스를 안내합니다.모델 1, 4 및 5는 각각 saliency만 사용한 실험 결과, saliency 맵과 BLIP 캡션의 감독을 통한 샘플 수준 의미론, 그리고 saliency 맵과 레이블 캡션의 감독을 통한 샘플 수준 의미론을 나타냅니다.실험 결과는 1과 4, 1과 5를 비교하여 샘플 수준 의미론을 사용하면 재구성된 이미지의 의미 정확도가 크게 증가한다는 것을 보여줍니다.BLIP 캡션 대 레이블 캡션 또한 두 가지 캡션 감독 방법을 모델 2와 3, 4와 5와 비교합니다.모든 메트릭에서 레이블 캡션의 실험 결과는 BLIP 캡션을 사용하는 것보다 우수합니다.이러한 결과는 EEG 신호가 클래스 수준 정보만 캡처할 수 있다는 것을 나타냅니다.따라서 BLIP 잠복 예측이 정확하지 않아 확산 모델의 성능이 저하됩니다.
--- CONCLUSION ---
이 논문에서 우리는 시각적으로 유발된 뇌 활동을 이해하는 방법을 탐구합니다. 구체적으로, 우리는 EEG 신호로부터 시각적 지각 이미지를 재구성하는 NEUROIMAGEN이라는 프레임워크를 제안했습니다. NEUROIMAGEN 첫 번째 카누 전기 기타 피자 말미잘 소 &gt; 이미지 SubjSubjSubjSubjSubjSubj그림 5: 다른 피험자의 재구성된 이미지 비교. 빨간색 상자가 있는 왼쪽의 이미지는 기준 진실 이미지를 나타냅니다. 다른 여섯 개의 이미지는 다른 피험자의 재구성된 이미지를 나타냅니다. 표시된 클래스에는 물고기, 피자, 기타, 카누가 포함됩니다. EEG 신호로부터 다중 레벨 의미 정보, 즉 픽셀 레벨의 돌출성 맵과 샘플 레벨의 텍스트 설명을 생성한 다음 확산 모델을 사용하여 추출된 의미를 결합하고 고해상도 이미지를 얻습니다. 정성적 및 정량적 실험 모두 NEUROIMAGEN의 강력한 능력을 보여줍니다. 이 분야의 예비 작업으로서, 우리는 인간의 시각적 지각을 복잡한 EEG 신호와 연결할 가능성을 보여줍니다. 우리는 이 발견이 인공지능, 인지과학, 신경과학 분야에서 협력하여 시각 인식 정보를 처리하기 위해 우리 뇌의 신비를 밝히는 데 더욱 동기를 부여할 수 있을 것으로 기대합니다.참고문헌 Allen, EJ; St-Yves, G.; Wu, Y.; Breedlove, JL; Prince, JS; Dowdle, LT; Nau, M.; Caron, B.; Pestilli, F.; Charest, I.; et al. 2022. 인지 신경과학과 인공지능을 연결하는 대규모 7T fMRI 데이터 세트.Nature Neuroscience, 25(1): 116–126. Bai, Y.; Wang, X.; Cao, Y.; Ge, Y.; Yuan, C.; and Shan, Y. 2023. DreamDiffusion: Generating High-Quality Images from Brain EEG Signals. arXiv 사전 인쇄본 arXiv:2306.16934. Beliy, R.; Gaziv, G.; Hoogi, A.; Strappini, F.; Golan, T.; and Irani, M. 2019. From voxels to pixels and back: Selfsupervision in natural-image reconstruction from fMRI. Advances in Neural Information Processing Systems, 32. Chen, Z.; Qing, J.; Xiang, T.; Yue, WL; and Zhou, JH 2023. Seeing beyond the brain: Conditional diffusion model with sparse masked modeling for vision decoding. IEEE/CVF Conference on Computer Vision and Pattern Recognition의 회의록, 22710-22720. Chen, Z.; Qing, J.; and Zhou, JH 2023. Cinematic Mindscapes: High-quality Video Reconstruction from Brain Activity. arXiv 사전 인쇄본 arXiv:2305.11675. Dhariwal, P.; 및 Nichol, A. 2021. 확산 모델은 이미지 합성에서 gans를 이겼습니다. 신경 정보 처리 시스템의 발전, 34: 8780-8794. Dosovitskiy, A.; Beyer, L.; Kolesnikov, A.; Weissenborn, D.; Zhai, X.; Unterthiner, T.; Dehghani, M.; Minderer, M.; Heigold, G.; Gelly, S.; et al. 2020. 이미지는 16xwords의 가치가 있습니다: 대규모 이미지 인식을 위한 변압기. arXiv 사전 인쇄본 arXiv:2010.11929. Goodfellow, I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.; Warde-Farley, D.; Ozair, S.; Courville, A.; 및 Bengio, Y. 2020. 생성적 적대 네트워크. ACM 커뮤니케이션, 63(11): 139–144. Ho, J.; Jain, A.; 및 Abbeel, P. 2020. 확산 확률적 모델의 잡음 제거. 신경 정보 처리 시스템의 발전, 33: 6840-6851. Kavasidis, I.; Palazzo, S.; Spampinato, C.; Giordano, D.; 및 Shah, M. 2017. Brain2image: 뇌 신호를 이미지로 변환. 1809-1817년 제25회 ACM 국제 멀티미디어 컨퍼런스 회의록. Khare, S.; Choubey, RN; Amar, L.; 및 Udutalapalli, V. 2022. NeuroVision: cProGAN을 사용한 인식된 이미지 재생성. 신경 컴퓨팅 및 응용 프로그램, 34(8): 5979-5991. Krizhevsky, A.; Sutskever, I.; 및 Hinton, GE 2012. 딥 합성곱 신경망을 사용한 Imagenet 분류. 신경 정보 처리 시스템의 발전, 25. Li, J.; Li, D.; Savarese, S.; 및 Hoi, S. 2023. Blip-2: 동결된 이미지 인코더와 대규모 언어 모델을 사용한 언어-이미지 사전 학습 부트스트래핑. arXiv 사전 인쇄본 arXiv:2301.12597. Lim, JH; 및 Ye, JC 2017. 기하학적 gan. arXiv 사전 인쇄본 arXiv:1705.02894. Mao, Q.; Lee, H.-Y.; Tseng, H.-Y.; Ma, S.; 및 Yang, MH 2019. 다양한 이미지 합성을 위한 모드 탐색 생성적 적대 네트워크. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 논문집, 1429-1437. Palazzo, S.; Spampinato, C.; Kavasidis, I.; Giordano, D.; Schmidt, J.; and Shah, M. 2020. 신경 활동 및 시각적 특징의 다중 모드 학습을 통한 뇌 표현 디코딩. IEEE 패턴 분석 및 머신 인텔리전스 저널, 43(11): 3833-3849. Radford, A.; Kim, JW; Hallacy, C.; Ramesh, A.; Goh, G.; Agarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.; et al. 2021. 자연어 감독에서 이전 가능한 시각적 모델 학습. International Conference on Machine Learning, 8748-8763. Rombach, R.; Blattmann, A.; Lorenz, D.;Esser, P.; 및 Ommer, B. 2022. 잠재 확산 모델을 사용한 고해상도 이미지 합성.IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 논문집, 1068410695.Ronneberger, O.;Fischer, P.; 및 Brox, T. 2015.U-net: 생물의학 이미지 분할을 위한 합성 네트워크.의료 이미지 컴퓨팅 및 컴퓨터 지원 개입, 234-241.Salimans, T.;Goodfellow, I.;Zaremba, W.;Cheung, V.;Radford, A.; 및 Chen, X. 2016.Gans 훈련을 위한 개선된 기술.신경 정보 처리 시스템의 발전, 29.Schroff, F.;Kalenichenko, D.; 및 Philbin, J. 2015. Facenet: 얼굴 인식 및 클러스터링을 위한 통합 임베딩. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 815-823. Shen, G.; Dwivedi, K.; Majima, K.; Horikawa, T.; 및 Kamitani, Y. 2019. 인간 뇌 활동으로부터 종단 간 심층 이미지 재구성. Frontiers in Computational Neuroscience, 13: 21. Sohl-Dickstein, J.; Weiss, E.; Maheswaranathan, N.; 및 Ganguli, S. 2015. 비평형 열역학을 사용한 심층 비지도 학습. International Conference on Machine Learning, 2256-2265. Song, J.; Meng, C.; 및 Ermon, S. 2020. 확산 암시적 모델의 노이즈 제거. arXiv 사전 인쇄본 arXiv:2010.02502. Spampinato, C.; Palazzo, S.; Kavasidis, I.; Giordano, D.; Souly, N.; and Shah, M. 2017. 자동화된 시각 분류를 위한 딥 러닝 인간 마인드. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 6809-6817. Szegedy, C.; Vanhoucke, V.; Ioffe, S.; Shlens, J.; and Wojna, Z. 2016. 컴퓨터 비전을 위한 인셉션 아키텍처 재고. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 2818-2826. Takagi, Y.; and Nishimoto, S. 2023. 인간 뇌 활동의 잠재 확산 모델을 사용한 고해상도 이미지 재구성. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 논문집, 14453–14463. Yang, L.; Zhang, Z.; Song, Y.; Hong, S.; Xu, R.; Zhao, Y.; Shao, Y.; Zhang, W.; Cui, B.; and Yang, M.-H. 2022. 확산 모델: 방법 및 응용 프로그램에 대한 포괄적 조사. arXiv 사전 인쇄본 arXiv:2209.00796. Ye, Z.; Yao, L.; Zhang, Y.; and Gustin, S. 2022. See what you see: Self-supervised cross-modal retrieval of visual stimuli from brain activity. arXiv 사전 인쇄본 arXiv:2208.03666. Zeng, B.; Li, S.; Liu, X.; Gao, S.; Jiang, X.; Tang, X.; Hu, Y.; Liu, J.; 및 Zhang, B. 2023. 제어 가능한 마인드 시각 확산 모델. arXiv 사전 인쇄본 arXiv:2305.10135. Zhao, S.; Liu, Z.; Lin, J.; Zhu, J.-Y.; 및 Han, S. 2020. 데이터 효율적인 gan 학습을 위한 미분 가능한 증강. 신경 정보 처리 시스템의 발전, 33: 7559-7570.
