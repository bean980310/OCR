--- ABSTRACT ---
전화 통화의 필사본은 영업, 고객 서비스, 의료 및 법 집행과 같은 다양한 분야에서 상당한 가치가 있습니다. 그럼에도 불구하고 이러한 녹음된 대화를 분석하는 것은 힘들고 시간이 많이 걸리는 프로세스가 될 수 있으며, 특히 확장되거나 다면적인 대화를 다룰 때 더욱 그렇습니다. 이 연구에서는 효율적이고 정확한 통화 분할 및 주제 추출을 위한 새로운 방법인 GPTdistilled Calls Segmentation and Tagging(GPT-Calls)을 제안합니다. GPT-Calls는 오프라인 및 온라인 단계로 구성됩니다. 오프라인 단계는 주어진 주제 목록에 한 번 적용되며 GPT 모델을 사용하여 각 주제에 대한 합성 문장 분포를 생성하고 앵커 벡터를 추출하는 것을 포함합니다. 온라인 단계는 모든 통화에 별도로 적용되며 오프라인 단계에서 발견된 주제 앵커와 필사된 대화 간의 유사성을 평가합니다. 그런 다음 유사성 점수에 시간 영역 분석을 적용하여 발언을 세그먼트로 그룹화하고 주제로 태그를 지정합니다. 제안된 패러다임은 레이블이 지정된 데이터가 필요 없는 정확하고 효율적인 통화 세분화 및 주제 추출 방법을 제공하므로 다양한 도메인에 적용할 수 있는 다재다능한 접근 방식입니다. 저희 알고리즘은 Dynamics 365 Sales Conversation Intelligence에서 프로덕션에서 작동하며, 저희의 연구는 다양한 Dynamics 365 Sales 테넌트에서 수집한 실제 영업 대화를 기반으로 합니다. 1.
--- INTRODUCTION ---
오늘날 경쟁이 치열한 시장에서 영업 담당자는 판매를 촉진하고 강력한 고객 기반을 유지하는 데 중요한 역할을 합니다. 영업 담당자가 고객과 상호 작용하는 주요 방법 중 하나는 전화 통화입니다. 이러한 전화 통화는 종종 품질 보증, 다른 판매자 교육 및 코칭, 통찰력 정리 등을 위해 녹음되고 필사됩니다. 따라서 영업 부서는 종종 수백만 건의 통화 필사본으로 구성된 광범위한 데이터베이스를 유지 관리하는데, 이는 수많은 작업에 대한 중요한 정보 소스 역할을 합니다. 그러나 녹음된 통화를 분석하는 것은 어렵고 시간이 많이 걸리는 작업일 수 있으며, 특히 대화가 길거나 여러 주제를 다룰 때 더욱 그렇습니다. *는 동등한 기여를 나타냅니다. 일반적인 접근 방식은 녹음된 텍스트를 후처리하고 각 세그먼트에 주제를 할당하여 통화를 세분화하는 것입니다. 이렇게 하면 판매자가 이전 통화에서 중요한 정보를 찾아 추출하는 프로세스가 간소화됩니다. 통화 세분화는 논의된 특정 주제나 테마에 따라 대화를 더 작은 섹션으로 나누는 것을 포함합니다. 이 세분화 및 태그 기능은 판매자와 관리자의 일상 업무를 크게 용이하게 합니다. 영업 담당자와 관리자가 과거 통화를 쉽게 추적하고 분석하고, 대화 주제에 따라 분류하고, 통화의 관련 부분으로 이동하여 중요한 정보를 추출하고, 필사된 통화를 처리하는 검색 엔진을 개선하는 등의 작업을 수행할 수 있습니다. 또한, 녹음된 통화의 자동 세분화 및 태그 지정을 통해 기업은 여러 측면에서 영업 전략과 프로세스를 최적화하는 데 도움이 될 수 있습니다. • • 판매자에게 개인화된 코칭 제공. 관리자는 전체 통화를 듣는 대신 통화의 특정 부분을 듣고 피드백과 지침을 제공할 수 있습니다. • • 고객 요구 사항, 선호도 및 문제점에 대한 통찰력 제공. 세분화되고 태그가 지정된 정보는 영업 전략을 맞춤화하고 고객 경험을 개선하는 데 사용할 수 있습니다. • • • 영업 대화에서 법률 및 윤리 지침 준수 모니터링. 판매자가 회사 정책 및 규정을 준수하고 있는지 확인. • • • 영업 실적 및 고객 행동에 대한 통찰력을 제공하는 보고서 및 대시보드 생성. 이 정보는 데이터 기반 의사 결정을 내리고 전반적인 비즈니스 성과를 개선하는 데 사용할 수 있습니다. 성공적인 결과와 관련이 있을 수 있는 통화의 주요 순간 식별. 이 정보는 영업 담당자를 교육하고 성과를 개선하는 데 사용할 수 있습니다. 궁극적으로 위의 모든 것이 고객 만족도, 충성도, 판매 및 수익 창출로 이어집니다. 안타깝게도 이 분야에서 많은 발전이 있었음에도 불구하고 현재의 콜 세분화 및 태그 지정 기술은 판매자와 관리자의 일상 업무에 미치는 영향과 침투를 방해하는 한계가 있습니다. 특히, 종종 최적이 아닌 콜 투 이반 캐신 - 헬스장 멤버십 개요 클립보드에 복사 메모 작업 항목. 언급 대본 제안된 메모 미리보기 × NW 00:10분 전 NW 콜 하이라이트 요약: - 발견 콜 - 100개 라이선스에 관심 있음 콜 분: • 고객이 무료 패스를 사용하고 싶어함 • 고객이 15~20파운드를 감량하려고 함 에이전트가 고객에게 체중 감량을 위한 프로그램이 있다고 알렸음 • 고객이 여름까지 체중 감량 목표를 달성하는 방법을 알고 싶어함 00:안녕하세요.그리고... 요청 및 com... NW 낸시 워... IC 이반 캐신 낸시 워너 검색 안녕하세요 이반, 저는 Dynamic fitness의 낸시입니다. IC Ivan Cashin 고객이 무료 패스를 사용하고 싶어합니다 +추가 00:00: 안녕하세요. NW Nancy Warner 고객이 15~20파운드를 감량하려고 합니다 +추가 00:00: 무료 패스를 사용해보셨는지 알아보기 위해 오늘 전화드립니다. IC Ivan Cashin 모두 보기 00: 아니요, 아직은 사용하지 않았습니다. 작업 항목 NW Nancy Warner Nancy Warner가 &quot;도움이 되는 정보&quot;에 대한 이메일을 +353892678274로 보냅니다. +추가 02:00: 좋아요, 문제 없습니다. 요청 및 불만 NW Nancy Warner 00: 무료 패스를 다운로드하기로 결정한 이유를 물어보겠습니다. 마무리 ་་་་감정 O 긍정적 중립 부정적 의견(0) ① |&lt;&lt; ‣ 小 00:00/ 02:그림 1. 통화 요약 대시보드. 요약(왼쪽), 제안된 메모(가운데), 필사된 대화(오른쪽)가 표시됩니다. 예측된 세분화와 관련 주제가 하단에 표시되고, 녹음된 통화 기간을 나타내는 해당 타임라인 막대와 통합됩니다. 정확도가 낮고, 다양한 주제를 표현하는 데 어려움이 있으며, 정확한 기준 진실 세분화를 생성하려면 상당한 레이블이 지정된 데이터와 도메인 전문 지식이 필요합니다. 그 결과, 기업은 녹음된 통화에서 사후 처리 세분화를 도입하는 데 느렸습니다. 이 작업에서는 이러한 한계를 극복하고 레이블이 지정된 데이터가 필요 없이 정확한 통화 세분화와 주제 추출을 제공하는 방법을 제안합니다. GPT 모델을 기반으로 하는 이 방법은 사전 정의된 주제 집합에 초점을 맞추면서 녹음된 통화에서 사용되는 자연어를 모방하는 합성 데이터를 생성합니다. 그런 다음 합성 데이터는 더 작은 Transformer 네트워크에서 통화를 정확하게 세분화하고 주제로 태그를 지정하는 데 사용됩니다. GPT-Calls라고 하는 이 방법은 대화 발화와 사전 정의된 주제 앵커 간의 유사성을 분석하여 전화 통화 중에 논의된 주제를 효율적으로 식별하도록 설계되었습니다. 이 알고리즘은 오프라인 및 온라인 단계로 구성됩니다. 오프라인 단계에서 GPT-Calls는 GPT 모델[1, 2]을 사용하여 각 주제에 대한 합성 문장 분포를 생성합니다. 그런 다음 문장을 개별적으로 임베드하고 클러스터링하여 앵커 벡터를 추출합니다. 온라인 단계에서 GPT-Calls는 언어 모델을 사용하여 각 발화를 임베드하고 주제 앵커와의 유사성에 대해 점수를 매겨 대화 내용을 처리합니다. 그런 다음 연속된 발화의 점수에 시간 영역 분석을 적용하여 특정 주제와 명확하게 식별되는 세그먼트로 그룹화합니다. 주제와 상관 관계가 없는 나머지 세그먼트는 &quot;배경&quot;으로 간주됩니다. GPT-Calls 방법은 레이블이 지정된 데이터가 필요 없이 모든 주제에 대처할 수 있는 통화 세분화 및 주제 추출을 위한 효과적이고 정확한 솔루션을 제공합니다. 이런 방식으로 조직은 특정 비즈니스 요구 사항과 관련된 사용자 지정 주제 목록을 선택할 수 있습니다. 또한 이 알고리즘은 일반적이며 고객 지원, 영업 대화, 설문 조사 등 다양한 도메인에 구현할 수 있습니다. 마지막으로, 시스템의 온라인 단계는 거의 실시간 시나리오에 적용할 수 있어 표준 하드웨어를 사용하여 2~3초 이내에 전체 통화를 세분화하고 태그 지정할 수 있습니다.GPT-Calls는 최근 Dynamics 365 Sales에 채택되었으며, 예측된 세분화는 통화 요약 대시보드의 하단에서 명확하게 볼 수 있습니다(그림 1 참조).저희의 기여는 다음과 같습니다.(1) 모든 도메인에서 기록된 통화를 분석하도록 설계된 일반적인 방법인 GPT-Calls 체계를 소개합니다.(2) 여러 도메인과 테넌트의 다양한 통화 데이터 세트에서 GPT-Calls의 성능을 평가하고 보고합니다.(3) 제안된 방법을 다른 최첨단 대안과 비교합니다.저희의 결과는 GPT-Calls 방법이 다른 접근 방식보다 상당한 마진으로 모든 데이터 세트에서 성능이 우수하다는 것을 보여줍니다. GPT-오프라인 토픽 임베딩 프롬프트: &quot;가격에 대해 논의하는 상담원과 고객&quot; கு &quot;...500달러에서 5000달러까지 패키지가 있습니다...&quot; 언어 모델 &quot;안녕하세요. ABC에서 존입니다. 시간 있으세요?&quot; 온라인 a0.언어 모델 0.0.벡터화 토픽 확률 יק 끝 인사 일정 ■uter #1 ■uter #2 ■uter #시간 영역 클러스터링 + + 0.인사말 일정 끝 0.0.시간 영역 분석시간 영역 그림 2. GPT 통화의 오프라인 및 온라인 단계에 대한 그림. 2.
--- RELATED WORK ---
최근 몇 년 동안 텍스트 분할에 대한 관심이 커지고 있는데, 이는 텍스트 구절을 내용에 따라 일관된 세그먼트로 나누는 것을 포함합니다. 전통적인 텍스트 분할
--- METHOD ---
, GPTdistilled Calls Segmentation and Tagging(GPT-Calls)은 효율적이고 정확한 콜 세분화 및 토픽 추출을 위한 것입니다. GPT-Calls는 오프라인 및 온라인 단계로 구성됩니다. 오프라인 단계는 주어진 토픽 목록에 한 번 적용되며 GPT 모델을 사용하여 각 토픽에 대한 합성 문장 분포를 생성하고 앵커 벡터를 추출하는 것을 포함합니다. 온라인 단계는 모든 콜에 개별적으로 적용되며 오프라인 단계에서 발견된 토픽 앵커와 필사된 대화 간의 유사성을 평가합니다. 그런 다음 유사성 점수에 시간 영역 분석을 적용하여 발언을 세그먼트로 그룹화하고 토픽으로 태그를 지정합니다. 제안된 패러다임은 레이블이 지정된 데이터가 필요하지 않은 정확하고 효율적인 콜 세분화 및 토픽 추출 방법을 제공하므로 다양한 도메인에 적용할 수 있는 다재다능한 접근 방식입니다. 저희 알고리즘은 Dynamics 365 Sales Conversation Intelligence에서 프로덕션에서 작동하며 저희 연구는 다양한 Dynamics 365 Sales 테넌트에서 수집한 실제 영업 대화를 기반으로 합니다. 1. 서론 오늘날 경쟁이 치열한 시장에서 영업 담당자는 판매를 촉진하고 강력한 고객 기반을 유지하는 데 중요한 역할을 합니다. 영업 담당자가 고객과 상호 작용하는 주요 방법 중 하나는 전화 통화입니다. 이러한 전화 통화는 종종 품질 보증, 다른 판매자 교육 및 코칭, 통찰력 정리 등을 위해 녹음되고 필사됩니다. 따라서 영업 부서는 종종 수백만 건의 통화 필사본으로 구성된 광범위한 데이터베이스를 유지 관리하는데, 이는 수많은 작업에 대한 중요한 정보 소스 역할을 합니다. 그러나 녹음된 통화를 분석하는 것은 어렵고 시간이 많이 걸리는 작업일 수 있으며, 특히 대화가 길거나 여러 주제를 다룰 때 더욱 그렇습니다. *는 동등한 기여를 나타냅니다. 일반적인 접근 방식은 녹음된 텍스트를 후처리하고 각 세그먼트에 주제를 할당하여 통화를 세분화하는 것입니다. 이를 통해 판매자가 이전 통화에서 중요한 정보를 찾고 추출하는 프로세스가 간소화됩니다. 통화 세분화는 논의된 특정 주제 또는 테마를 기반으로 대화를 더 작은 섹션으로 나누는 것을 포함합니다. 이러한 세분화 및 태그 기능은 판매자와 관리자의 일상 업무를 크게 용이하게 합니다. 영업 담당자와 관리자가 과거 통화를 쉽게 추적하고 분석하고, 대화 주제에 따라 분류하고, 통화의 관련 부분으로 이동하여 중요한 정보를 추출하고, 필사된 통화를 처리하는 검색 엔진을 개선하는 등의 작업을 수행할 수 있습니다. 또한, 녹음된 통화의 자동 세분화 및 태그 지정을 통해 기업은 여러 측면에서 영업 전략과 프로세스를 최적화하는 데 도움이 될 수 있습니다. • • 판매자에게 개인화된 코칭 제공. 관리자는 전체 통화를 듣는 대신 통화의 특정 부분을 듣고 피드백과 지침을 제공할 수 있습니다. • • 고객 요구 사항, 선호도 및 문제점에 대한 통찰력 제공. 세분화되고 태그가 지정된 정보는 영업 전략을 맞춤화하고 고객 경험을 개선하는 데 사용할 수 있습니다. • • • 영업 대화에서 법률 및 윤리 지침 준수 모니터링. 판매자가 회사 정책 및 규정을 준수하고 있는지 확인. • • • 영업 실적 및 고객 행동에 대한 통찰력을 제공하는 보고서 및 대시보드 생성. 이 정보는 데이터 기반 의사 결정을 내리고 전반적인 비즈니스 성과를 개선하는 데 사용할 수 있습니다. 성공적인 결과와 관련이 있을 수 있는 통화의 주요 순간 식별. 이 정보는 영업 담당자를 교육하고 성과를 개선하는 데 사용할 수 있습니다. 궁극적으로 위의 모든 것이 고객 만족도, 충성도, 판매 및 수익 창출로 이어집니다. 안타깝게도 이 분야에서 많은 발전이 있었음에도 불구하고 현재의 콜 세분화 및 태그 지정 기술은 판매자와 관리자의 일상 업무에 미치는 영향과 침투를 방해하는 한계가 있습니다. 특히, 종종 최적이 아닌 콜 투 이반 캐신 - 헬스장 멤버십 개요 클립보드에 복사 메모 작업 항목. 언급 대본 제안된 메모 미리보기 × NW 00:10분 전 NW 콜 하이라이트 요약: - 발견 콜 - 100개 라이선스에 관심 있음 콜 분: • 고객이 무료 패스를 사용하고 싶어함 • 고객이 15~20파운드를 감량하려고 함 에이전트가 고객에게 체중 감량을 위한 프로그램이 있다고 알렸음 • 고객이 여름까지 체중 감량 목표를 달성하는 방법을 알고 싶어함 00:안녕하세요.그리고... 요청 및 com... NW 낸시 워... IC 이반 캐신 낸시 워너 검색 안녕하세요 이반, 저는 Dynamic fitness의 낸시입니다. IC Ivan Cashin 고객이 무료 패스를 사용하고 싶어합니다 +추가 00:00: 안녕하세요. NW Nancy Warner 고객이 15~20파운드를 감량하려고 합니다 +추가 00:00: 오늘 전화드려서 무료 패스를 사용해보셨는지 알아보려고 합니다. IC Ivan Cashin 모두 보기 00: 아니요, 아직은 사용하지 않았습니다. 작업 항목 NW Nancy Warner Nancy Warner가 &quot;도움이 되는 정보&quot;에 대한 이메일을 +353892678274로 보냅니다. +추가 02:00: 좋아요, 문제 없습니다. 요청 및 불만 NW Nancy Warner 00: 무료 패스를 다운로드하기로 결정한 이유를 물어보겠습니다. 마무리 ་་་་감정 O 긍정 중립 부정 댓글(0) ① |&lt;&lt; ‣ 小 00:00/ 02:그림 1. 통화 요약 대시보드. 요약(왼쪽), 제안된 메모(가운데), 필사된 대화(오른쪽)가 표시됩니다. 예측된 세분화와 관련 주제가 하단에 표시되고, 녹음된 통화 기간을 나타내는 해당 타임라인 막대와 통합됩니다. 정확도가 낮고, 다양한 주제를 표현하는 데 어려움이 있으며, 정확한 기준 진실 세분화를 생성하려면 상당한 레이블이 지정된 데이터와 도메인 전문 지식이 필요합니다. 그 결과, 기업은 녹음된 통화에서 사후 처리 세분화를 도입하는 데 느렸습니다. 이 작업에서는 이러한 한계를 극복하고 레이블이 지정된 데이터가 필요 없이 정확한 통화 세분화와 주제 추출을 제공하는 방법을 제안합니다. GPT 모델을 기반으로 하는 이 방법은 사전 정의된 주제 집합에 초점을 맞추면서 녹음된 통화에서 사용되는 자연어를 모방하는 합성 데이터를 생성합니다. 그런 다음 합성 데이터는 더 작은 Transformer 네트워크에서 통화를 정확하게 세분화하고 주제로 태그를 지정하는 데 사용됩니다. GPT-Calls라고 하는 이 방법은 대화 발화와 사전 정의된 주제 앵커 간의 유사성을 분석하여 전화 통화 중에 논의된 주제를 효율적으로 식별하도록 설계되었습니다. 이 알고리즘은 오프라인 및 온라인 단계로 구성됩니다. 오프라인 단계에서 GPT-Calls는 GPT 모델[1, 2]을 사용하여 각 주제에 대한 합성 문장 분포를 생성합니다. 그런 다음 문장을 개별적으로 임베드하고 클러스터링하여 앵커 벡터를 추출합니다. 온라인 단계에서 GPT-Calls는 언어 모델을 사용하여 각 발화를 임베드하고 주제 앵커와의 유사성에 대해 점수를 매겨 대화 내용을 처리합니다. 그런 다음 연속된 발화의 점수에 시간 영역 분석을 적용하여 특정 주제와 명확하게 식별되는 세그먼트로 그룹화합니다. 주제와 상관 관계가 없는 나머지 세그먼트는 &quot;배경&quot;으로 간주됩니다. GPT-Calls 방법은 레이블이 지정된 데이터가 필요 없이 모든 주제에 대처할 수 있는 통화 세분화 및 주제 추출을 위한 효과적이고 정확한 솔루션을 제공합니다. 이런 방식으로 조직은 특정 비즈니스 요구 사항과 관련된 사용자 지정 주제 목록을 선택할 수 있습니다. 또한 이 알고리즘은 일반적이며 고객 지원, 영업 대화, 설문 조사 등 다양한 도메인에 구현할 수 있습니다. 마지막으로, 시스템의 온라인 단계는 거의 실시간 시나리오에 적용할 수 있어 표준 하드웨어를 사용하여 2~3초 이내에 전체 통화를 세분화하고 태그 지정할 수 있습니다.GPT-Calls는 최근 Dynamics 365 Sales에 채택되었으며, 예측된 세분화는 통화 요약 대시보드의 하단에서 명확하게 볼 수 있습니다(그림 1 참조).저희의 기여는 다음과 같습니다.(1) 모든 도메인에서 기록된 통화를 분석하도록 설계된 일반적인 방법인 GPT-Calls 체계를 소개합니다.(2) 여러 도메인과 테넌트의 다양한 통화 데이터 세트에서 GPT-Calls의 성능을 평가하고 보고합니다.(3) 제안된 방법을 다른 최첨단 대안과 비교합니다.저희의 결과는 GPT-Calls 방법이 다른 접근 방식보다 상당한 마진으로 모든 데이터 세트에서 성능이 우수하다는 것을 보여줍니다. GPT-오프라인 토픽 임베딩 프롬프트: &quot;가격에 대해 논의하는 상담원과 고객&quot; கு &quot;...500달러에서 5000달러까지 패키지가 있습니다...&quot; 언어 모델 &quot;안녕하세요. ABC에서 존입니다. 시간 있으세요?&quot; 온라인 a0.언어 모델 0.0.벡터화 토픽 확률 יק 끝 인사 일정 ■uter #1 ■uter #2 ■uter #시간 영역 클러스터링 + + 0.인사 일정 끝 0.0.시간 영역 분석시간 영역 그림 2. GPT 통화의 오프라인 및 온라인 단계에 대한 설명. 2. 관련 작업 최근 몇 년 동안 텍스트 분할에 대한 관심이 커지고 있는데, 이는 텍스트 구절을 내용에 따라 일관된 세그먼트로 나누는 것을 포함합니다. 기존의 텍스트 분할 방법은 구두점, 문단 구분 또는 규칙 기반 접근 방식과 같은 기능에 의존했지만, 이러한 방법은 항상 텍스트의 기본 의미 구조를 포착하지 못할 수 있습니다. 이러한 과제를 해결하기 위해 최근 여러 연구에서 의미 단어 임베딩을 사용하여 단어 간 관계의 일관성을 기반으로 세그먼트를 식별하는 것을 제안했습니다. 그러한 연구 중 하나는 의미 단어 임베딩을 기반으로 하는 텍스트 분할 방법을 제안합니다[3]. 이 연구에서 저자는 사전 학습된 단어 임베딩 모델을 사용하여 텍스트의 각 단어에 대한 임베딩을 생성한 다음 탐욕 알고리즘을 적용하여 단어를 세그먼트로 그룹화합니다. 저자는 분할 정확도 측면에서 해당 접근 방식이 기존 방법보다 성능이 우수하고 식별된 세그먼트가 텍스트에서 논의된 주제와 잘 일치한다는 것을 보여줍니다.
--- EXPERIMENT ---
s 섹션에서, 우리는 우리의 방법을 [3]과 같은 접근 방식을 기반으로 하는 Dynamics 365 Sales에서 호출 세분화를 위해 사용된 이전 방법과 비교합니다.다른 방향은 주제 태그 지정을 위해 텍스트 요약 방법을 사용하는 것입니다.이 접근 방식은 주어진 텍스트에 하나 이상의 태그를 지정하여 주요 주제 또는 테마를 나타내는 것을 포함합니다.추출 요약이라고 알려진 그러한 접근 방식 중 하나는 텍스트에서 주요 문장을 추출하여 텍스트에 사전 정의된 주제 태그를 지정하는 것입니다.추상 요약이라고 알려진 또 다른 접근 방식은 시퀀스 대 시퀀스 모델 또는 변환기 모델과 같은 신경 기반 요약 모델을 사용하여 관련 태그를 예측하는 데 사용할 수 있는 간결한 요약을 생성합니다.후자의 접근 방식은 PEGASUS 요약 모델[4]을 활용하여 태그 예측 프로세스를 용이하게 할 수 있는 요약을 생성할 수 있습니다(원래 텍스트의 태그를 예측하는 것과 비교).Dynamics 365 sales에서 사용된 이전 방법은 세그먼트를 요약하고 관련 주제를 추론하기 위해 PEGASUS 모델을 기반으로 구축되었습니다. 이 방법에 대한 자세한 내용과 평가는 Sec.4에서 찾을 수 있습니다.TextTiling[5]은 긴 텍스트를 일관된 주제별 섹션으로 효율적으로 나누는 뛰어난 텍스트 분할 알고리즘입니다.이 알고리즘은 로컬 어휘 응집성을 활용하고 주제 경계를 나타내는 텍스트의 주제 구조에서 갑작스러운 변화를 식별하는 데 중점을 둡니다.토큰화, 유사도 측정 및 평활화와 같은 통계적 기술을 사용하여 TextTiling은 텍스트에서 정보적 특징을 추출하여 이를 개별 섹션으로 클러스터링하여 대규모 텍스트 코퍼스를 더 잘 이해하고 구성할 수 있습니다.이 다재다능한 분할 알고리즘은 정보 검색, 요약 및 텍스트 분류를 포함한 다양한 자연어 처리 작업에 널리 적용되어 계산 언어학 분야 연구자에게 귀중한 도구가 되었습니다.회의 주제 분할은 회의 기록을 일관된 세그먼트로 자동 분할하여 담론 구조를 더 잘 이해하는 수단으로 상당한 주목을 받았습니다. [6]에서 저자는 BERT 임베딩(BERT-TSeg)을 통한 회의 세분화를 위한 비지도 방법을 제안합니다. 그들의 방법은 BERT를 기반으로 하여 필사본의 각 발화에 대한 맥락화된 단어 표현을 생성합니다. 이러한 임베딩을 활용하여 BERT-TSeg는 인접한 주제 간의 유사도를 계산합니다. 가격 책정 제가 받아들일 수 있는 가장 낮은 가격은 현재 제안의 절반입니다. 이 격차를 메우기 위해 전반적으로 4% 인상을 마련할 수 있습니까? 아니면 특정 수량까지 50% 할인하는 것은 어떨까요? 엄청난 새로운 가격인데, 저희 결제 시스템에 특별한 조치를 취해서 제공할 여지가 있습니까? 물론입니다. 부분적 유연한 지불이 관심 있는 경우, 저희의 연기 가격 책정 조건은 잠재적으로 귀사 팀이 원활하게 진입할 수 있도록 보장할 수 있습니다. 최종 단위 가격에 영향을 미치지 않고 관심 있는 제품에 대해 최대 30일 동안 연기 지불을 제공할 수 있습니다. [~1000개 이상의 문장] 그림 3. 주제 가격 책정을 위해 GPT3에서 생성한 대표적인 합성 문장. 세그먼트를 만들고 유사도 행렬을 구성합니다. 이후, 주제 경계를 식별하기 위해 이 행렬에 계층적 클러스터링 알고리즘을 적용합니다. 이 연구에서는 주제 세분화를 충족하는 데 있어 우리 접근 방식의 발전과 효과를 평가하기 위해 제안된 방법과 BERT-TSeg 간의 포괄적인 평가 및 비교를 수행합니다. 3. 방법 GPT-Calls 알고리즘은 오프라인 단계와 온라인 단계의 두 가지 뚜렷한 단계로 구성됩니다. 오프라인 단계는 GPT 모델을 사용하여 합성 데이터를 생성합니다. 이 단계는 사용자가 정의한 주제 목록에 대해 한 번 적용됩니다. 오프라인 단계 후, 알고리즘은 오프라인 단계 동안 추출된 표현을 강화하는 온라인 단계를 호출하여 주어진 호출에 대한 세분화와 주제를 정확하게 예측합니다. 3.1. 오프라인 단계 오프라인 단계에서 알고리즘은 GPT 모델을 사용하여 합성 데이터를 생성하고 사용자가 선택한 원하는 주제의 주어진 목록을 활용합니다. 이 단계는 원하는 주제의 특정 집합에 대해 한 번만 실행됩니다. 이후 온라인 단계에서 알고리즘은 오프라인 단계 동안 추출된 표현을 사용하여 개별 호출에 대한 세분화와 주제를 예측합니다. 구체적으로 각 주제에 대해 프롬프트¹를 작성하고 GPT-3를 사용하여 주제와 의미적으로 연관된 수천 개의 문장을 생성합니다. &quot;가격&quot; 주제에 대해 생성된 문장의 대표적 샘플이 그림 3에 나와 있습니다. 프롬프트의 예는 부록 섹션 A에서 찾을 수 있습니다. 각 주제에 대해 생성된 문장은 사전 학습된 Sentence-BERT(SBERT) 모델[7]을 통해 임베딩됩니다. 이 모델(1프롬프트에는 몇 개의 문장과 주제의 한 예가 포함되어 있으며, 그 뒤에 모델에 쿼리 주제에 대한 다른 예를 생성해 달라는 요청이 이어짐)은 표준 BERT 모델[8]을 조정하여 전체 문장을 384차원 임베딩 벡터로 인코딩하도록 고안되어 코사인 유사도 메트릭을 사용하여 의미적 유사도를 측정할 수 있습니다. 그런 다음, 각 주제의 문장 임베딩에 DBSCAN[9] 알고리즘을 적용하여 주제의 분포를 나타내는 여러 &quot;앵커&quot; 집합을 추출합니다. DBSCAN은 샘플 밀도에 따라 데이터를 클러스터로 그룹화하는 밀도 기반 클러스터링 알고리즘입니다. 고밀도 영역은 클러스터로 그룹화되고 저밀도 영역의 샘플은 이상치로 표시됩니다. 각 주제에 대해 DBSCAN을 적용하여 클러스터 집합을 검색합니다. 각 클러스터의 중심을 추출하여 앵커로 사용합니다. 이러한 앵커는 온라인 단계에서 호출의 각 발화에 대한 주제 확률을 추론하는 데 사용됩니다. 오프라인 단계의 파이프라인은 그림 2(위쪽)에 설명되어 있습니다. 전반적으로 오프라인 단계에는 주제 정의, 합성 문장 생성, SBERT를 사용하여 임베딩, DBSCAN을 사용하여 임베딩 클러스터링 및 앵커 추출이 포함됩니다. 앵커는 나중에 온라인 단계에서 주제의 확률을 추론하는 데 사용됩니다. 3.2. 온라인 단계 온라인 단계에서 GPT-Calls는 녹음된 대화의 필사본을 기반으로 작동하고 주어진 대화에서 각 발화에 대한 주제 확률을 예측합니다. 발화는 원자적 음성 단위로, 대부분 필사 모델에 의해 단일 문장이나 하위 문장으로 변환됩니다. 이 방법은 Azure Cognitive Service 필사 모델을 사용하고 SBERT를 통해 필사된 결과 발화를 포함합니다. 그런 다음 GPT-Calls는 각 필사된 발화의 임베딩을 반복하면서 미리 정의된 주제의 모든 앵커와의 유사성을 평가합니다. 각 주제에 대해 발화-주제 점수는 필사된 발화 임베딩과 주제와 관련된 앵커(오프라인 단계에서 설명한 대로 동일한 잠재 공간의 벡터이기도 함) 간의 최대 코사인 유사도로 정의됩니다. 각 주제에 대한 발화-주제 점수는 Softmax 함수를 사용하여 확률로 변환됩니다. 이 프로세스를 수행하면 벡터 시퀀스를 얻을 수 있으며, 각 벡터는 해당 발화가 각 주제와 관련될 확률을 나타냅니다. 주제 확률의 정확도를 높이기 위해 GPTCalls는 위의 시퀀스에 시간 영역 분석을 적용하여 이를 다변량 시계열로 처리합니다. 이는 &quot;열원&quot;이라고 하는 시계열의 각 차원에서 피크 포인트를 식별합니다. 그런 다음 GPT-Calls는 각 열원을 둘러싼 이웃 샘플에 열 확산 전략을 적용합니다. 시퀀스의 모든 샘플과 각 차원에서 GPT-Calls는 가장 가까운 오른쪽 및 왼쪽 2https://azure.microsoft.com/en-us/products/cognitive-services/speechto-text/ 열원까지의 거리를 계산하고, 가장 가까운 오른쪽 및 왼쪽 열원의 값에 비례하여 현재 샘플의 주제 확률을 강화하고, 거리만큼 확률을 감소시킵니다. 즉, 특정 주제와 높은 상관 관계를 갖는 다른 샘플에 가까운 샘플의 확률은 동일한 주제로 약간 승격됩니다. 이 접근 방식은 식별과 같은 특정 주제에서 종종 나타나는 노이즈가 많은 데이터 샘플의 존재를 상쇄하고자 합니다. 열 확산 프로세스 후, 소프트맥스 함수가 각 발화에 다시 적용되어 주제 전체의 점수가 합산 1이 되는 유효한 확률인지 확인합니다. 그런 다음 GPT-Calls는 슬라이딩 윈도우 기술을 적용하여 주제로 연속 발화의 윈도우를 태그합니다. 각 주제에 대해 다른 윈도우 너비가 사용되며, 이는 검증 세트를 사용하여 각 주제에 대해 개별적으로 결정되는 하이퍼파라미터입니다. 특정 주제의 누적 확률은 해당 윈도우 내의 모든 발화의 관련 확률을 평균하여 각 윈도우에 대해 계산됩니다. 누적 확률이 사전 정의된 임계값(각 주제에 대해 구성 가능)을 초과하면 윈도우에 해당 주제가 레이블됩니다. 이 프로세스는 모든 주제에 대해 반복됩니다. 위 프로세스가 끝나면 시퀀스가 주제로 태그가 지정된 윈도우와 연결됩니다. 그런 다음 GPT-Calls는 태그가 지정된 윈도우를 반복하고 동일한 주제가 있는 연속된 윈도우를 병합합니다. 창 또는 하위 창에 두 개 이상의 주제가 태그된 경우, 가장 높은 점수를 받은 선두 주제가 선택되고 다른 창도 그에 따라 업데이트됩니다.예측된 분할 및 태그는 최종 출력으로 검색됩니다.예측된 분할 및 태그의 시각화와 각 발화의 기본 확률은 그림 4에서 볼 수 있습니다.온라인 단계의 파이프라인은 그림 2(아래쪽 부분)에 설명되어 있습니다.4. 실험평가에서 GPT-Calls를 관련 작업 섹션에 언급된 기준 방법(TextTiling [5] 및 비지도 BERT-TSeg 방법 [6] 포함)과 비교합니다.TextTiling은 어휘 응집성을 기반으로 하는 슬라이딩 윈도우 접근 방식을 사용하여 문서 내의 일관된 세그먼트를 식별합니다.반면에 BERT-TSeg는 BERT 임베딩 및 계층적 클러스터링을 사용하여 회의 기록에서 주제 경계를 식별합니다. 또한 탐욕적 세분화 접근 방식을 활용한 기법을 채택한 Dynamics 365 Sales에서 사용된 이전 모델과 비교합니다. GPT 기반 태그 요약(GSGST)이 뒤따릅니다. GSGST는 먼저 세분화 절차를 적용한 다음 각 세그먼트에 관련 주제를 태그합니다. 세분화는 사전 훈련된 SBERT 모델을 사용하여 주어진 통화의 모든 발화를 임베드하는 것으로 시작합니다. 그런 다음 발화 임베드 구현 3에 대해 [3]³에 도입된 탐욕적 방법을 사용하여 세그먼트를 추론합니다. 여기에서 찾을 수 있습니다. 1.0.80.60.0.2-schedule pricing identification 0.greetings ending 그림 4. 67개 발화가 있는 대표 통화의 주제 점수(Y축) 대 발화 지수(X축). 모든 발화의 모든 주제 점수가 표시됩니다. 각 주제 점수는 다른 색상의 실선으로 표시됩니다. 최종적으로 검색된 세그먼트는 해당 주제 색상으로 채색된 배경 위에 관련 발화 위에 표시됩니다. ding. N개의 내장된 발화(w1, ..., WN)가 있는 호출이 주어지면 세그먼트 V = (wb, ..., we)가 됩니다. 여기서 b, e는 V의 시작 및 종료 인덱스(0 ≤ b + 1 &lt; e ≤ N)이고 분할 인덱스 b <t <e, the gain of splitting V at position t is defined as: g%(t) := Σ i=b e e + Ι-ΣΙ-ΙΣ Wi The greedy approach calculates the index that maximizes this term t* = arg max gf (t) t (1) Then, if gå (t*) > ↑ 여기서 7 &gt; 0은 사전 정의된 임계값이고, 세그먼트 V는 t*를 중심으로 두 개의 세그먼트로 분할됩니다. 이 방법은 각각 대화의 첫 번째와 마지막 발화로 b와 e를 시작하는 것으로 시작합니다. 이 프로세스는 모든 세그먼트에 대해 재귀적으로 진행되고 사전 정의된 임계값을 넘는 이득을 가진 후보 분할이 없거나 현재 세그먼트 수가 사용자가 정의한 최대값에 도달하면 중지됩니다. 마지막으로 마지막 분할이 출력으로 검색됩니다. 예측된 분할이 주어지면 [10]에서 도입한 제로샷 모델과 [4] PEGASUS에 기반한 요약 모델의 두 가지 모델을 사용하여 관련 주제를 예측합니다. 첫 번째 모델이 높은 신뢰도로 주제를 예측하지 못하면 두 번째 모델을 사용합니다. 두 번째 모델은 PEGASUS 모델을 기반으로 하며, 이 모델은 GPT [11]에서 생성한 요약인 레이블이 있는 영업 전화에서 미세 조정되었습니다. https://github.com/chschock/textsplit 4세그먼트의 최소 크기는Pk Sports WinDiff IT Diverse Pk WinDiff Pk WinDiff TextTiling BERT-TSeg 0.66 ± 0.0.36 ± 0.0.89 ± 0.0.36 ± 0.0.65 ± 0.0.34 ± 0.0.93 ± 0.0.35 ± 0.0.66 ± 0.0.92 ± 0.0.34 ±0.GSGST 0.33 ± 0.0.34 ± 0.0.31 0.0.32 ± 0.0.32 ± 0.0.35 ± 0.0.33±0.GPT-Calls 0.29 ± 0.0.31 ± 0.0.29 ± 0.0.30 ± 0.0.29 ± 0.0.31 ± 0.표 1. 각 모델과 데이터 세트에 대한 Pk 및 WinDiff 점수는 표준 편차(평균 ± SD)가 있는 평균값으로 보고됩니다. 이 방법은 각 주제가 전문가가 만든 소수의 대표적 문장(일반적으로 약 2-20개 문장)과 연관되어 있다고 가정합니다. 예를 들어, &quot;가격 책정&quot;이라는 주제의 경우 해당 집합에는 9개의 문장이 포함되며, 그 중 두 개는 &quot;대리인과 고객이 제품 가격에 대해 논의했습니다&quot;, &quot;고객이 더 나은 가격을 요청했습니다&quot; 등입니다. 이러한 문장은 SBERT 모델에 의해 개별적으로 임베드되었으며 평균 풀링을 통해 주제를 나타내는 단일 앵커를 추출했습니다. 이 모델은 모든 세그먼트에 대한 단일 문장 요약을 생성합니다. 그런 다음 요약된 세그먼트는 SBERT를 사용하여 임베드되고 각 주제의 단일 앵커와 비교됩니다. 예측된 주제는 요약된 문장 임베딩과 코사인 유사도를 최대화하는 주제입니다. 마지막으로 매우 짧은 세그먼트를 필터링하고 동일한 주제를 가진 인접한 세그먼트를 병합하는 등의 후처리를 수행합니다. 4.1. 메트릭 모델의 성능을 평가하기 위해 Pk 점수[12]와 WindowDiff[13]의 두 가지 메트릭을 계산합니다. 각 주제에 대한 성능을 개별적으로 측정하기 위해 각 주제의 예측 및 기준 진실 세분화를 통해 얻은 이진 세분화에 대해 메트릭을 계산합니다. 예를 들어, &quot;가격 책정&quot;이라는 주제를 평가할 때 가격과 관련이 없는 모든 세그먼트는 배경으로 간주되었습니다. Pk 점수는 슬라이딩 윈도우 기반 방법을 사용하여 계산되며, 여기서 윈도우 크기는 평균 실제 세그먼트 수의 절반으로 설정되었습니다. 이 메트릭은 윈도우의 두 끝이 실제 세그먼테이션에서 같은 세그먼트에 있는지 다른 세그먼트에 있는지 여부를 판별하고 불일치가 있는 경우 카운터를 늘립니다. 최종 점수는 페널티를 0과 1 사이로 조정하고 측정 수를 나누어 계산합니다. Pk 점수(거짓 부정을 거짓 긍정보다 더 많이 페널티하고 경계 수를 고려하지 않음)의 과제를 극복하기 위해 WindowDiff 메트릭도 계산했습니다. Pk 점수와 유사하게 WindowDiff도 슬라이딩 윈도우를 사용하여 계산합니다. 크기 k의 윈도우의 각 위치에 대해 실제 세그먼테이션의 경계 수를 모델에서 예측한 경계 수와 비교합니다. 4.2. 테스트 데이터 관련 도메인 전문 지식을 갖춘 인간 전문가를 고용하여 다양한 Dynamics 365 영업 테넌트에서 가져온 실제 대화의 세 가지 테스트 세트에 주석을 달았습니다.인간 전문가는 각 대화를 세분화하고 각 세그먼트에 인사, 마감, 가격 책정, 식별 및 일정 중 하나의 주제로 주석을 달았습니다.주석은 모델의 성능을 평가하기 위한 기준 진실 세분화로 사용되었습니다.~ ~&quot;스포츠&quot; 세트라고 하는 첫 번째 세트에는 다양한 스포츠 회사의 판매자가 고객과 구독 갱신, 티켓 주문, 좌석 변경 등에 대해 논의하는 200개의 스포츠 관련 대화가 포함되어 있습니다.&quot;IT&quot; 세트라고 하는 두 번째 세트에는 IT 판매자가 고객에게 연락하여 소프트웨어 서비스를 제안하고, 계약을 협상하고, IT 도메인 내에서 고객 문의에 대처하는 녹음된 대화가 포함되어 있습니다.마지막으로 &quot;다양한&quot; 세트라고 하는 세 번째 세트는 금융, 기술, 청구 회사, 의료 마케팅 등 다양한 분야의 영업 담당자의 약 200개 대화로 구성되어 있습니다.4.3. 결과 표 1은 앞서 언급한 세 가지 데이터 세트에서 모든 기준선의 세분화 성능을 제시하며, 실제 인간 주석을 사용하여 평가했습니다. 이 평가에서 우리는 세분화의 정확도 측정에만 집중하고 세그먼트와 관련된 주제는 고려하지 않습니다. 표에서 볼 수 있듯이 GPT-Calls는 다른 모든 대안보다 상당한 차이로 성능이 뛰어납니다. 구체적으로, 두 번째로 성능이 좋은 방법인 GSGST와 비교할 때, 스포츠 데이터 세트의 Pk 및 Win~Diff 점수에서 각각 약 12%, 8%의 상대적 개선을 관찰했습니다. 더욱이 제안된 방법은 나머지 기준선과 세 가지 데이터 세트 모두에 비해 더 큰 이득을 보여줍니다. 표 2에서는 식별, 가격 책정, 일정, 인사 및 마무리의 다섯 가지 주제에 대한 정량적 평가를 제시합니다. 이러한 평가를 위해 주석이 달린 테스트 세트를 활용하고 세입자의 동의를 받고 모든 개인 식별 정보가 제거된 후 GSGST 모델의 성능을 5와 비교합니다.식별 가격 일정 인사말 마감 GSGST GPT-통화 0.56/0.0.49/0.0.36/0.0.08/0.0.07/0.0.11/0.Improv. +80.4%/+44.4% 0.32/0.+34.6%/+3.8% 0.20/0.+44.4%/+28.5% 0.07/0.+12.5%/+0% 0.07/0.+0%/+40.0% 표 2. 각 주제에 대해 별도로 테스트 세트에서 평가한 제안된 방법과 GSGST 기준선의 성능 비교.Pk 점수/WinDiff가 보고됩니다. 둘 다 낮을수록 좋습니다.모델 이름 적중 합리적 실패 77.1% 16.2% 6.7% GPT-호출 표 3. 세그먼트 품질에 대한 인간 평가.우리는 (1) 기준 진실 주석과 일치하는 세그먼트(적중), (2) 기준 진실과 일치하지 않지만 합리적인 예측으로 간주되는 세그먼트(합리적), (3) 기준 진실과 일치하지 않고 세그먼트의 기본 발화와 관련하여 합리적이지 않은 세그먼트(실패)의 백분율을 측정합니다.5.
--- CONCLUSION ---
우리는 GPT 모델에서 지식을 추출하고 레이블이 지정된 데이터가 필요하지 않은 통화 세분화 및 태그 지정에 대한 새로운 접근 방식을 제안합니다.우리의 솔루션은 일반적이며 다양한 도메인에 적용할 수 있습니다.제안된 방법은 Dynamics 365 Sales Conversation Intelligence에 배포되었으며 다른 대안보다 상당히 개선된 것으로 나타났습니다.각 주제에 대해 별도로 Pk 점수와 WinDiff 측면에서 제안된 모델입니다.두 메트릭 모두 더 낮은 값을 달성하여 더 나은 성능을 나타냅니다.결과는 제안된 모델이 모든 주제에서 기준 모델과 유사하거나 더 나은 성능을 낸다는 것을 보여줍니다.특히 식별, 가격 책정, 일정 주제의 경우 Pk 및 WinDiff 점수에서 각각 34.6%~80.4% 및 3.8%~44.4% 범위의 개선을 관찰합니다.가장 큰 개선은 식별 주제에서 관찰되었으며, 이 모델에서 Pk 점수는 80.4%, WinDiff는 44.4% 개선되었습니다.4.4. 인간 평가 결과 위의 세 데이터 세트에서 무작위로 100개의 호출을 선택하여 최종 사용자 경험에 초점을 맞추면서 종단 간 방식으로 제안된 모델의 성능을 평가했습니다. 모델 성능은 세 가지 기준을 사용하여 평가되었습니다. (1) 예측 세그먼트가 기준 진실 세그먼트와 잘 연관되어 있을 때 &quot;적중&quot;이 지정되었습니다. (2) 예측 세그먼트와 기준 진실 사이에 불일치가 있지만 예측 세그먼트와 해당 주제가 기본 발화와 상당히 연관되어 있을 때 &quot;적절함&quot;이 지정되었습니다. (3) 예측 세그먼트가 기준 진실과 일치하지 않고 예측이 기본 발화와 잘 일치하지 않을 때 &quot;실패&quot;가 결정되었습니다. 표 3에 나와 있는 결과에 따르면 모델에서 예측한 세분화의 93.3%가 상당히 양호한 것으로 간주되었으며(즉, &quot;적중&quot; 또는 &quot;적당&quot;), 6.7%만 실패로 감지되었습니다.6. 참고문헌 [1] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al., &quot;Language models are few-shot learners,&quot; Advances in neural information processing systems, vol. 33, pp. 1877-1901, 2020. [2] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 영어: al., &quot;인간의 피드백을 통해 지시를 따르도록 언어 모델 훈련,&quot; arXiv 사전 인쇄본 arXiv:2203.02155, 2022. [3] Alexander A Alemi 및 Paul Ginsparg, &quot;의미적 단어 임베딩을 기반으로 한 텍스트 분할,&quot; arXiv 사전 인쇄본 arXiv:1503.05543, 2015. [4] Jingqing Zhang, Yao Zhao, Mohammad Saleh 및 Peter J Liu, &quot;페가수스: 추상 요약을 위한 추출된 갭 문장으로 사전 훈련. arxiv 전자 인쇄본,&quot; 2019. [5] Marti A Hearst, &quot;텍스트 타일링: 텍스트를 다중 문단 하위 주제 구절로 분할,&quot; 계산 언어학, vol. 23, no. 1, pp. 33–64, 1997. [6] Alessandro Solbiati, Kevin Heffernan, Georgios Damaskinos, Shivani Poddar, Shubham Modi, Jacques Cali, &quot;bert 임베딩을 사용한 회의의 비지도 주제 세분화&quot;, arXiv 사전 인쇄본 arXiv:2106.12978, 2021. [7] Nils Reimers와 Iryna Gurevych, &quot;Sentence-bert: siamese bert-networks를 사용한 문장 임베딩&quot;, arXiv 사전 인쇄본 arXiv:1908.10084, 2019. [8] Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, &quot;Bert: 언어 이해를 위한 딥 양방향 변환기의 사전 학습&quot;, arXiv 사전 인쇄본 arXiv:1810.04805, 2018. [9] Martin Ester, Hans-Peter Kriegel, Jörg Sander, Xiaowei Xu, et al., &quot;노이즈가 있는 대규모 공간 데이터베이스에서 클러스터를 발견하기 위한 밀도 기반 알고리즘.&quot;, kdd, 1996, vol. 96, pp. 226–231. [10] Wenpeng Yin, Jamaal Hay 및 Dan Roth, &quot;제로샷 텍스트 분류 벤치마킹: 데이터 세트, 평가 및 수반 접근 방식,&quot; arXiv 사전 인쇄본 arXiv:1909.00161, 2019. [11] Abedelkadir Asi, Song Wang, Roy Eisenstadt, Dean Geckt, Yarin Kuper, Yi Mao 및 Royi Ronen, &quot;영업 전화를 위한 종단 간 대화 요약 시스템,&quot; arXiv 사전 인쇄본 arXiv:2204.12951, 2022. [12] Doug Beeferman, Adam Berger 및 John D. Lafferty, &quot;텍스트 분할을 위한 통계 모델,&quot; 머신 러닝, 제34권, 제1호. 1-3, pp. 177–210, 1999. [13] Lev Pevzner와 Marti A Hearst, &quot;텍스트 분할을 위한 평가 지표에 대한 비판 및 개선&quot;, Computational Linguistics, vol. 28, no. 1, pp. 19-36, 2002. A. 부록 각 주제에 대해 단일 프롬프트를 만들고 수천 번 사용하여 주제와 관련된 합성 세그먼트 분포를 생성했습니다. 프롬프트에는 1~4개의 샷이 포함되어 있어 모델이 작업에 집중하고 고품질 합성 세그먼트를 생성할 수 있었습니다. 예를 들어, 가격 주제 프롬프트는 다음과 같습니다. &quot;이것은 두 사람 간의 통화 접두사로, 서로 인사하고 소개하는 내용입니다. &quot;Spencer와 Bryce에게 전화해 주셔서 감사합니다. 저는 Tracy입니다. 무엇을 도와드릴까요? 안녕하세요 Tracy, 저는 Paul Lana에게 연락하고자 하는 영업부의 Jeremy King입니다. 아, 알겠어요? 이름을 다시 말씀해 주세요. Jeremy 왕. 제레미, 무슨 일로 전화했나요? 저는 세일즈맨으로 일하고 있어요.” 다른 회사의 두 사람 간의 다른 전화 통화의 중간 부분입니다. 두 사람은 제품 가격을 논의하고 있습니다.
