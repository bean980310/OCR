--- ABSTRACT ---
대규모 언어 모델은 많은 인간 언어 작업에서 탁월하지만 학술 천문학과 같은 고도로 특화된 분야에서는 종종 실패합니다. 이러한 격차를 메우기 위해, 우리는 arXiv에서 300,000개 이상의 천문학 초록을 사용하여 LLAMA-2에서 미세 조정된 70억 개의 매개변수 모델인 AstroLLaMA를 소개합니다. 기존의 인과 언어 모델링에 최적화된 AstroLLaMA는 Llama2보다 30% 더 낮은 복잡도를 달성하여 현저한 도메인 적응을 보여줍니다. 우리 모델은 현저히 적은 매개변수를 가지고 있음에도 불구하고 최첨단 기반 모델보다 더 통찰력 있고 과학적으로 관련성 있는 텍스트 완성 및 임베딩 추출을 생성합니다. AstroLLaMA는 광범위한 미세 조정 잠재력을 가진 강력하고 도메인별 모델 역할을 합니다. 공개 릴리스는 자동 논문 요약 및 대화형 에이전트 개발을 포함하여 천문학 중심 연구를 촉진하는 것을 목표로 합니다.
--- CONCLUSION ---
3개의 에포크에서 AstroLLaMA는 평균 6.55의 복잡도를 달성합니다. 이는 기본 LLaMA 모델과 비교하여 복잡도가 32.5% 감소한 것을 나타내며, 모델의 예측 정확도가 상당히 향상되었음을 의미합니다. 3개의 결과 이전 섹션에서 설명한 대로 AstroLLaMA는 천문학 초록 내 토큰 예측 중 컨텍스트 인식 측면에서 미세 조정되지 않은 대응 제품인 LLAMA-2보다 성능이 뛰어납니다. 미세 조정의 이점을 더 자세히 알아보기 위해 AstroLLaMA의 일반적인 기능을 텍스트 생성과 임베딩 공간 품질이라는 두 가지 핵심 측면에서 평가합니다. LLaMA-2, GPT-4 및 GPT3(ada-002)를 포함한 여러 모델과 성능을 비교하여 포괄적인 평가를 제공합니다. 텍스트 생성과 관련하여, AstroLLAMA, LLAMA-2 및 GPT-4에 다양한 천문학 관련 초록을 완성하도록 과제를 부여했으며, 그 예가 그림 2에 나와 있습니다. 각 모델에는 초록의 처음 몇 문장이 프롬프트로 제공되어 맥락을 이해하고 의미 있는 연속을 생성하는 능력을 측정할 수 있습니다. GPT-4의 경우 ChatGPT를 활용하여 완성을 단일 문단으로 제한하도록 특별히 프롬프트합니다. AstroLLaMA 및 LLAMA-2는 표준 샘플링 방법을 사용하여 배포되며 온도는 0.3으로 설정되고 최대 새 토큰 제한은 1,024입니다. 온도 설정을 변경해도 LLAMA-2의 결과가 실질적으로 개선되지 않는다는 것을 발견했습니다. 우리의 관찰 결과는 그림 2에 나타난 패턴과 크게 일치합니다. LLAMA-2는 짧고 종종 주제와 관련 없는 연속만 생성한 후 의도한 맥락에서 벗어나 완성도가 떨어지는 경우가 많습니다. GPT-4는 더 일관된 텍스트를 생성하지만, 그 응답은 천문학 도메인에 필요한 미묘한 이해를 포착하기에는 너무 일반적입니다. 천문학 관련 주제에 초점을 맞추라는 명확한 메시지가 표시되더라도 GPT-4에서 생성된 텍스트는 도메인 특정이 아닌 대체로 대상에서 벗어나거나 일반적으로 적용됩니다. 극명한 대조적으로 AstroLLaMA는 천문학적 개념에 대한 깊은 이해를 보여줌으로써 완성에서 놀라운 맥락 인식을 보여줍니다. 예를 들어, 그림 2에서 AstroLLaMA는 마젤란 스트림에서 별을 효과적으로 검색하려면 초기 광시야 이미징, 그다음 Gaia의 천체 측정 데이터를 사용한 정제, 그다음 분광 데이터로 추가 큐레이션의 3단계 프로세스가 필요하다는 것을 이해합니다. 이 모델은 또한 Gaia-ESO가 남쪽 하늘을 조사하고 있으므로 마젤란 스트림(일부)을 관찰할 수 있다는 것을 이해합니다. 또한 마젤란 스트림에 대한 미묘한 지식을 보여주며 스트림 내에서 분기의 중요성을 이해합니다. 결과적으로, 남동쪽 흐름에 대해 논의하고 금속성 차이를 탐구하여 그 기원을 확인함으로써 텍스트를 적절하게 완성합니다. 임베딩 공간 품질과 관련하여, 우리는 천문학 텍스트 간의 의미적 유사성을 반영하는 모델의 능력을 평가합니다. 우리는 데이터 세트에서 10,000개의 초록을 무작위로 선택하여 AstroLLaMA와 GPT-3를 사용하여 임베딩합니다. 구체적으로, 우리는 OpenAI의 API를 사용하여 GPT-3(ada-002)에 대한 텍스트 임베딩 함수를 호출합니다. AstroLLaMA에서 텍스트 임베딩을 얻으려면 모델을 통해 입력을 전달하고 입력의 모든 토큰에 대한 임베딩을 포함하는 최종 숨겨진 상태를 추출합니다. 그런 다음 [BOS] 토큰을 생략하고 다른 모든 토큰의 임베딩의 평균을 구하여 최종 결과를 얻습니다. 마지막으로, 각 쌍의 초록에 대해 벡터 임베딩 간의 코사인 유사도(정규화된 점곱)를 계산합니다. 그림 3의 상단 패널은 두 가지 임베딩 방법에 대한 이러한 쌍별 유사도의 분포를 나타냅니다. GPT-3의 임베딩은 유사도가 비교적 높은 값인 0.7-0.9에 클러스터링되어 지나치게 일반적이라는 것을 발견했는데, 이는 판별력이 부족하다는 것을 시사합니다(대부분의 논문이 매우 유사하게 임베딩됨). 반면 AstroLLaMA의 임베딩은 각 빈 내에서 훨씬 더 높은 분산을 보입니다. 이는 우리의 미세 조정된 모델이 천문학 분야에 내재된 특수한 의미적 분산을 표현하는 데 더 능숙하다는 것을 시사하며, 이를 통해 천문학적 내용을 보다 세부적으로 표현할 수 있고 더 나은 문서 검색 및 의미 분석을 용이하게 할 수 있습니다. 그림 3의 하단 패널은 AstroLLaMA와 GPT 분류가 갈라지는 두 가지 대표적인 예를 제공합니다. 첫 번째 예에서 GPT는 키워드 &#39;magnetized&#39;에 고정하여 컨텍스트가 현저히 다르더라도 유사도 점수가 부풀려졌습니다. 반면 AstroLLaMA는 이러한 이질적인 맥락을 성공적으로 구별합니다. 두 번째 예에서 AstroLLaMA는 스피처 연구가 별 형성과 밀접한 관련이 있음을 정확하게 식별합니다. 그러나 GPT-3는 abDensity + ShiftGPT-3(ada) 임베딩 + AstroLLaMA 임베딩으로 인해 이러한 연결을 만드는 데 실패합니다.0.2 0.0.4 0.5 0.6 0.7 0.8 0.9 1. 쌍별 코사인 유사도 논문 1: 천체물리학적 자이로키네시스: 자화된 약하게 충돌하는 플라스마에서의 운동 및 유체 난류 폭포 논문 2: 강하게 자화된 진공에서의 수정된 쿨롱 법칙에 대한 논평 GPT-3 코사인 유사도 점수: 78.5% AstroLLaMa 코사인 유사도 점수: 36.3% 논문 1: IC 348 성운의 스피처 센서스 논문 2: 중적외선 헤일로 HII 영역 주변의 순차적이고 자발적인 별 형성 KRGPT-3 코사인 유사도 점수: 82.4% AstroLLaMa 코사인 유사도 점수: 92.8% 그림 3: 위: GPT-3의 유사도 수준에 따라 10개의 동일한 빈으로 나뉜 코퍼스에서 무작위로 선택한 10,000개의 초록 간의 쌍별 코사인 유사도 분포. 아래: AstroLLaMA와 GPT-3 임베딩을 비교할 때 발산하는 코사인 유사도 값을 보여주는 두 가지 대표적인 예. 키워드 일치의 의미. 4 한계와 미래 방향 이 작업에서 천문학 연구 논문의 300,000개 이상의 초록을 포함하는 데이터 세트에서 미세 조정된 70억 개의 매개변수 언어 모델인 AstroLLaMA를 소개합니다. 기본 모델인 LLAMA-2 및 현재 최첨단 일반 LLM인 GPT-4와 비교했을 때 AstroLLaMA는 이 문헌의 관련 정보를 유능하게 파악하여 고품질 초록을 생성하는 데 있어 현저한 개선을 보여줍니다. 그러나 AstroLLaMA에도 한계가 없는 것은 아닙니다. 가장 두드러지는 것은 천문학의 특정 분야에서 모델의 지식 격차입니다. 그림 2에서 AstroLLaMA가 Gaia-ESO 데이터에서 잠재적인 별 후보를 추정한 것은 현저히 부정확합니다. 이러한 문제를 해결하기 위해 우리는 AstroLLaMA의 훈련 세트를 초록뿐만 아니라 기존 천문학 기사의 전체 LaTeX 소스로 풍부하게 만들고 있으며, 이를 통해 토큰 수를 약 두 자릿수만큼 확장하고 있습니다. 또 다른 우려 사항은 모델이 환각적이거나 허구적인 수치 데이터를 생성하는 경향에 있습니다. 이는 모델을 사실적 정확성으로 명확하게 조종하기보다는 혼란을 줄이는 데 중점을 두었기 때문일 가능성이 높습니다. AstroLLaMA의 출시는 이러한 부정확성을 해결하고 &quot;충실성&quot;(과학적 증거와 정확성을 존중)과 &quot;창의성&quot;(흥미로운 가설을 생각해 낼 수 있는 능력) 간의 균형을 다듬기 위해 커뮤니티 참여를 촉진하는 것을 목표로 합니다. AstroLLaMA는 천문학 분야의 전문 LLM을 위한 매력적인 프로토타입으로, 매개변수가 훨씬 적음에도 불구하고 GPT4에 비해 뛰어난 컨텍스트 인식 기능을 보여줍니다. 질문 답변, 과학적 요약 및 가설 생성과 같은 작업에서 향상된 성능을 위한 길을 열 뿐만 아니라 다중 모달 모델에도 적용됩니다(Liu et al., 2023). 우리는 LLM을 천문학 중심 애플리케이션에 활용하는 데 관심이 있는 연구자들에게 AstroLLaMA의 가중치와 훈련 데이터를 공개적으로 제공했습니다. 이와 함께, 우리는 Hugging Face에 다양한 &quot;놀이터&quot;를 구축하여 관심 있는 독자들이 다양한 관련 다운스트림 작업을 위한 이 강력한 시작점을 더욱 조정하고 개선할 수 있도록 초대하고 있습니다. 감사의 말 우리는 프로젝트를 빠르게 추진할 수 있도록 지원해 준 Microsoft Accelerate Foundation Models Research Initiative에 깊이 감사드립니다. Microsoft Research의 고급 AI 플랫폼 덕분에 우리는 언어 모델을 사용하여 천문학 문헌을 분석하는 데 드는 노력을 상당히 가속화할 수 있었습니다. https://huggingface.co/universe TBD/astrollama 윤리 성명 우리는 Meta에서 LLaMA에 대한 사전 훈련된 가중치를 얻었으며, Meta는 이러한 모델을 Hugging Face에서 다운로드할 수 있도록 제공합니다. 이 논문에서 사용된 arXiv 데이터 세트는 Kaggle에서 공개적으로 사용할 수 있습니다. AstroLLaMA가 천문학 연구 논문에 대한 고품질의 관련성 있는 초록을 생성할 수 있음을 입증했지만, 부정확한 데이터와 측정값을 생성할 가능성이 있음을 발견했습니다. 이는 다운스트림 작업에 이 모델을 사용하려는 연구자에게 경고가 되어야 하며, 이 문제를 개선하기 위해 향후 작업에서 정렬 전략을 채택하기를 권장합니다. 참고문헌 Google AI PALM 2. https://ai.google/discover/palm2/. A. Accomazzi, MJ Kurtz, EA Henneken, R. Chyla, J. Luker, CS Grant, DM Thompson, A. Holachek, R. Dave, SS Murray. 2015. ADS: 차세대 검색 플랫폼. Open Science at the Frontiers of Librarianship, Astronomical Society of the Pacific Conference Series 492권, 189페이지. Andrés Almeida, Scott F. Anderson, Maria ArgudoFernández, Carles Badenes, Kat Barger, Jorge K. Barrera-Ballesteros, Chad F. Bender, Erika Benitez, Felipe Besser, Dmitry Bizyaev, Michael R. Blanton, John Bochanski, Jo Bovy, William Nielsen Brandt, Joel R. Brownstein, Johannes Buchner, Esra Bulbul, Joseph N. Burchett, Mariana Cano Díaz, Joleen K. Carlberg, Andrew R. Casey, Vedant Chandra, Brian Cherinka, Cristina Chiappini, Abigail A. Coker, Johan Comparat, Charlie Conroy, Gabriella Contardo, Arlin Cortes, Kevin Covey, Jeffrey D. 크레인, 카티아 쿠냐, 콜린 다비에리, 제임스 W. 데이비슨 주니어 au2, 메건 C. 데이비스, 네이선 드 리, 호세 에두아르도 멘데스 델가도, 세바스티안 데마시, 프란체스코 디 밀레, 존 도너, 피터 다우, 톰 드웰리, 마이크 에러클리어스, 제이미 에릭슨, 샤오후이 팬, 에밀리 파, 사라 프레드릭, 로건 프라이스, 피터 프린차보이, 보리스 T. Gaensicke, Junqiang Ge, Consuelo González Ávila, Katie Grabowski, Catherine Grier, Guillaume Guiglion, Pramod Gupta, Patrick Hall, Keith Hawkins, Christian R. Hayes, JJ Hermes, Lorena Hernández-García, David W. Hogg, Jon A. Holtzman, Hector Javier IbarraMedel, Alexander Ji, Paula Jofre, Jennifer A. 존슨, 에이미 M. 존스, 카렌 Kinemuchi, Matthias Kluge, Anton Koekemoer, Juna A. Kollmeier, Marina Kounkel, Dhanesh Krishnarao, Mirko Krumpe, Ivan Lacerna, Paulo Jakson Assuncao Lago, Chervin Laporte, Ang Liu, Chao Liu, Xin Liu, Alexandre Roman Lopes, Matin Macktoobian, Viktor Malanushenko, Dan Maoz, Thomas Masseron, Karen L. Masters, Gal Matijevic, Aidan McBride, Ilija Medan, Andrea Merloni, Sean Morrison, Natalie Myers, Szabolcs Mészáros, C. Alenka Negrete, David L. Nidever, Christian Nitschelm, Audrey Oravetz, Daniel Oravetz, Kaike Pan, Yingjie Peng, Marc H. Pinsonneault, Rick Pogge, Dan Qiu, Anna Barbara 드 안드라데 Queiroz, Solange V. Ramirez, HansWalter Rix, Daniela Fernández Rosso, Jessie Runnoe, Mara Salvato, Sebastian F. Sanchez, Felipe A. Santana, Andrew Saydjari, Conor Sayres, Kevin C. Schlaufman, Donald P. Schneider, Axel Schwope, Javier Serna, Yue Shen, Jennifer Sobeck, Ying-Yi 송, Diogo Souto, Taylor Spoo, Keivan G. Stassun, Matthias Steinmetz, Ilya Straumit, Guy Stringfellow, José Sánchez-Gallego, Manuchehr Taghizadeh-Popp, Jamie Tayar, Ani Thakar, Patricia B. Tissera, Andrew Tkachenko, Hector Hernandez Toledo, Benny Trakhtenbrot, Jose G. Fernandez 트린카도, 니콜라스 트룹, 조나단 R. 트럼프, 사라 터틀, 나탈리 울로아, 호세 안토니오 바스케스-마타, 파블로 베라 알파로, 산드로 빌라노바, 스테파니 와흐터, 앤-마리 바이만스, 애덤 휠러, 존 윌슨, 리 워즈노, 줄리언 울프, 샹샹 쉬에, 제이슨 E. 이바라, 엘레오노라 자리, 게일 자소프스키. 2023. 슬론 디지털 스카이 서베이의 18번째 데이터 공개: SDSSS-V의 타겟팅 및 첫 번째 스펙트럼. 크리스틴 L. 보그만과 모건 F. 워퍼드. 2021. 데이터 프로세스에서 데이터 제품으로: 천문학의 지식 인프라. arXiv 전자 인쇄물, arXiv:2109.01707 페이지. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, 정형원, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, 현택 임, 바렛 조프, 알렉산더 Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason 웨이, 캐시 마이어-헬스턴, 더글러스 에크, 제프 딘, 슬라브 페트로프, 노아 피델. 2022. PaLM: 경로를 통한 언어 모델링 확장. 은하계 이오아나 치우카(Galactic Ioana Ciucă)와 위안센 팅(Yuan-Sen Ting). 2023. ChitChat: 대규모 언어 모델을 사용하여 천문학 문헌과 대화. arXiv 전자 인쇄물, 페이지 arXiv:2304.05406. Ioana Ciucă, Yuan-Sen Ting, Sandor Kruk, Kartheik Iyer. 2023. 천문학에서 강력한 가설 생성을 위한 적대적 프롬프트와 대규모 언어 모델의 힘 활용. arXiv 전자 인쇄본, arXiv:2306.11648 페이지. C. Fabricius, X. Luri, F. Arenou, C. Babusiaux, A. Helmi, T. Muraveva, C. Reylé, F. Spoto, A. Vallenari, T. Antoja, E. Balbinot, C. Barache, N. Bauchet, A. Bragaglia, D. Busonero, T. CantatGaudin, JM Carrasco, S. Diakité, M. Fabrizio, F. Figueras, A. Garcia-Gutierrez, A. Garofalo, C. Jordi, P. Kervella, S. Khanna, N. Leclerc, E. Licata, S. Lambert, PM Marrese, A. Masip, P. Ramos, N. Robichon, AC Robin, M. Romero-Gómez, S. Rubele 및 M. Weiler. 2021. Gaia 초기 데이터 공개 3. 천문학 및 천체물리학, 649:A5. Felix Grezes, Sergi Blanco-Cuaresma, Alberto Accomazzi, Michael J. Kurtz, Golnaz Shapurian, Edwin Henneken, Carolyn S. Grant, Donna M. Thompson, Roman Chyla, Stephen McDonald, Timothy W. Hostetler, Matthew R. Templeton, Kelly E. Lockhart, Nemanja Martinovic, Shinyi Chen, Chris Tanner, Pavlos Protopapas. 2021. 천문학 및 천체물리학을 위한 언어 모델인 astroBERT 구축. Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen. 2021. LORA: 대규모 언어 모델의 저순위 적응. Taku Kudo 및 John Richardson. 2018. SentencePiece: 신경망 텍스트 처리를 위한 간단하고 언어 독립적인 하위 단어 토크나이저 및 디토크나이저. 2018년 자연어 처리의 경험적 방법에 대한 컨퍼런스: 시스템 데모, 66-71페이지. Haotian Liu, Chunyuan Li, Qingyang Wu, Yong Jae Lee. 2023. 시각적 지시 튜닝. Ilya Loshchilov와 Frank Hutter. 2018. 분리된 가중치 감소 정규화. 국제 학습 표현 컨퍼런스에서. Meta. 2023. Llama 2: Open Foundation 및 미세 조정된 채팅 모델 | Meta AI Research. https://ai.meta.com/research/publications/llama-2open-foundation-and-fine-tuned-chat-models/. OpenAI. 2023. GPT-4 기술 보고서. Rico Sennrich, Barry Haddow, Alexandra Birch. 2016. 하위 단어 단위가 있는 희귀 단어의 신경 기계 번역. Association for Computational Linguistics(제1권: 장문 논문)의 제54회 연례 회의록, 1715-1725쪽. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample. 2023. LLAMA: 개방적이고 효율적인 기초 언어 모델.
