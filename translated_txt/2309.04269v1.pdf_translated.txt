--- ABSTRACT ---
♡ Salesforce AI ◇ MIT 컬럼비아 대학교: CS*, 생물의학 정보학* 요약에 포함할 &quot;적절한&quot; 양의 정보를 선택하는 것은 어려운 작업입니다. 좋은 요약은 지나치게 빽빽하고 따라하기 어렵지 않으면서도 자세하고 엔터티 중심적이어야 합니다. 이러한 상충 관계를 더 잘 이해하기 위해, 우리는 &quot;Chain of Density&quot;(COD) 프롬프트라고 하는 것을 사용하여 점점 더 밀도가 높은 GPT-4 요약을 요청합니다. 구체적으로, GPT-4는 길이를 늘리지 않고 누락된 중요한 엔터티를 반복적으로 통합하기 전에 초기 엔터티 희소 요약을 생성합니다. CoD로 생성된 요약은 더 추상적이고, 더 많은 융합을 보이며, 바닐라 프롬프트로 생성된 GPT-4 요약보다 리드 편향이 적습니다. 우리는 100개의 CNN DailyMail 기사에 대한 인간 선호도 연구를 수행한 결과, 인간은 바닐라 프롬프트로 생성된 것보다 밀도가 더 높고 인간이 쓴 요약과 거의 비슷한 밀도의 GPT-4 요약을 선호한다는 것을 발견했습니다. 정성적 분석은 정보성과 가독성 사이에 상충 관계가 있다는 개념을 뒷받침합니다. 주석이 달린 CoD 요약 500개와 주석이 없는 요약 5,000개가 HuggingFace¹에서 무료로 제공됩니다. 1
--- INTRODUCTION ---
자동 요약은 지난 몇 년 동안 크게 발전했는데, 이는 주로 레이블이 지정된 데이터 세트에 대한 감독된 미세 조정에서 GPT-4(OpenAI, 2023)와 같은 대규모 언어 모델(LLM)을 사용한 제로샷 프롬프팅으로 패러다임이 전환되었기 때문입니다. 추가 교육 없이도 신중한 프롬프팅을 통해 길이(Goyal et al., 2022), 주제(Bhaskar et al., 2023), 스타일(Pu and Demberg, 2023)과 같은 요약 특성을 세부적으로 제어할 수 있습니다. 간과된 측면은 요약의 정보 밀도입니다. 이론상 다른 텍스트를 압축한 요약은 소스 문서보다 밀도가 높아야 합니다(정보 농도가 더 높아야 함). LLM 디코딩의 높은 지연 시간(Kaddour et al., 2023)을 감안할 때, 더 적은 수의 https://huggingface.co/datasets/griffin/chain_of_density 엔티티/토큰으로 더 많은 정보를 포함합니다.0.인간 요약 0.인간이 선호하는 CoD 0.0.0.밀도 사슬 단계 바닐라 GPT-그림 1: 밀도 사슬(COD) 요약은 점점 더 엔티티 밀도가 높아지며 바닐라 GPT-4 요약에 가깝게 시작하여 결국 인간이 작성한 요약을 능가합니다.인간 주석은 인간이 작성한 요약과 유사한 밀도가 더 바람직하다고 제안합니다.명확성(밀도가 낮을수록 좋음)과 정보성(밀도가 높을수록 좋음) 간의 적절한 균형을 찾는 것입니다.특히 실시간 애플리케이션의 경우 가치 있는 목표입니다.그러나 얼마나 밀도가 높은지는 미지수입니다.요약에 세부 정보가 충분하지 않으면 정보가 없습니다. 그러나 정보가 너무 많으면 전체 길이를 늘리지 않고는 따라가기 어려울 수 있습니다. 고정된 토큰 예산에 따라 더 많은 정보를 전달하려면 추상화, 압축 및 융합을 결합해야 합니다. 읽을 수 없게 되거나 사실적으로 부정확해지기 전에 추가 정보를 위한 공간을 얼마나 만들 수 있는지에 한계가 있습니다. 이 논문에서는 GPT-4에서 생성된 점점 더 밀도가 높아지는 요약 세트에 대한 인간의 선호도를 요청하여 이 한계를 파악하려고 합니다. 엔터티, 특히 토큰당 엔터티의 평균 수를 밀도의 대리로 처리하여 초기 엔터티-희소 요약을 생성합니다. 그런 다음 전체 길이(전체의 5배)를 늘리지 않고 이전 요약에서 누락된 1~3개의 엔터티를 반복적으로 식별하고 융합합니다. 각 요약은 이전 요약보다 엔터티 대 토큰 비율이 더 높습니다. 인간의 선호도 데이터를 기반으로 인간은 인간이 쓴 요약과 거의 비슷한 밀도를 가진 요약을 선호하며, 더 많은 Chain of Density(COD) 프롬프트 기사: {{기사}} 위의 기사에 대한 점점 더 간결하고 엔터티가 밀집된 요약을 생성합니다. 다음 2단계를 5번 반복합니다. 1단계. 이전에 생성된 요약에서 누락된 기사의 1~3개 정보적 엔터티(&quot;;&quot;로 구분)를 식별합니다. 2단계. 이전 요약의 모든 엔터티와 세부 정보와 누락된 엔터티를 포함하는 동일한 길이의 새롭고 더 조밀한 요약을 작성합니다. 누락된 엔터티는 다음과 같습니다. 주요 스토리와 관련이 있습니다. - 구체적: 설명적이지만 간결합니다(5단어 이하). - 소설: 이전 요약에 없습니다. - 충실함: 기사에 있습니다. 어디에나: 기사의 어느 곳에나 있습니다. 지침: 첫 번째 요약은 길어야 하지만(4~5문장, -80단어) 매우 비구체적이어야 하며, 누락으로 표시된 엔터티를 넘어서는 정보는 거의 포함하지 않아야 합니다. -80단어를 달성하기 위해 지나치게 장황한 언어와 필러(예: &quot;이 기사에서 논의합니다&quot;)를 사용합니다. - 모든 단어를 중요하게 여기세요. 이전 요약을 다시 작성하여 흐름을 개선하고 추가 엔터티를 위한 공간을 마련하세요. &quot;이 기사에서 논의합니다&quot;와 같이 정보가 없는 문구를 융합, 압축 및 제거하여 공간을 마련하세요. 요약은 매우 조밀하고 간결하면서도 독립적이어야 합니다. 예를 들어 기사 없이도 쉽게 이해할 수 있어야 합니다. 누락된 엔터티는 새 요약의 어느 곳에나 나타날 수 있습니다. - 이전 요약의 엔터티를 삭제하지 마세요. 공간을 마련할 수 없으면 새 엔터티를 덜 추가하세요. 각 요약에 정확히 같은 수의 단어를 사용해야 한다는 점을 기억하세요. JSON 형식으로 답변하세요. JSON은 키가 &quot;Missing_Entities&quot;와 &quot;Denser_Summary&quot;인 사전의 목록(길이 5)이어야 합니다. COD 출력(이전에서 추가된 세부 정보) 이 기사에서는 중국 그랑프리에서 두 명의 레이싱 드라이버인 젠슨 버튼과 파스터 말도나도가 관련된 사고에 대해 설명합니다. 두 사람은 13위를 놓고 경쟁하던 중 Button이 Maldonado의 차량과 충돌하여 두 차량 모두 손상되었습니다. 이 사고로 Button에게 페널티가 부과되어 14위로 강등되었습니다. 반면 Maldonado는 차량 손상으로 인해 경주에서 기권해야 했습니다. 중국 그랑프리에서 McLaren을 운전하던 Jenson Button은 13위를 놓고 경쟁하던 중 Pastor Maldonado의 Lotus와 충돌했습니다. 이 충돌로 Maldonado는 기권하고 Button은 페널티를 받아 14위로 떨어졌습니다. 이 사고는 충돌을 피하고 두 계단을 오른 Fernando Alonso 앞에서 벌어졌습니다. 중국 그랑프리에서 Jenson Button의 McLaren은 Pastor Maldonado의 Lotus를 충돌하여 Maldonado는 기권하고 Button은 5초 페널티를 받아 14위로 강등되었습니다. Button은 또한 슈퍼라이센스에 대한 페널티 포인트 2점을 받았습니다. 이 사고를 목격한 페르난도 알론소는 두 계단을 올랐고, 버튼은 니코 로즈버그의 메르세데스에 랩을 빼앗겼습니다. 젠슨 버튼의 맥라렌은 중국 그랑프리에서 파스터 말도나도의 로터스와 충돌하여 버튼의 차량은 앞날개가 손상되고 말도나도의 차량은 뒷부분이 손상되어 기권하게 되었습니다. 버튼은 5초의 페널티와 2개의 슈퍼라이센스 포인트를 받아 14위로 떨어졌습니다. 페르난도 알론소는 두 계단을 올랐고, 버튼은 니코 로즈버그에, 알론소는 세바스찬 베텔과 키미 라이코넨에 랩을 빼앗겼습니다. 사고로 가득 찬 중국 그랑프리의 49랩에서 젠슨 버튼의 맥라렌은 파스터 말도나도의 로터스를 들이받아 손상되고 말도나도는 기권하게 되었습니다. 버튼은 5초의 페널티와 2개의 슈퍼라이센스 포인트를 받아 14위로 떨어졌습니다. 충돌을 목격한 페르난도 알론소는 두 계단을 올랐고, 버튼은 니코 로즈버그에게, 알론소는 페라리의 세바스찬 베텔과 키미 라이코넨에게 뒤졌습니다.그림 2: 밀도 사슬(COD) 프롬프트와 예시 출력.각 단계에서 길이를 늘리지 않고 이전 요약에 1~3개의 추가 세부 정보(엔터티)가 추가됩니다.새로운 엔터티를 위한 공간을 마련하기 위해 기존 콘텐츠를 다시 작성합니다(예: 압축, 융합).주석 작성자의 절반(2/4)은 마지막에서 두 번째 요약을 선호하고 다른 사람들은 마지막 요약을 선호합니다.바닐라 GPT-4 프롬프트에서 생성된 것보다 밀도가 높습니다.저희의 주요 기여는 다음과 같습니다.• 요약을 점점 더 엔터티 밀도 있게 만들기 위한 프롬프트 기반 반복적 방법(COD)을 개발합니다.• CNN/Dailymail 기사에서 점점 더 밀도가 높은 요약에 대한 인간 및 자동 평가를 수행하여 정보성(더 많은 엔터티 선호)과 명확성(더 적은 엔터티 선호) 간의 상충 관계를 더 잘 이해합니다. 오픈 소스 GPT-4 요약, 주석 및 평가 또는 정제에 사용할 5,000개의 주석이 없는 CoD 요약 세트. 포함된 엔터티 수를 늘리는 동시에 동일한 길이를 유지하기 위해 이전 요약에서 의미 있는 콘텐츠를 삭제하는 대신 추상화, 융합 및 압축을 명시적으로 권장합니다. 그림 2는 예제 출력과 함께 프롬프트를 표시합니다. 엔터티 유형에 대해 규범적이기보다는 누락된 엔터티를 다음과 같이 간단히 정의합니다. • . 관련성: 주요 스토리와 관련이 있음. 구체적: 설명적이지만 간결함(5단어 이하). • 신규: 이전 요약에 없음. • 충실함: 기사에 있음. • 어디든: 기사의 아무 곳에나 있음. 2 밀도 사슬 프롬프트 프롬프트. 우리의 목표는 길이를 제어하면서 정보 밀도 수준이 다양한 GPT-4로 요약 세트를 생성하는 것입니다.길이는 요약을 평가할 때 강력한 교란 요인으로 입증되었습니다(Fabbri et al., 2021; Liu et al., 2023b). 이를 위해 단일 COD(Chain of Density) 프롬프트를 공식화하여 초기 요약을 생성하고 점점 더 엔터티 밀도를 높입니다. 구체적으로, 고정된 수의 턴 동안 소스 텍스트의 고유한 눈에 띄는 엔터티 세트를 식별하여 길이를 늘리지 않고 이전 요약에 융합합니다. 첫 번째 요약은 1~3개의 초기 엔터티에만 초점을 맞추므로 엔터티 희소합니다. 데이터. 우리는 COD 요약을 생성하기 위해 CNN/DailyMail 요약(Nallapati et al., 2016) 테스트 세트에서 무작위로 100개의 기사를 샘플링합니다. 참조점. 참조 프레임을 위해 CoD 요약 통계를 사람이 작성한 요점 스타일 참조 요약과 GPT-4에서 바닐라 프롬프트인 &quot;기사의 매우 짧은 요약을 작성하세요. 70단어를 초과하지 마세요.&quot;를 사용하여 생성한 요약과 비교합니다. 원하는 토큰 길이를 CoD 요약과 일치하도록 설정합니다(표 1 참조). 3 통계 직접 통계(토큰, 엔터티, 엔터티 밀도)는 COD에서 직접 제어하는 반면 간접 추출 밀도 바닐라 GPT-1.3.1.인간 요약 1.70 바닐라 GPT-3.융합 1.1.2.인간 요약 1.2.1.밀도 사슬 단계 밀도 사슬 단계 관사 내 평균 문장 위치 16.14.12.10.0 인간 요약 8.0 바닐라 GPT-6.4.밀도 사슬 단계 그림 3: CoD에서 생성된 요약은 점점 더 추상화되는 반면 융합이 더 많고 리드 편향이 줄었습니다. 통계는 밀도화의 예상 부산물입니다. COD 단계 토큰 엔터티 밀도(E/T)6.0.8.0.9.0.10.0.12.0.Human8.0.Vanilla GPT-8.0.표 1: GPT-4 COD 요약에 대한 명시적 통계. 직접 통계. 표 1에서 NLTK(Loper 및 Bird, 2002)로 토큰을 계산하고, Spacy²로 고유한 엔터티를 측정하고, 비율로 엔터티 밀도를 계산합니다. CoD 프롬프트는 대체로 고정된 토큰 예산을 따릅니다. 사실, 두 번째 단계는 불필요한 단어가 처음에 자세한 요약에서 제거됨에 따라 길이가 평균 5토큰(72에서 67) 감소합니다. 엔터티 밀도는 0.089에서 시작하여 처음에는 Human 및 Vanilla GPT-4(0.151 및 0.122)보다 낮았지만 5단계 밀도화 후 0.167로 상승합니다. 간접 통계. 추상성은 각 CoD 단계마다 증가해야 하는데, 이는 각 추가 엔터티에 대한 공간을 만들기 위해 요약을 반복적으로 다시 작성하기 때문입니다. 추출 밀도로 추상성을 측정합니다. 추출 조각의 평균 제곱 길이(Grusky et al., 2018). 마찬가지로 개념 융합 수준은 엔터티가 고정 길이 요약에 추가됨에 따라 단조롭게 증가해야 합니다. 우리는 각 요약 문장에 맞춰진 소스 문장의 평균 수로 융합을 대리합니다. 정렬을 위해 상대적 ROUGE 이득 방법(Zhou et al., 2018)을 사용하는데, 이는 추가 문장의 상대적 ROUGE 이득이 더 이상 양수가 아닐 때까지 소스 문장을 대상 문장에 맞춥니다. 또한 요약 내용이 출처인 기사의 위치인 콘텐츠 분포가 변경될 것으로 예상합니다. 구체적으로, CoD 요약은 처음에는 강한 리드 바이어스를 보이지만 점차적으로 기사의 중간과 끝에서 엔터티를 가져오기 시작할 것으로 예상합니다. 이를 측정하기 위해 융합에서 얻은 정렬을 사용하고 정렬된 모든 소스 문장의 평균 문장 순위를 측정합니다. 그림은 이러한 가설을 확인합니다. 추상성은 재작성 단계 수에 따라 증가하고(왼쪽의 낮은 추출 밀도), 융합 속도가 증가하고(가운데 그림), 요약은 기사 중간과 끝의 내용을 통합하기 시작합니다(오른쪽 그림). 흥미롭게도, 모든 CoD 요약은 인간이 쓴 요약과 기준 요약보다 더 추상적입니다. 4개 결과 CoD 요약에 존재하는 상충 관계를 더 잘 이해하기 위해 선호도 기반 인간 연구와 GPT-4를 사용한 평가 기반 평가를 수행합니다. COD 1위 투표 점유율 개별 주석자 집계 단계 3.0 2.0 13.0 17.8.25.28.0 43.0 31.30.22.28.21.0 24.23.29.25.0 13.0 26.22.21.0 17.0 10.0 16.15.표 2: 단계별 COD 요약에 대한 1위 투표 내역. 집계 선호도에 따라 모달 COD 단계는 2, 중앙값은 3, 기대값은 3.06입니다. 인간의 선호도. 우리는 밀도가 전반적인 품질에 대한 인간의 평가에 미치는 영향을 평가하기 위해 인간 평가를 실시합니다. 구체적으로, 논문의 처음 네 명의 저자에게 동일한 100개 기사에 대한 기사와 함께 무작위로 섞인 COD 요약이 제시되었습니다(5단계 * 100 = 총 500개 요약). Stiennon et al. (2020)의 &quot;좋은 요약&quot; 정의에 따라(논문의 표 6), 각 주석자는 가장 선호하는 요약을 표시했습니다. 표 2는 주석자 간 COD 단계별 1위 투표의 세부 내역과 주석자 간 집계를 보고합니다. 첫째, 요약과 작업의 주관적 특성 간의 미묘한 차이를 나타내는 낮은 Fleiss&#39; kappa(Fleiss, 1971) 0.112를 보고합니다. 최근 작업에는 COD 단계 개체 밀도 정보 품질 일관성 귀속 전체 GPT-4 평가 평균 0.4.4.4.4.4.0.4.4.4.5.4.4.0.4.4.4.5.4.4.0.4.4.4.5.4.4.0.4.4.4.4.4.4.표 3: 단계별 밀도 사슬(COD) 요약에 대한 GPT-4 리커트 척도(1-5) 평가. StepSky Sports 전문가 게리 네빌은 데얀 로브렌이 무모하게 아요제 페레즈에게 도전했을 때 뉴캐슬에 페널티를 주지 않은 심판 리 메이슨을 비판했습니다. 네빌은 메이슨의 입장이 그가 사건을 명확하게 보고 올바른 결정을 내릴 수 있도록 했어야 한다고 주장했습니다. 페널티는 뉴캐슬이 경기에 복귀할 수 있는 잠재적인 경로를 제공했을 수 있습니다. Denser is Preferred 프랑스어로 방송되는 글로벌 텔레비전 네트워크인 TV5Monde가 강력한 사이버 공격을 받았다고 Yves Bigot 감독이 확인했습니다. 파리 시간으로 오후 10시경 시작된 이 공격으로 인해 네트워크의 11개 채널, 소셜 미디어 아울렛, 웹사이트가 검은색으로 변했습니다. 일부 TV5Monde 소셜 미디어 계정에서 ISIS 로고가 발견되었습니다. 네트워크 팀은 몇 시간 후에도 서비스를 복구하기 위해 노력하고 있었습니다. Less Dense is Preferred Densification StepGary Neville은 Ayoze Perez가 Dejan Lovren에게 도전을 받은 후 Newcastle에 페널티킥을 주지 않은 심판 Lee Mason의 결정을 비난했습니다. Raheem Sterling과 Joe Allen의 골을 넣은 Liverpool은 페널티킥이 주어졌다면 Newcastle에서 반격을 당할 수도 있었습니다. Neville은 Mason의 위치가 올바른 판정으로 이어졌어야 한다고 주장했습니다. TV5Monde는 이브 비고 국장이 확인한 사이버 공격을 받아 파리 시간 오후 10시경 11개 채널, 소셜 미디어, 웹사이트에 대한 통제권을 잃었습니다. 소셜 미디어에는 ISIS 로고가 표시되었습니다. 프랑스 문화통신부에 따르면 전 세계적으로 2억 6천만 가구에 도달한 이 네트워크는 왈로니아-브뤼셀 연방과 협력하고 있습니다. 네트워크 팀은 서비스를 복구하고 있었습니다. 그림 4: 인간이 선호하는 밀도 증가 단계(왼쪽)와 선호하지 않는 단계의 예. 왼쪽의 경우, &quot;리버풀&quot;과 골 득점자가 추가되어 관련성이 있기 때문에 하단 요약이 선호됩니다. 두 번째 요약은 &quot;경기로 돌아갈 수 있는 잠재적 경로&quot;를 &quot;역전&quot;으로 합성하는 것과 같이 합리적인 압축으로 공간을 만듭니다. 오른쪽의 경우, &quot;TVMonde&quot;에 대한 자세한 내용을 추가해도 &quot;사이버 공격&quot;과 &quot;이브 비고&quot;라는 엔터티의 어색한 융합이 있는 것을 보완하지 못하는데, 이는 이전 요약을 강화해야 했던 직접적인 결과였습니다. 유사하게 GPT 기반 요약을 판단할 때 낮은 인스턴스 수준 일치가 나타났습니다(Goyal et al., 2022). 그러나 시스템 수준에서는 몇 가지 추세가 나타나기 시작했습니다. 4명의 주석자 중 3명의 경우 CoD 단계는 100개 예제에서 1위 투표에서 가장 큰 점유율을 받았습니다(각각 28, 43 및 31.4%). 그러나 전체적으로 1위를 차지한 요약의 61%(23.0+22.5+15.5)에는 ≥ 3 밀도화 단계가 포함되었습니다. 중간 선호 COD 단계는 중간(3)에 있으며 예상 단계는 3.06입니다. 3단계 요약의 평균 밀도를 기준으로 COD 후보에서 선호되는 엔터티 밀도가 약 0.15라고 대략적으로 추론할 수 있습니다. 표 1에서 이 밀도가 인간이 작성한 요약(0.151)과 일치하지만 바닐라 GPT-4 프롬프트로 생성된 요약(0.122)보다 눈에 띄게 높다는 것을 알 수 있습니다.자동 메트릭.평가자로서 GPT-는 인간 판단과 적절하게 상관관계가 있는 것으로 나타났으며(Fu et al., 2023; Liu et al., 2023a), 일부 주석 작업에서는 크라우드 소싱 작업자보다 잠재적으로 더 우수한 성과를 거두기도 합니다(Gilardi et al., 2023).인간 평가(아래)를 보완하기 위해 GPT-4가 CoD 요약(1-5)을 정보적, 품질, 일관성, 귀속적, 전반적인 5가지 측면에서 평가하도록 합니다.정보적, 품질, 귀속적의 정의는 Aharoni et al.(2023)에서 나온 반면, 일관성은 Fabbri et al.(2021)³에서 나왔습니다.전반적인 목표는 이러한 품질을 함께 포착하는 것입니다. 부록 A에서 사용된 프롬프트를 참조하세요.3 품질 및 일관성은 기사와 독립적인 지표입니다.각 차원에 대한 점수를 요청합니다.표 3은 밀도가 정보성과 상관관계가 있음을 시사하지만 한계가 있으며 점수는 단계(4.74)에서 정점을 이룹니다.기사 없는 차원: 품질과 일관성은 더 빨리 감소합니다(각각 2단계와 1단계 후).모든 요약은 출처 기사에 기인하는 것으로 간주됩니다.전체 점수는 더 밀도 있고 정보가 많은 요약으로 치우치며, 4단계가 가장 높은 점수를 받습니다.차원 전체에서 평균적으로 첫 번째와 마지막 COD 단계는 가장 선호되지 않는 반면 중간 세 단계는 가깝습니다(각각 4.78, 4.77 및 4.76).부록 A에서 우리는 인간의 판단에 대한 전체 지표의 가장 높은 요약 수준 상관관계(0.31 피어슨 상관관계)를 보고하지만, Deutsch et al.(2022)이 요약의 품질이 비슷할 때 관찰한 현상인 전반적으로 낮은 상관관계에 주목합니다.질적 분석. 요약의 일관성/가독성과 정보성 사이에는 명확한 상충 관계가 있습니다. 예를 들어, 그림 4에서 우리는 두 가지 COD 단계를 제시합니다. 하나는 요약이 더 자세히 개선되는 단계이고, 다른 하나는 요약이 손상되는 단계입니다. 평균적으로 중간 CoD 요약이 이 균형을 가장 잘 달성했지만, 이 상충 관계를 정확하게 정의하고 정량화하는 것은 향후 작업에 맡깁니다. 5
--- RELATED WORK ---
GPT 요약. Goyal 등(2022)은 뉴스 기사 요약에 GPT-3를 벤치마킹하여 인간이 이전의 감독 기준선보다 GPT-3 요약을 선호한다는 것을 발견했는데, 이는 기존의 참조 기반 및 참조 없는 지표를 반영하지 못했습니다. Zhang 등(2023)은 프리랜서 작가에게 고품질 요약을 요청함으로써 제로샷 GPT-3 요약이 인간과 동등한 성과를 보인다는 것을 발견했습니다. 엔티티 기반 요약. Narayan 등(2021)은 키워드(Li 등, 2020; Dou 등, 2021) 또는 순수 추출 단위(Dou 등, 2021; Adams 등, 2023a)와 대조적으로 요약 모델의 감독 미세 조정을 위한 계획 단계로 엔티티 체인을 생성하는 것을 제안했습니다. 엔티티는 요약을 위한 제어의 한 형태로 통합되기도 하며(Liu와 Chen, 2021; He 등, 2022; Maddela 등, 2022), 충실도를 개선하기 위해(Nan 등, 2021; Adams 등, 2022), 평가 단위로서도 통합되었습니다(Cao 등, 2022; Adams 등, 2023b). 6 결론 우리는 요약 밀도가 전반적인 품질에 대한 인간의 선호도에 미치는 영향을 연구합니다. 밀도가 어느 정도 선호되지만, 요약에 토큰당 엔티티가 너무 많으면 가독성과 일관성을 유지하기가 매우 어렵습니다. 우리는 고정 길이, 가변 밀도 요약 주제에 대한 추가 연구를 위해 주석이 달린 테스트 세트와 더 큰 주석이 없는 훈련 세트를 오픈 소스로 제공합니다. 7 제한 사항 우리는 뉴스 요약이라는 단일 도메인에 대한 COD만 분석합니다. 주석은 높은 요약 수준의 일치를 보이지 않았지만 시스템 수준의 추세를 보이기 시작했으며, 이는 LLM 기반 평가에 대한 이전 작업(Goyal et al., 2022)과 일치합니다. 마지막으로 GPT-4는 폐쇄형 소스 모델이므로 모델 가중치를 공유할 수 없습니다. 그러나 모든 평가 데이터, 주석, 그리고 5,un-annotated COD를 게시하여 다운스트림 사용 사례에 사용합니다. 예를 들어 LLAMA-2와 같은 오픈 소스 모델로의 밀도 증류입니다(Touvron et al., 2023). 참고문헌 Griffin Adams, Alex Fabbri, Faisal Ladhak, Noémie Elhadad, Kathleen McKeown. 2023a. 계획 기반 요약 재순위 지정을 위한 EDU 추출물 생성. 제61회 연례 총회 의사록(제1권: 장문 논문), 2680-2697쪽, 캐나다 토론토. 전산 언어학 협회. 그리핀 애덤스, 한친 싱, 칭 선, 크리스토퍼 와인스톡, 캐슬린 맥키언, 노에미 엘하다드. 2022. 충실한 요약을 위한 참고문헌 수정 방법 배우기. 전산 언어학 협회의 연구 결과: EMNLP 2022, 4009-4027쪽, 아랍에미리트 아부다비. 전산 언어학 협회. 그리핀 애덤스, 제이슨 주커, 노에미 엘하다드. 2023b. 장문 병원 과정 요약을 위한 충실성 지표의 메타 평가. arXiv 사전 인쇄본 arXiv:2303.03948. Roee Aharoni, Shashi Narayan, Joshua Maynez, Jonathan Herzig, Elizabeth Clark, Mirella Lapata. 2023. 사실적 일관성 평가를 통한 다국어 요약. Findings of the Association for Computational Linguistics: ACL 2023, 3562-3591페이지, 토론토, 캐나다. Association for Computational Linguistics. Adithya Bhaskar, Alex Fabbri, Greg Durrett. 2023. GPT-3.5를 사용한 촉구 의견 요약. Findings of the Association for Computational Linguistics: ACL 2023, 9282-9300페이지, 토론토, 캐나다. Association for Computational Linguistics. Meng Cao, Yue Dong, Jackie Cheung. 2022. 환각이지만 사실! 추상 요약에서 환각의 사실성 검사. 제60회 전산 언어학 협회 연례 회의록(제1권: 장문 논문), 3340-3354쪽, 아일랜드 더블린. 전산 언어학 협회. Daniel Deutsch, Rotem Dror, Dan Roth 저. 2022. 자동 요약 평가 지표의 시스템 수준 상관 관계 재검토. 2022년 전산 언어학 협회 북미 지부 회의록: 인간 언어 기술, 6038-6052쪽, 미국 시애틀. 전산 언어학 협회. Zi-Yi Dou, Pengfei Liu, Hiroaki Hayashi, Zhengbao Jiang, Graham Neubig 저. 2021. GSum: 안내 신경 추상 요약을 위한 일반 프레임워크. 2021년 북미 컴퓨터 언어학 협회 회의록: 인간 언어 기술, 4830-4842쪽, 온라인. 컴퓨터 언어학 협회. Alexander R. Fabbri, Wojciech Kryściński, Bryan McCann, Caiming Xiong, Richard Socher, Dragomir Radev. 2021. SummEval: 요약 평가 재평가. 컴퓨터 언어학 협회 회의록, 9:391-409. Joseph L Fleiss. 1971. 많은 평가자 간의 명목 척도 일치도 측정. Psychological bulletin, 76(5):378. Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, Pengfei Liu. 2023. Gptscore: 원하는 대로 평가하세요. arXiv 사전 인쇄본 arXiv:2302.04166. Fabrizio Gilardi, Meysam Alizadeh, Maël Kubli. 2023. Chatgpt는 텍스트 주석 작업에서 크라우드 워커보다 성능이 우수합니다. arXiv 사전 인쇄본 arXiv:2303.15056. Tanya Goyal, Junyi Jessy Li, Greg Durrett. 2022. GPT-3 시대의 뉴스 요약 및 평가. arXiv 사전 인쇄본 arXiv:2209.12356. Max Grusky, Mor Naaman, Yoav Artzi. 2018. 뉴스룸: 다양한 추출 전략을 갖춘 130만 개의 요약 데이터 세트. 2018년 북미 컴퓨터 언어학회 학술대회 논문집: 인간 언어 기술, 제1권(긴 논문), 708-719쪽, 루이지애나주 뉴올리언스. 컴퓨터 언어학회. 허 준시안, 보이치에크 크리신스키, 브라이언 맥캔, 나즈닌 라자니, 카이밍 시옹. 2022. CTRLsum: 일반적인 제어 가능 텍스트 요약을 향해. 2022년 경험적 언어학 학술대회 논문집
--- CONCLUSION ---
우리는 요약 밀도가 전반적인 품질에 대한 인간의 선호도에 미치는 영향을 연구합니다. 우리는 어느 정도의 밀도가 선호되지만, 토큰당 요약에 너무 많은 엔터티가 포함되어 있으면 가독성과 일관성을 유지하기가 매우 어렵다는 것을 발견했습니다. 우리는 고정 길이, 가변 밀도 요약 주제에 대한 추가 연구를 위해 주석이 달린 테스트 세트와 더 큰 주석이 없는 교육 세트를 오픈 소스로 제공합니다. 7 한계 우리는 단일 도메인인 뉴스 요약에 대한 COD만 분석합니다. 주석은 높은 요약 수준의 일치를 보이지 않았지만 시스템 수준의 추세를 보이기 시작했는데, 이는 LLM 기반 평가에 대한 이전 연구(Goyal et al., 2022)와 일치합니다. 마지막으로, GPT-4는 폐쇄형 소스 모델이므로 모델 가중치를 공유할 수 없습니다. 그러나 우리는 다운스트림 사용 사례에 사용할 모든 평가 데이터, 주석, 주석이 없는 5, COD를 게시합니다.예를 들어, LLAMA-2(Touvron et al., 2023)와 같은 오픈 소스 모델로의 밀도 증류).참고문헌 Griffin Adams, Alex Fabbri, Faisal Ladhak, Noémie Elhadad, Kathleen McKeown.2023a.계획 기반 요약 재순위 지정을 위한 EDU 추출물 생성.제61회 전산 언어학 협회 연례 회의록(제1권: 장문 논문), 2680-2697쪽, 캐나다 토론토.전산 언어학 협회.Griffin Adams, Han-Chin Shing, Qing Sun, Christopher Winestock, Kathleen McKeown, Noémie Elhadad. 2022. 충실한 요약을 위한 참고문헌 수정 방법 학습. 계산 언어학 협회의 연구 결과: EMNLP 2022, 4009-4027페이지, 아랍에미리트 아부다비. 계산 언어학 협회. Griffin Adams, Jason Zucker, Noémie Elhadad. 2023b. 장문 병원 과정 요약을 위한 충실도 지표의 메타 평가. arXiv 사전 인쇄본 arXiv:2303.03948. Roee Aharoni, Shashi Narayan, Joshua Maynez, Jonathan Herzig, Elizabeth Clark, Mirella Lapata. 2023. 사실적 일관성 평가를 통한 다국어 요약. 계산 언어학 협회의 연구 결과: ACL 2023, 3562-3591페이지, 캐나다 토론토. Association for Computational Linguistics. Adithya Bhaskar, Alex Fabbri, Greg Durrett. 2023. GPT-3.5를 사용한 촉구 의견 요약. Association for Computational Linguistics의 발견: ACL 2023, 9282-9300쪽, 토론토, 캐나다. Association for Computational Linguistics. Meng Cao, Yue Dong, Jackie Cheung. 2022. 환각이지만 사실! 추상적 요약에서 환각의 사실성 검토. Association for Computational Linguistics의 제60회 연례 회의록(제1권: 장문 논문), 3340-3354쪽, 더블린, 아일랜드. Association for Computational Linguistics. Daniel Deutsch, Rotem Dror, Dan Roth에서. 2022. 자동 요약 평가 지표의 시스템 수준 상관 관계 재검토. 2022년 북미 컴퓨터 언어학회 회의록: 인간 언어 기술, 6038-6052쪽, 미국 시애틀. 컴퓨터 언어학회. Zi-Yi Dou, Pengfei Liu, Hiroaki Hayashi, Zhengbao Jiang, Graham Neubig. 2021. GSum: 유도 신경 추상 요약을 위한 일반 프레임워크. 2021년 북미 컴퓨터 언어학회 회의록: 인간 언어 기술, 4830-4842쪽, 온라인. 컴퓨터 언어학회. Alexander R. Fabbri, Wojciech Kryściński, Bryan McCann, Caiming Xiong, Richard Socher, Dragomir Radev. 2021. SummEval: 요약 평가 재평가. 계산 언어학 협회의 거래, 9:391-409. Joseph L Fleiss. 1971. 많은 평가자 간의 명목 척도 일치 측정. 심리학 게시판, 76(5):378. Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, Pengfei Liu. 2023. Gptscore: 원하는 대로 평가. arXiv 사전 인쇄본 arXiv:2302.04166. Fabrizio Gilardi, Meysam Alizadeh, Maël Kubli. 2023. Chatgpt는 텍스트 주석 작업에서 군중 작업자보다 성능이 우수합니다. arXiv 사전 인쇄본 arXiv:2303.15056. Tanya Goyal, Junyi Jessy Li, Greg Durrett. 2022. gpt-3 시대의 뉴스 요약 및 평가. arXiv 사전 인쇄본 arXiv:2209.12356. Max Grusky, Mor Naaman, Yoav Artzi. 2018. 뉴스룸: 다양한 추출 전략을 사용한 130만 개의 요약 데이터 세트. 2018년 북미 컴퓨터 언어학 협회 회의록: 인간 언어 기술, 제1권(긴 논문), 708-719쪽, 루이지애나주 뉴올리언스. 컴퓨터 언어학 협회. Junxian He, Wojciech Kryscinski, Bryan McCann, Nazneen Rajani, Caiming Xiong. 2022. CTRLsum: 일반적인 제어 가능 텍스트 요약을 향해. 2022 자연어 처리 경험적 방법 컨퍼런스 회의록, 5879-5915페이지, 아랍에미리트 아부다비. 계산언어학 협회. 장 카두르, 조슈아 해리스, 막시밀리안 모제스, 허비 브래들리, 로베르타 라일레아누, 로버트 맥하디. 2023. 대규모 언어 모델의 과제와 응용. arXiv 사전 인쇄본 arXiv:2307.10169. 하오란 리, 주난 주, 지아준 장, 청칭 종, 허 샤오동. 2020. 키워드 안내 추상 문장 요약. 인공지능에 대한 AAAI 컨퍼런스 회의록, 34권, 8196-8203페이지. 양 리우, 댄 이터, 이총 쉬, 슈오항 왕, 루오첸 쉬, 청광 주. 2023a. Gpteval: 더 나은 인간 정렬을 갖춘 gpt-4를 사용한 Nlg 평가. arXiv 사전 인쇄본 arXiv:2303.16634. Yixin Liu, Alex Fabbri, Pengfei Liu, Yilun Zhao, Linyong Nan, Ruilin Han, Simeng Han, Shafiq Joty, Chien-Sheng Wu, Caiming Xiong, Dragomir Radev. 2023b. 금본위제 재검토: 견고한 인간 평가를 통한 요약 평가 기반. 제61회 전산언어학 협회 연례 회의록(제1권: 장문 논문), 4140-4170쪽, 캐나다 토론토. 전산언어학 협회. Zhengyuan Liu와 Nancy Chen. 2021. 개인 명명 엔터티 계획을 통한 제어 가능한 신경 대화 요약. 2021 자연어 처리 경험적 방법 컨퍼런스 회의록, 92-106페이지, 온라인 및 도미니카 공화국 푼타카나. 전산 언어학 협회. Edward Loper 및 Steven Bird. 2002. Nltk: 자연어 툴킷. arXiv 사전 인쇄본 cs/0205028. Mounica Maddela, Mayank Kulkarni 및 Daniel Preotiuc-Pietro. 2022. EntSUM: 엔터티 중심 추출 요약을 위한 데이터 세트. 전산 언어학 협회 제60회 연례 회의 회의록(제1권: 장문 논문), 3355-3366페이지, 아일랜드 더블린. 전산 언어학 협회. Ramesh Nallapati, Bowen Zhou, Cicero dos Santos, Çağlar Gulçehre, Bing Xiang. 2016. 시퀀스-투-시퀀스 RNN 및 그 이상을 사용한 추상 텍스트 요약. 독일 베를린에서 열린 제20회 SIGNLL 계산 자연어 학습 컨퍼런스 회의록, 280-290쪽. 계산 언어학 협회. Feng Nan, Ramesh Nallapati, Zhiguo Wang, Cicero Nogueira dos Santos, Henghui Zhu, Dejiao Zhang, Kathleen McKeown, Bing Xiang. 2021. 추상 텍스트 요약의 엔터티 수준 사실적 일관성. 계산 언어학 협회 유럽 지부 제16회 컨퍼런스 회의록: 주요 권, 2727-2733쪽, 온라인. Association for Computational Linguistics. Shashi Narayan, Yao Zhao, Joshua Maynez, Gonçalo Simões, Vitaly Nikolaev, Ryan McDonald. 2021. 추상적 요약을 위한 학습된 엔티티 프롬프트를 사용한 계획. Association for Computational Linguistics의 거래, 9:1475-1492. OpenAI. 2023. abs/2303.08774. Gpt-4 기술 보고서. ArXiv, Dongqi Pu, Vera Demberg. 2023. ChatGPT 대 인간이 작성한 텍스트: 제어 가능한 텍스트 요약 및 문장 스타일 전환에 대한 통찰력. Association for Computational Linguistics의 제61회 연례 회의록(제4권: 학생 연구 워크숍), 1-18쪽, 캐나다 토론토. Association for Computational Linguistics. Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, Paul F Christiano. 2020. 인간 피드백을 통한 요약 학습. 신경 정보 처리 시스템의 발전, 33:3008-3021. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open Foundation 및 미세 조정된 채팅 모델. arXiv 사전 인쇄본 arXiv:2307.09288. Tianyi Zhang, Faisal Ladhak, Esin Durmus, Percy Liang, Kathleen McKeown, Tatsunori B Hashimoto. 2023. 뉴스 요약을 위한 대규모 언어 모델 벤치마킹. arXiv 사전 인쇄본 arXiv:2301.13848. Qingyu Zhou, Nan Yang, Furu Wei, Shaohan Huang, Ming Zhou, Tiejun Zhao. 2018. 문장을 채점하고 선택하도록 공동 학습하여 신경망 문서 요약. Association for Computational Linguistics(제1권: 장문 논문)의 제56회 연례 회의록, 654-663페이지, 호주 멜버른. Association for Computational Linguistics. GPT-4 지표 GPT-4 Likert 스타일 평가의 경우 다음 프롬프트 템플릿을 사용합니다. 기사: {{Article}} 요약: {{Summary}} {{Dimension}}과 관련하여 요약을 평가해 주세요(1=최악~5=최고). {{정의}} 아래에서 각 품질 지표에 대한 정의를 제시합니다. • 정보적: 정보적 요약은 기사의 중요한 정보를 포착하여 정확하고 간결하게 제시합니다. • 품질: 고품질 요약은 이해하기 쉽고 이해 가능합니다. • 일관성: 일관된 요약은 잘 구성되고 잘 정리되어 있습니다. • 귀속성: 요약의 모든 정보가 기사에 완전히 귀속될 수 있습니까? • 전반적인 선호도: 좋은 요약은 기사의 주요 아이디어를 간결하고 논리적이며 일관된 방식으로 전달해야 합니다. 품질 및 일관성 프롬프트에는 프롬프트에 기사가 포함되지 않습니다. 이러한 정의는 이전 요약 주석 작업에서 의역되었습니다(Fabbri et al., 2021; Aharoni et al., 2023). 차원 상관 관계 정보적 0. 품질 0. 일관성 0. 귀속 가능 0. 전체 0. 표 4: 인간의 선호도와 GPT-4 리커트 평가 간의 요약 수준 피어슨 상관 계수. 메타 평가. 요약 수준 상관 관계를 계산하기 위해, 우리는 먼저 선호도 데이터를 요약이 1위 투표를 받은 횟수를 나타내는 벡터로 바꾸었습니다. 표 4는 전반적인 요약 평가를 포착하도록 설계된 프롬프트가 전반적인 선호도에 대한 요약 수준 피어슨 상관 관계가 가장 높음을 놀랍지 않게 보여줍니다(31). 그러나 전반적인 상관 관계는 여전히 낮습니다.
