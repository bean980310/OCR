--- ABSTRACT ---
이 논문은 뷰 위치와 다른 움직이는 점 광원에 의해 조명된 물체의 구조화되지 않은 사진의 작은 세트에서 자유로운 뷰포인트 재조명을 위한 새로운 신경 암묵적 광도 표현을 제시합니다. 우리는 다층 퍼셉트론으로 모델링된 부호 거리 함수로 모양을 표현합니다. 이전의 재조명 가능한 암묵적 신경 표현과 달리, 우리는 다른 빛 전송 구성 요소를 풀지 않고 각 지점에서 로컬 및 글로벌 빛 전송을 두 번째 다층 퍼셉트론으로 모델링합니다. 이 퍼셉트론은 밀도 특징, 현재 위치, 법선(부호 거리 함수에서), 뷰 방향 및 빛 위치 외에도 네트워크가 해당 고주파 빛 전송 효과를 모델링하는 데 도움이 되는 그림자 및 하이라이트 힌트를 사용합니다. 이러한 힌트는 제안으로 제공되며, 최종 재조명 결과에 이를 통합하는 방법은 네트워크에 맡깁니다. 우리는 다양한 모양, 재료 속성 및 글로벌 조명 빛 전송을 나타내는 합성 및 실제 장면에서 신경 암묵적 표현을 시연하고 검증합니다. CCS 개념 • ⚫ 컴퓨팅 방법론 → 반사 모델링. 키워드 이미지 기반 렌더링; ReRelighting, 자유 시점, Neural Implicit Modeling *Microsoft Research Asia에서 인턴십 기간 동안 수행한 작업. ACM 참조 형식: Chong Zeng, Guojun Chen, Yue Dong, Pieter Peers, Hongzhi Wu, Xin Tong. 2023. 그림자 및 하이라이트 힌트를 사용한 신경 복사 필드 재조명. 컴퓨터 그래픽 및 대화형 기술에 대한 특수 관심 그룹 컨퍼런스 컨퍼런스 회의록(SIGGRAPH &#39;23 컨퍼런스 회의록), 2023년 8월 6-10일, 미국 캘리포니아주 로스앤젤레스. ACM, 뉴욕, 뉴욕, 미국, 12페이지. https://doi.org/10.1145/3588432.
--- INTRODUCTION ---
실제 세계 객체의 모양은 조명과 객체의 복잡한 기하학 및 관련 재료 속성 간의 복잡한 빛 전송 상호 작용의 결과입니다. 실제 세계 객체와 장면의 모양을 디지털로 재현하는 것은 컴퓨터 그래픽과 컴퓨터 비전에서 오랜 목표였습니다. 역 렌더링 방법은 복잡한 빛 전송을 취소하여 선택한 모델과 함께 렌더링 시 모양을 복제하는 희소한 모델 매개변수 집합을 결정하려고 시도합니다. 그러나 서로 얽힌 다른 구성 요소를 분리하는 것은 잘못된 자세이며 종종 모호함으로 이어집니다. 또한 한 모델의 부정확성은 다른 구성 요소를 분리할 수 있는 정확도에 부정적인 영향을 미칠 수 있으므로 강력한 정규화 및 가정이 필요합니다. 이 논문에서는 일반적인 객체와 장면의 자유 시점 재조명을 위한 새로운 NeRF에서 영감을 받은 [Mildenhall et al. 2020] 신경 암묵적 광도 표현을 제시합니다. 분석적 반사 모델과 신경 암묵적 표현의 역 렌더링을 사용하는 대신, 우리는 데이터 기반 접근 방식을 따르고 다른 광 전송 구성 요소에서 모양을 분해하지 않습니다. 따라서 신경 암묵적 표현을 재조명하는 대부분의 이전 작업[Boss et al. 2021a, 2022; Kuang et al. 2022; Zeng et al. Srinivasan et al. 2021; Zheng et al. 2021]과 달리, 우리는 임의의 점광 위치에서 각 뷰를 조명하여 개체의 핸드헬드 촬영 사진에 포함된 조명 정보를 완화하고 풍부하게 합니다. 이를 통해 핸드헬드 촬영의 편의성을 유지하면서 개체의 모양 변화 공간에 대한 더 광범위하고 비구조화된 샘플링을 제공합니다. 또한 학습하기 어려운 구성 요소의 재현 품질을 개선하기 위해 신경 광도 표현에 그림자 및 하이라이트 힌트를 제공합니다. 중요한 점은 이러한 힌트가 추정된 광도와 어떻게 결합되는지(예: 빛 가시성을 곱하여 그림자 매핑)를 강요하지 않고, 대신 신경 표현이 이러한 힌트를 최종 결과에 통합하는 방법을 결정하도록 맡긴다는 것입니다. 힌트 기반 암묵적 신경 표현은 구현하기 쉽고, 유사한 기능을 가진 이전의 재조명 방법보다 훨씬 적은 사진이 필요하고, 모델링할 수 있는 모양 및/또는 재료에 덜 유연성을 제공하는 최첨단 방법과 동일한 수의 사진이 필요합니다. NERF[Mildenhall et al. 2020]와 같은 고정 조명 암묵적 표현과 비교할 때, 재조명 가능성을 얻는 동안 5배 더 많은 사진과 2배의 렌더링 비용만 필요합니다. 우리는 다양한 까다로운 합성 및 실제 객체(예: 그림 1)에 대한 표현의 효과성을 보여주고 견고성을 검증합니다. 여기에는 광범위한 재료(예: 표면 아래 산란, 거친 반사 재료 등), 모양 복잡성의 변화(예: 얇은 특징, 잘 정의되지 않은 털 모양 등) 및 전역적 빛 전송 효과(예: 상호 반사, 복잡한 그림자 등)가 포함됩니다.
--- RELATED WORK ---
영어: 우리는 이미지 기반 재조명, 역 렌더링 및 신경 암묵적 표현 재조명 분야의 선구적이고 최근의 작업에 대한 관련 작업에 대한 논의에 중점을 둡니다. 심층적인 개요를 위해 신경 렌더링 [Tewari et al. 2022], (재)조명 [Einabadi et al. 2021] 및 모양 모델링 [Dong 2019]에 대한 최근 조사를 참조합니다. 이미지 기반 재조명. 지난 10년 동안 머신 러닝의 놀라운 발전은 이미지 기반 재조명 [Debevec et al. 2000]에도 큰 영향을 미쳐 새로운 기능을 제공하고 품질을 개선했습니다 [Bemana et al. 2020; Ren et al. 2015; Xu et al. 2018]. 딥 러닝은 이후 초상화에 대한 보다 전문화된 재조명 작업에 적용되었습니다 [Bi et al. 2021; Meka et al. 2019; Pandey et al. 2021; Sun et al. 2019, 2020], 전신 [Guo et al. 2019; Kanamori and Endo 2018; Meka et al. 2020; Yeh et al. 2022; Zhang et al. 2021a], 야외 장면 [Griffiths et al. 2022; Meshry et al. 2019; Philip et al. 2019]. 이러한
--- METHOD ---
ologies → flectance modeling. 키워드 이미지 기반 렌더링; ReRelighting, Free-viewpoint, Neural Implicit Modeling *Microsoft Research Asia에서 인턴십을 하는 동안 수행한 작업. ACM 참조 형식: Chong Zeng, Guojun Chen, Yue Dong, Pieter Peers, Hongzhi Wu, Xin Tong. 2023. Relighting Neural Radiance Fields with Shadow and Highlight Hints. Special Interest Group on Computer Graphics and Interactive Techniques Conference Conference Proceedings(SIGGRAPH &#39;23 Conference Proceedings), 2023년 8월 6-10일, 미국 캘리포니아주 로스앤젤레스. ACM, 뉴욕, 뉴욕, 미국, 12페이지. https://doi.org/10.1145/3588432. 서론 실제 세계 객체의 모습은 조명과 객체의 복잡한 기하학 및 관련 재료 속성 간의 복잡한 빛 전달 상호 작용의 결과입니다. 실제 세계 객체와 장면의 모양을 디지털 방식으로 재현하는 것은 컴퓨터 그래픽과 컴퓨터 비전에서 오랜 목표였습니다. 역 렌더링 방법은 복잡한 빛 전송을 취소하여 선택한 모델과 함께 렌더링 시 모양을 복제하는 희소한 모델 매개변수 집합을 결정하려고 시도합니다. 그러나 서로 얽힌 다른 구성 요소를 분리하는 것은 잘못된 자세이며 종종 모호함으로 이어집니다. 더욱이 한 모델의 부정확성은 다른 구성 요소를 분리할 수 있는 정확도에 부정적인 영향을 미칠 수 있으므로 강력한 정규화와 가정이 필요합니다. 이 논문에서는 일반적인 객체와 장면의 자유 시점 재조명을 위한 새로운 NeRF에서 영감을 받은 [Mildenhall et al. 2020] 신경 암묵적 광도 표현을 제시합니다. 신경 암묵적 표현의 분석적 반사 모델과 역 렌더링을 사용하는 대신 데이터 기반 접근 방식을 따르고 다른 빛 전송 구성 요소의 모양을 분해하지 않습니다. 따라서 신경 암묵적 표현을 재조명하는 이전 작업의 대부분과 달리 [Boss et al. 2021a, 2022; Kuang 등. 2022; Zeng 등. Srinivasan 등. 2021; Zheng 등. 2021], 우리는 임의의 점광 위치에서 각 뷰를 조명하여 손으로 촬영한 물체 사진에 포함된 조명 정보를 완화하고 풍부하게 합니다. 이를 통해 물체의 외관 변화 공간에 대한 더 광범위한 비구조적 샘플링을 제공하는 동시에 핸드헬드 촬영의 편의성을 유지합니다. 또한 학습하기 어려운 구성 요소의 재현 품질을 개선하기 위해 신경 광도 표현에 그림자 및 하이라이트 힌트를 제공합니다. 중요한 점은 이러한 힌트가 추정된 광도와 결합되는 방식(예: 빛 가시성과 곱하여 그림자 매핑)을 강요하지 않고 대신 신경 표현이 최종 결과에 이러한 힌트를 통합하는 방법을 결정하도록 맡긴다는 것입니다. 힌트 기반 암묵적 신경 표현은 구현하기 쉽고, 유사한 기능을 가진 이전의 재조명 방법보다 훨씬 적은 사진이 필요하며, 모델링할 수 있는 모양 및/또는 재료에 덜 유연성을 제공하는 최신 방법과 동일한 수의 사진이 필요합니다. NERF[Mildenhall et al. 2020]와 같은 고정 조명 암묵적 표현과 비교했을 때, 재조명 가능성을 얻는 동안 5배 더 많은 사진과 2배의 렌더링 비용만 필요합니다. 우리는 다양한 까다로운 합성 및 실제 객체(예: 그림 1)에 대한 표현의 효과성을 보여주고 견고성을 검증합니다.여기에는 광범위한 재료(예: 표면 아래 산란, 거친 반사 재료 등), 모양 복잡성의 변화(예: 얇은 특징, 잘 정의되지 않은 털 모양 등) 및 전역적 빛 전송 효과(예: 상호 반사, 복잡한 그림자 등)가 포함됩니다.관련 작업 우리는 이미지 기반 재조명, 역 렌더링 및 신경 암시적 표현 재조명 분야의 선구적이고 최근의 작업에 관련 작업에 대한 논의에 중점을 둡니다.심층적인 개요는 신경 렌더링[Tewari et al. 2022], (재)조명[Einabadi et al. 2021] 및 모양 모델링[Dong 2019]에 대한 최근 설문 조사를 참조하십시오.이미지 기반 재조명.지난 10년 동안 머신 러닝의 놀라운 발전은 이미지 기반 재조명[Debevec et al. 2000], 새로운 기능을 활성화하고 품질을 개선합니다[Bemana et al. 2020; Ren et al. 2015; Xu et al. 2018]. 이후 딥 러닝은 초상화[Bi et al. 2021; Meka et al. 2019; Pandey et al. 2021; Sun et al. 2019, 2020], 전신[Guo et al. 2019; Kanamori and Endo 2018; Meka et al. 2020; Yeh et al. 2022; Zhang et al. 2021a], 야외 장면[Griffiths et al. 2022; Meshry et al. 2019; Philip et al. 2019]에 대한 보다 전문화된 재조명 작업에 적용되었습니다. 이러한 방법을 확장하여 잘 정의되지 않은 모양(예: 털)과 반투명 및 반사 재료를 가진 개체가 포함된 장면을 처리하는 방법은 불분명합니다.또한, 저희의 방법은 이러한 어려운 효과를 모델링하는 데 도움이 되는 하이라이트 및 그림자 힌트를 활용하는 자유 시점 재조명 방법으로 볼 수도 있습니다.Philip et al. [2019]는 단순화된 태양+구름 조명 모델에서 주로 확산된 실외 장면을 재조명하기 위해 딥 셰이딩 방식[Nalbach et al. 2017]을 따릅니다.재조명된 이미지는 프록시 지오메트리에서 계산된 입력 및 출력 그림자 맵이 정제되고, 이후 추가 렌더 버퍼와 함께 재조명 네트워크의 입력으로 사용되는 2단계 프로세스로 생성됩니다.Zhang et al. [2021a]는 거친 지오메트리에서 확산 매개변수 모델(즉, 광도 힌트)을 활용하는 잔여 학습이 있는 반 매개변수 모델과 텍스처 공간에 포함된 비확산 및 전역 광 전송을 모델링하는 학습된 표현을 도입합니다.비확산 효과를 정확하게 모델링하기 위해 Zhang et al. 영어: 조명 스테이지로 촬영한 많은 수(~8,000개)의 구조화된 사진이 필요합니다. 지연된 신경 재조명[Gao et al. 2020]은 기능 면에서 우리 방법에 가장 가깝습니다. 전체 전역 조명 효과와 복잡한 빛-물질 상호 작용(지하 산란 및 털 포함)을 사용하여 잘 정의되지 않은 모양의 객체에 자유 시점 재조명을 수행할 수 있습니다. Zhang et al.[2021a]과 유사하게 Gao et al.은 거친 지오메트리의 텍스처 공간에 학습된 피처를 임베드하여 대상 뷰에 투사하고 광도 큐와 곱합니다. 이러한 광도 큐는 전역 조명이 있는 대상 조명 아래에서 다른 BRDF(예: 4가지 다른 거칠기를 가진 확산 및 광택 BRDF)를 사용하여 거친 지오메트리를 시각화한 것입니다. 그런 다음 결과 이미지를 대상 장면의 많은 수(~10,000개)의 비구조화된 사진에서 신경 렌더러가 훈련한 장면에 대한 안내 힌트로 사용하여 참조 모양을 재생성하기 위한 무작위 포인트 조명-시점 조합을 사용합니다. Philip et al. [2021]도 신경 렌더러를 안내하기 위해 광도 힌트(확산 및 거울 광도로 제한됨)를 사용합니다. 그러나 Zhang et al. 및 Gao et al.과 달리 장면별 미세 조정이 필요 없고 입력 및 출력 조건 모두에 대한 광도 신호를 사용하는 신경 렌더러를 사전 학습합니다. Philip et al.은 단일 고정 자연 조명 조건으로 조명되고 단단한 표면과 BRDF와 같은 재료가 있는 장면으로 제한되지만 우리 방법과 거의 같은 수의 입력 이미지가 필요합니다. 네 가지 방법 모두 복잡한 장면에서는 실패할 수 있는 다중 뷰 스테레오에 의존합니다. 이와 대조적으로 우리 방법은 강력한 신경 암시적 표현을 사용합니다. 또한 네 가지 방법 모두 최종 재조명 이미지를 생성하기 위해 이미지 공간 신경 렌더러에 의존합니다. 이와 대조적으로 우리 방법은 신경 암시적 표현의 볼륨 렌더링 중에 힌트를 제공하므로 뷰 종속 이미지 컨텍스트와 무관합니다. 우리 방법은 Philip et al.과 유사한 수의 입력 사진만 사용하면서 Gao et al. [2020]과 동일한 복잡성으로 장면을 재조명할 수 있습니다. [2021] 견고성을 희생하지 않고도.모델 기반 역 렌더링.데이터 기반 재조명의 대안은 역 렌더링(일명 합성에 의한 분석)으로, 일련의 시험 모델 매개변수가 렌더링된 모델 매개변수와 참조 사진의 차이에 따라 최적화됩니다.역 렌더링은 핵심적으로 복잡한 비선형 최적화 문제입니다.미분 가능한 렌더링의 최근 발전[Li et al. 2018; Loper and Black 2014; Nimier-David et al. 2019; Xing et al. 2022]으로 인해 더 복잡한 장면과 캡처 조건에 대해 더욱 견고한 역 렌더링이 가능해졌습니다.BID-R++[Chen et al. 2021]는 미분 가능한 광선 추적과 래스터화를 결합하여 알려진 삼각형 메시에 대한 공간적으로 변하는 반사 매개변수와 구면 가우시안 조명을 모델링합니다.Munkberg et al. [2022] 암묵적 모양 표현(즉, 부호 있는 거리 필드)을 최적화하고 삼각형 메시에 정의된 반사율과 조명을 번갈아 사용합니다.Hasselgren et al. [2022]는 Munkberg et al. [2022]의 작업을 미분 가능한 몬테카를로 렌더러로 확장하여 면 광원을 처리하고, 비선형 최적화기를 구동하기 위해 기울기 계산에 대한 몬테카를로 노이즈의 부작용을 완화하기 위해 노이즈 제거기를 내장했습니다.마찬가지로, Fujun et al. [2021]도 미분 가능한 Relighting Neural Radiance Fields with Shadow and Highlight Hints Monte Carlo 렌더러를 사용하여 동일한 위치에 배치된 뷰/조명 사진의 작은 세트에서 모양과 공간적으로 변하는 반사율을 추정합니다.이러한 모든 방법은 직접 조명에만 초점을 맞추고 강한 상호 반사가 있는 객체나 장면에 대해 최적이 아닌 결과를 생성할 수 있습니다.주목할 만한 예외는 Cai et al. [2022]는 명시적 및 암묵적 기하 구조를 결합하고 간접 조명을 고려하면서 다양한 불투명 객체에 대해 알려진 조명 하에서 역 렌더링을 보여줍니다.위의 모든 방법은 결국 모양을 삼각형 메시로 표현하여 잘 정의된 표면이 있는 객체에 대한 적용성이 제한됩니다.또한 이러한 방법의 정확도는 기본 BRDF 및 조명 모델의 표현력에 의해 본질적으로 제한됩니다.신경 암묵적 표현.삼각형 메시를 사용한 역 렌더링의 주요 과제는 최적화 중에 토폴로지의 변화를 효율적으로 처리하는 것입니다.삼각형 메시 표현에 대한 대안은 각 복셀에 불투명도/밀도 추정치와 반사율 속성에 대한 설명이 포함된 체적 표현을 사용하는 것입니다.토폴로지 변경과 무관하지만 복셀 그리드는 메모리 집약적이며 그리드 워핑[Bi et al. 2020]이 있더라도 미세한 기하학적 세부 사항을 모델링하기 어렵습니다.복셀 그리드의 고유한 메모리 오버헤드를 피하기 위해 NeRF[Mildenhall et al. 2020]은 위치(및 색상의 뷰 방향)로 매개변수화된 두 개의 다층 퍼셉트론(MLP)을 사용하여 연속적인 체적 밀도와 공간적으로 변하는 색상을 모델링합니다. NeRF의 MLP는 장면별로 학습되어 누적된 밀도와 뷰 광선을 따라 이동하는 색상 광선이 참조 사진에서 관찰된 광도와 일치합니다. NeRF는 잘 정의되지 않은 모양과 복잡한 재료를 포함한 광범위한 개체 유형의 나가는 광도장을 모델링하는 데 매우 효과적인 것으로 나타났습니다. NeRF의 주요 한계 중 하나는 캡처 시 존재하는 조명이 모델에 내장되어 있다는 것입니다. 제한된 조명 모델에서 캡처 후 재조명을 지원하거나 [Li et al. 2022; MartinBrualla et al. 2021] 색상 MLP를 변경하여 개체 모양의 분석 모델을 구동하는 매개변수를 생성하는 여러 방법이 도입되었습니다 [Boss et al. 2021a, 2022, 2021b; Kuang et al. 2022; Srinivasan 등 2021; Yao 등 2022; Zhang 등 2021c], 참여 매체 [Zheng 등 2021] 또는 전체 야외 장면 [Rudnev 등 2022]. 광선 행진 2차 광선의 높은 계산 비용으로 인해 그림자와 간접 조명을 순진하게 계산하는 것은 비실용적입니다. Zhang 등 [2021c], Li 등 [2022], Yang 등 [2022]은 빛 차단 비율을 모델링하기 위해 추가 MLP를 학습하여 그림자 광선 추적을 피합니다. 그러나 세 가지 방법 모두 간접 조명을 무시합니다. Zheng 등 [2021]은 5대역 확장의 계수를 반환하는 MLP를 사용하여 참여 매체 내부의 간접 조명을 모델링합니다. NeILF [Yao 등 2022]는 알려진 지오메트리가 있는 장면에 대해 (학습된) 5D 입사광 필드에 간접 조명과 그림자를 포함합니다.NeRV[Srinivasan et al. 2021]는 색상 MLP를 수정하여 BRDF 매개변수와 가장 가까운 &#39;경질 표면&#39;과 조명 가시성까지의 거리를 모델링하는 가시성 필드를 출력합니다.가시성 필드를 통해 그림자 계산과 1회 반사 간접 조명을 위한 값비싼 레이 마칭 단계를 우회할 수 있습니다.이러한 솔루션의 단점은 추정된 밀도 필드와 폐색이 결합되어 있다는 것을 보장하지 않는다는 것입니다.반대로, 우리의 방법은 폐색을 추정된 암묵적 지오메트리에 직접 연결하여 보다 충실한 그림자를 재현합니다.또한 이러한 방법은 BRDF에 의존하여 표면 반사율을 모델링하므로 복잡한 빛-물질 상호 작용이 있는 장면은 배제됩니다.NeRV[Srinivasan et al. 2021]는 인간의 얼굴을 다시 비추는 것을 목표로 하므로 표면 아래 산란을 정확하게 재현하는 것이 중요합니다.따라서 Sun et al. MLP를 통한 광도와 전역 광 전송을 특성화합니다. 또한 MLP를 활용하여 로컬 및 전역 광 전송을 모델링합니다. 주요 차이점은 저희 방법이 이 MLP를 뷰 및 광 방향 측면에서 매개변수화하는 반면 NeLF는 전체 광 전송 벡터를 직접 출력하고 조명과의 내적을 통해 재조명 색상을 계산한다는 것입니다. NeLF는 자연 조명으로 재조명하는 데 더 적합하지만 모양과 반사율에 제한적인 변화만 보이는 인간의 얼굴을 재조명하도록 설계되었습니다. 저희 방법과 유사한 정신으로 Lyu et al. [2022]은 신경 광도 전달 필드(NRTF)라는 MLP를 사용하여 광 전송을 모델링합니다. 그러나 저희와 달리 Lyu et al.은 정적 자연 조명 하에서 장면에 대한 비정형적 관찰에서 계산된 신경 부호 거리 필드 [Wang et al. 2021]에서 추출한 삼각형 메시에 대한 물리 기반 역 렌더링을 통해 얻은 대략적인 BRDF 근사치에서 생성된 합성 학습 데이터에서 MLP를 학습합니다. 대략적인 BRDF 근사로 인한 오류를 수정하기 위해 촬영한 사진을 사용하여 MLP의 최종 정제 단계를 수행합니다. Lyu 등과 유사하게 간접 조명을 포함한 빛 전송을 모델링하기 위해 MLP도 사용합니다. 그러나 Lyu 등과 달리 빛 폐색 및 반사 하이라이트와 같은 고주파 빛 전송 효과를 모델링하기 위해 MLP에만 의존하지 않습니다. 대신 광도 네트워크에 그림자 및 하이라이트 힌트를 제공하고 학습 프로세스에서 이러한 힌트를 가장 잘 활용하는 방법을 발견하게 합니다. 또한 광도와 함께 최적화된 모양에 대한 신경 표현을 사용하여 잘 정의되지 않은 지오메트리가 있는 장면을 캡처할 수 있습니다. 반면 Lyu 등은 모양(삼각형 메시로 변환)과 광도를 별도로 최적화하여 모양 오류에 민감하고 잘 정의된 모양의 개체로 제한하는 방법을 만들었습니다. 암묵적 신경 밀도 필드를 사용하는 것의 대안은 부호 거리 필드(SDF)를 통해 모양을 모델링하는 것입니다. 대부분의 NeRF 기반 방법과 마찬가지로 PhySG[Zhang et al. 2021b] 및 IRON [Zhang et al. 2022a]도 체적 BRDF 매개변수를 나타내기 위해 MLP에 의존합니다.그러나 높은 계산 비용으로 인해 이러한 방법은 그림자나 간접 조명을 고려하지 않습니다.Zhang et al. [2022b]는 간접 조명을 별도로 모델링하고 SDF 지오메트리를 레이 캐스팅하여 각 지점에서 계산된 입사 조명을 사용하여 추가 입사광 필드 MLP를 학습합니다.우리의 방법도 신경 암시적 표현 [Wang et al. 2021]을 기반으로 하지만 기본 매개변수 BRDF 모델에 의존하지 않고 대신 MLP를 통해 전체 빛 전송을 모델링합니다.또한 추정된 지오메트리에서 분리된 MLP에 의존하여 그림자를 추정하지 않고 대신 뷰 레이당 단일 그림자 레이를 따라 빛 폐색을 축적하여 그림자와 추정된 지오메트리 간의 일관성을 보장합니다.방법 우리의 목표는 NeRF [Mildenhall et al. 2020] 조명 변화를 모델링합니다. NeRF는 시점 보간에 매우 효율적인 것으로 입증되었습니다. 고체 표면을 사용한 광선 추적과 달리 NeRF는 광선 Ο 캡처 프로세스 캡처된 이미지 뷰 방향 조명 위치 일반 그림자 힌트 하이라이트 힌트 재조명 가능 광도 네트워크 밀도 네트워크 Zeng et al. 밀도 매핑 주파수 인코딩 입력 데이터 출력 중간 데이터 학습 가능 네트워크 그림 2: 개요: 신경 암묵적 광도 표현은 다른 시점에서 캡처하고 다른 점광 위치에서 조명을 받은 장면의 비정형 사진에서 학습됩니다. 신경 암묵적 광도 표현은 밀도 필드를 모델링하고 빛 전송을 모델링하기 위한 두 개의 다층 퍼셉트론(MLP) 네트워크로 구성됩니다. 밀도를 모델링하기 위한 MLP는 위치를 입력으로 받고 모양의 부호 거리 함수와 현재 위치, SDF에서 추출한 법선, 뷰 방향, 광원 위치 및 조명 전송 힌트와 함께 광도 MLP로 전달되는 특징 벡터를 출력합니다.그러면 광도 MLP에서 뷰 및 조명에 따라 달라지는 광도를 계산합니다.볼륨을 통과하는 행진으로 적어도 한 자릿수 이상의 계산이 필요합니다.이 광선 행진 비용은 렌더링에 영향을 미칠 뿐만 아니라 보조 광선(예: 그림자 및 간접 조명)을 고려할 때 엄청나게 큰 학습 비용으로 이어집니다.NeRF에서 방법을 빌드하는 대신 신경 암묵적 부호 거리 필드 표현인 NeuS[Wang et al. 2021]를 방법의 기반으로 사용하기로 했습니다.Neus는 광선 행진을 가속화하지 않지만 편향되지 않은 깊이 추정치를 제공하며 하위 섹션 3.2에서 이를 활용하여 그림자 광선의 수를 줄입니다. 이전 작업에 따라, 우리의 신경 암시적 광도 표현은 밀도 필드(NeuS에 따름)를 모델링하고 현재 위치, 밀도 필드에서 파생된 법선, 시야 방향, 점광 위치 및 밀도 네트워크에서 제공하는 특징을 기반으로 하는 (직접 및 간접) 광도를 모델링하기 위해 두 개의 다층 퍼셉트론(MLP)에 의존합니다. 또한 그림자 및 하이라이트와 같이 모델링하기 어려운 효과의 재현 품질을 개선하기 위해 재조명 가능 광도 MLP에 빛 전달 힌트를 제공합니다. 그림 2는 아키텍처를 요약한 것입니다. 신경 암시적 재조명 가능 광도 표현을 학습하려면 다른 관점에서 보고 다른 점광 위치에서 조명된 대상 장면에 대한 관찰이 필요합니다. 이러한 관찰에는 폐색 및 상호 반사가 포함되는 것이 필수적입니다. 동일 위치에 있는 조명(예: [Luan et al. 2021; Nam et al. 2018])은 눈에 보이는 그림자를 나타내지 않으므로 적합하지 않습니다. 대신 우리는 지연된 신경 조명[Gao et al. 2020]의 획득 프로세스를 따르고 다른 방향에서 두 번째 카메라의 플래시 라이트로 장면을 비추는 동안 핸드헬드 카메라로 다른 관점에서 장면을 캡처합니다. 우리는 물리적 캡처 프로세스를 더 잘 반영하기 때문에 재조명의 기준으로 점광원에 대한 광도 함수를 매개변수화하기로 선택합니다. 활성 조명(예: 조명 단계)에 의존하는 이전 재조명 작업에서 일반적인 근사값은 유한한 광원 거리로 인한 입사 조명의 발산을 무시하고 조명 방향에 따라서만 반사 필드를 매개변수화하는 것입니다. 마찬가지로, 캡처 거리와 같은 반지름을 가진 큰 구에 조명 방향을 투사하여 정의된 점 조명으로 먼 조명을 근사할 수도 있습니다. 3.1 표현 밀도 네트워크. 우리의 신경 암시적 기하 표현은 NeuS[Wang et al. 2021]은 MLP를 사용하여 부호 거리 함수(SDF) f(p)를 인코딩하고, 여기서 밀도 함수는 확률 밀도 함수 os(f(p))를 사용하여 도출됩니다. 이 확률 밀도 함수는 불투명한 객체의 경우 SDF의 제로 레벨 집합이 표면에 해당하도록 설계되었습니다. 확률 분포의 폭은 표면 위치의 불확실성을 모델링합니다. 우리는 NeuS와 동일한 밀도 MLP 아키텍처를 따릅니다. Softplus 활성화를 사용하는 256개 노드가 있는 8개 은닉 계층과 입력과 4번째 계층 사이의 건너뛰기 연결입니다. 입력(즉, 광선을 따라 현재 위치)은 6개 대역의 주파수 인코딩을 사용하여 증강됩니다. 또한 원래 입력 신호를 인코딩에 연결합니다. 밀도 네트워크의 결과 출력은 p의 SDF와 위치 종속 피처를 인코딩하는 잠재 벡터입니다. Relightable Radiance Network. NERF와 NeuS의 각 체적 위치에서 뷰에 따라 달라지는 색상을 평가하는 색상 MLP와 유사하게, 각 체적 위치에서 뷰와 조명에 따라 달라지는(직접 및 간접) 빛 전송을 평가하는 재조명 가능 광도 MLP를 도입합니다. NeRF/NeuS의 색상 MLP와 유사한 아키텍처를 따르고 밀도 MLP에서 생성된 위치 종속적 특징 벡터, SDF에서 파생된 법선, 현재 위치, 뷰 방향 및 점 조명 위치를 입력으로 사용하여 확장합니다. 이 입력이 주어지면 광도 MLP는 폐색 및 상호 반사와 같은 모든 빛 전송 효과를 포함하는 결과 광도를 출력합니다. 흰색 광원 색상을 가정합니다. 광원 색상(즉, 빛 전송의 선형성)으로 광도를 조정하여 색상 조명을 얻을 수 있습니다. 밀도 네트워크 f의 출력과 광도 네트워크의 출력이 주어졌을 때, 카메라 위치 o에서 시작하여 방향 v로 뷰 레이를 따라가는 색상 C는 다음과 같습니다.C(o, v) = √ w(t)s(p, n, v, 1, ƒ, ☺) dt, (1) 여기서 뷰 레이를 따라가는 샘플 위치는 깊이 t에서 p = 0 + tv이고, n은 정규화된 SDF 그래디언트로 계산된 법선입니다.n = Vƒ (p)/||Vƒ (p)||, 그림자와 하이라이트 힌트로 신경 광도 필드 재조명 v는 뷰 방향, 1은 점 광원 위치, ƒ는 밀도 MLP의 해당 특징 벡터이며, 광도 네트워크에 제공된 추가 힌트 세트입니다(3.2절에서 설명).NeuS와 유사하게 뷰 방향, 광원 위치 및 힌트는 모두 4개 대역으로 주파수 인코딩됩니다. 마지막으로 w(t)는 다음과 같이 계산된 비편향 밀도 가중치[Wang et al. 2021]입니다.(3) w(t) = T(t)p(t), T(t) = exp (- &#39; p(u) du).(4) p(t) = max ..).(5) 하이라이트 힌트. 그림자와 유사하게 반사 하이라이트는 희소하게 분포된 고주파 광 전송 효과입니다.Gao et al.[2020]에서 영감을 받아 거칠기 매개변수가 {0.02, 0.05, 0.13, 0.34}인 GGX 분포[Walter et al. 2007]를 갖는 4개의 마이크로패싯 BRDF를 평가하여 광도 네트워크에 반사 하이라이트 힌트를 제공합니다.Gao et al.과 달리 SDF(식 2)에서 계산된 표면 법선에만 의존하는 로컬 셰이딩을 사용하여 하이라이트 힌트를 계산하고 추가 입력으로 광도 MLP에 전달합니다. 그림자 힌트와 유사하게, 우리는 뷰 레이 당 하나의 하이라이트 힌트를 계산하고 뷰 레이를 따라 모든 샘플에 재사용했습니다. do&#39;s (f(t)) dt Þs (f(t))&#39; 여기서 T는 불투명도 p에 대한 투과율, s는 SDF f에서 밀도를 계산하는 데 사용된 PDF Os의 CDF입니다. 색상 계산 속도를 높이기 위해 방정식 1의 적분은 뷰 레이를 따라 밀도 필드를 중요도 샘플링하여 계산합니다. 이미지 기반 재조명의 정신에 따라, 우리는 재조명 가능 광도 MLP 네트워크에 상호 반사 및 폐색과 같은 전역 광 전송 효과를 포함하도록 선택했습니다. MLP는 이론적으로 보편적 근사자이지만, 일부 광 전송 구성 요소는 다른 구성 요소보다 배우기가 더 쉽습니다(예: 확산 반사). 특히 그림자 및 반사 하이라이트와 같은 고주파 광 전송 구성 요소는 문제를 일으킵니다. 동시에 그림자와 반사 하이라이트는 장면의 기하학 및 밀도 필드와 높은 상관 관계가 있습니다. 이러한 내장된 지식을 활용하기 위해 재조명 광도 MLP에 추가 그림자 및 하이라이트 힌트를 제공합니다. 3.2 광 전송 힌트 그림자 힌트. 재조명 광도 네트워크는 광원 폐색의 효과를 대략적으로 모델링할 수 있지만, 결과적으로 생성되는 그림자는 일반적으로 선명도와 세부 정보가 부족합니다. 그러나 광원 폐색은 광원을 향해 그림자 광선을 따라 밀도를 수집하여 비교적 쉽게 평가할 수 있습니다. 이 프로세스는 단일 그림자 광선에 대해 비교적 저렴하지만 각 기본 광선의 샘플링된 위치에 대해 보조 광선 행진을 수행하면 계산 비용이 수십 배 증가하여 실제 훈련에는 비용이 너무 많이 듭니다. 그러나 대부분의 기본 광선의 경우 광선 샘플이 시야 광선을 따라 밀도의 중요도 샘플링으로 인해 SDF의 제로 레벨 세트 주변에 밀접하게 패킹되어 있음을 관찰합니다. 따라서 제로 레벨 세트에서 단일 그림자 광선을 쏘아 광원 가시성을 근사화하고 시야 광선을 따라 각 샘플에 대해 동일한 광원 가시성을 사용하는 것을 제안합니다. 0 레벨 집합의 깊이를 결정하기 위해 뷰 레이를 따라 밀도 가중 깊이를 계산합니다.D(o, v) = √ w(p)t dt. Ο (6) 불투명한 표면의 경우 단일 그림자 레이로 충분하지만 불투명하지 않거나 잘 정의되지 않은 표면의 경우 단일 그림자 레이는 빛 폐색에 대한 추정치가 낮습니다.또한 그림자 정보를 하드 마스크로 사용하면 간접 조명의 효과가 무시됩니다.따라서 그림자 정보를 광도 네트워크에 추가 입력으로 제공하여 네트워크가 그림자 정보를 포함할지 무시할지 학습하고 그림자 영역의 간접 조명을 혼합할 수 있도록 합니다.3.3 손실 및 학습 이미지 재구성 손실 Lc와 SDF 정규화 손실 Le를 사용하여 밀도 및 광도 네트워크를 공동으로 학습합니다. 이미지 재구성 손실은 관찰 C(o, v)와 해당 추정 색상 C(o, v) 사이의 L₁ 거리로 정의되며, 이는 방정식 1을 사용하여 계산됩니다. Lc = ||C - C||1, 캡처된 학습 이미지의 픽셀(따라서 시야 광선)을 무작위로 샘플링한 경우(3.4절). 또한 NeuS를 따르고 Eikonal 손실[Gropp et al. 2020]로 밀도 MLP를 정규화하여 유효한 SDF를 보장합니다. Le (||Vƒ(p)||2-1)². 계산 효율성을 위해 그림자와 하이라이트 힌트에서 그래디언트를 역전파하지 않습니다. = 3.4 데이터 수집 암묵적 표현을 학습하려면 그림자와 상호 반사가 포함되도록 무작위 관점에서 보고 다른 무작위 조명 위치에서 조명을 받은 장면에 대한 관찰이 필요합니다. Gao et al.의 절차를 따릅니다. [2020]: 핸드헬드 카메라를 사용하여 무작위 관점에서 장면의 사진을 촬영하는 반면, 두 번째 카메라는 동일한 위치에 있는 플래시 조명을 사용하여 장면을 촬영합니다. 두 번째 카메라의 이미지는 광원 위치를 보정하는 데만 사용됩니다. 카메라 보정을 돕기 위해 장면을 체커보드 패턴에 배치합니다. 이 논문의 모든 예는 기본 카메라로 Sony A7II, 보조 카메라로 iPhone 13 Pro를 사용하여 촬영했습니다. 수집 프로세스는 약 10분이 걸립니다. 수집의 주요 병목 현상은 카메라를 장면 주변으로 이동하는 것입니다. 실제로 각 카메라에서 비디오 시퀀스를 캡처하고 무작위로 500-1,000개의 프레임을 훈련 데이터로 선택합니다. 비디오는 과다 노출을 최소화하기 위해 S-log 인코딩을 사용하여 캡처합니다. 합성 장면의 경우 장면 주변의 상반구에서 뷰와 조명 위치를 무작위로 샘플링하여 수집 프로세스를 시뮬레이션하며, 장면 크기의 2~2배 사이의 무작위 거리를 지정합니다. 합성 장면은 Blender Cycles를 사용하여 전역 조명 전송으로 렌더링합니다. 3.5 시점 최적화 카메라 보정의 불완전성은 얇은 기하학적 특징의 부정확한 재구성을 초래할 수 있으며 흐릿한 결과로 이어질 수 있습니다.카메라 보정 오류의 영향을 완화하기 위해 시점과 신경 표현을 함께 최적화합니다.Zeng et al.금속성: 27.79 |0.9613 |0.광택 금속: 30.08 |0.9722 |0.이방성 금속: 29.07 |0.9676 |0.확산성 37.10 |0.9942 |0.플라스틱: 34.94 |0.9885 |0.반투명성: 36.22 |0.9911 |0.모피 공: 32.18 |0.9619 |0.겹으로 짠 공 |33.52 | 0.9853 | 0.BASKET: 26.84 | 0.9586 | 0.HOTDOG: 34.18 | 0.9851 | 0.LEGO: 29.93 | 0.9719 | 0.DRUMS: 27.92 | 0.9556 | 0.그림 3: 새로운 시점과 조명 방향(훈련 데이터의 일부가 아님)에 대해 다시 조명한 합성 장면(오른쪽)과 렌더링된 참조 이미지(왼쪽) 간의 정성적 비교. 각 예제에 대해 균일한 뷰 및 조명 위치 샘플링을 통해 계산된 평균 PSNR, SSIM 및 LPIPS를 나열합니다. 초기 뷰 방향 Ro와 뷰 위치 to가 주어지면, 정제된 카메라 방향 R과 위치 t를 다음과 같이 공식화합니다. R = AR. Ro, t = At + AR to, (7) 여기서 AR E SO(3) 및 At = R³는 학습 가능한 보정 변환입니다. 학습하는 동안 재조명 광도 네트워크 외에도 재구성 손실을 보정 변환으로 역전파합니다.초기 카메라 보정의 오류가 작다고 가정하고 보정 변환에 0.06배 더 작은 학습 속도를 사용하여 시점 변경을 제한합니다.결과 PyTorch에서 신경 암시적 광도 표현을 구현했습니다[Paszke et al. 2019].각 모델을 Adam 옵티마이저[Kingma and Ba 2015]를 사용하여 1,000k 반복으로 학습하고 ẞ₁ = 0.9 및 ẞ2 = 0.999로 학습 이미지에서 반복당 512개 샘플을 무작위로 추출했습니다.NeuS와 동일한 워밍업 및 코사인 감소 학습 속도 일정을 따릅니다[Wang et al. 2021].단일 신경 암시적 광도 표현을 학습하는 데는 4개의 Nvidia V100 GPU에서 약 20시간이 걸립니다. 우리는 17개의 합성 장면과 7개의 캡처된 장면([Gao et al. 2020]에서 가져온 4개 포함)에서 신경 암묵적 광도 표현의 재조명 기능을 광범위하게 검증했으며, 이는 다양한 모양, 재료 및 조명 효과를 포함합니다.합성 장면.그림 3은 다양한 합성 장면의 재조명 결과를 보여줍니다.각 예에서 500개의 훈련 이미지와 다른 100개의 테스트 이미지에 대해 계산된 PSNR, SSIM 및 LPIPS [Zhang et al. 2018] 오류 통계를 나열합니다.주요 테스트 장면에는 꽃병과 주사위 두 개가 포함되어 있습니다.이 장면은 매우 오목한 물체(꽃병)와 주사위 사이의 복잡한 상호 반사가 특징입니다.다양한 재료 속성을 가진 주요 테스트 장면의 여러 버전을 포함합니다.DIFFUSE, METALLIC, GLOSSY-METAL, ROUGH-METAL, ANISOTROPIC-METAL, PLASTIC, GLOSSY-PLASTIC, ROUGH-PLASTIC 및 TRANSLUCENT; 참고로, 일부 버전은 보충 자료에만 포함되어 있습니다. 또한, 잘 정의되지 않은 지오메트리가 있는 모양에 대한 방법의 성능을 검증하기 위해 수정된 지오메트리가 있는 두 가지 버전인 SHORT-FUR과 LONG-FUR도 포함합니다. 또한, 더 긴 털이 보이는 FUR-BALL 장면도 포함합니다. 그림자 힌트의 성능을 검증하기 위해 복잡한 그림자가 있는 장면도 포함합니다. 얇은 기하학적 특징이 포함된 BASKET 장면과 복잡한 가시성과 강한 상호 반사를 결합한 LAYERED WOVEN BALL입니다. 방법의 기능을 체계적으로 조사하기 위해 특별히 설계된 이러한 장면 외에도, 신경 암묵적 모델링에서 일반적으로 사용되는 합성 장면인 HOTDOG, LEGO 및 DRUMS에 대한 신경 암묵적 광도 표현도 검증합니다[Mildenhall et al. 2020]. 오류 통계를 기반으로 오류가 장면의 기하학적 복잡성(꽃병과 주사위, HOTDOG, LAYERED WOVEN BALL은 모피 장면 및 LEGO와 DRUMS 장면과 같은 세부 사항이 작은 장면보다 성능이 우수함)과 상관 관계가 있음을 알 수 있습니다.그림자 및 하이라이트 힌트를 사용하여 신경 광도장 재조명 PIKACHU STATUE PSNR: 35.SSIM: 0.LPIPS: 0.CAT ON DECOR PSNR: 36.CUP AND FABRIC PSNR: 38.SSIM: 0.LPIPS: 0.SSIM: 0.LPIPS: 0.그림 4: 새로운 관점 및 조명 방향(훈련 데이터의 일부가 아님)에 대해 재조명을 한 캡처 장면(오른쪽)과 참조 사진(왼쪽) 간의 정성적 비교. 각 예에서 무작위로 샘플링된 뷰 및 조명 위치에 대해 계산된 평균 PSNR, SSIM 및 LPIPS를 나열합니다.참조 PSNR |SSIM |LPIPS IRON 19.13 | 0.8736 | 0. Ours 26.16 0.9516 | 0. 그림 5: METALLIC 장면에서 IRON [Zhang et al. 2022a]의 역 렌더링 결과와 비교(500개의 동일 위치에 배치된 학습 이미지에서). 우리 모델은 동일 위치에 배치된 점 조명에서 평가됩니다. IRON은 상호 반사의 영향을 받으며 지오메트리를 정확하게 재구성하지 못합니다. 참조 PSNR | SSIM | LPIPS NRTF 22.01 0.9008 0. Ours 26.72 0.9602 | 0. 그림 6: 500개의 OLAT 참조 이미지와 참조 지오메트리에서 학습된 신경 복사 전달 필드(NRTF)와 비교. 공정한 비교를 제공하기 위해 점 조명 대신 동일한 방향의 OLAT 이미지(참조 지오메트리 없음)에서 네트워크를 학습합니다. NRTF는 그림자 경계와 반사 상호 반사를 올바르게 재현하는 데 어려움을 겪습니다(확대 참조). 참조 PSNR | SSIM | LPIPS [Philip et al. 2021] 재구성된 기하학 포함 21.29 0.8655 | 0.[Philip et al. 2021] 참조 기하학 포함 23.22 0.8992 | 0.우리의 것 27.79 | 0.9613 | 0.bbbb 그림 7: 대상 조명으로 렌더링된 METALLIC 장면의 500개 입력 이미지에 대한 Philip et al. [2021]의 사전 학습된 재조명 네트워크와 비교. 이러한 유리한 조건에서도 해당 방법은 새로운 관점에 대한 올바른 모양을 재현하는 데 어려움을 겪습니다. Zeng et al. 및 재료 속성(METALLIC 및 ANISOTROPIC-METAL과 같은 매우 반사성이 강한 재료는 오류가 더 높음)이 있는 경우. 시각적으로 가장 눈에 띄는 차이는 반사와 작은 기하학적 세부 사항에서 나타납니다. 표 1: 합성 장면의 소거 결과 캡처된 장면. 우리는 핸드헬드 설정으로 촬영한 3개의 새로운 장면을 모델링하여 신경 암묵적 재조명 표현의 기능을 보여줍니다(그림 4). PIKACHU STATUE 장면에는 광택 하이라이트와 상당한 자체 폐색이 포함되어 있습니다. CAT ON DECOR 장면은 잘 정의되지 않은 기하학이 있는 실제 세계 객체에 대한 우리 방법의 견고성을 보여줍니다. CUP AND FABRIC 장면은 반투명 재료(컵), 공의 반사, 직물의 이방성 반사를 보여줍니다. 회전 카메라와 조명 위치에 대해 시각화된 이러한 장면의 추가 비디오 시퀀스는 보충 자료를 참조하세요. 비교. 그림 5는 우리 방법을 부호 거리 필드로 기하학에 대한 신경 표현을 채택하는 역 렌더링 방법인 IRON[Zhang et al. 2022b]과 비교합니다. 이러한 결과에서 IRON은 강한 상호 반사가 있는 경우 모양과 반사를 올바르게 재구성하지 못한다는 것을 알 수 있습니다. 두 번째 비교(그림 6)에서 우리 방법을 Neural Radiance Transfer Fields(NRTF) [Lyu et al. 2022]와 비교합니다. 취약한 역 렌더링 단계를 건너뛰고 500개의 참조 OLAT 이미지와 참조 지오메트리로 NRTF를 학습합니다. 공정한 비교를 제공하기 위해 포인트 라이트 위치 대신 라이트 방향에 따라 광도 네트워크를 조절하여 동일한 방향성 OLAT 이미지에서 네트워크를 학습하고 평가합니다. 이 테스트를 통해 NRTF가 그림자 가장자리와 반사 반사를 정확하게 재현하는 데 어려움을 겪고 우리 방법이 방향 조명으로도 성공적으로 학습될 수 있음을 알 수 있습니다. 그림 7은 우리 방법을 까다로운 METALLIC 테스트 장면에서 Philip et al. [2021]의 사전 학습된 신경 재조명 네트워크와 비교합니다. 이 장면에서는 다중 뷰 스테레오 [Schönberger and Frahm 2016]가 실패하므로 NeuS SDF에서 재구성된 지오메트리와 기준 진실 지오메트리를 입력합니다. 마지막으로 참조 대상 조명 아래에서 입력 이미지를 렌더링합니다. 우리 네트워크는 대상 조명에 대한 접근 없이 훈련됩니다. 이러한 유리한 조건에서도 Philip et al.의 재조명 방법은 올바른 모양을 재현하는 데 어려움을 겪습니다. 마지막으로, 우리 방법을 지연 신경 조명[Gao et al. 2020](데이터와 훈련된 모델 사용)과 비교합니다. 우리 방법은 지연 신경 조명의 ~10, 입력 이미지와 비교하여 ~500개의 입력 이미지에서 유사한 품질의 결과를 얻을 수 있습니다. 시각적으로 매우 유사하지만 지연 신경 조명의 전반적인 오류는 우리 방법보다 약간 낮습니다. 이는 주로 두 방법 모두 카메라 보정 오류를 처리하는 방식의 차이 때문입니다. 지연 신경 조명은 각 프레임의 차이를 개별적으로 최소화하려고 하므로 이미지에 카메라 보정 오류를 포함할 수 있습니다. 그러나 보정이 완벽하지 않을 때 시간적 &quot;반짝임&quot;이 발생합니다. 반면에 우리 방법은 3D 표현을 최적화하여 더 나은 시간적 안정성을 제공하고(따라서 뷰 보간에 필요한 사진이 줄어듬) 카메라 보정 오류가 있는 경우 이미지가 약간 흐릿해지는 대가를 치릅니다. 1 기본 소재 Ablation Variant 전체 힌트 w/o 하이라이트 힌트 w/o 섀도우 힌트 w/o 모든 힌트 없음 PSNR ↑ 32.SSIM ↑ LPIPS↓ 0.0.31.96 0.9724 0.27.67 0.9572 0.27.54 0.9568 0.31.54 0.9707 0.31.54 0.9707 0.4 기본 소재 32.0.9727 0.31.0.9726 0.24.0.9335 0.27.96 0.9572 0.30.36 0.9666 0.32.02 0.9727 0.2 기본 소재 8 기본 소재 50개 학습 이미지 100개 학습 이미지 250개 학습 이미지 500개 학습 이미지 표 2: 실제 촬영된 장면에 대한 시점 최적화의 절제 결과 시점 최적화가 있는 절제 변형 시점 최적화 없음 절제 연구 PSNR ↑ SSIM ↑ 34.33.0.0.LPIPS↓ 0.0.우리는 여러 번의 절제를 수행합니다.
--- EXPERIMENT ---
영어: s(시각적 및 정량적)를 합성 데이터 세트에 적용하여 신경 암묵적 광도 표현을 구성하는 각 구성 요소의 영향을 평가합니다.그림자 및 하이라이트 힌트.중요한 기여는 재조명 가능 광도 MLP에 그림자 및 하이라이트 힌트를 포함하는 것입니다.그림자 힌트 없이, 하이라이트 힌트 또는 둘 다 학습한 영향을 보여줍니다.그림자 힌트가 없으면 이 방법은 지면에서 선명한 그림자 경계를 올바르게 재현하지 못합니다.이러한 선명한 그림자의 부족은 표 1에 요약된 정량적 오류에도 반영됩니다.하이라이트 힌트를 포함하면 예를 들어 꽃병 입구에서 더 나은 하이라이트 재현이 가능합니다.그림자 광선 수의 영향.현재 그림자 힌트를 계산하는 데 단일 그림자 광선만 사용합니다.그러나 여러 그림자 광선을 쏘고(뷰 광선을 따라 샘플링 포인트를 중요도에 따라) 광도 네트워크에 더 정확한 힌트를 제공할 수도 있습니다.그림자 10은 16개의 그림자 광선으로 학습한 광도 네트워크의 결과를 보여줍니다. 더 정확한 그림자 힌트를 제공하는 반면, 계산 비용이 크게 증가함에 따라 미미한 이점이 있어 그림자 힌트를 계산하기 위해 단일 그림자 광선을 선택한 것이 정당화됩니다.NeuS 대 NeRF 밀도 MLP.재조명 가능한 광도 MLP는 그림자 힌트를 얼마나 신뢰할지 학습하지만(최악의 경우 신뢰할 수 없는 힌트를 완전히 무시할 수 있음), 광도 MLP는 그림자 힌트에 포함되지 않으면 일반적으로 고주파 세부 정보를 다시 도입할 수 없습니다.좋은 그림자 힌트를 얻으려면 뷰 광선을 따라 평균 깊이에 대한 정확한 깊이 추정치가 필요합니다.Wang et al.[2021]은 NeRF가 편향된 깊이 추정치를 생성한다는 점을 지적했으며, 이 문제를 해결하기 위해 NeuS를 도입했습니다.밀도 네트워크에서 Neus를 NERF로 대체하면(그림 10) 편향된 깊이 추정치가 그림자 힌트에 부정적인 영향을 미쳐 그림자 재생성이 저하됩니다. 반투명한 겹겹이 짜여진 공 그림자와 하이라이트 힌트를 사용한 신경 광도장 재조명 참고문헌 DNL Ours 참고문헌 DNL PSNR |SSIM |LPIPS 39.22 0.9932 |0.36.42 0.9856 |0.PSNR |SSIM |LPIPS 34.02 0.9763 |0.Ours 32.94 0.9708 |0.참고문헌 PSNR |SSIM |LPIPS DNL Ours 35.36 0.9730 |0.33.07 0.9695 |0.참고문헌 PSNR |SSIM |LPIPS DNL Ours 32.093 0.9469 |0.30.96 |0.9445 |0.참고문헌 그림 8: 지연된 신경 조명과의 비교[Gao et al. 2020]. Gao 등의 데이터 세트에 대해 무작위로 선택한 1/25(~500) 프레임만을 사용하여 신경 암묵적 광도 표현을 훈련하는 동시에 비슷한 결과를 얻었습니다. 하이라이트 힌트 없음, 섀도우 힌트 없음, 힌트 없음 그림 9: 섀도우 및 하이라이트 힌트의 영향. 힌트가 없으면 네트워크가 원하는 효과를 정확하게 재현하지 못합니다. 참조 NeRF 1 섀도우 레이 PSNR |SSIM |LPIPS 16 섀도우 레이 28.22 0.9667 |0.1 섀도우 레이(저희) 26.84 0.9586 |0.23.71 0.9160 |0.그림 10: BASKET 장면에서 보여준 섀도우 레이 수와 기본 암묵적 모양 표현의 영향. 16개의 섀도우 레이를 사용하면 상당한 계산 오버헤드를 희생하고 미미한 개선만 제공됩니다. 영어: NeRF를 신경 암묵적 모양의 기초로 사용하면 깊이 편향으로 인해 그림자 품질이 저하됩니다.강조 힌트에 대한 기초 자료 수의 영향.표 1은 하이라이트 힌트를 계산하기 위해 1, 2, 4 및 8 기초 자료를 사용한 결과를 보여줍니다.추가 하이라이트 힌트는 어느 정도 결과를 개선합니다.너무 많은 힌트가 제공되면 잘못된 상관 관계로 인해 전체 오류가 증가할 수 있습니다.4 기초 자료는 계산 비용, 네트워크 복잡성 및 품질 간에 좋은 균형을 이룹니다.학습 이미지 수의 영향.그림 11과 표는 Zeng 등의 입력 이미지 수를 변경하는 효과를 보여줍니다.참조 50개 입력 100개 입력 250개 입력 500개 입력 그림 11: 캡처된 학습 이미지 수의 영향.학습 이미지 수를 늘리면 품질이 향상됩니다.이미지 수가 250개 미만이면 품질이 상당히 저하됩니다.참조 PSNR |SSIM |LPIPS w/o Viewpoint Optimization 31.43 | 0.9803 | 0.w/ 시점 최적화 35.08 | 0.9877 | 0.0.그림 12: 시점 최적화의 효과. 시점 최적화를 사용하면 선명도와 세부 사항 측면에서 이미지 품질이 크게 향상됩니다. 50, 100, 250에서 500. 예상대로 학습 이미지가 많을수록 결과가 향상되고 이미지 수가 증가함에 따라 향상 증가가 줄어듭니다. 250개 이미지로 이미 그럴듯한 재조명 결과를 얻었습니다. 학습 이미지 수를 줄이면 눈에 띄는 외관 차이가 발생합니다. 시점 최적화의 효과. 그림 12와 표는 실제로 촬영한 장면에서 시점 최적화의 효과를 보여줍니다. 양적 오류의 개선은 제한적이지만, 시점 최적화가 선명도를 높이고 미세한 세부 사항을 더 잘 보존하여 재구성 품질을 크게 향상시킨다는 것을 시각적으로 볼 수 있습니다. 6 제한 사항 신경 암묵적 광도 표현은 복잡한 모양과 소재가 있는 장면을 재조명하는 데 필요한 입력 이미지 수를 크게 줄이지만 제한이 없는 것은 아닙니다. 현재 우리는 재조명 가능한 광도 MLP 모델이 고주파 광 전송 효과를 모델링하는 데 도움이 되는 그림자 및 하이라이트 힌트를 제공합니다. 그러나 다른 고주파 효과가 존재합니다. 특히 장면의 다른 부분을 반사하는 매우 반사적인 표면은 광도 네트워크에 어려움을 줍니다. &#39;반사 힌트&#39; 및/또는 재매개변수화[Verbin et al. 2022]를 순진하게 포함하면 네트워크에 도움이 되지 않습니다. 주로 날카로운 반사 소재에 대한 표면 법선(반사 방향을 예측하는 데 필요함)의 정확도가 떨어지기 때문입니다. 이러한 제한 사항을 해결하는 것은 이미지 기반 재조명을 위한 신경 암묵적 모델링에 대한 미래 연구의 핵심 과제입니다.
--- CONCLUSION ---
이 논문에서 우리는 구조화되지 않은 사진의 작은 세트에서 자유 시점 재조명을 위한 새로운 신경 암묵적 광도 표현을 제시했습니다. 우리의 표현은 두 개의 MLP로 구성됩니다. 하나는 SDF를 모델링하기 위한 것(NeuS와 유사)이고 두 번째 MLP는 각 지점에서 국소 및 간접 광도를 모델링하기 위한 것입니다. 우리 방법의 핵심은 그림자 및 하이라이트 힌트를 포함하여 재조명 가능 광도 MLP가 고주파 광 전달 효과를 모델링하는 데 도움이 되는 것입니다. 우리 방법은 장면의 약 500장의 사진만으로 재조명 결과를 생성할 수 있습니다. 유사한 기능을 가진 이전 작업과 비교하여 1~2배의 크기를 절약합니다. 감사의 말 Pieter Peers는 NSF 보조금 IIS-1909028에서 부분적으로 지원을 받았습니다. Chong Zeng과 Hongzhi Wu는 NSF China(62022072 &amp; 62227806), Zhejiang Provincial Key R&amp;D Program(2022C01057) 및 XPLORER PRIZE에서 부분적으로 지원을 받았습니다. 참고문헌 Mojtaba Bemana, Karol Myszkowski, Hans-Peter Seidel, Tobias Ritschel. 2020. X-Fields: Implicit Neural View-, Light- and Time-Image Interpolation. ACM Trans. Graph. 39, 6 (2020). Sai Bi, Stephen Lombardi, Shunsuke Saito, Tomas Simon, Shih-En Wei, Kevyn Mcphail, Ravi Ramamoorthi, Yaser Sheikh, Jason Saragih. 2021. 애니메이션이 가능한 얼굴을 위한 Deep relightable appearance models. ACM Trans. Graph. 40, 4 (2021), 1-15. Sai Bi, Zexiang Xu, Kalyan Sunkavalli, Miloš Hašan, Yannick Hold-Geoffroy, David Kriegman, Ravi Ramamoorthi. 2020. Deep Reflectance Volumes: Relightable Reconstructions from Multi-View Photometric Images. ECCV에 게재. 294–311. Mark Boss, Raphael Braun, Varun Jampani, Jonathan T. Barron, Ce Liu, and Hendrik PA Lensch. 2021a. NeRD: 이미지 컬렉션에서 신경 반사 분해. ICCV에 게재. 그림자 및 하이라이트 힌트를 사용하여 신경 복사 필드 재조명 Mark Boss, Andreas Engelhardt, Abhishek Kar, Yuanzhen Li, Deqing Sun, Jonathan T. Barron, Hendrik PA Lensch, and Varun Jampani. 2022. SAMURAI: 제약 없는 실제 세계 임의 이미지 컬렉션에서 얻은 모양과 재질. NeurIPS에 게재. Mark Boss, Varun Jampani, Raphael Braun, Ce Liu, Jonathan Barron, and Hendrik PA Lensch. 2021b. Neural-PIL: 반사 분해를 위한 신경 사전 통합 조명. NeurIPS, Vol. 34. 10691-10704. Guangyan Cai, Kai Yan, Zhao Dong, Ioannis Gkioulekas, Shuang Zhao. 2022. 결합된 암시적 및 명시적 기하 구조를 사용한 물리 기반 역 렌더링. Comp. Graph. Forum 41, 4(2022), 129-138. Wenzheng Chen, Joey Litalien, Jun Gao, Zian Wang, Clement Fuji Tsang, Sameh Khalis, Or Litany, Sanja Fidler. 2021. DIB-R++: 하이브리드 미분 가능 렌더러를 사용하여 조명 및 재질 예측 학습. NeurIPS에서. Paul Debevec, Tim Hawkins, Chris Tchou, Haarm-Pieter Duiker, Westley Sarokin, and Mark Sagar. 2000. Acquiring the Reflectance Field of a Human Face. In Proceedings of the 27th Annual Conference on Computer Graphics and Interactive Techniques. 145-156. Yue Dong. 2019. Deep Appearance Modeling: A Survey. Visual Informatics 3, 2 (2019), 59-68. Farshad Einabadi, Jean-Yves Guillemaut, and Adrian Hilton. 2021. Deep Neural Models for illumination estimation and relighting: A Survey. In Comp. Graph. Forum, Vol. 40. 315-331. Duan Gao, Guojun Chen, Yue Dong, Pieter Peers, Kun Xu, and Xin Tong. 2020. 지연된 신경 조명: 비정형 사진에서 자유 시점 재조명. ACM Trans. Graph. 39, 6, Article 258(2020년 11월). David Griffiths, Tobias Ritschel, Julien Philip. 2022. OutCast: Cast Shadows를 사용한 야외 단일 이미지 재조명. Comp. Graph. Forum 41, 2(2022), 179-193. Amos Gropp, Lior Yariv, Niv Haim, Matan Atzmon, Yaron Lipman. 2020. 모양 학습을 위한 암묵적 기하학적 정규화. arXiv 사전 인쇄본 arXiv:2002.10099(2020). Kaiwen Guo, Peter Lincoln, Philip Davidson, Jay Busch, Xueming Yu, Matt Whalen, Geoff Harvey, Sergio Orts-Escolano, Rohit Pandey, Jason Dourgarian, Danhang Tang, Anastasia Tkach, Adarsh Kowdle, Emily Cooper, Mingsong Dou, Sean Fanello, Graham Fyffe, Christoph Rhemann, Jonathan Taylor, Paul Debevec, Shahram Izadi. 2019. The Relightables: Volumetric Performance Capture of Humans with Realistic Relighting. ACM Trans. Graph. 38, 6, Article 217 (nov 2019). Jon Hasselgren, Nikolai Hofmann, Jacob Munkberg. 2022. Monte Carlo Rendering과 Denoising을 사용한 이미지의 모양, 빛 및 재료 분해. NeurIPS에서. Yoshihiro Kanamori와 Yuki Endo. 2018. Relighting Humans: Occlusion-Aware Inverse Rendering for Full-Body Human Images. ACM Trans. Graph. 37, 6, Article 270 (2018년 12월). Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. ICLR에서. Zhengfei Kuang, Kyle Olszewski, Menglei Chai, Zeng Huang, Panos Achlioptas, and Sergey Tulyakov. 2022. NeROIC: 온라인 이미지 컬렉션의 객체에 대한 신경 렌더링. ACM Trans. Graph. 41, 4, Article 56 (2022년 7월). Quewei Li, Jie Guo, Yang Fei, Feichao Li, and Yanwen Guo. 2022. NeuLighting: 제약 없는 사진 컬렉션을 사용한 자유 시점 야외 장면 재조명을 위한 신경 조명. SIGGRAPH Asia 2022 컨퍼런스 논문. 기사 13. Tzu-Mao Li, Miika Aittala, Frédo Durand, Jaakko Lehtinen. 2018. 엣지 샘플링을 통한 미분 가능 몬테카를로 광선 추적. ACM Trans. Graph. 37, 6, 기사 222(2018년 12월). Matthew M. Loper, Michael J. Black. 2014. OpenDR: 대략적인 미분 가능 렌더러. ECCV. 154-169. Fujun Luan, Shuang Zhao, Kavita Bala, Zhao Dong. 2021. 미분 가능 몬테카를로 렌더링을 사용한 통합 모양 및 SVBRDF 복구. Comp. Graph. Forum 40, 4(2021), 101-113. Linjie Lyu, Ayush Tewari, Thomas Leimkühler, Marc Habermann, Christian Theobalt. 2022. 글로벌 조명을 사용한 재조명 가능한 새로운 뷰 합성을 위한 신경 광도 전달 필드. ECCV, Vol. 13677. 153-169. Ricardo Martin-Brualla, Noha Radwan, Mehdi SM Sajjadi, Jonathan T. Barron, Alexey Dosovitskiy, Daniel Duckworth. 2021. 야생의 NeRF: 제약 없는 사진 컬렉션을 위한 신경 광도 필드. CVPR에서. Abhimitra Meka, Christian Häne, Rohit Pandey, Michael Zollhöfer, Sean Fanello, Graham Fyffe, Adarsh Kowdle, Xueming Yu, Jay Busch, Jason Dourgarian, Peter Denny, Sofien Bouaziz, Peter Lincoln, Matt Whalen, Geoff Harvey, Jonathan Taylor, Shahram Izadi, Andrea Tagliasacchi, Paul Debevec, Christian Theobalt, Julien Valentin, Christoph Rhemann. 2019. Deep Reflectance Fields: HighQuality Facial Reflectance Field Inference from Color Gradient Illumination. ACM Trans. Graph. 38, 4, Article 77(2019년 7월). Abhimitra Meka, Rohit Pandey, Christian Haene, Sergio Orts-Escolano, Peter Barnum, Philip David-Son, Daniel Erickson, Yinda Zhang, Jonathan Taylor, Sofien Bouaziz 등 2020. 심도 재조명 가능한 텍스처: 신경 렌더링을 통한 체적 성능 캡처. ACM 트랜스. 그래프. 39, 6(2020), 1–21. Moustafa Mahmoud Meshry, Dan B Goldman, Sameh Khamis, Hugues Hoppe, Rohit Kumar Pandey, Noah Snavely 및 Ricardo Martin Brualla. 2019. 야생에서의 신경 렌더링. CVPR에서. Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi 및 Ren Ng. 2020. NeRF: 뷰 합성을 위한 신경 복사장으로 장면 표현. ECCV(2020). J. Munkberg, W. Chen, J. Hasselgren, A. Evans, T. Shen, T. Muller, J. Gao, and S. Fidler. 2022. 이미지에서 삼각형 3D 모델, 재료 및 조명 추출. CVPR에서. 8270-8280. O. Nalbach, E. Arabadzhiyska, D. Mehta, H.-P. Seidel, and T. Ritschel. 2017. 딥 셰이딩: 화면 공간 셰이딩을 위한 합성 신경망. Comp. Graph. Forum 36, 4(2017), 65-78. Giljoo Nam, Joo Ho Lee, Diego Gutierrez, and Min H. Kim. 2018. 비정형 플래시 사진을 사용한 3D 객체의 실용적 SVBRDF 획득. ACM Trans. Graph. 37, 6, Article 267(2018년 12월). Merlin Nimier-David, Delio Vicini, Tizian Zeltner, Wenzel Jakob. 2019. Mitsuba 2: 리타겟팅 가능한 전방 및 역방향 렌더러. ACM Trans. Graph. 38, 6, Article 203(2019년 11월). Rohit Pandey, Sergio Orts Escolano, Chloe Legendre, Christian Haene, Sofien Bouaziz, Christoph Rhemann, Paul Debevec, Sean Fanello. 2021. 전체 재조명: 배경 교체를 위한 인물 사진 재조명 학습. ACM Trans. Graph. 40, 4(2021), 1-21. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, Soumith Chintala. 2019. PyTorch: 명령형 스타일, 고성능 딥 러닝 라이브러리. NeurIPS에서. 8024-8035. Julien Philip, Michaël Gharbi, Tinghui Zhou, Alexei A. Efros, George Drettakis. 2019. 기하 인식 네트워크를 사용한 다중 뷰 재조명. ACM Trans. Graph. 38, 4, Article 78(2019년 7월). Julien Philip, Sébastien Morgenthaler, Michaël Gharbi, and George Drettakis. 2021. Free-Viewpoint Indoor Neural Relighting from Multi-View Stereo. ACM Trans. Graph. 40, 5, Article 194 (sep 2021). Peiran Ren, Yue Dong, Stephen Lin, Xin Tong, and Baining Guo. 2015. Image Based Relighting Using Neural Networks. ACM Trans. Graph. 34, 4, Article 111 (jul 2015). Viktor Rudnev, Mohamed Elgharib, William Smith, Lingjie Liu, Vladislav Golyanik, and Christian Theobalt. 2022. NeRF for Outdoor Scene Relighting. ECCV에서. Johannes Lutz Schönberger and Jan-Michael Frahm. 2016. Structure-from-Motion Revisited. CVPR에서. PP Srinivasan, B. Deng, X. Zhang, M. Tancik, B. Mildenhall, JT Barron. 2021. NeRV: 재조명 및 뷰 합성을 위한 신경 반사율 및 가시성 필드. CVPR에서. Tiancheng Sun, Jonathan T. Barron, Yun-Ta Tsai, Zexiang Xu, Xueming Yu, Graham Fyffe, Christoph Rhemann, Jay Busch, Paul E. Debevec, Ravi Ramamoorthi. 2019. 단일 이미지 인물 사진 재조명. ACM Trans. Graph. 38, 4, Article 79 (2019). Tiancheng Sun, Kai-En Lin, Sai Bi, Zexiang Xu, Ravi Ramamoorthi. 2021. NeLF: 인물 사진 합성 및 재조명을 위한 신경 광 전송 필드. EGSR에서. 155-166. Tiancheng Sun, Zexiang Xu, Xiuming Zhang, Sean Fanello, Christoph Rhemann, Paul Debevec, Yun-Ta Tsai, Jonathan T Barron, and Ravi Ramamoorthi. 2020. Light stage super-resolution: Continuous high-frequency relighting. ACM Trans. Graph. 39,(2020), 1-12. Ayush Tewari, Justus Thies, Ben Mildenhall, Pratul Srinivasan, Edgar Tretschk, W Yifan, Christoph Lassner, Vincent Sitzmann, Ricardo Martin-Brualla, Stephen Lombardi, et al. 2022. Advances in neural rendering. In Comp. Graph. Forum, Vol. 41. 703–735. Dor Verbin, Peter Hedman, Ben Mildenhall, Todd Zickler, Jonathan T Barron, and Pratul P Srinivasan. 2022. Ref-nerf: 신경 복사장에 대한 구조화된 뷰 종속적 모양. CVPR에서. 5481-5490. Bruce Walter, Stephen R Marschner, Hongsong Li, Kenneth E Torrance. 2007. 거친 표면을 통한 굴절을 위한 미세면 모델. EGSR에서. 195–206. Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, Wenping Wang. 2021. NeuS: 다중 뷰 재구성을 위한 볼륨 렌더링을 통한 신경 암묵적 표면 학습. NeurIPS(2021). Jiankai Xing, Fujun Luan, Ling-Qi Yan, Xuejun Hu, Houde Qian, Kun Xu. 2022. RGBXY 미분 및 최적 수송을 사용한 미분 가능 렌더링. ACM Trans. 그래프. 41, 6, Article 189(2022년 11월). Zexiang Xu, Kalyan Sunkavalli, Sunil Hadap, and Ravi Ramamoorthi. 2018. 최적의 희소 샘플에서 심층 이미지 기반 재조명. ACM Trans. Graph. 37, 4, Article 126(2018년 7월). Wenqi Yang, Guanying Chen, Chaofeng Chen, Zhenfang Chen, and Kwan-Yee K. Wong. 2022. PS-NeRF: 다중 뷰 광도 스테레오를 위한 신경 역 렌더링. ECCV에서. Yao Yao, Jingyang Zhang, Jingbo Liu, Yihang Qu, Tian Fang, David McKinnon, Yanghai Tsin, and Long Quan. 2022. NeILF: 재료 및 조명 추정을 위한 신경 입사 광 필드. ECCV에서. Yu-Ying Yeh, Koki Nagano, Sameh Khamis, Jan Kautz, Ming-Yu Liu, Ting-Chun Wang. 2022. 가상 조명 스테이지와 합성-실제 적응을 통한 인물 이미지 재조명 학습. ACM Trans. Graph. 41, 6 (2022), 1–21. Kai Zhang, Fujun Luan, Zhengqi Li, Noah Snavely. 2022a. IRON: 광도 이미지에서 신경 SDF 및 재료를 최적화하여 역 렌더링. CVPR에 게재. 55555564. Kai Zhang, Fujun Luan, Qianqian Wang, Kavita Bala, Noah Snavely. 2021b. PhySG: 물리 기반 재료 편집 및 재조명을 위한 구면 가우시안을 사용한 역 렌더링. CVPR에 게재. Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, Oliver Wang. 2018. 지각적 지표로서의 딥 피처의 비합리적 효과성. CVPR에서. 586-595. Xiuming Zhang, Sean Fanello, Yun-Ta Tsai, Tiancheng Sun, Tianfan Xue, Rohit Pandey, Sergio Orts-Escolano, Philip Davidson, Christoph Rhemann, Paul Debevec, Jonathan T. Barron, Ravi Ramamoorthi, William T. Freeman. 2021a. 재조명 및 뷰 합성을 위한 신경 광 전송. ACM Trans. Graph. 40, 1, Article 9(2021년 1월). Xiuming Zhang, Pratul P. Srinivasan, Boyang Deng, Paul Debevec, William T. Freeman, Jonathan T. Barron. 2021c. NeRFactor: 알려지지 않은 조명 하에서 모양과 반사율의 신경 인수 분해. ACM Trans. Graph. 40, 6, Article(2021년 12월). Yuanqing Zhang, Jiaming Sun, Xingyi He, Huan Fu, Rongfei Jia, Xiaowei Zhou. 2022b. 역 렌더링을 위한 간접 조명 모델링. CVPR에서. Quan Zheng, Gurprit Singh, Hans-Peter Seidel. 2021. 신경 재점화 참여 미디어 렌더링. NeurIPS, Vol. 34에서. 15203-15215. Zeng et al. arXiv:2308.13404v1 [cs.CV] 8월 25일 그림자 및 하이라이트 힌트를 사용한 신경 복사장 재조명 Chong Zeng* 저장대학교 CAD 및 CG 주립 핵심 연구실, 중국 항저우 chongzeng2000@gmail.com Pieter Peers 윌리엄 앤 메리 칼리지, 미국 윌리엄스버그 ppeers@siggraph.org Guojun Chen Microsoft Research Asia 베이징, 중국 guoch@microsoft.com Hongzhi Wu 저장대학교 CAD 및 CG 주립 핵심 연구실, 중국 항저우 hwu@acm.org Yue Dong Microsoft Research Asia 베이징, 중국 yuedong@microsoft.com Xin Tong Microsoft Research Asia 베이징, 중국 xtong@microsoft.com 짧은 털: 29.70 | 0.9598 | 0.긴 털: 25.53 | 0.9060 | 0.거친 금속: 35.75 | 0.9908 | 0.GLOSSY-PLASTIC: 36.16 | 0.9920 | 0.ROUGH-PLASTIC: 37.41 | 0.9945 | 0.BASKET: 26.84 | 0.9586 0.그림 1: 새로운 관점과 새로운 조명 방향(훈련 데이터의 일부가 아님)에 대해 다시 조명한 추가 합성 장면(오른쪽)과 렌더링된 참조 이미지(왼쪽) 간의 정성적 비교. 각 예에서 균일한 뷰 및 조명 위치 샘플링을 통해 계산된 평균 PSNR, SSIM 및 LPIPS를 나열합니다. ACM 참조 형식: Chong Zeng, Guojun Chen, Yue Dong, Pieter Peers, Hongzhi Wu 및 Xin Tong. 2023. 그림자 및 하이라이트 힌트를 사용한 신경 광도 필드 다시 조명. 영어: Special Interest Group on Computer Graphics and Interactive Techniques Conference Conference Proceedings(SIGGRAPH &#39;23 Conference Proceedings), 2023년 8월 6-10일, 미국 캘리포니아주 로스앤젤레스.ACM, 미국 뉴욕, NY, 2페이지.https://doi.org/10.1145/3588432.추가 결과 그림 1은 다른 재료 속성의 장면에서 방법을 추가로 테스트하기 위한 추가 합성 결과를 보여줍니다.BASKET 장면은 절제 연구 그림에 포함되어 있지만 그림 3(본 논문)에는 나열되어 있지 않습니다.완벽성을 위해 여기에 포함했습니다.네트워크 아키텍처 세부 정보 밀도 MLP에 대해 NeuS [Wang et al. 2021]와 정확히 동일한 아키텍처를 따릅니다.Softplus를 사용하여 256개 노드가 있는 8개 은닉층 *Microsoft Research Asia에서 인턴십 중에 수행한 작업. C256 MLP / Softplus C39 주파수 인코딩 C3 위치 C256 MLP / Softplus C256 MLP / Softplus C1 SDF C256 기능 C256 MLP / Softplus C256 MLP / Softplus C256 MLP/Softplus C256 MLP / Softplus C217 MLP / Softplus 밀도 네트워크 C3 위치 C3 보기 C27 주파수 인코딩 C3 빛 C27 주파수 인코딩 C1 그림자 힌트 C9 주파수 인코딩 C4 하이라이트 힌트 C36 주파수 인코딩 C3 일반 C3 색상/시그모이드 C256 MLP / ReLU C256 MLP/ReLU C256 MLP/ReLU CMLP/ReLU 재조명 광도 네트워크 그림 2: 밀도 및 재조명 광도 네트워크의 자세한 네트워크 아키텍처. 출력 채널 수와 활성화도 표시됩니다. 활성화 및 입력과 4번째 레이어 간의 건너뛰기 연결. 입력(즉, 광선을 따라 현재 위치)은 6개 대역의 주파수 인코딩을 사용하여 증강됩니다. 재조명 가능 광도 네트워크는 Neus의 색상 MLP와 유사한 네트워크 아키텍처를 갖습니다. ReLU 활성화를 사용하는 256개 노드가 있는 4개의 은닉층입니다. 최종 색상은 시그모이드 활성화 후 출력되어 Zeng et al. 출력 색상이 (-1, 1) 범위 내에 있도록 합니다. 그림 2는 우리 방법의 네트워크 아키텍처를 자세히 설명합니다. 참고문헌 Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, Wenping Wang. 2021. NeuS: 다중 뷰 재구성을 위한 볼륨 렌더링을 통한 신경 암묵적 표면 학습. NeurIPS(2021).
