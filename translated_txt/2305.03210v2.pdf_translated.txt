--- ABSTRACT ---
-변환 모델은 머신 러닝에 혁명을 일으키고 있지만, 그 내부 작동 방식은 여전히 신비롭습니다. 이 연구에서 우리는 연구자들이 변환기의 자기 주의 메커니즘을 이해하도록 돕기 위해 설계된 새로운 시각화 기술을 제시합니다. 이를 통해 이러한 모델은 시퀀스의 요소 간에 풍부하고 맥락적인 관계를 학습할 수 있습니다. 우리 방법의 주요 아이디어는 변환기 모델이 주의를 계산하는 데 사용하는 쿼리 및 키 벡터의 공동 임베딩을 시각화하는 것입니다. 이전의 주의 시각화 기술과 달리, 우리의 접근 방식은 여러 입력 시퀀스에서 전역 패턴을 분석할 수 있습니다. 우리는 이러한 공동 쿼리-키 임베딩을 기반으로 대화형 시각화 도구인 Attention Viz(데모: http://attentionviz.com)를 만들고, 이를 사용하여 언어 및 시각 변환기에서 주의 메커니즘을 연구합니다. 우리는 여러 응용 시나리오와 전문가 피드백을 통해 모델 이해를 개선하고 쿼리-키 상호 작용에 대한 새로운 통찰력을 제공하는 데 있어서 우리 접근 방식의 유용성을 보여줍니다. 색인 용어 변환기, 주의, NLP, 컴퓨터 비전, 시각적 분석
--- INTRODUCTION ---
변압기 신경망 아키텍처[52]는 자연어 처리(NLP)[13,42]부터 컴퓨터 비전[14]에 이르는 분야에 큰 영향을 미치고 있습니다. 실제로 변압기는 현재 수억 명의 사람들이 사용하는 대규모 실제 시스템(예: Stable Diffusion, ChatGPT, Microsoft Copilot)에 배포되고 있습니다. 그러나 이러한 성공의 배후에 있는 메커니즘은 여전히 다소 신비로 남아 있으며, 특히 모델 복잡성과 크기가 증가함에 따라 새로운 기능이 계속 등장하고 있습니다[11,60]. 변압기 모델에 대한 더 깊은 이해는 보다 안정적인 시스템을 구축하고 문제를 해결하며 개선 방안을 제안하는 데 도움이 될 수 있습니다. • 저자는 하버드 대학교에 있습니다. Viégas와 Wattenberg도 Google에 있지만 이 작업은 하버드에서 수행되었습니다. 이메일: {catherineyeh, yidachen, aoyuwu, fernanda, wattenberg}@g.harvard.edu, cynthiachen@college.harvard.edu 원고 수신 xx xxx. 201x; 수락 xx xxx. 201x. 출판일 xx xxx. 201x; 현재 버전 날짜 xx xxx. 201x. 이 기사의 재인쇄본을 얻는 방법에 대한 정보는 reprints@ieee.org로 이메일을 보내주십시오. 디지털 객체 식별자: xx.xxxx/TVCG.201x.xxxxXXX 이 작업에서 우리는 변압기의 작동 방식을 더 잘 이해하기 위한 새로운 시각화 기술을 설명합니다. (2절에 변압기에 대한 간략한 소개가 포함되어 있습니다.) 우리 분석의 목표는 이러한 모델이 입력 요소 간의 풍부한 관계 집합을 학습하고 사용할 수 있도록 하는 특징적인 변압기 자체 주의 메커니즘입니다. 주의 패턴은 집중적으로 연구되었지만, 이전 기술은 일반적으로 한 번에 단일 입력 시퀀스(예: 한 문장 또는 이미지)와 관련된 정보를 시각화합니다. 일반적인 접근 방식은 주어진 입력 시퀀스에 대한 주의 가중치의 이분 그래프[51,53] 또는 히트맵[20, 30] 표현을 만듭니다. 우리의 방법은 더 높은 수준의 관점을 제공하는데, 여기서 우리는 여러 입력 시퀀스의 자기 주의 패턴을 한 번에 볼 수 있다. 이 접근 방식에 대한 한 가지 영감은 연구자가 신경망의 개요를 &quot;축소&quot;하여 보고, 그런 다음 세부 정보를 자세히 볼 수 있게 해주는 Activation Atlas[5]와 같은 도구의 성공이다. 우리의 경우, 우리는 연구자에게 변환기의 다양한 주의 헤드가 어떻게 작동하는지에 대한 풍부하고 자세한 보기를 제공할 수 있는 일종의 &quot;주의 아틀라스&quot;를 구축하고자 한다. 주요 새로운 기술은 변환기가 사용하는 쿼리 및 키 벡터의 공동 임베딩을 시각화하는 것으로, 이는 개별 주의 헤드에 대한 시각적 시그니처를 만든다. 우리의 기술을 설명하기 위해, 우리는 사용자가 언어 및 시각 변환기에서 주의를 탐색할 수 있게 해주는 대화형 시각화 도구인 AttentionViz를 구현한다. Attention Viz는 여러 수준의 세부 정보를 탐색할 수 있게 해주며(그림 1), 모든 주의 헤드를 한 번에 볼 수 있는 글로벌 뷰와 단일 주의 헤드 또는 입력 시퀀스의 세부 정보를 확대할 수 있는 기능을 제공한다. 우리는 Attention Viz와 도메인 전문가 인터뷰를 통한 여러 응용 시나리오를 통해 우리 기술의 유용성을 입증합니다.구체성을 위해 우리는 시각화가 BERT[13], GPT-2[41], ViT[14]와 같은 널리 사용되는 몇 가지 변환기에 대해 무엇을 보여줄 수 있는지에 초점을 맞춥니다.우리는 BERT에서 주의 패턴과 연결된 여러 식별 가능한 &quot;시각적 흔적&quot;을 발견하고, ViT의 시각적 주의 메커니즘에서 새로운 색조/주파수 행동을 감지하고, GPT-2에서 잠재적으로 비정상적인 행동을 발견합니다.사용자 피드백은 또한 다른 임베딩을 대규모로 시각화하는 데 있어 우리 접근 방식의 더 폭넓은 적용 가능성을 뒷받침합니다.요약하자면, 이 작업의 기여는 다음과 같습니다.• • 공동 쿼리 키 임베딩을 기반으로 하는 변환기 모델에서 주의 추세를 탐색하기 위한 시각화 기술.. Attention Viz는 여러 규모에서 시각 및 언어 변환기에서 자기 주의를 연구하기 위한 우리 기술을 적용하는 대화형 도구입니다.Attention Viz가 변환기 주의 패턴에 대한 통찰력을 어떻게 보여줄 수 있는지 보여주는 응용 시나리오와 전문가 피드백. 변압기 모델의 배경 [52]에 도입된 변압기는 순차적 입력에서 작동하도록 설계된 신경망 아키텍처입니다. 변압기에 대한 전체 설명은 이 논문의 범위를 벗어나지만 몇 가지 개념은 작업을 이해하는 데 중요합니다. 첫째, 변압기는 벡터 집합(종종 임베딩이라고 함)을 입력으로 받습니다. 임베딩은 다양한 입력 유형을 나타낼 수 있습니다. 텍스트 기반 변압기에서 임베딩은 단어 또는 단어 조각에 해당합니다. 비전 변압기에서는 픽셀 패치를 인코딩합니다. 네트워크는 이러한 벡터를 일련의 어텐션 계층을 통해 반복적으로 변환하며, 각 계층은 임베딩 쌍 간에 정보를 이동합니다. &quot;주의&quot;라는 이름은 모든 임베딩이 동일하게 관련되지 않을 것임을 암시합니다. 특정 쌍은 더 강력하게 상호 작용합니다. 즉, 서로에게 더 많은 &quot;주의&quot;를 기울입니다. 주의 계층은 어떤 쌍이 상호 작용해야 하고 어떤 정보가 그 사이에 흐르도록 해야 하는지 결정합니다. 예를 들어, &quot;갈색 카피바라는 지금 자고 있다&quot;라는 문장의 단어에서 작동하는 변환기에서 &quot;카피바라&quot;와 &quot;is&quot;에 대한 임베딩 사이에는 높은 주의(및 정보 흐름)가 예상되지만 &quot;갈색&quot;과 &quot;지금&quot; 사이에는 그렇지 않을 수 있습니다. 이 논문에서 초점을 맞춘 자체 주의 메커니즘을 통해 변환기는 시퀀스 요소 간의 풍부한 관계 집합을 학습하고 사용할 수 있으므로 다양한 NLP 및 컴퓨터 비전 작업에서 상당한 성능 향상을 가져옵니다[13,14,41]. 임베딩 쌍이 서로 주의를 기울이는 데에는 여러 가지 이유가 있을 수 있습니다. 예를 들어, 예제 문장에서 &quot;갈색&quot;과 &quot;카피바라&quot;는 형용사-명사 관계로 연결되어 있는 반면 &quot;카피바라&quot;와 &quot;is&quot;는 주어-동사 관계. 여러 관계 유형을 허용하기 위해, 트랜스포머 어텐션 레이어는 여러 어텐션 헤드로 구성되며, 각각은 다른 패턴의 어텐션과 정보 흐름을 나타낼 수 있습니다. 각 어텐션 헤드는 쿼리 가중치 행렬 Wo와 키 가중치 행렬 WK에서 계산된 쌍선형 형태를 사용하여 자체 어텐션 패턴을 계산합니다. 구체적으로, 두 개의 임베딩 벡터 x와 y에 대해 어텐션은 쿼리 벡터 Wox와 키 벡터 Wky의 스케일링된 내적과 관련됩니다. d를 Wky의 차원이라고 하면, f(x,y) = (Wox, Wky) 임베딩 벡터 {x1, x2,...,xn}이 주어지면, x 사이의 셀프 어텐션을 계산합니다. 그리고 소프트맥스 함수를 사용하는 다른 벡터: attn(x¡,x;) = softmax¡(f(xi,x),………‚ƒ (xi,xn)) = ef (xi,xj)/Σef (xi,xk) k 이 공식은 쿼리 벡터와 키 벡터 사이의 점곱이 클수록 최종 어텐션 값이 높아진다는 것을 보여주는데, 이는 우리가 조인트 임베딩 시각화에서 의존하는 사실입니다. 여기서 다루는 것보다 트랜스포머 아키텍처에 훨씬 더 많은 내용이 있습니다. 특히, 우리는 임베딩 쌍 사이의 어텐션 가중치만 설명했고, 그 사이를 흐르는 특정 정보는 설명하지 않았습니다. (나중에 논의하겠지만, 이는 추가 조사가 필요한 영역입니다.) 그러나 마지막 기술적 요점은 나중에 논문에서 이미지를 해석하는 데 도움이 될 것이므로 언급할 가치가 있습니다. 트랜스포머에 제공된 초기 임베딩은 일반적으로 순서(1D 시퀀스의 경우) 또는 공간 구성(비전 트랜스포머에서와 같이 그리드의 경우)의 벡터 표현을 통합합니다. 시퀀스의 경우 이러한 위치 벡터는 삼각 함수를 사용하여 정의되며 고차원 공간의 나선형 곡선에 위치합니다(참조 [52]). 2. 이 논문에서 연구한 모델 우리는 BERT(언어), GPT-2(언어), ViT(비전)의 세 가지 변환기 모델을 연구합니다. 각각은 머신 러닝 커뮤니티에서 중요한 연구 대상이었으며, 세 모델은 다양한 변환기 아키텍처와 애플리케이션을 포괄합니다. BERT 또는 Bidirectional Encoder Representations from Transformers[13]는 다층 변환기 인코더입니다. 양방향 모델인 BERT는 어느 방향으로든 토큰(즉, 입력 요소)에 처리할 수 있습니다. GPT-2 또는 Generative Pre-trained Transformer 2[42]는 다층 변환기 디코더입니다. GPT-2는 단방향 모델로, 이전 토큰에만 처리합니다. ViT 또는 Vision Transformer[14]는 이미지를 &quot;패치&quot;로 분할하고 문장의 토큰처럼 처리하여 셀프 어텐션 기반 트랜스포머 아키텍처를 사용합니다. BERT와 유사하게 VIT는 다중 계층 양방향 트랜스포머 인코더입니다. 이 작업에서 우리는 16x16(VIT-16) 및 32x32(ViT-32) 패치 크기에서 ViT 성능을 살펴봅니다. 3
--- RELATED WORK ---
많은 연구자들이 변환기의 내부 작동을 조사하려고 시도했습니다.[8,34]는 학습된 언어 표현을 탐색하여 변환기 기반 언어 모델의 성능 향상을 이해하려고 시도했으며,[49] BERT가 품사 태그에서 관계 분류에 이르기까지 자연어 분석의 고전적 단계를 요약한다고 관찰했습니다.또 다른 인기 있는 접근 방식은 기계적 해석 가능성, 즉 역엔지니어링 변환기 모델입니다(예: [15, 16,37]).변환기의 중추인 주의도 집중적으로 연구되었습니다.예를 들어, 주의는 NLP 시스템의 구문 구조[9,57]와 시각 변환기의 게슈탈트 유사 그룹화[33]와 관련이 있는 것으로 보입니다.연구자들은 ViT의 시각적 주의 메커니즘을 합성 필터와도 비교하여 주의가 이미지 폐색, 손상 및 고주파 노이즈에 더 강력하다는 것을 발견했습니다[35,40].관련 작업에 대한 논의에서 우리는 변환기 주의를 연구하기 위한 시각적 접근 방식에 초점을 맞춥니다. 3.1 단일 입력 시퀀스에서 주의 시각화 주의 패턴은 언어 및 시각 변환기[4,12,21,31,39]에서 자연스럽게 시각화에 적합합니다. 이러한 시각화는 주로 이분 그래프(예: [30, 48,51,53]) 또는 히트맵(예: [1, 10, 20, 22, 25, 30, 43])을 사용하여 단일 입력 시퀀스에서 쿼리와 키 토큰 간의 주의 가중치를 시각화하는 데 중점을 둡니다. 여러 모델 또는 계층 간의 비교를 허용하는 몇 가지 시각화가 제안되었습니다. 예를 들어, 주의 흐름[12]은 사용자가 BERT의 계층 내부 및 계층 간, 그리고 단일 문장이 주어진 주의 헤드 간의 주의를 비교하도록 지원합니다. Dodrio[59]는 단일 입력에 적용되는 그리드 보기를 사용하여 주의 헤드를 직접 비교할 수 있습니다. 또 다른 시스템인 VisQA[21]는 언어 자기 주의, 시각 자기 주의, 언어-시각 교차 주의의 히트맵을 표시하여 시각적 질문-답변 작업에 대한 다양한 헤드에서의 주의를 시각화합니다.그러나 이러한 모델 비교 시스템에서도 분석가는 주어진 주의 헤드에 대한 패턴을 식별하고 확인하기 위해 한 번에 하나씩 다양한 입력을 살펴봐야 합니다.3.2 단일 입력 너머: 임베딩 및 활성화 극대화 시각화 여러 입력에서 유지되는 패턴을 찾는 것은 자연스러운 일입니다.이 목표를 달성하는 데 효과적인 것으로 입증된 한 가지 기술은 여러 입력 시퀀스의 임베딩 벡터 컬렉션을 시각화하는 것입니다[3, 18, 19, 46, 47, 58].예를 들어, [43]은 여러 다른 맥락에서 사용된 동일한 단어에 대한 BERT 임베딩을 시각화하고 단어 의미에 해당하는 클러스터를 찾았습니다. 구문 처리에 대한 탐구에서 [8]은 다국어 BERT 모델의 임베딩을 시각화하고 해석에 도움이 되는 의미 있는 클러스터를 다시 한번 찾았습니다.LMFingerprints [45]는 트리 기반 방사형 레이아웃을 사용하여 다양한 언어 모델에서 임베딩 벡터를 비교합니다.[17,61]에서 비전 변환기에 사용된 두 번째 기술은 특정 단위의 활성화를 최대화하는 이미지를 찾는 것을 목표로 합니다.이 기술을 임베딩 벡터에 적용하면 명확하게 해석 가능한 결과를 생성합니다.그러나 저자는 쿼리 및 키 벡터에 적용할 때 이 기술이 유용한 결과를 생성하지 않는 것으로 보인다고 언급합니다.3.3 문헌의 격차우리는 우리의 작업에 동기를 부여하는 기존 문헌에서 세 가지 격차를 발견했습니다.첫째, 임베딩 벡터를 시각화하는 것은 여러 입력에서 패턴을 분석하는 데 효과적인 기술로 나타났지만 변환기 모델에서 쿼리 및 키 임베딩을 시각화하려는 체계적인 시도는 알지 못합니다.[6]은 또한 쿼리 및 키와 같은 셀프 어텐션의 중간 아티팩트가 충분히 탐색되지 않았다고 주장합니다. 이러한 관찰은 우리의 공동 쿼리-키 임베딩 기술을 동기를 부여합니다. 둘째, 여러 임베딩을 비교하기 위해 시각화 기술이 제안되었지만(예: [2,3,26]) 이러한
--- METHOD ---
영어: 변환기 모델이 주의를 계산하는 데 사용하는 쿼리 및 키 벡터의 공동 임베딩을 시각화하는 것입니다. 이전의 주의 시각화 기술과 달리, 우리의 접근 방식은 여러 입력 시퀀스에서 전역 패턴을 분석할 수 있게 합니다. 우리는 이러한 공동 쿼리-키 임베딩을 기반으로 대화형 시각화 도구인 Attention Viz(데모: http://attentionviz.com)를 만들고 이를 사용하여 언어 및 시각 변환기에서 주의 메커니즘을 연구합니다. 우리는 여러 응용 시나리오와 전문가 피드백을 통해 모델 이해를 개선하고 쿼리-키 상호 작용에 대한 새로운 통찰력을 제공하는 데 있어서 우리 접근 방식의 유용성을 보여줍니다. 색인 용어 변환기, 주의, NLP, 컴퓨터 비전, 시각적 분석 소개 변환기 신경망 아키텍처[52]는 자연어 처리(NLP)[13,42]에서 컴퓨터 비전[14]에 이르는 분야에 큰 영향을 미치고 있습니다. 실제로 변환기는 현재 수억 명의 사람들이 사용하는 대규모 실제 시스템(예: Stable Diffusion, ChatGPT, Microsoft Copilot)에 배포됩니다. 그러나 이러한 성공의 이면에 있는 메커니즘은 여전히 다소 신비로 남아 있으며, 특히 모델 복잡성과 크기가 증가함에 따라 새로운 기능이 계속 등장하고 있기 때문입니다[11,60]. 변압기 모델에 대한 보다 깊은 이해는 보다 안정적인 시스템을 구축하고 문제를 해결하며 개선 방안을 제안하는 데 도움이 될 수 있습니다. • 저자는 하버드 대학교에 있습니다. Viégas와 Wattenberg도 Google에 있지만 이 작업은 하버드에서 수행되었습니다. 이메일: {catherineyeh, yidachen, aoyuwu, fernanda, wattenberg}@g.harvard.edu, cynthiachen@college.harvard.edu 원고 수신 xx xxx. 201x; 승인 xx xxx. 201x. 출판일 xx xxx. 201x; 현재 버전 날짜 xx xxx. 201x. 이 기사의 재인쇄본을 얻는 방법에 대한 자세한 내용은 reprints@ieee.org로 이메일을 보내주십시오. 디지털 객체 식별자: xx.xxxx/TVCG.201x.xxxxXXX 이 작업에서 우리는 변압기의 작동 방식을 더 잘 이해하기 위한 새로운 시각화 기술을 설명합니다.(2절에서 변압기에 대한 간략한 소개를 포함합니다.) 우리 분석의 목표는 이러한 모델이 입력 요소 간의 풍부한 관계 집합을 학습하고 사용할 수 있도록 하는 특징적인 변압기 자기 주의 메커니즘입니다.주의 패턴이 집중적으로 연구되었지만, 이전 기술은 일반적으로 한 번에 단일 입력 시퀀스(예: 한 문장 또는 이미지)와 관련된 정보를 시각화합니다. 일반적인 접근 방식은 주어진 입력 시퀀스에 대한 주의 가중치의 이분 그래프[51,53] 또는 히트맵[20, 30] 표현을 만듭니다. 우리 방법은 더 높은 수준의 관점을 제공하며, 여기서 여러 입력 시퀀스의 자기 주의 패턴을 한 번에 볼 수 있습니다. 이 접근 방식에 대한 한 가지 영감은 연구자가 신경망의 개요를 보기 위해 &quot;축소&quot;한 다음 세부 정보를 자세히 볼 수 있도록 해주는 Activation Atlas[5]와 같은 도구의 성공입니다. 우리의 경우, 연구자에게 변환기의 다양한 어텐션 헤드가 작동하는 방식에 대한 풍부하고 자세한 보기를 제공할 수 있는 일종의 &quot;어텐션 아틀라스&quot;를 구축하고자 합니다. 기본적인 새로운 기술은 변환기에서 사용하는 쿼리 및 키 벡터의 공동 임베딩을 시각화하여 개별 어텐션 헤드에 대한 시각적 시그니처를 만드는 것입니다. 우리의 기술을 설명하기 위해, 사용자가 언어 및 시각 변환기에서 어텐션을 탐색할 수 있는 대화형 시각화 도구인 AttentionViz를 구현합니다. Attention Viz는 여러 수준의 세부 정보를 통해 탐색할 수 있도록 하며(그림 1), 모든 어텐션 헤드를 한 번에 볼 수 있는 글로벌 뷰와 단일 어텐션 헤드 또는 입력 시퀀스에서 세부 정보를 확대할 수 있는 기능을 제공합니다. 우리는 Attention Viz와 도메인 전문가 인터뷰를 통한 여러 응용 시나리오를 통해 우리 기술의 유용성을 보여줍니다. 구체성을 위해, 우리는 시각화가 BERT[13], GPT-2[41], ViT[14] 등 널리 사용되는 몇 가지 변환기에 대해 무엇을 밝힐 수 있는지에 초점을 맞춥니다.우리는 BERT에서 주의 패턴과 연결된 여러 식별 가능한 &quot;시각적 흔적&quot;을 발견하고, ViT의 시각적 주의 메커니즘에서 새로운 색조/주파수 행동을 감지하고, GPT-2에서 잠재적으로 비정상적인 행동을 발견합니다.사용자 피드백은 또한 다른 임베딩을 대규모로 시각화하는 데 있어 우리 접근 방식의 더 폭넓은 적용 가능성을 뒷받침합니다.요약하자면, 이 작업의 기여는 다음과 같습니다.• • 공동 쿼리-키 임베딩을 기반으로 하는 변환기 모델에서 주의 추세를 탐색하기 위한 시각화 기술.. 여러 규모에서 시각 및 언어 변환기에서 자기 주의를 연구하는 데 우리 기술을 적용하는 대화형 도구인 Attention Viz.Attention Viz가 변환기 주의 패턴에 대한 통찰력을 어떻게 밝힐 수 있는지 보여주는 응용 시나리오 및 전문가 피드백.변환기 모델의 배경 [52]에서 도입된 변환기는 순차적 입력에서 작동하도록 설계된 신경망 아키텍처입니다. 트랜스포머에 대한 전체 설명은 이 논문의 범위를 벗어나지만, 몇 가지 개념은 우리의 작업을 이해하는 데 중요합니다. 첫째, 트랜스포머는 벡터 집합(종종 임베딩이라고 함)을 입력으로 받습니다. 임베딩은 다양한 입력 유형을 나타낼 수 있습니다. 텍스트 기반 트랜스포머에서 임베딩은 단어 또는 단어 조각에 해당합니다. 비전 트랜스포머에서 임베딩은 픽셀 패치를 인코딩합니다. 네트워크는 일련의 어텐션 레이어를 통해 이러한 벡터를 반복적으로 변환하며, 각 레이어는 임베딩 쌍 간에 정보를 이동합니다. &quot;주의&quot;라는 이름은 모든 임베딩이 동일하게 관련되지 않을 것임을 암시합니다. 특정 쌍은 더 강력하게 상호 작용합니다. 즉, 서로에게 더 많은 &quot;주의&quot;를 기울입니다. 주의 계층은 어떤 쌍이 상호 작용해야 하고 어떤 정보가 그 사이에 흐르도록 해야 하는지 결정합니다. 예를 들어, &quot;갈색 카피바라는 지금 자고 있다&quot;라는 문장의 단어에서 작동하는 변환기에서 &quot;카피바라&quot;와 &quot;is&quot;에 대한 임베딩 사이에는 높은 주의(및 정보 흐름)가 예상되지만 &quot;갈색&quot;과 &quot;지금&quot; 사이에는 그렇지 않을 수 있습니다. 이 논문에서 초점을 맞춘 자체 주의 메커니즘을 통해 변환기는 시퀀스 요소 간의 풍부한 관계 집합을 학습하고 사용할 수 있으므로 다양한 NLP 및 컴퓨터 비전 작업에서 상당한 성능 향상을 가져옵니다[13,14,41]. 임베딩 쌍이 서로 주의를 기울이는 데에는 여러 가지 이유가 있을 수 있습니다. 예를 들어, 예제 문장에서 &quot;갈색&quot;과 &quot;카피바라&quot;는 형용사-명사 관계로 연결되어 있는 반면 &quot;카피바라&quot;와 &quot;is&quot;는 주어-동사 관계. 여러 관계 유형을 허용하기 위해, 트랜스포머 어텐션 레이어는 여러 어텐션 헤드로 구성되며, 각각은 다른 패턴의 어텐션과 정보 흐름을 나타낼 수 있습니다. 각 어텐션 헤드는 쿼리 가중치 행렬 Wo와 키 가중치 행렬 WK에서 계산된 쌍선형 형태를 사용하여 자체 어텐션 패턴을 계산합니다. 구체적으로, 두 개의 임베딩 벡터 x와 y에 대해 어텐션은 쿼리 벡터 Wox와 키 벡터 Wky의 스케일링된 내적과 관련됩니다. d를 Wky의 차원이라고 하면, f(x,y) = (Wox, Wky) 임베딩 벡터 {x1, x2,...,xn}이 주어지면, x 사이의 셀프 어텐션을 계산합니다. 그리고 소프트맥스 함수를 사용하는 다른 벡터: attn(x¡,x;) = softmax¡(f(xi,x),………‚ƒ (xi,xn)) = ef (xi,xj)/Σef (xi,xk) k 이 공식은 쿼리 벡터와 키 벡터 사이의 점곱이 클수록 최종 어텐션 값이 높아진다는 것을 보여주는데, 이는 우리가 조인트 임베딩 시각화에서 의존하는 사실입니다. 여기서 다루는 것보다 트랜스포머 아키텍처에 훨씬 더 많은 내용이 있습니다. 특히, 우리는 임베딩 쌍 사이의 어텐션 가중치만 설명했고, 그 사이를 흐르는 특정 정보는 설명하지 않았습니다. (나중에 논의하겠지만, 이는 추가 조사가 필요한 영역입니다.) 그러나 마지막 기술적 요점은 나중에 논문에서 이미지를 해석하는 데 도움이 될 것이므로 언급할 가치가 있습니다. 트랜스포머에 제공된 초기 임베딩은 일반적으로 순서(1D 시퀀스의 경우) 또는 공간 구성(비전 트랜스포머에서와 같이 그리드의 경우)의 벡터 표현을 통합합니다. 시퀀스의 경우 이러한 위치 벡터는 삼각 함수를 사용하여 정의되며 고차원 공간의 나선형 곡선에 위치합니다(참조 [52]). 2. 이 논문에서 연구한 모델 우리는 BERT(언어), GPT-2(언어), ViT(비전)의 세 가지 변환기 모델을 연구합니다. 각각은 머신 러닝 커뮤니티에서 중요한 연구 대상이었으며, 세 모델은 다양한 변환기 아키텍처와 애플리케이션을 포괄합니다. BERT 또는 Bidirectional Encoder Representations from Transformers[13]는 다층 변환기 인코더입니다. 양방향 모델인 BERT는 어느 방향으로든 토큰(즉, 입력 요소)에 처리할 수 있습니다. GPT-2 또는 Generative Pre-trained Transformer 2[42]는 다층 변환기 디코더입니다. GPT-2는 단방향 모델로, 이전 토큰에만 처리합니다. ViT 또는 Vision Transformer[14]는 이미지를 &quot;패치&quot;로 분할하고 문장의 토큰처럼 처리하여 셀프 어텐션 기반 변압기 아키텍처를 사용합니다. BERT와 유사하게 VIT는 다층 양방향 변압기 인코더입니다. 이 작업에서 우리는 16x16(VIT-16) 및 32x32(ViT-32) 패치 크기에서 ViT 성능을 살펴봅니다. 3 관련 작업 많은 연구자들이 변압기의 내부 작동을 조사하려고 시도했습니다. [8,34]는 학습된 언어 표현을 탐색하여 변압기 기반 언어 모델의 성능 향상을 이해하려고 시도했으며, [49]는 BERT가 품사 태그에서 관계 분류에 이르기까지 자연어 분석의 고전적 단계를 요약한다고 관찰했습니다. 또 다른 인기 있는 접근 방식은 기계적 해석 가능성, 즉 변압기 모델 역공학입니다(예: [15, 16,37]). 변압기의 중추인 어텐션도 집중적으로 연구되었습니다. 예를 들어, 주의는 NLP 시스템의 구문 구조[9,57] 및 시각 변환기의 게슈탈트 유사 그룹화[33]와 관련이 있는 것으로 보입니다. 연구자들은 ViT의 시각적 주의 메커니즘을 합성 필터와 비교하여 주의가 이미지 폐색, 손상 및 고주파 노이즈에 더 강력하다는 것을 발견했습니다[35,40]. 관련 작업에 대한 논의에서 우리는 변환기 주의를 연구하기 위한 시각적 접근 방식에 초점을 맞춥니다. 3.1 단일 입력 시퀀스에서 주의 시각화 주의 패턴은 언어 및 시각 변환기 모두에서 자연스럽게 시각화에 적합합니다[4,12,21,31,39]. 이러한 시각화는 이분 그래프(예: [30, 48,51,53]) 또는 히트맵(예: [1, 10, 20, 22, 25, 30, 43])을 사용하여 단일 입력 시퀀스에서 쿼리와 키 토큰 간의 주의 가중치를 시각화하는 데 주로 초점을 맞춥니다. 여러 모델 또는 계층 간 비교를 허용하는 몇 가지 시각화가 제안되었습니다. 예를 들어, Attention Flows[12]는 사용자가 BERT의 계층 내부 및 계층 간, 그리고 단일 문장이 주어진 어텐션 헤드 간에 어텐션을 비교하도록 지원합니다. Dodrio[59]는 단일 입력에 적용되는 그리드 보기를 사용하여 어텐션 헤드를 직접 비교할 수 있습니다. 또 다른 시스템인 VisQA[21]는 언어 자기 어텐션, 시각 자기 어텐션, 언어-시각 교차 어텐션의 히트맵을 표시하여 시각적 질문-답변 작업에 대한 다른 헤드에서의 어텐션을 시각화합니다. 그러나 이러한 모델 비교 시스템에서도 분석가는 주어진 어텐션 헤드에 대한 패턴을 식별하고 확인하기 위해 한 번에 하나씩 다른 입력을 살펴봐야 합니다. 3.2 단일 입력을 넘어서: 임베딩 및 활성화 극대화 시각화 여러 입력에서 유지되는 패턴을 찾는 것은 자연스러운 일입니다. 이 목표를 향해 효과적인 것으로 입증된 한 가지 기술은 여러 입력 시퀀스에서 임베딩 벡터 컬렉션을 시각화하는 것입니다[3, 18, 19, 46, 47, 58]. 예를 들어, [43]은 여러 다른 맥락에서 사용된 동일한 단어에 대한 BERT 임베딩을 시각화하고 단어 의미에 해당하는 클러스터를 찾았습니다. 구문 처리를 탐구하면서[8]는 다국어 BERT 모델의 임베딩을 시각화하고 해석에 도움이 되는 의미 있는 클러스터를 다시 한 번 찾았습니다. LMFingerprints[45]는 트리 기반 방사형 레이아웃을 사용하여 다양한 언어 모델에서 임베딩 벡터를 비교합니다. [17,61]에서 비전 변환기에 사용된 두 번째 기술은 특정 단위의 활성화를 최대화하는 이미지를 찾는 것을 목표로 합니다. 이 기술을 임베딩 벡터에 적용하면 명확하게 해석 가능한 결과를 생성합니다. 그러나 저자는 이 기술을 쿼리 및 키 벡터에 적용하면 유용한 결과를 생성하지 못하는 것으로 보인다고 언급합니다. 3.3 문헌의 격차 우리는 우리의 작업에 동기를 부여하는 기존 문헌의 세 가지 격차를 발견했습니다. 첫째, 임베딩 벡터를 시각화하는 것은 여러 입력에서 패턴을 분석하는 데 효과적인 기술로 나타났지만, 변환기 모델에서 쿼리 및 키 임베딩을 시각화하려는 체계적인 시도는 알지 못합니다. [6]은 또한 쿼리 및 키와 같은 셀프 어텐션의 중간 아티팩트가 충분히 탐구되지 않았다고 주장합니다. 이러한 관찰은 우리의 공동 쿼리-키 임베딩 기술에 동기를 부여합니다. 둘째, 여러 임베딩을 비교하기 위해 시각화 기술이 제안되었지만(예: [2,3,26]), 이러한 방법은 종종 몇 가지 임베딩으로 제한되고 다른 변환기 헤드 및 계층에서 임베딩을 비교해야 하는 우리의 요구를 해결할 수 없습니다. 따라서 우리는 규모에 맞게 쿼리-키 임베딩을 시각화하기 위해 글로벌 행렬 뷰를 설계합니다. 마지막으로, 이분 그래프 표현은 NLP 기반 변환기를 분석하는 데 도움이 되는 것으로 입증되었지만 비전 작업에 적용되는 것은 보지 못했습니다. 우리는 ViT에서 이미지 주의 패턴을 연구하기 위해 이분형 시각화를 만들어 이 방향을 탐구합니다.4 목표 및 과제 이 작업의 포괄적인 목표는 트랜스포머 모델에서 글로벌 주의 추세를 탐색할 수 있는 새로운 시각화 기법을 설계하는 것입니다.이 아이디어에 대한 초기 피드백을 수집하고 사용자 요구 사항에 대해 자세히 알아보기 위해 모델 해석성에 관심이 있는 5명의 머신 러닝(ML) 연구자(박사 과정 학생 4명과 교수 1명)와 대화했습니다.이 개별 인터뷰에서 전문가에게 트랜스포머로 작업할 때의 현재 관행과 과제와 주의 시각화가 연구 목표에 어떻게 도움이 될 수 있는지 설명해 달라고 요청했습니다.이러한 전문가를 E1-5라고 칭합니다.4.1 목표 궁극적으로 전문가와의 대화에서 세 가지 주요 목표가 도출되었습니다.G1 자기 주의가 모델 동작에 어떤 영향을 미치는지 이해합니다.전반적으로 5명의 전문가 모두 다양한 주의 헤드의 동작과 트랜스포머 모델이 특징적인 자기 주의 메커니즘을 통해 무엇을 학습하고 있는지 더 잘 이해하고 싶어했습니다.따라서 그들은 주의 패턴을 빠르고 쉽게 탐색할 수 있기를 원했습니다. E는 &quot;주의는 여전히 매우 폐쇄적이고 많은 미스터리가 있다&quot;고 설명했기 때문에, 트랜스포머 주의 패턴에 대한 더 깊은 이해를 얻으면 &quot;대규모 언어 모델이 추론 작업과 수학에서 실패하는 이유&quot;에 대한 통찰력을 얻을 수 있습니다. G2 주의 헤드를 비교 및 대조합니다. E5는 주의 헤드의 차이를 시각화하면 연구 프로세스의 첫 번째 단계인 가설 생성에 도움이 될 수 있다고 언급했습니다. &quot;시각화는 가설을 공식화하여 테스트하고 트랜스포머가 무엇을 하는지 직관적으로 파악하는 데 도움이 될 수 있습니다.&quot; 또한 3명의 전문가(E1, E2, E5)는 주의 헤드 비교가 모델 가지치기 및 편집 목적으로 유용할 것이라고 언급했습니다. 즉, 두 개의 주의 헤드가 비슷하게 작동하는 것처럼 보이면 모델 성능에 큰 영향을 미치지 않고 하나를 제거할 수 있습니다. E1의 말에 따르면, 헤드를 비교하면 &quot;실제로 유용한 모델 부분을 찾을 수 있습니다.&quot; G3 - 주의 이상 현상 식별. 4명의 연구자(E2-5)는 주의 패턴 탐색을 통해 트랜스포머의 불규칙성과 잠재적인 행동 문제를 식별하고자 했습니다. 이 정보는 모델 디버깅 목적으로 사용될 수 있습니다. 예를 들어, E4는 &quot;관심을 시각화하면 결과가 정확하더라도 모델이 잘못된 것을 보고 있을 때 알아차리는 데 도움이 될 수 있습니다.&quot;라고 말했습니다. E3는 동의하여 입력 &quot;하늘은 파랗다&quot;를 반복합니다. 쿼리 (X1, X2, Xa) 하늘 (X1, X2, Xa} 차원 감소는 {X1, X2, Xa) t-SNE/UMAP/PCA 파란색 {X1, X2, Xa} 키 파란색 하늘⚫ (y1, Y2, Ya} 하늘 파란색 하늘 (y1, y2, ..., Ya} 는 (y1, Y2, Ya} 파란색 (y1, Y2, Ya} Q/K 벡터로 변환 공동 Q/K 임베딩 그림 2: 단일 어텐션 헤드에 대한 공동 쿼리-키 임베딩 공간 생성 NLP 사례에서 입력 문장이 주어지면 먼저 각 토큰을 해당 쿼리 및 키 벡터로 변환합니다. 그런 다음 tSNE/UMAP/PCA를 사용하여 이러한 1 × d 벡터를 2D/3D 산점도 좌표로 투영합니다. BERT, GPT-2 및 사용된 ViT 모델, d = 64. 특히 모델 학습 맥락에서 디버깅의 중요성: &quot;학습은 종종 실패하고 종료되지만, 실패하거나 예상치 못한 동작을 생성하는 이유를 이해하기 어렵습니다.&quot; 4.2 과제 이러한 목표를 고려하여 다음과 같은 일련의 설계 과제를 개발했습니다. T1 대규모로 어텐션 헤드 시각화. 사용자가 모델 동작을 빠르게 탐색하고[G1] 어텐션 패턴을 쉽게 비교 및 대조할 수 있도록[G2] 도구는 변환기 계층에서 셀프 어텐션 헤드를 동시에 시각화합니다. T2 - 쿼리-키 상호 작용 탐색. E1과 E4는 변환기 셀프 어텐션에 대한 이해를 높이기 위해 쿼리-키 쌍 정보를 더 잘 이해하고자 하는 욕구를 표현했습니다. 따라서 도구는 쿼리-키 상호 작용을 시각화하여 어텐션 패턴 비교[G2]와 이상 감지[G3]를 더욱 지원합니다. T3 - 여러 수준에서 어텐션 조사. 도구는 문장/이미지, 헤드 및 모델 수준에서 시각화를 제공하여 로컬 및 글로벌 어텐션 비교[G2]를 허용합니다. 단일 인터페이스에서 여러 뷰를 전환하는 유연성은 지식 발견[G1]을 용이하게 하고 사용자가 모델 불규칙성[G3]을 식별하는 데 도움이 됩니다.T4 - 모델 및 데이터 입력 사용자 지정.Attention Viz는 새로운 변환기 및 데이터 세트로 쉽게 확장할 수 있어 다양한 모델 및 모달리티(언어 및 시각)에서 주의 패턴을 빠르게 시각적으로 비교[G2]하고 합성[G1]할 수 있습니다.QUERY/Key 임베딩 및 주의 VIZ 설계 이러한 목표와 작업을 해결하기 위해 Attention Viz라는 도구를 빌드합니다. 도구에서 사용하는 주요 기술은 각 주의 헤드에 대한 쿼리 및 키 벡터의 공동 임베딩을 시각화하는 것입니다. 이 섹션에서는 먼저 이 기술의 기반이 되는 동기와 수학을 설명한 다음 전체 애플리케이션의 설계를 논의합니다.5. 쿼리/키 임베딩 시각화 Attention Viz의 기술은 비교적 간단하지만 아래에서 설명하듯이 효과적이려면 두 가지 수학적 트릭이 필요합니다. 각 트랜스포머 어텐션 헤드가 행렬 Wo와 WK를 각각 적용하여 입력 임베딩을 쿼리 벡터와 키 벡터로 변환한다는 점을 기억하세요(2절). 이러한 행렬은 원래 벡터 임베딩을 더 낮은 차원 공간에 투영하여 본질적으로 고차원 벡터 임베딩에서 특정 유형의 정보를 선택합니다. 따라서 쿼리 및 키 벡터를 검사하면 Wo와 WK가 어떤 정보를 선택하는지 알 수 있습니다. 핵심적인 관찰은 쿼리 및 키 벡터의 상대적 위치가 어텐션이 어떻게 분포될지에 대한 단서를 제공할 수 있다는 것입니다. 어텐션 계수는 쿼리와 키 간의 점곱에 따라 달라지기 때문입니다. 이유를 알아보려면 쿼리 및 키 벡터가 항상 동일한 규범을 갖는 가상 상황을 고려하세요. 그런 다음 더 가까운 거리는 작은 거리 높은 점곱 푸른 하늘 푸른 하늘 큰 거리 낮은 점곱 점곱 - BERT, 계층 4 헤드 5.7.5 10.0 12.5 15.0 17.5 20.0 22.L2 H 키 벡터를 변환하기 전 L2 H 키 벡터를 변환한 후 그림 3: 왼쪽: 조인트 임베딩 공간에서의 원래 쿼리와 키. 오른쪽: 쿼리와 키 중심을 맞추기 위해 키를 변환한 후의 증가된 중첩. 더 높은 어텐션 계수와 직접적으로 관련이 있습니다. 실제로 쿼리 및 키 벡터는 규범이 다르므로 점곱과 거리 간의 관계는 정확하지 않습니다. 그러나 다음 섹션에서 설명하듯이 이 관계를 놀라울 정도로 가깝게 만들 수 있습니다. 그림 2는 언어 변환기에서 단일 어텐션 헤드의 합성 예를 사용하여 기술을 설명합니다. 조인트 임베딩을 생성하기 위해 먼저 주어진 문장에서 각 토큰의 쿼리 및 키 벡터 표현을 얻습니다(섹션 2). 그런 다음 세 가지 차원 축소 방법 중 하나를 사용하여 이러한 고차원 벡터를 공유된 저차원 부분 공간에 투영합니다.t-SNE [50], UMAP [32] 또는 PCA [24]. 이러한 차원 축소 알고리즘의 출력은 2D/3D 산점도이며, 각 점은 단일 쿼리 또는 키 토큰을 나타냅니다. 동일한 프로세스를 사용하여 각 토큰이 이미지 패치인 ViT 어텐션 헤드에 대한 조인트 임베딩을 만들 수 있습니다. 기본적으로 쿼리는 녹색으로, 키는 분홍색으로 시각화합니다. 그러나 사용자가 선택할 수 있는 여러 색상 인코딩이 있으며(5.2절 참조) 다른 팔레트를 시스템에 쉽게 대체할 수 있습니다. 당사의 조인트 임베딩을 통해 사용자는 쿼리와 키 간의 세부적인 상호 작용을 탐색할 수 있으며, 이러한 플롯의 모양은 종종 기본 셀프 어텐션 패턴의 시각적 지표 역할을 할 수 있습니다(7절 참조). 각 차원 축소 기술은 주어진 데이터 세트에 대해 다른 패턴을 생성하여 고유한 통찰력과 사용 사례를 제공합니다. 5.1.벡터 정규화 Attention Viz를 설계하는 동안, 우리는 정보를 잃지 않고 변경할 수 있는 두 가지 &quot;자유 매개변수&quot;를 발견했습니다. 이러한 매개변수를 조정하면 임베딩 거리와 어텐션 가중치 간의 관계가 더욱 긴밀해지고 시각화의 가독성이 크게 향상됩니다. 이러한 정규화는 차원 축소 전에 적용됩니다(그림 2). 키 변환: 쿼리 및 키 벡터는 때때로 시각화에서 잘 분리됩니다(그림 3, 왼쪽). 이러한 분리로 인해 쿼리 및 키 임베딩을 직접 비교하기 어렵습니다. 그러나 간단한 수학적 트릭을 사용하면 주어진 입력 시퀀스에 대한 셀프 어텐션 계산에 영향을 주지 않고 이러한 임베딩을 서로 더 가깝게 이동할 수 있습니다. 특히, 소프트맥스 함수는 변환 불변입니다. 즉, 모든 상수 a에 대해 소프트맥스; (x1+a, x2 + a,...) = 소프트맥스; (x1, x2,...)가 있습니다. 이제 쿼리 벡터 x와 키 벡터 y₁,...,yn을 고려합니다. 모든 벡터 v에 대해 다음이 있습니다. 어텐션; (x) = 소프트맥스; ((x, y₁), (x, y2),...) = softmax; ((x, y₁)+(x, y), (x, y2) + (x, v),...) = softmax;((x,y1+v), (x, y2+v), ...) 여기서 두 번째 단계는 변환 불변성에 따릅니다. 즉, 주어진 입력에서 어텐션 패턴을 변경하지 않고도 모든 키 벡터를 변환하여 각 어텐션 헤드의 쿼리 및 키 분포가 동일한 중심을 가질 수 있습니다. 이렇게 하면 쿼리와 키를 훨씬 더 쉽게 비교할 수 있습니다(그림 3, 오른쪽). 쿼리 및 키 크기 조정: GPT-2와 같은 일부 변환기에서 평균 쿼리 규범이 평균 키 규범과 매우 다른 경우를 관찰했습니다. 이 차이로 인해 조인트 임베딩에서 키-쿼리 관계를 해석하기 어렵습니다. 수학적으로 이는 점곱과 거리 간의 관계가 좋지 않음을 나타냅니다. 시각적으로 쿼리는 느슨한 키 클라우드로 둘러싸인 작은 클러스터일 수 있음을 의미합니다. (a) 거리 (b) 그림 4: (a) 더 높은 점곱을 갖는 쿼리-키 쌍이 공동 임베딩 공간에서 더 가까운 이상적인 거리-주의 관계. (b) BERT에서 쿼리-키 거리와 점곱 사이에 강한 음의 상관관계(-0.983)가 있는 예시 주의 헤드. 다행히도 스케일은 시스템의 또 다른 &quot;자유 매개변수&quot;입니다. 셀프 어텐션 수준은 쿼리와 키 벡터의 점곱에만 의존하므로 모든 쿼리 벡터를 c + 0의 인수로 스케일하고 모든 키 벡터를 c-1의 인수로 스케일하면 어텐션 값은 변경되지 않습니다. 이를 통해 그림 4a에 나와 있는 것처럼 조인트 시각화에서 높은 어텐션 쿼리-키 쌍이 서로 더 가까이 있을 수 있습니다. (미묘한 점: 스케일링 자체로는 코사인 거리가 변경되지 않지만 변환 정규화와 결합하면 사소하지 않은 효과가 있습니다.) c의 최적 값을 결정하기 위해 조인트 시각화에서 근처 쿼리와 키에 가장 관심이 있으므로 거리가 짧은 쿼리-키 쌍에 더 큰 가중치를 두는 가중 상관 관계 메트릭을 정의할 수 있습니다. 따라서 쿼리-키 점곱과 거리 간의 가중 상관 관계가 최대화되도록 스케일 인자 c를 선택할 수 있습니다. 이 스케일링 방법을 사용하면 조인트 임베딩 공간의 거리가 쿼리와 키 간의 실제 어텐션 값을 가장 정확하게 나타낼 수 있습니다. 5.1.2 주의의 대리로서의 거리 위에서 설명한 대로 이상적으로는 쿼리-키 쌍이 크고 양의 점곱(높은 최종 자기 주의 값에 해당)을 갖는 경우 임베딩 공간에서 서로 더 가깝게 배치해야 하며 그 반대의 경우도 마찬가지입니다(그림 4a). 따라서 우리는 공동 쿼리-키 임베딩에서 거리가 주의와 반비례할 것으로 예상합니다. 우리는 BERT, GPT-2 및 ViT에서 각 주의 헤드에 대한 코사인 거리와 점곱 간의 스피어만 순위 상관 관계를 계산하여 이 잠재적인 연결을 연구합니다. 또한
--- EXPERIMENT ---
영어: t-SNE 및 UMAP 투영을 쿼리와 키로 생성할 때 유클리드 거리를 거리 측정 기준으로 사용했지만, 일반적으로 거리-점적 상관 관계가 약해졌습니다. 여러 데이터 세트와 모델에서 거리와 주의 간의 관계는 상당히 잘 유지됩니다. 예를 들어 Wiki-Auto 데이터[23]에서 쿼리-키 거리와 점적 간의 평균 상관 관계는 BERT의 경우 -0.938이고 GPT의 경우 -0.792입니다. BERT의 예시 결과는 그림 4b에 나와 있습니다. 사용된 COCO 이미지 세트[28]에서 평균 상관 관계는 ViT-32의 경우 -0.873이고 ViT-16의 경우 -0.884입니다. 5.2 색상 인코딩 쿼리와 키의 다양한 속성을 시각화하기 위해 Attention Viz는 다양한 색상 인코딩을 제공합니다. 기본 옵션은 토큰 유형(예: 쿼리 또는 키)별로 포인트에 색상을 지정합니다. 비전 변환기의 경우 사용자는 이미지 패치 행 또는 열별로 색상을 지정하여 위치 패턴을 시각화할 수 있습니다(그림 10). 이미지는 자체 색상 정보를 인코딩하므로 사용자가 추가 스타일 요소 없이도 원본 패치를 볼 수 있도록 허용합니다(그림 8). 언어 변환기의 경우 정규화된 것과 불연속적인 것의 두 가지 위치 색상 구성표를 지원합니다. 정규화된 위치를 계산하기 위해 문장에서 각 토큰의 위치를 문장 길이로 나누어 연속적인 색상 척도를 생성합니다. 더 밝은 색조는 토큰이 문장의 시작 부분에 더 가까움을 나타냅니다(그림 5b). 불연속 위치 인코딩은 각 토큰의 위치를 가져와 모듈로 연산자를 적용하여 5로 나눈 나머지를 구합니다. 따라서 1번째와 6번째 토큰은 같은 색상을 받고, 2번째와 7번째 토큰은 같은 색상을 받습니다. 우리는 동일한 5가지 색상을 사용하여 다른 위치의 쿼리와 키를 인코딩하고, 전자의 경우 더 어두운 색조를 사용합니다. 영어: 이 계획은 (b) 주의 Viz 단일 보기 클릭하여 주의를 탐색합니다.모델 bert 투영 tsne V 검색 예: cat, april 레이블 주의 선 표시 점 크기 표준에 따른 크기 조정 색상 위치 a 모드 2D 3D 색상 정보: 어둠은 문장 내 토큰 위치를 인코딩합니다(정규화됨) 데이터 정보: 5056개 토큰(84개 문장) 기반 인접 헤드 보기 (a) L2 HL2 HL2 HL2 HL2 HL2 HL2 HL2 HL2 HLHL3 HL3 HL3 HL3 HL3 HL3 H(c) Laye.Headgo로 확대/축소 재설정 모든 헤드 보기 정보 C 문장 보기(L3 H9) 재설정 | clear 토큰을 클릭하여 줄을 끄거나 켜십시오 L3 HHide Icls] [sep] 쿼리 [CLS] 키 [CLS] [1] 10:finals 9:cup 11:were 10:finals it it marked marked the the stanley first first cup (키, 위치: 9/18) time time that the the stanley stanley CUD cup finals were broadcast american finals [els] were broadcast 8tificat .18: [sep] on american first network television network television [SEP] [SEP] 2:marked 3:the 18: [sep] 그림 5: BERT에서 함수에 대한 연결 형식. (a) Matrix View에서 레이어 3에 나선형 플롯이 여러 개 있습니다. (b) Single View를 사용하여 이러한 헤드 중 하나(L3 H9)를 확대하면 입력 시퀀스의 위치를 인코딩하는 밝은 색에서 어두운 색으로의 색상 구성표를 사용하여 위치 주의 패턴을 볼 수 있습니다. (c) 이러한 패턴은 문장 수준의 시각화를 탐색하여 확인할 수 있습니다. (a) (b) ⚫ april march october april (6개 결과) a ⚫ february ⚫ april april ● april march may march ⚫ june L2 HL2 Hཡ་ཁ • aprilbapril ● marcharch march march ⚫ june ⚫ may L3 HL3 HL3 HL3 HL3 H그림 6: 글로벌 검색을 통한 주의 패턴 탐색. (a) 검색 결과 클러스터가 적은 헤드는 더 많은 의미적 행동을 보이는 반면, 결과가 분산된 헤드는 토큰 위치에 더 집중합니다. (b) 주요 결과 클러스터가 하나인 헤드인 L2 H6를 확대하면 실제로 의미적으로 관련된 쿼리와 키 토큰의 큰 그룹을 볼 수 있습니다. 영어: 길이가 &gt; 5인 문장의 모호성 때문에, 우리는 작은 위치 오프셋(예: 그림 11, 왼쪽에서와 같이 한 단계 떨어진 키에 주의를 기울이는 쿼리)을 기반으로 관계를 보는 데 이산적 색칠이 도움이 된다는 것을 알았습니다. 모호성은 토큰 위에 마우스를 올려놓으면 쉽게 해결되고, 우리의 탐색에서 오프셋이 2 또는 3보다 큰 패턴은 보지 못했습니다. 사용자는 쿼리/키 규범에 따라 색칠할 수도 있습니다(그림 12a). 5.3 뷰 Attention Viz는 주의 탐색을 위한 세 가지 주요 대화형 뷰를 제공합니다. 행렬 뷰, 단일 뷰, 문장/이미지 뷰입니다. 5.3. 행렬 뷰 AttentionViz의 초기 뷰는 행렬 뷰로, 작은 배수를 사용하여 변환기의 모든 주의 헤드를 한 번에 시각화하여(그림 5a) [T1]과 [T3]을 직접 다룹니다. 각 행은 모델 계층에 해당하며 인터페이스 상단의 이전 계층에서 하단의 이후 계층으로 이동합니다. 이 &quot;전역적&quot; 관점을 통해 사용자는 단일 플롯(예: [53]) 또는 인스턴스 수준 시각화(예: [3,47])에 비해 다양한 변압기 계층과 헤드에서 패턴을 보다 쉽게 스캔할 수 있습니다. 이 작업에 사용된 모든 모델은 동일한 아키텍처를 가졌습니다. 계층당 12개 계층 x 12개 헤드 = 총 144개 어텐션 헤드이지만, 시스템은 다른 차원으로 확장됩니다. Matrix View에서 사용자는 t-SNE, UMAP 또는 PCA로 만든 공동 쿼리 키 임베딩을 볼 수 있습니다. 또한 모델 유형(예: BERT, GPT-2, ViT-16/32) 또는 데이터 세트[T4] 간에 전환하고, 다양한 색 구성표를 탐색하고, 결과 플롯을 2D 또는 3D로 볼 수도 있습니다. Matrix View는 글로벌 검색 기능(그림 6a)을 지원하여 다양한 헤드에서 토큰 위치의 패턴을 강조 표시하고 규모에 맞게 어텐션을 분석하는 또 다른 방법을 제공합니다(섹션 7 참조). 5.3.2 단일 뷰 사용자는 매트릭스 뷰에서 어떤 플롯을 클릭해도 단일 뷰로 확대할 수 있습니다(그림 5b).단일 뷰에서는 단일 어텐션 헤드를 더 자세히 살펴볼 수 있습니다[T3].매트릭스 뷰와 마찬가지로 사용자는 단일 뷰에서 색상, 차원, 투영 모드, 데이터 세트, 모델을 전환할 수 있습니다[T4].모든 그래픽 변경 사항은 뷰 간에 동기화되어 비교를 용이하게 합니다.사용자는 지점을 클릭하여 해당 입력 시퀀스의 모든 토큰을 강조 표시하여 공동 임베딩 공간에서 관련 쿼리와 키를 강조 표시할 수 있습니다.또한 사용자는 쿼리와 키 토큰을 연결하는 산점도에 어텐션 선을 투영할 수 있습니다(그림 5c).가독성을 높이기 위해 각 토큰에 대해 상위 2개의 어텐션 가중치만 표시합니다.어텐션 선 기능은 [T2]를 지원하며 헤드 수준에서 변환기의 어텐션 패턴을 시각화하는 새로운 방법을 제공합니다.단일 뷰에서 사용자는 토큰을 검색하고 레이블링 기능을 사용하여 [47]과 유사하게 데이터의 의미 패턴을 발견할 수도 있습니다. 예를 들어, 그림 6b에서 검색은 유사한 의미를 가진 쿼리/키 토큰이 이 BERT 헤드의 조인트 임베딩에 함께 배치되어 있으며, 이는 토큰 간에 강력한 주의를 나타낸다(5.1.2절). 5.3.3 문장/이미지 뷰 문장/이미지 뷰는 단일 문장이나 이미지 내의 세분화된 주의 패턴을 탐색할 수 있게 해준다[T2, T3]. 두 뷰 모두 (a) (b) (c) (d) 다른 이미지 토큰으로<CLS> 자신에게<CLS> 토큰 Le HBrightness Attention L1 HSynthetic Dataset Hue Attention ☐ ☐ Attention Pattern 그림 7: ViT 이미지 보기. (a) 원본 이미지. (b) 투명도 주의 열지도. 녹색 테두리로 선택된 토큰(쿼리)을 강조 표시합니다. (c) 오버레이된 주의 화살표. (d) 글로벌 주의 흐름. 정사각형 아이콘은 이미지 패치가 가장 강력한 주의 연결을 가지고 있음을 의미합니다.<CLS> 영어: 토큰은 원본 이미지에 없습니다. Single View와 동기화되어 각 쿼리/키 산점도에 중첩된 주의 선을 일치시켜 원활한 사용자 경험을 제공합니다. 문장 보기. BERT 또는 GPT-2를 사용할 때 사용자는 Single View에서 지점을 클릭하여 왼쪽 사이드바에 문장 보기를 열 수 있으며, 여기에는 클릭한 토큰이 강조 표시된 BertViz에서 영감을 받은 문장 수준 주의 시각화가 표시됩니다[53](그림 5c). 또한 히트맵 시각화(예: [39])를 사용하는 것도 고려했지만, 이분 그래프 방식이 긴 문장에 대한 가독성과 패턴 탐색의 용이성을 더 높여 줄 것으로 보였습니다. 왼쪽 열의 쿼리 토큰과 오른쪽 열의 키 토큰을 연결하는 선의 불투명도는 해당 주의 강도를 나타냅니다. 토큰 위에 마우스를 올려 놓으면 토큰별 주의 선이 강조 표시됩니다. BERT의 분류 토큰과 구분 기호 또는 GPT-(Sec. 7)의 첫 번째 토큰에서 발생하는 노이즈를 줄이기 위해 사용자는 이러한 특수 토큰에서 주의 선을 숨길 수 있습니다. 다른 토큰과 주요 토큰도 켜거나 끌 수 있으며, 모든 주의 쿼리 라인은 이에 따라 재정규화됩니다. 사용자는 각 주의 헤드에 대한 집계 주의 패턴을 보고 다른 비교 계층을 제공할 수도 있습니다(그림 11a). 이미지 보기. ViT의 이미지 기반 입력의 경우 사용자가 이미지 패치를 클릭하면 측면 패널에 해당 원본 이미지가 표시되고 클릭한 토큰이 색상 테두리로 강조 표시됩니다(그림 7a). 사용자는 주의 히트맵이 중첩된 이미지도 볼 수 있으며, 여기서 투명도는 클릭한 이미지 패치와 이미지의 다른 영역 간의 주의 가중치를 나타냅니다(그림 7b). 단일 토큰의 주의를 시각화하는 것 외에도 이미지 보기를 사용하면 다른 이미지 패치 사이에 화살표가 있는 주의 선을 표시하여 이미지 내의 전반적인 주의 패턴을 탐색할 수 있습니다. 주의 화살표를 시각화할 때 사용자에게 두 가지 옵션을 제공합니다. 첫 번째 옵션은 원본 이미지 패치 위에 화살표를 중첩하며, 각 화살표는 시작 이미지 패치와 대상 패치 간의 가장 강력한 주의 연결을 나타냅니다(그림 7c). 이것은 사용자가 특정 헤드 내에서 가장 중요한 패턴을 특성화할 수 있도록 단순화된 이분 어텐션 그래프를 생성합니다.두 번째 옵션은 원본 이미지 옆에 모든 강력한 어텐션 연결(즉, attn(x¡,x;) &gt; 0.1)을 표시하여 어텐션에 대한 보다 포괄적인 보기를 제공합니다(그림 7d).이 시각화에서는 불투명도와 선 두께가 모두 어텐션 연결의 강도를 인코딩하는 데 사용됩니다.또한 [53]을 보다 밀접하게 반영하기 위해 쿼리와 키 사이의 모든 가중치를 시각화하려고 시도했지만, 이는 종종 혼잡하고 이해할 수 없는 결과를 생성했습니다.6 시스템 구현 모델 입력을 처리하고 어텐션 정보를 계산하기 위해 Hugging Face Transformers 라이브러리와 PyTorch를 사용합니다.Google과 OpenAI의 모델 가중치와 함께 BERT, GPT-2(소형), ViT-16/32의 사전 학습된 구현을 사용합니다. 각 NLP 데이터 세트에 대해 무작위로 그림 8: ViT-32 Matrix View에서 두 개의 흥미로운 시각적 주의 헤드를 찾았습니다. 한 헤드는 밝기에 따라 흑백 이미지 토큰을 정렬하고 다른 헤드는 색조에 따라 다채로운 패치를 정렬합니다. 이미지 뷰에 표시된 주의 패턴은 동일한 밝기의 패치 간의 주의 흐름을 확인합니다. 200개의 문장을 샘플링합니다(쿼리와 키를 모두 포함하여 주의 헤드당 약 10,000개의 토큰). 이미지 주의 데이터의 계산 크기가 증가했기 때문에 ViT-16의 경우 헤드당 10개의 이미지(1,000개의 토큰)를 표시하고 ViT-16의 경우 헤드당 4개의 이미지(1,576개의 토큰)를 표시합니다. 더 큰 데이터 세트는 시스템 대기 시간이 증가하는 대가로 Attention Viz에 입력할 수 있습니다. 현재 각 NLP 데이터 세트를 로드하는 데 약 6초가 걸리고 ViT-16 데이터를 로드하는 데 약 초가 걸립니다. 각 어텐션 헤드에 대한 쿼리 및 키 벡터 임베딩을 추출한 후, 해당 2D/3D t-SNE, UMAP 및 PCA 좌표를 생성합니다(5.1절). ViT에서 이미지 패치에 대한 의미 레이블(예: &quot;개&quot; 또는 &quot;배경&quot;)을 생성하기 위해 DeepLabv3 분할 모델[7]을 사용합니다. 전체적으로 NVIDIA AGPU에서 각 BERT/GPT-2 데이터 세트를 사전 처리하는 데 약 시간이 걸리고, ViT-32의 경우 약 30분이 걸립니다. 최종 Attention Viz 프로토타입은 Vue 및 Typescript로 작성된 프런트엔드와 통신하는 Python/Flask 백엔드로 구성됩니다. 데모 시스템은 http://attentionviz.com에서 사용할 수 있습니다. 데이터의 크기가 크고 브라우저 메모리 제약이 있기 때문에 백엔드를 통해 JSON 파일을 통해 미리 계산된 어텐션/투영 정보를 로드합니다. ViT의 경우 백엔드는 프런트엔드에 표시하기 위해 이미지 조작(예: 패치 강조 표시 및 투명도 조정)도 수행합니다. 우리는 Deck.gl을 사용하여 결과 쿼리-키 조인트 임베딩을 시각화합니다.Attention Viz는 매우 확장성이 뛰어나고 모델에 독립적이어서 사용자가 시스템에 새로운 변환기와 데이터 세트를 추가할 수 있습니다.7 발견 및 평가 세 가지 응용 프로그램 시나리오와 도메인 전문가의 피드백을 통해 Attention Viz의 유용성을 설명합니다.우리의 시나리오는 섹션 4의 목표를 목표로 하며 AttentionViz가 시각 및 언어 변환기에서 글로벌 자기 주의 추세에 대한 통찰력을 어떻게 제공할 수 있는지 보여줍니다.데이터.BERT/GPT-2의 경우 다양한 NLP 데이터 세트를 실험했지만 응용 프로그램 시나리오에서는 두 가지에 집중했습니다.우리는 Wiki-Auto[23]를 기준으로 일반적인 입력 문장을 샘플링하고 SuperGLUE AX[56]를 사용하여 텍스트 함의에 대한 작업별 주의 패턴을 탐색합니다.ViT의 경우 ImageNet[44]과 Microsoft COCO[28]의 이미지와 합성 이미지 데이터를 샘플링합니다.사용자 인터뷰. 우리는 E2와 E3를 2차 인터뷰에 초대했고, E6(해석 연구자)와 E7(시각 과학 박사 과정 학생)이라는 두 명의 새로운 전문가를 포함시켰습니다. 4절에서와 마찬가지로 모든 전문가는 개별적으로 인터뷰를 받았습니다. 우리는 먼저 전문가들에게 우리 도구에 대한 간단한 데모를 제공하고, 우리의 발견 사항 중 일부를 공유하면서, 생각이나 통찰력을 공유해 달라고 요청했습니다(7.1-7.3절). 그런 다음, Attention Viz의 주요 강점, 약점, 참신함에 대한 보다 일반적인 피드백을 요청했습니다(7.4절). 또한, 전문가들에게 이 기술을 확장하여 대규모 임베딩을 시각화하는 데 사용할 수 있는 가능성에 대해서도 물었습니다. 수직 그룹 대각선 그룹 L1 H수평 그룹<CLS><CLS><CLS> 공간 패턴 증가 주파수 저주파 고주파 수직 패턴 대각선 패턴 수평 패턴 그림 9: 왼쪽: 주파수와 각도가 다른 공간 패턴의 데이터 세트.중앙: 단일 보기에서 ViT-32의 한 어텐션 헤드가 공간 패턴의 주파수와 각도에 따라 이미지 토큰을 배열하는 것을 관찰합니다.오른쪽: 이미지 보기의 어텐션 히트맵은 이러한 결과를 더욱 확인합니다.비슷한 각도의 공간 패턴은 서로에게 더 큰 주의를 기울입니다.7.1 목표: 머신 시각적 어텐션 이해 어텐션 Viz는 이미지 패치 데이터의 본질적인 시각적 특성으로 인해 시각 변환기에서 어텐션에 대한 새로운 통찰력을 발견하는 데 특히 도움이 될 수 있습니다[G1].시각적 어텐션의 색조/밝기 특수화.어떤 시각적 어텐션 헤드가 색상 기반 패턴과 밝기 기반 패턴 중 하나를 전문으로 하는지 궁금했습니다.이를 테스트하기 위해 사전 학습된 ViT32 모델에 합성 색상 및 밝기 그라데이션 이미지(그림 8)를 제공하고 결과 쿼리와 키 토큰을 어텐션 Viz에 로드했습니다. Matrix View에서 글로벌 PCA 패턴을 탐색하면서 색상과 무색 시각과 유사한 두 개의 어텐션 헤드를 식별했습니다. 한 헤드는 밝기에 따라 흑백 이미지 토큰을 정렬하는 것처럼 보이고, 다른 헤드는 색조에 따라 다채로운 패치를 정렬합니다. 저희 데이터 세트에는 모든 방향의 색상 및 밝기 그라데이션 이미지가 포함되어 있으며, 원본 이미지에서의 위치와 관계없이 조인트 임베딩 공간에서 유사한 패치가 함께 클러스터링되는 것을 볼 수 있습니다. Image View의 어텐션 히트맵은 이러한 결과를 확인합니다. 토큰은 동일한 색상이나 밝기를 가진 다른 토큰에 가장 많은 주의를 기울입니다. E7은 이전에 합성곱 신경망(CNN)의 색상 잠복 공간을 연구한 적이 있어 이러한 결과에 흥미를 느꼈고, 저희 도구를 사용하여 CNN과 ViT 동작의 차이점을 더 탐구하는 데 관심을 표명했습니다. 주파수 필터링 및 각도 감지. 주파수와 각도는 이미지 데이터의 저수준 특성입니다. 비전 변환기에 이러한 특징을 기반으로 시각적 패턴을 연관시키는 어텐션 헤드가 있는지 조사하기 위해 저희는 다양한 주파수와 방향을 가진 사인파 신호의 이미지를 생성하여 사전 학습된 ViT-32 모델을 사용하여 처리했습니다. Matrix View에서 결과 쿼리와 키 임베딩을 검토한 결과, 공간 패턴의 빈도(x축)와 각도(y축)를 기준으로 이미지 토큰을 구분하는 어텐션 헤드를 식별했습니다(그림 9). Image View를 통해 동심원 이미지의 토큰이 유사한 곡률을 가진 다른 토큰에 주의를 기울이는 것을 관찰하여 이 어텐션 헤드가 각도를 기준으로 시각적 패턴을 연관시킨다는 것을 더욱 확인했습니다. E7은 이 결과가 흥미롭지만 색조/밝기 결과를 감안하면 그다지 놀랍지 않다고 말했으며, 이러한 &quot;유사한 패치에 주의를 기울이는&quot; 행동을 보이지 않는 헤드에 대해 더 궁금했습니다. 그들이 제안한 한 가지 실험은 어텐션 변조를 연구하는 것이었습니다. 예를 들어, 동일한 이미지 패치(예: 수직 줄무늬)가 두 이미지(예: 얼룩말 대 우산)에서 다른 맥락에서 발생하는 경우 고유한 어텐션 패턴을 볼 수 있을까요? 모델 계층에서 어텐션 거리를 증가시킵니다. [14]에서 언급했듯이, 자기 어텐션은 비전 변환기의 더 깊은 계층에서 이미지 전반에 걸쳐 더 광범위하게 주의를 기울입니다. AttentionViz에서 쿼리와 키 토큰의 상호 작용적인 공동 시각화를 사용하여 이 발견을 확인했습니다. Matrix View를 사용하여 이미지 &quot;행&quot;과 &quot;열&quot;별로 패치를 색칠하여 ViT-32의 레이어 1과 2에서 토큰을 가장 가까운 공간적 이웃과 그룹화하는 네 개의 어텐션 헤드를 찾았습니다. 왼쪽, 오른쪽, 위, 아래에 있습니다. 레이어 3과 4에서 유사한 위치 어텐션 패턴을 보았지만 이미지 토큰은 가장 가까운 이웃을 넘어 같은 행이나 열에 있는 모든 패치에 주의를 기울입니다(그림 10). 이는 정사각형 필터를 사용하여 이미지를 처리하는 CNN과 달리 변환기의 셀프 어텐션 메커니즘은 종종 행별로 이미지를 처리하고<CLS> L1 그 L4 H<CLS> LayerLayerIncreasing Attention Distance 그림 10: 행별로 이미지 패치를 색칠하면 ViT-32에서 위치적 주의 패턴이 강조 표시됩니다.Layer 1에서 같은 행과 인접한 열의 토큰이 작은 클러스터를 형성합니다.Image View에서 왼쪽 패턴을 볼 수 있습니다.Layer 4에서 행 위치를 기준으로 큰 토큰 클러스터가 형성됩니다.화살표로 표시된 선을 사용하면 더 넓고 양방향의 주의 흐름이 보입니다.열별로, 길쭉한 필터와 유사합니다.7.2 목표: 글로벌 주의 추적 찾기 언어 변환기[G2]에서 자기 주의 패턴이 다른 헤드에서 어떻게 달라지는지 이해하기 위해 Attention Viz를 사용하여 BERT를 탐색했습니다.위치적 주의 시그니처.TSNE를 사용하여 고유한 모양을 가진 여러 주의 헤드를 관찰했습니다(예: 레이어 3의 나선형 플롯(그림 5a).예를 들어, Single View에서 정규화된 위치에 따라 레이어 3 헤드 9를 색칠하면 나선형의 바깥쪽에서 안쪽으로 이동함에 따라 토큰 위치가 증가함을 알 수 있습니다(그림 5b). 우리는 문장 뷰를 사용하여 이 패턴을 더 자세히 조사했고(그림 5c), 위치적 &quot;다음 토큰&quot; 주의 패턴이 있음을 확인했습니다. 이 &quot;나선형&quot;은 또한 변환기에 주어진 초기 순서 벡터를 반영합니다(2절). 그런 다음 우리는 Matrix View에서 다른 식별 가능한 &quot;흔적&quot;을 발견했고, 작은 &quot;클럼프&quot;가 있는 플롯도 위치 패턴을 인코딩한다는 것을 발견했습니다(그림 11, 왼쪽). 우리는 이를 이산 위치 채색으로 검증했습니다. &quot;나선형&quot;과 &quot;클럼프&quot;의 차이는 토큰이 한 위치 떨어진 다른 토큰에 선택적으로 주의를 기울이는지, 아니면 여러 다른 가능한 위치에 주의를 기울이는지에 달려 있는 것 같습니다(그림 5c). 마찬가지로, 우리는 높은 쿼리-키 중복이 있는 헤드에서 토큰이 일반적으로 자신과 동일한 토큰의 다른 인스턴스에 주의를 기울여 &quot;자신을 보는&quot; 패턴을 보인다는 것을 알게 되었습니다. 이러한 헤드를 확대하면 근처 쿼리-키의 명확한 의미 클러스터가 보입니다. 집계 보기(L2 H0) 쿼리 문장 보기(L8 H4) 쿼리 키 키 [CLS] [CLS]thesides sidescame cameto toanagreement agreementafter aftertheir theirmeeting meetingin in sweden swedenthe thesides sides cameto to an L2 HØ agreement agreement after after their meeting their meeting in stockholm stockholm [SEP] [SEP] L8 H그림 11: 주의의 다른 시각적 흔적. 왼쪽: 작은 &quot;클럼프&quot;가 있는 헤드는 종종 나선형보다 더 좁은 위치 패턴을 갖습니다. 각 토큰을 위치 모듈로 5에 따라 색칠하는 이산 위치 인코딩은 &quot;다음 토큰&quot; 주의 추세를 강조합니다. 오른쪽: 쿼리와 키의 계층화된 밴드는 SuperGLUE AXɓ 데이터[56]는 텍스트 시작, 끝 및 중간 지점에 대한 강한 주의를 나타냅니다.그림 6b에 표시된 쌍은 이 관찰을 더욱 뒷받침합니다.[29]는 초기 변압기 레이어가 선형 단어 순서에 대한 가장 많은 정보를 가지고 있음을 보여주며, 이는 [9,53]과 같은 우리의 연구 결과 및 이전 작업과 일치합니다.인터뷰 중에 E2, E6 및 E7은 이러한 흥미로운 기하학, 특히 나선형을 즉시 알아차리고 관찰된 구조 중 얼마나 많은 부분이 위치에 의한 것인지 궁금해했습니다.이는 전문가들로부터 여러 후속 실험 아이디어, 예를 들어 변압기 모델에서 위치 임베딩을 조작하거나 제거하고 쿼리 키 시각화가 어떻게 변경되는지 확인하는 데 영감을 주었습니다.작업별 추적.Attention Viz로 여러 데이터 세트를 시각화한 후, 조인트 임베딩의 모양이 다양한 NLP 작업에서 매우 일관적임을 발견했습니다.그러나 SuperGLUE AX 데이터(그림 11, 오른쪽)가 있는 BERT의 일부 후속 레이어에서만 발생하는 하나의 시각적 추적을 보았습니다. 그러한 헤드(레이어헤드 9) 중 하나를 클릭하고 위치별로 색칠한 결과, 텍스트 시작 부분의 키와 쿼리가 맨 위에 쌓이고, 그 다음에 텍스트 끝에 쿼리와 키가 역순으로 쌓이는 쿼리-키 &quot;샌드위치&quot;를 관찰했습니다. 문장 보기는 텍스트의 시작, 중간, 끝이 가장 많은 주의를 받는다는 것을 보여줍니다. 전반적인 플롯 모양과 주의 패턴은 이러한 헤드가 텍스트의 &quot;중간점&quot;을 식별하고 문장을 구별할 수 있음을 시사하는데, 이는 함축 작업에서 두 문장을 비교하여 유사한 의미가 있는지 확인하는 방식과 유사합니다. 질의는 또한 대부분 동일한 문장의 키에 주의를 기울입니다. [25,54]는 구문 및 작업별 정보가 중간에서 후반 모델 계층에서 가장 두드러지는 방식을 보여주며, 아마도 이 추적의 고유성을 설명하는 것일 수 있습니다. 글로벌 검색 패턴. Matrix View의 집계 검색 기능을 사용하여 헤드 전체에서 주의 추세를 빠르게 스캔하고 비교할 수도 있습니다[G2]. 검색 결과의 패턴은 이전에 식별된 시각적 주의 추적(그림 6a)을 반영한다는 것을 발견했습니다. 예를 들어, 나선형이거나 작은 덩어리의 질의/키가 있는 헤드는 더 분산된 검색 결과를 가지며, 이는 기본 위치 주의 패턴을 나타냅니다. 반면, &quot;자기 보기&quot; 주의 패턴을 가진 헤드는 검색 결과 클러스터가 하나뿐이어서 동일한 토큰의 질의와 키 간의 강력한 상호 작용을 강조합니다. 조인트 쿼리-키 임베딩에 독특한 모양이 없더라도 검색 결과 클러스터가 몇 개뿐인 경우 헤드가 더 많은 의미적 행동을 보일 수 있음을 알 수 있습니다.그렇지 않으면 위치적 주의 패턴이 있을 가능성이 높습니다.[49]에 따르면 의미 정보는 BERT의 여러 계층에 분산되어 있으며, 이는 Attention Viz로 확인했습니다.모든 전문가는 특히 도구의 이 기능과 주의 패턴 비교를 용이하게 하는 기능에 흥분했습니다.7.3 목표: 이상 및 예상치 못한 동작 식별 AttentionViz의 조인트 쿼리-키 임베딩과 상호 작용하여 몇 가지 불규칙한 모델 동작을 발견했습니다[G3].규범 불일치 및 null 주의. Matrix View에서 GPT-2를 탐색하는 동안 초기 모델 계층에서 일부 쿼리와 (a) LO HLO Hq k (b) 첫 번째 토큰 쿼리 키 숨기기 이벤트 이벤트 수신 수신 &quot;지불 지불 당 숨기기 첫 번째 토큰 쿼리 키 이벤트 이벤트 수신 수신지불 ཕྲུ ༅ ་ ཕྱ ར ཟླ ་ རྗ ༔ ༅ ཟླ ༅ ་ ༈ ནྡྲ ་ ལཱ་པྲ ཾ་ སེ ་ ་ ༅ ནཱ་ ༄༅, ༦༢༅, རྡོཊྛིཋཱ╗༅,ཕྲུནྡོ, ཝཱ, རྡི ཙིཾ,per L1 HL1 Hview view view view buys buys buys down down down down from from from from the the the the L2 HL2previous previous previous previous year year year L3 HL3 Hevent ofeventbuysbuys year event event of ofbuys buys 그림 12: GPT-2의 이상 현상. (a) 초기 모델 계층에서 많은 어텐션 헤드(예: 표준 스케일링 이전의 Ll H8)에 대한 쿼리 키 표준 간에 상당한 차이가 있음을 확인했습니다. (b) 이후 계층에서 널리 퍼진 &quot;먼저 주의를 기울이는&quot; 패턴의 예입니다. 문장 보기에서는 첫 번째 토큰을 숨긴 후 잠재적 어텐션 행동을 보여줍니다. 키 클러스터는 잘 분리되었으며, 키 변환 후에도 그렇습니다(5.1.1절). 규범에 따라 색상을 지정하면(규범 스케일링 단계 전에 측정), 많은 헤드에서 쿼리 벡터와 키 벡터의 규범 사이에 상당한 차이가 있음을 알 수 있었습니다(그림 12a). 쿼리 규범이 작을 때(즉, 밝은 녹색), 키 규범은 커지는 경향이 있으며(즉, 진한 분홍색), 그 반대의 경우도 마찬가지입니다. GPT-2와 BERT에서 쿼리와 키 사이의 평균 규범 차이를 계산한 결과, 전자의 경우 어텐션 헤드 전체에서 평균 쿼리 규범 - 키 규범 = -4.59인 반면, 후자의 경우 평균 차이가 0.41에 불과함을 발견했습니다. 전문가 중 누구도 이 결과를 설명할 수 없었습니다. &quot;쿼리와 키의 규범이 왜 그렇게 다른지 전혀 이해가 되지 않습니다&quot;(E6). 흥미롭게도, 우리가 이 관찰을 한 후에 발표된 논문[11]은 통제 불능의 쿼리 및 키 규범이 심각한 훈련 불안정성의 원인이라고 지적하여 이 현상을 더 연구할 가치가 있음을 시사합니다. 이 관찰은 또한 Sec. 5.1.1의 스케일링 접근 방식에 영감을 주었습니다. 또한 많은 GPT-2 헤드에서 대부분의 주의가 첫 번째 토큰(그림 12b)으로 향한다는 것을 알아챘습니다. 특히 후반 레이어에서 그렇습니다. [54]는 &quot;주의 헤드가 포착한 언어적 속성이 입력 텍스트에 나타나지 않을 때&quot; GPT-2에서 첫 번째 토큰이 주의 수신을 위한 널 위치로 처리된다고 간략히 언급합니다. 그러나 이 현상은 여전히 충분히 탐구되지 않아 고려해야 할 또 다른 열린 해석 가능성 문제가 제기됩니다. E2와 E6은 모두 우리 도구를 사용하여 이러한 비정상적인 동작을 스스로 알아챘고, 모든 전문가가 이 결과에 놀랐습니다. [55]는 변압기의 대부분의 주의 헤드를 가지치는 것이 모델 성능에 큰 영향을 미치지 않을 수 있음을 보여줍니다. Le H(a) ,6) 2,6) (3,3) (b) 2,3) ,3) 4,2)<CLS> (c) 주요 매개변수 -1.-1.1.0.쿼리 대 주요 매개변수.선형 상관관계 r = 0.-2.-2.0 -15 -10 -0.5 0.0 0.5 10쿼리 매개변수 (d) 그림 13: ViT-32에서 &quot;자기 자신을 보는&quot; 어텐션 헤드 식별. (a) 단일 보기는 쿼리와 키가 조인트 임베딩 공간에 희소하게 분포되어 있음을 보여줍니다. (b) 확대하면 동일한 이미지 토큰의 쿼리 및 키 벡터가 단단히 겹쳐 있습니다. (c) 이미지 보기는 토큰이 자신에게 가장 많은 주의를 기울인다는 것을 보여줍니다. (d) 쿼리 및 키 투영 계층의 학습된 매개변수를 비교하면 중복된 투영을 학습한다는 것을 확인할 수 있습니다. 이는 아마도 이 지배적인 널 어텐션 패턴에 부분적으로 기인할 수 있습니다. 그럼에도 불구하고 어텐션 Viz를 사용하면 사용자가 첫 번째 토큰에 지불된 주의를 필터링하여 숨겨진 쿼리-키 상호 작용을 발견할 수 있습니다. &quot;자기 자신을 보는&quot; 어텐션 헤드. 어텐션 Viz는 또한 비전 변환기에서 놀라운 어텐션 패턴을 보여줄 수 있습니다. Matrix View에서 우리는 ViT-32의 초기 계층에서 매우 확산된 키-쿼리 클러스터를 가진 여러 헤드를 식별했습니다(그림 13a). 그러한 어텐션 헤드 중 하나(계층 0 헤드 8)를 살펴보면, 같은 토큰의 쿼리와 키 임베딩이 작지만 밀집된 클러스터를 형성하고 각 쿼리-키 쌍이 다른 쌍과 잘 분리되어 있음을 발견했습니다(그림 13b). Image View의 투명도 히트맵에서 패치가 자기 자신에게만 주의를 기울이고 있음을 알 수 있습니다(그림 13c). 화살표가 있는 주의 선으로 전환하면, 이 이미지의 전반적인 주의 패턴은 &quot;자기 자신을 보라&quot;는 것을 알 수 있습니다. 여기서 이 헤드의 이미지 토큰 간에는 정보가 흐르지 않습니다. 이 불규칙한 주의 패턴을 식별한 후, 상관 관계 테스트를 통해 쿼리와 키 행렬의 학습된 매개변수를 확인했습니다. 강력한 유사도 점수(선형 상관 관계 = 0.94)를 발견했는데, 이는 이 ViT 헤드의 쿼리와 키 레이어가 실제로 중복된 투영을 학습하고 있음을 나타냅니다(그림 13d). E3는 이 지식이 모델 가지치기 실험에 정보를 제공할 수 있으며, Attention Viz는 잠재적인 학습 실패 또는 기타 불규칙성을 감지하는 데 유사하게 사용될 수 있다고 언급했습니다. 7.4 사용자 피드백에서 얻은 Matrix View의 장점. 여러 전문가는 Matrix View가 제공하는 &quot;전역&quot; 관점이 Attention Viz의 가장 새롭고 가치 있는 부분이라고 생각했습니다. E6에서 말했듯이, &quot;빠른 비교에 유용하고 여러 임베딩을 한 번에 시각화하려고 할 때 하이퍼 매개변수를 조정할 필요가 없습니다.&quot; E7은 또한 Matrix View가 유용하다고 언급했습니다. &quot;작은 시각화의 경우, 제가 직접 코드를 작성할 수 있지만, 규모가 크고 데이터가 많을수록 훨씬 더 어렵습니다.&quot; 이러한 의견은 임베딩을 규모에 맞게 시각화하고 비교하는 이 아이디어가 다른 ML 설정에서도 유익할 수 있음을 시사합니다. 공동 쿼리 키 임베딩에 대한 응용 프로그램. 전문가들은 시각화 기술에 대한 다양한 사용 사례와 확장을 제안하여 더 광범위한 적용 가능성을 입증했습니다. 예를 들어, E2는 훈련되지 않았거나 손상된 변환기의 패턴을 시각화하는 것을 제안했고, E3과 E는 모두 원래 목표(4절)에 맞춰 자체 모델에 대한 훈련 중 주의의 변화를 시각화하기를 원했습니다. E2와 E6은 또한 인과 추적에 도움이 되도록 도구를 조정하는 것을 제안했으며, &quot;가설 검정을 위해 모델 전체에서 주의 흐름을 추적하는 것이 유용할 수 있습니다.&quot;라고 설명했습니다. 마찬가지로 E3는 &quot;두 주의 패턴이 다른 헤드에서 어떻게 연결되는지&quot;를 조사하는 데 관심을 표명했는데, 이는 확실히 유도 헤드 쌍을 시각화하는 데 적용될 수 있습니다. E2는 &quot;두 헤드 간의 유사성을 정량화하는&quot; 방법을 추가하는 것이 유용할 수 있다고 언급했고, E6는 모델 가지치기 목적으로 &quot;헤드의 무작위성을 측정하거나 시각화하는 것&quot;을 제안했습니다. 투영 임베딩 - 신뢰할지 말지? E3는 투영 방법을 사용하는 데 따르는 어려움을 강조했습니다. 그들은 우리가 발견한 놀라운 기하학적 패턴(예: 나선형)을 높이 평가했지만, E3는 t-SNE 및 UMAP와 같은 기술의 왜곡으로 인해 이러한 시각화를 해석하는 데 회의적이었습니다. &quot;내가 보는 것을 신뢰할 수 있는지 어떻게 알 수 있습니까?&quot; 이는 시각적 통찰력을 실행 가능한 개입에 연결하는 것의 중요성을 강조하는데, 아마도 탐색 외에도 가설 검정을 지원하기 위해 도구를 증강하는 것을 통해 그렇게 할 수 있습니다. 유연성-사용성 트레이드오프. E2는 Attention Viz가 &quot;매우 사용하기 쉽고 사용자 정의가 가능하다&quot;고 말했고, &quot;배우고 사용하기에 너무 어려운 기존 시각화 도구&quot;와 대조됩니다. 그러나 E6와 같은 일부 전문가는 &quot;모든 기능과 헤드를 보여주는 것이 압도적일 수 있다... 정보를 요약할 방법이 있을까? 아니면 특정 작업에 더 집중할 수 있을까?&quot;라고 여전히 우려했습니다. E7은 &quot;헤드에 레이블을 지정하는 더 빠르고 소화하기 쉬운 방법이 있을까?&quot;라고 덧붙이며 기능 시각화에 더 가까운 접근 방식을 제안했습니다[36]. 우리는 Attention Viz를 유연한 도구(예: 다양한 변환기와 다양한 세분성에서 주의 분석 허용)로 설계했지만, 설계의 유연성-사용성 균형[27]은 여전히 개선될 수 있는 것 같습니다. 추가 상호 작용 모드. 일부 전문가는 추가 상호 작용 모드, 예를 들어 즉석 추론(E3) 또는 쿼리와 키의 원형 클러스터에 대한 추가 차원 감소를 제안하여 추가 정보를 공개하고 세분화된 분석을 수행(E2)했습니다. E7은 사용자가 시스템에 새 데이터 세트를 직접 업로드할 수 있도록 하는 것의 중요성을 강조했습니다. &quot;이 도구는 훨씬 더 강력할 수 있습니다... 사람들은 자신의 이미지를 추가하는 것처럼 더 많이 탐색하고 싶어할 것입니다.&quot;
--- CONCLUSION ---
S &amp; 향후 작업 이 작업에서 우리는 쿼리와 키에 대한 공동 임베딩 공간을 기반으로 변환기 셀프 어텐션을 시각화하는 새로운 기술을 소개합니다. 이 기술을 적용하여 대화형 시각화 도구인 Attention Viz(데모: http://attentionviz.com)를 만들고 이를 사용하여 언어 및 시각 변환기 모두에서 어텐션에 대한 통찰력을 얻습니다. 예를 들어, ViT에서 새로운 색조/주파수 동작을 발견하고 GPT-2에서 눈에 띄는 쿼리 키 규범 차이를 발견합니다. 우리의 접근 방식은 셀프 어텐션에 맞춰져 있지만 벡터 정규화를 적절히 수정하면 다른 어텐션 메커니즘(예: 교차 어텐션)으로 일반화할 수 있습니다. 마찬가지로 의미 패턴에 초점을 맞추지만, 어텐션 Viz는 NLP 라이브러리를 사용하여 품사와 같은 메타데이터를 추가하는 것과 같이 구문적 특징을 연구하는 데에도 사용할 수 있습니다. 전문가 피드백은 또한 여러 임베딩 시각화의 복잡성을 관리하고 사용자를 관심 있는 기능에 집중시키는 방법을 찾는 것과 같은 향후 작업을 위한 여러 가지 방향을 제시합니다. 현재 저희 시스템은 데이터 사전 계산 시간과 메모리 요구 사항에 의해 제한을 받고 있지만, Attention Viz의 확장성을 개선하고 사용자가 즉시 새로운 입력을 추가할 수 있도록 할 계획입니다. 충분히 큰 임의 샘플(예: 수천 개의 토큰)은 대규모의 글로벌 현상을 표면화하기에 충분하지만, 더 큰 데이터 세트와 모델은 [38]에서 제안한 것처럼 추가적인 의미적 통찰력을 보여줄 수 있습니다. 다른 데이터 샘플링 접근 방식을 시도하는 것도 유익할 수 있습니다(예: Zipf의 법칙으로 인한 편향을 줄이기 위해 [62]). 미래 연구를 위한 또 다른 자연스러운 방향은 각 어텐션 헤드에 값 벡터의 정보를 통합하는 방법을 탐색하는 것입니다[52]. 이러한 값 벡터는 어텐션 메커니즘의 필수적인 부분이지만 쿼리와 키의 맥락에서 이를 시각화하는 방법은 명확하지 않습니다. 적절한 시각화 접근 방식을 찾으면 어텐션 헤드가 어떻게 기능하는지에 대한 이해가 더 깊어질 수 있습니다. 마지막으로, Attention Viz는 탐색 도구이지만 가설 검정 및/또는 인과 추적에 적용하면 실제 모델 디버깅에 대한 지원을 제공할 수 있습니다. 감사의 말 사용자 인터뷰에 참여해 주신 모든 분께 시간과 귀중한 통찰력에 감사드립니다. 또한 이 논문을 개선하는 데 철저하고 건설적인 의견을 주신 익명의 검토자분들께도 감사드립니다. 마지막으로 이 프로젝트 전반에 걸쳐 Harvard Insight + Interaction Lab 구성원들이 제공한 사려 깊은 피드백과 지원에 감사드립니다. 참고문헌 [1] E. Aflalo, M. Du, S.-Y. Tseng, Y. Liu, C. Wu, N. Duan, V. Lal. Vlinterpret: 시각 언어 변환기를 해석하기 위한 대화형 시각화 도구. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 논문집, 21406-21415쪽. IEEE, New Orleans, 2022. doi: 10.1109/CVPR52688.2022.02072[2] DL Arendt, N. Nur, Z. Huang, G. Fair, W. Dou. 병렬 임베딩: 학습된 표현을 대조하기 위한 시각화 기술. 제25회 국제 지능형 사용자 인터페이스 컨퍼런스 논문집, 259-274쪽. ACM, Cagliari, 2020. doi: 10.1145/3377325. 3377514[3] A. Boggust, B. Carter, A. Satyanarayan. 임베딩 비교기: 소규모 다중을 통해 글로벌 구조와 로컬 이웃의 차이점 시각화. 제27회 국제 지능형 사용자 인터페이스 컨퍼런스, 746-766쪽. ACM, 헬싱키, 2022. doi: 10.1145/3490099. 3511122 3,[4] M. Caron, H. Touvron, I. Misra, H. Jégou, J. Mairal, P. Bojanowski, A. Joulin. 자체 감독 비전 변환기의 새로운 속성. IEEE/CVF 컴퓨터 비전 국제 컨퍼런스 회의록, 9650-9660쪽. IEEE, 몬트리올, 2021. doi: 10.1109/ICCV48922. 2021.00951[5] S. Carter, Z. Armstrong, L. Schubert, I. Johnson, C. Olah. 활성화 아틀라스. Distill, 4(3), 2019. doi: 10.23915/distill.00015[6] H. Chefer, S. Gur, 및 L. Wolf. 주의 시각화를 넘어서는 Transformer 해석 가능성. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 782-791쪽. IEEE, 온라인, 2021. doi: 10.1109/CVPR46437.2021.00084[7] L.-C. Chen, G. Papandreou, F. Schroff, 및 H. Adam. 의미적 이미지 분할을 위한 아트로스 합성 재고. arXiv 사전 인쇄본, 2017. doi: 10.48550/arxiv. 1706.05587[8] EA Chi, J. Hewitt, 및 CD Manning. 다국어 BERT에서 보편적인 문법적 관계 찾기. Association for Computational Linguistics의 제58회 연례 회의록, 5564-5577쪽. ACL, 온라인, 2020년. doi: 10.18653/v1/2020. acl-main.493 2,[9] K. Clark, U. Khandelwal, O. Levy, CD Manning. BERT는 무엇을 살펴보는가? BERT의 주의 분석. 2019년 ACL 워크숍 BlackboxNLP: NLP를 위한 신경망 분석 및 해석, 276-286쪽. ACL, Florence, 2019년. doi: 10.18653/v1/W19-4828 2,[10] J.-B. Cordonnier, A. Loukas, and M. Jaggi. 자기 주의와 합성곱 계층 간의 관계에 관하여. 제8회 학습 표현 국제 컨퍼런스에서. 아디스아바바, 2020. doi: 10.48550/arxiv. 1911.03584[11] M. Dehghani, J. Djolonga, B. Mustafa, P. Padlewski, J. Heek, J. Gilmer, A. Steiner, M. Caron, R. Geirhos, I. Alabdulmohsin, et al. 비전 변환기를 220억 개의 매개변수로 확장. arXiv 사전 인쇄본, 2023. doi: 10. 48550/arxiv.2302.05442 1,[12] JF DeRose, J. Wang, and M. Berger. 주의 흐름: 언어 모델에서 주의 메커니즘 분석 및 비교. IEEE 시각화 및 컴퓨터 그래픽스 저널, 27(2):1160-1170, 2021. doi:.1109/TVCG.2020.3028976[13] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert: 언어 이해를 위한 딥 양방향 변환기의 사전 학습. arXiv 사전 인쇄본, 2018. doi: 10.48550/arxiv. 1810.04805 1,[14] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, et al. 이미지는 16x16 단어의 가치가 있습니다: 대규모 이미지 인식을 위한 변환기. 제9회 학습 표현 국제 컨퍼런스에서. 온라인, 2021. doi: 10.48550/arXiv.2010.11929 1, 2,[15] N. Elhage, T. Hume, C. Olsson, N. Schiefer, T. Henighan, S. Kravec, Z. Hatfield-Dodds, R. Lasenby, D. Drain, C. Chen, et al. 중첩의 장난감 모델. arXiv 사전 인쇄본, 2022. doi: 10.48550/arXiv. 2209.10652[16] N. Elhage, N. Nanda, C. Olsson, T. Henighan, N. Joseph, B. Mann, A. Askell, Y. Bai, A. Chen, T. Conerly, et al. 변압기 회로를 위한 수학적 프레임워크. Transformer Circuits Thread, 2021. https://transformer-circuits.pub/2021/framework/index.html.[17] A. Ghiasi, H. Kazemi, E. Borgnia, S. Reich, M. Shu, M. Goldblum, AG Wilson, and T. Goldstein. 시각 변압기는 무엇을 배울까요? 시각적 탐구. arXiv 사전 인쇄본, 2022. doi: 10.48550/arxiv.2212.06727[18] F. Hohman, M. Kahng, R. Pienta, and DH Chau. 딥 러닝의 시각적 분석: 차세대를 위한 질문 조사. IEEE 시각화 및 컴퓨터 그래픽스 저널, 25(8):2674-2693, 2018. doi:.1109/TVCG.2018.2843369[19] F. Hohman, H. Park, C. Robinson, DHP Chau. Summit: 활성화 및 속성 요약을 시각화하여 딥 러닝 해석 가능성 확장.IEEE 시각화 및 컴퓨터 그래픽스 저널, 26(1):1096-1106, 2019. doi: 10.1109/TVCG.2019.2934659[20] B. Hoover, H. Strobelt, S. Gehrmann. exBERT: Transformer 모델에서 학습된 표현을 탐색하는 시각적 분석 도구. 제58회 계산 언어학 협회 연례 회의록: 시스템 시연, 187-196쪽. ACL, 온라인, 2020. doi: 10. 18653/v1/2020. acl-demos.22 1,[21] T. Jaunet, C. Kervadec, R. Vuillemot, G. Antipov, M. Baccouche, and C. Wolf. Visqa: 트랜스포머에서의 X선 영상 및 언어 추론. IEEE 시각화 및 컴퓨터 그래픽스 저널, 28(1):976-986, 2022. doi: 10.1109/TVCG.2021.3114683[22] X. Ji, Y. Tu, W. He, J. Wang, H.-W. Shen, and P.-Y. Yen. Usevis: 정보 검색에서 주의 기반 신경 임베딩의 시각적 분석. Visual Informatics, 5(2):1-12, 2021. doi: 10.1016/j.visinf. 2021.03.003[23] C. Jiang, M. Maddela, W. Lan, Y. Zhong, and W. Xu. 텍스트 단순화에서 문장 정렬을 위한 신경망 CRF 모델. Association for Computational Linguistics의 제58회 연례 회의록, pp. 7943-7960. ACL, 온라인, 2020. doi: 10.18653/v1/2020. acl-main. 709 1, 4,[24] IT Jolliffe. 회귀 분석의 주성분, pp. 129-155. Springer, New York, 1986. doi: 10.1007/978-1-4757-1904-8_8[25] O. Kovaleva, A. Romanov, A. Rogers, and A. Rumshisky. BERT의 어두운 비밀을 폭로하다. 2019년 자연어 처리 경험적 방법에 관한 컨퍼런스 및 제9회 자연어 처리 국제 공동 컨퍼런스의 회의록, 4365-4374쪽. ACL, 홍콩, 2019. doi: 10.18653/v1/D19-1445 2,[26] Q. Li, KS Njotoprawiro, H. Haleem, Q. Chen, C. Yi, and X. Ma. Embeddingvis: 비교 네트워크 임베딩 검사를 위한 시각적 분석 접근 방식. 2018년 IEEE Visual Analytics Science and Technology 컨퍼런스, pp. 48-59. IEEE, 베를린, 2018. doi: 10.1109/VAST.2018. 8802454[27] W. Lidwell, K. Holden, J. Butler. 디자인의 보편적 원칙, 개정 및 업데이트: 사용성 향상, 인식에 영향 미침, 매력도 증가, 더 나은 디자인 결정 내리기, 디자인을 통한 교육 125가지 방법. Rockport Pub, Beverly, 2010.[28] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, CL Zitnick. Microsoft coco: 맥락 속의 공통 객체. 유럽 컴퓨터 비전 컨퍼런스, pp. 740-755. Springer, Zurich, 2014. doi: 10.1007/978-3-319-10602-1_48 4,[29] Y. Lin, YC Tan, and R. Frank. Open sesame: Getting inside BERT&#39;s linguistic knowledge. 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP의 진행 상황, pp. 241– 253. ACL, Florence, 2019. doi: 10.18653/v1/W19-4825[30] S. Liu, T. Li, Z. Li, V. Srikumar, V. Pascucci, and P.-T. Bremer. 자연어 추론 및 기계 이해를 위한 주의 기반 모델의 시각적 조사. 2018년 자연어 처리 경험적 방법에 관한 컨퍼런스의 회의록: 시스템 시연, pp. 36-41. ACL, 브뤼셀, 2018. doi: 10.18653/v1/D18-2007 1,[31] J. Ma, Y. Bai, B. Zhong, W. Zhang, T. Yao, and T. Mei. 비전 변환기에서 패치 상호 작용 시각화 및 이해. IEEE 신경망 및 학습 시스템 거래, pp. 1-10, 2023. doi: 10. 1109/TNNLS.2023.3270479[32] L. McInnes, J. Healy, and J. Melville. Umap: 차원 축소를 위한 균일 매니폴드 근사 및 투영. arXiv 사전 인쇄본, 2018. doi: 10.48550/arxiv. 1802.03426[33] P. Mehrani 및 JK Tsotsos. 시각 변환기의 자기 주의는 주의가 아닌 지각적 그룹화를 수행합니다. arXiv 사전 인쇄본, 2023. doi: 10. 48550/arxiv.2303.01542[34] A. Miaschi, D. Brunato, F. Dell&#39;Orletta 및 G. Venturi. 신경 언어 모델의 언어적 프로파일링. 제28회 국제 계산 언어학 컨퍼런스 회의록, 745-756쪽. 국제 계산 언어학 위원회, 바르셀로나, 2020. doi: 10. 18653/v1/2020.coling-main.65[35] MM Naseer, K. Ranasinghe, SH Khan, M. Hayat, F. Shahbaz Khan, and M.-H. Yang. 시각 변환기의 흥미로운 특성. 신경 정보 처리 시스템의 발전, vol. 34, pp. 23296–23308. Curran Associates, Inc., 온라인, 2021. doi: 10.48550/arXiv.2105.10497[36] C. Olah, A. Mordvintsev, and L. Schubert. 기능 시각화. Distill, 2(11), 2017. doi: 10.23915/distill.00007[37] C. Olsson, N. Elhage, N. Nanda, N. Joseph, N. DasSarma, T. Henighan, B. Mann, A. Askell, Y. Bai, A. Chen, et al. 상황별 학습 및 유도 헤드. arXiv Preprint, 2022. doi: 10.48550/arXiv.2209.[38] M. Oquab, T. Darcet, T. Moutakanni, H. Vo, M. Szafraniec, V. Khalidov, P. Fernandez, D. Haziza, F. Massa, A. El-Nouby 등 Dinov2: 감독 없이 강력한 시각적 기능을 학습합니다. arXiv Preprint, 2023. doi: 10. 48550/arxiv.2304.07193[39] C. Park, I. Na, Y. Jo, S. Shin, J. Yoo, BC Kwon, J. Zhao, H. Noh, Y. Lee, and J. Choo. Sanvis: 자기 주의 네트워크 이해를 위한 시각적 분석. 2019 IEEE Visualization Conference, pp. 146–150. IEEE, Vancouver, 2019. doi: 10.1109/VISUAL. 2019.8933677 2,[40] N. Park and S. Kim. 비전 변환기는 어떻게 작동할까요? 제10회 학습 표현 국제 컨퍼런스에서. 온라인, 2022. doi: 10. 48550/arxiv.2202.06709[41] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever 외. 생성적 사전 학습을 통한 언어 이해 향상. OpenAI 블로그, 2018. https://openai.com/research/language-unsupervised.[42] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever 외. 언어 모델은 비지도 멀티태스크 학습기입니다. OpenAI 블로그, 2019. https://openai.com/research/better-language-models. 1,[43] E. Reif, A. Yuan, M. Wattenberg, FB Viegas, A. Coenen, A. Pearce, B. Kim. bert의 기하학을 시각화하고 측정합니다.신경 정보 처리 시스템의 발전, vol. 32.Curran Associates, Inc., Vancouver, 2019.doi: 10.5555/3454287.3455058 2,[44] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, et al.Imagenet 대규모 시각 인식 챌린지.International Journal of Computer Vision, 115:211252, 2015.doi: 10.1007/s11263-015-0816-y[45] R. Sevastjanova, E. Cakmak, S. Ravfogel, R. Cotterell, and M. El-Assady.언어 모델 적응의 시각적 비교. IEEE 시각화 및 컴퓨터 그래픽스 저널, 29(1):1178–1188, 2022. doi: 10. 1109/TVCG.2022.3209458[46] V. Sivaraman, Y. Wu, 및 A. Perer. Emblaze: 임베딩 공간의 상호 작용적 비교를 통한 머신 러닝 표현 조명. 제27회 지능형 사용자 인터페이스 국제 컨퍼런스, p. 418-432. ACM, 헬싱키, 2022. doi: 10.1145/3490099.3511137[47] D. Smilkov, N. Thorat, C. Nicholson, E. Reif, FB Viégas, 및 M. Wattenberg. 임베딩 프로젝터: 임베딩의 상호 작용적 시각화 및 해석. arXiv 사전 인쇄본, 2016. doi: 10.48550/arxiv. 1611.05469 3,[48] H. Strobelt, S. Gehrmann, M. Behrisch, A. Perer, H. Pfister, and AM Rush. Seq2seq-vis: 시퀀스 대 시퀀스 모델을 위한 시각적 디버깅 도구. IEEE 시각화 및 컴퓨터 그래픽 트랜잭션, 25(1):353–363, 2019. doi: 10.1109/TVCG.2018.2865044[49] I. Tenney, D. Das, and E. Pavlick. BERT가 고전적 NLP 파이프라인을 재발견. Association for Computational Linguistics의 제57회 연례 회의록, pp. 4593-4601. ACL, Florence, 2019. doi: 10.18653/v1/P19-1452 2,[50] L. van der Maaten 및 G. Hinton. t-sne을 사용하여 데이터 시각화. Journal of Machine Learning Research, 9(86):2579-2605, 2008. http://jmlr. org/papers/v9/vandermaaten08a.html.[51] A. Vaswani, S. Bengio, E. Brevdo, F. Chollet, AN Gomez, S. Gouws, L. Jones, Ł. Kaiser, N. Kalchbrenner, N. Parmar, et al. 신경망 기계 번역을 위한 Tensor2tensor. arXiv 사전 인쇄본 arXiv:1803.07416, 2018. 1,[52] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, AN Gomez, L. u. Kaiser, and I. Polosukhin. 주의만 있으면 됩니다.신경 정보 처리 시스템의 발전, 30권.Curran Associates, Inc., Long Beach, 2017. doi: 10.48550/arxiv. 1706.03762 1, 2,[53] J. Vig. 변압기 모델에서 주의의 다중 스케일 시각화.계산 언어학 협회의 제57회 연례 회의록: 시스템 시연, 37-42쪽. ACL, 플로렌스, 2019. doi: 10.18653/v1/P19-3007 1, 2, 5, 6,[54] J. Vig 및 Y. Belinkov. 변환기 언어 모델에서 주의 구조 분석. 2019년 ACL 워크숍 BlackboxNLP의 진행 사항: NLP를 위한 신경망 분석 및 해석, 63-76쪽. ACL, 플로렌스, 2019. doi: 10.18653/v1/W19-4808[55] E. Voita, D. Talbot, F. Moiseev, R. Sennrich 및 I. Titov. 멀티헤드 셀프 어텐션 분석: 전문화된 헤드가 힘든 작업을 수행하고 나머지는 정리할 수 있습니다. 57회 연례 총회 논문집, 5797-5808쪽. ACL, 플로렌스, 2019. doi: 10. 18653/v1/P19-1580[56] A. Wang, Y. Pruksachatkun, N. Nangia, A. Singh, J. Michael, F. Hill, O. Levy, SR Bowman. Superglue: 범용 언어 이해 시스템을 위한 더욱 끈적끈적한 벤치마크. 신경 정보 처리 시스템의 발전, vol. 32, 3266-3280쪽. Curran Associates Inc., Vancouver, 2019. doi: 10.5555/3454287.3454581 6,[57] K. Wang, A. Variengien, A. Conmy, B. Shlegeris, and J. Steinhardt. 야생에서의 해석 가능성: gpt-small에서 간접 객체 식별을 위한 회로. arXiv 사전 인쇄본, 2022. doi: 10.48550/arxiv.2211.00593[58] Y. Wang, S. Liu, N. Afzal, M. Rastegar-Mojarad, L. Wang, F. Shen, P. Kingsbury, and H. Liu. 생물의학 자연어 처리를 위한 단어 임베딩 비교. Journal of Biomedical Informatics, 87:12-20, 2018. doi: 10.1016/j.jbi.2018.09.008[59] ZJ Wang, R. Turko, and DH Chau. Dodrio: 대화형 시각화를 통한 변환기 모델 탐색. Association for Computational Linguistics의 제59회 연례 회의록 및 자연어 처리에 관한 제11회 국제 공동 컨퍼런스: 시스템 데모, pp. 132–141. ACL, 온라인, 2021. doi: 10.18653/v1/.acl-demo. 16[60] J. Wei, Y. Tay, R. Bommasani, C. Raffel, B. Zoph, S. Borgeaud, D. Yogatama, M. Bosma, D. Zhou, D. Metzler, EH Chi, T. Hashimoto, O. Vinyals, P. Liang, J. Dean, W. Fedus. 대규모 언어 모델의 새로운 능력. 기계 학습 연구 저널, 2022. doi: 10.48550/arxiv.2206.07682[61] S. Yang, Z. Quan, M. Nie, W. Yang. 전치: 변압기를 통한 키포인트 로컬라이제이션. IEEE/CVF 컴퓨터 비전 국제 컨퍼런스 회의록, pp. 11802-11812. Montreal, 2021. doi: 10.1109/ ICCV48922.2021.01159[62] GK Zipf. 언어의 상대 빈도 원리에 대한 선별 연구. Harvard University Press, Cambridge, 1932. doi: 10.4159/ harvard.9780674434929
