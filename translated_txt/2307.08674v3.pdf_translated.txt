--- ABSTRACT ---
테이블은 실제 데이터베이스에서 널리 사용되며, 인간이 분석하고 조작하려면 상당한 시간과 노력이 필요합니다. 대규모 언어 모델(LLM)의 발전으로 자연어 입력을 사용하여 테이블과 상호 작용할 수 있게 되어 이 기능이 현실에 더 가까워졌습니다. 이 논문에서는 LLM이 외부 기능 명령을 사용하여 테이블을 이해하고 조작할 수 있도록 하는 통합된 미세 조정 프레임워크인 TableGPT를 제시합니다. 테이블과 원활하게 상호 작용하여 질문 답변, 데이터 조작(예: 삽입, 삭제, 쿼리 및 수정 작업), 데이터 시각화, 분석 보고서 생성 및 자동 예측과 같은 광범위한 기능을 사용할 수 있는 기능을 소개합니다. TableGPT는 사용자가 표 데이터를 손쉽게 활용할 수 있도록 하여 사용자에게 편의성과 접근성을 제공하는 것을 목표로 합니다. TableGPT의 핵심에는 LLM이 메타 정보를 넘어 전체 테이블에 대한 포괄적인 이해를 얻을 수 있도록 하는 새로운 개념의 글로벌 표 표현이 있습니다. TableGPT는 테이블과 텍스트 모달리티에 대한 LLM을 공동으로 훈련함으로써 표 형식 데이터에 대한 심층적인 이해와 명령 체계 지침을 통해 표에서 복잡한 작업을 수행하는 능력을 얻습니다. 중요한 점은 TableGPT가 외부 API 인터페이스에 의존하는 대신 독립형 시스템이라는 이점을 제공한다는 것입니다. 또한 효율적인 데이터 처리 흐름, 쿼리 거부(적절한 경우) 및 비공개 배포를 지원하여 더 빠른 도메인 데이터 미세 조정을 가능하게 하고 데이터 개인 정보 보호를 보장하여 프레임워크의 특정 사용 사례에 대한 적응성을 향상시킵니다.
--- CONCLUSION ---
테이블 분석, 테이블 통합, 자연 언어 및 명령을 위해 설계된 대규모 언어 모델인 TableGPT를 소개합니다. TableGPT는 질문에 대답하고, 데이터를 조작하고, 정보를 시각화하고, 분석 보고서를 생성하고, 기술적으로 예측하는 등의 다양한 기능을 가능하게 합니다. 포괄적인 테이블 이해, 명령 체인 생성 및 도메인별 미세 조정을 포함하여 테이블 데이터 처리를 위한 자연어 기반 프레임워크를 개발하는 데 있어 몇 가지 주요 과제는 TableGPT가 테이블 형식 데이터 처리 환경을 재구성할 수 있는 잠재력을 가지고 있다고 믿습니다. 테이블 모델링 및 탐색적 데이터 분석(EDA)의 효율성을 가속화하고 금융, 운송, 과학 연구 등과 같은 다양한 영역에 권한을 부여합니다. 테이블 GPT •* 이탈 데이터 세트 Bank.csv 좋습니다. 업로드한 CSV 파일을 받았습니다 09:10 : 10: 분석 작업이 생성되었습니다. 작업이 완료되었습니다. 10:10: CSV 41B 귀하의 요청에 따라 50세 이상의 프랑스와 독일 여성의 평균 신용 점수를 추출했습니다. 그 결과, 평균신용점수는 645.14점으로 나타났습니다. 이 값은 데이터 세트에서 추출된 평균 신용 점수만을 나타내며 최신 데이터가 아닐 수도 있습니다. 여기에 말하고 싶은 내용을 입력하고 Enter를 클릭하여 보내세요. 그림 2: TableGPT 이탈 데이터세트 Bank.csv CSV 668.8K 50세 이상 프랑스 및 독일 여성의 평균 신용 점수는 얼마입니까? 표 GPT * chun_dataset_Bank.csv에 대한 대화 A 좋습니다. 업로드한 CSV 파일을 받았습니다. 10: 분석 작업이 생성되었습니다. 잠시 기다려 주세요. 10: 작업이 완료되었습니다. 10:10: data.csv CSV는 파일에 따라 다릅니다. 데이터 해당 지역 남성 고객의 최대 급여와 평균 연령은 다음과 같습니다. 1. 프랑스: 최대 급여는 199,929.17위안, 평균 연령은 38.296404세입니다. 2. 독일: 최고연봉은 199,693.84위안, 평균연령은 39.424772세이다. 3. 스페인: 최고연봉은 199,953.33위안, 평균연령은 38.649135세이다. 이 결과는 원본 데이터 세트의 지침에 따라 추출 및 분석되었으며 각각 프랑스, 독일, 스페인 각 지역의 남성 고객의 최대 소득과 평균 연령을 나타냅니다. 10: 여기에 말하고 싶은 내용을 입력하고 Enter를 클릭하여 Table GPT를 보내세요. * housing_price.csv에 대한 대화가 진행 중입니다. 그림 3: TableGPT 사례입니다.&quot; data.csv 11: POSTED BY UNDER CONSTRU CTION RERA BHK_NO. BHK_OR_RK SQUARE chun_dataset_Bank.csv CSV 668.8K 10: 지역별 남성 고객의 최대 연봉과 평균 연령은 어떻게 되나요? 10: S skzv housing_price.csv 175M 보내기 11: 소유자가 직접 게시한 주택 정보를 보고 싶습니다 OwnerBHK 1800.37066. 당신을 위해 만들어졌습니다 OwnerBHK 775.11:OwnerBHK 1335.OwnerBHK 1450. 작업 완료 OwnerBHK 403.11: OwnerBHK 1322.data.csv CSV 641.1K OwnerBHK 1200.11: 확인 취소 11: 쿼리가 실행되었습니다. 고객님의 요청에 따라 집주인이 직접 게시한 매물 정보만 공개하게 되었습니다. 결과에서 모든 목록의 &quot;POSTED_BY&quot; 열이 &quot;소유자&quot;임을 확인할 수 있습니다. 이는 해당 목록이 주택 소유자가 직접 게시했음을 나타냅니다. 여기에 말하고 싶은 내용을 입력하고 Enter를 클릭하여 전송하세요. 그림 4: TableGPT.Table GPT 사례 * churn_dataset_Bank.csv에 대한 대화 좋습니다. 업로드한 CSV 파일을 받았습니다. 14: 분석 작업이 생성되었습니다. 잠시 기다려 주세요. 15: 작업 완료 15: hulic s3://tablegpt/art.. 187.43M 15: 예측 시작 15: 작업 완료 15: infer.csv 답변 생성 중... Table GPT * vgsales.csv에 대한 대화 중 알겠습니다. 업로드한 CSV 파일을 받았습니다. 14: 분석 작업이 생성되었습니다. 기다려 주세요. 14: 작업 완료 14:14: 평가 및 예측 A로 돌아가기 여기에 말하고 싶은 내용을 입력하고 Enter를 클릭하여 전송합니다. 그림 5: TableGPT 사례 그림 6: 사례 TableGPT.churn_dataset_Bank.csv CSV 668.8K 현재 데이터를 고객 유지 예측 모델을 훈련하기 위한 훈련 세트로 사용할 수 있습니까? 14:15:vgsales.csv CSV 1.39M 14:게임 시장이 가장 큰 지역은 어디입니까? :테이블 GPT • vgsales.csv 정보 대화를 나누세요. 업로드한 CSV 파일을 받았습니다. 14:14: 작업이 완료되었습니다. 14:14: 여기에 말하고 싶은 내용을 입력하세요. 테이블 GPT를 보내려면 Enter를 클릭하세요. * 이제 vgsales.csv에 대한 대화 14: 좋습니다. 업로드한 CSV 파일을 받았고 분석 작업이 생성되었습니다. 잠시 기다려 주세요. 14: 작업이 완료되었습니다. 14:14:14: data.csv CSV그림 7: TableGPT 사례 자료에 따르면 닌텐도가 가장 잘 퍼블리싱하는 유형은 &#39;어드벤처&#39; 시리즈, &#39;마라휘&#39; 시리즈 등 일부 유명 롤플레잉게임(RPG)을 포함한 플랫폼 게임이다. 또한 Nintendo는 액션 게임, 어드벤처 게임, 추측 게임과 같은 다양한 유형의 게임을 만드는 데에도 매우 능숙합니다. 여기에 원하는 내용을 입력하고 Enter를 클릭하여 전송하세요. 그림 8: TableGPT.vgsales.csv 사례 1.39M 14:= 지난 10년 동안 다양한 지역에서 게임 시장이 어떻게 발전했나요? .csv 1.39M Nintendo의 가장 잘하는 게임 유형은 무엇입니까? skzv 14:참고자료 [1] Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli. wav2vec 2.0: 음성 표현의 자기 지도 학습을 위한 프레임워크, 2020. [2] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 언어 모델은 신경 정보 처리 시스템의 발전입니다. 33:1877–1901, 2020. [3] Hao Chen, Yiming Zhang, Qi Zhang, Hantao Yang, Xiaomeng Hu, Xuetao Ma, Yifan Yanggong 및 Junbo Zhao가 필요할 수도 있습니다. 낮은 훈련에 대한 예비 탐색. 데이터 명령 조정, 2023. [4] Zhihong Chen, Feng Jiang, Junying Chen, Tiannan Wang, Fei Yu, Guiming Chen, Hongbo Zhang, Juhao Liang, Chen Zhang, Zhiyi Zhang 등 Phoenix: 언어 간 chatgpt 민주화. arXiv 사전 인쇄 arXiv:2304.10453, 2023. [5] Jacob Devlin, Ming-Wei Chang, Kenton Lee 및 Kristina Toutanova. 언어 이해를 위한 심층 양방향 변환기 사전 훈련, 2019. [6] Tao Gong, Chengqi Lyu, Shilong Zhang, Yudong Wang, Miao Zheng, Qian Zhao, Kuikun Liu, Wenwei Zhang, Ping Luo 및 Kai Chen. Multimodal-gpt: 인간과의 대화를 위한 비전 및 언어 모델: arXiv:2305.04790, 2023. [7] Stefan Hegselmann, Alejandro Buendia, Hunter Lang, Monica Agrawal, Xiaoyi Jiang, 및 David Sontag: 대규모 언어 모델을 사용한 표 형식 데이터 분류, 5549-5581페이지 PMLR, 2023. [8] Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo , Junbo Zhao 및 Hang Zhao: arXiv 사전 인쇄본으로 데이터베이스를 사용하여 Ilms 강화. arXiv:2306.03901, 2023. [9] Rongjie Huang, Mingze Li, Dongchao Yang, Jiatong Shi, Xuankai Chang, Zhenhui Ye, Yuning Wu, Zhiqing Hong, Jiawei Huang, Jinglin Liu, et al. Audiogpt: 음성, 음악 이해 및 생성 , 사운드, arXiv 프리프린트. arXiv:2304.12995, 2023. [10] IDEA-CCNL. Fengshenbang-lm. https://github.com/IDEA-CCNL/Fengshenbang-LM, 2023. [11] Shima Imani, Liang Du 및 Harsh Shrivastava: 대규모 언어 모델을 이용한 수학적 추론, 2023. [12] Baichuan Intelligence. Baichuan-7b. https://github.com/baichuan-inc/baichuan-7B, 2023. [13] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C Berg, Wan-Yen Lo, et al. arXiv 사전 인쇄 arXiv:2304.02643, 2023. [14] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo 및 Yusuke Iwasawa. 대규모 언어 모델은 제로 샷 추론기입니다. 35:22199-22213, 2022. [15] LangChain . Langchain. https://blog.langchain.dev/, 2022. [16] 이주호, 이윤호, 김정택, 아담 코시오렉, 최승진, 테 이유. 집합 변환기: 주의 기반 순열 불변 신경망을 위한 프레임워크, 기계 학습에 관한 국제 회의, 2019년. [17 ] Hongxin Li, Jingran Su, Yuntao Chen, Qing Li 및 Zhaoxiang Zhang: 소프트웨어 생산성 향상. arXiv 사전 인쇄 arXiv:2305.19308, 2023. [18] Jinyang Li, Binyuan Hui, Reynold Cheng, Bowen Qin, Chenhao Ma, Nan Huo, Fei Huang, Wenyu Du, Luo Si 및 Yongbin Li. -t5: text-to-sql을 위해 사전 훈련된 변환기와 그래프 인식 레이어 혼합 arXiv 사전 인쇄 arXiv:2301.07507, 2023. [19] Liyao Li, Haobo Wang, Liangyu Zha, Qingyi Huang, Sai Wu, Gang Chen 및 Junbo Zhao 학습. 학습 표현에 관한 제11차 국제 컨퍼런스, 2022. [20] Guoshan Lu, Haobo Wang, Saisai Yang, Jing Yuan, Guozheng Yang, Cheng Zang, Gang Chen 및 Junbo Zhao. 참고: 자동화된 기능 엔지니어링을 위한 공동 기능 세트 검색 2023년 ACM 웹 컨퍼런스 회보, 2023페이지. [21] .Chatgpt. https://openai.com/blog/chatgpt, 2022. [22] Gpt-4. 기술 보고서, 2023. [23] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. . 기계 학습에 관한 국제 회의, 페이지 8748-8763. PMLR, 2021. [24] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. 생성적 사전 훈련을 통한 언어 이해 향상. 2018. [25] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. OpenAI 블로그, 1(8):9, 2019. [26] Pengzhen Ren, Yun Xiao, Xiaojun Chang, Po-Yao Huang, Zhihui Li, Brij B. Gupta, Xiaojiang Chen, Xin Wang. 딥 액티브 러닝 조사, 2021. [27] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie -Anne Lachaux, Timothée Lacroix, Baptiste Rozière, 나만 고얄, Eric Hambro, Faisal Azhar 등 Llama: 개방형 및 효율적인 기초 언어 모델 arXiv:2302.13971, 2023. [28] Peking University. https://chatexcel.com/, 2023. [29] Ashish Vaswani, Noam Shazeer, Jakob Uszkoreit , Llion Jones, Aidan N Gomez, Łukasz Kaiser, 및 Illia Polosukhin. 신경 정보 처리 시스템의 발전, 30, 2017. [30] Jianguo Wang, Xiaomeng Yi, Rentong Guo, Hai Jin, Peng Xu, Shengjun Li, Xiangyu Wang, Xiangzhou Guo, Chengming Li. , Xiaohai Xu 외 Milvus: 2021년 국제 경영 컨퍼런스 회의록에서 특별히 제작된 벡터 데이터 관리 시스템. of Data, 페이지 2614-2627, 2021. [31] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi 및 Hannaneh Hajishirzi: 자체 생성 지침에 맞게 언어 모델 조정. arXiv:2212.10560, 2022. [32] Yuxuan Wang, RJ Skerry-Ryan, Daisy Stanton, Yonghui Wu, Ron J. Weiss, Navdeep Jaitly, Zongheng Yang, Ying Xiao, Zhifeng Chen, Samy Bengio, Quoc Le, Yannis Agiomyrgiannakis, Rob Clark 및 Rif A. Tacotron: 끝이 가까워집니다. -to-end 음성 합성, 2017. [33] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 대규모 언어 모델에서 추론을 이끌어내는 사고 연쇄, 35:24824-24837, 2022. [34] Chao Ye, Guoshan Lu, Haobo Wang, Liyao Li, Sai Wu, Gang Chen, Junbo Zhao: 다음을 통해 더 나은 표 형식 학습. 크로스 테이블 사전 훈련 arXiv:2307.04308, 2023. [35] Wentao Ye, Mingfeng Ou, Tianyi Li, Xuetao Ma, Yifan Yanggong, Sai Wu, Jie Fu, Gang Chen, Junbo Zhao, et al. llms의 위험: 견고성, 일관성 및 신뢰성에 대한 실증적 연구 arXiv 사전 인쇄. arXiv:2305.10235, 2023. [36] Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al. -훈련된 모델. 제11차 학습 표현에 관한 국제 컨퍼런스, 2022. [37] Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin 등 Opt: arXiv 사전 인쇄 arXiv:2205.01068, 2022 [38] Wenqi Zhang, Yongliang Shen, Weiming Lu 및 Yueting Zhuang. 데이터 부조종사: 자율 워크플로로 수십억 개의 데이터와 인간 연결. arXiv 사전 인쇄 arXiv:2306.07209, 2023. [39] Victor Zhong, Caiming Xiong 및 Richard Socher: 강화 학습을 사용하여 자연어에서 구조화된 쿼리 생성. :1709.00103, 2017.
