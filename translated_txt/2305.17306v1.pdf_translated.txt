--- ABSTRACT ---
대규모 언어 모델(LLM)이 지속적으로 개발됨에 따라 이를 평가하는 것은 점점 더 중요하면서도 어려워지고 있습니다. 이 연구에서는 대규모 언어 모델의 다단계 추론 기능에 대한 오픈 소스 평가 모음인 Chain-of-Thought Hub를 제안합니다. 우리는 두 가지 이유에서 이 설정에 관심이 있습니다. (1) GPT 및 PaLM 모델 패밀리의 동작에서 복잡한 추론이 약한 LLM과 강한 LLM 간의 주요 차별화 요소가 될 가능성이 있음을 관찰했습니다. (2) 대규모 언어 모델이 차세대 계산 플랫폼이 되고 LLM 기반 새로운 애플리케이션의 생태계를 육성할 것으로 예상합니다. 이를 위해서는 자연스럽게 기초 모델이 언어 및 논리 연산의 구성을 포함하는 복잡한 작업을 수행해야 합니다. 우리의 접근 방식은 LLM의 진행 상황을 추적하기 위해 일련의 어려운 추론 벤치마크를 컴파일하는 것입니다. 우리의 현재 결과는 다음과 같습니다. (1) 모델 규모는 추론 기능과 명확하게 상관 관계가 있습니다. (2) 2023년 5월 현재, Claude-v1.3과 PALM-2는 GPT-4와 비교할 수 있는 유일한 두 모델인 반면, 오픈소스 모델은 여전히 뒤처져 있습니다. (3) LLaMA-65B는 code-davinci-002와 유사한 성능을 보이며, 인간 피드백을 통한 강화 학습(RLHF)과 같은 성공적인 추가 개발을 통해 GPT-3.5-Turbo에 가까워질 수 있는 큰 잠재력이 있음을 나타냅니다. 또한, 저희의 결과는 오픈소스 노력이 따라잡으려면 커뮤니티가 더 나은 기본 모델을 구축하고 RLHF를 탐색하는 데 더 집중해야 한다는 것을 시사합니다. 1.
--- METHOD ---
이 섹션에서는 Chain-ofThought Hub의 구성에 대해 설명합니다. 먼저 테스트 데이터 수집 방법을 설명한 다음 테스트 모음에서 모델 성능을 얻는 방법을 설명합니다. 우리의 주요 목표는 (1) LLM의 실제 사용과 긴밀하게 관련된, (2) 더 강하고 약한 언어 모델의 성능을 명확하게 구분하는 고품질 데이터 세트 모음을 큐레이션하는 것입니다. 다음 데이터 세트를 고려합니다. GSM8k 널리 사용되는 수학 추론 데이터 세트로, 모델의 산술 추론 능력과 언어를 사용하여 수학 단계를 구성하는 능력을 공동으로 테스트하는 8k 문제로 구성됩니다(Cobbe et al., 2021). MATH 모델의 고급 수학 및 과학 추론을 테스트하는 7개 범주 내의 12k 문제로 구성된 까다로운 데이터 세트입니다. 이 데이터 세트의 문제는 Latex로 작성된 수학 대회에서 나왔기 때문에 매우 어렵습니다. GPT조차도 성능이 42.5%에 불과합니다(Hendrycks et al., 2021). MMLU 모델의 고등학교 및 대학 수준 지식과 추론을 테스트하는 주제 내 15,000개 문제의 평가 모음(Hendrycks et al., 2020). BigBench Hard 특히 사슬 사고 프롬프트 테스트에 적합한 23개 하위 집합 내 6.5,000개 문제로 구성된 언어 및 기호 추론 과제 모음(Suzgun et al., 2022). HumanEval 모델의 코딩 능력을 테스트하는 텍스트 주석과 docstring이 있는 164개 Python 프로그래밍 문제의 손으로 쓴 데이터 세트(Chen et al., 2021). 2https://www.anthropic.com/index/introducing-claude https://platform.openai.com/docs/model-index-forresearchers C-Eval 다양한 학문과 4가지 난이도에 걸친 13,000개 객관식 문제로 구성된 기초 모델을 위한 중국어 평가 모음(Huang et al., 2023). 이러한 데이터 세트의 대부분이 이미 GPT-4(OpenAI, 2023a) 및 PaLM-2(Anil et al., 2023)와 같은 주요 대규모 언어 모델의 평가에 사용되고 있다는 점에 유의합니다. Few-Shot Chain-of-thought Prompting LLM을 평가하기 위해 fewThere shot chain-of-thought prompting을 사용합니다. 이는 대부분이 답변 전용 프롬핑을 사용하기 때문에 HeLM(Liang et al., 2022)과 같은 대부분의 다른 동시 평가와 당사의 평가 사이에 명확한 차이를 나타냅니다. 또한 few-shot은 사전 학습된 검사점과 명령어 조정 검사점 모두에 존재하는 기능이기 때문에 zeroshot 프롬핑 대신 few-shot을 사용한다는 점을 강조합니다. 반면 zero-shot은 명령어 조정 검사점에 더 적합하고 사전 학습된 검사점을 과소평가할 수 있습니다. 기존 및 동시 작업과 비교하면 HeLM, Chatbot Arena4, Open LLM Leaderboard와 같은 대규모 언어 모델을 위한 훌륭한 기존 평가 제품군이 많이 있습니다. 이 작업과 다른 작업의 주요 차이점은 다음과 같습니다. (1) HeLM은 추론 평가에 중점을 두는 반면 상당히 더 광범위한 작업을 평가합니다. 이 작업의 대부분 결과는 사고의 사슬 프롬프트(따라서 &quot;사고의 사슬 허브&quot;라는 이름)를 사용하는 반면 HeLM은 주로 답변 전용 프롬프트(CoT 없음)를 사용합니다. (2) Chatbot Arena는 추론을 평가하는 대화 사용자 선호도를 평가합니다. (3) Open LLM Leaderboard는 오픈 소스 LLM에 중점을 두고, 오픈 소스이든 아니든 주요 LLM을 공동으로 고려합니다. 추론 기능의 프록시로 최종 답변 정확도 사용 고려하는 대부분의 데이터 세트는 하나의 패턴을 공유합니다. 최종 답변(수학 문제의 경우 숫자, 객관식 문제의 경우 선택지 또는 코딩의 경우 고정 출력)에 도달하려면 모델이 해당 답변에 대한 중간 단계를 파악해야 합니다. 평가할 때 최종 답변 정확도만 사용하고 중간 단계의 정확성은 고려하지 않습니다. 이는 경험적으로 중간 단계의 정확성이 최종 정확도와 강력하게 상관되기 때문입니다. 중간 단계가 매우 잘못되면 모델이 최종 답에 도달할 가능성이 낮아집니다. 최종 답이 맞으면 중간 단계는 일반적으로 충분히 좋습니다(Wei et al., 2022b; Lewkowycz et al., 2022). 3.
--- EXPERIMENT ---
s 먼저 고려하는 모델 패밀리에 대해 논의합니다. GPT, Claude, PALM, LLAMA 및 T5 모델 패밀리를 포함하여 프로덕션에서 인기 있는 모델에 초점을 맞춥니다. 특히: https://leaderboard.lmsys.org/ Shttps://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboardChain-of-Thought Hub 표 1. Chain-of-Thought Hub에서의 전반적인 모델 성능. 별표(*)가 있는 숫자는 테스트 스크립트에서 가져온 것입니다. 모델 유형의 경우, 기준은 사전 학습 후의 모델 검사점을 의미하고 SIFT는 감독 지침 미세 조정을 의미합니다. 다른 것은 해당 논문에서 가져온 것입니다. 다음을 관찰합니다. (1) 주요 LLM(GPT, Claude 및 PaLM)과 오픈 소스(LLaMA 및 FlanT5) 사이에 격차가 있습니다. (2) 대부분의 주요 LLM은 RLHF 이후에 있으며, 이 기술을 사용하여 오픈 소스 모델을 개선할 수 있는 기회를 나타냅니다. (3). 모델 성능은 일반적으로 모델 규모와 상관관계가 있으며, 특히 오픈 소스 모델의 경우 확장에 대한 추가 기회를 나타냅니다. 또한 오픈 소스 모델 중에서 LLaMA 65B가 ChatGPT의 기본 모델인 code-davinci-002와 유사한 성능을 보인다는 점을 강조합니다. 이는 LLaMA 65B에서 RLHF를 올바르게 수행하면 ChatGPT와 유사해질 수 있음을 시사합니다. 모델 #Params Туре GSM8k MATH MMLU BBH HumanEval C-Eval GPT-? RLHF 92.42.86.67.68.7* claude-v1.? RLHF 81.8* 74.8* 67.3* 54.2* PALM-? Base 80.34.78.78.gpt-3.5-turbo ? RLHF 74.9* 67.3* 70.1* 48.54.4* 클로드-인스턴트-v1.? RLHF 70.8* 66.9* 54.9* 텍스트-다빈치-? RLHF 64.70.코드-다빈치-002 ? 기본 66.19.64.73.47.미네르바 540B SIFT 58.33.플랜-팔LM 540B SIFT 70.66.플랜-유-팔LM 540B SIFT 69.64.팔LM 540B 기본 56.8.62.62.26.텍스트-다빈치-? SIFT 55.60.67.PALM 64B Base 52.4.49.42.LLAMA 65B Base 50.10.63.23.38.8* LLAMA 33B Base 35.7.57.21.LLAMA 13B Base 17.3.46.15.Flan-T11B SIFT 16.1* 48.41.LLAMA 7B Base 11.2.35.10.Flan-T3B SIFT 13.5* 45.35.OpenAI GPT에는 GPT-4(현재 가장 강력함), GPT3.5-Turbo(더 빠르지만 성능이 떨어짐), text-davinci-003, text-davinci-002, code-davinci-002(Turbo 이전의 중요한 이전 버전)가 포함됩니다. 포괄적인 논의는 Fu &amp; Khot(2022)을 참조하십시오. Anthropic Claude에는 claude-v1.3(느리지만 더 유능함)과 claude-instant-v1.0(빠르지만 덜 유능함)이 포함됩니다.6. 강력한 경쟁자의 GPT 모델. Google PaLM에는 PaLM, PaLM-2 및 해당 명령어 조정 버전(FLan-PaLM 및 Flan-UPaLM)이 포함됩니다. 강력한 기반 및 명령어 조정 모델. Meta LLAMA에는 7B, 13B, 33B 및 65B 변형이 포함됩니다. 중요한 오픈 소스 기반 모델. Google FlanT5 명령어 조정 T5 모델은 더 작은 모델 체제에서 강력한 성능을 보여줍니다. 이러한 모델의 성능을 CoT Hub 제품군에서 보고합니다. 고려하는 작업과 모델의 스펙트럼이 넓기 때문에 평가가 사소하지 않으며 추론을 실행하는 데도 노력이 필요합니다. 또한 공개 액세스를 제공하지 않는 모델(예: PaLM)이 있어 평가하기 어렵습니다. 이러한 이유로 다음 전략을 사용하여 숫자를 보고합니다. 모델의 성능이 이미 논문에 보고된 경우 해당 논문을 참조하고 그렇지 않은 경우 직접 테스트합니다. 이 전략은 일부 데이터 세트에서 테스트되지 않은 비공개 모델의 일부가 여전히 있으므로 포괄적이지 않습니다. 이것이 부분적으로 CoT 허브를 지속적인 노력으로 보는 이유입니다. 표 1은 전체 결과를 보여줍니다. 모델의 추론 기능을 테스트하는 고전적인 벤치마크이기 때문에 GSM8k 성능을 사용하여 모델을 순위를 매겼습니다. 별표로 표시된 숫자는 직접 테스트한 것이고 다른 숫자는 다음 소스에서 테스트한 것입니다. GPT-4 및 PaLM-2 결과는 각각 기술 보고서(OpenAI, 2023a; Anil et al., 2023)에서 가져온 것입니다. HumanEval에서 GPT-3.5-Turbo의 성능도 OpenAI에서 가져온 것입니다. (2023a). Text-davinci-003, code-davinci-and text-davinci-002 성능은 Chung et al. (2022)의 부록과 Fu et al. (2022)에서 가져왔습니다. Minerva의 성능은 Lewkowycz et al. (2022)에서 가져왔습니다. PaLM의 성능은 Chowdhery et al. (2022)에서 가져왔습니다. Flan-PaLM과 FlanT5 성능은 Chung et al. (2022)에서 가져왔습니다. LLAMA의 성능은 Touvron et al. (2023)에서 가져왔습니다. 오픈소스와 선도적 LLM 간의 격차 InMMLU AccuracyGPT-PALM-Claude-v1.GPT-3.5-Turbo Code-davinci-Chain-of-Thought HubGSM8k Accuracy20GPT-Claude-v1.PALM-GPT-3.5-Turbo Code-davinci-Minerva 540B PaLM 540B PaLM 64B LLAMA 65B LLAMA 33B LLAMA 13B FlanT5 11B LLAMA 7B FlanT5 3B10°10°10² 그림 1. X축은 10억 개의 매개변수로 측정한 모델 규모의 로그를 의미합니다. 모델 성능은 일반적으로 규모와 상관관계가 있으며 대략 로그 선형 추세를 보입니다. 규모를 공개하지 않는 모델은 일반적으로 규모 정보를 공개하는 모델보다 성능이 더 좋습니다. 영어: 또한 저희의 관찰 결과에 따르면 오픈 소스 커뮤니티는 추가 개선을 위해 스케일링과 RLHF에 대한 &quot;해자&quot;를 여전히 탐색/파악해야 할 수도 있습니다. 일반적으로 오픈 소스 모델(LLaMA 및 FlanT5와 같은)과 폐쇄 소스 모델(GPT, Claude 및 PaLM) 간에 성능 불일치가 관찰됩니다. 중요한 점은 오픈 소스 모델의 성능이 LLAMA 65B에 의해 상한이 정해진 것 같습니다. 선두 LLM은 RLHF 이후입니다. PaLM-2를 제외하고 리더보드의 상위 6개 모델은 인간 피드백을 통한 강화 학습 이후입니다. 이는 RLHF의 효과를 강력히 나타냅니다. RLHF가 여전히 미개척 분야이므로 커뮤니티에서 이 주제에 대해 더 많이 연구할 것을 강력히 권장합니다. 모델 규모와 추론 간의 상관 관계 모델 성능을 모델 규모에 대해 시각화하여 모델 규모와 모델의 추론 성능 간의 관계를 추가로 연구합니다. 결과는 그림 1에 나와 있습니다. 다음이 있습니다. (1) 일반적으로 모델 성능은 모델 규모와 상관 관계가 있으며 대략 로그 선형 추세를 보입니다. (2) 규모를 공개하지 않는 모델은 일반적으로 규모를 공개하는 모델보다 성능이 더 좋으며, 이는 오픈 소스와 클로즈 소스 간에 여전히 격차가 있음을 나타냅니다.LLaMA-65B의 잠재력에 관하여 마지막으로 LLAMA 65B의 인상적인 성능을 강조하고 싶습니다.MMLU에서는 GPT-3.5 시리즈의 기본 모델인 code-davinci-002에 가깝습니다.GSM8k에서는 더 나쁘지만(아마도 코드에서 학습되지 않았기 때문일 것임) 다른 오픈 소스 모델보다 비슷하고 훨씬 좋습니다(아마도 Chinchilla-optimal Hoffmann et al., 2022에 따라 학습되었기 때문일 것임). 이러한 관찰 결과를 GPT3.5-Turbo(ChatGPT)가 codedavinci-002에 기반한 RLHF 모델이라는 사실과 결합하면 DeepMind Sparrow(Glaese et al., 2022)와 Anthropic Claude(Askell et al., 2021; Bai et al., 2022a;b)에서 논의된 RLHF 기술을 적용하여 LLAMA 65B에 기반한 ChatGPT를 재현하는 것이 가능할 수 있습니다.
--- CONCLUSION ---
및 향후 작업 이 작업에서 우리는 매우 큰 언어 모델의 추론 능력을 측정하기 위한 오픈소스의 지속적인 노력인 Chain-of-Thought Hub를 제안합니다. 우리의 결과는 더 작은 모델과 더 큰 모델 간, 그리고 클로즈 소스와 오픈 소스 모델 간의 성능 차이를 명확히 보여줍니다. 결과를 주의 깊게 검토한 후, 우리는 오픈 소스 모델을 더욱 개선하기 위한 두 가지 중요한 방향을 보여줍니다. 더 나은 기본 모델을 구축하고 RLHF를 탐색하는 것입니다. 또한 LLaMA 65B의 엄청난 잠재력을 지적합니다. 더 나은 SFT와 RLHF로 적절하게 정렬하면 ChatGPT-3.5와 동등한 성능을 낼 수 있습니다. 앞으로는 다음을 통해 CoT Hub를 더욱 확장할 계획입니다. (1) 특히 상식적 추론, 수학 정리 증명 및 외부 API 호출 기능을 측정하는 데이터 세트와 같이 신중하게 선택된 추론 데이터 세트를 포함합니다. (2) Vicuna와 같은 LLaMA 기반, 명령 미세 조정 모델 및 Cohere 및 PaLM-2 chat-bison-0019와 같은 API 액세스를 통한 모델과 같은 더 많은 언어 모델을 포함합니다. (3) 아마도 가장 어려운 데이터 세트(Latex로 작성된 수학 경연 대회로 구성됨을 기억하세요)인 MATH를 풀기 위한 방법을 탐색합니다. Wolfram Alpha¹º와 같은 기호 및 수치 미적분을 계산하는 API를 호출합니다. 요약하자면, 우리의 작업은 오픈 소스 대규모 언어 모델 개발을 안내하는 평가 플랫폼 역할을 한다고 믿습니다. https://lmsys.org/blog/2023-03-30-vicuna/ https://cohere.com/generate &quot;https://cloud.google.com/vertex-ai10https://www.wolframalpha.com/ 참고 문헌 Chain-of-Thought Hub Anil, R., Dai, AM, Firat, O., Johnson, M., Lepikhin, D., Passos, A., Shakeri, S., Taropa, E., Bailey, P., Chen, Z., et al. arXiv 사전 인쇄 arXiv:2305.10403, 2023. Askell, A., Bai, Y., Chen, A., Drain, D., Ganguli, D., Henighan, T., Jones, A., Joseph, N., Mann, B., DasSarma, N., et al. arXiv 사전 인쇄를 위한 실험실로. arXiv:2112.00861, 2021. Bai, Y., Jones, A., Ndousse, K., Askell, A., Chen, A., DasSarma, N., Drain, D., Fort, S., Ganguli, D., Henighan, T., et al. 인간 피드백을 통한 강화 학습으로 도움이 되고 무해한 조수 훈련. arXiv 사전 인쇄본 arXiv:2204.05862, 2022a. Bai, Y., Kadavath, S., Kundu, S., Askell, A., Kernion, J., Jones, A., Chen, A., Goldie, A., Mirhoseini, A., McKinnon, C., et al. 헌법적 ai: ai 피드백의 무해성. arXiv 사전 인쇄본 arXiv:2212.08073, 2022b. Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, HP d. O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., et al. 코드에 대해 훈련된 대규모 언어 모델을 평가합니다. arXiv 사전 인쇄 arXiv:2107.03374, 2021. Chiang, W.-L., Li, Z., Lin, Z., Sheng, Y., Wu, Z., Zhang, H., Zheng, L., Zhuang, S., Zhuang, Y., Gonzalez, JE, Stoica, I., and Xing, EP Vicuna: 인상적인 오픈 소스 챗봇 chatgpt 품질 90%*의 gpt-4, 2023년 3월. URL https://lmsys.org/blog/ 2023-03-30-vicuna/. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, HW, Sutton, C., Gehrmann, S., et al. Palm: 경로로 언어 모델링 확장. arXiv 사전 인쇄본 arXiv:2204.02311, 2022. Chung, HW, Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., et al. 명령어 미세 조정 언어 모델 확장. arXiv 사전 인쇄본 arXiv:2210.11416, 2022. Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., et al. 수학 단어 문제를 풀기 위한 검증자 훈련. arXiv 사전 인쇄본 arXiv:2110.14168, 2021. Databricks. 무료 돌리: 세계 최초의 진정한 개방형 명령어 조정 Ilm 소개. 블로그 게시물, 2023년 4월. URL https://www. databricks.com/blog/2023/04/12/ 모델을 소스로 전송합니다. Yao Fu&#39;s Notion, 2022년 12월. URL https://yaofu.notion.site/ How-does-GPT-Obtain-its-Ability-Tracing-EmergentFu, Y., Peng, H., Sabharwal, A., Clark, P., and Khot, T. 다단계 추론을 위한 복잡성 기반 프롬핑. arXiv 사전 인쇄본 arXiv:2210.00720, 2022. Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., and Song, D. Koala: 학술 연구를 위한 대화 모델. 블로그 게시물, 2023년 4월. URL https://bair.berkeley.edu/ blog/2023/04/03/koala/. Glaese, A., McAleese, N., Trebacz, M., Aslanides, J., Firoiu, V., Ewalds, T., Rauh, M., Weidinger, L., Chadwick, M., Thacker, P., et al. 타깃 인간 판단을 통한 대화 에이전트 정렬 개선. arXiv 사전 인쇄본 arXiv:2209.14375, 2022. Gudibande, A., Wallace, E., Snell, C., Geng, X., Liu, H., Abbeel, P., Levine, S., and Song, D. 독점적 llms를 모방하는 것의 허무한 약속. arXiv 사전 인쇄본 arXiv:2305.15717, 2023. Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J. Measuring massive multitask language understanding. arXiv 사전 인쇄본 arXiv:2009.03300, 2020. Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song, D., and Steinhardt, J. Measuring mathematical problem solving with the math dataset. NeurIPS, 2021. Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, LA, Welbl, J., Clark, A. 등. 컴퓨팅에 최적화된 대규모 언어 모델을 교육합니다. arXiv 사전 인쇄 arXiv:2203.15556, 2022. Huang, Y., Bai, Y., Zhu, Z., Zhang, J., Zhang, J., Su, T., Liu, J., Lv, C., Zhang, Y., Lei, J., et al. C-eval: 기초 모델을 위한 다단계, 다분야 중국어 평가 제품군입니다. arXiv 사전 인쇄 arXiv:2305.08322, 2023. Lewkowycz, A., Andreassen, A., Dohan, D., Dyer, E., Michalewski, H., Ramasesh, V., Slone, A., Anil, C., Schlag, I., Gutman-Solo, T., et al. 언어 모델을 사용하여 양적 추론 문제 해결. arXiv 사전 인쇄본 arXiv:2206.14858, 2022. dolly-first-open-commercially-viable-insLiang P. Bommasani, R. Lee, T., Tsipras, D., Soylu, D., Fu, Yao; Peng, H., Khot, T. gpt는 어떻게 능력을 얻을까? 언어의 새로운 능력 추적 Yasunaga, M., Zhang, Y., Narayanan, D., Wu, Y., Kumar, A., et al. 언어 모델의 전체적 평가. arXiv 사전 인쇄본 arXiv:2211.09110, 2022. Chain-of-Thought Hub OpenAI. Gpt-4 기술 보고서. arXiv:2303.08774, 2023a. arXiv 사전 인쇄본 OpenAI. Gpt-4, 2023b. URL https://openai.com/ research/gpt-4. Suzgun, M., Scales, N., Schärli, N., Gehrmann, S., Tay, Y., Chung, HW, Chowdhery, A., Le, QV, Chi, EH, Zhou, D., et al. 빅벤치 과제에 도전하고 사고의 사슬로 해결할 수 있는지. arXiv 사전 인쇄본 arXiv:2210.09261, 2022. Taori, R., Gulrajani, I., Zhang, T., Dubois, Y., Li, X., Guestrin, C., Liang, P., and Hashimoto, TB Stanford 알파카: 지시를 따르는 라마 https://github.com/tatsu-lab/ 모델. stanford_alpaca, 2023. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., et al. Llama: 개방적이고 효율적인 기초 언어 모델입니다. arXiv 사전 인쇄 arXiv:2302.13971, 2023. Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D., et al. 대규모 언어 모델의 새로운 능력. arXiv 사전 인쇄 arXiv:2206.07682, 2022a. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., and Zhou, D. 사고의 사슬을 촉진하는 것은 대규모 언어 모델에서 추론을 이끌어냅니다. arXiv 사전 인쇄본 arXiv:2201.11903, 2022b.
