arXiv:2309.03907v1 [q-bio.BM] 18 May 2023
1-14
Drug Chat: Towards Enabling Chat GPT-Like Capabilities on
Drug Molecule Graphs
Youwei Liang*
Ruiyi Zhang*
Li Zhang
Pengtao Xie
University of California San Diego, *Equal contribution.
Abstract
A ChatGPT-like system for drug compound analysis could be a game-changer in pharma-
ceutical research, accelerating drug discovery, enhancing our understanding of structure-
activity relationships, guiding lead optimization, aiding drug repurposing, reducing the
failure rate, and streamlining clinical trials. In this work, we make an initial attempt
towards enabling ChatGPT-like capabilities on drug molecule graphs, by developing a pro-
totype system DrugChat. DrugChat works in a similar way as ChatGPT. Users upload a
compound molecule graph and ask various questions about this compound. DrugChat
will answer these questions in a multi-turn, interactive manner.
The Drug Chat sys-
tem consists of a graph neural network (GNN), a large language model (LLM), and an
adaptor. The GNN takes a compound molecule graph as input and learns a representa-
tion for this graph. The adaptor transforms the graph representation produced by the
GNN into another representation that is acceptable to the LLM. The LLM takes the
compound representation transformed by the adaptor and users' questions about this
compound as inputs and generates answers. All these components are trained end-to-
end. To train DrugChat, we collected instruction tuning datasets which contain 10,834
drug compounds and 143,517 question-answer pairs. The code and data is available at
https://github.com/UCSD-AI4H/drugchat
1. Introduction
The process of drug discovery and development is a time-intensive and costly endeavor, often
taking years and billions of dollars to bring a single drug to market (Avorn, 2015). This
process involves the exploration and understanding of vast chemical spaces and the intricate
relationships between molecular structures and their biological activities, commonly known
as structure-activity relationships (SAR) (Idakwo et al., 2020). Traditional methods (Rycker
et al., 2018) often involve laborious iterative testing, with a high rate of late-stage failures.
Recent advancements in computational chemistry and chemoinformatics (Zeng et al., 2022)
have offered some respite, but there is still a pressing need for tools that can intuitively
understand and generate meaningful insights from the complex data inherent in molecular
graphs of drug compounds.
© Y. Liang*, R. Zhang*, L. Zhang & P. Xie.
DRUGCHAT: TOWARDS ENABLING CHATGPT-LIKE CAPABILITIES ON DRUG MOLECULE GRAPHS
This technical report introduces the concept of applying ChatGPT-like capabilities to
drug molecule graphs, aiming to revolutionize the way we interact with and understand
these complex entities. By transforming these molecular graphs into a form amenable to
AI analysis, we can enable dynamic exploration of chemical spaces, efficient prediction
of compound properties, and intelligent suggestions for drug design and optimization. A
ChatGPT-like AI system capable of understanding drug compound molecule graphs and
answering various questions about these drugs could revolutionize pharmaceutical research
in several ways:
• Speeding up Drug Discovery. A Chat GPT-like AI system could drastically cut
down the time required for initial stages of drug discovery by providing immediate in-
sights into a compound's potential therapeutic uses, side effects, and contraindications
based on its structure.
• Predicting Drug Interactions. A Chat GPT-like AI system could predict potential
interactions between new drug candidates and existing drugs. By comparing the
molecular structures of thousands of known substances, the system could identify
possible conflicts or synergies, helping researchers to better anticipate how a new
drug might behave in the real world.
• Understanding Structure-Activity Relationships (SAR). SAR (Idakwo et al.,
2020) is a crucial aspect of drug design. A ChatGPT-like AI system could help
researchers understand the relationship between a drug's chemical structure and its
biological activity. It could also help predict what modifications to the chemical
structure might enhance its effectiveness or reduce unwanted side effects.
• Guiding Lead Optimization. During the drug discovery process, 'lead' compounds
(those that show promise in initial screenings) (Hughes et al., 2011) are typically
optimized for better efficacy, reduced toxicity, and improved pharmacokinetics. A
Chat GPT-like AI system could offer suggestions for structural modifications to en-
hance these parameters, guiding researchers in the right direction and saving valuable
time.
.
Supporting Drug Repurposing. A ChatGPT-like AI system could also aid in
drug repurposing (Pushpakom et al., 2019) efforts. By understanding the structural
properties of existing drugs, it could identify candidates that may be effective against
diseases they were not initially developed to treat. This could help breathe new life
into existing drugs and offer more rapid routes to treatment for challenging diseases.
• Reducing the Failure Rate. The failure rate in drug discovery is high (Hughes
et al., 2011), often due to unforeseen toxicity or efficacy issues that emerge late in
development. By providing more accurate predictions about a drug's properties and
effects at the outset, a Chat GPT-like AI system could help reduce these costly late-
stage failures.
Streamlining Clinical Trials. A ChatGPT-like AI could help design more effective
clinical trials by predicting how a drug will interact with other medications or condi-
2
DRUGCHAT: TOWARDS ENABLING CHATGPT-LIKE CAPABILITIES ON DRUG MOLECULE GRAPHS
tions, enabling researchers to target their trials more effectively and recruit suitable
patient cohorts.
Developing a ChatGPT-like system for drug molecule graphs is highly challenging. First,
one of the primary challenges lies in the representation of molecular graphs. Unlike text
data, which is sequential and has a well-defined structure, molecular graphs are inherently
non-sequential and highly complex, with no clear start or end point. Developing a methodol-
ogy to translate these graphs into a format that a GPT model can process is crucial. Second,
another significant challenge is capturing and understanding the intricate structure-activity
relationships (SAR) in drug compounds. These relationships are often not straightforward
and can involve subtle interactions between different parts of a molecule. Third, to train
such a system, large datasets of molecular structures, along with their associated biological
activities, side effects, and other properties, would be required. The generation or compi-
lation of such datasets is a non-trivial task, given the proprietary nature of much of this
information and the sheer diversity of the chemical space.
In this technical report, we make an initial attempt towards enabling ChatGPT-like ca-
pabilities on drug molecule graphs, by developing a prototype system DrugChat. DrugChat
works in a similar way as ChatGPT. Users upload a compound molecule graph and ask var-
ious questions about this compound. DrugChat will answer these questions in a multi-turn,
interactive manner.
The DrugChat system consists of a graph neural network (GNN) (Hu et al., 2020), a
large language model (LLM) (Chiang et al., 2023), and an adaptor. The GNN takes a
compound molecule graph as input and learns a representation for this graph. The adaptor
transforms the graph representation produced by the GNN into another representation
that is acceptable to the LLM. The LLM takes the compound representation transformed
by the adaptor and users' questions about this compound as inputs and generates answers.
All these components are trained end-to-end. To train DrugChat, we collected instruction
tuning datasets which contain 10,834 drug compounds and 143,517 question-answer pairs.
The major contributions of this work are as follows:
• We develop Drug Chat, a prototype system aiming to achieve Chat GPT-like capabili-
ties on drug molecule graphs. DrugChat allows users to interactively ask open-ended
questions about drug compounds and provides informative answers.
• We collect instruction tuning datasets which contain 10,834 drug compounds and
143,517 question-answer pairs. These datasets enable the training of ChatGPT-like
models for drug compounds and are publicly available.
⚫ To our best knowledge, DrugChat represents the first system that bridges graph
data with large language models (LLMs), which enables interactive conversations on
graphs. Our system seamlessly integrates graph neural networks with LLMs and can
be easily extended to analyze other graph data beyond compound molecule graphs.
2. Related Works
AI-based drug properties analysis (Paul et al., 2021) is a promising approach to signifi-
cantly reduce costs and time associated with the traditional drug discovery and development
3
DRUGCHAT: TOWARDS ENABLING CHATGPT-LIKE CAPABILITIES ON DRUG MOLECULE GRAPHS
pipeline. For example, ImageMol (Zeng et al., 2022) is an unsupervised pretraining method
that processes images of chemical structures and outputs molecular properties, such as drug
metabolism, brain penetration, toxicity, and molecular target profiles like beta-secretase en-
zyme and kinases. ImageMol was pretrained on 10 million unlabeled drug-like, bioactive
molecules through predicting molecular targets of candidate compounds. It was assessed on
51 benchmark datasets and demonstrated high accuracy in identifying anti-SARS-CoV-2
molecules across 13 high-throughput experimental datasets.
Large language models (LLMs) (Brown et al., 2020) have demonstrated outstanding ca-
pabilities in generating inventive text, responding to reading comprehension queries, math-
ematical reasoning, etc. Nevertheless, the weight parameters of some of the most powerful
LLMs are not publicly available, which considerably hinders academic research. Moreover,
early LLMs were limited to processing text information as input, restricting their ability to
understand information in other modalities. Consequently, researchers have developed an
array of publicly accessible LLMs, including multi-modal variants, to address these chal-
lenges.
LLAMA (Touvron et al., 2023), an LLM with 65 billion parameters, was developed by
Meta AI ¹. This model is trained on publicly accessible datasets including English Com-
monCrawl, C4, Github, Wikipedia, Gutenberg Project, ArXiv, and Stack Exchange. This
training dataset encompasses 20 languages with the most speakers. Although it is smaller
than GPT-3, LLaMA demonstrates superior performance on many benchmarks, includ-
ing commonsense reasoning, question answering, reading comprehension, code generation,
etc. Vicuna (Chiang et al., 2023) is an open-source chatbot trained by fine-tuning LLAMA
on around 70,000 user-shared conversations with ChatGPT 2. Vicuna was evaluated using
GPT-4. MiniGPT-4 (Zhu et al., 2023) is a vision-language model capable of processing im-
ages and generating textual answers 3. For instance, it can create stories and poems from
input images and offer solutions to problems depicted in images. MiniGPT-4 incorporates
a linear projection layer to align the visual information from a pretrained vision encoder
with a large language model. LLaVA (Liu et al., 2023) is another multi-modal model that
integrates a vision encoder with an LLM to facilitate general-purpose visual and language
understanding 4. Different from MiniGPT-4, LLaVA is trained on multi-turn conversation
data. The projection layer and the LLM are both updated in the training stage while only
the visual encoder parameters are frozen. The training data was created by converting raw
image-text pairs into a suitable instruction-following format using ChatGPT/GPT-4.
3. Drug Instruction Tuning Data
To train DrugChat, we curate instruction tuning data for drug compounds, from two sources
- ChEMBL and PubChem. Table 1 summarizes the statistics of the curated two datasets.
1. https://ai.facebook.com/blog/large-language-model-llama-meta-ai/
2. https://lmsys.org/blog/2023-03-30-vicuna/
3. https://minigpt-4.github.io/
4. https://llava-vl.github.io/
4
DRUGCHAT: TOWARDS ENABLING CHATGPT-LIKE CAPABILITIES ON DRUG MOLECULE GRAPHS
Table 1: Dataset statistics.
DATASET NUMBER OF DRUGS NUMBER OF QUESTION-ANSWER PAIRS
CHEMBL
PUBCHEM
3,892
6,942
129,699
13,818
3.1. ChEMBL Drug Instruction Tuning Dataset
In this section, we outline the process of constructing the ChEMBL Drug Instruction Tuning
dataset. We gathered data from the ChEMBL website 5, which houses information for a total
of 2,354,965 chemical compounds. We downloaded the sqlite version of the data dump,
which was last updated on February 28, 20236. Out of the entire dataset, we identified
14,816 compounds that contain drug information. After applying further filtering to exclude
drugs with insufficient descriptive information, we ended up with a dataset containing 3,892
drugs.
For each drug, we initially gathered its SMILES string, representing the molecular struc-
ture. Subsequently, we obtained various molecular features, including the complete molec-
ular formula and its classification as an acid, base, or neutral compound. Additionally,
we collected drug-specific properties, such as the mechanism of action and therapeutic ap-
plications. Based on these attributes, we manually crafted 129,699 question-answer pairs.
Question-answer (QA) pairs for an exemplar drug in the ChEMBL Drug Instruction Tuning
Dataset is shown in Table 2.
Table 2. Question-answer (QA) pairs for an exemplar drug in the ChEMBL Drug
Instruction Tuning Dataset.
SMILES of the drug
QA Pair 1
QA Pair 2
QA Pair 3
QA Pair 4
QA Pair 5
QA Pair 6
CC(=O)/N=c1/sc(S(N)(=O)=O)nn1C
Q: Please provide a description of this drug's mechanism of action.
A: Carbonic anhydrase II inhibitor.
Q: Is this compound an acid, a base, or neutral?
A: Neutral.
Q: How many rotatable bonds does this compound have?
A: 1.
Q: Determine if this drug is administered as a racemic mixture, a single
stereoisomer, an achiral molecule, or has an unknown chirality.
A: An achiral molecule.
Q: Does this compound satisfy the rule-of-three criteria?
A: No.
Q: How many violations of Lipinski's Rule of Five are there for this
compound, using the HBA LIPINSKI and HBD LIPINSKI counts?
A: 0.
5. https://www.ebi.ac.uk/chembl/
6. https://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/latest/
5
DRUGCHAT: TOWARDS ENABLING CHATGPT-LIKE CAPABILITIES ON DRUG MOLECULE GRAPHS
QA Pair 7
QA Pair 8
QA Pair 9
QA Pair 10
QA Pair 11
QA Pair 12
QA Pair 13
QA Pair 14
QA Pair 15
QA Pair 16
QA Pair 17
QA Pair 18
QA Pair 19
QA Pair 20
QA Pair 21
QA Pair 22
Q: Is it known whether this drug is administered parenterally?
A: No.
Q: Is this compound a small molecule polymer,
such as polystyrene sulfonate?
A: No.
Q: What is the calculated ALogP value for this compound?
A: -1.42.
Q: Is this molecule characterized by a small molecular
structure or a protein sequence?
A: It has a small molecule structure.
Q: Determine if this molecule is inorganic, meaning it contains only metal
atoms and fewer than two carbon atoms.
A: No.
Q: What is the highest development stage achieved for this compound
across all indications? Please respond with Approved, Phase 3 Clinical
Trials, Phase 2 Clinical Trials, Phase 1 Clinical Trials,
Early Phase 1 Clinical Trials, or Clinical Phase Unknown.
A: Approved.
Q: What is the first recorded year of approval for this drug?
A: 1959.
Q: Is there a black box warning associated with this drug?
A: No.
Q: Is it known if this drug is the first approved in its class, regardless of
the indication or route of administration, acting on a specific target?
A: No.
Q: How many hydrogen bond acceptors does this compound have?
A: 6.
Q: Is this drug used for therapeutic purposes, rather than for imaging,
additives, or other non-therapeutic applications?
A: Yes.
Q: What is the polar surface area (PSA) value of this compound?
A: 107.41.
Q: Has this approved drug been withdrawn due to toxicity
reasons for all indications, populations, and
doses in at least one country (not necessarily the US)?
A: No.
Q: How many violations of Lipinski's Rule of Five (using HBA and
HBD definitions) are there for this compound?
A: 0.
Q: How many heavy (non-hydrogen) atoms does this compound have?
A: 14.
Q: How many aromatic rings does this compound have?
A: 1.
6
DRUGCHAT: TOWARDS ENABLING CHATGPT-LIKE CAPABILITIES ON DRUG MOLECULE GRAPHS
QA Pair 23
QA Pair 24
QA Pair 25
QA Pair 26
QA Pair 27
QA Pair 28
QA Pair 29
QA Pair 30
QA Pair 31
QA Pair 32
QA Pair 33
QA Pair 34
Q: Determine the type of availability for this drug.
A: Prescription only.
Q: Is it known whether this drug is taken orally?
A: Yes.
Q: How many hydrogen bond acceptors are there in this compound,
calculated according to Lipinski's original rules
(i.e., counting N and O atoms)?
A: 7.
Q: Is the drug administered
in this specific form, such as a particular salt?
A: Yes.
Q: Determine if this compound is a prodrug.
A: No.
Q: What is the molecular weight of this compound's parent molecule?
A: 236.28.
Q: How many hydrogen bond donors are there in this compound,
calculated according to Lipinski's original
rules (i.e., counting NH and OH groups)?
A: 2.
Q: Which USAN substem can
this drug or clinical candidate name be matched with?
A: Zolamide.
Q: What is the definition of this compound's USAN stem?
A: Carbonic anhydrase inhibitors.
Q: What is the molecular formula
of this compound, including any salt that it may have?
A: C5H8N403S2.
Q: How many hydrogen bond donors does this compound have?
A: 1.
Q: What is the classification of this molecule? Please respond with
Small Molecule, Protein, Antibody, Oligosaccharide, Oligonucleotide,
Cell, Enzyme, Gene, or Unknown.
A: Small molecule.
3.2. PubChem Drug Instruction Tuning Dataset
In this section, we outline the process of constructing the PubChem Drug Instruction Tuning
Dataset. The data was collected from the PubChem website, which houses information
of 66,469,244 chemical compounds. We utilized the data version last updated on May 9,
20238. Among these compounds, 19,319 possess drug information. After filtering out drugs
lacking detailed textual descriptions, we retained 6,942 drugs.
7. https://pubchem.ncbi.nlm.nih.gov/
8. https://pubchem.ncbi.nlm.nih.gov/classification/
7
DRUGCHAT: TOWARDS ENABLING CHATGPT-LIKE CAPABILITIES ON DRUG MOLECULE GRAPHS
For each drug, we gathered its SMILES string and descriptions from databases including
ChEBI, LOTUS, and YMDB. In total, we acquired 13,818 compound description summaries
and curated 13,818 question-answer (QA) pairs. QA pairs for an exemplar drug in PubChem
are provided in Table 3.
Table 3: Question-answer (QA) pairs for an exemplar drug in the PubChem Drug Instruc-
tion Tuning Dataset.
Compound Name
Canonical SMILES
ChEBI Database
LOTUS Database
YMDB Database
Acetylcarnitine
CC(=O)OC(CC(=O)[O-])C[N+](C)(C)C
Q: Please describe this drug.
A: O-acetylcarnitine is an O-acylcarnitine
having acetyl as the acyl substituent.
It has a role as a human metabolite.
It is functionally related to an acetic acid.
It is a conjugate base of an O-acetylcarnitinium.
Q: Please describe this drug.
A: Acetylcarnitine is a natural
product found in Pseudo-nitzschia multistriata,
Euglena gracilis, and other organisms with data available.
Q: Please describe this drug.
A: L-Acetylcarnitine is a metabolite
found in or produced by Saccharomyces cerevisiae.
4. Method
An overview of DrugChat is provided in Figure 1. It takes a compound molecule graph
as input and allows users to ask multi-turn questions about this compound. For each
question, Drug Chat generates an answer. DrugChat consists of a graph neural network
(GNN), a large language model (LLM), and an adaptor between GNN and LLM. The GNN
learns a representation for the compound molecule graph. The adaptor (which is a linear
transformation matrix) transforms the graph representation into an LLM-compatible soft
prompt vector. The LLM takes a user-question and the graph prompt vector as inputs
and generates an answer. We employ a pretrained GNN from (Hu et al., 2020) and a
pretrained LLM - Vicuna13b (Chiang et al., 2023). When training DrugChat, we fix the
weight parameters of the GNN and LLM, and only update the adaptor's weights. Given
a drug in the instruction tuning data and a question about this drug, the drug's graph is
first fed into the GNN to produce a representation vector which is then fed into the adaptor
to produce a prompt vector. The prompt vector and the question are fed into the LLM
to generate an answer. A negative log likelihood loss between the generated answer and
groundtruth answer is calculated. The adaptor is trained by minimizing this loss. Next, we
introduce each component in DrugChat.
8
DRUGCHAT: TOWARDS ENABLING CHATGPT-LIKE CAPABILITIES ON DRUG MOLECULE GRAPHS
Drug Compound Graph
Pretrained
GNN
→>>
Projection
Layer
Prompt Describe the mechanism of this drug.
Vicuna-13b
Language Model
Answer
O-acetylcarnitine is an O-acylcarnitine having
acetyl as the acyl substituent. It has a role as a
human metabolite. It is functionally related to an
acetic acid. It is a conjugate base of an O-acetylcar-
nitinium...
Figure 1: An overview of the DrugChat framework.
4.1. Graph Neural Networks (GNNs)
A GNN (Hu et al., 2020) utilizes the graph structure and node features to learn multiple
layers of representation vectors for each node v and a representation vector hg for the
entire graph G. The representation of each node is updated by aggregating features from
its neighboring nodes. At layer k, the representation h½ of node v encompasses information
from nodes within the k-hop network neighborhood of v. Formally, he is calculated as
follows:
k-1
h² = 0 (h¹, AGG({hk−¹‚ u = N(v)})),
(1)
where AGG represents a function that aggregates information from neighboring nodes.
σ is a function that combines information from the node feature of the previous layer
and neighboring nodes. N(v) indicates all neighboring nodes for node v. To acquire the
representation vector for the entire graph G, a pooling function f (which is permutation-
invariant, such as averaging) extracts information from all node features at the final layer
K:
hG = f({h, v = G}).
4.2. Large Language Models (LLMs)
LLMs utilize the Transformer (Vaswani et al., 2017) decoder to model the conditional
probability po(n¿\n<i) for token n¿ in a language model. The Transformer decoder applies a
multi-head self-attention block (Vaswani et al., 2017) to the input context tokens and uses a
position-wise feedforward network to calculate the probabilities over output tokens. Given
the context vector of tokens, the token generation probability is computed as follows:
where Ni-1
=
(n1, n2,
ho= Ni-1We + Wp
h₁ = transformer_block(hɩ_1)(1 ≤ 1 ≤ m)
p(ni|Ni−1) = Softmax (hmWT)
3
, ni-1) denotes the context vector of tokens, m refers to the num-
ber of layers, We denotes the token embedding matrix, and Wp represents the positional
embedding matrix.
9
DRUGCHAT: TOWARDS ENABLING CHATGPT-LIKE CAPABILITIES ON DRUG MOLECULE GRAPHS
SMILES
N=C(N)clccc(OCCCOc2ccc(C3-NCCN3)cc2)cc1
Beam search numbers)
Temperature
Start Chatting
Restart
what makes this compound unique?
1
1
A
This compound is unique because it combines both isoenzymes of AChE inhibition (donepezil and
galantamine) in a single molecule, which theoretically could lead to greater synergy in AChE inhibition,
resulting in better clinical outcomes.
what diseases can this compound potentially treat?
This compound has the potential to treat neurodegenerative disorders such as Alzheimer's disease and other
dementias, as well as other conditions such as myasthenia gravis and mild cognitive impairment.
why can it treat Alzheimer's disease?
This compound can potentially treat Alzheimer's disease by inhibiting the breakdown of the neurotransmitter
acetylcholine in the brain. Acetylcholine is involved in memory and cognition, and a deficiency in this
neurotransmitter is thought to contribute to the symptoms of Alzheimer's disease. By inhibiting AChE, this
compound may increase the levels of acetylcholine in the brain, which could potentially improve cognitive
function in people with Alzheimer's disease.
what are the potential side effects of this compound?
The potential side effects of this compound are not yet known. It is important to note that all drugs have the
potential to cause side effects, and it is always possible that this compound could have unexpected or
unintended side effects. Further research is needed to determine the safety and efficacy of this compound in
humans.
Figure 2: A demonstration of the DrugChat framework.
10
DRUGCHAT: TOWARDS ENABLING CHATGPT-LIKE CAPABILITIES ON DRUG MOLECULE GRAPHS
SMILES
CC(C)clcccccl-nlcc(CN2CCN(c3ccccc3)CC2)c2ccccc21
what diseases can this compound potentially treat?
The compound acts by inhibition of PI3KS. It is an experimental medication for cancer.
what type of cancer?
This compound is a potential treatment for various types of cancer, including but not limited to breast cancer,
ovarian cancer, and endometrial cancer.
how can it inhibit PI3K8?
This compound can inhibit PI3K by binding to the catalytic domain of the enzyme and inhibiting its activity,
thereby reducing the production of downstream signaling molecules such as PIP3.
why it can bind to the catalytic domain of the enzyme?
The compound can bind to the catalytic domain of PI3KS because it has a chemical structure that is
complementary to the shape of the catalytic domain, allowing it to fit into the active site of the enzyme and
inhibit its activity. This binding inhibits the conversion of PIP2 to PIP3, which is a key step in the PI3K/Akt
signaling pathway that plays a role in cell growth and survival. The inhibition of PI3K by this compound has
been shown to reduce the proliferation and survival of cancer cells in in vitro and in vivo models, making it a
potential treatment for cancer.
Figure 3: A demonstration of the DrugChat framework.
11
O o
o o
o o
DRUGCHAT: TOWARDS ENABLING CHATGPT-LIKE CAPABILITIES ON DRUG MOLECULE GRAPHS
4.3. Aligned Graph-Text Generation
At this stage, we create a prompt for every training graph-text pair, which allows the LLM
to generate descriptions from drug compound graphs. We utilize a prompt template that
adheres to the conversational format of Vicuna-13b:
Q: < Graph >< GraphFeature >< /Graph >< Instruction
A: < Desc>
(4)
In this prompt, < Graph Feature > is a soft prompt that symbolizes the graph structure
feature encoded by the linear projection layer. < Instruction > serves as a directive
sentence, prompting the LLM to generate descriptions for the drug, such as "Describe the
mechanism of this drug”. During the training stage, < Desc > is populated with descriptive
text from human experts to train the linear projection layer. In the testing stage, < Desc>
remains empty, and the model is expected to generate descriptive text for the provided drug
structure.
5. Results
We tested DrugChat on compound graphs that are not contained in the training data. Fig-
ure 2 and 3 show two examples. DrugChat can answer diverse multi-turn questions about
compounds, such as "what makes this compound unique?”, “what diseases can this com-
pound potentially treat?". Note that these questions are not contained in the training data.
We will perform a systematic quantitative evaluation by collaborating with pharmaceutical
scientists.
6. Conclusions, Limitations and Future Work
In this report, we present the DrugChat framework, designed to answer questions and
generate text descriptions for drugs from their molecular graphs. We develop the ChEMBL
Drug Dataset and the PubChem Drug Dataset to train the DrugChat model. With further
development and evaluation, DrugChat has the potential to enable conversational analysis
of drug compounds.
A potential limitation of DrugChat is language hallucination. Since DrugChat incor-
porates an LLM module, it may occasionally produce untrustworthy answers and descrip-
tions for drugs, which hampers its practical application in real drug discovery pipelines. If
Drug Chat generates seemingly convincing yet incorrect text descriptions, it could mislead
human decision-makers and potentially result in adverse consequences.
In the future, this issue could be mitigated by utilizing higher-quality training data
and implementing effective filtering strategies. Additionally, more advanced GNN encoders
and LLMs will play a crucial role in addressing this challenge. As the number of users
increases, human feedback can also be utilized to fine-tune the DrugChat model through
reinforcement learning techniques (Ouyang et al., 2022).
12
DRUGCHAT: TOWARDS ENABLING CHATGPT-LIKE CAPABILITIES ON DRUG MOLECULE GRAPHS
References
Jerry Avorn. The $2.6 billion pill-methodologic and policy considerations. N Engl J Med.,
2015.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini
Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya
Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric
Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner,
Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models
are few-shot learners. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin,
editors, Advances in Neural Information Processing Systems, volume 33, pages 1877–1901.
Curran Associates, Inc., 2020. URL https://proceedings. neurips.cc/paper_files/
paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.
Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin
Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P.
Xing. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality,
March 2023. URL https://lmsys.org/blog/2023-03-30-vicuna/.
Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, and
Jure Leskovec. Strategies for pre-training graph neural networks. In International Con-
ference on Learning Representations, 2020. URL https://openreview.net/forum?id=
HJ1WWJSFDH.
JP. Hughes, S. Rees, SB. Kalindjian, and KL. Philpott. Principles of early drug discovery.
Br J Pharmacol., 2011.
G. Idakwo, S. Thangapandian, Luttrell, and J. et al. Structure-activity relationship-based
chemical classification of highly imbalanced tox21 datasets. J Cheminform, 2020.
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning.
arXiv:2304.08485, 2023.
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schul-
man, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell,
Peter Welinder, Paul F Christiano, Jan Leike, and Ryan Lowe. Training lan-
guage models to follow instructions with human feedback. In S. Koyejo, S. Mo-
hamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural
Information Processing Systems, volume 35, pages 27730-27744. Curran Associates,
Inc., 2022. URL https://proceedings. neurips.cc/paper_files/paper/2022/file/
b1efde53be364a73914f58805a001731-Paper-Conference.pdf.
D. Paul, G. Sanap, S. Shenoy, D. Kalyane, K. Kalia, and RK. Tekade. Artificial intelligence
in drug discovery and development. Drug Discov Today., 2021.
13
DRUGCHAT: TOWARDS ENABLING CHATGPT-LIKE CAPABILITIES ON DRUG MOLECULE GRAPHS
S. Pushpakom, F. Iorio, and P. et al. Eyers. Drug repurposing: progress, challenges and
recommendations. Nat Rev Drug Discov, 2019.
De Rycker, B. M., Baragaña, and S.L. et al. Duce. Challenges and recent progress in drug
discovery for tropical diseases. Nature, 2018.
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux,
Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien
Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. Llama: Open and
efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.
Ashish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N.
Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In NIPS, 2017.
Xiangxiang Zeng, Hongxin Xiang, Linhui Yu, Jianmin Wang, Kenli Li, Ruth Nussinov, and
Feixiong Cheng. Accurate prediction of molecular properties and drug targets using a
self-supervised image representation learning framework. Nature Machine Intelligence,
2022.
Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. Minigpt-4:
Enhancing vision-language understanding with advanced large language models. arXiv
preprint arXiv:2304.10592, 2023.
14
