--- ABSTRACT ---
우리는 과거 토큰의 창이 주어진 다음 토큰에 대한 예측인자로 대규모 언어 모델 LLaMA-7B를 사용하여 영어 엔트로피의 점근적 상한에 대한 새로운 추정치를 제공합니다. 이 추정치는 [1], [2]에서 현재 사용 가능한 추정치보다 상당히 작습니다. 자연스러운 부산물은 대규모 언어 모델의 예측과 무손실 압축 방식을 결합한 영어 텍스트의 무손실 압축 알고리즘입니다. 제한된 실험의 예비 결과에 따르면 우리의 방식은 BSC, ZPAQ, paq8h와 같은 최첨단 텍스트 압축 방식보다 성능이 우수합니다. I.
