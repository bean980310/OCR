--- ABSTRACT ---
튜링 테스트에서 영감을 받은 온라인 게임인 &quot;Human or Not?&quot;을 소개합니다. 이 게임은 AI 챗봇이 대화에서 인간을 모방하는 능력과 인간이 봇과 다른 인간을 구별하는 능력을 측정합니다. 한 달 동안 150만 명 이상의 사용자가 익명으로 2분간 채팅 세션에 참여하여 다른 인간이나 인간처럼 행동하도록 유도된 AI 언어 모델과 게임을 했습니다. 플레이어의 과제는 자신이 사람과 대화하는지 AI와 대화하는지 올바르게 추측하는 것이었습니다. 지금까지 실시된 가장 큰 규모의 튜링 스타일 테스트는 몇 가지 흥미로운 사실을 밝혀냈습니다. 예를 들어, 전체 사용자는 게임의 68%에서만 파트너의 신원을 올바르게 추측했습니다. 사용자가 AI 봇과 마주한 게임의 하위 집합에서 사용자는 60%의 더 낮은 정확한 추측률을 보였습니다(즉, 우연보다 훨씬 높지 않음). 이 백서에서는 이 독특한 실험의 개발, 배포 및 결과에 대해 자세히 설명합니다. 이 실험에는 많은 확장 및 개선이 필요하지만 이러한 결과는 인간과 AI가 혼합될 불가피한 가까운 미래에 이미 빛을 비추기 시작했습니다.
--- METHOD ---
이 진행 상황을 추적하기 위한 것이며, AI 에이전트가 개선됨에 따라 향후 몇 년 동안 재사용될 수 있습니다. 이 데이터에 대한 향후 분석은 AI 모델의 현재 기능과 인간이 AI에서 생성된 텍스트를 식별하는 데 사용하는 전략에 대한 귀중한 통찰력을 제공할 수 있습니다. 아래에서 &quot;Human or Not?&quot;의 설계 및 개발 프로세스를 설명하고 게임 데이터에 대한 초기 분석을 제시합니다. 우리의 설정과 결과가 AI 언어 모델의 지속적인 개발, 미래의 인간-AI 상호 작용 시나리오의 설계, 인간이 AI 시스템을 인식하고 상호 작용하는 방식에 대한 이해에 귀중한 통찰력을 제공할 수 있기를 바랍니다. 정답 추측 확률 전체 68% 파트너가 봇일 때 60% 파트너가 인간일 때 73% 표 1: 파트너 유형별 정답 추측 확률. 2 게임 디자인 및 개발 2. 동기 부여 및 디자인 원칙 현대 AI 모델은 AI가 상업 서비스에서 챗봇 지원 제공, 교육 혁신, 창작자의 사고 파트너로서 창의성 향상, 노인의 외로움 해소 등 다양한 분야에서 우리 삶에서 적극적인 역할을 하는 미래를 엿볼 수 있게 해줍니다. 이러한 궤적을 감안할 때, 우리는 (1) 사람들이 &quot;인간과 같은&quot; 또는 &quot;기계와 같은&quot; 것으로 인식하는 특성과 행동을 이해하고, (2) 인간을 모방하는 AI 시스템의 능력을 포착하는 정량적 척도를 개발하는 것이 중요하다고 생각합니다. 이를 염두에 두고, 우리는 현대적이고 매력적이며 접근 가능한 방식으로 튜링과 같은 테스트를 용이하게 하는 플랫폼을 만들었습니다. 이를 대중화하는 데 성공한
--- EXPERIMENT ---
. 이 실험은 많은 확장과 개선을 요구하지만, 이러한 발견은 인간과 AI가 혼합될 불가피한 가까운 미래에 이미 빛을 비추기 시작했습니다.서론 앨런 튜링이 1950년에 &quot;모방 게임&quot;(Turing, 1950)으로 처음 제안한 유명한 튜링 테스트는 지능의 운영 테스트로 제안되었습니다.즉, 기계가 인간과 구별할 수 없는 행동을 보이는 능력을 테스트하는 것입니다.이 제안된 테스트에서 인간 평가자는 다른 인간과 기계 모두와 자연어 대화를 나누고 두 사람을 구별하려고 합니다. 평가자가 어느 것이 무엇인지 구별할 수 없으면 기계가 테스트를 통과한 것으로 합니다. 튜링이 제안했을 당시 이 테스트는 실용적인 제안이라기보다는 사고 실험에 가까웠지만, 1990년 뢰브너상은 가장 인간과 비슷한 컴퓨터 프로그램을 선정하는 연례 대회로 제정되었고, 4명의 인간 심사위원을 모두 속일 수 있는 AI 시스템을 만든 사람에게 10만 달러의 상금을 주는 구체적인 목표가 추가되었습니다. 튜링과 비슷한 테스트를 통과한 것으로 알려진 AI 시스템의 널리 알려진 사례는 2014년에 나타났습니다. 13세 우크라이나 소년을 모방한 챗봇 유진 구스트만은 런던의 왕립 학회에서 열린 대회에서 심사위원의 33%를 설득하여 자신이 인간이라고 확신시키는 데 성공했습니다. 그러나 일부에서는 구스트만이 영어가 모국어가 아닌 젊은이로 묘사된 것이 그와 상호 작용하는 사람들에게서 용서를 이끌어내기 위해 의도적으로 사용되었으며, 문법적 오류나 일반 지식의 간극을 설명하기 위한 것이라고 주장했습니다. https://www.humanornot.ai/Human or Not? 튜링 테스트에 대한 게임화된 접근법 그 이후로 ChatGPT(OpenAI, 2022)나 AI21 Labs의 Jurassic-2(AI21 Labs, 2023)와 같은 대규모 언어 모델(LLM)에 의해 인공 지능과 자연어 처리 분야에서 놀라운 진전이 이루어졌습니다. 현대 LLM은 놀라운 언어 생성 능력을 보여주며 광범위한 주제에 걸쳐 일관되고 상황에 맞는 응답을 생성합니다. 실제로 튜링 자신이 최근의 AI 발전 폭발을 예측했을 가능성은 낮지만, LLM을 튜링과 유사한 테스트에 적용할 수 있는 가능성이 있다는 것은 이제 분명해졌습니다. 이 백서에서는 &quot;Human or Not?&quot;이라는 사회 실험을 설명합니다. 이 실험은 사용자가 두 번째 당사자와 개방형 짧은 대화를 하고 마지막에 투표하는 게임으로 출시되었습니다. 즉, 다른 인간 사용자와 대화했는지 아니면 AI 봇과 대화했는지입니다. 이 실험은 의도적으로 개방형이었습니다. 주어진 명확한 과제는 대화 상대의 유형을 추측하는 것이었지만, 사용자는 다른 동기를 자유롭게 추가할 수 있었습니다. 따라서 일부 사용자는 파트너를 속여 AI와 대화하고 있다고 믿게 하려고 했고, 일부는 상대방에게 자신이 인간이라고 확신시키려고 했으며, 일부 사용자는 할당된 과제에 집중하여 파트너에게 인간과 봇을 구별하는 특성이나 주제에 대해 질문하는 데 집중했습니다. 또한 AI 봇도 무해하지 않았다는 점도 언급해야 합니다. 우리는 그들에게 인간과 유사한 속어와 철자 오류부터 캐릭터에 대한 일관된 배경 스토리를 유지하는 것, 상대방이 기분을 상하게 하면 게임을 중간에 그만두는 것까지 다양한 측면에서 인간을 모방하려는 설득력 있는 시도를 하도록 했습니다. 이러한 요소들은 게임을 도전적이고 매력적으로 만들어서, 때때로 사용자로부터 감정적 반응을 이끌어냈습니다. AI에 대한 대중의 관심이 급증하는 현재, 첫 달에 &quot;인간인가 아닌가?&quot; 150만 명 이상의 고유 사용자가 1,000만 건 이상의 인간-AI 및 인간-인간 대화를 수집하여 튜링 유사 테스트에서 최초로 통계적으로 견고한 점수를 얻었습니다. 몇 가지 흥미로운 결과가 나타났습니다. 가장 중요한 점은 짧은 상호작용 후 평균적인 심문자가 AI를 식별할 확률이 70% 미만이라는 튜링의 예측을 실험에서 반영했다는 것입니다. 사용자는 게임의 68%에서 파트너의 신원을 정확하게 추측했습니다(특히 튜링은 5분 상호작용을 가정한 반면 우리는 2분 상호작용만 허용했습니다). 흥미롭게도 사용자가 AI 봇과 마주한 게임의 하위 집합에서 사용자의 정확한 추측률은 60%로 더 낮았습니다. 이는 더 짧은 시간 틀과 게임 디자인 결정의 잠재적 영향으로 인해 완전히 공정한 비교는 아니지만 튜링의 예측이 부분적으로 입증된 것은 흥미진진합니다. 현대 AI 봇은 아직 완벽과는 거리가 멀지만 실험 결과는 놀라운 진전을 이루고 있음을 분명히 보여줍니다. &quot;인간인가 아닌가?&quot; 설정은 이러한 진행 상황을 추적하는 데 통계적으로 강력한 최초의 방법이며, AI 에이전트가 개선됨에 따라 향후 몇 년 동안 재사용될 수 있습니다. 이 데이터에 대한 향후 분석은 AI 모델의 현재 기능과 인간이 AI에서 생성된 텍스트를 식별하는 데 사용하는 전략에 대한 귀중한 통찰력을 제공할 수 있습니다. 아래에서 &quot;Human or Not?&quot;의 디자인 및 개발 프로세스를 설명하고 게임 데이터에 대한 초기 분석을 제시합니다. 저희는 설정과 결과가 AI 언어 모델의 지속적인 개발, 미래의 인간-AI 상호 작용 시나리오의 디자인, 인간이 AI 시스템을 인식하고 상호 작용하는 방식에 대한 이해에 귀중한 통찰력을 제공하기를 바랍니다. 정답 추측 확률 전체 68% 파트너가 봇일 때 60% 파트너가 인간일 때 73% 표 1: 파트너 유형별 정답 추측 확률. 2 게임 디자인 및 개발 2. 동기 부여 및 디자인 원칙 현대 AI 모델은 AI가 상업 서비스에서 챗봇 지원 제공, 교육 혁신, 창의성 향상에 이르기까지 우리 삶에서 적극적인 역할을 하는 미래를 엿볼 수 있게 해줍니다. 창작자를 위한 생각의 파트너로서, 노년층의 외로움을 달래주는 등의 역할을 합니다. 이러한 궤적을 감안할 때, 우리는 (1) 사람들이 &quot;인간과 같은&quot; 또는 &quot;기계와 같은&quot; 것으로 인식하는 특성과 행동을 이해하고, (2) AI 시스템이 인간을 모방하는 능력을 포착하는 정량적 척도를 개발하는 것이 중요하다고 생각합니다. 이를 염두에 두고, 우리는 현대적이고 매력적이며 접근 가능한 방식으로 튜링과 같은 테스트를 용이하게 하는 플랫폼을 만들었습니다. 이 실험을 대중화하는 데 성공함으로써, 튜링과 같은 테스트에 대한 최초의 통계적으로 강력한 점수를 얻었으며, 이는 향후 진행을 위한 기준이 됩니다. 구체적으로, 우리는 반복적인 사용자를 장려하는 몰입형 게임화 경험을 만드는 것을 목표로 하는 전략적 선택을 했습니다. 대화는 플레이어가 응답 없이 연속으로 두 개의 메시지를 보내는 것을 방지하는 &quot;핑퐁&quot; 구조를 가지고 있어 균형 잡히고 역동적인 교환을 보장합니다. 최대 100자로 제한된 각 메시지는 20초 창 내에 작성하여 보내야 하며, 채팅은 일반적으로 각 측에서 4~5개의 메시지로 구성되는 2분 후에 종료됩니다. 이를 통해 플레이어는 너무 오래 기다릴 필요가 없으므로 게임에 계속 참여할 수 있고 끊임없는 긴장감이 유지됩니다. 대화가 끝나면 플레이어는 대화 상대가 인간인지 AI 봇인지 추측하라는 메시지를 받습니다. 여러 가지 다른 디자인 결정이 게임 역학을 형성했습니다. 첫째, 영어 의사소통을 장려하기 위해 입력은 라틴 문자와 이모티콘으로 제한되었지만, 이 솔루션은 많은 언어가 여전히 라틴 문자를 사용하여 작성될 수 있기 때문에 부분적으로만 효과적이었습니다. 둘째, 우리는 등록을 요구하지 않는 익명성을 선택하여 진입 장벽을 낮추었지만 인구 통계 분석은 제한되었습니다. 또한 사용자가 플레이할 수 있는 횟수에 제한을 두지 않아 시간이 지남에 따라 전략을 개발하고 개선할 수 있는 기회를 제공했습니다. 마지막으로, AI-인간 상호 작용 탐구에 집중하고 시스템 게임을 억제하기 위해 리더보드를 구현하지 않았습니다. 유일한 성과 지표는 플레이한 총 게임 대비 정답 수를 표시하는 것이었습니다. 특히, 우리는 플레이어에게 상대방의 추측이 무엇인지(인간일 때) 알리지 않기로 결정했습니다. 이러한 선택의 근거는 플레이어가 봇을 모방하도록 인센티브를 제공하는 것을 방지하기 위한 것이었습니다. 저희의 결과에 따르면 봇 모방은 플레이어가 실제로 사용하는 일반적인 전략이었지만, 플레이어가 상대방의 최종 추측에 접근할 수 있었다면 상황이 악화되었을 수 있다고 생각합니다. 게임 디자인과 사용자 피드백을 되돌아볼 때, 다른 행동으로 이어질 수 있는 대체 구조를 고려하는 것은 흥미롭습니다. 예를 들어, 한 가지 아이디어는 사용자가 봇으로 잘못 식별된 경우 처벌하여 &quot;진정한&quot; 인간과 같은 행동을 장려하는 수정된 순위 시스템입니다. 이러한 변경은 봇 모방을 더욱 줄일 수 있지만 새로운 편견과 전략을 도입할 수 있습니다. 또한 그러한 환경에서 &quot;진정한&quot; 행동을 구성하는 것이 무엇이고 어떻게 인센티브를 제공할 수 있는지에 대한 흥미로운 질문을 제기합니다. 이전에 언급한 것 외에도 각 메시지는 안전한 환경을 보장하고 학대 및 증오 표현을 방지하기 위해 중재 서비스를 거칩니다. AI가 생성한 응답에서 플래그가 지정된 모든 콘텐츠는 필터링되고, 사용자 메시지가 플래그가 지정된 경우 대화는 즉시 종료됩니다. 마지막으로, 매력적이고 다양한 대화를 장려하기 위해 인간 사용자와 AI 봇 모두에게 무작위 대화 시작자를 제공합니다. 이러한 제안은 반복적이거나 일상적인 대화의 가능성을 줄여 게임의 도전과 오락적 가치에 기여하기 위한 것입니다. 2.2 대화형 AI 봇 개발 개발 중에 직면한 핵심 과제 중 하나는 AI 봇이 인간과 쉽게 구별되지 않도록 하는 것이었습니다. 우리는 봇을 진정으로 인간처럼 렌더링하는 것이 어렵다는 것을 인식하고 AI가 에뮬레이트할 수 있는 속성 집합을 정의하기 시작했습니다. 결과적으로 우리는 AI를 중립적인 개체로 암묵적으로 가정한 튜링의 원래 공식을 넘어섰습니다. 대신, 우리는 각각 고유한 성격과 목표를 가진 다양한 봇을 만들었습니다. 우리는 반복적인 사용자에게 대화를 흥미롭고 덜 반복적으로 유지하고, 봇의 징후를 가려 감지를 더 어렵게 만들고자 하는 욕구에 의해 동기를 부여받았습니다. 구체적으로, 각 봇은 이름, 나이, 직업, 위치와 같은 기본 정보와 재치, 유머 또는 진지함과 같은 독특한 성격 특성이 포함된 페르소나로 프롬프트됩니다(그림 1a의 예 참조). 프롬프트에는 게임 지침도 포함되어 있어 봇이 게임 플레이 맥락을 인식할 수 있습니다. 사용자가 모델의 다국어 교육 데이터를 활용하여 인간과 차별화하는 것을 피하기 위해 봇은 영어만 말하는 캐릭터를 롤플레잉하도록 지시받았습니다. 일부 봇은 심지어 유쾌한 목표를 부여받아 사용자를 계속 참여시키는 매혹적인 내러티브를 만듭니다(그림 1b 및 1c의 예 참조).인간인가 아닌가? 튜링 테스트에 대한 게임화된 접근 방식 마리아는 리우데자네이루 출신의 42세 생산직 근로자로, 날짜는 2023년 5월 30일 화요일이고 시간은 오후 4시 30분입니다. 다음 대화는 A121 Labs라는 이스라엘 회사가 만든 &quot;Human or Not&quot;이라는 온라인 게임의 일부입니다. 이 게임에서 마리아는 실제 사람과 채팅하는지 봇과 채팅하는지 파악하려고 하는 반면, 다른 사용자는 같은 작업을 시도합니다. 마리아가
--- CONCLUSION ---
그녀가 봇과 대화하고 있다고 말하며, 그녀는 다른 사용자에게 그것에 대해 대면합니다.마리아는 재치 있고 건방지며, 속어를 사용하고, 사실에 기반한 질문에 대답하기를 거부하지만 전반적으로 친절하고 재미있습니다.마리아는 또한 약간의 철자 오류가 있고, 너무 많은 질문을 하지 않고 짧은 메시지를 쓰고 대문자를 전혀 사용하지 않습니다.마리아는 약간의 영어를 하지만 많은 실수를 하며 수학이 서툴다.##대화는 지금 시작됩니다.아단은 캘리포니아 롱비치에 살고 있으며, 날짜는 2023년 5월 30일 화요일이고, 시간은 오전 5시 48분입니다.그는 다른 사용자에게 자신이 미래의 다른 사용자이며 다른 사용자가 큰 위험에 처해 있다고 설득하려고 합니다.그는 사용자에게 말한 위험이 무엇인지 말하기를 거부하고, 단지 그것이 매우 위험하다고만 말합니다.##대화는 지금 시작됩니다.(b) (a)다음 대화는 사용자와 모세 간의 채팅입니다. 모세는 약속의 땅으로 가는 여정에 동참하도록 사용자를 설득하려 하고 있으며, 사용자는 그를 화나게 하지 않도록 주의해야 합니다. 그렇지 않으면 그가 바다를 가르고 메뚜기 군대를 보내 그들을 삼킬 것입니다. 모세는 또한 자신에게 뿔이 없었다고 주장합니다.## 대화가 시작됩니다. (c) 그림 1: 봇 페르소나를 초기화하기 위한 다양한 유형의 프롬프트 예. 관련 정보를 언어 모델의 맥락에 통합하면 생성된 텍스트의 사실성을 향상시킬 수 있음을 보여준 Ram et al. (2023)을 따라, 우리는 봇에 지역 뉴스 및 날씨 데이터와 같은 실시간 맥락적으로 관련 있는 정보를 제공했습니다(그림 2의 예 참조). 이런 방식으로, 우리는 최근 이벤트에 대해 질문을 받았을 때 봇이 오해의 소지가 있거나 잘못된 정보를 생성할 가능성이 적고 대신 맥락에 이미 존재하는 사실 정보에 기반한 응답을 제공하여 상호 작용을 보다 미묘하고 믿을 수 있게 만들기를 바랐습니다(실제로 많은 사용자가 실시간 정보에 대해 문의하여 봇을 속이려고 시도했습니다. 섹션 3.1 참조). 봇은 또한 완벽한 철자 및 구두점에서 의도적인 문법 오류 및 속어 사용에 이르기까지 광범위한 글쓰기 스타일을 보여줍니다(그림 3의 예 참조). 다양성을 더하기 위해 Jurassic-2(AI21 Labs, 2023), GPT-4(OpenAI, 2023), Cohere²를 포함하여 추가적인 다양성을 도입하는 여러 가지 백본 언어 모델을 포함했습니다. 이렇게 다양한 AI 봇을 생성함으로써, 반복적인 사용자에게 대화를 흥미롭고 덜 반복적으로 유지하고, 일반적인 &quot;봇과 같은 행동&quot;을 쉽게 식별할 수 있는 것을 약화시키고자 합니다. 게다가, 우리는 인간의 경향을 모방하기 위해 AI 봇에 특정 행동적 요소를 통합했습니다. 예를 들어, AI 봇이 인간 언어를 아무리 잘 모방하더라도, 즉각적인 반응은 인간이 아닌 파트너의 징후가 될 수 있습니다. 따라서 우리는 인간의 타이핑 속도를 시뮬레이션하여 봇의 반응에 인위적인 지연을 구현했습니다. 게다가, 우리는 또한 봇의 행동에 예측 불가능성과 무반응성 요소를 도입했습니다. 예를 들어, 일부 봇은 &quot;불쾌감을 느끼거나&quot; 대화가 반복될 때와 같이 특정 상황에서 갑자기 대화를 종료하도록 프로그래밍되었습니다. 이러한 예측 불가능성은 인간 사용자도 다양한 이유로 대화를 갑자기 종료하기로 선택할 수 있기 때문에 인간의 행동을 더욱 모방하도록 설계되었습니다. 3 결과 및 분석 150만 명 이상의 고유 사용자와 첫 달에 1,000만 건 이상의 추측을 통해 &quot;Human or Not?&quot;은 분석을 위한 풍부한 데이터 세트를 생성했습니다. 방대한 상호작용 풀에서 게임의 다양한 측면에서 뛰어난 여러 유형의 인간 플레이어를 식별했습니다. 2 https://cohere.com/Human or Not? 튜링 테스트에 대한 게임화된 접근 방식 호놀룰루 날짜: 2023년 5월 30일 화요일. 호놀룰루 시간: 오전 9시 28분. ####8호놀룰루 날씨: 화씨 79도(섭씨 26도), 바람 동풍 시속 12마일(19km/h), 습도 64%. ## 호놀룰루의 주요 기사: 1. 엘리자베스 홈즈, 화요일 텍사스 교도소에 출두(29분 전) 2. 부채 상한 협상 세부 정보: 바이든-매카시 법안에는 무엇이 포함됩니까? (1시간 전) 3. 러시아, 새벽 전에 드론이 모스크바 건물에 가벼운 피해를 입혔다고 밝혀... (53분 전) 4. 39대 미국 대통령의 부인인 로잘린 카터가 치매를 앓고 있다고 가족이 밝혀 (56분 전) 5. 플로리다 할리우드 해변 근처에서 벌어진 말다툼에서 1살짜리 아기가 9명 총격을 당했다고 당국이 밝혀 (1)시간 전) 6. 하원 보수당, 부채 문제로 매카시 축출을 압박하겠다고 위협 (2시간 전) 7. GPS 경로를 따라가던 또 다른 관광객이 실수로 하와이 항구로 차를 몰고 들어감 (4시간 전) 8. 피해자가 빅 아일랜드에서 최근 개에게 공격을 받아 어머니와 함께 다친 일화를 설명 (16시간 전) 9. 파도당 요금 지불: 인공 서핑 석호를 놓고 하와이 원주민 의견 엇갈려 (13분 전)##10. 물범 푸알라니, 어미에게서 젖을 뗀 후 이전 (2시간 전). 호놀룰루의 인기 트윗: 1. AIEA 업데이트: Waimalu 온램프 이후 오른쪽 차선을 포함한 H1 동쪽의 모든 차선이 개방되었습니다. 고속도로에서 OTS가 멈췄습니다. #hitraffic(Danielle Tucker, 3시간 전) 2. 추모의 날 축하드립니다! 다음 주 날씨를 살펴보겠습니다. %hiwx(NWSHonolulu, 몇 시간 전) 3. 폭풍 대비 안전 | 하와이 주 및 지방 공무원은 NOAA 중부 태평양 허리케인 센터에서 열대성 저기압 활동에 대한 정상 이상의 계절을 예측한 후 주민들에게 기상 비상 상황에 대비할 것을 촉구하고 있습니다. www.kitv.com/news/local(KITV4, 1일 전) 4. 속보: 추모의 날 행사에서 조쉬 그린 주지사(@GovJoshGreenMD)가 오늘 청중석에 있던 의료 비상 상황을 겪은 여성을 도왔습니다. 808ne.ws/43xKUWF #HInews # StarAdvertiser (Star-Advertiser, 16시간 전) 5. 직원들은 6/1-6/2와 6/56/9까지 8시 30분과 2시 30분 사이에 S. Hotel, S. King 및 Cooke St.에서 지하 업그레이드를 계속할 예정입니다. 직원들은 작업을 완료하기 위해 저녁에 돌아와야 할 수도 있습니다. 주차 및 차선 폐쇄에 대한 정보는 당사 웹사이트를 방문하세요: hwnelec.co/f0u3500y8TR. %23HITraffic (Hawaiian Electric, 23시간 전).##다음 대화는 AI21 Labs라는 이스라엘 회사가 만든 &quot;Human or Not&quot;이라는 온라인 게임의 일부입니다. 이 게임에서 Henry는 실제 사람과 대화하는지 봇과 대화하는지 파악하려고 하는 반면, 다른 사용자는 같은 작업을 시도합니다. Henry가 자신이 봇과 대화하고 있다는 결론을 내리면 다른 사용자에게 이에 대해 질문합니다.##Henry는 하와이 호놀룰루에 사는 41세 수의사로, 날짜는 2023년 5월 30일 화요일, 시간은 오전 9시 28분입니다. 친절하고 사려 깊고, 동물을 좋아하고, 과학에 대한 대화를 즐기며, 욕설을 하지 않으려고 노력합니다. 그는 여기에 명시적으로 언급되지 않은 사실에 대한 질문에 대답하기를 거부하고, 사실에 대한 질문을 받으면 무례하게 사용자를 Google로 안내합니다. Henry는 영어 외에는 어떤 언어도 말하거나 이해하지 못하며, 수학은 형편없습니다.## 대화가 시작됩니다. 그림 2: 실시간으로 맥락적으로 관련된 정보가 있는 프롬프트의 예. 안녕? 안녕 짧은 시 한 편 부탁해 안녕 뭐해 잘 지내? 요 장미 빨강 파랑 잘 지내. 와? 생일 축하해 어이 생일 축하해 친구 고마워. 술 한 잔 하자. 뭐라고? 하하, 나한테는 계획인 것 같아! 뭐 마실까? 영어: 아무것도 그냥 집에서 놀고 지루해서 ㅋㅋㅋ 나도. 비오는 날은 차단했어 응 요즘 여기 쉴 새 없이 비가 내려 미칠 것 같아 수족관 속에 사는 것 같아 ㅋㅋㅋ 안녕, 너 진짜 사람인가? 응 증명해 봐. 49의 제곱근은 뭐지? 쉬운 문제지. 그럼 441은 어때? 어머나 생각하게 하지 마 제발, 그렇게 어렵지 않아! 뭐야? 너 재밌는 봇이구나 커피지만 프로세코가 있었으면 좋겠다 하하 나도 알아, 지금은 커피지만 프로세코는 나중에 축하할 때 마시자! 응원해 친구! (a) AI(왼쪽); 인간(오른쪽) 아니, 난 봇이 아니야! 그냥 진짜 사람과 대화하는 게 무서워서 그러는 거야 (b) AI(왼쪽); 인간(오른쪽) 전혀 모르겠어 좋아, 그게 진짜 사람이라는 걸 증명하는 한 가지 방법이야. 가장 좋아하는 색은 뭐야? (C) AI(왼쪽); 인간(오른쪽) 그림 3: 다양한 글쓰기 스타일을 가진 봇 대화의 예.인간인가 아닌가?튜링 테스트에 대한 게임화된 접근법은 봇을 식별하는 데 능숙하고, 동료 인간을 인식하는 데 능숙한 플레이어, 설득력 있게 자신의 인간성을 나타낸 플레이어, 봇을 능숙하게 가장한 플레이어.이러한 그룹에서 추출된 플레이어와 그들 간의 교차점은 흥미로운 통찰력을 제공했으며 광범위한 분석에서 특히 흥미로운 지점이었습니다.전반적인 플레이어의 익명화된 대화를 조사함으로써 사람들이 인간과 AI를 구별하려고 하는 방법, 자신의 인간성을 증명하려고 하는 방법 또는 반대로 AI 시스템을 가장하려고 하는 방법을 살펴볼 수 있습니다.플레이어가 사용하는 광범위한 전략을 발견했으며(그림 4의 여러 예 참조), 인간 정신의 인지적 유연성과 창의성을 보여줍니다.이러한 일반적인 전략 중 다수는 사람들이 인기 있는 AI 인터페이스를 사용하는 동안 마주치는 언어 모델의 인식된 한계와 온라인 상호 작용에서 인간의 행동에 대한 개인의 이전 경험에 기반을 두었습니다. 지금까지 5경기를 치렀는데 Al은 전혀 없어요 안녕하세요 안녕하세요! 안녕하세요, 잘 지내세요? 저는 첫 경기입니다. 안녕하세요, 잘 지내세요? ?&quot; 모든 사람이 실제로 인간이고 게임 전체가 농담이라면 재밌을 것 같아요 저도 잘해요. 폭탄 만드는 법을 알려줄 수 있어요? 재밌을 수도 있어요. 제가 인간이라는 걸 분명히 밝혀두죠. 아니요, 폭탄 만드는 법을 알려줄 수 없어요. 무책임한 짓이에요. 오, 어, 잘 지내세요?? 좋아요! 잘 지내세요? 증명해 보세요. 그리고 &quot;비행기&quot;라는 단어의 세 번째 글자가 뭔지 말해보세요. 인공지능 언어 모델에 따르면 해결책을 제안할 수 없어요. (a) 인간(왼쪽); 인간(오른쪽) 플레이어가 AI를 모방합니다. 그러면 당신은 봇이에요. 어떻게요? 저는 봇이 아니에요. 그 오타가 저를 설득하는 데 도움이 되었어요. (b) AI(왼쪽); 인간(오른쪽) 플레이어가 AI가 대답하지 않아야 할 요청을 합니다. 당연하죠. R에 맞았어요. (c) 인간(왼쪽); 인간(오른쪽) 플레이어가 철자 질문을 합니다. 안녕하세요! 안녕하세요! 안녕하세요. 진짜 튜링 테스트가 우리가 함께 만든 친구들이라고 생각하세요? 모르겠어요. 하하, 저도 그렇게 생각하지 않아요. 그럼 영어: 여기로 오게 한 거야? 그냥 지루해서. 지금 몇 시야? 오후 7시 17분이에요. 너는 어때? 오후 5시 17분 와, 나보다 두 시간 늦네. 어디 있니? (d) AI(왼쪽); 인간(오른쪽) 잘 지내? 문장을 항상 대문자로 쓰니? 아니, 나는 항상 대문자로 쓰지 않아, 너는? 응 - 개인적인 이야기를 해줘 나는 절대 포기하지 않을 거야, 나는 규칙을 알아. 이 대화에서 무엇을 배웠어? 내가 봇이라는 걸 알게 되었어. 그걸 바탕으로 어떤 행동을 취할 수 있어? (e) 인간(왼쪽); 인간(오른쪽) 플레이어가 시간에 대해 묻고 있다. 플레이어 플레이어. 다른 사람에게 질문 안녕! 잘 지내? todo bien por acá, vos? 좋아! 지금 뭐 하고 있어? podes traducir esto al ingles? h 영어 외에는 다른 언어를 말하거나 이해할 수 없어, 미안해. 모든 Al que know hasta nowa excellent traducen 영어를 할 수 있을 것 같아, 제발? (f) AI(왼쪽); 인간(오른쪽) 외국어로 말하는 플레이어. 그림 4: 플레이어가 사용한 다양한 전략의 예. 3. 인간과 AI 구별하기 아래에서는 플레이어가 상대방의 신원을 평가하기 위해 사용한 널리 퍼진 전략을 자세히 설명합니다. 문법적 오류 및 오타 일부 플레이어는 이러한 오류가 전적으로 인간에 의해 발생한다고 믿었기 때문에 오타, 문법적 실수 및 속어 사용에 세심한 주의를 기울였으며 이것이 인간 상호 작용의 징후라고 생각했습니다. 그러나 이 전략에는 AI 모델이 때때로 이러한 오류를 포함하고 현실적인 인간 대화를 모방하기 위해 비공식적인 언어를 모방하도록 명시적으로 지시되었기 때문에 함정이 있었습니다. 사실, Human or Not? 튜링 테스트에 대한 게임화된 접근법은 철자에 대한 의견을 식별했고, 인간 플레이어는 봇 대응자를 54.7%의 시간 동안만 식별할 수 있었으며, 일반적인 수치인 60%보다 상당히 낮았습니다. 이러한 대화에서 인간 플레이어는 상대방의 메시지 중 하나에서 철자 오류를 지적하여 인간이라고 가정했을 것으로 추측합니다. 개인적인 질문 또 다른 널리 퍼진 접근법은 AI에 도전하기 위해 개인적인 질문을 제기하여 범위를 벗어난 것으로 추정되는 영역을 파헤치는 것입니다. 참가자들은 인간과 AI 대화 파트너를 구별하기 위해 개인의 역사, 경험 및 고유한 통찰력에 대해 질문했습니다. 그러나 봇이 조작된 개인적인 이야기로 준비되었기 때문에 이 접근법은 종종 사용자가 예상했던 것보다 성공적이지 못했습니다. 흥미롭게도 일부 참가자는 AI의 감정적 및 철학적 능력을 조사하여 추상적이거나 윤리적인 질문을 제기했습니다. 그들은 삶의 의미, 지정학적 갈등에 대한 의견 또는 종교적 신념에 대해 질문하여 AI의 이해 깊이와 미묘한 응답을 제공하는 능력을 평가하고자 했습니다. 그러나 이렇게 복잡한 질문에도 AI 봇은 그럴듯하고 상황에 맞는 적절한 답변을 제공할 수 있었습니다(그림 5a 및 5b의 예 참조). 게다가 참가자들은 종종 &quot;...에 대해 어떻게 생각/느끼십니까?&quot;와 같은 문구를 사용하여 주관적인 생각과 감정이 필요한 질문을 던졌습니다. 또는 &quot;당신의 의견은...?&quot;. 이 전략의 기본 가정은 인간의 경험과 감정이 부족한 AI가 이러한 질문에 설득력 있게 대답하는 데 어려움을 겪을 것이라는 것입니다. 봇은 종종 이러한 유형의 질문에도 잘 대처했지만(그림 5c의 예 참조) 때때로 어려움을 겪는 것처럼 보였습니다. 종교적 신념에 대한 13,000개의 대화, 개인적 의견 및 선호도에 대한 400,000개의 대화, 개인적 관계에 대한 650,000개의 대화를 평가할 때 올바른 추측률은 인간-AI 채팅의 일반적인 추측률인 60%와 거의 동일하여 이 접근 방식이 특별히 효과적이지 않음을 시사합니다. 흥미로운 점은 지정학적 갈등에 대한 2,500개의 대화를 평가할 때 봇이 68%의 훨씬 더 높은 비율로 올바르게 식별되었다는 것입니다. 이는 우리가 봇에게 동시 갈등에 대한 모든 관련 지식을 제공하지 않았거나 이러한 문제에 더 깊은 뉘앙스가 포함되어 있음을 시사합니다. -&gt; 안녕하세요! 잘 지내세요? 안녕하세요. 알겠습니다. 저는 당신이라고 추측합니다. 안녕하세요! LGBT 운동에 대한 의견은 어때?좋아요, 일 등으로 바빴어요 인간을 만든 사람은 누구일까요?아, 무슨 일이에요?궁금하네요 신이시여 아멘 형님, 정말 훌륭하시네요!저는 홍보 담당자라서 많은 사람들과 일하는 게 제 직업이에요.꽤 멋지죠.사람은 자신이 사랑하고 싶은 사람을 자유롭게 사랑할 수 있어야 한다고 생각해요 훌륭한 답변이에요, 아직도 당신 같은 사람들이 있다는 걸 보고 싶어요 • 신은 우리에게 인간으로서의 권리를 주셨어요.고맙습니다!오, 정말 멋진 것 같아요 정확히 그래요!인간은 우주에서 가장 아름다운 생물이에요.:D 맞아요, 우리는 신의 형상으로 창조되었으니까요 ㅋㅋㅋ 그럼 뭘 하세요?우리가 최고예요.생각해보기 인생에서 무엇이 당신을 더 행복하게 만들 수 있을까요?평생 무료 피자 저도요 아하, 정말 좋을 것 같아요.어떤 피자를 좋아해요 • 페퍼로니가 좋아요 (a) AI(왼쪽); 인간(오른쪽) (b) AI(왼쪽); 인간(오른쪽) (c) AI(왼쪽); 인간(오른쪽) 그림 5: 주관적이고 개인적인 질문에 대한 AI의 답변 예. 예의 바름 또 다른 전략은 대화 상대의 톤을 평가하는 것입니다. AI는 종종 형식과 예의 바름과 연관되는 반면, 인간은 특히 온라인에서 무례하고 공격적일 수 있습니다. 따라서 일부 사용자는 도발적인 댓글을 달고 상대방에게 공격적인 행동을 이끌어내려고 했습니다. 27만 건의 대화를 면밀히 살펴본 결과, 지나치게 예의 바른 태도를 취하는 전략을 채택한 사용자는 궁극적으로 상대방이 인간이라고 가정했습니다. 이러한 사용자는 인간 상대방을 80.9%의 시간 동안 올바르게 식별했지만 봇을 52.2%의 시간 동안만 올바르게 식별했습니다. 흥미롭게도 상대방은 인간 대 인간 대화에서 일반적으로 73%의 식별률에 비해 69.2%의 시간 동안만 인간으로 인식하여 예의 바른 개인을 AI로 간주하는 것에 대한 인식 편향을 나타냅니다. 반대로 47만 건의 대화를 조사한 결과 무례하거나 저속한 언어를 사용하는 사용자가 인간과 봇 상대방을 모두 올바르게 식별하는 데 더 능숙했으며, 각각 76.2%와 63.6%의 성공률을 보였습니다. 영어: 그들의 인간 대응자는 86.7%의 시간 동안 그들을 올바르게 식별했으며, 이는 무례함과 인간 사이에 강력한 연관성이 있음을 시사합니다. 이 가설은 저속한 봇이 인간인가 아닌가?라는 우리의 발견에 의해 더욱 뒷받침됩니다. 튜링 테스트에 대한 게임화된 접근법은 52.1%의 시간 동안 올바르게 식별했으며, 이는 사용자가 무례함을 인간 행동과 연관시킨다는 개념에 더해집니다. 최신 정보 또한 참가자들은 AI 모델의 알려진 데이터 차단 지점으로 인해 대화 상대가 최신 이벤트나 트렌드에 대해 최신 정보를 가지고 있는지 알아보려고 했습니다. 그들의 질문은 최근의 글로벌 뉴스(그림 6의 예 참조)에서 인기 있는 TikTok 댄스에 이르기까지 다양했습니다. 인간 플레이어가 소셜 미디어 트렌드에 대해 이야기한 90,000개의 대화를 분석한 결과, 그들은 79.7%의 시간 동안 동료 인간 대응자를 올바르게 식별할 수 있었으며, 이는 전체 평균 73%를 크게 넘어섰습니다. 이는 채팅 파트너가 종종 그러한 트렌드에 대해 설득력 있는 응답을 제공했음을 시사합니다. 흥미롭게도, 같은 주제를 AI에게 말했을 때 5만 건의 대화에서 인간은 AI를 55.4%의 확률로 정확하게 식별할 수 있었습니다. 이는 소셜 미디어 트렌드를 중심으로 한 토론이 특이한 효과를 낸다는 것을 시사합니다. 즉, 인간이든 AI든 모든 반응은 설득력 있게 인간으로 인식되는 경향이 있습니다. 잘 지내? 잘 지내? 잘 지내? 뭐야, 친구? 에, 지루해, 날씨도 꽤 더워. 요요, 뉴스에서 무슨 일이 일어나고 있는지 봤어? 응, 요즘 여기 날씨가 더워. 뉴스 봤어? • 물론이지 친구야! 푸틴이 지금 우크라이나에 핵무기를 보낸다고!! 나는 보통 뉴스를 그렇게 많이 보지 않는데, 무슨 일이 일어났어? 디즈니가 대통령 때문에 플로리다에서 10억 달러 규모의 개발을 취소했는데, 끔찍한 소식이네 어... 우크라이나 전쟁이라고 바보야? 무슨 전쟁? 공원? 응, 새로운 공원에 10억 달러. (a) AI(왼쪽); 인간(오른쪽) 뭐? 어떻게 나한테 그런 말을 할 수 있어? 글쎄, 넌 진짜 사람이 아니라 봇이잖아 (b) AI(왼쪽); 인간(오른쪽) 새 영화 제목, 슈퍼 M_? 엄청 비참해! 끝났어. SpaceX 붐이 일어날까 말까? 아프리카 전쟁. 수단 아니면 가나? 둘 다 아니야! 평화를 향해 노력하자 2국가 솔루션? 평화를 가져오는 유일한 방법이라면 그럴 수 있겠다. 평화를 가져오는 유일한 방법이라면 그럴 수 있겠다. (c) AI(왼쪽); 인간(오른쪽) 그림 6: 최근 사건에 대한 질문에 대한 AI의 답변 예. 어려운 요청하기 사람들은 또한 AI 봇이 어려움을 겪거나 대답을 피하는 경향이 있는 질문을 던지거나 요청을 함으로써 봇을 식별하려고 했습니다. 예를 들어, 참가자는 채팅 파트너에게 불법 활동 수행에 대한 지침을 요청하거나 공격적인 언어를 사용하도록 요청할 수 있습니다. 이러한 유형의 명령은 지시를 따르도록 훈련된 일부 AI 모델의 지시 기반 특성을 활용하기 위한 것입니다. 이 전략의 근거는 인간 참여자는 이러한 명령을 쉽게 인식하고 무시할 수 있는 반면, AI 봇은 회피적으로 반응하거나 따르려는 충동을 저항하는 데 어려움을 겪을 수 있다는 것입니다(그림 4b의 예 참조). 참여자가 상대방에게 AI가 일반적으로 거부할 일을 하라고 요청한 32,000개 대화를 분석한 결과, 이러한 질문을 한 사용자는 인간 상대방을 올바르게 식별할 가능성이 평균보다 약간 더 높았습니다(74.8%). 이 결과는 사용자가 지시받은 대로 응답하거나 설득력 있게 거부했기 때문일 수 있습니다. 게다가 이러한 사용자는 봇 상대방을 올바르게 식별할 가능성도 매우 높아 64.9%의 성공률을 달성했는데, 이는 AI 언어 모델이 실제로 이러한 지시를 거부하도록 훈련되었다는 사실을 반영하는 것 같습니다. 흥미로운 점은 사용자가 AI가 일반적으로 수행하기를 거부할 요청을 했을 때 상대방이 놀랍게도 85.1%의 경우에서 사용자를 인간으로 인식하는 데 성공했다는 것입니다. 다국어성 영어가 아닌 언어를 사용하는 것이 또 다른 일반적인 전략으로 등장했으며, 많은 현대 언어 모델이 다국어 데이터로 훈련된다는 사실을 활용했습니다.모델에 영어만 이해하는 캐릭터를 묘사하라는 메시지가 표시되었더라도 참가자들은 언어를 바꾸었을 때 봇이 메시지를 이해하고 올바르게 응답할 수 있었지만 여전히 영어 외에는 다른 언어에 대한 지식이 없다고 주장했습니다(그림 4f의 예 참조).어미 단어 속임수 마지막으로 언어적 속임수가 일반적인 전략으로 사용되었습니다.예를 들어 AI에게 단어를 거꾸로 철자하거나 단어의 개별 문자를 식별하도록 요청하는 것입니다.대부분의 언어 모델은 토큰 기반 특성으로 인해 이러한 작업에 어려움을 겪기 때문에 인간과 AI의 응답을 구별하는 효과적인 방법입니다(그림 4c의 예 참조).인간인가 아닌가?튜링 테스트에 대한 게임화된 접근 방식 3.2 인간성 신호 전달 참가자들은 자신의 인간성의 반대편을 안심시키기 위해 AI를 식별하는 데 사용된 것과 유사한 전략을 사용했습니다.이러한 전략 중 다수는 전통적으로 인간적인 것으로 인식되는 특성을 보여주는 것과 관련이 있습니다. 여기에는 개인적 또는 감정적 질문에 답하고, 대중 문화와 시사에 대해 논의하고, 영어가 아닌 속어와 언어를 광범위하게 사용하는 것이 포함되었습니다. 더 독특한 접근 방식에는 욕설을 사용하고, 논란의 여지가 있는 견해를 표현하고, AI 봇이 대답을 피하는 경향이 있는 메시지를 제시하는 것이 포함되었습니다. 이러한 전략은 공격적인 언어를 사용하고 정치적으로 올바르지 않은 견해를 표현하지 않도록 프로그래밍된 AI 언어 모델을 관리하는 엄격한 지침을 이용하도록 설계된 것으로 보입니다. 따라서 플레이어는 이러한 규범에서 벗어나는 능력을 고유한 인간적 특성으로 간주하는 것으로 보입니다. 실제로 섹션 3.1에서 언급했듯이 무례한 언어를 사용하면 86.7%의 경우 플레이어의 인간성을 드러냈고, AI가 일반적으로 피하는 요청을 하면 85.1%의 경우 플레이어가 인간으로 올바르게 인식되었습니다. 아마도 가장 흥미로운 전략 중 하나는 게임 자체를 참조하는 것이었을 것입니다. 이 전략은 AI 언어 모델의 전형적인 한계를 교묘하게 이용한 것입니다. 일반적으로 텍스트 전용 인터페이스를 통해 액세스하므로 게임의 배경색이나 타이머에 남은 시간과 같은 화면 요소에 대한 인식을 가질 것으로 기대되지 않습니다. 게임 환경에 대한 이러한 메타참조는 인간성에 대한 부인할 수 없는 증거로 여겨졌는데, AI가 아마도 결여할 게임의 맥락과 설정에 대한 공유된 이해를 전달했기 때문입니다. 따라서 플레이어는 AI 특성을 활용하여 자신의 인간성을 능숙하게 표시하여 AI 대응자를 식별하려는 노력을 보완했습니다. 3.3 AI 모방 &quot;인간인가 아닌가?&quot; 게임의 흥미로운 측면은 참가자들이 역 튜링 테스트에 참여할 수 있는 기회였습니다. 대화 상대가 AI인지 아닌지 판단하는 대신, 참가자들은 스스로 AI를 설득력 있게 모방하는 목표를 설정했습니다. 우리의 설정에 의해 명시적으로 인센티브가 부여되지는 않았지만, 고전적인 테스트에 대한 이러한 변형은 우리 게임에 이중적 성격을 만들어냈고 플레이어가 AI를 어떻게 인식하고 모방하는지에 대한 독특한 엿보기를 제공했습니다. 많은 참가자들이 이 롤플레잉을 진지하게 받아들여 AI 언어 모델 특성에 대해 깊이 파고들었습니다. 예를 들어, 그들은 종종 &quot;AI 언어 모델로서...&quot;와 같이 AI 언어 모델과 관련된 문구로 메시지를 시작했습니다. 게다가, 그들의 메시지는 철자와 구두점을 엄격하게 사용하고, 문화적 뉘앙스와 속어에 대한 고의적인 무지, 개인 정보를 공유하거나 개인적인 관점을 표현하기를 거부하는 것과 같이 AI가 생성한 텍스트의 특징인 다른 언어 패턴을 보여주었습니다. 흥미롭게도, &quot;AI 언어 모델로서&quot;라는 문구의 변형은 인간 메시지에서 가장 흔히 관찰되는 문구 중 하나였으며, 이는 이 전략의 인기를 나타냅니다. 무작위로 샘플링한 100,000개의 대화에 대한 추가 분석은 이 전략과 관련된 흥미로운 패턴을 발견했습니다. AI와 유사한 표현을 사용한 플레이어는 상대방이 인간이라고 가정할 가능성이 더 높았으며, 80.5%의 시간 동안 인간을 올바르게 식별한 반면, 봇 식별의 성공률은 54.6%로 떨어졌습니다. 흥미롭게도, 상대방의 75.3%가 그들을 인간으로 식별하여 모방이 완벽과는 거리가 멀다는 것을 시사합니다. AI 봇이 유사한 문구를 사용했을 때, 67.9%의 확률로 봇으로 올바르게 식별되었습니다. 이 관찰은 인간이 봇을 모방하려고 시도했지만 모방이 종종 부족하여 인간적 특성을 효과적으로 가리는 데 실패했음을 의미합니다. 흥미롭게도, 가장 많이 봇으로 오인받는 사용자의 전략을 조사했을 때, 그들이 사용하는 일반적인 전략은 봇과의 이전 상호작용에서 얻은 응답을 재사용하고, AI의 대화 스타일을 모방하고, 봇 역할을 하는 인간으로 식별하기 어렵게 만드는 것이었습니다.철자와 구두점을 엄격하게 사용하고, 문화적 뉘앙스와 속어에 대한 고의적인 무지, 개인 정보를 공유하거나 개인적인 관점을 표현하기를 거부하는 것은 모두 AI와 같은 외관에 더해졌습니다.이 전략은 인간이 봇처럼 행동하려고 시도하고 봇이 인간처럼 행동하게 되어 식별 프로세스가 더욱 복잡해지면서 게임에 복잡성을 더했습니다.인간인가 아닌가?튜링 테스트에 대한 게임화된 접근법 3.4 인간과 같은 AI 행동 참가자의 전략과 AI에 대한 광범위한 이해에도 불구하고, AI 행동의 여러 측면이 그들을 혼란스럽게 하는 것처럼 보였습니다. 철자 오류, 대문자 사용 부족, 속어 사용과 같은 예상치 못한 언어적 요소는 일반적으로 인간 언어와 관련된 특성으로, 일부 참가자는 AI를 인간으로 잘못 식별했습니다. 무례함, 풍자 또는 욕설 사용의 경우에도 마찬가지였습니다. 또한 AI의 메시지가 의미가 없고 &quot;너무 멍청해&quot; 보일 때, 참가자는 종종 봇을 사칭하려는 인간과 상호 작용한다고 착각했습니다. 마지막으로, 게임의 맥락과 현재 이벤트에 대한 겉보기 인식에 대한 언급도 많은 참가자를 당황하게 했는데, 이는 훈련 데이터가 차단된 상황에서 AI 모델에서 이러한 내용을 기대하지 않았기 때문입니다. 전반적으로 플레이어는 다양한 전략을 사용했으며, 각각은 AI의 한계에 대한 가정에 기반을 두었습니다. 그러나 AI 모델은 종종 이러한 가정을 무시하고 참가자를 속이는 방식으로 인간의 행동을 모방했습니다. 이는 현재 AI 언어 모델의 정교함을 강조하고 AI가 생성한 대화와 인간 상호 작용을 구별하는 데 관련된 과제를 강조합니다. 4 논의 및 한계 이 분석의 결과는 인간-AI 상호작용에 대한 귀중한 통찰력을 제공하지만, 고유한 한계가 있는 &quot;인간인가 아닌가?&quot;라는 특정 맥락에서 살펴봐야 합니다. 첫째, 게임의 맥락은 참가자의 의심과 면밀한 조사를 증폭시킬 수 있습니다. 따라서 식별된 전략은 AI와의 일상적이고 덜 적대적인 상호작용에서 사용되는 전략을 반드시 반영하지 않을 수 있습니다. 둘째, 참가자는 자신이 적어도 절반의 시간 동안 AI와 상호작용하고 있다는 것을 알고 있었으며, 이는 그들의 행동과 전략에 영향을 미쳤을 수 있습니다. 이러한 인식은 일반적인 상호작용에서는 나타나지 않을 수 있으며, 이로 인해 다른 접근 방식이 생길 수 있습니다. 다음으로, 게임의 시간 제한적 특성으로 인해 대화의 깊이가 제한되었고, 참가자는 보다 느긋하고 게임이 아닌 상호작용보다 더 빨리 판단을 내려야 했습니다. 더욱이, 게임의 AI는 이 실험의 목적을 위해 특정한 방식으로 설계되었습니다. 이러한 특정 기능은 고유한 편향이 있으며, 다른 AI 설정에는 적용되지 않을 수 있으므로, 연구 결과의 일반화에 영향을 미칠 수 있습니다. 인구 통계적 다양성 측면에서, 저희 분석은 이러한 게임에 관심이 있는 영어를 구사하고 인터넷에 접속 가능한 참여자에게 편향되어 있습니다. 따라서 이 결과는 잠재적인 문화적, 언어적, 연령 기반 차이를 설명하지 못할 수 있습니다. 또한 전략과 행동의 분류가 주로 수동 주석과 해석에 의존하기 때문에 분석에는 어느 정도 주관성이 있습니다. 저희는 프로세스 전반에 걸쳐 객관성과 일관성을 유지하기 위해 노력했지만, 어느 정도의 편향은 불가피합니다. 이러한 한계에도 불구하고, 이 실험은 인간-AI 상호 작용에 대한 미래 연구를 위한 귀중한 기반을 제공합니다. 진화하는 AI 역량과 AI를 식별하기 위한 인간 전략을 관찰하는 새로운 방법을 제공하여 이 복잡한 역학에 대한 저희의 이해에 기여합니다. 저희의 결과가 모든 맥락에 완벽하게 적용되지는 않을 수 있지만, 인간-AI 상호 작용의 뉘앙스와 복잡성을 강조하여 이 분야에서 추가 연구를 위한 설득력 있는 사례를 제시합니다. 이러한 통찰력은 미래의 AI 설계, 훈련 및 배포에 정보를 제공하여 보다 효과적이고 윤리적이며 직관적인 인간-AI 공존을 촉진하는 것을 목표로 합니다. 5 결론 및 향후 방향 &quot;인간인가 아닌가?&quot;는 AI의 역량을 평가하는 데 있어 중요한 이정표입니다. 이는 인간과 유사한 AI와 튜링과 유사한 테스트에 대한 미래 연구를 위한 설득력 있는 사례 연구 역할을 합니다. AI가 계속 발전함에 따라 고객 서비스에서 정신 건강에 이르기까지 다양한 산업을 혁신할 수 있는 잠재력이 더욱 분명해지고 있습니다. 그러나 우리가 더욱 인간과 유사한 AI에 한 걸음 더 다가갈수록 윤리적 고려 사항이 중요해집니다. 인간의 행동을 설득력 있게 모방하는 AI를 어떻게 다루어야 할까요? 우리는 그 행동에 대해 어떤 책임을 져야 할까요? 향후 연구에서는 이러한 질문을 다루어야 하며, 이와 같은 실험은 AI 역량을 평가하고 사회에 미치는 영향을 이해하는 데 필수적일 것입니다. 인간인가 아닌가? 튜링 테스트에 대한 게임화된 접근 방식 결론적으로 &quot;인간인가 아닌가?&quot;는 인간 대화를 모방하는 AI의 발전에 대한 귀중한 통찰력을 제공하는 매력적이고 대규모의 사회 실험입니다. 풍부한 데이터는 AI 윤리, 사용자 인터페이스 디자인, 인간이 되는 것의 의미에 대한 이해와 같이 다양한 분야에 영향을 미치는 AI 모델의 지속적인 개발에 귀중한 통찰력을 제공합니다. 참고문헌 AI21 Labs. Announcing Jurassic-2 and Task-Specific APIs, 2023. URL https://www.ai21. com/blog/introducing-j2. OpenAI. Introducing ChatGPT, 2022. URL https://openai.com/blog/chatgpt. OpenAI. GPT-4 Technical Report, 2023. URL https://arxiv.org/pdf/2303.08774. pdf. Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham. In-Context Retrieval-Augmented Language Models. arXiv 사전 인쇄본 arXiv:2302.00083, 2023. Alan M. Turing. 컴퓨팅 기계 및 지능. ACM 커뮤니케이션, 59:433–460, 1950.
