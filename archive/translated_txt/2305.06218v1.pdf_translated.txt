--- ABSTRACT ---
이 논문에서는 대화에서 표현된 사용자의 명시적 선호도에 따라 추천을 제공하는 것을 목표로 하는 대화 추천 작업에 대한 멀티태스크 엔드투엔드 변환기 모델의 성능을 분석합니다. 이 분야의 이전 연구에서는 대화 관리 및 엔터티 추천 작업이 별도의 구성 요소에서 처리되는 복잡한 다중 구성 요소 접근 방식을 채택했지만, T5 텍스트-텍스트 변환기 모델을 기반으로 하는 통합 변환기 모델이 관련 항목을 추천하고 대화 대화를 생성하는 데 모두 경쟁력 있는 성능을 발휘할 수 있음을 보여줍니다. ReDIAL 대화 영화 추천 데이터 세트에서 모델을 미세 조정하고, 멀티태스크 학습 설정에서 MovieLens에서 파생된 추가 교육 작업(예: 입력 영화를 기반으로 한 영화 속성 및 관련 영화 예측)을 만듭니다. 일련의 프로브 연구를 사용하여 추가 작업에서 학습된 지식이 대화 설정으로 전송되어 각 작업이 관련 프로브 점수에서 9%-52% 증가함을 보여줍니다. 1
--- INTRODUCTION ---
상업용 애플리케이션에서 발견되는 최신 추천 시스템은 주로 웹 페이지 클릭, 품목 구매 또는 미디어 스트림에 대한 사용자 기록과 같은 암묵적 선호도에 기반하며, 이러한 작업의 기록을 사용하여 관련 추천을 검색합니다(Rendle et al., 2012). 이러한 접근 방식은 종종 효과가 있지만, 사용자에게 광범위한 기록이 없거나 평소의 틈새 시장과 일치하지 않는 추천을 원하는 경우 명시적 선호도를 활용할 수 있는 시스템이 필요할 수 있습니다. 딥 러닝 언어 모델의 성공이 커지면서 사용자의 명시적 선호도에 따라 사용자 정의 추천을 검색하는 동안 사용자와 직접 통신할 수 있는 대화형 추천 모델을 설계할 수 있게 되었습니다. 대화형 추천 시스템에 대한 대부분의 이전 작업은 다중 구성 요소 접근 방식을 채택합니다(Gao et al., 2021). 이러한 모델은 종종 언급된 엔터티를 분석하여 관련 품목을 예측하는 추천 구성 요소와 입력 문구를 분석하고 대화형 응답을 생성하는 대화 구성 요소를 사용하여 구현됩니다(Jannach et al., 2020). 다중 구성 요소 접근 방식은 대화 및 추천 분야의 표준 모델에서 직접 구축할 수 있기 때문에 매력적입니다. 그러나 각 구성 요소에서 학습한 지식은 다른 구성 요소에서 즉시 사용할 수 없습니다(즉, 항목 추천 모델은 대화 상태에서 직접적인 이점을 얻지 못하고 그 반대의 경우도 마찬가지). 따라서 이러한 접근 방식은 데이터를 최대한 활용할 수 없습니다. 이상적으로 대화 추천 모델은 대화에서 설명적 언어를 사용하여 관련 항목을 검색하고 항목에 대한 매력적인 대화를 동시에 생성할 수 있어야 합니다. 이 문제를 해결하기 위해 이 논문에서는 단일 구성 요소 모델을 사용하는 대화 추천에 대한 종단 간 접근 방식이 모델이 두 작업 모두에 대화 기능을 완전히 활용할 수 있도록 하여 대화 및 추천 생성을 개선할 수 있는지 조사합니다. 이 논문은 단일 대형 변환기 모델을 활용하여 관련 추천과 자연스러운 대화를 모두 생성하고 완전히 통합된 대화 및 추천 모듈의 이점을 평가하여 대화 추천에 대한 통합 모델의 타당성을 보여주고자 합니다. 단일 엔드투엔드 모델이 다중 구성 요소 접근 방식과 일치하거나 더 나은 성능을 보이는지 확인하기 위해, 우리는 영화 추천 도메인에서 여러 표준 데이터 세트에 대해 모델을 훈련하고 결과를 이전 작업과 비교합니다. 동일한 모델에서 대화와 추천을 생성하는 이점을 측정하기 위해, 우리는 다음에서 일반적인 절차를 따릅니다.
--- RELATED WORK ---
(Penha 및 Hauff, 2020) 및 모델이 대화와 추천을 생성하기 위해 다양한 유형의 정보를 활용하는 방식을 평가하기 위한 일련의 프로브를 설계합니다. 단일 구성 요소 시스템의 잠재적인 문제 중 하나는 추천과 언어 정보를 모두 포함하는 샘플 대화의 대규모 데이터 세트에 의존한다는 것입니다. 단일 대규모 대화 데이터 세트에 대한 필요성을 우회하기 위해, 우리는 비교적 작은 대화 데이터 세트에서 사전 학습된 T5 모델을 미세 조정하고, 멀티태스크 설정을 사용하여 추가 데이터 세트에서 영화 관계, 속성 및 설명 정보를 통합합니다. 이 논문의 주요 기여는 다음과 같습니다. • 대화와 항목 추천 모두에 통합 모델을 사용하는 대화형 추천에 대한 완전한 종단 간 접근 방식. • 대화형 추천 작업이 여러 개의 개별 소규모 데이터 세트에서 멀티태스크 교육을 통해 모델이 학습한 지식으로부터 어떻게 이익을 얻는지 보여주는 일련의 프로브 연구 수행. 이 논문의 나머지 부분은 다음과 같이 구성됩니다. 먼저, 대화형 추천 시스템, 변환기 모델 및 프로브 연구에 대한 관련 작업을 간략히 제시합니다. 그 후, 우리는 T5 기반 접근 방식과 모델을 훈련하는 데 사용된 데이터 세트, 작업 및 훈련 절차를 설명합니다. 그런 다음 실험
--- EXPERIMENT ---
영어: al 방법론과 대화와 추천이 공통 모델을 공유함으로써 어떻게 상호 개선되는지 보여주는 일련의 프로브 연구.1.1 관련 연구 이 섹션에서는 대화 추천, 멀티태스크 변환기 모델 및 프로브 연구를 통한 대화 추천 모델 평가에 대한 간략한 배경 정보를 제공합니다.Gao et al.(2021)이 발표한 최근 설문 조사는 대화 추천 시스템(CRS)이 직면한 다양한 과제를 해결하는 데 사용된 다양한 전략을 강조합니다.자연스러운 대화 질문을 사용하여 정확한 사용자 표현을 구축하는 모델이 수행하는 질문 기반 사용자 선호도 도출(Zou et al., 2020), 다양한 대화 표현을 사용하여 장문 대화에 대한 사용자 선호도를 추적하는 다중 턴 대화 추천 전략(Li et al., 2020), 종종 대규모 사전 학습된 언어 모델을 사용하여 추천을 자연스러운 텍스트로 변환하는 자연어 이해 및 생성(Wang et al., 2021). 이러한 과제는 다양한 다중 구성 요소 모델을 사용하여 접근되었지만, 저희 모델은 단일 구성 요소 변환기 모델이 대화형 추천 작업을 수행할 수 있으며, 통합된 설계로 인해 교차 작업 전송의 이점을 얻을 수도 있음을 보여주는 것을 목표로 합니다.Deng et al.(2021)의 통합 대화형 추천에 대한 다른 접근 방식은 그래프 기반 마르코프 의사 결정 프로세스를 기반으로 하는 단일 구성 요소 시스템을 구축하는 데 성공했습니다.이 시스템은 미리 정의된 질문 묻기, 추천 및 대화 패턴 간을 전환하여 다중 턴 대화에서 사용자를 추천으로 안내합니다.그러나 이 접근 방식은 대화 패턴의 엄격한 흐름에 고정되어 있으며 자유형 대화나 비구조화된 대화를 만들거나 이해하는 데 필요한 자연어 이해 또는 생성 구성 요소를 포함하지 않습니다.대화 생성은 역사적으로 여러 가지 방법으로 접근되어 왔으며, 최근의 노력은 RNN 모델(LSTM(Hochreiter and Schmidhuber, 1997)과 변환기(Vaswani et al., 2017)와 같은)에 집중되었습니다. 추천 시스템은 일반적으로 행렬 분해 시스템이나 자동 인코더(Ricci et al., 2011)와 같은 다양한 모델을 사용하여 사용자-항목 연관 집합에 대한 협업 필터링을 수행합니다. Li et al. (2018)은 이 두 영역을 기능적 대화형 추천 모델로 결합하는 접근 방식을 제안했으며, 자동 인코더 추천자와 GRU 기반 계층적 인코더-디코더 시스템을 함께 사용하여 대화를 생성합니다. 구성 요소 간에는 일부 상호 작용이 있으며, 언급된 영화와 감정이 자동 인코더에 입력되어 사용자가 좋아하는 영화와 싫어하는 영화를 기반으로 관련 추천을 검색하지만 대화와 추천 생성은 여전히 크게 분리되어 있습니다. Chen et al. (2019)은 이 접근 방식을 한 단계 더 발전시켜 대화에서 언급된 엔터티를 사용하여 관련 항목에 대한 지식 그래프 검색을 수행하고 사용자 표현에 따른 어휘 편향을 변환기 기반 대화 생성 모듈에 다시 추가하는 대화형 추천 시스템을 만들었습니다. 이 모델은 대화와 추천 작업 간의 전이 가능성을 보여주지만, 대화와 추천 기능의 불완전한 표현이 별도의 구성 요소로 전달된 다음 스위칭 네트워크와 결합되는 복잡한 구조가 필요합니다. 이 논문에서는 별도의 구성 요소가 필요 없이 이 교차 작업 전이를 최대한 활용하려고 시도합니다. 최근 몇 년 동안 많은 연구에서 다양한 자연어 생성 작업에서 대규모 사전 훈련된 트랜스포머 기반 언어 모델의 효과를 입증했습니다. 언어를 모델링하기 위해 셀프 어텐션 블록을 사용하는 아키텍처는 Vaswani et al.(2017)에 의해 제안되었으며 다양한 벤치마크에서 최첨단 성능을 달성했습니다. 대규모 텍스트 코퍼스에서 사전 훈련된 경우 BERT(Devlin et al., 2018), GPT-3(Brown et al., 2020), UniT(Hu and Singh, 2021)와 같은 트랜스포머 모델은 최소한의 미세 조정으로 여러 언어 기반 작업을 처리할 수 있는 능력을 보여주었습니다. (Raffel et al., 2019)가 도입한 T5 모델은 여러 출처의 다양한 유형의 지식을 통합하고 텍스트 대 텍스트 형식으로 여러 가지 이질적인 작업을 처리하는 뚜렷한 능력을 보여주었습니다. 대화형 추천 작업에서 이러한 대규모 변환기 모델을 평가하는 것과 관련하여 Penha와 Hauff(2020)가 제안한 효과적인 접근 방식 중 하나는 프로브 연구를 사용하여 생성된 입력 집합에 따라 특정 엔터티의 가능성을 평가하는 모델의 능력을 측정하는 것입니다. Penha와 Hauff는 BERT의 예측, 유사성 및 다음 문장 예측 기능을 사용하여 모델이 책, 영화 또는 노래를 관련 항목이나 속성과 연관시키는 능력을 평가하여 대화형 추천 작업에서 BERT의 성능을 평가합니다. Penha와 Hauff는 대화형 추천에 대한 BERT의 지식을 평가하지만, 그들의 연구에서 BERT가 그 자체로 완전한 대화형 추천 시스템으로 작동하지 않으며 종단 간 CRS의 예로 간주될 수 없다는 점에 유의하는 것이 중요합니다. 그것은 단지 프로브를 서로 순위를 매기는 데 사용되고 있으며, 대화와 추천을 생성하거나 사용자와의 대화를 관리하는 데 사용되지 않습니다.2 우리의 접근 방식 우리 접근 방식의 주요 아이디어는 대화 추천 작업을 텍스트-텍스트 문제의 인스턴스로 공식화하는 것입니다.우리는 ReDial 데이터 세트에 포함된 영화 추천 대화에 대한 사전 학습된 변환기 모델을 미세 조정하고, 다중 작업 학습 설정에서 추가 교육 작업을 도입하여 대화 내의 영화 속성과 설명적 세부 정보를 활용하는 모델의 능력을 개선합니다.이 섹션에서는 T5 변환기 모델에 대한 배경, 각 교육 데이터 세트에 대한 요약 및 우리가 사용한 미세 조정 매개변수에 대한 개요를 제시합니다.2.1 T5 모델 T5는 Raffel et al.(2019)이 만든 대규모의 공개적으로 사용 가능한 인코더-디코더 변환기 기반 모델입니다.이 모델은 텍스트-텍스트 형식을 사용하여 가능한 한 많은 다른 사용 사례를 지원하려는 의도로 교육되고 구조화되었습니다. 추천 시스템의 맥락에서 T5와 관련 모델은 자연어 이해 및 생성 작업에서 좋은 성과를 보이고 하나의 모델 내에서 여러 가지 다른 유형의 텍스트 데이터를 학습하는 능력을 보여주었기 때문에 매력적입니다.2.2 ReDial Dialogue 작업 ReDial(Recommendation Dialogues) 데이터 세트는 Amazon Mechanical Turk(Li et al., 2018)를 통해 수집한 주석이 달린 11248개 대화 세트입니다.각 대화에는 &quot;추천자&quot; 또는 &quot;추천 탐색자&quot; 역할을 하는 두 당사자 간에 전송된 영화와 메시지가 포함됩니다.이 데이터 세트는 비교적 작고 다른 추천 중심 데이터 세트만큼 많은 영화 관계 및 속성 데이터를 캡처하지는 않지만 T5가 대화형 추천의 스타일과 구조를 학습하기에 충분한 예를 제공한다는 것을 발견했습니다.데이터 세트의 각 대화에 대해 인간 추천자의 각 응답에 해당하는 학습 예제를 만듭니다.모델 입력에는 특정 추천자 발화까지의 대화가 포함되고 출력에는 추천자 당사자의 다음 발화가 포함됩니다. 이 형식을 사용하면 T5 모델은 대화의 이전 메시지에서 관련 영화, 속성 및 대화 세부 정보를 구문 분석하고 적절한 응답을 공식화하는 방법을 학습할 수 있습니다.T5의 표준 어휘를 사용하므로 영화 제목은 다른 입력과 마찬가지로 단어로 처리됩니다.모델이 이러한 제목을 학습하도록 돕기 위해 @ 기호를 사용하여 영화 제목과 나머지 대화를 구분합니다.ReDial 대화의 각 메시지 앞에는 출처를 나타내는 [USER] 또는 [ASSISTANT] 태그가 붙습니다.부록 A에 표시된 재다이얼 대화는 추천자의 각 응답에 해당하는 여러 교육 예제로 처리되었습니다.표 1은 이 프로세스의 샘플 교육 예제를 보여줍니다.2.3 MovieLens 시퀀스 작업 MovieLens 25m 데이터 세트는 백만 개의 평가와 백만 개의 태그 연결의 컬렉션입니다.교육 입력 ReDial 대화 [사용자] 로맨틱 코미디를 볼 기분입니다.무엇을 제안하시겠습니까? [Assistant] @ 첫키스 50번째(2004) @ 훈련 네, 그녀는 훌륭합니다.타겟을 좋아하세요?싱어 MovieLens 시퀀스 @ 인크레더블(2004) @ 해리포터와 비밀의 방(2002) 헝거게임 모킹제이 1부(2014) @ MovieLens 태그 드라마, 원작, 원작:책 MovieLens 리뷰 @ 앨리스 인 원더랜드(1951)에 대한 리뷰 @ 언더월드: ing(2012) 어웨이큰-도둑 아마도 (2013) 웨딩(1998) @ 초현실주의가 사이키델릭의 히피 문화와 일치했기 때문일 것입니다.앨리스 인 원더랜드(1951) 지식 대화 추천 속성 설명 표 1: 주요 훈련 과제(ReDial Dialogues)와 추천, 속성, 설명 지식을 높이기 위해 설계된 세 가지 보조 훈련 과제 비교. 종종 영화 관계와 속성을 정량화하는 데 사용됩니다(Harper 및 Konstan, 2015). 이 데이터는 다양한 유형의 영화 정보를 정량화하는 데 사용할 수 있으므로 여러 작업에 활용합니다. 첫 번째 추가 학습 작업은 1-9개의 관련 영화 시퀀스가 주어진 상태에서 영화를 추천하는 것입니다. 이 작업은 ReDial Dialogues 작업에서 추천의 질을 높이기 위해 영화 관계 정보를 통합하며, ML Sequences 작업이라고 합니다. MovieLens 25m 데이터 세트에 포함된 사용자 평가를 사용하여 영화 연관성을 생성하기 위해 동일한 사용자가 4.0/5.0보다 높게 평가한 영화가 10개 있는 곳마다 영화 시퀀스를 만듭니다. 이러한 시퀀스에서 1 &lt; n &lt; 10인 각 n에 대한 예를 만듭니다. 이때 처음 n개의 영화를 입력으로 매핑하고 위치(n + 1)에 있는 영화를 대상으로 매핑합니다. 표 1에 이 형식의 예가 나와 있습니다. 2.4 MovieLens 태그 작업 MovieLens 25m 데이터 세트에는 1,129개 태그 세트에서 각 영화의 관련성을 평가하는 태그 게놈이 포함되어 있습니다(Vig et al., 2012). 이러한 태그는 영화 속성 또는 설명적 단어로, 종종 장르(&quot;공포&quot;, &quot;액션&quot;, &quot;미스터리&quot;), 플롯 요소(&quot;외계인 침략&quot;, &quot;캐릭터 연구&quot;, &quot;부-딸 관계&quot;), 의견(&quot;훌륭한 대본&quot;, &quot;지루한&quot;, &quot;과장된&quot;) 또는 일반 정보(&quot;오스카(남우주연상)&quot;, &quot;책 기반&quot;, &quot;스탠리 큐브릭&quot;)에 해당합니다. 각 영화에 대해 관련성 점수가 0.8을 넘는 각 태그를 영화 태그 목록에 추가합니다. 이러한 태그 목록에서 1~5개 태그를 입력으로 포함하고 관련 영화를 대상으로 하는 예를 무작위로 샘플링합니다. 이 매핑을 통해 모델은 영화 속성 정보를 연관시키고 대화의 설명적 세부 정보를 기반으로 영화를 더 잘 추천할 수 있습니다. 표 1은 태그-영화 매핑의 예를 보여줍니다.2.5 MovieLens 리뷰 작업 MovieLens 리뷰 작업이라고 하는 마지막 훈련 작업은 Penha와 Hauff(2020)가 만든 공동 데이터 세트를 사용하여 추가 영화 설명 및 의견 데이터를 통합합니다.이 작업의 훈련 예제는 MovieLens 데이터베이스에 있는 각 영화와 관련된 IMDB 사용자 리뷰가 포함된 Penha와 Hauff(2020)의 검색 데이터 세트의 리뷰 부분에서 생성됩니다.이러한 리뷰에는 ReDial 데이터 세트에서 찾을 수 있는 캐주얼하고 자연스러운 대화 스타일로 작성된 영화 속성 데이터가 포함되어 있으므로 모델의 자연스러운 텍스트 생성 및 설명 기능에 도움이 됩니다.표 1에서 볼 수 있듯이 이러한 리뷰는 모델이 영화 제목과 잘린 리뷰 1이 주어졌을 때 리뷰의 다음 문장을 예측하도록 요청하는 예제로 처리됩니다.2. 멀티태스크 훈련 T5 모듈은 멀티태스크 훈련을 지원하며, 여기서 훈련 데이터 세트의 예제는 자체 전처리 단계(이 경우 소문자로만 표시)를 통해 로드됩니다. 우리는 기본 크기(2억 2천만 개의 매개변수)를 &#39;의 학습률로 미세 조정하기로 했습니다. MovieLens Reviews 데이터 세트의 영화 제목과 제목 조각이 구분되지 않았기 때문에 MovieLens Reviews 학습 과제는 영화 제목을 구분하기 위해 &#39;@&#39; 기호를 사용하지 않습니다. 40,000단계와 배치 크기 128 2의 경우 0.003입니다. 최대 시퀀스 길이(예: 입력의 경우)와 대상의 경우 128보다 긴 텍스트는 잘립니다. 우리는 효과를 분리하기 위해 4가지 학습 과제의 다른 조합으로 변형을 학습합니다. 각 과제의 예제는 동일하게 자주 로드되었습니다. Raffel 등이 제안한 대로 (2019), 우리는 각 작업에 대한 입력을 작업 레이블로 추가합니다: &quot;대화 다시 걸기:&quot;, &quot;영화 렌즈 시퀀스:&quot;, &quot;영화 렌즈 태그:&quot;, 또는 &quot;영화 렌즈 리뷰:&quot;. 이 지점에서 T5라는 이름은 기본 제공 사전 학습된 T5 모델을 나타내는 데 사용되고 T5-CR이라는 이름은 4가지 미세 조정 작업이 모두 포함된 사용자 지정 T5 모델을 나타내는 데 사용됩니다. 3 기준 평가 엔드투엔드 방식이 대화와 추천에서 경쟁력 있는 성능을 낼 수 있는지 확인하기 위해 BLEU 점수와 리콜을 사용하여 성능을 비교합니다. 이러한 메트릭은 모두 ReDial 데이터 세트와 함께 제공된 평가 세트에서 실행됩니다. BLEU 점수는 모델과 인간 반응의 유사성을 측정하여 대화 품질을 측정하는 역할을 합니다. 리콜 메트릭은 평가 대화에서 모델이 언급한 영화를 ReDial 대화 평가 세트에서 인간 추천자가 언급한 영화 세트와 비교하여 계산합니다. 엔드투엔드 리콜은 Recall @ 1은 대화 작업에서 계산되고, Rec Module Recall은 격리된 추천 모듈이 있는 경우에만 실행된 동일한 영화에서 계산됩니다. 이 두 가지 지표는 이 분야의 많은 이전 작업에서 실행된 표준이기 때문에 선택되었습니다. 우리는 BLEU 또는 Recall 점수를 보고하지 않은 ReDial 및 KBRD 모델에 대한 기준선을 계산했으며, Wang et al.에서 다른 기준선을 출처로 했습니다.표 2에서 가장 관련성 있는 모델을 비교했습니다.(1) HRED CR 시스템인 ReDial(Li et al., 2018), (2) 대화에 변환기를 사용하고 추천에 지식 그래프를 사용하는 KBRD(Chen et al., 2019), (3) 지식 그래프와 변환기를 사용하여 단어와 엔터티 지식을 융합하는 KGSF(Zhou et al., 2020), (4) 사전 학습된 변환기인 GPT-2, (5) 관계형 그래프 합성곱 네트워크(RGCN)가 있는 사전 학습된 언어 모델을 사용하는 RID(Wang et al., 2021). 2 T5는 공개 T5 코드베이스를 사용하여 미세 조정되었습니다: https://github.com/google-research/text-to-text-transfertransformer 3. BLEU BLEU 점수는 기계 번역 및 텍스트 생성 작업에서 사용되는 표준 지표로, 생성된 구문이 예상 대상 구문과 얼마나 유사한지를 정량화합니다(Papineni et al., 2002). 지표를 계산하기 전에 ReDial 예측을 후처리하여 영화 제목을 &quot; _unk_ &quot; 토큰으로 바꿉니다. 이렇게 하면 BLEU 점수가 대화가 대상과 얼마나 가까운지에 대한 정보만 포착하고 올바른/잘못된 영화 제목 및 추천의 영향을 받지 않습니다. 4가지 학습 작업 모두에서 학습한 T5-CR 모델은 KBRD 및 ReDial 모델 접근 방식보다 우수한 성과를 거두어 BLEU 점수 15.39를 달성했습니다. BLEU 점수의 증가는 멀티태스크 학습 설정을 통한 영화 설명 및 속성 데이터 도입과 T5와 같은 대규모 사전 학습된 언어 모델의 일반적인 유창성 증가의 결과일 가능성이 높습니다.Wang 등이 학습한 RID 모델도 사전 학습된 변압기를 사용하여 구축되었으며 20.70점으로 가장 좋은 성능을 보였습니다.3.2 회수 추천의 품질을 평가하기 위해 종단 간 회수를 인간 추천자가 해당 재다이얼 대화에서 제공한 알려진 추천 중 하나에 해당하는 대화에서 모델이 생성한 영화의 백분율로 계산합니다.Rec 모듈 회수는 분리된 추천 모듈만 사용할 때의 회수 @1 점수를 나타냅니다.ReDial, KBRD 및 KGSF 모델과 같은 이전 노력에서 종단 간 회수 점수는 Rec 모듈 회수 점수보다 상당히 낮았는데, 이는 모델이 분리된 추천 작업으로 사용할 때보다 대화에서 추천 지식을 정확하게 적용할 가능성이 낮음을 시사합니다. 이는 통합된 구조로 인해 모델이 고품질 대화와 추천을 동시에 생성할 수 있으므로 엔드투엔드 방식의 이점을 강조합니다. 멀티태스크 T5-CR 모델은 모든 기준 모델을 능가하는 6.93의 리콜 점수를 달성했습니다. 리콜의 증가는 모델의 엔드투엔드 구조로 인해 대화 기능을 사용하여 더 나은 추천을 검색할 수 있고, 영화 관계 및 속성 교육 작업을 통해 사용자 선호도를 보다 정확하게 분석할 수 있기 때문일 가능성이 높습니다. 모델 이름 모델 유형 BLEU Rec 모듈 Recall End-to-End Recall ReDial KBRD KGSF GPT-RID T5-CR Autoencoder + LSTM 8.2.0.Knowledge Graph + Transformer 11.3.0.Knowledge Graph Semantic Fusion 3.0.Pretrained Transformer 1.RGCN + Pretrained Transformer 20.3.Finetuned T5(4개 작업) 15.6.표 2: T5-CR, 4개 작업에 대해 미세 조정된 T5 변형 및 대화형 추천에 대한 이전 접근 방식 간의 BLEU 및 Recall@1 메트릭 비교. 모든 평가 점수는 ReDial 검증 대화에서 모델의 성능을 기반으로 계산됩니다. KGSF, GPT-2 및 RID 모델의 기준 점수와 KBRD 및 ReDial 모델의 End-to-End Recall 점수는 (Wang et al., 2021)에서 가져왔습니다. 4 프로브 연구 ReDial 평가 데이터 세트의 BLEU 및 Recall 점수는 엔드투엔드 모델이 다중 구성 요소 접근 방식보다 성능이 우수할 수 있음을 증명하지만, 이 점수는 멀티태스크 학습 설정이 모델의 대화 및 추천 생성 능력에 어느 정도 도움이 되었는지에 대한 통찰력을 제공하지 않습니다.또한 ReDial 평가 슬라이스는 소수의 영화와 대화 상호 작용을 다룹니다.각 학습 작업의 기여도와 동일한 T5 아키텍처 내에서 교차 작업 전송의 측정 가능한 이점을 확인하기 위해 Penha 및 Hauff(2020) 스타일로 4개의 프로브 연구를 제시합니다.각 프로브는 다양한 유형의 샘플 대화를 조건으로 관련 정보와 관련 없는 정보를 구별하는 T5-CR의 능력을 측정하여 특정 대화 상호 작용을 테스트합니다.모델에 정보가 거의 없는 철자 오류, 대체 제목 및 희귀 영화를 걸러내기 위해 ML Sequences 데이터 세트에서 30회 이상 발생하는 영화 세트를 사용하여 프로브를 생성합니다. 약 5,개의 영화로 구성된 이 세트에서 생성된 프로브 예제를 통해 제한된 ReDial 평가 세트보다 훨씬 더 광범위한 데이터에 대한 평가를 실행할 수 있습니다. 이러한 프로브는 대화 설정에서 멀티태스크 학습을 통해 얻은 정보를 적용하는 모델의 능력을 측정하도록 설계되었으므로 모든 프로브 데이터는 ReDial Dialogue 작업을 통해 평가됩니다. 4.1 추천 프로브 추천 프로브는 모델이 무작위로 선택한 인기 영화와 관련 영화를 구별하는 능력을 측정합니다. ML Sequences 데이터 세트에서 동시 발생을 기반으로 관련 영화를 정량화하기 위해 점별 상호 정보(PMI)의 변형인 PMI²(Role 및 Nadif, 2011)를 기반으로 영화를 순위를 매깁니다. PMI²는 PMI의 일반적으로 사용되는 변형으로, 드물고 빈번하지 않은 항목에 대한 PMI의 알려진 편향을 줄입니다(Role 및 Nadif, 2011). 상위 10개 관련 영화 각각에 대해 ML Sequences 데이터 세트에서 빈도 순으로 순위가 매겨진 상위 10%의 영화에서 무작위 인기 영화를 샘플링합니다. 각 영화에 대해 생성된 10개의 (relatedį, popular;) 쌍 각각에 대해 표 4에서 볼 수 있듯이 영화를 일반적인 대화로 바꿔서 프로브를 만듭니다. 프로브 점수는 관련 영화가 포함된 대상의 모델 로그 가능도 점수, L(0)가 무작위 인기 영화보다 높은 프로브의 백분율로 계산됩니다. 프로브 결과에 거의 영향을 미치지 않고 다양한 문구와 대화 형식이 테스트되었다는 점에 유의하세요. 그림 3에서 볼 수 있듯이 ML Sequences 작업을 도입하면 관련 영화와 무작위 영화를 구별하는 모델의 능력이 향상되어 ReDial 전용 모델과 ReDial + ML Sequences 모델 간의 추천 프로브 점수가 30% 증가한 것으로 나타났습니다. 이 증가는 ML Sequences 작업에서 입력된 영화 시퀀스의 패턴을 일반화하여 대화 작업 내에서 적용할 수 있음을 보여줍니다. 흥미롭게도 ReDial + ML 태그 모델은 ReDial 전용 모델보다 성능이 우수했으며, ReDial 전용 모델보다 추천 프로브 점수가 23% 증가했습니다. 이러한 증가는 엔드투엔드 형식의 이점을 보여줍니다. 대화에서 설명적 단어를 이해하는 데 도움이 되는 데이터가 통합되어 추가 데이터가 영화 관계를 직접 지정하지 않았음에도 불구하고 영화 간 추천 성능이 향상되었습니다. 추천과 대화가 동일한 모델에서 처리되므로 관련성이 없어 보이는 데이터의 패턴을 활용할 수 있습니다. 이 경우 모델은 서로 다른 영화와 관련된 태그의 중복을 사용하여 관련이 있는지 여부를 판단할 가능성이 높습니다. T5 Finetuning Tasks Rec Probe Attr Probe Combo Probe Desc Probe None(T5) 0.0.0.0.ReDial 0.0.0.0.ReDial + ML Sequences 0.0.0.0.ReDial + ML Tags 0.0.0.0.ReDial + ML Reviews 0.0.0.0.All(T5-CR) 0.0.0.0.Table 3: 다양한 Finetuning Tasks를 사용한 T5 모델 간 프로브 점수 비교. 모든 4가지 학습 태스크가 포함된 결합 모델에서 모델이 가장 좋은 성과를 보였습니다(ReDial 전용 모델보다 +37%). 이 점수는 멀티태스크 변환기가 성능 저하 없이 다양한 데이터 소스와 태스크를 통합할 수 있음을 보여줍니다. 전반적으로 추천 프로브의 성능은 학습 태스크 간의 영화 관계 지식 전달을 나타내지만 이 전달은 완벽하지 않습니다. 프로브(ReDial Dialogues 작업에 입력됨)가 Combined 모델에서 .6599점을 달성한 반면, 대화 없이 ML Sequences 작업에 입력된 동일한 쌍은 .7711점을 달성했습니다. 이러한 증가는 MovieLens Sequences 작업에서 ReDial Dialogues 작업으로의 지식 전달이 불완전하거나 ReDial Conversations에 이미 있는 영화 추천 데이터의 편향을 나타냅니다. 마찬가지로, 영화 추천 프로브에 대한 T5의 성능은 영화 쌍에서 .8096점을 달성한 순수 행렬 분해 모델보다 낮습니다. 4.2 속성 프로브 속성 프로브는 모델이 대화에서 나타나는 세부 정보와 설명적 단어를 사용하여 관련 영화를 검색하는 능력을 측정합니다. 표 4에서 볼 수 있듯이 MovieLens 태그 데이터 세트의 각 영화-태그 연관에 대해 프로브가 생성되며, 인기 있는 무작위 영화가 부정으로 사용됩니다. 가장 인기 있는 태그(예: &quot;action&quot; 또는 &quot;excellent&quot;) 중 상당수가 인기 영화의 상당 부분에 적용될 수 있으므로, 부정 태그를 필터링하여 해당 태그와 연관되지 않도록 합니다. 속성 프로브 점수는 멀티태스크 학습의 효과도 입증했으며, ML 태그 작업을 도입한 결과 ReDial 전용 모델보다 성능이 52% 향상되었습니다. 이 프로브는 종단 간 학습의 장점 중 하나를 직접적으로 보여줍니다. 대화 분석과 추천 생성이 동일한 모델에서 이루어지기 때문에 입력 대화(또는 영화 &quot;태그&quot;)에 언급된 설명적 속성은 입력에 영화 제목이 언급되지 않은 경우에도 모델이 해당 속성과 관련된 영화를 검색하는 데 도움이 될 수 있습니다. Combined 모델은 RD Tags 모델보다 성능이 좋지 않았지만 프로브 세트에 대한 정확도가 .7689로 일관되게 수행되었습니다. 4.3 Combination Probe Combination Probe는 모델의 멀티태스크 기능을 측정하여 속성 및 영화 엔터티 데이터를 동시에 사용하여 관련 응답을 생성할 수 있는지 여부를 판별합니다. 표 4에 나와 있듯이, 영화 상위 10개에서 가장 관련성이 높은 각 영화가 공유하는 태그마다 프로브가 생성됩니다. 속성 프로브에서처럼 인기 있는 부정을 필터링하여 주어진 태그와 일치하지 않도록 합니다. 조합 프로브는 이전 두 프로브의 결과를 확장합니다. 모델은 언급된 영화나 영화 속성을 사용하여 추천에 영향을 미칠 수 있을 뿐만 아니라 동시에 두 가지를 모두 수행할 수 있습니다. 문제에 대한 다중 구성 요소 접근 방식은 이전에 언급된 영화나 대화에서 언급된 속성에만 추천을 기반으로 하는 반면, 엔드투엔드 접근 방식은 이러한 정보를 함께 사용합니다. 결합 모델은 입력 대화에서 영화와 태그가 주어졌을 때 프로브 쌍의 84.18%를 구별할 수 있었으며, 이는 추천 또는 속성 프로브에 대한 성능보다 향상되었습니다. 이 개선 사항은 두 가지 유형의 정보를 함께 사용할 때 모델이 관련 영화를 더 정확하게 추천할 수 있음을 보여줍니다. 4.4 영화 설명 프로브 이전 세 프로브는 모델이 조건에 따라 관련 영화 제목을 검색할 수 있는지 테스트합니다.추천 프로브 속성 프로브 입력(관련) [사용자] @ Zootopia(2016)와 같은 영화 추천해 줄 수 있나요?@ [사용자] 뱀파이어 영화 추천해 줄 수 있나요?입력(Rand. 인기) 대상(관련) 물론, @ In- 물론, @ Side Out(2015) 보셨나요?@? @ Interview with the Vampire: the Vampire Chronicles(1994) @?대상(Rand. 인기) 데이터 물론, @ I Am Sam(2001) 보셨나요?@ ML 시퀀스 메트릭 L(T1 | I1) &gt; L(T₂ | I1) 물론, Sicko(2007) 보셨나요?@ ML 태그 조합 프로브 [사용자] @ Looper(2012)와 같은 공상과학 영화 추천해 줄 수 있나요? 물론, @ Edge of Tomorrow(2014)를 보셨나요? 물론, Zoolander(2001)를 보셨나요? 설명 프로브 [사용자] @ Ringing Bell(1978)에 대한 의견은 어떻습니까? @? [사용자] @ Robin Hood: Men in Tights(1993)에 대한 의견은 어떻습니까? @? 어렸을 때 이걸 여러 번 보는 건 꽤나... ML 시퀀스 + 태그 ML 리뷰 L(T1 | I1) &gt; L(T2|11) L(T1|11) &gt; L(T2|I1) L(T1 | I1) &gt; L(T1 | I2) 표 4: 모델이 관련 엔터티를 무작위 부정보다 가능성이 더 높은 것으로 올바르게 순위를 매길 수 있는지 여부를 판별하는 4개의 프로브 세트 비교. 영화 설명 프로브는 역방향을 테스트합니다. 모델이 특정 영화 제목을 조건으로 할 때 관련성 있거나 설명적인 대화를 검색할 수 있습니까? 이를 위해 ML Reviews 데이터 세트에서 리뷰의 처음 네 문장에서 가져온 주어진 리뷰 스니펫의 가능성을 측정합니다. 이전 프로브에서 우리는 가능성을 기준으로 두 개의 다른 타겟을 순위를 매겼지만, 리뷰 스니펫은 길이, 문구, 언어 스타일 및 가능성에 영향을 줄 수 있는 다른 요인에서 크게 다르기 때문에 타겟을 동일하게 유지하고 관련/관련 없는 영화를 조건으로 할 때 주어진 리뷰 스니펫의 가능성을 비교하기로 했습니다. 표 4에서 볼 수 있듯이 관련된 입력 I₁, 임의의 인기 입력 12 및 리뷰 스니펫 T에 대해 로그 가능성 점수를 비교하고 L(T | I1) &gt; L(T | I2)인 빈도를 측정합니다. 설명 프로브는 종단 간 모델에서 영화를 언급하면 모델이 관련 대화를 검색하도록 할 수 있음을 보여줍니다. 이 기능은 언급된 영화가 대화와 별도로 처리되는 기존의 다중 구성 요소 접근 방식에서는 제공되지 않습니다. ML 리뷰 교육 과제는 ReDial 전용 모델보다 9.38% 증가를 가져왔고, 결합 모델은 ReDial 전용 모델보다 11.72% 증가한 0.7929점을 달성할 수 있었습니다. 5
--- CONCLUSION ---
이 논문에서 우리는 엔드투엔드 대화 추천에 대한 멀티태스크 접근 방식을 제시했습니다. 이 분야에서 이전에 발표된 두 모델과 직접 비교했을 때, 우리의 T5 기반 아키텍처는 대화 품질과 추천 측면에서 모두 기준선을 능가했습니다. 추천, 속성 지식 및 설명에 대해 조사했을 때, 우리 모델은 모델 아키텍처를 공유함으로써 대화와 추천을 상호 개선할 수 있음을 보여줍니다. 구체적으로, 조사는 모델이 대화 기능을 사용하여 추천을 알리고 영화 언급을 통해 대화 생성에 영향을 미칠 수 있음을 증명합니다. 이러한 결과는 많은 분야에서 대규모 사전 학습된 트랜스포머 모델이 빠르게 최첨단이 되고 있는 현재 자연어 처리 환경의 일반적인 추세를 뒷받침합니다. 사실, 우리의 연구는 멀티태스크 모델의 더 광범위한 영역에 영향을 미치며, 형식에 관계없이 제한된 데이터 세트(예: ReDial)에 여러 보조 데이터 세트의 정보를 주입할 수 있는 방법을 강조합니다. 미래에는 이 효과로 인해 시스템의 각 기능에 대한 최적화된 구성 요소를 학습하고 결합하는 것에서 모든 원하는 정보를 사전 학습된 멀티태스크 모델에 다른 작업으로 간단히 통합하는 것으로 초점이 바뀔 수도 있습니다.참고 문헌 Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei. 2020. 언어 모델은 few-shot 학습기입니다. CORR, abs/2005.14165. Qibin Chen, Junyang Lin, Yichang Zhang, Ming Ding, Yukuo Cen, Hongxia Yang, Jie Tang. 2019. 지식 기반 추천 대화 시스템을 향하여. CoRR, abs/1908.05391. Yang Deng, Yaliang Li, Fei Sun, Bolin Ding, Wai Lam. 2021. 그래프 기반 강화 학습을 통한 통합 대화형 추천 정책 학습. CORR, abs/2105.09710. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. 2018. BERT: 언어 이해를 위한 딥 양방향 변환기의 사전 학습. CoRR, abs/1810.04805. Chongming Gao, Wenqiang Lei, Xiangnan He, Maarten de Rijke, and Tat-Seng Chua. 2021. 대화형 추천 시스템의 발전과 과제: 조사. CoRR, abs/2101.09459. F. Maxwell Harper and Joseph A. Konstan. 2015. The movielens datasets: History and context. ACM Trans. Interact. Intell. Syst., 5(4). Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computing, 9(8):1735-1780. Ronghang Hu and Amanpreet Singh. 2021. Transformer만 있으면 됩니다: 통합된 Transformer를 사용한 멀티모달 멀티태스크 학습. CORR, abs/2102.10772. Dietmar Jannach, Ahtsham Manzoor, Wanling Cai, and Li Chen. 2020. 대화형 추천 시스템에 대한 조사. CORR, abs/2004.00646. Raymond Li, Samira Kahou, Hannes Schulz, Vincent Michalski, Laurent Charlin, and Chris Pal. 2018. 심층적인 대화형 추천을 향해. arXiv 사전 인쇄본 arXiv:1812.07617. Shijun Li, Wenqiang Lei, Qingyun Wu, Xiangnan He, Peng Jiang, and Tat-Seng Chua. 2020. 속성과 항목을 매끄럽게 통합: 콜드 스타트 사용자를 위한 대화형 추천. CORR, abs/2005.12979. Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: 기계 번역의 자동 평가 방법. 40th Annual Meeting on Association for Computational Linguistics 회의록, ACL &#39;02, 311-318페이지, 미국. Association for Computational Linguistics. Gustavo Penha와 Claudia Hauff. 2020. Bert는 책, 영화, 음악에 대해 무엇을 알고 있을까? 대화형 추천을 위해 Bert를 조사하다. 14th ACM Conference on Recommender Systems, RecSys &#39;20, 388-397페이지, 뉴욕, 뉴욕, 미국. Association for Computing Machinery. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu. 2019. 통합 텍스트-텍스트 변환기를 사용하여 전이 학습의 한계 탐구. arXiv 사전 인쇄본 arXiv:1910.10683. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, Lars Schmidt-Thieme. 2012. Bpr: 암묵적 피드백을 통한 베이지안 개인화 순위. arXiv 사전 인쇄본 arXiv:1205.2618. Francesco Ricci, Lior Rokach, Bracha Shapira, Paul B. Kantor. 2011. 추천 시스템 핸드북. Springer. François Role, Mohamed Nadif. 2011. 단어 유사도의 동시 발생 기반 측정에 대한 저주파 이벤트의 영향 처리 - 점별 상호 정보의 사례 연구. 국제 지식 발견 및 정보 검색 컨퍼런스 회의록, KDIR 2011. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin. 2017. 주의만 있으면 됩니다. 신경 정보 처리 시스템의 발전, 5998-6008쪽. Jesse Vig, Shilad Sen, John Riedl. 2012. 태그 게놈: 새로운 상호 작용을 지원하기 위한 커뮤니티 지식 인코딩. ACM Trans. Interact. Intell. Syst., 2(3). Lingzhi Wang, Huang Hu, Lei Sha, Can Xu, Kam-Fai Wong, Daxin Jiang. 2021. 지식 그래프를 사용한 대화형 추천을 위한 대규모 사전 학습 언어 모델 미세 조정. CORR, abs/2110.07477. Kun Zhou, Wayne Xin Zhao, Shuqing Bian, Yuanhang Zhou, Ji-Rong Wen, and Jingsong Yu. 2020. Improving conversational recommender systems via knowledge graph based semantic fusion. CORR, abs/2007.04032. Jie Zou, Yifan Chen, and Evangelos Kanoulas. 2020. Towards question-based recommender systems. CoRR, abs/2005.14255. A 부록 - Redial 데이터 세트 샘플 ReDial 대화의 시작 부분 예는 ReDial 데이터 세트에서 무작위로 선택하여 1에 표시했습니다. REDIAL CONVERSATION: 발신자: 로맨틱 코미디를 볼 기분입니다. 무엇을 추천하시겠습니까? 응답자: @ 50번째 첫 키스(2004) 그거 보셨나요? 발신자: 오, 그거 봤어요. 정말 좋아요... 그림 1: ReDial 데이터 세트에서 무작위로 선택한 예시의 시작 부분.
