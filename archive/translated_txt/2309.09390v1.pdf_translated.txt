--- ABSTRACT ---
구어 의미 구문 분석(SSP)은 입력 음성에서 기계가 이해할 수 있는 구문 분석을 생성하는 것을 포함합니다. 훈련 데이터에 표현된 기존 애플리케이션 도메인에 대한 견고한 모델을 훈련하거나 새로운 도메인으로 확장하려면 해당 음성 전사-의미 구문 분석 데이터의 세 쌍이 필요하며, 이를 얻는 데 비용이 많이 듭니다. 이 논문에서는 해당 음성 없이 전사-의미 구문 분석 데이터(페어링되지 않은 텍스트)를 사용할 수 있는 방법을 검토하여 이 과제를 해결합니다. 첫째, 기존 텍스트 코퍼스에서 페어링되지 않은 텍스트를 추출할 때, 조인트 오디오 텍스트(JAT)와 텍스트 음성 변환(TTS)을 페어링되지 않은 텍스트에 대한 음성 표현을 생성하는 방법으로 비교합니다. STOP 데이터 세트에 대한 실험 결과, 기존 및 새 도메인의 페어링되지 않은 텍스트는 절대 정확한 일치(EM)에서 각각 2%와 30%의 성능을 향상시킵니다. 둘째, 기존 텍스트 코퍼스에서 페어링되지 않은 텍스트를 사용할 수 없는 설정을 고려합니다. 기존 및 새 도메인에 대해 페어링되지 않은 텍스트를 생성하기 위해 대규모 언어 모델(LLM)을 촉구할 것을 제안합니다. 실험 결과, 의도와 함께 나타나는 예와 단어는 Llama 2.0으로 짝이 없는 텍스트를 생성하는 데 사용할 수 있습니다. 생성된 텍스트를 JAT 및 TTS와 함께 사용하여 구어 의미 구문 분석을 수행하면 기존 도메인과 새 도메인에서 각각 1.4%와 2.6%의 STOP EM이 절대값으로 향상됩니다. 색인 용어 구어 이해, 온디바이스, 짝이 없는 데이터, 대규모 언어 모델, 프롬프트 1.
--- METHOD ---
해당 음성 없이도 전사 의미 분석 데이터(페어링되지 않은 텍스트)를 사용할 수 있는 s. 첫째, 기존의 텍스트 코퍼스에서 페어링되지 않은 텍스트를 추출할 때, Joint Audio Text(JAT)와 Text-to-Speech(TTS)를 페어링되지 않은 텍스트에 대한 음성 표현을 생성하는 방법으로 비교합니다.
--- EXPERIMENT ---
STOP 데이터 세트의 s는 기존 및 새 도메인의 짝이 없는 텍스트가 절대적 정확한 일치(EM)에서 각각 2% 및 30%만큼 성능을 향상시킨다는 것을 보여줍니다. 둘째, 기존 텍스트 코퍼스에서 짝이 없는 텍스트를 사용할 수 없는 설정을 고려합니다. 기존 및 새 도메인에 대한 짝이 없는 텍스트를 생성하기 위해 대규모 언어 모델(LLM)을 촉구하는 것을 제안합니다. 실험 결과 의도와 함께 나타나는 예와 단어를 사용하여 Llama 2.0으로 짝이 없는 텍스트를 생성할 수 있습니다. 생성된 텍스트를 JAT 및 TTS와 함께 사용하여 구어 의미 구문 분석을 수행하면 기존 및 새 도메인에 대해 각각 STOP에서 EM이 1.4% 및 2.6%만큼 향상됩니다. 색인 용어 구어 이해, 온디바이스, 짝이 없는 데이터, 대규모 언어 모델, 촉구 1. 서론 구어 이해(SLU)는 오늘날 대화 에이전트 및 가상 비서를 포함한 많은 실제 세계 응용 프로그램에 필수적입니다. SPOKEN SEMANTIC PARSE(SSP)는 녹음을 기계가 이해할 수 있는 파스 트리로 변환하는 SLU 작업입니다[1]. 엔드투엔드 모델[2]은 음성에서 직접 작동하는 반면, 캐스케이드 모델[3]은 필사본을 기반으로 의미 파스를 생성합니다. 2단계 심의 모델[4]은 1단계 필사본과 음성 임베딩을 사용하여 음성 의미 파스를 개선함으로써 두 가지의 장점을 결합합니다. 그러나 이러한 모델을 감독을 통해 훈련하려면 음성, 필사본 및 의미 파스의 매칭된 3중 데이터가 필요합니다. 이러한 3중 데이터에 주석을 달기 위해서는 비용이 많이 들기 때문에 훈련 데이터의 크기가 제한되고 결과적으로 모델 성능이 저하됩니다. 매칭된 데이터에 대한 필요성은 텍스트 데이터만 사용할 수 있는 방법을 개발함으로써 완화할 수 있습니다. 텍스트 데이터(전사-의미 구문 분석)는 음성보다 더 쉽게 얻을 수 있습니다.기존 텍스트 코퍼스에서 얻거나 대규모 언어 모델(LLM)을 프롬프트하여 얻을 수 있으며, 적은 양의 쌍을 이룬 음성-텍스트 데이터와 많은 양의 쌍을 이루지 않은 텍스트로 모델을 학습하는 것이 유용합니다.텍스트 전용 데이터를 엔드투엔드 모델에 통합하는 것은 간단하지 않습니다.모델 출력 *첫 번째 저자는 Meta Prompt(IWP/EP) LLM에서 이 작업을 수행했습니다.기존 텍스트 코퍼스 파리의 날씨는 어때요?실제 음성이 포함된 쌍을 이룬 사본 JAT 또는 TTS 음성이 포함된 쌍을 이루지 않은 사본 E2E SLU 모델 의미 구문 분석 [IN:GET_WEATHER [SL:LOCATION Paris]의 날씨는 어때요?] 그림 1. 이 논문: 우리는 쌍을 이루지 않은 텍스트를 사용하여 숙고 모델을 학습하는 방법을 설명합니다.여기서 쌍을 이루지 않은 데이터는 LLM 또는 기존 텍스트 코퍼스에서 얻을 수 있습니다. 우리는 JAT 또는 TTS를 사용하여 음성 입력 없이는 얻을 수 없는 쌍이 없는 데이터의 음성 표현을 얻습니다. 이전 연구에서는 음성 인식을 위해 텍스트 데이터를 사용하는 방법을 살펴보았습니다[5–7]. 텍스트에서 학습된 외부 언어 모델은 토큰 예측 확률을 보간하는 데 사용할 수 있지만[8] 추가 메모리가 필요하므로 장치 내 애플리케이션에는 적합하지 않습니다. 조정된 학습 방법[9, 10]은 음성 인식을 위해 음성과 텍스트를 공유 임베딩 공간에 투사하지만 이러한 모델은 견고한 매핑을 학습하기 위해 상당한 양의 쌍이 있는 음성-텍스트 데이터가 필요합니다. 마지막 작업 유형은 쌍이 없는 음성에 대한 음성 표현을 생성합니다. Joint Audio Text(JAT)[11]는 쌍이 있는 데이터에서 평균 음성 임베딩을 사용하여 쌍이 없는 텍스트를 나타냅니다. 이는 계산 비용이 저렴하지만 음성 임베딩에는 실제 음성에 포함된 정보가 포함되지 않습니다. 반면, 텍스트-음성(TTS) 모델[5]의 합성 음성은 유익한 음성 표현을 생성하지만 계산 비용이 많이 들 수 있습니다. 의미 구문 분석을 위해 추가 텍스트 데이터를 수집할 수 있는 경우는 두 가지가 있습니다. (a) 기존 도메인의 모델을 개선하기 위해(ED) 및 (b) 새로운 도메인을 지원하기 위해(ND)입니다. 이 논문에서는 기존 및 새로운 도메인에서 쌍이 없는 텍스트 데이터를 가져올 때 SSP에 대한 JAT와 TTS를 비교합니다. 기존 코퍼스에서 쌍이 없는 텍스트를 사용할 수 없는 경우 SSP에 대한 텍스트 데이터를 생성하기 위해 대규모 언어 모델(LLM) [12-14]을 프롬프트하는 것을 제안합니다. LLM은 입력 프롬프트를 기반으로 현실적인 텍스트를 생성하는 데 뛰어나며, 이 논문에서는 LLama 2.0 [14]을 사용하여 텍스트 데이터를 생성합니다. ED 설정의 경우 사전 훈련된 의미 구문 분석기를 사용하여 대본에서 의미 구문 분석을 얻을 수 있으므로 대본을 생성하는 것으로 충분합니다. 우리는 두 가지 프롬핑 방법을 설명합니다. (a) 의도-단어 기반 프롬핑(IWP), 여기서 LLM은 특정 의도 클래스에 해당하고 의도와 동시에 발생하는 단어를 포함하는 대본을 생성합니다. (b) 예시 기반 프롬핑(EP), 여기서는 제공된 예와 유사한 대본을 생성합니다. 우리는 사전 훈련된 ROBERTa [15] 모델을 사용하여 생성된 발화에 대한 의사 레이블을 생성하고 JAT를 사용하여 SSP 모델을 훈련합니다. 우리는 EP가 더 간단하지만 IWP가 원하는 의도를 더 자주 생성한다는 것을 발견했습니다. 두 방법의 데이터를 사용하면 STOP 데이터의 정확한 일치(EM)가 절대값으로 1.4포인트 향상됩니다. ND 설정의 경우, 의사 레이블링을 위한 사전 훈련된 모델은 새 도메인에서 사용할 수 없으므로 LLM을 사용하여 의미 구문 분석을 직접 생성합니다. 그런 다음 의미 구문 분석에서 대본을 추론합니다. 예시 기반 프롬핑(EP)은 모든 가능한 의도-슬롯 조합에 대한 실제 예와 함께 사용되어 대규모 데이터를 생성합니다. 우리는 생성된 데이터가 조합당 3개의 예만 사용하는 기준선에 비해 EM을 절대적으로 2.3포인트 향상시킨다는 것을 발견했습니다. 요약하면, 이 논문은 다음과 같은 기여를 합니다. 1. 이전에 ASR에 사용된 JAT를 종단 간 음성 의미 구문 분석으로 확장하고 기존 도메인과 새 도메인의 텍스트 데이터에 대해 JAT를 TTS와 비교합니다. 2. LLM을 사용하여 기존 및 새 도메인에서 텍스트 필사본과 의미 구문 분석을 생성하기 위한 프롬프트 전략을 개발합니다. 3. LLM에서 생성된 텍스트 데이터를 JAT 및 TTS와 함께 사용하여 음성 의미 구문 분석을 향상시킬 수 있음을 보여줍니다. 2. SLU에 대한 심의 모델 심의 기반 SLU 모델[4, 16]은 첫 번째 패스에서 ASR 필사본을 예측하는 2단계 모델입니다. 첫 번째 패스 필사본과 오디오를 사용하여 두 번째 패스에서 의미 구문 분석을 생성합니다. 별도로 훈련된 자동 음성 인식(ASR) 및 SLU 구성 요소를 활용하는 캐스케이드 모델과 달리, 심의 모델은 ASR 및 SLU 구성 요소를 함께 최적화합니다.장치 내 스트리밍 기능을 달성하기 위해 첫 번째 패스 ASR 구성 요소는 RNNT(Recurrent Neural Network Transducer)[17-19]를 사용하여 구현됩니다.전사 정확도를 유지하기 위해 심의 모델의 ASR 구성 요소는 독립적으로 훈련되고 동결 상태로 유지됩니다.심의 기반 SLU 모델은 두 가지 기본 모듈로 구성됩니다.(1) 퓨전 및 (2) 디코더.퓨전 모듈은 첫 번째 패스 RNNT 인코더 및 예측기에서 중간 오디오 및 텍스트 임베딩을 각각 결합합니다.멀티 헤드 어텐션[20]을 사용하여 퓨전 모듈은 변환기 기반 디코더 모듈에서 대상 의미 구문 분석 시퀀스를 예측하는 데 사용되는 결합된 표현을 생성합니다.3. 페어링되지 않은 텍스트에 대한 음성 표현 3.1. 영어: Joint Audio-Text Training (JAT) Joint Audio-Text Training(JAT) [11]은 ASR [10, 11, 21, 22]을 개선하기 위해 쌍을 이루지 않은 텍스트 전용 데이터를 활용하는 최근의 접근 방식입니다. 외부 신경망 언어 모델(NNLM)의 토큰 분포를 고려하는 얕은 퓨전과 달리 JAT는 추가 모델 매개변수나 지연 시간이 필요하지 않아 장치 내 스트리밍 ASR에 적합합니다. JAT의 핵심 아이디어는 사용 가능한 쌍을 이룬 음성/텍스트 데이터에 대해 계산된 평균 음성 임베딩을 사용하여 쌍을 이루지 않은 텍스트의 음성 표현을 생성할 수 있다는 것입니다. 이 논문에서는 JAT 접근 방식을 사용하여 &quot;음성 텍스트 의미 분석&quot; 및 &quot;텍스트 의미 분석&quot; 데이터 세트로 모두 학습할 수 있도록 구어체 언어 이해(SLU) 모델을 학습합니다. 3.2. Voicebox를 사용한 음성 합성 Voicebox[23]는 흐름 매칭[24]을 기반으로 하는 최첨단 비자기회귀 음성 생성 모델입니다. 우리는 합성 음성에서 음성 특징을 추출하여 짝이 없는 텍스트에 대한 표현을 생성합니다. 합성 음성은 TTS 모드에서 Voicebox를 사용하여 얻을 수 있습니다. 즉, 오디오는 입력 텍스트를 조건으로 생성합니다. [23]과 달리 우리가 사용하는 Voicebox 모델은 입력 텍스트를 음소가 아닌 문자소로 나타냅니다. 오디오를 생성하려면 먼저 흐름 매칭 기반 기간 모델을 사용하여 입력 텍스트의 각 문자소에 대한 단위 기간을 샘플링한 다음 단위 기간 정보를 사용하여 문자소 시퀀스를 업샘플링합니다. 이 정보는 오디오 모델을 사용하여 스펙트로그램을 생성하는 조건으로 사용됩니다. 마지막으로 HiFi-GAN [25] 보코더를 사용하여 스펙트로그램을 시간 영역 신호로 변환했습니다. 4. LLAMA 2를 사용한 텍스트 데이터 생성. LLama 2.0 [14]은 최대 4096개의 컨텍스트가 있는 대량의 공개적으로 사용 가능한 데이터와 코드로 학습된 공개 오픈 소스 대규모 언어 모델입니다. 이 논문에서는 13B 매개변수 채팅 모델을 사용합니다. 4.1. 기존 도메인에 대한 텍스트 데이터 생성 ED 설정에서 LLM을 사용하여 필사본을 생성하는 것을 제안합니다. 해당 의미 구문 분석은 기존 쌍 데이터에서 학습된 의사 레이블 텍스트 의미 구문 분석 모델을 사용하여 얻습니다. 여기서 의미 구문 분석 모델은 필사본을 입력으로 받고 의사 레이블 의미 구문 분석을 출력으로 생성합니다. 필사본은 의도 단어 기반 또는 예시 기반이라는 두 가지 프롬프트 전략 중 하나를 사용하여 생성할 수 있습니다. 의도 단어 기반 프롬프트(IWP): IWP의 목표는 특정 의도에 따라 분류될 수 있는 필사본을 생성하는 것이며, 선택적으로 &quot;의도 단어&quot;를 포함합니다. 의도 단어는 중지 단어를 제거한 후 주어진 의도와 함께 가장 자주 발생하는 의미 구문 분석의 단어입니다. 그림 2에 예가 나와 있습니다. STOP 데이터에서 모든 의도와 함께 가장 자주 발생하는 40개 단어가 의도 단어로 사용됩니다. 모든 의도 및 의도 단어 조합에 대해 40개 예가 생성됩니다. IWP는 우수한 합성 데이터를 생성하지만 의도와 함께 자주 발생하지 않는 단어는 의도와 관련이 적다는 사실에 의해 제한됩니다. 덜 관련성 있는 의도 단어로 생성된 이러한 예는 원하는 의도 클래스에 따라 분류되지 않을 수 있습니다. 또한 LLM이 소수의 의도-의도 단어 조합을 사용하여 많은 고유한 예를 생성할 수 없기 때문에 생성할 수 있는 합성 데이터의 양이 제한됩니다. 모든 발화를 의도에 따라 분류할 수 있는 의도-슬롯 프레임워크에서 작업하고 있습니다. 다음은 의도의 몇 가지 예와 해당 기능에 대한 설명입니다. 1. IN:ADD_TIME_TIMER - 새 타이머를 만듭니다. 2. IN:GET_ESTIMATED DEPARTURE - 예상 출발 시간을 가져옵니다. 이제 날씨 애플리케이션에 대한 의도를 분류하려고 합니다. IN:GET WEATHER 의도가 주어지면 이 의도에 따라 분류되는 40개의 발화를 생성합니다. 사람과 장소의 이름과 함께 &quot;날씨&quot;라는 단어를 사용하여 40개의 발화를 생성할 수 있습니다. 응답에는 각 줄에 하나의 발화가 있는 번호가 매겨진 발화가 있어야 합니다. 반복되는 응답이 없도록 주의하세요.1부터 시작하세요.그림 2. IWP 기반 발화 생성을 위한 프롬프트 다음 문장과 의도가 비슷한 문장을 60개 더 생성하세요.1. 내일 샌프란시스코 화씨 95도 정도 될까요?2. 오늘 밤 카라치 섭씨 72도 정도 될까요?한 줄에 문장 하나씩 쓰세요.문장 구조가 다른 진술문과 질문을 생성하세요.그림 3. EP 기반 발화 생성을 위한 프롬프트 각 문장은 대괄호 [ ]로 묶어야 합니다.첫 번째 대괄호 [ 뒤에는 대문자로 쓰고 IN:으로 시작하는 인텐트가 와야 합니다(예: IN: GET_WEATHER).문장 안에서 명사에 슬롯을 표시해야 하며, 슬롯도 대괄호 [ 로 묶어야 합니다.슬롯은 모두 대문자로 쓰고 SL:로 시작합니다(예: SL:LOCATION).각 문장에는 인텐트가 하나만 있을 수 있지만 슬롯은 여러 개 있을 수 있습니다. 다음은 몇 가지 예입니다. 1. [IN:GET WEATHER [SL:LOCATION 파리]의 날씨는 어때요?] 2. [IN:GET WEATHER [SL:LOCATION 북극]의 기온은 얼마인가요?] 3. [IN:GET WEATHER [SL:LOCATION 센트럴 파크]의 날씨는 어때요?] IN: GET WEATHER와 SL:LOCATION 슬롯 중 하나를 사용하여 더 많은 예를 생성해 주세요. 문장은 [IN:GET_WEATHER [SL:LOCATION] ]와 같은 의도/슬롯 형식을 가져야 하지만 위의 예와 같이 다른 텍스트가 있어야 합니다. 비슷한 문장 30개를 쓴 다음 중지합니다. 예에서 사람과 장소의 이름을 사용하세요. 그림 4. seqlogical 구문 분석의 EP 기반 생성을 위한 프롬프트 예시 기반 프롬프트(EP): LLM은 강력한 문맥 내 학습자[26]이므로 대안적인 접근 방식은 LLM이 예를 기반으로 필사본을 생성하도록 하는 것입니다. 모든 의도-슬롯 조합에 대해 최대 4개의 무작위 예시 필사본을 제공하고 모델에 유사하지만 다양한 문장 구조를 가진 60개의 추가 필사본을 생성하도록 요청합니다.그림 3에 예시 프롬프트가 나와 있습니다.결과적인 필사본이 항상 예제가 추출된 의도 클래스와 일치하지는 않지만 이 방법을 사용하면 중복 없이 더 많은 양의 데이터를 생성할 수 있습니다.의미 구문 분석 생성 및 품질 평가: LLM에서 생성된 필사본은 먼저 정규화됩니다.기록된 텍스트는 음성 형태로 변환되고, 아포스트로피를 제외한 구두점은 제거되고 텍스트는 소문자로 변환됩니다.의미 구문 분석 의사 레이블은 STOP(EM=86.8)에서 학습된 강력한 ROBERTa 기반 의미 구문 분석기를 사용하여 이러한 정규화된 필사본에서 얻습니다.데이터 품질을 평가하기 위해 얻은 의사 레이블의 의도를 IWP의 프롬프트의 의도 또는 EP의 제공된 예제의 의도와 비교합니다.의도 일치 정확도(IMA)는 의사 레이블의 의도가 프롬프트의 원하는 의도와 일치하는 횟수의 백분율로 정의됩니다. 4.2. 새로운 도메인에 대한 전사-의미적 구문 분석 생성 새로운 도메인의 경우, 쌍을 이룬 데이터와 사전 학습된 모델을 사용할 수 없으므로, 전사와 의미적 구문 분석의 쌍을 직접 생성해야 합니다. 이를 수행하는 한 가지 방법은 LLM을 직접 사용하여 의미적 구문 분석과 해당 전사의 쌍을 생성하는 것입니다. 그러나 생성된 구문 분석과 전사의 일관성을 유지하는 것은 현재 LLM의 경우 어렵습니다. 또 다른 대안은 LLM에서 의미적 구문 분석의 seqlogical 형식만 생성하고 구문 분석에서 전사를 추론하는 것입니다. 분리된 형식과 달리 구문 분석의 seqlogical 형식은 슬롯 및 의도 태그와 함께 전사의 모든 단어로 구성됩니다. 따라서 슬롯 및 의도 태그를 제거하면 seqlogical 구문 분석에서 전사를 얻을 수 있습니다. 예시 기반 프롬프팅: (a) 새 도메인에 대해 인식해야 하는 인텐트와 슬롯이 알려져 있고, (b) 모든 인텐트와 함께 발생할 수 있는 슬롯, 즉 인텐트-슬롯 조합이 알려져 있으며, (c) 모든 인텐트-슬롯 조합에 대해 수동으로 주석이 달린 몇 가지 예시가 알려져 있다고 가정합니다. 이 정보를 사용하여 LLM은 그림 4에 표시된 대로 프롬프팅되어 주어진 인텐트-슬롯 조합에 대한 새로운 seqlogical 구문 분석을 생성할 수 있습니다. 프롬프팅은 먼저 유효한 seqlogical 구문 분석을 생성하는 단계를 설명한 다음 원하는 인텐트-슬롯 조합을 가진 seqlogical 구문 분석의 최대 3개 예시를 제시합니다. 사후 처리: 생성된 seqlogical 구문 분석은 괄호의 잘못된 배치, 어휘 범위 밖(OOV) 인텐트 및 슬롯이 있는지 확인합니다. OOV 인텐트는 OOV 인텐트를 올바른 인텐트로 바꾸고 첫 번째 인텐트 이외의 인텐트를 바꾸도록 모델을 다시 프롬프팅하여 수정했습니다. 모든 OOV 슬롯은 해당 슬롯 단어를 유지하면서 제거됩니다. 5. 실험 설정 5.1. STOP 데이터, 모델 및 메트릭 데이터: STOP[27]은 구어체 의미 분석을 위한 실제 음성이 포함된 공개 데이터 세트입니다. STOP에는 알람, 이벤트, 메시징, 음악, 내비게이션, 알림, 타이머 및 날씨의 8개 도메인에 대한 데이터가 있습니다. 이 데이터에는 28개의 고유한 의도와 82개의 슬롯 유형이 포함되어 있습니다. 메트릭: 모든 모델을 평가하는 데 정확한 일치(EM)가 사용됩니다. ASR 오류가 없는 발화에 대한 정확한 일치 정확도인 EM(No Err) 및 ASR 오류가 있는 발화에 대한 정확한 일치 정확도인 EM w/ Err을 보고합니다. 모델 구성: ASR 모듈의 경우 인코더에 컨포머 레이어, 예측기에 LSTM 레이어 1개, 조이너에 선형 레이어 1개가 있는 RNNT를 사용합니다. 심의 모델의 경우 Fusion 모듈에서 어텐션을 사용하고, Pooling 모듈에서 2개의 트랜스포머 인코더 계층을 사용하고, Decoder 모듈에서 포인터 생성기가 있는 트랜스포머 디코더 계층을 사용합니다[16]. 모델은 최대 학습 속도가 8e-3인 Adam[28]으로 최적화되었습니다. 5.2. 설정: 텍스트 코퍼스의 텍스트 데이터 텍스트 데이터를 사용할 수 있다고 가정하는 실험의 경우 STOP 데이터 세트를 두 부분으로 나눕니다. 두 가지 실험을 수행합니다. 하나는 첫 번째와 두 번째 분할을 각각 페어링된 데이터와 페어링되지 않은 데이터로 사용하고, 다른 하나는 두 번째와 첫 번째 분할을 각각 페어링된 데이터와 페어링되지 않은 데이터로 사용합니다. 이러한 실험의 평균 성능은 각 경우에 보고됩니다. ED 설정에서 모든 도메인의 동일한 양의 데이터가 두 분할에 존재합니다. ND 설정의 경우 STOP은 도메인별로 분할되는데, 한 분할에는 4개 도메인(메시징, 알림, 시간 및 날씨)의 모든 교육 데이터가 포함되고, 다른 분할에는 다른 4개 도메인(알람, 이벤트, 음악 및 내비게이션)의 교육 데이터가 포함됩니다. 두 분할 모두 거의 같은 수의 발화가 있도록 설계되었습니다.5.3. 설정: LLM의 텍스트 데이터 짝이 맞지 않는 데이터를 사용할 수 없는 경우 Llama 2.0을 사용하여 ED 및 ND 설정에 대한 예제를 생성합니다.ED 설정의 경우 LLama 2를 사용하여 발화를 생성합니다.그런 다음 STOP에서 학습된 사전 학습된 12계층 ROBERTA 모델을 사용하여 생성된 발화에 대한 가상 레이블을 생성합니다.생성된 LLama 2.0 전사-의미 구문 분석으로 STOP을 보강합니다.JAT는 LLama 2 텍스트를 나타내는 데 사용됩니다.ND 설정의 경우 LLama 2.0에서 생성된 데이터는 일치하는 실제 음성이 없으므로 실제 테스트 세트로 적합하지 않습니다.따라서 기존 STOP 데이터를 7개의 표시된 도메인과 1개의 새 도메인(날씨)으로 분할하기로 했습니다.예시 기반 프롬프트를 사용하여 날씨에 대한 전사-의미 구문 분석 쌍을 생성합니다. 이를 위해 STOP의 실제 전사-의미 구문 분석 예를 사용합니다. TTS를 사용하여 생성된 데이터에 대한 동등한 음성 표현을 생성합니다. (a) STOP의 7개 도메인, (b) 날씨에 대한 예가 있는 STOP의 7개 도메인(예시는 TTS, 7개 도메인은 실제 음성), (c) 예와 Llama 2.0에서 생성된 데이터가 있는 STOP의 7개 도메인, (d) 실제 데이터와 TTS가 있는 STOP의 7개 도메인을 사용하는 최상위 라인에서 훈련된 모델의 날씨 도메인에서의 성능을 비교합니다. 6. 실험 6.1. 텍스트 데이터가 있는 경우 표 1은 기존 도메인과 새 도메인에서 각각 페어링되지 않은 텍스트를 가져온 ED 및 ND 설정에 대한 다양한 모델의 성능을 비교합니다. ED 및 ND 설정에서 페어링되지 않은 텍스트를 사용하면 EM 점수가 향상되는 것을 발견했습니다. ED 설정의 경우 JAT와 TTS가 유사한 정확한 일치 점수를 달성하는 것을 발견했습니다. JAT는 TTS와 성능이 비슷하고 Voicebox와 같은 복잡한 TTS 모델에 비해 비교적 저렴하기 때문에 JAT는 ED 설정에 최적입니다. 또한 JAT와 TTS의 차이는 주로 ASR 오류가 있는 발화에서 나타나는 것으로 보이는데, 합성 음성 표현을 사용하여 ASR 오류가 의미 구문 분석에 미치는 영향을 줄일 수 있기 때문입니다. ND 설정의 경우 JAT가 기준선보다 성능이 뛰어나지만 TTS가 JAT보다 성능이 뛰어납니다. 이는 새로운 도메인에는 인식하기 어려울 수 있는 다른 엔터티와 도메인별 용어가 있을 수 있으며, TTS는 첫 번째 통과 ASR을 기반으로 예측을 개선하는 데 사용할 수 있는 유효한 음성 표현을 제공하기 때문입니다. 그림 5는 쌍을 이루지 않은 텍스트 데이터의 양이 일정한 쌍을 이룬 데이터로 증가하고 상대적인 이득이 어느 정도 증가하고 포화됨을 보여줍니다. 표 1. ED 및 ND의 쌍을 이루지 않은 텍스트에 대한 음성 표현으로서 JAT와 TTS 비교. 쌍을 이룬 발화와 쌍을 이루지 않은 발화의 수, 정확한 일치(EM)가 보고됩니다 모델 기준선 #Pair/#Unpair EM EM(Err 없음) EM w/ Err 60.4k /64.80.24.w/ JAT w/ TTS 60.4k / 60.4k 66.83.25.60.4 / 60.4k 67.83.25.W 기준선 w/ JAT w/ TTS 최상위 60.7k /33.41.13.60.7k / 60.1k 57.73.19.60.7k / 60.1k 63.80.22.120.9k / 0 67.84.26.6.2. LLama 2.0 생성 데이터: ED 설정 표 2는 Llama 2.0을 사용하여 동일한 도메인에서 발화를 생성하기 위한 다양한 프롬프팅 전략을 비교합니다. LLama에서 생성한 데이터를 기존 STOP 데이터와 결합하면 ASR 오류가 있는 테스트 예제와 없는 테스트 예제에서 성능이 향상될 수 있음을 발견했습니다. 추가 분석에서 STOP 기준선에서 상대적으로 성능이 좋지 않은 도메인에서 상당한 개선이 관찰되었음을 발견했습니다. IWP와 EP 사이에서 EP가 약간 더 나은 것을 발견했습니다. EP는 주어진 의도에 따라 분류될 수 있는 발화를 생성하도록 제약받지 않으므로 의도 일치 정확도(IMA)는 EM보다 낮습니다(%)페어링되지 않은 데이터의 백분율로 나타낸 페어링되지 않은 데이터 그림 5. EM에 대한 페어링되지 않은 텍스트 증가의 영향 표 2. LLama 2.0에서 생성된 발화와 ROBERTa 가상 레이블로 교육 데이터를 증강한 영향 평가.EM은 IWP의 정확한 일치 정확도 모델입니다.STOP 기준선 + IWP-JAT #Utts IMA 160k EM 67.EM(Err 없음) EM w/ Err 84.26.+ EP-JAT 230k 68.87 68.218k 64.24 68.84.26.85.27.85.26.+ (IWP+EP)-JAT 298k 67.87 68. 두 전략에서 생성된 데이터를 결합하면 STOP 기준선에 비해 성능이 더욱 향상됩니다.6.3. LLama 2.0 생성 데이터: ND 설정 표 3. 짝이 맞지 않는 텍스트가 보이지 않는 새 도메인에 있는 경우 TTS를 사용하여 LLama 2.0 텍스트에 대한 음성 생성 모델 STOP 7 도메인 + 3개 예제-TTS + 모범 LLama2-TTS 최상위: STOP 날씨-TTS #Utts(날씨)날씨 EM전체 EM 54.48.61.2,50.62.2,63.66.표 3은 날씨에 대한 데이터가 없거나 날씨에 대한 360개 예제가 있는 기준선 모델과 LLama 2.0에서 생성된 데이터를 사용하는 모델의 성능을 비교합니다.Llama 2에서 생성된 텍스트는 절대 EM에서 2포인트 이상 성능을 향상시킬 수 있지만 STOP의 데이터를 사용하는 최상위 성능보다 뒤처집니다.7.
--- CONCLUSION ---
우리는 모델이 텍스트 전용 데이터를 사용할 수 있도록 함으로써 구어 의미 분석을 위해 음성-전사 의미 분석 데이터를 수동으로 레이블링하는 데 드는 높은 비용을 해결합니다. JAT는 기존 도메인의 쌍이 없는 텍스트에 대해 효율성과 쌍이 있는 데이터 기준선에 비해 2.5% EM의 이득을 제공하는 반면, 더 많은 계산 비용이 드는 TTS의 0.1% EM 내에 있기 때문에 선호됩니다. 새로운 도메인의 쌍이 없는 텍스트의 경우 TTS는 전체적으로 JAT보다 절대 EM이 6% 더 높고, 쌍이 있는 기준선에 비해 30.6% EM의 이득을 제공합니다. 기존 텍스트 코퍼스에서 텍스트 데이터를 얻을 수 없는 경우 LLM에 전사 의미 분석 쌍을 생성하도록 촉구하는 것을 제안합니다. 우리는 다른 촉구 전략을 사용하여 비교적 많은 양의 쌍이 없는 텍스트 데이터를 생성할 수 있음을 보여줍니다. JAT와 TTS를 사용하면 이 LLM 생성 데이터를 활용하여 기존 및 새로운 도메인에 대해 SSP를 1.4% EM 및 2.6% EM 절대값으로 더욱 개선할 수 있습니다. [21] 8. 참고문헌 [19] [1] S. Wang, A. Shrivastava 및 S. Livshits, Treepiece: 트리 토큰화를 통한 더 빠른 의미 구문 분석, 2023. [20] [2] S. Arora, H. Futami, S.-L. Wu, J. Huynh, Y. Peng, Y. Kashiwagi, E. Tsunoo, B. Yan, and S. Watanabe, &quot;중지 품질 도전을 위한 음성 의미 구문 분석을 위한 파이프라인 및 e2e slu 시스템 통합에 대한 연구&quot;, Proc. ICASSP, 2023, pp. 1–2. [3] H. Futami, J. Huynh, S. Arora, S.-L. Wu, Y. Kashiwagi, Y. Peng, B. Yan, E. Tsunoo, and S. Watanabe, &quot;중지 저리소스 도전을 위한 mlm 기반 데이터 증강을 갖춘 asr 및 nlu의 파이프라인 시스템&quot;, Proc. ICASSP, 2023, pp. 1–2. [4] D. Le, A. Shrivastava, P. Tomasello, S. Kim, A. Livshits, O. Kalinli, ML Seltzer, &quot;디바이스 음성 언어 이해를 위한 심의 모델&quot;, Interspeech, 2022. [23] [5] G. Wang, A. Rosenberg, Z. Chen, Y. Zhang, B. Ramabhadran, Y. Wu, P. Moreno, &quot;합성 음성에 대한 일관된 예측을 사용하여 음성 인식 개선&quot;, Proc. ICASSP, 2020, 70297033쪽. [22] [24] [6] S. Toshniwal, A. Kannan, C.-C. Chiu, Y. Wu, TN Sainath, K. Livescu, &quot;인코더-디코더 음성 인식에서 언어 모델 통합 기술 비교&quot;, 2018 IEEE 음성 언어 기술 워크숍(SLT), 2018, pp. 369–375. [25] [7] T. Hori, R. Astudillo, T. Hayashi, Y. Zhang, S. Watanabe, and J. Le Roux, &quot;종단간 음성 인식을 위한 사이클 일관성 훈련,&quot; Proc. ICASSP, 2019, pp. 6271-6275. [26] [8] [9] [10] [11] [12] [13] Z. Meng, Y. Gaur, N. Kanda, J. Li, X. Chen, Y. Wu, and Y. Gong, &quot;종단간 음성 인식을 위한 텍스트 전용 데이터를 사용한 내부 언어 모델 적응,&quot; Proc. Interspeech, 2022, pp. 26082612. Z. Chen, Y. Zhang, A. Rosenberg, B. Ramabhadran, PJ Moreno, A. Bapna, and H. Zen, &quot;MAESTRO: Modality Matching을 통한 Matched Speech Text Representations&quot;, Proc. Interspeech, 2022, pp. 4093-4097. TN Sainath, R. Prabhavalkar, A. Bapna, Y. Zhang, Z. Huo, Z. Chen, B. Li, W. Wang, and T. Strohman, &quot;Joist: ASR을 위한 공동 음성 및 텍스트 스트리밍 모델&quot;, Proc. SLT, 2023, pp. 52-59. S. Kim, K. Li, L. Kabela, R. Huang, J. Zhu, O. Kalinli, D. Le, &quot;스트리밍 음성 인식의 트랜스포머 리스코어를 위한 공동 오디오/텍스트 훈련&quot;, EMNLP, 2022. L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al., &quot;인간의 피드백을 통해 지시를 따르도록 언어 모델 훈련&quot;, Advances in Neural Information Processing Systems, vol. 35, pp. 27 730-27744, 2022. H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, et al., 영어: &quot;Llama: 개방적이고 효율적인 기초 언어 모델,&quot; arXiv 사전 인쇄본 arXiv:2302.13971, 2023. [14] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale 외, &quot;Llama 2: 개방형 기초 및 미세 조정된 채팅 모델,&quot; arXiv 사전 인쇄본 arXiv:2307.09288, 2023. [27] [28] C. Liu, F. Zhang, D. Le, S. Kim, Y. Saraf, G. Zweig, &quot;보조 작업을 통한 RNN 변환기 기반 ASR 개선,&quot; Proc. SLT, 2021. A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, AN Gomez, L. Kaiser, I. Polosukhin, &quot;주의만 있으면 됩니다.&quot; 2017. TN Sainath, R. Pang, RJ Weiss, Y. He, C.-c. Chiu, T. Strohman, &quot;주의 기반 조인트 음향 및 텍스트 온디바이스 엔드투엔드 모델&quot; Proc. ICASSP, 2020, 7039-7043쪽. P. Wang, TN Sainath, RJ Weiss, &quot;엔드투엔드 음성 인식을 위한 텍스트 데이터를 사용한 멀티태스크 학습&quot; arXiv 사전 인쇄본 arXiv:2010.14318, 2020. M. Le, A. Vyas, B. Shi, B. Karrer, L. Sari, R. Moritz, M. Williamson, V. Manohar, Y. Adi, J. Mahadeokar, et al., &quot;Voicebox: 텍스트 기반 다국어 범용 음성 생성,&quot; arXiv 사전 인쇄본 arXiv:2306.15687, 2023. Y. Lipman, RT Chen, H. Ben-Hamu, M. Nickel, and M. Le, &quot;생성적 모델링을 위한 흐름 매칭,&quot; arXiv 사전 인쇄본 arXiv:2210.02747, 2022. J. Kong, J. Kim, and J. Bae, &quot;Hifi-gan: 효율적이고 고충실도 음성 합성을 위한 생성적 적대적 네트워크,&quot; Advances in Neural Information Processing Systems, vol. 33, pp. 17022-17033, 2020. J. Wei 외, &quot;대규모 언어 모델의 새로운 능력&quot;, Transactions on Machine Learning Research, 2022, Survey Certification. P. Tomasello, A. Shrivastava, D. Lazar, P.-C. Hsu, D. Le, A. Sagar, A. Elkahky, J. Copet, W.-N. Hsu, Y. Adi 외, &quot;중단: 구어체 작업 지향 의미 구문 분석을 위한 데이터 세트&quot;, Proc. SLT, 2023, pp. 991998. DP Kingma 및 J. Ba, &quot;Adam: 확률적 최적화를 위한 방법,&quot; Proc. ICLR, Y. Bengio 및 Y. LeCun, 편집, 2015. [15] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer 및 V. Stoyanov, Ro{bert}a: 견고하게 최적화된 {bert} 사전 학습 접근 방식, 2020. [16] [17] [18] S. Kim, A. Shrivastava, D. Le, J. Lin, O. Kalinli 및 ML Seltzer, &quot;견고한 엔드투엔드 구어 이해를 위한 모달리티 신뢰도 인식 학습,&quot; Interspeech, 2023. A. Graves, &quot;순환 신경망을 사용한 시퀀스 변환 네트워크,&quot; arXiv 사전 인쇄본 arXiv:1211.3711, 2012. S. Kim, Y. Shangguan, J. Mahadeokar, A. Bruguier, C. Fuegen, ML Seltzer, D. Le, &quot;스트리밍 순환 신경망 변환기를 위한 개선된 신경 언어 모델 융합&quot;, Proc. ICASSP, 2021, pp. 7333-7337.
