--- ABSTRACT ---
참조 소스 BLIP-Edit 사용자 정의 편집 텍스트-이미지 확산 모델은 사용자가 제공한 텍스트 프롬프트를 기반으로 다양하고 충실도가 높은 이미지를 생성할 수 있습니다. 최근 연구에서는 이러한 모델을 확장하여 텍스트 가이드 이미지 편집을 지원했습니다. 텍스트 가이드는 사용자에게 직관적인 편집 인터페이스이지만 종종 사용자가 전달한 정확한 개념을 보장하지 못합니다. 이 문제를 해결하기 위해 사용자 정의 편집을 제안합니다. 여기서는 (i) 몇 개의 참조 이미지로 확산 모델을 사용자 정의한 다음 (ii) 텍스트 가이드 편집을 수행합니다. 우리의 주요 발견은 증강된 프롬프트로 언어 관련 매개변수만 사용자 정의하면 소스 유사성을 유지하면서 참조 유사성이 크게 향상된다는 것입니다. 또한 각 사용자 정의 및 편집 프로세스에 대한 레시피를 제공합니다. 인기 있는 사용자 정의 방법을 비교하고 다양한 데이터 세트를 사용하여 두 가지 편집 방법에 대한 결과를 검증합니다. 1.
--- METHOD ---
s 및 다양한 데이터 세트를 사용하여 두 가지 편집 방법에 대한 연구 결과를 검증합니다.1. 서론 심층 생성 모델에 대한 최근 연구로 인해 이미지 편집이 빠르게 발전했습니다.대규모 데이터베이스[23]에서 학습한 텍스트-이미지 모델[19, 22]을 사용하면 다양한 도메인의 이미지를 직관적으로 편집[7, 15]할 수 있습니다.그렇다면 이러한 모델이 정확한 편집 지침을 얼마나 지원할 수 있을까요?특히 대규모 학습 중에 접하지 못한 고유한 사용자 개념을 편집에 활용할 수 있을까요?성능이 좋은 캡션 모델[13]에서 얻은 프롬프트로 편집하면 그림 1에서 볼 수 있듯이 참조의 모양을 포착하지 못합니다.우리는 (i) 몇 개의 참조 이미지를 사용하여 모델을 사용자 정의[6, 12, 21]한 다음 (ii) 효과적인 텍스트 안내 편집 방법[7, 15, 16]을 활용하여 이미지를 편집하는 2단계 접근 방식인 Custom-Edit을 제안합니다. 이전의 커스터마이징 연구[6, 12, 21]가 이미지의 무작위 생성(노이즈→이미지)을 다루는 반면, 저희의 연구는 이미지 편집(이미지→이미지)에 초점을 맞춥니다.그림 1에서 볼 수 있듯이, 커스터마이징은 레퍼런스의 모양에 대한 충실도를 큰 폭으로 향상시킵니다.이 논문에서는 커스터마이징이 * 책임 저자 V* 고양이 인형 검은 고양이... 다채로운 도자기 고양이 AV* 고양이 인형... 인형... V* 무늬 찻주전자 딸기 컵... 빨간색과 금색 찻주전자... V* 무늬 찻주전자... 그림 1. 저희의 Custom-Edit은 몇 가지 레퍼런스가 주어졌을 때 고충실도 텍스트 가이드 편집을 허용합니다.BLIP2[13] 캡션이 있는 편집된 이미지는 레퍼런스의 세밀한 모양을 포착하는 데 있어 텍스트 가이드의 한계를 보여줍니다.증강된 프롬프트가 있는 언어 관련 매개변수만이 편집된 이미지의 품질을 크게 향상시킵니다.또한, 저희는 각 커스터마이징 및 편집 프로세스에 대한 디자인 선택을 제시하고 Custom-Edit에서 소스-레퍼런스 트레이드오프에 대해 논의합니다. 2. 확산 모델 논문 전체에서 오픈 소스 텍스트-이미지 모델인 Stable Diffusion[19]을 사용합니다.확산 모델[5, 8, 24, 26]은 계산 효율성을 위해 이미지를 다운샘플링하는 VAE[11]의 잠재 공간에서 학습됩니다.모델은 텍스트 조건 c가 주어진 경우 CLIP 텍스트 인코더[18]에 내장된 섭동 표현 xt에서 깨끗한 잠재 표현 xo를 재구성하도록 학습됩니다.확산 모델은 다음과 같은 목적으로 학습됩니다.T Σ Exo, e [|| € – €0 (xt, t, c)||²], t=(1) 여기서 는 추가된 노이즈, t는 섭동 노이즈 레벨을 나타내는 시간 단계, 는 어텐션 블록[27]이 있는 U-Net[20] 아키텍처를 갖춘 확산 모델입니다. 영어: 훈련하는 동안 텍스트 임베딩은 키에 투사되고 t ...V* 패턴화된 티포트 ...tt V* 패턴화된 티포트... *훈련 가능 ☐ 고정 t-참조 사전 전환 주의 전환 주의 KV KV 확산 U-Net 확산 U-Net 주의 07KV 전환 주의.. 패턴화된 티포트 ... - Q 이 (a) 사용자 지정 프로세스 전환 주의 KV 전환 주의 확산 U-Net 참조 출력 주입 주입(P2P) (P2P) 사전 소스 전환 주의 KV 확산 U-Net... strawberry cup... (b) 편집 프로세스 전환 주의 Q 출력 소스 0* 그림 2. 사용자 지정 편집은 사용자 지정 프로세스와 편집 프로세스의 두 가지 프로세스로 구성됩니다. (a) 사용자 지정. 주어진 참조 이미지 집합에서 언어 관련 매개변수(즉, 사용자 지정 임베딩 V* 및 주의 가중치)만 최적화하여 확산 모델을 사용자 지정합니다. 또한 언어 드리프트를 완화하기 위해 사전 보존 손실을 적용합니다.(b) 편집. 그런 다음 사용자 지정 단어를 사용하여 소스 이미지를 출력으로 변환합니다. 이 프로세스에 P2P 및 Null-text 반전 방법[7, 16]을 활용합니다. 교차 주의 계층의 값을 변경하고 텍스트 인코더는 언어 이해 기능을 보존하기 위해 동결 상태로 유지합니다.Imagen[22] 및 eDiffi[1]는 대규모 언어 모델의 풍부한 언어 이해를 동결하여 활용하는 것이 성능을 높이는 데 중요함을 보여주었습니다.3. 사용자 지정 편집 우리의 목표는 참조 이미지로 제공된 복잡한 시각적 지침이 있는 이미지를 편집하는 것입니다(그림 1). 따라서 (i) 주어진 참조에 대한 모델을 사용자 지정(3.1절)하고 (ii) 텍스트 프롬프트가 있는 이미지를 편집(3.2절)하는 2단계 접근 방식을 제안합니다. 우리의 방법은 그림 2에 나와 있습니다.3.1. 사용자 지정 학습 가능 매개변수. 우리는 Custom-Diffusion [12]에 따라 교차 주의와 &#39;[희귀 토큰]&#39;의 키와 값만 최적화합니다. 4절에서 논의하듯이, 우리의 결과는 이러한 언어 관련 매개변수를 훈련하는 것이 참조 개념을 소스 이미지로 성공적으로 전송하는 데 중요하다는 것을 나타냅니다. 더욱이, 이러한 매개변수만 훈련하는 데 필요한 저장 공간은 Dreambooth [21]보다 적습니다. 증강 프롬프트. 우리는 Eq. (1)을 최소화하여 위에서 언급한 매개변수를 미세 조정합니다. 우리는 텍스트 입력을 &#39;[희귀 토큰] [수정자] [클래스 명사]&#39;(예: &#39;V* 패턴 찻주전자&#39;)로 증강하여 편집을 위해 CustomDiffusion을 개선합니다. 우리는 &#39;[수정자]&#39;가 모델이 참조의 모양을 학습하는 데 집중하도록 장려한다는 것을 발견했습니다. 데이터 세트. 참조를 미세 조정하는 동안 언어 이해를 유지하기 위해 참조와 같은 클래스에 속하는 다양한 이미지에 대한 사전 보존 손실[21]을 최소화합니다. 따라서 우리는 텍스트 쿼리 &#39;photo of a [modifier] [class noun]&#39;를 사용하여 LAION 데이터 세트[23]에서 200개의 이미지와 캡션을 검색하기 위해 CLIP 검색[3]을 사용합니다. 3.2. 프롬프트 간 텍스트 가이드 이미지 편집. 우리는 소스 프롬프트만 수정하여 이미지를 편집하는 최근에 도입된 편집 프레임워크인 프롬프트 간[7](P2P)을 사용합니다. P2P는 소스 이미지의 구조를 보존하기 위해 어텐션 주입을 제안합니다. 각 노이즈 제거 단계 t에 대해 소스 및 편집된 이미지의 어텐션 맵을 각각 M₁ 및 M+*로 표시하겠습니다. 그런 다음 P2P는 새로운 어텐션 맵 Edit(Mt, Mt*, t)를 모델 ee에 주입합니다. Edit은 프롬프트 정제 및 단어 교환을 포함하는 어텐션 맵 편집 작업입니다. 또한 P2P는 자동으로 계산된 마스크로 로컬 편집을 가능하게 합니다. P2P는 단어 w와 관련된 교차 어텐션 Mt,w 및 M의 평균을 계산하고 임계값을 설정하여 이진 마스크 B(Mt) UB(M*)을 생성합니다. P2P로 편집하기 전에 Null-Text Inversion[16]을 사용하여 소스 보존을 향상시킵니다. 자세한 설명은 Sec. C를 참조하십시오. 작업 선택. 참조 이미지의 수가 제한되어 있기 때문에 사용자 지정 단어는 제한된 종류의 구조만 선호합니다. 이는 다음과 같은 레시피를 제안하게 된 영감입니다. 첫째, 편집 기능에 대한 신속한 정제를 사용합니다. 사용자 지정 단어가 교환된 어텐션 맵을 선호하지 않으면 단어 교환이 실패합니다. 둘째, 사용자 지정 단어가 잘못된 마스크를 생성할 가능성이 높으므로 B(M) UB(M*) 대신 마스크 B(Mt)를 사용합니다. t, w 소스-참조 트레이드오프. 이미지 편집의 핵심 과제는 편집된 이미지의 소스와 참조 유사성을 균형 있게 조정하는 것입니다. T/T를 강도라고 하며, P2P는 t = T에서 7까지 자기 주의를 주입합니다. P2P에서 우리는 상충 관계를 제어하는 데 중요한 요소가 주입임을 관찰했습니다.참조 출처 편집됨 출처 편집됨 V* 나무 냄비 테이블 위에 와인 한 병과 유리잔 AV* 나무 냄비에 와인... V* 거북이 봉제 인형 물 표면 아래에서 수영하는 바다 거북이 사막에서 선글라스와 모자를 쓴 선인장 AV* 나무 냄비에... AV* 거북이 봉제 인형 수영... 왕관을 쓴 너구리 그림 ... 왕관을 쓴 V* 거북이 봉제 인형... V* 도자기 새 나뭇가지에 앉은 두 마리의 작은 새 두 마리 V* 도자기 새 앉아... 마카롱이 가득한 바구니 위에 앉은 파랑까치 AV* 도자기 새가 앉아... V* 연필 그림 파란색 양동이에서 물을 마시는 기린 사진 V* 기린의 연필 그림... 카우보이 모자를 쓴 노인이 시가를 피우는 사진 V* 노인의 연필 그림... V* 고양이 두 마리의 고양이 욕실 앞 거울에 앉아 있다 두 마리의 V* 고양이가 앉아 있다... 사과가 가득 찬 바구니가 V* 고양이가 가득 찬 나무 의자에 앉아 있다... 그림 3. 사용자 정의 편집 결과. 이 방법은 참조의 모양을 전례 없는 충실도로 소스 이미지로 전송합니다. 소스의 구조는 잘 보존됩니다. BLIP2[13]를 사용하여 소스 프롬프트를 얻습니다. 연필 그림 예제를 제외하고 교차 주의가 아닌 자기 주의의 자동 생성 마스크를 사용하여 P2P의 로컬 편집을 사용합니다. 강도가 높을수록 참조 유사성이 희생되어 소스 유사성이 높아집니다. 4절에서는 이미지를 t = 0에서 t = T로 확산시키고 다시 노이즈를 제거하는 SDEdit[15]을 사용한 결과도 보여줍니다. P2P와 달리 SDEdit의 강도가 높을수록 참조 유사성이 높아집니다. 4.
