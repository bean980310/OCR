--- ABSTRACT ---
이 논문은 효율적인 파노라마 분할을 위한 마스크 변환기의 학습을 용이하게 하는 새로운 메커니즘을 제시하고, 배포를 민주화합니다. 우리는 높은 복잡성으로 인해 파노라마 분할의 학습 목표가 필연적으로 훨씬 더 높은 거짓 양성 페널티로 이어질 것이라고 관찰합니다. 이러한 불균형 손실은 엔드투엔드 마스크 변환기 기반 아키텍처의 학습 프로세스를 어렵게 만듭니다. 특히 효율적인 모델의 경우 더욱 그렇습니다. 이 논문에서는 파노라마 분할을 위한 학습 중에 마스크 예측과 클래스 예측에 완화를 추가하는 ReMax를 제시합니다. 우리는 학습 중에 이러한 간단한 완화 기술을 통해 추론에 대한 추가 계산 비용 없이도 모델을 명확한 마진으로 지속적으로 개선할 수 있음을 보여줍니다. MobileNetV3-Small과 같은 효율적인 백본과 방법을 결합함으로써, 이 방법은 COCO, ADE20K 및 Cityscapes에서 효율적인 파노라마 분할을 위한 새로운 최첨단 결과를 달성합니다. 코드와 사전 학습된 체크포인트는 https://github.com/google-research/deeplab2에서 제공됩니다. 1
--- INTRODUCTION ---
파노라마 분할[35]은 인스턴스 분할[20]과 의미 분할[23]을 통합하여 전체적인 장면 이해[61]를 제공하는 것을 목표로 합니다. 장면에 대한 포괄적인 이해는 각 픽셀에 레이블을 지정하고 의미 클래스와 인스턴스 ID를 모두 인코딩하여 얻습니다. 이전 작업에서는 인스턴스 및 의미 분할에 특화된 별도의 분할 모듈을 채택한 다음 불일치를 해결하기 위해 또 다른 융합 모듈을 채택했습니다[69, 10, 34, 68, 52, 41]. 최근에는 변환기 아키텍처[62, 4] 덕분에 클래스 레이블이 지정된 마스크를 직접 예측하여 엔드투엔드 파노라마 분할을 위한 마스크 변환기[64, 11, 73, 42, 70, 13, 71]가 제안되었습니다. Panoptic 분할의 정의는 각 픽셀을 단 하나의 마스크 엔터티와만 연관시킬 수 있지만, 최근의 일부 마스크 변환기 기반 작업[11, 73, 12, 39]은 마스크 감독을 위해 시그모이드 교차 엔트로피 손실(즉, 소프트맥스 교차 엔트로피 손실을 통해 단일 예측을 적용하지 않음)을 적용합니다. 이를 통해 각 픽셀을 여러 마스크 예측과 연관시킬 수 있어 학습 중에 손실이 매우 불균형하게 발생합니다. 그림 1에서 볼 수 있듯이 시그모이드 교차 엔트로피 손실을 사용하여 마스크 분기를 감독할 때 거짓 양성(FP) 손실은 거짓 음성(FN) 손실보다 10³배 더 클 수 있습니다. 놀랍게도 이러한 불균형 손실은 소프트맥스 교차 엔트로피를 사용하는 것보다 더 나은 결과를 가져오는데, 이는 FP 손실로 생성된 그래디언트가 더 나은 성능에 여전히 도움이 됨을 나타냅니다. 그러나 손실의 급격한 불균형으로 인해 네트워크가 확신 있는 예측을 생성하는 것이 어려워지며, 특히 효율적인 백본의 경우 [27, 56, 26] 더 작은 모델 크기에서 더 많은 실수를 하는 경향이 있습니다. 한편, 대규모 손실 변동으로 인해 학습 프로세스도 불안정해집니다. 이 문제를 해결하기 위해 최근 접근 방식[4, 11, 12, 39]은 * Google Research에서 인턴십 중에 수행한 작업. 문의처: kevinsun@robots.ox.ac.uk * Google에서 근무하는 동안 수행한 작업. 사전 인쇄본. 검토 중. CountSigmoid CE × sem ✗pan Softmax CE 175-100-Semantic head Panoptic head mpan Lsem ms sem stop gradFP/FN loss, log scale 그림 1: 히스토그램은 로그 스케일에서 교차 엔트로피 손실에 대한 거짓 양성과 거짓 음성의 비율을 보여줍니다. 활성화 함수로 시그모이드를 사용하는 경우 거짓 양성 손실은 항상 거짓 음성보다 100배 이상 크기 때문에 총 손실이 극도로 불균형해집니다. р Lpan mpan 그림 2: ReMask 연산. 회색으로 표시된 모듈, 표현 및 연산은 테스트에 사용되지 않습니다. &gt; 및 는 행렬 곱셈과 아다마르 곱셈을 나타내고 +는 요소별 합을 의미합니다. x 기호와 &quot;stop grad&quot;는 학습 중에 pan에서 msem으로 기울기가 전달되지 않음을 의미합니다. 학습 기울기를 0.01과 같이 매우 작은 값으로 낮추지 않으면 손실이 폭발하고 학습이 붕괴됩니다. 이런 식으로 네트워크의 수렴도 느려집니다. 따라서 자연스럽게 다음과 같은 의문이 생깁니다. 네트워크 학습을 더 잘 안정화하는 동시에 이러한 양의 기울기를 유지할 방법이 있을까요? 학습 목표에서 앞서 언급한 충돌을 해결하기 위해 한 가지 순진한 해결책은 학습 중에 가중 시그모이드 교차 엔트로피 손실을 적용하는 것입니다. 그러나 수작업으로 만든 가중치를 적용하면 모든 데이터 포인트에 대한 손실이 동등하게 확장되므로 이러한 긍정적이고 유용한 그래디언트도 축소됩니다.따라서 이 논문에서는 마스크 변환기에 훈련 시간 완화만 추가하여 손실 가중치를 적응적으로 조정할 수 있는 방법을 제시합니다[71, 64, 11, 13, 42, 73].특히 마스크 완화(ReMask)와 클래스 완화(ReClass)의 두 가지 유형의 완화를 제안합니다.제안된 ReMask는 의미적 분할이 동일한 클래스의 여러 인스턴스를 구별하지 않고 각 픽셀에 대해 예측된 의미적 클래스만 필요한 파노라마 분할보다 비교적 쉬운 작업이라는 관찰에서 동기를 얻었습니다.결과적으로 의미적 분할 예측은 거친 작업으로 사용되어 파노라마 분할의 의미적 학습을 안내할 수 있습니다.특히 파노라마 마스크를 예측하는 방법을 직접 학습하는 대신 훈련 중에 다른 보조 분기를 추가하여 해당 이미지에 대한 의미적 분할 출력을 예측합니다. 그런 다음, 팬옵틱 예측은 의미론적 분할 출력에 의해 교정되어 너무 많은 거짓 양성 예측이 생성되지 않도록 합니다. 이런 식으로 네트워크는 거짓 양성 손실로 인해 덜 처벌받을 수 있습니다. 제안된 ReClass는 각 예측 마스크가 특히 초기 학습 단계에서 여러 클래스를 포함하는 영역을 잠재적으로 포함할 수 있다는 관찰에서 동기를 얻었지만, 각 기준 진실 마스크와 최종 예측 마스크는 마스크 변환기 프레임워크에서 하나의 대상만 포함해야 합니다[64]. 이 불일치를 설명하기 위해 각 마스크의 원래 원핫 클래스 레이블을 부드러운 레이블로 대체하여 기준 진실 레이블이 여러 클래스를 가질 수 있도록 합니다. 각 클래스의 가중치는 각 예측 마스크와 모든 기준 진실 마스크의 겹침에 따라 결정됩니다. 이러한 간단한 이완 기술을 최첨단 kMaX-DeepLab[71]에 적용함으로써 ReMax라고 하는 우리 방법은 기준선보다 10배 이상 높은 학습률로 그래디언트 클리핑 작업 없이도 네트워크를 안정적으로 학습할 수 있습니다. 실험 결과에 따르면, 저희 방법은 학습 속도를 3배 높일 뿐만 아니라, 파노라마 분할에 대해 훨씬 더 나은 결과를 도출합니다.전반적으로 ReMax는 효율적인 파노라마 분할에 대한 최첨단 기록을 세웠습니다.특히, MobileNetV3-Small 및 MobileNetV3-Large[26]와 같은 효율적인 백본의 경우, 저희 방법은 짧은 일정 학습의 경우 COCO 파노라마에서 PQ에서 강력한 기준선보다 각각 4.9 및 5.2만큼 우수한 성능을 발휘할 수 있습니다.최종 결과(즉, 긴 일정)의 경우 PQ가 각각 2.9 및 2.1만큼 향상됩니다.한편, Axial-ResNet50(MaX-S)[63] 백본을 사용한 저희 모델은 Cityscapes[16]에서 ConvNeXt-L[46]과 같이 3배 더 큰 백본을 사용한 모든 최첨단 방법보다 우수한 성능을 발휘합니다. 우리 모델은 효율적인 파노라마 분할을 위해 COCO [43], ADE20K [74] 및 Cityscapes [16]에서 YOSO [28] 및 MaskConver [28]와 같은 다른 최첨단 효율적인 파노라마 분할 아키텍처와 비교했을 때 최첨단 성능을 달성할 수도 있습니다. 2
--- RELATED WORK ---
이미지 분할을 위한 마스크 변환기. 이미지 분할의 최근 발전은 작업 디코더로 변환기를 사용하여 예측 마스크와 기준 진실 마스크의 헝가리안 매칭을 통해 클래스 레이블이 지정된 개체 마스크를 예측하는 마스크 변환기[64]가 상자 기반 변환기보다 성능이 우수하다는 것을 증명했습니다[62, 4].
--- METHOD ---
MobileNetV3-Small과 같은 효율적인 백본을 사용하여, 우리의 방법은 COCO, ADE20K 및 Cityscapes에서 효율적인 파노라마 분할을 위한 최신 결과를 달성합니다. 코드와 사전 훈련된 체크포인트는 https://github.com/google-research/deeplab2에서 사용할 수 있습니다. 1. 서론 파노라마 분할[35]은 인스턴스 분할[20]과 의미 분할[23]을 통합하여 전체적인 장면 이해[61]를 제공하는 것을 목표로 합니다. 장면에 대한 포괄적인 이해는 각 픽셀에 레이블을 지정하고 의미 클래스와 인스턴스 ID를 모두 인코딩하여 얻습니다. 이전 작업에서는 인스턴스 및 의미 분할에 특화된 별도의 분할 모듈을 채택한 다음 불일치를 해결하기 위해 또 다른 융합 모듈을 채택했습니다[69, 10, 34, 68, 52, 41]. 최근에는 변압기 아키텍처[62, 4] 덕분에 마스크 변압기[64, 11, 73, 42, 70, 13, 71]가 클래스 레이블이 지정된 마스크를 직접 예측하여 엔드투엔드 팬옵틱 분할을 위해 제안되었습니다. 팬옵틱 분할의 정의는 각 픽셀을 단 하나의 마스크 엔터티와만 연관시킬 수 있지만, 일부 최근 마스크 변압기 기반 작업[11, 73, 12, 39]은 마스크 감독을 위해 시그모이드 교차 엔트로피 손실(즉, 소프트맥스 교차 엔트로피 손실을 통해 단일 예측을 적용하지 않음)을 적용합니다. 이를 통해 각 픽셀을 여러 마스크 예측과 연관시킬 수 있어 학습 중에 손실이 매우 불균형해집니다. 그림 1에서 볼 수 있듯이 시그모이드 교차 엔트로피 손실을 사용하여 마스크 분기를 감독할 때 거짓 양성(FP) 손실이 거짓 음성(FN) 손실보다 10³배 더 클 수 있습니다. 놀랍게도 이러한 불균형 손실은 소프트맥스 교차 엔트로피를 사용하는 것보다 더 나은 결과로 이어지며, 이는 FP 손실에 의해 생성된 그래디언트가 더 나은 성능에 여전히 도움이 됨을 나타냅니다. 그러나 손실의 급격한 불균형으로 인해 네트워크가 확신 있는 예측을 생성하는 것이 어렵습니다. 특히 효율적인 백본의 경우 [27, 56, 26] 더 작은 모델 크기를 고려할 때 더 많은 실수를 하는 경향이 있기 때문입니다. 한편, 대규모 손실 변동으로 인해 학습 프로세스도 불안정해집니다. 이 문제를 해결하기 위해 최근의 접근 방식[4, 11, 12, 39]은 다음을 신중하게 클리핑해야 합니다. * Google Research에서 인턴십 중에 수행한 작업. 문의처: kevinsun@robots.ox.ac.uk * Google에서 근무하는 동안 수행한 작업. 사전 인쇄본. 검토 중. CountSigmoid CE × sem ✗pan Softmax CE 175-100-Semantic head Panoptic head mpan Lsem ms sem stop gradFP / FN loss, log scale 그림 1: 히스토그램은 로그 스케일에서 교차 엔트로피 손실에 대한 거짓 양성과 거짓 음성의 비율을 보여줍니다. 활성화 함수로 시그모이드를 사용하는 경우 거짓 양성 손실은 항상 거짓 음성보다 100배 이상 크기 때문에 총 손실이 극도로 불균형해집니다. р Lpan mpan 그림 2: ReMask 연산. 회색으로 표시된 모듈, 표현 및 연산은 테스트에 사용되지 않습니다. &gt; 및 는 행렬 곱셈과 아다마르 곱셈을 나타내고 +는 요소별 합을 의미합니다. x 기호와 &quot;stop grad&quot;는 학습 중에 pan에서 msem으로 기울기가 전달되지 않음을 의미합니다. 학습 기울기를 0.01과 같은 매우 작은 값으로 낮추십시오. 그렇지 않으면 손실이 폭발하고 학습이 붕괴됩니다. 이런 식으로 네트워크의 수렴도 더 느려질 것입니다. 따라서 자연스럽게 다음과 같은 의문이 생깁니다. 네트워크의 학습을 더 잘 안정화하는 동시에 이러한 양의 기울기를 유지할 방법이 있을까요? 학습 목표에서 앞서 언급한 갈등을 해결하기 위해 한 가지 순진한 해결책은 학습 중에 가중 시그모이드 교차 엔트로피 손실을 적용하는 것입니다. 그러나 수작업으로 만든 가중치를 적용하면 모든 데이터 포인트에 대한 손실도 동등하게 조정되므로 이러한 양의 유용한 기울기도 축소됩니다. 따라서 이 논문에서는 마스크 변환기에 학습 시간 완화만 추가하여 손실 가중치를 적응적으로 조정할 수 있는 방법을 제시합니다[71, 64, 11, 13, 42, 73]. 특히 마스크 완화(ReMask)와 클래스 완화(ReClass)의 두 가지 유형의 완화를 제안합니다. 제안된 ReMask는 의미적 분할이 동일한 클래스의 여러 인스턴스를 구별하지 않고 각 픽셀에 대해 예측된 의미적 클래스만 필요한 파노라마 분할보다 비교적 쉬운 작업이라는 관찰에 의해 동기를 부여받았습니다. 결과적으로 의미적 분할 예측은 거친 작업으로 사용되어 파노라마 분할의 의미적 학습을 안내할 수 있습니다. 구체적으로, 파노라마 마스크를 예측하는 방법을 직접 학습하는 대신, 학습 중에 다른 보조 분기를 추가하여 해당 이미지에 대한 의미적 분할 출력을 예측합니다. 파노라마 예측은 의미적 분할 출력에 의해 교정되어 너무 많은 거짓 양성 예측이 생성되지 않도록 합니다. 이런 식으로 네트워크는 거짓 양성 손실로 인해 덜 처벌받을 수 있습니다. 제안된 ReClass는 각 예측 마스크에 여러 클래스가 포함된 영역이 포함될 가능성이 있다는 관찰에 의해 동기를 부여받았지만, 특히 초기 학습 단계에서는 각 기준 진실 마스크와 최종 예측 마스크가 마스크 변환기 프레임워크에서 하나의 대상만 포함해야 합니다[64]. 이러한 불일치를 설명하기 위해 각 마스크의 원래 원핫 클래스 레이블을 부드러운 레이블로 대체하여 기준 진실 레이블이 여러 클래스를 가질 수 있도록 합니다. 각 클래스의 가중치는 각 예측 마스크와 모든 기준 진실 마스크의 겹침으로 결정됩니다. 이러한 간단한 이완 기술을 최첨단 kMaX-DeepLab[71]에 적용하여 ReMax라고 하는 우리 방법은 기준선보다 10배 이상 높은 학습 속도로 그래디언트 클리핑 작업 없이도 네트워크를 안정적으로 학습할 수 있습니다.
--- EXPERIMENT ---
모든 결과에 따르면, 저희 방법은 학습 속도를 3배 높일 뿐만 아니라, 파노라마 분할에 대해 훨씬 더 나은 결과를 도출합니다.전반적으로, ReMax는 효율적인 파노라마 분할에 대한 최첨단 기록을 세웠습니다.특히, MobileNetV3-Small 및 MobileNetV3-Large[26]와 같은 효율적인 백본의 경우, 저희 방법은 짧은 일정 학습의 경우 COCO 파노라마에서 PQ에서 강력한 기준선보다 각각 4.9 및 5.2만큼 우수한 성능을 발휘할 수 있습니다.최종 결과(즉, 긴 일정)의 경우 PQ가 각각 2.9 및 2.1만큼 향상됩니다.한편, Axial-ResNet50(MaX-S)[63] 백본을 사용한 저희 모델은 Cityscapes[16]에서 ConvNeXt-L[46]과 같이 3배 더 큰 백본을 사용한 모든 최첨단 방법보다 우수한 성능을 발휘합니다. 영어: 저희 모델은 효율적인 팬옵틱 분할을 위해 COCO [43], ADE20K [74] 및 Cityscapes [16]에서 YOSO [28] 및 MaskConver [28]와 같은 다른 최첨단 효율적 팬옵틱 분할 아키텍처와 비교했을 때 최첨단 성능을 달성할 수도 있습니다.2 관련 작업 이미지 분할을 위한 마스크 변환기.이미지 분할의 최근 발전은 예측 마스크와 기준 진실 마스크의 헝가리안 매칭을 통해 클래스 레이블이 지정된 개체 마스크를 예측하는 마스크 변환기 [64]가 감지된 개체 경계 상자에 대한 마스크를 예측하는 것 [22] 및 병합 모듈 [41, 52, 44, 69, 10, 40]과 같은 여러 대리 작업으로 팬옵틱 분할을 분해하는 상자 기반 방법 [34, 68, 53]보다 성능이 우수하다는 것을 증명했습니다. Mask Transformer 기반 방법은 객체 쿼리를 마스크 임베딩 벡터[31, 60, 65]로 변환한 다음 픽셀 피처와 곱하여 예측 마스크를 생성하는 데 의존합니다.Segmenter[58] 및 MaskFormer[13]와 같은 다른 접근 방식도 의미 분할을 위해 마스크 변환기를 사용했습니다.K-Net[73]은 마스크 생성을 위한 동적 커널을 제안합니다.CMT-DeepLab[70]은 변환기의 교차 주의를 개선하기 위해 추가 클러스터링 업데이트 항목을 제안합니다.Panoptic Segformer[42]는 변형 가능한 주의를 통해 마스크 변환기를 향상시킵니다[75].Mask2Former[13]는 계단식 변환기 디코더[4], 변형 가능한 주의[75] 및 불확실성 기반 포인트 감독[36]과 같은 기타 기술적 개선 사항과 함께 마스크 주의를 채택하는 반면 kMaX-DeepLab[71]은 k-평균 교차 주의를 사용합니다. OneFormer[30]는 멀티태스크 트레인 원스(train-once) 설계로 Mask2Former를 확장합니다.저희 작업은 최신 마스크 변환기인 kMaX-DeepLab[71]을 기반으로 하며, 모델 용량을 개선하기 위해 새로운 완화 방법을 채택합니다.제안된 마스크 완화(ReMask)는 예측된 마스크에 픽셀 필터링 연산도 적용한다는 점에서 Mask2Former[13]의 마스크 어텐션과 kMaX-DeepLab[71]의 k-평균 어텐션과 유사합니다.그러나 저희의 ReMask 연산은 여러 면에서 근본적으로 다릅니다.(1) 저희는 훈련 중에 의미 헤드를 통해 파노라마 마스크 예측에서 픽셀을 필터링하는 데 사용되는 임계값을 학습하는 반면, 마스크 어텐션[13]과 k-평균 어텐션[71]은 모두 필터링을 위해 픽셀별 신뢰도에 하드 임계값 설정 또는 argmax 연산을 사용합니다. (2) 우리의 접근 방식은 ReMask에 대한 의미 마스크에 픽셀 단위 의미 손실을 적용하여 학습 목표를 완화하지만, 그 목적에 대한 명시적 감독은 없습니다.그리고 (3) 우리는 ReMask가 섹션 4에서 k-평균 주의를 보완할 수 있음을 보여줍니다.효율적인 파노라마 분할을 위한 마스크 변환기의 가속화.DETR[4]은 변환기 기반 접근 방식이 파노라마 분할을 위한 디코더로 사용될 수 있음을 성공적으로 증명했지만, 한 번에 300개 이상의 에포크가 필요한 느린 학습 문제로 여전히 어려움을 겪습니다.최근 연구[13, 71, 75, 49]에 따르면 지역성 향상 주의 메커니즘을 적용하면 인스턴스 및 파노라마 분할의 학습 속도를 높이는 데 도움이 될 수 있습니다.한편, 다른 연구[73, 42, 32]에 따르면 스터프 클래스에 대한 이분 매칭을 제거하고 스터프 클래스에 대한 별도의 마스크 쿼리 그룹을 적용하면 수렴 속도를 높이는 데 도움이 될 수도 있습니다. 네트워크에 아키텍처 수준의 변경 사항을 적용하는 것과 달리, 우리의 방법은 프레임워크에 훈련 시간 완화만 적용하며, 이는 테스트 중에 추가 비용을 발생시키지 않습니다.훈련 가속 외에도, 최근 연구[25, 28, 10, 54, 50]는 파노라마 분할을 위한 시스템을 보다 효율적으로 만드는 방법에 초점을 맞춥니다.그러나 이러한 모든 연구는 변조된 아키텍처 설계에 초점을 맞추는 반면, 우리의 접근 방식은 두 개의 직교 방향이어야 하는 훈련 파이프라인에 초점을 맞춥니다.이미지 분할을 위한 대략적-미세 조정.컴퓨터 비전 분야에서는, 특히 이미지 분할에서 대략적에서 미세한 표현으로 학습하는 것이 일반적인 관행입니다.예를 들어, DeepLab[6, 8]은 분할 결과를 점진적으로 조정하는 그래프 기반 접근 방식[37, 7]을 제안합니다. 최근, [64, 13, 73, 67, 42, 19]와 같은 이미지 분할을 위한 변압기 기반 방법도 변압기 디코더에서 예측된 분할 결과를 반복적으로 개선하기 위해 다단계 전략을 채택했습니다. [9, 2, 3]을 포함하여 세분화된 예측(예: 인스턴스 분할)을 조정하기 위해 거친 입자 기능(예: 의미 분할)을 사용하는 개념이 특정 기존 작업에 존재합니다. 그러나 이러한 접근 방식은 학습과 추론 중에 모델 크기와 매개변수 수를 상당히 증가시킬 수 있습니다. 이와 대조적으로, 우리의 ReMax는 추론 중에 추가 매개변수나 계산 비용을 도입하지 않고 완화를 위해 거친 입자 계층 구조만 활용하는 데 중점을 둡니다. 정규화 및 완화 기술. 제안된 클래스에 대한 완화(ReClass)는 마스크 오버랩에 대한 사전 지식을 기반으로 레이블 가중치를 조정하는 것을 포함하며, 이는 [72, 5]와 같은 CutMix 기반 방법에서 사용되는 재레이블링 전략과 이미지 분류에 사용되는 레이블 부드럽게 하기[59]와 유사합니다. 그러나 우리가 다루고 있는 문제는 이미지 분류에서 위의 레이블 부드럽게 하기 관련 방법과 실질적으로 다릅니다. 이미지 분류에서, 특히 ImageNet[55]과 같은 대규모 단일 클래스 이미지 인식 벤치마크의 경우 이미지가 다른 유사한 클래스의 일부 콘텐츠를 포함하는 것은 불가피하며, 레이블 부드럽게 하기가 이러한 레이블 노이즈를 학습 프로세스로 완화하기 위해 제안됩니다. 그러나 우리의 접근 방식은 파노라마 분할을 위한 마스크 변환기[64, 11, 13, 71, 70]를 위해 설계되었기 때문에 각 이미지는 픽셀 수준까지 정확하게 레이블이 지정되므로 데이터 세트에는 이러한 레이블 노이즈가 없습니다. 우리는 클래스 예측 외에도 마스크 변환기 접근 방식이 클래스 헤드에 대한 기본 클래스 식별 작업을 도입한다는 것을 관찰합니다. ReClass 연산의 제안은 Mask Transformers에서 분류 작업의 복잡성을 줄입니다. Mask Transformers가 등장하기 전에는 이전 접근 방식에서는 마스크가 아닌 픽셀에서 직접 클래스 레이블을 예측했기 때문에 이 문제가 발생하지 않았습니다.3 방법 방법의 세부 사항을 살펴보기 전에 종단 간 파노라마 분할을 위한 마스크 변환기[64]의 프레임워크를 간략히 요약해 보겠습니다.[64, 13, 73, 67, 42]와 같은 마스크 변환기는 단일 Transformer 기반 모델을 사용하여 전체 이미지에서 의미적 분할과 인스턴스 분할을 모두 수행합니다.이러한 접근 방식은 기본적으로 전체 프레임워크를 3개 부분으로 나눕니다.특징 추출을 위한 백본, 백본에서 생성된 특징을 융합하는 특징 피라미드가 있는 픽셀 디코더, 픽셀 디코더의 특징을 파노라마 마스크와 해당 클래스 범주로 변환하는 변환기 마스크 디코더입니다.변압기 디코더에서 마스크 쿼리 집합은 마스크 헤드에 의해 이미지를 마스크 집합으로 분할하고 분류 헤드에 의해 해당 범주로 분할하도록 학습됩니다. 이러한 쿼리는 각 트랜스포머 디코더(일반적으로 최소 6개의 트랜스포머 디코더가 있음) 내에서 교차 어텐션 메커니즘[62]에 의해 업데이트되어 마스크 및 클래스 예측이 점진적으로 정제됩니다. 예측 세트는 학습 중에 이분 매칭을 통해 기준 진실과 매칭되고, 이러한 쿼리는 추론 중에 사후 처리로 다른 임계값으로 필터링됩니다. 3. 마스크에 대한 완화(ReMask) 제안된 마스크에 대한 완화(ReMask)는 파노라마 분할 모델의 학습을 용이하게 하는 것을 목표로 합니다. 파노라마 분할은 모델이 두 가지 유형의 분할(즉, 인스턴스 분할 및 의미 분할)을 수행해야 하기 때문에 일반적으로 의미 분할보다 더 복잡한 작업으로 간주됩니다. 의미 분할에서 이미지의 모든 픽셀은 동일한 클래스의 여러 인스턴스(사물)를 구별하지 않고 해당 클래스로 레이블이 지정됩니다. 결과적으로 의미 분할은 파노라마 분할에 비해 더 거친 작업으로 간주됩니다. 현재 팬옵틱 분할의 추세는 통합 프레임워크에서 사물과 물건을 모델링하고 사물에 대한 거친 세분화 작업과 사물에 대한 보다 세밀한 세분화 작업을 모두 사물에 대한 더 엄격한 복합 목표를 사용하여 함께 학습하는 것인데, 이는 모델 학습을 더 어렵게 만듭니다. 따라서 학습을 용이하게 하기 위해 보조 의미적 분할 분기를 활용하는 ReMask를 제안합니다. 정의. 그림 2에서 볼 수 있듯이 마스크 표현 Xpan Є R#W×Nɖ가 주어지면 팬옵틱 마스크 헤드를 적용하여 팬옵틱 마스크 로짓 man Є RHWXNQ를 생성합니다. 해당 분류 결과 p = R³×Nc를 생성하는 마스크 분류 헤드가 각 쿼리 표현 qЄRNQxda에 적용됩니다. 픽셀 디코더의 의미적 특징 X sem ERHW x sem 뒤에 의미적 헤드를 적용하여 각 픽셀에 클래스 레이블을 지정하는 픽셀별 의미적 분할 맵 msem Є RHWXNC를 생성합니다. 여기서 H, W는 피처의 높이와 너비를 나타내고, NQ는 마스크 쿼리 수, No는 대상 데이터 세트에 대한 의미 클래스 수, d₁는 쿼리 표현에 대한 채널 수, dsem은 의미 헤드 입력에 대한 채널 수를 나타냅니다. 의미 헤드의 구조에 관해서는 ASPP 모듈[8]과 1×Image Ground Truth ReClass 야구 글러브를 적용합니다: 1.야구 글러브: 0.사람: 0.그림 3: ReClass 작동 방식에 대한 데모. 파란색으로 렌더링된 마스크를 예로 사용합니다. ReClass 작업은 예측 마스크와 Ground Truth 마스크 사이의 겹침 정도를 고려하여 클래스별 Ground Truth를 부드럽게 하는 것을 목표로 합니다. 파란색 마스크는 &quot;야구 글러브&quot;와 &quot;사람&quot;의 두 마스크와 교차하므로 최종 클래스 가중치에는 둘 다 포함되고 예측에서 &quot;사람&quot;의 활성화는 더 이상 학습 중에 거짓 양성 사례로 간주되지 않습니다. 그 후에 합성곱 계층을 사용하여 dsem 채널을 의미 예측으로 No 채널로 변환합니다. 그림 2에서 보듯이 추론하는 동안 전체 보조 의미 분기가 건너뛰어집니다. msem과 mpan 사이의 채널 차원이 다르기 때문에 의미 마스크를 다음과 같이 팬옵틱 공간에 매핑합니다. msem = σ(mem)σ(p³), (1) 여기서 σ() 함수는 로짓을 구간 [0, 1]로 정규화하는 시그모이드 함수를 나타냅니다. 그런 다음 의미 마스크 처리 과정에서 다음과 같이 완화된 팬옵틱 출력 m̃pan을 생성할 수 있습니다. mpan = mpan (sem Ompan), (2) 여기서 는 Hadamard 곱 연산을 나타냅니다. ReMask 연산을 통해 인간의 거짓 양성 예측은 msem에 의해 억제될 수 있으므로 학습하는 동안 각 완화된 마스크 쿼리가 해당 클래스의 영역에 빠르게 초점을 맞출 수 있습니다. 여기서는 mpan의 원래 크기를 유지하기 위해 항등 매핑을 적용하여 테스트 중에 의미 분기를 제거할 수 있습니다. 따라서 ReMask는 테스트 중에 오버헤드 비용이 발생하지 않는 완전한 완화 기술이 됩니다. 재조정된 파노라마 출력 mpan은 손실 Lpan에 의해 감독됩니다. msem에 대한 더 간단한 목적에 대한 그래디언트 중지. 파노라마 분할을 위해 설계된 손실이 의미 헤드의 매개변수에 영향을 미치지 않도록 하기 위해 그림 2에서 설명한 대로 msem에 대한 그래디언트 흐름을 중지합니다. 즉, 의미 헤드는 의미 손실 sem에 의해서만 감독되므로 덜 복잡한 작업인 의미 분할의 목적에 집중할 수 있습니다. ReMask는 어떻게 작동합니까? 위에서 정의한 대로 ReMask 연산이 학습에 도움이 되는 두 가지 요소가 있습니다. (1) 거짓 양성 손실을 억제하는 데 도움이 되는 의미 출력과 파노라마 출력 간의 Hadamard 곱 연산; (2) 일관된(대단위) 의미 예측으로 전체 네트워크를 동시에 학습하는 학습 목적에 대한 완화. 의미 마스킹은 [13, 71]과 같이 변환기 디코더의 지역성을 향상시킬 수도 있으므로 msem을 기준 진실 의미 마스크로 대체하여 실험을 수행하여 학습 완화 또는 지역 강화가 학습을 개선하는지 확인했습니다.msem에 기준 진실을 할당하면 각 단계에 sem이 적용되지 않으므로 가장 정확한 지역 강화가 적용됩니다.이런 식으로 기준 진실 의미 마스크로 마스크된 거짓 양성 예측이 대량으로 발생하므로 거짓 양성 그래디언트가 크게 줄어듭니다.결과는 섹션 4에서 보고합니다.3.2 클래스에 대한 완화(재분류) 마스크 변환기[64, 13, 71, 42]는 각 마스크 예측이 단일 클래스에 해당한다는 가정 하에 작동하므로 분류 헤드에 대한 기준 진실은 원핫 벡터입니다.그러나 실제로는 학습 프로세스 중에 모델이 예측한 각 불완전한 마스크가 여러 기준 진실 마스크와 교차할 수 있으며, 특히 학습 초기 단계에서 그렇습니다. 그림 3에서 보인 것처럼 마스크 예측인 파란색 마스크는 실제로 기준 진실에 정의된 두 클래스(&quot;야구 글러브&quot;와 &quot;사람&quot;)를 포함합니다. 클래스별 기준 진실에 59.53.54.Method만 포함되어 있는 경우 52.2배 더 빠름 51.52.53.Backbone Resolution FPS PQ Panoptic-DeepLab [10] MNV3-L [26]| 641×641 26.3 30.48.Panoptic-DeepLab [10] R50 [21] 641×641 20.0 35.48.실시간 [25] R50 [21] 800x1333 15.9 37.44.45.MaskConver [54] MN-MH [15] 45.43.MaskFormer [13] R50 [21] 3배 더 빠름 42.42.YOSO [28] R50 [21] YOSO [28] R50 [21] 39.38.40.40.kMaX-DeepLab [71] R50 [21] 640×640 40.2 37.800x1333 17.6 46.800x1333 23.6 48.512×800 45.6 46.1281x1281 16.3 53.3배 더 빠름 36.37.37.ReMaX-T* MNV3-S [26] ReMax-St 33.32.30.ReMax-RReMaX-MNV3-S ReMaX-MNV3-L 100K kMaX-RkMaX-MNV3-S MNV3-L [26] R50 [21] R50 [21] 50K 150K kMaX-MNV3-L Iters 그림 4: 기준 kMaX-DeepLab [71]과 비교한 COCO val의 성능. ReMax는 기준에 비해 3배 더 빠른 수렴을 가져올 수 있으며, 기준선을 명확한 여백으로 개선할 수 있습니다. 모델을 200K 반복으로 학습하면 ResNet-50의 성능을 54.2 PQ까지 더욱 개선할 수 있습니다.ReMaX-M+ ReMaX-B 641×641 108.7 40.641x641 80.9 44.641x641 51.9 49.1281x1281 16.3 54.COCO val set에서 효율적인 모델(&gt;15 FPS).파레토 곡선은 그림 5(b)에 나와 있습니다.모든 모델의 FPS는 배치 크기 1의 NVIDIA V100 GPU에서 평가됩니다.효율적인 픽셀 및 변압기 디코더 적용.자세한 내용은 부록을 확인하세요.표 1: 최신 클래스 &quot;야구 글러브&quot;와의 비교, &quot;사람&quot;에 대한 예측은 거짓 양성 사례로 간주됩니다. 그러나 다른 엔터티의 특징이 존재하면 과도한 페널티가 발생하여 네트워크 예측이 신뢰도가 낮아질 수 있습니다.위의 문제를 해결하기 위해 클래스 로짓에 또 다른 완화 전략인 클래스별 완화(ReClass)를 도입합니다.이 전략은 예측된 마스크와 기준 진실 의미 마스크의 겹침에 따라 각 예측된 마스크의 레이블에 대한 클래스 신뢰도를 재할당합니다.onehot 클래스 레이블을 y로, 기준 진실 이진 의미 마스크를 S로 표시합니다.보충 클래스 가중치는 다음과 같이 계산합니다.Ут = σ(mpan)&#39;S ΣΗ HW Si = [So, ..., SHw] ∈ {0,1}HW×Nc, (3) 여기서 Ут는 예측된 마스크와 기준 진실 마스크 간의 정규화된 교집합으로 가중치가 적용된 레이블을 나타냅니다. ym을 사용하여 최종 클래스 가중치 ŷ € [0, 1] Nc를 다음과 같이 정의합니다.ŷ = = nym + (1 - nym)y, (4) 여기서 n은 분류 헤드에 적용되는 완화 정도를 제어하는 ReClass의 부드러운 계수를 나타냅니다.4 실험 결과 4.1 데이터 세트 및 평가 지표.ReMaX에 대한 연구에는 일반적으로 사용되는 세 가지 이미지 분할 데이터 세트에서 성능을 분석하는 것이 포함됩니다.COCO[43]는 80개의 &quot;사물&quot; 및 &quot;물건&quot; 범주로 의미, 인스턴스 및 파노라마 분할을 지원합니다.Cityscapes[16]는 8개의 &quot;사물&quot;과 11개의 &quot;물건&quot; 범주로 구성되어 있으며 ADE20K[74]에는 100개의 &quot;사물&quot;과 50개의 &quot;물건&quot; 범주가 포함되어 있습니다. 영어: 우리는 [35]에 정의된 Panoptic Quality(PQ) 메트릭(panoptic 분할용), [43]에 정의된 Average Precision(인스턴스 분할용), mIoU [18] 메트릭(의미 분할용)을 사용하여 우리 방법을 평가합니다.4.2 COCO Panoptic 구현 세부 정보에 대한 결과.ReMax의 매크로 아키텍처는 기본적으로 kMaX-DeepLab [71]을 따르지만, 우리는 섹션 3에서 소개한 모듈을 해당 헤드에 통합합니다.구체적으로, 우리는 그림 2에 정의된 xsem과 같이 각 k-means 교차 주의 연산에서 키를 사용합니다.학습 중에 도입된 의미 헤드는 ASPP 모듈[8]과 채널 수를 출력하지 않는 1 × 1 합성곱으로 구성됩니다.다양한 크기의 모델에 대한 사양은 부록에 소개되어 있습니다. PQ 54.54.53.51.COCO PQ 69.◆ 68.도시경관 68.66.66.66.49.48.A48.45.46.. 46.63.64.62.62.44.59.759.42.42.40.60.59.+ 39.59.3 58.57.X 37.37.60.57.56.36.35.ReMax kMaX-DeepLab 37.ReMax MaskFormer 33.Panoptic-DeepLab -YOSO MaskConver 54.30.30.실시간 YOSO -실시간 51.0 XLPSNet kMaX-DeepLab Panoptic-DeepLab UPSNet Mask2Former 52.100 FPS25 FPS (b) 그림 5: (a) COCO Panoptic val set 및 (b) Cityscapes val set의 FPS-PQ 파레토 곡선. 해당 데이터 포인트의 세부 정보는 표 1 및 8에서 확인할 수 있습니다. 우리는 kMaX-DeepLab [71], Mask2Former [13], YOSO [28], Panoptic-DeepLab [10], Real-time Panoptic Segmentation [25], UPSNet [68], LPSNet [24], MaskFormer [11] 및 MaskConver [54]를 포함한 Panoptic 분할을 위한 다른 최첨단 효율적 파이프라인과 우리 방법을 비교합니다. 학습 세부 정보. 우리는 기본적으로 kMaX-DeepLab [71]에서 제안된 학습 레시피를 따르지만 네트워크에 더 많은 완화를 추가하기 때문에 하이퍼 매개변수를 약간 변경합니다. 여기서 우리는 필요한 부분을 강조하고 우리 모델의 전체 학습 세부 정보와 사양도 부록에서 찾을 수 있습니다. ImageNet 사전 학습된 [55] 백본의 학습률은 더 작은 학습률 계수 0.1과 곱해집니다. 학습 증가를 위해 0.3에서 1.7까지의 스케일링 비율로 입력 이미지를 무작위로 스케일링한 다음 1281 x 1281의 해상도로 잘라내어 다중 스케일 학습을 채택합니다. [64, 70, 71]에 따라 무작위 색상 지터링 [17]과 파노라마 복사-붙여넣기 증가 [32, 57]를 추가로 적용하여 네트워크를 학습합니다. DropPath [29, 38]는 백본인 변압기 디코더에 적용됩니다. AdamW [33, 48] 최적화기는 짧은 일정 50K 및 100K의 경우 가중치 감소 0.005와 배치 크기 64로 사용됩니다. 긴 일정의 경우 가중치 감소를 0.02로 설정합니다. 초기 학습률은 0.006으로 설정되고, 학습이 전체 반복의 85%와 95%에 도달하면 감소 계수 0.1로 곱해집니다. 전체 프레임워크는 TensorFlow [1]의 DeepLab2 [66]로 구현됩니다. [64]에 따라 PQ 스타일 손실, Mask-ID 교차 엔트로피 손실, 인스턴스 판별 손실을 적용하여 백본에서 추출한 기능을 더 잘 학습합니다. 모든 실험에서 지정하지 않은 경우 기본적으로 ResNet-50을 백본으로 사용하고 트랜스포머 디코더의 처음 4단계에 ReMask를 적용합니다. ReClass 연산의 n은 0.1로 설정됩니다. 모든 모델은 27개 에포크(즉, 50K 반복) 동안 학습됩니다. 트랜스포머 디코더의 각 단계에 적용되는 의미적 손실에 대한 손실 가중치는 0.5로 설정됩니다. ReMax는 학습 수렴을 크게 개선하고 기준선보다 훨씬 우수한 성능을 보입니다. 그림 4에서 볼 수 있듯이 50K, 100K 및 150K의 다른 학습 일정으로 모델을 학습할 때 우리 방법이 모든 다른 일정에 대해 기준선보다 명확한 여백으로 성능이 우수한 것을 볼 수 있습니다.구체적으로 ReMax는 백본 ResNet-50에 대해 단기 일정 50K 반복(27 에포크)으로 학습할 때 최첨단 기준선 kMaX-DeepLab보다 3.6 PQ만큼 성능이 우수할 수 있습니다.특히 50K 반복만으로 학습한 우리 모델은 100K 반복(54 에포크)으로 학습한 kMaX-DeepLab[71]보다 성능이 더 뛰어납니다.즉, 우리 모델은 학습 프로세스를 약 2배 빠르게 할 수 있습니다.ResNet-50의 성능은 200K 반복의 경우 54.2 PQ까지 더욱 향상될 수 있습니다. ReMax는 MobileNetV3-Small [26] 및 MobileNetV3-Large [26]를 포함한 효율적인 백본에서 매우 잘 작동하며, 이는 50K 반복의 경우 기준 성능보다 각각 4.9 및 5.2 PQ, 150K 반복의 경우 각각 3.3 및 2.5 PQ를 능가합니다. 이러한 결과는 제안된 완화가 수렴 속도를 크게 높일 수 있지만 네트워크가 더 긴 일정에 따라 학습될 때 더 나은 결과로 이어질 수 있음을 보여줍니다. 효율적인 파노라마 분할을 위한 ReMax 대 다른 최첨단 모델. 표 1과 그림 5(a)는 COCO Panoptic에서 효율적인 파노라마 분할을 위한 다른 최첨단 방법과 저희 방법을 비교합니다. 저희는 ReMax-Tiny(T), ReMaX-Small(S), ReMaX-Medium(M) 및 ReMaX-Base(B)라는 서로 다른 해상도와 모델 용량을 가진 4가지 모델을 제시합니다. 공간 제한으로 인해 이러한 모델의 자세한 사양은 부록에 포함되어 있습니다. 그림 5(a)에 표시된 파레토 곡선에 따르면, 우리의 접근 방식은 이전의 최첨단 효율적 모델보다 명확한 마진으로 성능이 뛰어납니다.특히, COCO Panoptic val set에서 우리 모델은 40.4, 44.6,50.4 51.9 52.4 51.w/ w/ gradActivation ReMax?PQ clip?#ReMasksη softmax Х 48.PQ 0 0.01 0.05 0.1 0.PQ 51.7 51.7 51.9 52.4 51.softmax × 49.sigmoid × X 50.sigmoid ✓ 51.sigmoid × 52를 달성합니다.표 2: 방정식에서 정의된 활성 ReMax per- fernt ½의 영향표 3: 적용된 difReMask 수의 영향표 4: 적용된 difReMask 수의 영향.ReMax per- fernt ½ 영어: 4 for forms for best when ReMask is applied when ReClass. Here we observe that the result is the first 4 stage of trans-economic w/ ReMask mapping? Method Backbone FPS PQ in test? PQ 52.MaskFormer [11] K-Net [73] 17.6 46.47.7.8 49.✓ 52.52.51.26.3 53.16.8 53.26.3 54.N/A ☑ w/stop-grad? w/ gt? PQ ☑ 52.✓ 45.36.6* ☑ 표 5: 테스트 중 ReMask에 대한 항등 매핑과 보조 헤드를 적용한 효과. 항등 매핑과 함께 팬을 적용할 때 보조 의미 헤드를 제거해도 성능 저하가 발생하지 않습니다. PanSegFormer [42] Mask2Former [13] kMaX-DeepLab [71] MaskDINO [39] ReMaX R50 [21] 8.6 51.표 6: ResNet50을 백본으로 사용하는 다른 모델과 COCO val에서 비교.여기서 FPS는 V100에서 1200×800 해상도에서 평가되었으며 모델은 200K 반복으로 학습되었습니다.‡는 A100 GPU를 사용하여 평가되었습니다.표 7: 정지 그래디언트 및 gt-마스킹의 효과.w/ gt?의 표시는 msem에 대해 기준 진실 의미 마스크를 사용하는지 여부를 의미합니다.stopgradient 연산이 없는 결과는 학습에서 잘 수렴하지 않습니다.각각 ReMaX-T, ReMaX-S, ReMaX-M 및 ReMaX-B에 대해 109, 81, 52 및 16 FPS의 49.1 및 54.2 PQ입니다. 이러한 모델의 속도는 ReMax-Base를 제외하고 641×641 해상도에서 평가되며, ReMax-Base는 1281×1281 해상도에서 평가됩니다. 한편, 표 6에서 볼 수 있듯이 백본 ResNet-50을 사용하는 가장 큰 모델도 동일한 백본을 사용하는 다른 비효율적인 최신 방법보다 더 나은 성능을 달성합니다. 다른 활성화 효과와 그래디언트 클리핑 사용. 표 2는 Mask-ID 교차 엔트로피 손실과 Eq (1)에서 정의된 σ(.)에 대해 다른 활성화 함수(시그모이드 대 소프트맥스)를 사용한 효과를 보여줍니다. 표에서 시그모이드를 활성화 함수로 사용할 때 ReMask가 더 나은 성능을 보이지만, 우리 방법은 그래디언트 클리핑을 제거하고도 더 나은 결과를 얻을 수 있습니다. ReMask가 국소성을 향상시키는 대신 완화로 인해 작동하는 이유는 무엇일까요? 섹션 3에서 논의했듯이, 학습을 개선하는 것이 완화인지 픽셀 필터링인지 알아내기 위해 학습 중에 msem을 기준 진실 의미 마스크로 대체하는 실험을 제안합니다. msem을 기준 진실로 변경하면 기준 진실 마스크 외부의 모든 긍정적 예측이 제거되므로 거짓 긍정 손실이 상당히 줄어듭니다. 엄청난 감소(표 7에서 52.4 대 45.1 PQ)는 거짓 긍정 손실의 그래디언트가 최종 성능에 도움이 될 수 있음을 나타냅니다. 또한 표 7은 파노라마 손실에서 의미 예측으로 그래디언트 흐름을 활성화할 때 전체 프레임워크가 잘 수렴하지 못해 성능이 급격히 떨어집니다(36.6 PQ). 그래디언트 흐름이 중단되면 의미 마스크 msem은 더 간단한 목표(즉, 의미 분할만)에 직면합니다. 마스크 완화의 수. 표 3은 각 단계에 적용된 ReMask 수의 효과를 보여줍니다. 이를 통해 성능이 점차 증가하여 ReMask 수가 4일 때 52.4 PQ에서 최고치에 도달하는 것을 확인할 수 있습니다. 이는 다른 모든 절제 연구에 대한 최종 설정이기도 합니다. 네트워크에서 ReMask(&gt;4) 작업을 너무 많이 사용하면 프레임워크에 너무 많은 완화가 추가되어 파노라마 분할의 최종 복합 목표에 잘 맞지 않을 수 있습니다. ReClass는 또한 ReMax의 성능을 개선하는 데 도움이 될 수 있습니다. 이 부분에서 ReClass와 하이퍼 매개변수 ŉ를 조사하고 표 4에 결과를 보고합니다. 표 4에서 5개의 다른 ŋ을 0에서 0.2까지 절제하고 ReClass가 n = 0.1일 때 가장 좋은 성능을 보이며 강력한 기준선에 비해 n이 0.5만큼 증가함을 발견했습니다. ReClass의 효능은 각 마스크가 여러 클래스의 영역을 포함할 수 있다는 가정을 검증합니다. 테스트 중 ReMask에 대한 보조 의미 헤드 제거 효과. ReMask 작업은 테스트 중에 적용하고 제거할 수 있습니다.표 5에서 모델MaX-S[26] 6.5 74M 68.Method Backbone FPS PQ Method Backbone FPS #params PQ Mask2Former[13] R50[21] 4.1 62.Mask2Former[71] Swin-LT[45] 216M 66.Panoptic-DeepLab[10] Xception-71[14] 5.7 63.kMaX-DeepLab[71]| MAX-S*[64] 6.74M 66.LPSNet[24] R50[21] 7.7 59.Panoptic-DeepLab[10]| R50 [21] 8.5 59.kMaX-DeepLab [71] R50 [21] 9.0 64.kMaX-DeepLab [71] ConvNeXt-L* [46] 3.OneFormer [30] ConvNeXt-L [46] ReMaX 232M 68.220M 68.실시간 [25] R50 [21] 10.1 58.YOSO [28] R50 [21] 11.1 59.kMaX-DeepLab [71] MNV3-L [26] 22.8 60.ReMaX 9.0 65.ReMaX 640-640-34.39.7 46.ReMaX R50 [21] MNV3-L [26] 22.8 62.MNV3-S [26] 25.6 57.표 8: 가벼운 백본에 대한 Cityscapes val set 결과.COCO [43] 및 Mapillary Vistas [51]와 같은 추가 데이터에 대한 사전 학습이 없는 방법과 공정한 비교를 위한 테스트 시간 증가를 고려합니다.1025×2049 해상도와 V100 GPU로 FPS를 평가합니다.다른 방법에 대한 FPS는 원래 논문에서 보고된 해상도를 사용하여 평가합니다.표 9: 더 큰 백본에 대한 Cityscapes val set 결과.ImageNet-22k에서 사전 학습됨.방법 MaskFormer [11] Mask2Former [13] YOSO [28] kMaX-DeepLab [71] kMaX-DeepLab [71]| ReMaX Backbone Resolution FPS PQ mIoU R50 [21] R50 [21] 640-2560 35.4 38.641x641 38.7 41.5 45.1281×1281 14.4 42.3 45.641x641 38.7 41.9 45.1281x1281 14.4 43.4 46.표 10: ADE20K val set 결과. FPS는 표에 보고된 해당 해상도에서 NVIDIA V100 GPU에서 평가됩니다. ReMaX는 두 설정에서 비슷한 성능을 보입니다. 표 5에서는 테스트 중에 보조 의미 헤드를 제거하기 위해 학습 중에 mpan에 항등 매핑을 적용해야 함을 보여줍니다. 학습 시 동일성 매핑 없이 테스트 중에 의미 헤드를 제거하면 표 5의 첫 번째 행인 52.4에서 51.9로 0.5가 떨어집니다. 4.3 도시 경관 구현 세부 정보의 결과. 모델은 32개의 TPU 코어에서 32의 배치 크기를 사용하여 학습되었으며 총 60K 반복이 이루어졌습니다. 처음 5K 반복은 워밍업 단계를 구성하며, 여기서 학습률은 0에서 3 × 10−³로 점차 증가합니다. 학습하는 동안 입력 이미지는 1025 ×픽셀로 패딩됩니다. 또한, 서로 다른 가중치를 갖는 4개의 손실 구성 요소를 포함하는 멀티태스크 손실 함수를 사용합니다. 구체적으로, PQ 스타일 손실, 보조 의미 손실, 마스크 ID 교차 엔트로피 손실 및 인스턴스 판별 손실의 가중치는 각각 3.0, 1.0, 0.3 및 1.0으로 설정됩니다. 우리 모델의 특징 표현을 생성하기 위해 256개 클러스터 센터를 사용하고 픽셀 디코더에 추가 병목 블록을 통합하여 출력 스트라이드가 2인 특징을 생성합니다. 이러한 설계는 기본적으로 kMaX-DeepLab[71]에서 제안되었으며 공정한 비교를 위해 여기에서 간단히 따릅니다. 도시 경관에 대한 결과. 표 8과 그림 5(b)에서 볼 수 있듯이 다른 방법이 ResNet-50을 기반으로 하는 반면 더 작은 백본 MobileNetV3-Large(62.5 PQ)를 사용할 때 우리 방법이 더 나은 성능을 달성할 수 있음을 보여줍니다. 한편, 백본으로 Axial-ResNet-50(즉, MaXS, 74M 매개변수)을 사용하는 우리 모델은 ConvNext-L 백본(&gt;220M 매개변수)을 사용하는 최신 모델[30, 71]보다 성능이 우수할 수 있습니다. 그림 5(b)의 파레토 곡선은 속도-정확도 트레이드오프 측면에서 우리 방법의 효능을 명확히 보여줍니다. 4.4 ADE20K 구현 세부 정보의 결과. 기본적으로 COCO 데이터 세트와 동일한 실험 설정을 따르지만, 모델을 100K 반복(54 에포크) 동안 훈련한다는 점이 다릅니다. 또한 각각 1281 x 1281 픽셀과 641 x 641의 입력 해상도를 사용하여 실험을 수행합니다. 추론하는 동안 전체 입력 이미지를 전체적으로 처리하고 긴 쪽을 대상 크기에 맞게 조정한 다음 짧은 쪽을 패딩합니다. 이전 접근 방식은 슬라이딩 윈도우 접근 방식을 사용하는데, 이는 더 많은 계산 리소스가 필요할 수 있지만 정확도와 탐지 품질 측면에서 더 나은 성능을 낼 것으로 예상됩니다. ReMask 및 ReClass의 하이퍼 매개변수의 경우 COCO에서 제안한 것과 동일한 설정을 사용했습니다. ADE20K의 결과. 표 10에서 우리는 ReMax의 성능을 ResNet-50을 백본으로 사용하는 다른 방법과 비교했고, 우리 모델은 mIOU 측면에서 기준 모델보다 1.5배 더 우수한 것으로 나타났습니다. 이는 추가 계산 비용이 필요하지 않고 학습 중 완화만 필요하기 때문에 기준 모델과 비교했을 때 명확한 차이입니다. 또한 우리 모델은 PQ 측면에서 기준 모델 kMaX-DeepLab보다 1.1배 더 우수한 것으로 나타났습니다. ResNet-50을 백본으로 통합한 다른 프레임워크와 비교했을 때, 우리 모델은 Mask2Former와 MaskFormer보다 각각 3.7과 8.7 PQ만큼 상당히 우수한 것으로 나타났습니다. 5
--- CONCLUSION ---
이 논문은 ReMax라는 새로운 접근 방식을 제시하는데, 이는 ReMask와 ReClass라는 두 가지 구성 요소로 구성되어 있으며, Mask Transformers를 사용한 파노라마 분할에 대한 더 나은 학습으로 이어집니다. 제안된 방법은 특히 효율적인 모델의 경우 학습 속도와 최종 성능에 상당한 영향을 미치는 것으로 나타났습니다. 저희는 저희의 작업이 이 방향으로 추가 연구를 촉진하여 더 효율적이고 정확한 파노라마 분할 모델을 만들어내기를 바랍니다. 감사의 말. 저희는 친절한 도움과 토론에 대해 Google Research의 Xuan Yang에게 감사드리고 싶습니다. Shuyang Sun과 Philip Torr는 UKRI 보조금인 Turing AI Fellowship EP/W002981/1과 EPSRC/MURI 보조금인 EP/N019474/1의 지원을 받았습니다. 저희는 또한 Royal Academy of Engineering과 FiveAI에 감사드리고 싶습니다. 부록 A ReMask를 사용한 ReMax CountSigmoid CE의 손실 시각화, std=0.Sigmoid CE w/o ReMask, std=0.Method Backbone #Params FLOPS FPS PQ kMaX-DeepLab [71] ConvNeXt-T* [64] 61M ReMaX ConvNeXt-T [64] 61M Mask2Former [13] Swin-B* [45] 107M kMaX-DeepLab [71] ConvNeXt-S* [64] 83M ReMaX ConvNeXt-S [64] 83M 172G 21.8 55.172G 21.8 55.466G 56.251G 16.5 56.251G 16.5 56.-1.2.2.2.FP/FN 손실, 로그 스케일 2.3.3.3.그림 6: 히스토그램은 로그 스케일에서 교차 엔트로피 손실에 대한 거짓 양성과 거짓 음성의 비율을 보여줍니다. 표 11: COCO val set에서 더 큰 모델의 결과. FLOPS와 FPS는 입력 크기 1200 x 800과 V100 GPU로 평가됩니다. †: ImageNet-22K 사전 학습. 그림 6에서 ReMask를 적용한 손실과 ReMask 없이 적용한 손실을 시각화합니다. 이를 통해 ReMask가 매우 높은 거짓 양성 손실을 효과적으로 줄일 수 있음을 알 수 있습니다. 따라서 이 방법은 프레임워크의 학습을 안정화할 수 있습니다. B 모델 사양 모델 백본 해상도 #픽셀 #변압기 디코더 디코더 #FLOPS #매개변수 FPS ReMaX-T MNV3-S [26] 641 ×[1, 1, 1, 1] ReMaX-S MNV3-L [26] ReMaX-M ReMaX-B 641 ×[1, 1, 1, 1] R50 [21] 641[1, 5, 1, 1] [1, 1, 1] [1, 1, 1] [1, 1, 1] [2, 2, 2] 18.8G 18.6M20.9G 22.0M67.8G 50.8M294.7G 56.6MR50 [21] 1281 x 1281 [1, 5, 1, 1] 표 12: 사양 ReMax 패밀리의 다양한 모델.우리는 표 12에서 우리 모델의 사양과 그에 해당하는 매개변수 수와 FLOP를 제공합니다.[·, ·, ·, ·] 형식의 픽셀 디코더 수는 입력 크기의 [32, 16, 3, 1]배인 피처의 수를 나타냅니다.우리는 입력 크기의 해상도 32, 16인 모든 피처 맵에 대해 Axial attention[63]을 사용하고 나머지에는 일반 병목 잔여 블록[21]을 사용합니다. 변압기 디코더의 표시 [·, ·, ·]는 입력 크기의 [1, ½,] 배의 해상도에 대한 숫자를 나타냅니다.8&quot; C 더 큰 모델의 성능 또한 ConvNeXt-Tiny(T) 및 ConvNextSmall(S)과 같은 더 큰 모델에 대한 ReMax의 성능을 검증합니다. 표 11에서 ReMaX가 기준 kMaX-DeepLab[71] 및 Mask2Former[13]에 비해 더 나은 결과를 얻을 수 있음을 알 수 있습니다. 그러나 숫자가 높아지면 ReMax의 개선이 포화됩니다. 특히 ConvNeXt-T 백본을 사용할 때 ReMax는 추론 중에 추가적인 계산 비용이 발생하지 않으면서 kMaX-DeepLab보다 0.PQ 증가로 이어질 수 있습니다. kMaX-DeepLab은 ConvNext-S 백본을 사용하여 36% 더 많은 매개변수(22M)와 46% 더 많은 FLOP(79G).D 제한 사항 TensorFlow에서 방법을 구현했기 때문에 빌드할 수 있는 기준선이 제한적입니다.향후 작업을 위해 PyTorch의 Mask2Former[13]와 같은 다른 기준선에서 접근 방식을 검증할 것입니다.한편 ReClass는 각 마스크의 크기에 따라 각 클래스의 가중치를 측정하는데, 이는 정확하지 않을 수 있으며 향후 더욱 개선될 수 있습니다.E 경계 영향 이 방법은 효율적인 파노라마 분할을 위한 모델을 더 잘 훈련하는 데 도움이 될 수 있습니다.자율 주행, 로봇 공학, 증강 현실과 같은 분야에서 새로운 애플리케이션을 개발하는 데에도 사용할 수 있습니다.예를 들어, 자율 주행에서 효율적인 파노라마 분할을 사용하여 도로상의 다른 차량, 보행자 및 장애물을 식별하고 추적할 수 있습니다.이 정보는 자동차가 안전하게 주행하는 데 도움이 될 수 있습니다.로봇 공학에서 효율적인 파노라마 분할을 사용하여 로봇이 주변 환경을 이해하고 장애물을 피하는 데 도움이 될 수 있습니다.이 정보는 로봇이 물건을 집어 올리고 놓거나 복잡한 환경을 탐색하는 것과 같은 작업을 수행하는 데 도움이 될 수 있습니다. 증강 현실에서 효율적인 파노라마 분할을 사용하여 실제 세계 위에 디지털 정보를 중첩할 수 있습니다. 이 정보는 사용자에게 주변 환경에 대한 정보를 제공하거나 새로운 도시에서 길을 찾는 것과 같은 작업을 돕는 데 사용할 수 있습니다. 전반적으로, 우리의 방법은 컴퓨터 비전 및 로봇 공학 분야에서 다양한 응용 프로그램을 강화하는 데 사용할 수 있습니다. 참고문헌 [1] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Manjunath Kudlur, Josh Levenberg, Rajat Monga, Sherry Moore, Derek G. Murray, Benoit Steiner, Paul Tucker, Vijay Vasudevan, Pete Warden, Martin Wicke, Yuan Yu, Xiaoqiang Zheng. Tensorflow: 대규모 머신 러닝을 위한 시스템. 2016년 제12회 USENIX 운영 체제 설계 및 구현 컨퍼런스 논문집.[2] Anurag Arnab 및 Philip HS Torr. 심층 고차 crfs를 사용한 하향식 인스턴스 분할. BMVC에서, 2016년.[3] Anurag Arnab, Sadeep Jayasumana, Shuai Zheng 및 Philip HS Torr. 심층 신경망의 고차 조건부 난수 필드. ECCV에서, 2016년.[4] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov 및 Sergey Zagoruyko. 변환기를 사용한 종단 간 객체 감지. ECCV에서, 2020년. 1,[5] Jie-Neng Chen, Shuyang Sun, Ju He, Philip HS Torr, Alan Yuille 및 Song Bai. Transmix: 비전 변환기의 믹스에 참석. CVPR, 2022.[6] Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy 및 Alan L Yuille. 딥 컨볼루션 네트와 완전 연결 crf를 사용한 의미적 이미지 분할. ICLR, 2015.[7] Liang-Chieh Chen, Alexander Schwing, Alan Yuille 및 Raquel Urtasun. 딥 구조화 모델 학습. ICML, 2015.[8] Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy 및 Alan L Yuille. Deeplab: 딥 컨볼루션 네트, 아트로스 컨볼루션 및 완전 연결 crf를 사용한 의미적 이미지 분할. IEEE TPAMI, 2017. 3, 4,[9] Bowen Cheng, Liang-Chieh Chen, Yunchao Wei, Yukun Zhu, Zilong Huang, Jinjun Xiong, Thomas S Huang, Wen-Mei Hwu, Honghui Shi. Spgnet: 장면 구문 분석을 위한 의미 예측 지침. ICCV에서, 2019.[10] Bowen Cheng, Maxwell D Collins, Yukun Zhu, Ting Liu, Thomas S Huang, Hartwig Adam, LiangChieh Chen. Panoptic-DeepLab: 하향식 Panoptic 분할을 위한 간단하고 강력하며 빠른 기준선. CVPR에서, 2020. 1, 3, 6, 7,[11] Bowen Cheng, Alexander G Schwing, Alexander Kirillov. 픽셀당 분류만으로는 의미 분할에 필요한 것이 아닙니다. NeurIPS, 2021. 1, 2, 4, 7, 8,[12] Bowen Cheng, Anwesa Choudhuri, Ishan Misra, Alexander Kirillov, Rohit Girdhar, Alexander G Schwing. 비디오 인스턴스 분할을 위한 Mask2former. CVPR, 2022.[13] Bowen Cheng, Ishan Misra, Alexander G Schwing, Alexander Kirillov, Rohit Girdhar. 범용 이미지 분할을 위한 Maskedattention 마스크 변환기. CVPR, 2022. 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,[14] François Chollet. Xception: 깊이별 분리형 합성곱을 사용한 딥 러닝. CVPR, 2017.[15] Grace Chu, Okan Arikan, Gabriel Bender, Weijun Wang, Achille Brighton, Pieter-Jan Kindermans, Hanxiao Liu, Berkin Akin, Suyog Gupta, Andrew Howard. 아키텍처 검색을 통한 다중 하드웨어 모바일 모델 검색. CVPR 워크숍, 2021.[16] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, Bernt Schiele. 의미론적 도시 장면 이해를 위한 도시 경관 데이터 세트. CVPR, 2016. 3,[17] Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, Quoc V Le. 자동 증강: 데이터에서 증강 정책 학습. CVPR, 2019.[18] Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, Andrew Zisserman. Pascal Visual Object Classes(VOC) Challenge. IJCV, 88:303–338, 2010.[19] Xiuye Gu, Yin Cui, Jonathan Huang, Abdullah Rashwan, Xuan Yang, Xingyi Zhou, Golnaz Ghiasi, Weicheng Kuo, Huizhong Chen, Liang-Chieh Chen, David A Ross. Dataseg: 범용 다중 데이터 세트 다중 작업 분할 모델 길들이기. arXiv 사전 인쇄본 arXiv:2306.01736, 2023.[20] Bharath Hariharan, Pablo Arbeláez, Ross Girshick, Jitendra Malik. 동시 감지 및 분할. ECCV, 2014.[21] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. 이미지 인식을 위한 심층 잔여 학습. CVPR, 2016년. 6, 8, 9,[22] Kaiming He, Georgia Gkioxari, Piotr Dollár, Ross Girshick. 마스크 r-cnn. ICCV, 2017년.[23] Xuming He, Richard S Zemel, Miguel Á Carreira-Perpiñán. 이미지 레이블링을 위한 다중 스케일 조건부 난수 필드. CVPR, 2004년.[24] Weixiang Hong, Qingpei Guo, Wei Zhang, Jingdong Chen, Wei Chu. Lpsnet: 빠른 파노라마 분할을 위한 경량 솔루션. CVPR, 2021. 7,[25] Rui Hou, Jie Li, Arjun Bhargava, Allan Raventos, Vitor Guizilini, Chao Fang, Jerome Lynch, Adrien Gaidon. 밀집 탐지에서 실시간 파노라마 분할. CVPR, 2020. 3, 6, 7,[26] Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, et al. mobilenetv3 검색. ICCV, 2019. 1, 2, 6, 7, 9,[27] Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam. Mobilenets: 모바일 비전 애플리케이션을 위한 효율적인 합성 신경망. arXiv 사전 인쇄본 arXiv:1704.04861, 2017.[28] Jie Hu, Linyan Huang, Tianhe Ren, Shengchuan Zhang, Rongrong Ji, Liujuan Cao. You only segment once: 실시간 파노라마 분할을 향해. CVPR, 2023. 3, 6, 7,[29] Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, Kilian Q Weinberger. 확률적 깊이를 갖춘 딥 네트워크. ECCV, 2016.[30] Jitesh Jain, Jiachen Li, Mang Tik Chiu, Ali Hassani, Nikita Orlov, Humphrey Shi. Oneformer: 범용 이미지 분할을 지배하는 하나의 변압기. CVPR, 2023. 3,[31] Xu Jia, Bert De Brabandere, Tinne Tuytelaars, Luc V Gool. 동적 필터 네트워크. NeurIPS, 2016.[32] Dahun Kim, Jun Xie, Huiyu Wang, Siyuan Qiao, Qihang Yu, Hong-Seok Kim, Hartwig Adam, In So Kweon, Liang-Chieh Chen. TubeFormer-DeepLab: 비디오 마스크 변압기. CVPR, 2022. 3,[33] Diederik P Kingma 및 Jimmy Ba. Adam: 확률적 최적화 방법. ICLR, 2015.[34] Alexander Kirillov, Ross Girshick, Kaiming He, Piotr Dollár. 파노라마 피처 피라미드 네트워크. CVPR, 2019. 1,[35] Alexander Kirillov, Kaiming He, Ross Girshick, Carsten Rother, Piotr Dollár. 파노라마 분할. CVPR, 2019. 1,[36] Alexander Kirillov, Yuxin Wu, Kaiming He, Ross Girshick. Pointrend: 렌더링으로서의 이미지 분할. CVPR, 2020.[37] Philipp Krähenbühl 및 Vladlen Koltun. 가우시안 에지 전위가 있는 완전히 연결된 crfs에서의 효율적 추론. NeurIPS, 2011.[38] Gustav Larsson, Michael Maire, Gregory Shakhnarovich. Fractalnet: 잔차가 없는 초심층 신경망. arXiv 사전 인쇄본 arXiv:1605.07648, 2016.[39] Feng Li, Hao Zhang, Shilong Liu, Lei Zhang, Lionel M Ni, Heung-Yeung Shum, et al. Mask dino: 객체 감지 및 분할을 위한 통합된 변압기 기반 프레임워크를 향하여.CVPR에서, 2023. 1,[40] Qizhu Li, Xiaojuan Qi, Philip HS Torr. 파노라마 분할을 위한 통합된 훈련 및 추론.CVPR에서, 2020.[41] Yanwei Li, Xinze Chen, Zheng Zhu, Lingxi Xie, Guan Huang, Dalong Du, Xingang Wang. 파노라마 분할을 위한 주의 유도 통합 네트워크.CVPR에서, 2019. 1,[42] Zhiqi Li, Wenhai Wang, Enze Xie, Zhiding Yu, Anima Anandkumar, Jose M Alvarez, Tong Lu, Ping Luo. Panoptic segformer: transformers를 사용한 panoptic segmentation 심층 분석. CVPR, 2022. 1, 2, 3, 4, 5,[43] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, C Lawrence Zitnick. Microsoft coco: 컨텍스트 내 공통 객체. ECCV, 2014. 3, 6,[44] Huanyu Liu, Chao Peng, Changqian Yu, Jingbo Wang, Xu Liu, Gang Yu, Wei Jiang. panoptic segmentation을 위한 종단 간 네트워크. CVPR, 2019.[45] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo. Swin transformer: 이동된 창을 사용한 계층적 비전 변환기. ICCV, 2021. 9,[46] Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie. 2020년대를 위한 합성 신경망. CVPR, 2022. 3,[47] Jonathan Long, Evan Shelhamer, Trevor Darrell. 의미 분할을 위한 완전 합성 신경망. CVPR, 2015.[48] Ilya Loshchilov 및 Frank Hutter. 분리된 가중치 감소 정규화. ICLR, 2019.[49] Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang. 빠른 학습 수렴을 위한 조건부 detr. ICCV, 2021.[50] Rohit Mohan 및 Abhinav Valada. Efficientps: 효율적인 파노라마 분할. IJCV, 129(5):1551–1579, 2021.[51] Gerhard Neuhold, Tobias Ollmann, Samuel Rota Bulo 및 Peter Kontschieder. 거리 풍경의 의미적 이해를 위한 mapillary vistas 데이터 세트. ICCV, 2017.[52] Lorenzo Porzi, Samuel Rota Bulò, Aleksander Colovic 및 Peter Kontschieder. 원활한 장면 분할. CVPR, 2019. 1,[53] Siyuan Qiao, Liang-Chieh Chen 및 Alan Yuille. 감지기: 재귀적 특징 피라미드와 전환 가능한 아트로스 합성곱을 사용하여 객체 감지. CVPR, 2021.[54] Abdullah Rashwan, Yeqing Li, Xingyi Zhou, Jiageng Zhang 및 Fan Yang. Maskconver: 순수 합성곱을 사용한 범용 파노라마 및 의미 분할 모델. OpenReview, 2023. 3, 6,[55] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael S. Bernstein, Alexander C. Berg, Li Fei-Fei. Imagenet 대규모 시각 인식 챌린지. IJCV, 115:211–252, 2015. 4,[56] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. Mobilenetv2: 역 잔차 및 선형 병목 현상. CVPR에서, 2018.[57] 신인규, 김다훈, 유치항, 시준, 김홍석, 브래들리 그린, 인소권, 윤국진, 첸량치. Video-kmax: 온라인 및 준온라인 비디오 파노라마 분할을 위한 간단한 통합 접근 방식. arXiv 사전 인쇄본 arXiv:2304.04694, 2023.[58] 로빈 스트루델, 리카르도 가르시아, 이반 랍테프, 코델리아 슈미트. 세그멘터: 의미 분할을 위한 변환기. ICCV, 2021.[59] 크리스티안 세게디, 빈센트 반호우케, 세르게이 이오페, 존 슐렌스, 즈비그뉴 워즈나. 컴퓨터 비전을 위한 인셉션 아키텍처 재고. CVPR, 2016.[60] 지 티안, 츈화 센, 하오 첸. 인스턴스 분할을 위한 조건부 합성곱. ECCV, 2020.[61] Zhuowen Tu, Xiangrong Chen, Alan L Yuille, Song-Chun Zhu. 이미지 구문 분석: 분할, 감지 및 인식 통합. IJCV, 63:113–140, 2005.[62] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin. 주의만 있으면 됩니다. NeurIPS, 2017. 1, 3,[63] Huiyu Wang, Yukun Zhu, Bradley Green, Hartwig Adam, Alan Yuille, Liang-Chieh Chen. AxialDeepLab: 파노라마 분할을 위한 독립 실행형 축 방향 주의. ECCV, 2020. 3,[64] Huiyu Wang, Yukun Zhu, Hartwig Adam, Alan Yuille 및 Liang-Chieh Chen. Max-deeplab: 마스크 변압기를 사용한 종단 간 파노라마 분할. CVPR, 2021. 1, 2, 3, 4, 5, 7, 9,[65] Xinlong Wang, Rufeng Zhang, Tao Kong, Lei Li 및 Chunhua Shen. SOLOv2: 동적 및 빠른 인스턴스 분할. NeurIPS, 2020.[66] Mark Weber, Huiyu Wang, Siyuan Qiao, Jun Xie, Maxwell D. Collins, Yukun Zhu, Liangzhe Yuan, Dahun Kim, Qihang Yu, Daniel Cremers, Laura Leal-Taixe, Alan L. Yuille, Florian Schroff, Hartwig Adam 및 Liang-Chieh Chen. DeepLab2: 딥 라벨링을 위한 TensorFlow 라이브러리. arXiv: 2106.09748, 2021.[67] Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M Alvarez, Ping Luo. Segformer: 변환기를 사용한 의미 분할을 위한 간단하고 효율적인 설계. NeurIPS에서, 2021. 3,[68] Yuwen Xiong, Renjie Liao, Hengshuang Zhao, Rui Hu, Min Bai, Ersin Yumer, Raquel Urtasun. Upsnet: 통합 파노라마 분할 네트워크. CVPR에서, 2019. 1, 3,[69] Tien-Ju Yang, Maxwell D Collins, Yukun Zhu, Jyh-Jing Hwang, Ting Liu, Xiao Zhang, Vivienne Sze, George Papandreou, Liang-Chieh Chen. Deeperlab: 싱글샷 이미지 파서. arXiv 사전 인쇄본 arXiv:1902.05093, 2019. 1,[70] Qihang Yu, Huiyu Wang, Dahun Kim, Siyuan Qiao, Maxwell Collins, Yukun Zhu, Hartwig Adam, Alan Yuille, and Liang-Chieh Chen. Cmt-deeplab: 파노라마 분할을 위한 클러스터링 마스크 변환기. CVPR, 2022. 1, 3, 4,[71] Qihang Yu, Huiyu Wang, Siyuan Qiao, Maxwell Collins, Yukun Zhu, Hartwig Adam, Alan Yuille, and Liang-Chieh Chen. k-means 마스크 변환기. ECCV, 2022. 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,[72] Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo. Cutmix: 지역화 가능한 특징을 가진 강력한 분류기를 훈련하기 위한 정규화 전략. ICCV, 2019.[73] Wenwei Zhang, Jiangmiao Pang, Kai Chen, and Chen Change Loy. K-net: 통합 이미지 분할을 향해. NeurIPS, 2021. 1, 2, 3, 4,[74] Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio Torralba. ade20k 데이터 세트를 통한 장면 구문 분석. CVPR, 2017. 3,[75] Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang 및 Jifeng Dai. Deformable detr: 엔드투엔드 객체 감지를 위한 변형 가능한 변환기입니다. ICLR, 2021.
