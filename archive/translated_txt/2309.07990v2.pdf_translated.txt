--- ABSTRACT ---
뉴스 기사와 같은 텍스트 문서에서 콘텐츠와 주요 이벤트는 일반적으로 문서에 언급된 모든 엔터티의 하위 집합을 중심으로 전개됩니다. 이러한 엔터티는 종종 두드러진 엔터티로 간주되며, 독자에게 문서의 관련성에 대한 유용한 단서를 제공합니다. 엔터티의 두드러짐을 식별하는 것은 검색, 순위 지정, 엔터티 중심 요약 등과 같은 여러 다운스트림 애플리케이션에서 도움이 되는 것으로 나타났습니다. 두드러진 엔터티 감지에 대한 이전 작업은 주로 대규모 기능 엔지니어링이 필요한 머신 러닝 모델에 초점을 맞추었습니다. 우리는 중간 크기의 언어 모델을 교차 인코더 스타일 아키텍처로 미세 조정하면 기능 엔지니어링 접근 방식보다 상당한 성능 향상을 얻을 수 있음을 보여줍니다. 이를 위해 중간 크기의 사전 학습된 언어 모델 패밀리를 대표하는 모델을 사용하여 공개적으로 사용 가능한 네 가지 데이터 세트에 대한 포괄적인 벤치마킹을 수행합니다. 또한 명령어 조정 언어 모델의 제로샷 프롬프팅은 열등한 결과를 생성하여 작업의 고유성과 복잡성을 나타냅니다. 1
--- INTRODUCTION ---
많은 NLP 연구에서 문서의 의미를 이해하는 데 있어 엔터티의 중요성을 강조했습니다(Wu et al., 2020b; Meij et al., 2012). 구조화되지 않은 텍스트 문서에서 엔터티를 자동으로 식별하고 위키피디아와 같은 기본 지식 기반에 연결하는 것은 핵심 NLP 작업 중 하나이며, 여러 공유 작업(Tjong Kim Sang and De Meulder, 2003; Strauss et al., 2016), 벤치마크(Hoffart et al., 2011; Hovy et al., 2006; Pradhan et al., 2013; Rijhwani and Preotiuc-Pietro, 2020; Derczynski et al., 2016) 및 이를 해결하는 데 전념하는 연구(Kolitsas et al., 2018; Nguyen et al., 2014)가 있습니다. 영어: 엔터티가 문서 이해에서 중요한 의미적 역할을 할 수 있지만, 모든 엔터티가 *작업은 저자가 Bloomberg에 소속되어 있는 동안 수행되었습니다.머스크가 440억 달러 규모의 Twitter 거래를 완료 뉴스 세계에서 가장 부유한 사람이자 Tesla의 CEO이며 미국의 연구 실험실 Open Al의 설립자인 Elon Musk가 소셜 미디어 회사 Twitter를 440억 달러에 인수했습니다.목요일에 Twitter의 사장인 Parag Agrawal이 해고되어 샌프란시스코 본사에서 쫓겨났습니다.뉴욕 증권 거래소는 Twitter의 주식 거래가 금요일부터 중단되었다고 보도했습니다.머스크는 도널드 트럼프 전 미국 대통령을 포함하여 과거에 중단된 사용자에 대한 금지를 해제할 것이라고 주장했습니다.비주요 엔터티 주요 엔터티 CEO Elon Musk Twitter Tesla, Inc. Open Al Parag Agrawal 샌프란시스코 뉴욕 증권 거래소 미국 대통령 도널드 트럼프 그림 1: 주요 엔터티와 비주요 엔터티가 있는 문서의 예.엔터티 언급은 텍스트에서 강조 표시됩니다.텍스트 문서는 동등한 역할을 합니다. 일부 엔터티는 문서 내에서 중심 주제 또는 행위자로, 이를 중심으로 콘텐츠와 주요 이벤트가 전개됩니다. 다른 엔터티는 주요 이벤트에 대한 추가 맥락을 제공하기 위해서만 언급됩니다. 예를 들어, 일부 엔터티는 주변 이벤트의 행위자일 수 있지만, 다른 엔터티는 문서 이해에 도움이 되지 않는 것으로 간주됩니다. 따라서 텍스트에서 엔터티 두드러짐은 대상 엔터티가 주어진 텍스트에서 중심적인 정도를 정량화하기 위한 이진 또는 순서적 평가로 정의됩니다(Gamon et al., 2013; Dunietz and Gillick, 2014). 그림 1은 언급된 엔터티와 그 두드러짐과 함께 예시 텍스트를 제공합니다. 텍스트에 대한 엔터티의 두드러짐은 문서를 읽거나 검색할 때 사용자의 관심과 무관하다는 점에 유의합니다(Gamon et al., 2013). 이를 일반적으로 엔터티 관련성이라고 합니다. 또한 문서와 무관하게 엔터티의 전반적인 중요성을 정량화하는 엔터티 중요도와도 다릅니다. 엔티티 샐리언스를 자동으로 추론하는 것은 검색을 돕고(Gamon 등, 2013), 순위 결과를 개선하고(Xiong 등, 2018), 엔티티 감지(Trani 등, 2018)를 돕고, 엔티티 중심 요약과 같은 엔티티 중심 애플리케이션을 가능하게 하는 것으로 나타났습니다(Maddela 등, 2022). 이 논문에서는 엔티티 샐리언스 감지 작업에서 Transformer 기반 사전 학습된 언어 모델(PLM)의 효과를 연구합니다. 엔티티 두드러짐을 결정하는 이전 작업은 엔티티 빈도(Dunietz 및 Gillick, 2014년; Dojchinovski 등, 2016년), 문서 내 엔티티 언급 위치(Dunietz 및 Gillick, 2014년; Trani 등, 2018년), 다른 엔티티와의 관계(Trani 등, 2018년), 길이(Gamon 등, 2013년)와 같은 문서 특징, 엔티티 이름이나 컨텍스트와 같은 어휘적 특징과 같은 관련 측면을 명시적으로 포함하는 특징을 제작하기 위해 많은 특징 엔지니어링에 의존했습니다. 최근 단일 작업만이 주요 엔티티 감지를 포함하는 파이프라인에서 PLM을 사용하려고 시도했지만 평가 범위는 단일 고성능 데이터 세트로 제한되었습니다(Zhao 등, 2021년). 이와 대조적으로, 제안하는 방법은 대상 엔티티의 이름이나 별칭과 텍스트 문서에서의 맥락적 언급이 PLM 인코더에 의해 인코딩되는 교차 인코더 아키텍처를 사용합니다. 분류기는 멘션의 데실 위치 임베딩 벡터를 통해 인코딩된 엔터티에 대한 문맥적 표현과 선택적으로 위치 정보를 사용하여 대상 엔터티의 두드러짐 점수를 결정합니다. 우리는 공개적으로 사용 가능한 데이터 세트 4개에 대한 실험을 수행하는데, 그 중 2개는 인간이 주석을 달았고 2개는 반자동으로 큐레이션했습니다. 우리는 PLM을 사용하여 여러 교차 인코더를 미세 조정하고 이것이 피처 기반 방법과 지시 조정 PLM을 촉구하는 것보다 일관되고 상당한 개선을 가져온다는 것을 보여줍니다. 후자는 엔터티 두드러짐 감지 작업의 참신함과 복잡성을 보여주며, 이를 위해서는 모델이 이 자연어 이해 작업을 위해 상당한 작업별 의미 지식을 학습해야 합니다. 이 논문에서 우리의 기여는 다음과 같습니다. • 우리는 엔터티 두드러짐 감지를 위한 위치 정보의 명시적 인코딩을 사용하여 이전 피처 엔지니어링 접근 방식보다 7~24.4 F1 점수의 일관된 개선을 보여주는 교차 인코더 스타일 아키텍처를 제안합니다. • 우리는 엔티티 눈에 띄는 특성 감지 작업을 위해 두 개의 인간이 주석을 단 데이터 세트와 두 개의 반자동으로 큐레이팅한 데이터 세트의 균일한 벤치마크를 확립했으며 이는 이 작업의 미래 연구에 유익할 것으로 기대합니다. • 모델의 예측 동작에 대한 측면 분석. 2
--- RELATED WORK ---
문서의 관련성을 이해하는 것은 정보 검색 및 자연어 처리(Gamon et al., 2013) 분야의 연구에서 오랫동안 추구해 온 목표 중 하나입니다. 주요 용어 추출(Hulth, 2003; Mihalcea and Tarau, 2004), 잠재적 주제 식별(Blei et al., 2003), 텍스트 요약 생성(Erkan and Radev, 2004) 등 여러 가지 접근 방식이 제안되었습니다. 최근에는 엔터티를 사용하여 문서의 내용을 이해하는 데 중점을 두고 있습니다. 이 목표를 달성하기 위해 엔터티 중요도 작업이 웹 페이지(Gamon et al., 2013)와 뉴스 콘텐츠(Dunietz and Gillick, 2014)에 대해 처음 설명되었습니다. 중요도가 이진인 경우 이 작업은 제한된 형태의 키워드 또는 키프레이즈 추출(Alami Merrouni et al., 2020)로 볼 수 있습니다. 이 연구의 나머지 부분에서는 (Gamon et al., 2013)에 설명된 대로 두드러짐의 개념을 사용할 것입니다. 엔터티의 두드러짐 레이블은 여러 평가자로부터 크라우드소싱 레이블을 얻어 두드러진 엔터티를 식별하거나(Gamon et al., 2013; Dojchinovski et al., 2016; Trani et al., 2018; Maddela et al., 2022) 프록시를 사용하여 얻었습니다. 예를 들어 (Dunietz and Gillick, 2014)는 두드러진 엔터티가 기사의 초록에 나타나는 엔터티라고 가정합니다. (Wu et al., 2020a)는 엔터티에 해당하는 Wikinews 범주가 기사의 범주로 레이블이 지정된 경우 엔터티를 두드러진 것으로 식별합니다. 과거 연구는 대부분 머신 러닝을 제안했습니다.
--- METHOD ---
대상 엔터티의 이름 또는 별칭과 텍스트 문서의 문맥적 언급이 PLM 인코더에 의해 인코딩되는 교차 인코더 아키텍처를 사용합니다. 분류기는 문맥적 표현과 선택적으로 언급의 데실 위치 임베딩 벡터를 통해 인코딩된 엔터티에 대한 위치 정보를 사용하여 대상 엔터티의 두드러짐 점수를 결정합니다. 우리는 다음을 수행합니다.
--- EXPERIMENT ---
4개의 공개적으로 사용 가능한 데이터 세트에 대한 s, 그 중 2개는 인간이 주석을 달았고 2개는 반자동으로 큐레이션했습니다. PLM을 사용하여 여러 교차 인코더를 미세 조정하고 이것이 피처 기반 방법 및 지시 조정 PLM을 촉진하는 것보다 일관되고 상당한 개선을 가져온다는 것을 보여줍니다. 후자는 엔터티 두드러짐 감지 작업의 참신함과 복잡성을 보여주며, 이 자연어 이해 작업을 위해 모델이 상당한 작업별 의미 지식을 학습해야 합니다. 이 논문에서 우리의 기여는 다음과 같습니다. • 우리는 엔터티 두드러짐 감지를 위한 위치 정보를 명시적으로 인코딩하는 교차 인코더 스타일 아키텍처를 제안하며, 이는 이전의 피처 엔지니어링 접근 방식보다 7~24.4 F1 점수의 일관된 개선을 보여줍니다. • 우리는 이 작업에 대한 미래 연구에 유익할 것으로 기대하는 엔터티 두드러짐 감지 작업을 위한 2개의 인간 주석이 달린 데이터 세트와 2개의 반자동으로 큐레이션된 데이터 세트의 균일한 벤치마크를 확립합니다. • 모델의 예측 동작에 대한 측면 분석. 2 관련 연구 문서의 관련성을 이해하는 것은 정보 검색 및 자연어 처리(Gamon et al., 2013) 분야의 연구의 오랜 목표 중 하나입니다. 주요 용어 추출(Hulth, 2003; Mihalcea and Tarau, 2004), 잠재적 주제 식별(Blei et al., 2003), 텍스트 요약 생성(Erkan and Radev, 2004)을 포함한 여러 유형의 접근 방식이 제안되었습니다. 최근에는 문서의 내용을 이해하기 위해 엔터티를 사용하는 데 중점을 두고 있습니다. 이 목표를 달성하기 위해 엔터티 중요도 작업이 웹 페이지(Gamon et al., 2013)와 뉴스 콘텐츠(Dunietz and Gillick, 2014)에 대해 처음 설명되었습니다. 이 작업은 중요도가 이진인 경우 제한된 형태의 키워드 또는 키프레이즈 추출(Alami Merrouni et al., 2020)로 볼 수 있습니다. 이 연구의 나머지 부분에서는 (Gamon et al., 2013)에 설명된 대로 두드러짐의 개념을 사용할 것입니다. 엔터티의 두드러짐 레이블은 여러 평가자로부터 크라우드소싱 레이블을 얻어 두드러진 엔터티를 식별하거나(Gamon et al., 2013; Dojchinovski et al., 2016; Trani et al., 2018; Maddela et al., 2022) 프록시를 사용하여 얻었습니다. 예를 들어 (Dunietz and Gillick, 2014)는 두드러진 엔터티가 기사의 초록에 나타나는 엔터티라고 가정합니다. (Wu et al., 2020a) 엔터티에 해당하는 Wikinews 범주가 기사의 범주로도 레이블이 지정되어 있는 경우 엔터티를 두드러진 것으로 식별합니다. 이전 연구에서는 주로 수작업으로 만든 기능에 의존하여 주어진 엔터티의 두드러짐을 추론하는 기계 학습 방법을 제안했습니다. 대상 엔터티 언급과 문서에서만 계산할 수 있는 기능은 다음과 같이 분류할 수 있습니다.위치 기반(예: 엔터티가 초록에 있는 경우 문서 내 위치)(Dunietz and Gillick, 2014), 카운트 기반(예: 엔터티에 대한 참조 수)(Dunietz and Gillick, 2014; Wu et al., 2020a), 로컬 컨텍스트(Trani et al., 2018) 또는 글로벌 컨텍스트(Ponza et al., 2019). 또한 엔터티 그래프(예: 엔터티 그래프의 중심성)를 사용하여 기능을 생성하여 공동 엔터티 두드러짐 해결을 수행할 수 있습니다(Dunietz and Gillick, 2014; Trani et al., 2018). 마지막으로 과거 연구에서는 지식 기반의 엔터티에 대한 외부 지식을 통합하면 예측 성능이 향상될 수 있음을 보여주었습니다(Dojchinovski et al., 2016). 엔티티에 대한 두드러짐을 자동으로 추론하면 엔티티가 포함된 쿼리의 순위 결과를 개선(Xiong et al., 2018)하거나 공동 모델링을 통한 엔티티 감지 성능을 개선(Trani et al., 2018)하는 등 여러 다운스트림 애플리케이션에 직접적인 이점이 될 수 있습니다.또한 두드러짐을 추론함으로써 검색에서 두드러진 엔티티를 강조(Gamon et al., 2013), 두드러진 엔티티를 통해 뉴스 트렌드의 해석성을 개선(Ponza et al., 2021), 뉴스 기사의 엔티티 중심 요약을 작성하기 위한 엔티티 식별(Maddela et al., 2022; Hofmann-Coyle et al., 2022)과 같은 새로운 엔티티 중심 애플리케이션을 구축할 수 있습니다.3 문제 정의 (Gamon et al., 2013)에서 도입된 두드러짐의 개념을 사용합니다. 두드러진 엔티티는 텍스트 구조의 함수로서 객관적으로 중요한 문서에 명시적으로 언급된 엔티티입니다. 두드러짐 모델의 목표는 문서 D와 명시적 엔터티가 Me를 언급하는 것만 사용하여 엔터티 e에 대한 단일 두드러짐 점수 &amp;(e)를 생성하는 것입니다. 지식 기반의 엔터티에 대한 정보와 같은 외부 지식을 사용하는 것은 범위를 벗어나며 이러한 지식의 통합은 향후 작업으로 남겨둡니다. 4가지 방법 사전 학습된 언어 모델(PLM)은 매개변수에서 구문적 및 의미적 지식을 인코딩하는 놀라운 능력을 보여주었으며(Tenney et al., 2018, 2019), 다운스트림 자연어 이해(NLU) 작업에서 미세 조정 시 활용할 수 있습니다. PLM을 활용하여 대상 기반 문서 수준 NLU 작업인 엔터티 두드러짐 감지에 도움을 줄 수 있다고 가정합니다. 이 섹션에서는 엔터티 두드러짐 감지 작업에 맞게 조정된 교차 인코더 설정을 기반으로 하는 아키텍처를 제시합니다. 4.1 교차 인코더 인코딩 문서 D와 문서에 언급된 대상 엔터티 e가 주어지면, 특수 [SEP] 토큰을 사용하여 대상 엔터티의 이름과 문서를 연결합니다. 그런 다음 Transformer 기반 사전 학습된 인코더를 사용하여 텍스트를 인코딩합니다. 그림 2는 교차 인코더 모델의 그래픽 표현을 보여줍니다. 이 설정을 통해 모델은 대상 엔터티와 전체 문서 간에 깊은 교차 어텐션을 가질 수 있습니다. 문서 D에서 엔터티 e의 각 언급 mЄ Me 주위에 특수 마커 토큰 [BEGIN_ENTITY]와 [END_ENTITY]를 사용한다는 점에 유의하세요. 두드러짐 점수(e) [CLS]의 표현 FFNN [CLS], hpe] 인코딩된 데실 위치 Transformer [CLS] 대상 엔터티의 이름 [SEP] 문서의 텍스트 그림 2: 데실 위치 인코딩을 사용한 교차 인코더 아키텍처의 그래픽 표현. 위치 인코딩 문서 D에서 각 엔터티 언급(m Є Me)에 대한 데실수 위치를 계산하려면 문서가 10개의 동일한 청크로 분할된 경우 언급이 문서의 어느 부분에 속하는지를 나타내는 위치 인덱스 pm Є {0, 1, ..., 9}를 사용합니다. 언급의 수와 위치에 따라 벡터는 p 벡터에 0이 아닌 여러 값을 포함할 수 있습니다. 예를 들어 엔터티 e가 첫 번째 데실수에 1개, 두 번째 데실수에 2개, 다섯 번째 데실수에 1개 언급이 있는 경우 위치 인코더에 대한 입력은 pm [1, 1, 0, 0, 1, 0, 0, 0, 0]이 됩니다. 각 데실수에서 pm의 언급 수를 캡처하지 않는다는 점에 유의하세요. 위치 임베딩을 얻기 위해 위치 인덱스를 차원 dmodel의 밀집 벡터에 매핑하는 임베딩 계층을 사용합니다. 공식적으로는 hpe(m) 임베딩(pm)입니다. 점수 매기기 [CLS] 토큰의 출력 표현은 평균 위치 임베딩 벡터 hpe와 연결되어 엔티티 e에 대한 두드러짐 점수 &amp;(e) = [0, 1]을 생성하는 점수 매기기 모듈에 입력됩니다. 두드러짐 점수 매기기는 시그모이드 점수 매기기 함수 헤드가 있는 피드포워드 네트워크입니다. 형식적으로 = (e) = σ(FFN(h[CLS]||hpe)) 4.2 최적화 기준 진실 이진 두드러짐 레이블과 예측 두드러짐 점수 &amp;(e)를 사용하여 계산된 이진 교차 엔트로피 손실을 최소화하여 위에서 설명한 모델을 미세 조정합니다. 5 데이터 세트 이 섹션에서는 4개의 데이터 세트로 구성된 엔터티 두드러짐 벤치마크를 설명합니다.두 개의 데이터 세트 NYT-Salience WN-Salience SEL EntSUM # 문서 110,6, 문서 길이(평균 문자) 5,2,1,4,# 고유 엔터티 179,23,6,7,# 언급 4,405,145,19,729 20,% 두드러진 엔터티 14% 27% 10% 39% 실제 인간 추상 정렬 범주 정렬 인간 표 1: 실험에 사용된 데이터 세트에 대한 요약 통계 및 레이블 수집 방법.데이터 세트는 반자동화된 방법을 사용하여 큐레이션되었고 두 개의 인간 주석이 사용되었습니다.표 1에 이러한 데이터 세트와 레이블 수집 방법에 대한 요약 통계가 나와 있습니다.NYT-Salience 이 데이터 세트는 (Dunietz and Gillick, 2014)에서 소개되었으며 엔터티 두드러짐 감지를 위한 현재까지 가장 큰 데이터 세트입니다. 데이터 세트는 NYT Corpus(Sandhaus, 2008)의 뉴스 기사 초록에서 중요한 엔터티가 언급된다는 가정 하에 큐레이션되었습니다. 엔터티와 해당 언급은 POS 태그, 종속성 구문 분석 및 명사구 추출을 포함하는 기존 NLP 파이프라인을 사용하여 식별됩니다. 대규모임에도 불구하고 자동 데이터 세트 생성 프로세스는 데이터 하위 집합에 대한 인간 주석자와의 적당한 일치 수치로 입증된 대로 노이즈를 도입할 수 있습니다. 데이터 세트에는 각 엔터티에 대한 이진 중요도 레이블이 포함되어 있습니다. WN-Salience (Wu et al., 2020a)에 도입된 이 데이터 세트는 Wikinews 기사로 구성된 또 다른 자동 큐레이션 데이터 세트입니다. 여기에는 작성자가 Wikinews 범주로 주석을 달았습니다. WN-Salience는 엔터티에 해당하는 Wikinews 범주가 기사의 범주로 레이블이 지정된 경우 엔터티가 중요하다는 가설을 사용하여 중요한 엔터티를 식별합니다. NYT-Salience와 유사하게 이 데이터 세트에는 이진 중요도 레이블이 있습니다. SEL 이는 (Trani et al., 2018)이 공개한 Wikinews 기반의 또 다른 데이터 세트입니다. 그러나 WNSalience와 달리 이 데이터 세트는 여러 명의 인간 주석자가 엔터티의 두드러짐을 4가지 범주 중 하나로 순위를 매긴 인간 주석입니다. 다른 데이터 세트의 이진 레이블과 일치하도록 4가지 범주를 {0, 1}의 이진 레이블로 매핑합니다. 즉, 아래 두 클래스를 두드러지지 않음으로, 위 두 클래스를 두드러짐으로 매핑합니다. EntSUM 이 데이터 세트는 (Maddela et al., 2022)에 도입되었습니다. 이 데이터 세트를 구성하기 위해 NYT 코퍼스의 693개 기사 하위 집합에 걸쳐 무작위로 선택된 엔터티 집합에 인간 주석자가 [0,3] 사이의 4단계 척도로 두드러짐 레이블을 지정했습니다. 각 문서 엔터티 쌍에 대해 두 개의 독립적인 주석을 수집했으며, 의견이 일치하지 않는 경우 최대 5개까지 늘렸습니다. 엔터티의 평균 주석 점수가 1.5보다 크면 긍정적인 두드러짐 레이블이 지정됩니다. 5.1 추론된 언급을 통한 데이터 강화 EntSUM을 제외하고, 데이터 세트에는 많은 피처 기반 접근 방식과 위치 임베딩을 계산하는 데 필요한 주석으로 명시적인 엔터티 언급 오프셋이 없습니다.SEL에는 엔터티당 언급 표면 텍스트만 포함되어 있는 반면, NYT-Salience와 WN-Salience는 엔터티의 첫 번째 언급의 시작 및 끝 문자 인덱스(일명 언급 오프셋)만 제공합니다.이를 위해 Flair NER(Akbik et al., 2019)과 패턴 매칭을 결합하여 텍스트 내에서 엔터티의 추가 언급을 추론합니다.SEL의 경우 언급을 사용할 수 있으므로 패턴 매칭 접근 방식을 사용하여 언급의 표면 텍스트를 일치시켜 언급 오프셋을 추론합니다.NYT-Salience 및 WN-Salience의 경우 먼저 Flair NER를 사용하여 텍스트에서 명명된 엔터티의 언급을 식별합니다.이러한 언급을 해당 데이터 세트에 제공된 문서의 각 엔터티의 첫 번째 언급과 일치시키려고 시도합니다. 다른 언급의 표면 텍스트가 첫 번째 언급과 다를 수 있으므로 언급의 표면 텍스트와 엔터티 이름 사이의 중복을 해당 엔터티의 후보 언급으로 추가로 사용합니다.이 접근 방식을 적용하여 텍스트에서 엔터티의 추가 언급과 해당 오프셋을 추론합니다.이 프로세스는 약간의 노이즈를 유발할 수 있지만 이 프로세스를 통해 데이터 세트의 전반적인 품질이 향상됩니다.6 실험 제안된 PLM 기반 방법, 과거 연구에서 사용된 다른 ML 및 휴리스틱 기반 접근 방식, 그리고 명령어 조정 PLM을 사용하여 엔터티 두드러짐 벤치마크에서 실험합니다.6. 데이터 분할 이전 연구(Dunietz 및 Gillick, 2014; Trani et al., 2018; Wu et al., 2020a)는 일관되지 않은(또는 보고되지 않은) 학습/검증/테스트 분할을 사용합니다.NYTSalience 및 WN-Salience 데이터 세트는 학습/테스트 분할(검증 없음)과 함께 제공되는 반면 SEL 데이터 세트는 분할 없이 제공됩니다. 이로 인해 모델 간에 공정한 비교를 통해 이전 작업을 벤치마킹하기 어렵습니다. 이 문제를 극복하기 위해 NYT-Salience와 WN-Salience의 원래 학습 세트를 뉴스 기사의 발행 시간을 기준으로 새로운 학습/검증 세트로 시간적으로 분할하여 보다 현실적인 테스트 설정을 제공합니다(Huang 및 Paul, 2018; Rijhwani 및 Preotiuc-Pietro, 2020). 또한 SEL 및 EntSUM 데이터 세트를 학습/검증/테스트 세트로 시간적으로 분할합니다. 데이터 세트 분할에 대한 자세한 내용은 부록 A에 나와 있습니다. 6.2 기준선 먼저 과거 연구에서 사용된 모든 방법을 나열하고, 해당 방법에 대한 원래 논문의 결과를 보고합니다. • 첫 번째 문장. 문서 본문의 첫 번째 문장에 나타나는 경우 엔터티를 중요한 것으로 분류합니다. (Dunietz 및 Gillick, 2014)와 (Wu et al., 2020a) 모두에서 사용됩니다. • 위치 및 빈도(Dunietz 및 Gillick, 2014). 첫 번째 문장 인덱스와 엔터티의 빈도 특징을 로지스틱 회귀 모델에 공급합니다.• 모든 특징(Dunietz 및 Gillick, 2014). 로지스틱 회귀 모델에 공급된 위치, 빈도 및 PageRank 신호에 기반한 일련의 특징을 사용합니다.• SEL(Trani 등, 2018). sklearn에 구현된 Gradient Boosted Decision Tree 알고리즘에 공급된 위치, 빈도 및 Wikipedia 그래프 통계에 기반한 특징의 조합을 사용합니다(Pedregosa 등, 2011).• SWAT(Ponza 등, 2019). 위에서 설명한 SEL 방법과 유사한 특징 세트를 사용하지만 엔터티 임베딩에 기반한 특징이 추가되었습니다.모든 특징은 XGBoost에 구현된 Gradient Boosted Decision Tree 알고리즘에 공급됩니다(Chen 등, 2015). • 위치 특징(Wu et al., 2020a). 로지스틱 회귀 모델에서 엔터티가 언급된 첫 번째 문장의 인덱스를 특징으로 사용합니다. 이 방법은 (Wu et al., 2020a)의 WN Salience 데이터 세트에서 가장 좋은 결과를 제공합니다. 다음으로, 위의 기준선을 기반으로 하는 일반적인 방법 세트를 다시 구현하여 네 가지 데이터 세트 모두에서 테스트할 수 있도록 합니다. 이렇게 하면 평가가 동일한 실험 설정에서 수행되도록 할 수 있습니다. • 위치 헤드라인. 입력 문서의 헤드라인에 나타나는지 여부에 관계없이 엔터티를 두드러진 것으로 분류합니다. • 위치 헤드라인 및 리드. 문서의 헤드라인이나 문서의 첫 번째 문장(리드 문장)에 나타나는 경우 엔터티를 두드러진 것으로 분류합니다. • • 엔터티 빈도. 주어진 값보다 더 빈번한 경우 엔터티를 두드러진 것으로 분류합니다. 각 데이터 세트에 대해 다른 임계값을 계산하고 가장 좋은 결과를 보고했습니다. 임계값은 부록에서 찾을 수 있습니다. • 특징 및 GBDT. 이 방법은 과거 연구(Dunietz 및 Gillick, 2014; Wu et al., 2020a; Trani et al., 2018; Ponza et al., 2019)에서 가장 일반적인 특징, 즉 엔터티의 첫 번째 문장 인덱스와 엔터티 빈도를 사용하여 LightGBM(Ke et al., 2017)을 사용하여 구현된 GBDT 모델에 공급합니다.• SEL GBDT. (Trani et al., 2018)의 방법을 따르고 sklearn의 GBDT(Pedregosa et al., 2011)를 사용하여 SEL 데이터 세트와 함께 제공된 특징에 대한 모델을 학습합니다.• • • 대상 엔터티 마스킹. 이 방법은 특수 마스크 토큰을 통해 표현된 대상 엔터티 언급을 사용하여 Transformer 기반 인코더(ROBERTabase)에 입력을 공급합니다. 두드러짐 예측은 마스크 토큰 표현을 평균 풀링하고 이를 피드포워드 네트워크에 통과시켜 얻습니다. 제로샷 프롬프팅. 우리는 제로샷 프롬프팅을 사용하여 명령어 조정 LLM을 테스트합니다. 프롬프트는 작업 설명을 소개하고, 그 뒤에 입력 텍스트와 대상 엔터티가 나오고, 예/아니요 질문을 합니다. 그것은 모델이 &#39;예&#39; 또는 &#39;아니요&#39;를 답변으로 생성할 것으로 기대합니다. 이미 많은 NLU 작업 컬렉션에서 명령어 조정이 된 LLM은 프롬프트, 입력 텍스트, 대상 엔터티를 기반으로 답변을 제공하려고 시도합니다. 이 모델 패밀리는 여러 벤치마크에서 견고하고 다재다능한 것으로 입증되었습니다(Chung et al., 2022). 우리는 평가를 위해 Flan-UL2(20B)(Tay et al., 2023)와 LLaMa 2-Chat(7B)(Touvron et al., 2023)을 사용합니다. NYT-Salience WN-Salience 출처 Туре 방법 Р R FP RF(Dunietz and Gillick, 2014) 휴리스틱 첫 번째 문장 59.37.8 46.(Dunietz and Gillick, 2014) ML 위치 및 빈도 59.3 61.3 60.(Dunietz and Gillick, 2014) ML(Ponza et al., 2019) ML 모든 기능 SWAT 60.5 63.5 62.(Wu et al., 2020a) 휴리스틱 첫 번째 문장(Wu et al., 2020a) ML(Wu et al., 2020a) ML 기능 및 GBDT 휴리스틱 위치 헤드라인 휴리스틱 휴리스틱 구현 ML PLM(ROBERTA) PLM(ROBERTA) PLM(DeBERTa) 교차 인코더 모델 PLM(ROBERTA) 교차 인코더, 위치 삽입 가능.PLM(DeBERTA) 교차 인코더, 위치 삽입 가능. 위치적 특징 엔티티 빈도 특징 및 GBDT 대상 엔티티 마스킹 교차 인코더 62.4 66.0 64.56.0 41.0 47.3 47.9 53.2 50.19.0 41.3 26.0 29.39.2 59.7 47.3 29.2 48.1 36.57.5 42.0 48.5 46.1 51.5 48.49.8 55.4 52.5 41.0 60.0 48.53.7 53.3 53.6 37.3 61.9 46.61.0 57.4 59.2 46.64.6 50.2 56.5 57.0 65.4 60.75.9 87.1 81.1 71.8 73.6 72.77.5 87.4 82.1 71.5 78.3 74.78.7 84.2 81.4 71.2 76.7 73.75.9 88.4 81.7 73.3 76.1 74.표 2: NYT-Salience 및 WN-Salience 데이터 세트의 결과. 이러한 데이터 세트의 실제 값은 초록/범주 정렬을 통해 생성되었습니다. 상단 섹션은 원본 논문에서 원래 보고된 결과를 제시합니다. 78.9 42. 위치 헤드라인 및 리드 53.3 49. SEL 소스 Туре 방법 P (Trani et al., 2018) ML SEL (5-fold cross val. 포함) (Ponza et al., 2019) ML 휴리스틱 SWAT (5-fold cross val. 포함) 위치 헤드라인 R F50.0 61.0 52.58.0 64.9 61.Р EntSUM R F26.6 78.4 39.7 60.7 18.5 28. 휴리스틱 위치 헤드라인 및 리드 휴리스틱 엔터티 빈도 구현 ML ML 기능 및 GBDT SEL GBDT 22.13.5 57.8 21.9 48.4 54.0 51.26.6 78.4 39.7 60.7 52.0 56.87.1 35.3 51.2 31.6 39.PLM(ROBERTa) PLM(ROBERTA) 교차 인코더 PLM(DeBERTA) 교차 인코더 대상 엔터티 마스킹 모델 71.1 47.8 57.36.3 13.8 20.0 63.0 41.7 50.51.6 73.6 60.6 65.5 60.6 63.64.1 73.6 68.5 64.9 59.2 61.PLM(ROBERTa) 교차 인코더 위치 포함 emb. 63.0 69.9 66.3 67.5 57.0 61.PLM(DeBERTA) 교차 인코더 위치 포함 67.3 62.4 64.7 72.1 51.5 60.표 3: SEL 및 EntSUM 데이터 세트의 결과. 이러한 데이터 세트의 기준 진실은 인간 주석을 통해 생성되었습니다. 상단 섹션은 원본 논문에서 원래 보고된 결과를 보여줍니다. 6.3 실험 설정 우리는 ROBERTa-base(Liu et al., 2019) 및 DeBERTa-v3-base(He et al., 2023)를 실험을 위한 기본 PLM으로 사용합니다. 이러한 각 기본 모델에 대해 우리는 교차 인코더 모델과 데실 위치 임베딩으로 증강된 교차 인코더 모델을 모두 훈련합니다. 제안된 모델을 훈련하기 위해 우리는 AdamW(Loshchilov and Hutter, 2019)를 최적화 도구로 사용합니다. 우리는 다음 값 집합을 사용하여 학습률에 대한 하이퍼파라미터 검색을 수행합니다: {0.001, 0.0005, 0.0002, 0.0001, 0.00005}. 우리는 검증 세트 성능에 따라 조기 중단을 사용하여 최대 10개 에포크 동안 모델을 학습합니다. 우리는 검증 세트의 성능에 따라 각 데이터 세트에 대해 가장 성능이 좋은 모델 체크포인트를 선택합니다. 표 2와 3에서 우리는 엔티티 두드러짐에 대한 이전 연구에 따라 긍정(주목받는) 클래스에 대한 표준 분류 메트릭(예: 정밀도, 재현율 및 F1)을 사용하여 모델과 기준선의 성능을 보고합니다. 각 Transformer 기반 모델의 학습 및 추론을 위해 32GB GPU 메모리, 4개 CPU 및 128GB 주 메모리가 있는 단일 NVIDIA V100 GPU를 사용합니다. 6.4 결과 표 2와 3에서 섹션 5에서 설명한 4개 데이터 세트에 대한 베이스라인과 제안된 모델의 실험 결과를 제시합니다.특징 기반 방법과의 비교.교차 인코더 모델이 F1 점수에서 모든 베이스라인 모델보다 상당히 우수한 성능을 보이는 것을 관찰했습니다.또한 4개 데이터 세트 중 3개에서 베이스라인과 비교하여 더 나은 정밀도를 제공합니다.공개적으로 사용 가능한 사전 계산된 특징으로 학습된 SEL GBDT 모델이 교차 인코더보다 더 나은 정밀도의 모델을 생성하는 것은 SEL 데이터 세트에 대해서만입니다.교차 인코더로 데실 위치 임베딩을 추가하면 모든 데이터 세트에서 정밀도가 향상되지만 NYT-Salience를 제외한 모든 데이터 세트에서 재현율이 저하되는 것을 관찰했습니다.변환기 기반 모델로 맥락 정보를 활용하는 대상 엔터티 마스킹 접근 방식은 엇갈린 결과를 생성합니다. 전반적으로 이 모델은 SEL을 제외한 모든 데이터 세트에 대해 피처 기반 모델보다 더 나은 정밀도를 얻을 수 있지만, 이 모델은 모든 데이터 세트에서 리콜이 낮아 특히 크로스 인코더 모델과 비교할 때 F1 점수가 상당히 낮습니다. 위치 방법과 GBDT 방법에 대한 우리의 재구현은 이전 연구에서 보고된 성능과 일치합니다. 숫자의 분산은 추론된 언급이 있는 데이터 세트의 풍부함(섹션 5.1)과 실험에 사용된 명시적인 학습/개발/테스트 데이터 분할(섹션 6.1)에 기인할 수 있습니다. 6.5 대규모 언어 모델의 제로 샷 프롬핑 우리는 제로 샷 프롬핑을 사용한 두드러짐 감지 문제를 다음과 같이 공식화합니다. 엔터티 두드러짐 작업과 문서 텍스트의 정의가 주어지면 특정 엔터티가 두드러지는지 여부에 대해 &quot;예&quot; 또는 &quot;아니오&quot;를 생성하도록 모델에 요청합니다. 우리는 Hugging Face 1에서 사용 가능한 두 가지 오픈 소스 모델(Flan-UL2(20B) 및 LLaMa 2-Chat(7B))을 실험했으며, 그 결과를 표 4에 제시합니다. 저희가 아는 한, 이는 엔티티 두드러짐 감지 작업을 위한 명령어 조정 모델의 제로샷 프롬핑에 대한 첫 번째 평가입니다. 70억 개의 매개변수를 가진 LLaMa 2-Chat 모델은 모든 데이터 포인트에 대해 긍정적인 레이블만 생성하기 때문에 의미 있는 결과를 산출하지 못하는 것을 관찰했습니다(따라서 100% 리콜을 관찰했습니다). Flan-UL 모델은 긍정적인 레이블과 부정적인 레이블을 모두 생성할 수 있습니다. 그러나 데이터 세트 전체에서 정확도가 여전히 너무 낮습니다. 부록(섹션 C)에서 이러한 성능의 원인과 구현 세부 정보를 추가로 논의합니다. 전반적으로 이러한 ex&#39;www.huggingface.com 실험은 엔티티 두드러짐 감지가 이 두 모델이 명령어 조정된 다른 작업과 유사하지 않은 고유한 작업임을 시사합니다. 7 분석 이 섹션에서는 모델 동작에 대한 더 많은 통찰력을 얻고 추가 개선을 위한 잠재적인 방안을 이해하기 위해 모델 예측에 대한 분석을 수행합니다. 따라서 모든 엔터티 언급을 추론하는 것의 중요성, 첫 번째 엔터티 언급의 위치, 엔터티 언급 빈도를 포함한 다양한 요인에 따라 성능을 분류합니다.7.1 추론된 언급의 영향 섹션 5.1에서 NYT-Salience 및 WN-Salience 데이터 세트에 대한 엔터티의 추가 언급을 추론했습니다. 엔터티의 여러 언급을 활용하는 최상의 모델의 성능을 문서의 첫 번째 엔터티 언급만으로 학습된 버전과 비교합니다. 이 실험에 대한 구체적인 입력 형식은 부록 B에 나와 있습니다.표 5의 결과는 그렇게 하면 모든 데이터 세트에서 모델의 성능이 일관되게 향상됨을 보여줍니다.특히 가장 큰 데이터 세트인 NYT-Salience의 경우 모델은 27.3 F1 포인트라는 상당한 이득을 얻습니다. 이 실험은 추가 언급으로 데이터 세트를 증강하는 것의 중요성과 모든 엔터티 언급 주변에 존재하는 맥락적 정보를 명시적으로 모델링하는 것의 중요성을 보여줍니다.7.2 첫 번째 언급 위치에 대한 계층화 분석 우리는 이전 연구에서 사용된 가장 인기 있는 피처(Dunietz and Gillick, 2014; Wu et al., 2020a; Trani et al., 2018)에 의존하는 재구현된 기준선인 피처 및 GBDT 모델과 교차 인코더 모델을 비교합니다.표 2와 3의 결과에서 볼 수 있듯이, 다른 피처들 중에서 위치 피처가 두드러짐에 가장 많은 정보를 제공합니다.직감적으로, 엔터티가 헤드라인이나 뉴스 기사의 첫 번째 문장에 언급되면 해당 엔터티가 두드러질 가능성이 높습니다.그림 3은 첫 번째 언급이 문서의 헤드라인이나 첫 번째 문장에 있을 때 모든 모델이 좋은 성과를 보임을 보여줍니다. 우리는 크로스 인코더 모델이 지속적으로 Features &amp; GBDT 모델보다 우수한 성과를 보이고 있으며, 가장 큰 성과는 SEL 및 WN-Salience 데이터 세트에서 관찰된다는 것을 알았습니다. 이 관찰은 교차 인코더 모델이 FFE NYT-Salience WN-Salience SEL EntSUM 모델 PR FP R FР R FР R FCross-encoder(DeBERTa) 77.Flan-UL87.31.LLaMa 2-Chat 14.82.1 71.5 78.3 74.8 64.64.72.4 43.5 30.7 90.1 45.9 16.7 98.3 28.5 27.6 83.6 41.100.0 25.4 27.1 100.0 42.6 9.49 100.0 17.3 19.2 100.0 32.73.6 68.59.2 61임을 나타냅니다.표 4: 성능 비교 LLM의 제로 샷 프롬핑을 사용한 교차 인코더 모델. 모델 Р Р NYT-Salience WN-Salience R FR 첫 번째 언급이 있는 교차 인코더 54.2 57.5 55.8 69.6 80.67.0 69.1 53.2 60. 모든 언급이 있는 교차 인코더 77.5 87.4 82.1 71.5 78.3 74.8 64.1 73.6 68.5 64.9 59.2 61. SEL EntSUM FР R FР R F74.6 59.76. 표 5: 첫 번째 언급만 있는 교차 인코더 모델과 추론된 모든 언급이 있는 교차 인코더 모델의 성능 비교. F1 점수: 헤드라인 + 첫 문장에서 처음 언급됨 1.F1 점수: 최대 시퀀스 길이(512)에서 처음 언급됨 1.1.F1 점수: 최대 시퀀스 길이(512) 밖에서 처음 언급됨 1.00 1.00 1.0.60.84 0.0.83 0.0.84 0.0.80.0.0.0.72 0.0.E 0.82 0.0.76 0.0.0.0.0.0.60.62 0.0.0.E 방법 LightGBM DeBERTa DeBERTa+Decile 0.6 0.59 0.62 0.0.0.46 0.0.0.20.40.0.0.40.20.0.0.0.EntSUM SEL WN-Salience NYT-Salience EntSUM SEL WN-Salience NYT-Salience EntSUM SEL 데이터 집합 데이터 집합 데이터 집합 WN-Salience 0.00 0.00 0.NYT-Salience (a) 언급 위치와 관련된 성능. NYT의 컨텍스트 창 외부에 언급된 내용은 없습니다. F1 점수: 언급 빈도F1 점수: 언급 빈도 2-1.1.0.0.63 0.0.60.0.76 0.0.62 0.0.64 0.0.0.0.0.0.40.0.0.0.0.0.NYT-Salience 1.EntSUM SEL 데이터 세트 F1 점수: 언급 빈도 6-E 0.0.40.0.WN-Salience NYT-Salience 0.88 0.0.0.0.0.75 0.0.73 0.71 0.0.0.60.0.20.0.0.56 0.0.0.EntSUM SEL 데이터 세트 1.0.93 0.95 0.F1 점수: 언급 빈도 &gt;0.92 0.92 0.0.0.0.80.60.0.0.81 0.WN-Salience 0.0.0.0.0.NYT-Salience EntSUM SEL WN-Salience NYT-Salience EntSUM 0.00 0.00 0.SEL WN-Salience 데이터 집합 데이터 집합 방법 LightGBM DeBERTa DeBERTa+Decile (b) 엔터티의 빈도에 대한 성능. SEL 데이터 집합의 테스트 분할에는 문서에서 10개 이상 언급된 엔터티가 없습니다. 그림 3: 모델 및 데이터 집합에 대한 계층화 분석. 이 정보를 기능으로 명시적으로 사용하지 않고도 제목이나 문서의 첫 번째 부분에서 발생하는 언급이 종종 눈에 띄는지 식별하기 위해 컨텍스트를 사용할 수 있습니다. 또한 첫 번째 언급이 PLM의 컨텍스트 창 안이나 밖에 있을 때(여기서는 512개 토큰) 모델의 성능을 조사합니다. 언급이 컨텍스트 창 내부에 있는 경우, 교차 인코더 모델이 지속적으로 기능 및 GBDT 모델보다 우수한 성과를 거두는 것을 관찰했습니다. 언급이 컨텍스트 창 외부에 있는 경우, 모델 예측은 무작위에 가까워지는데, 이는 모델이 언급 주변에 즉각적인 컨텍스트 정보를 가지고 있지 않기 때문에 예상된 것입니다. 더 긴 입력을 처리할 수 있는 모델을 사용하는 것은 이러한 샘플의 개선을 위한 유망한 방향이 될 것입니다(Beltagy et al., 2020). 흥미롭게도, WN-Salience의 경우, 기능 및 GBDT 모델도 첫 번째 토큰 외부에서 상당히 더 나쁜 성과를 거두었습니다. 7.3 언급 빈도에 대한 계층 분석 언급 위치 분석과 유사하게, 우리는 우리의 교차 인코더 모델을 언급 빈도를 입력 기능 중 하나로 사용하는 기능 및 GBDT 모델과 비교합니다. 그림 3은 교차 인코더 모델과 기능 및 GBDT가 엔터티 언급의 다양한 빈도와 어떻게 비교되는지 보여줍니다. 단일 언급이 있는 두드러진 엔터티의 경우, 교차 인코더 모델이 기능 및 GBDT 모델보다 상당히 더 나은 성과를 거두었습니다. 특히, NYT-Salience 데이터 세트의 경우, Features &amp; GBDT 모델은 단일 언급 엔터티를 두드러지게 예측하지 못했습니다. 이 관찰 결과는 교차 인코더 모델이 단순히 언급 빈도를 모델링하는 것이 아니라, 단일 언급이 있는 엔터티의 두드러짐을 결정하기 위해 다른 맥락적 정보를 잠재적으로 활용한다는 것을 나타냅니다. Features &amp; GBDT 모델의 성능은 엔터티당 언급이 많을수록 향상됩니다. 사실, 엔터티당 6-10개의 언급 빈도 범위에서 Features &amp; GBDT 모델은 EntSUM 및 SEL 데이터 세트의 교차 인코더 모델보다 더 나은 성능을 보입니다. 이 관찰 결과는 두드러짐을 결정하기 위해 Features &amp; GBDT 모델이 언급 빈도에 지나치게 의존한다는 것을 나타내지만, 교차 인코더가 이 휴리스틱을 완전히 사용할 수 없다는 것도 나타냅니다. 8
--- CONCLUSION ---
이 논문은 사전 훈련된 언어 모델에 인코딩된 의미적 지식을 활용하여 엔티티 두드러짐을 감지하는 것을 목표로 합니다. 위치 표현을 사용한 Transformer 기반 PLM을 기반으로 하는 교차 인코더 방법을 제안하고, 4개의 서로 다른 데이터 세트(두 개는 인간이 주석을 달고 두 개는 자동으로 큐레이션)에서 여러 ML 기반 방법, 휴리스틱 방법 및 명령어 조정 LLM과 성능을 비교합니다. 모든 실험에서 사전 훈련된 언어 모델을 기반으로 하는 교차 인코더 모델은 다른 모든 방법보다 성능이 뛰어나며, 종종 F-1 점수에서 두 자릿수 이득을 얻습니다. 모델 동작 분석은 언급 빈도, 언급 위치 및 문서 길이가 성능에 미치는 중요한 영향을 보여주며, 향후 작업 영역을 강조합니다. 9 한계점 우리는 영어 문서에서만 두드러짐을 연구했지만, 대상 언어를 포함하는 사전 훈련된 언어 모델이 있는 한 다른 언어에도 직접 적용할 수 있습니다. 우리는 일부 방법에서 추론을 위해 데이터에 주석이 달린 엔티티 언급이나 엔티티 인식 및 엔티티 확인을 통해 추론된 엔티티 언급을 사용합니다. 이 정보는 모든 응용 프로그램에서 추론 시점에 사용할 수 없을 수 있습니다. LLM을 사용한 실험은 제로샷 프롬프트로 제한됩니다. 우리는 모델이 두드러짐 감지 작업을 학습하는 데 도움이 될 수 있는 명령어 튜닝을 실험하지 않았습니다. 마지막으로, 우리는 모델링에서 엔터티와 그 관계에 대한 외부 지식을 사용하지 않습니다. 이는 과거 연구에서 결과를 약간 개선하는 것으로 나타났습니다(Dunietz 및 Gillick, 2014; Trani et al., 2018; Ponza et al., 2019). 우리는 이것을 분석 범위에서 벗어나며 향후 작업의 실행 가능한 방향으로 간주합니다. 10 윤리 성명 우리는 엔터티 두드러짐 감지 작업을 위한 공개적으로 사용 가능한 데이터 세트를 사용합니다. 우리가 사용한 데이터 세트와 사전 학습된 모델은 연구 사용을 허용하는 허가된 라이선스를 가지고 있습니다. 우리는 이 논문에서 논의하는 작업과 관련된 잠재적 위험을 예상하지 않습니다. 참고문헌 Alan Akbik, Tanja Bergmann, Duncan Blythe, Kashif Rasul, Stefan Schweter, and Roland Vollgraf. 2019. FLAIR: 최첨단 NLP를 위한 사용하기 쉬운 프레임워크. NAACL 2019, 2019 북미 컴퓨터 언어학 협회 연례 컨퍼런스(데모), 54-59쪽. Zakariae Alami Merrouni, Bouchra Frikh, Brahim Ouhbi. 2020. 자동 키워드 추출: 조사 및 추세. Journal of Intelligent Information Systems, 54(2):391–424. Iz Beltagy, Matthew E. Peters, Arman Cohan. 2020. Longformer: 긴 문서 변환기. David M. Blei, Andrew Y. Ng, Michael I. Jordan. 2003. 잠재 디리클레 할당. J. Mach. Learn. Res., 3(null):993-1022. Tianqi Chen, Tong He, Michael Benesty, Vadim Khotilovich, Yuan Tang, Hyunsu Cho, Kailong Chen, et al. 2015. XGBoost: Extreme Gradient Boosting. R 패키지 버전 0.4-2, 1(4):1–4. Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models. arXiv 사전 인쇄본 arXiv:2210.11416. Leon Derczynski, Kalina Bontcheva, and Ian Roberts. 2016. Broad Twitter corpus: 다양한 명명된 엔터티 인식 리소스. COLING 2016의 회의록, 제26회 국제 계산 언어학 컨퍼런스: 기술 논문, 1169-1179쪽, 일본 오사카. COLING 2016 조직 위원회. Milan Dojchinovski, Dinesh Reddy, Tomáš Kliegr, Tomáš Vitvar, Harald Sack. 2016. 엔터티 샐리언스 주석이 있는 크라우드소싱 코퍼스. 제10회 국제 언어 자원 및 평가 컨퍼런스(LREC&#39;16)의 회의록, 3307-3311쪽, 슬로베니아 포르토로지. 유럽 언어 자원 협회(ELRA). Jesse Dunietz와 Daniel Gillick. 2014. 수백만 개의 학습 예제가 있는 새로운 엔터티 샐리언스 작업. 제14차 유럽 지부 회의록, 제2권: 단편 논문, 205-209쪽, 스웨덴 예테보리.Association for Computational Linguistics.Günes Erkan과 Dragomir R. Radev.2004.Lexrank: 텍스트 요약에서 두드러짐으로서의 그래프 기반 어휘 중심성.J. Artif.Int.Res., 22(1):457-479.Michael Gamon, Tae Yano, Xinying Song, Johnson Apacible, Patrick Pantel.2013.문서 관련성 이해 1단계: 두드러진 엔터티 식별.기술 보고서 MSR-TR-2013-73.Pengcheng He, Jianfeng Gao, Weizhu Chen. 2023. DeBERTav3: 그래디언트-분리된 임베딩 공유를 사용한 ELECTRA 스타일 사전 학습을 사용하여 deBERTa 개선. 제11회 학습 표현 국제 컨퍼런스. Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen Fürstenau, Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, Gerhard Weikum. 2011. 텍스트에서 명명된 엔터티의 강력한 모호성 해소. 2011년 자연어 처리 경험적 방법 컨퍼런스 회의록, 782-792쪽, 스코틀랜드 에든버러, 영국. 계산 언어학 협회. Ella Hofmann-Coyle, Mayank Kulkarni, Lingjue Xie, Mounica Maddela, Daniel Preotiuc-Pietro. 2022. 추출적 엔터티 중심 요약을 바이인코더를 사용한 문장 선택으로 사용. Association for Computational Linguistics의 아시아 태평양 지부 2차 회의록 및 자연어 처리에 관한 제12회 국제 공동 회의(제2권: 단편 논문), 326-333페이지, 온라인 전용. Association for Computational Linguistics. Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, Ralph Weischedel. 2006. OntoNotes: 90% 솔루션. NAACL의 인간 언어 기술 회의록, Companion Volume: 단편 논문, 57-60페이지, 미국 뉴욕시. Association for Computational Linguistics. Xiaolei Huang, Michael J. Paul. 2018. 문서 분류에서 시간성 조사. 56회 연례 총회 논문집(제2권: 단편 논문), 694-699쪽, 호주 멜버른. Association for Computational Linguistics. Anette Hulth. 2003. 언어적 지식이 더 많아졌을 때 자동 키워드 추출 개선. 2003년 자연어 처리 경험적 방법 컨퍼런스 논문집, 216-223쪽. Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, Tie-Yan Liu. 2017. Lightgbm: 고효율 그래디언트 부스팅 결정 트리. 신경 정보 처리 시스템의 발전, 30. Nikolaos Kolitsas, Octavian-Eugen Ganea, Thomas Hofmann. 2018. 종단 간 신경 엔티티 연결. 제22회 Computational Natural Language Learning 컨퍼런스 논문집, 519-529쪽, 벨기에 브뤼셀. Association for Computational Linguistics. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov. 2019. ROBERTa: 강력하게 최적화된 BERT 사전 학습 방법. arXiv 사전 인쇄본 arXiv:1907.11692. Ilya Loshchilov와 Frank Hutter. 2019. 분리된 가중치 감소 정규화. International Conference on Learning Representations. Mounica Maddela, Mayank Kulkarni, Daniel Preotiuc-Pietro. 2022. EntSUM: 엔티티 중심 추출 요약을 위한 데이터 세트. 제60회 연례 총회 의사록(제1권: 장문 논문), 3355-3366쪽, 아일랜드 더블린. Association for Computational Linguistics. Edgar Meij, Wouter Weerkamp, and Maarten de Rijke. 2012. 마이크로블로그 게시물에 의미론 추가. 제5회 ACM 국제 웹 검색 및 데이터 마이닝 컨퍼런스 의사록, WSDM &#39;12, 563-572쪽, 미국 뉴욕. Association for Computing Machinery. Rada Mihalcea and Paul Tarau. 2004. TextRank: 텍스트에 질서 부여. 2004년 자연어 처리 경험적 방법 컨퍼런스 의사록, 404-411쪽, 스페인 바르셀로나. Association for Computational Linguistics. Dat Ba Nguyen, Johannes Hoffart, Martin Theobald, and Gerhard Weikum. 2014. Aida-light: High-throughput named-entity disambiguation. 2014년 4월 8일, 한국 서울에서 열린 제23회 국제 월드 와이드 웹 컨퍼런스(WWW 2014)와 공동으로 개최된 웹의 연결 데이터 워크숍 회의록, CEUR 워크숍 회의록 1184권. CEURWS.org. F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Python에서의 머신 러닝. Journal of Machine Learning Research, 12:28252830. Marco Ponza, Diego Ceccarelli, Paolo Ferragina, Edgar Meij, Sambhav Kothari. 2021. 뉴스 기사에서 트렌드 엔터티의 맥락화. 웹 검색 및 데이터 마이닝에 대한 제14회 ACM 국제 컨퍼런스의 회의록, 346-354쪽. Marco Ponza, Paolo Ferragina, Francesco Piccinno. 2019. Swat: 텍스트에서 눈에 띄는 위키피디아 엔터티를 감지하는 시스템. Computational Intelligence, 35(4):858-890. Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Hwee Tou Ng, Anders Björkelund, Olga Uryupina, Yuchen Zhang, Zhi Zhong. 2013. OntoNotes를 사용한 강력한 언어 분석을 향해. 제17회 계산 자연어 학습 컨퍼런스의 회의록, 143-152페이지, 불가리아 소피아. 계산 언어학 협회. Shruti Rijhwani와 Daniel Preotiuc-Pietro. 2020. 명명된 엔터티 인식의 시간 정보 분석. 계산 언어학 협회의 제58회 연례 회의의 회의록, 7605-7617페이지, 온라인. 계산 언어학 협회. Evan Sandhaus. 2008. 뉴욕 타임스 주석 코퍼스. 필라델피아 언어 데이터 컨소시엄, 6(12):e26752. Benjamin Strauss, Bethany Toma, Alan Ritter, MarieCatherine De Marneffe, Wei Xu. 2016. w-nut 2016 명명된 엔터티 인식 공유 작업의 결과. 제2회 노이즈가 많은 사용자 생성 텍스트 워크숍(WNUT) 회의록, 138-144쪽. Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Jason Wei, Xuezhi Wang, Hyung Won Chung, Siamak Shakeri, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Denny Zhou, Neil Houlsby, Donald Metzler. 2023. U12: 언어 학습 패러다임 통합. Ian Tenney, Dipanjan Das, Ellie Pavlick. 2019. BERT가 고전적 NLP 파이프라인을 재발견. 제57회 컴퓨터 언어학 협회 연례 회의록, 4593-4601쪽, 이탈리아 피렌체. 컴퓨터 언어학 협회. Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R Thomas McCoy, Najoung Kim, Benjamin Van Durme, Samuel R Bowman, Dipanjan Das, et al. 2018. 문맥에서 무엇을 배울까요? 문맥화된 단어 표현에서 문장 구조를 탐색합니다. International Conference on Learning Representations에서. Erik F. Tjong Kim Sang 및 Fien De Meulder. 2003. CoNLL-2003 공유 과제 소개: 언어 독립적 명명된 엔터티 인식. HLT-NAACL 2003에서 열린 제7회 자연어 학습 컨퍼런스 회의록, 142-147쪽. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning 마오, 자비에 마르티네, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, 안젤라 팬(Angela Fan), 멜라니 캄바두르(Melanie Kambadur), 샤란 나랑(Sharan Narang), 아우렐리앙 로드리게스(Aurelien Rodriguez), 로버트 스토이닉(Robert Stojnic), 세르게이 에두노프(Sergey Edunov), 토마스 시알롬(Thomas Scialom). 2023. Llama 2: 개방형 기반 및 미세 조정된 채팅 모델. Salvatore Trani, Claudio Lucchese, Raffaele Perego, David E. Losada, Diego Ceccarelli 및 Salvatore Orlando. 2018. Sel: 핵심 엔터티 연결을 위한 통합 알고리즘. Computational Intelligence, 34(1):229. Chuan Wu, Evangelos Kanoulas, Maarten de Rijke, Wei Lu. 2020a. Wn-salience: 엔티티 샐리언스 주석이 있는 뉴스 기사 모음. 제12회 언어 자원 및 평가 컨퍼런스 회의록, 2095-2102쪽. Chuan Wu, Evangelos Kanoulas, Maarten de Rijke. 2020b. 엔티티 패싯 토픽 모델을 사용하여 엔티티 중심 문서 표현 학습. Inf. Process. Manage., 57(3). Chenyan Xiong, Zhengzhong Liu, Jamie Callan, Tie-Yan Liu. 2018. 커널 엔티티 샐리언스 모델링을 통한 더 나은 텍스트 이해 및 검색을 향해. 정보 검색 연구 및 개발에 관한 제41회 국제 ACM SIGIR 컨퍼런스, 575-584쪽. Lingyun Zhao, Lin Li, Xinhao Zheng, Jianwei Zhang. 2021. 온라인 금융 텍스트를 위한 bert 기반 감정 분석 및 주요 엔터티 감지 접근법. 2021년 IEEE 24회 컴퓨터 지원 협력 설계(CSCWD) 국제 컨퍼런스, 1233-1238페이지. IEEE. 부록 A 데이터 세트 분할 세부 정보 표 6에는 섹션 6.1에 설명된 시간 분할 전략을 적용한 후 각 데이터 세트의 학습, 개발 및 테스트 분할이 포함되어 있습니다. 이러한 분할은 모델 학습 및 평가에 사용됩니다. B 실험을 위한 입력 형식 섹션 4.1에 설명된 대로 대상 엔터티(즉, 모델이 두드러짐 레이블을 예측해야 하는 엔터티)가 언급될 때마다 특수 마커 토큰을 추가합니다. 다음에서 예를 제공합니다. 텍스트 Musk가 440억 달러 규모의 Twitter 거래를 완료했습니다. Elon Musk, 세계의 ... 모델 입력 [BE[CLS] Elon Musk [SEP] GIN_ENTITY] Musk [END_ENTITY]가 440억 달러 규모의 Twitter 거래를 완료했습니다.[BEGIN_ENTITY] Elon [END_ENTITY]가 세계의 ... Musk 섹션 7.1에서 보고한 첫 번째 언급에 대한 실험의 경우, 다음 예에서 볼 수 있듯이 첫 번째 언급만 특수 마커 토큰으로 제한됩니다.모델 입력 [CLS] Elon Musk [SEP] [BEGIN_ENTITY] Musk [END_ENTITY]가 440억 달러 규모의 Twitter 거래를 완료했습니다.Elon Musk, 세계의 ... Elon Musk에 대한 두 번째 언급은 마커 토큰으로 제한되지 않는다는 점에 유의하십시오.C LLM의 제로샷 프롬프팅 구현 세부 정보 그림 4와 그림 5는 각각 LLaMa 2-Chat(7B) 및 Flan-UL2(20B) 모델에 사용한 프롬프트를 보여줍니다.표 7에는 생성 매개변수가 나열되어 있습니다. 우리는 이 방법을 사용하여 얻은 비교적 낮은 정확도에 대해 다음과 같은 원인을 추측합니다. • 명령어는 두드러짐 작업 정의를 정의하지만 두드러짐 정의와 일치하도록 참조 예(few-shot prompting)를 제공하지 않습니다. 이로 인해 모델은 문서에서 빈도에 따라 엔터티를 두드러짐으로 식별합니다. 그러나 메모리 부족 문제를 방지하기 위해 프롬프트의 최대 입력 길이를 제한해야 하므로 few-shot prompt를 만드는 것은 어렵습니다. • 우리는 전체 프롬프트가 2048개 토큰 이하가 되도록 문서 텍스트를 잘라서 긴 문서의 끝 부분에 있는 잠재적인 정보를 모두 버립니다. <s>[INST] &lt;</s><SYS> <s>&gt; 엔티티의 두드러짐은 전체 문서 텍스트에 대한 해당 엔티티의 중요성 또는 중심성에 대한 정보를 제공합니다. 다음에서 엔티티와 텍스트가 주어졌을 때, 텍스트 문서가 해당 엔티티에 대한 것이면 &#39;예&#39;, 텍스트가 해당 엔티티에 대한 것이 아니면 &#39;아니요&#39;라고 답해야 합니다. «</s>
