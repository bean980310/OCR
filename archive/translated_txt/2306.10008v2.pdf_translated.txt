--- ABSTRACT ---
딥 러닝 기반 얼굴 인식 시스템의 성공은 디지털 세계에서 사용자를 무단으로 추적할 수 있는 능력으로 인해 심각한 개인 정보 보호 문제가 발생했습니다. 개인 정보 보호를 강화하기 위한 기존 방법은 사용자 경험을 손상시키지 않으면서 얼굴 개인 정보를 보호할 수 있는 &quot;자연스러운&quot; 이미지를 생성하지 못합니다. 우리는 사전 학습된 생성 모델의 저차원 매니폴드에서 적대적 잠재 코드를 찾는 것에 의존하는 얼굴 개인 정보 보호를 위한 새로운 2단계 접근 방식을 제안합니다. 첫 번째 단계는 주어진 얼굴 이미지를 잠재 공간으로 반전하고 생성 모델을 미세 조정하여 잠재 코드에서 주어진 이미지를 정확하게 재구성합니다. 이 단계는 좋은 초기화를 생성하여 주어진 신원과 유사한 고품질 얼굴의 제안된 대상을 생성하는 데 도움이 됩니다. 그런 다음 사용자 정의 메이크업 텍스트 프롬프트와 신원 보존 정규화를 사용하여 잠재 공간에서 적대적 코드를 검색합니다. 광범위한 실험 결과, 우리의 접근 방식으로 생성된 얼굴은 얼굴 검증 작업에서 최첨단 얼굴 프라이버시 보호 접근 방식보다 12.06%의 절대 이득을 보이며 더 강력한 블랙박스 전이성을 보입니다. 마지막으로, 우리는 제안된 접근 방식이 상업용 얼굴 인식 시스템에 효과적임을 보여줍니다. 우리의 코드는 https://github.com/fahadshamshad/Clip2Protect에서 제공됩니다. 1.
--- INTRODUCTION ---
영어: 딥 러닝 기반 얼굴 인식(FR) 시스템[43, 61]은 여러 응용 프로그램에서 널리 사용되고 있습니다(표 1). 자연스러운 출력, 블랙박스 설정, 얼굴 검증 및 식별 작업에서의 실험, 제한 없음(의미적으로 의미 있음) 및 보다 유연한 텍스트 유도 적대자에 관한 다양한 얼굴 프라이버시 보호 방법 간 비교.Adv-Makeup[71] TIP-IM[70] AMT-GAN[22] Ours 자연스러운 출력 예 부분적으로 부분적으로 예 블랙박스 예 예 예 예 검증 예 아니요 예 예 식별 아니요 예 아니요 예 제한 없음 텍스트 유도 예 아니요 예 예 아니요 아니요 아니요 예 보안[63], 생체 인식[38] 및 범죄 수사[45]를 포함하여 많은 시나리오에서 인간보다 우수한 성과를 거두었습니다[12, 48, 61]. 이 기술의 긍정적인 측면에도 불구하고 FR 시스템은 대량 감시 기능을 가능하게 할 수 있는 잠재력 때문에 디지털 세계에서 개인의 보안과 프라이버시를 심각하게 위협합니다[1,67]. 예를 들어, 정부 및 민간 기관은 FR 시스템을 사용하여 Twitter, Linkedin, Facebook과 같은 소셜 미디어 프로필에서 얼굴 이미지를 스크래핑하여 사용자 관계 및 활동을 추적할 수 있습니다[18,20]. 이러한 기관은 일반적으로 사양이 대중에게 알려지지 않은 독점적인 FR 시스템(블랙박스 모델)을 사용합니다. 따라서 이러한 알려지지 않은 FR 시스템으로부터 얼굴 프라이버시를 보호하는 효과적인 접근 방식에 대한 시급한 필요성이 있습니다. 이상적인 얼굴 프라이버시 보호 알고리즘은 자연스러움과 프라이버시 보호 간의 적절한 균형을 맞춰야 합니다[70, 77]. 이 맥락에서 &quot;자연스러움&quot;은 인간 관찰자가 쉽게 인지할 수 있는 노이즈 아티팩트가 없고 인간이 인지하는 신원이 보존되는 것으로 정의됩니다. &quot;프라이버시 보호&quot;는 보호된 이미지가 블랙박스 악성 FR 시스템을 속일 수 있어야 한다는 사실을 말합니다. 즉, 보호된 이미지는 주어진 얼굴 이미지와 매우 유사해야 하며 인간 관찰자에게는 아티팩트가 없어야 하지만 동시에 알려지지 않은 자동화된 FR 시스템을 속여야 합니다. 자연스러운 얼굴을 생성하지 못하면 소셜 미디어 플랫폼에서 사용자 경험에 상당한 영향을 미칠 수 있으므로 개인 정보 보호 향상 알고리즘을 채택하기 위한 필수 전제 조건입니다.최근 연구에서는 원래 얼굴 이미지에 노이즈 제약(경계)된 적대적 교란을 중첩하여 사용자의 신원을 숨기는 적대적 공격[57]을 활용합니다[6,53,74].적대적 예시는 일반적으로 이미지 공간에서 최적화되므로 자연스러움과 개인 정보 보호를 동시에 달성하기 어려운 경우가 많습니다[70].노이즈 기반 방법과 달리 제한 없는 적대적 예시는 이미지 공간의 교란 크기에 의해 제한되지 않으며 적대적으로 효과적인 동시에 인간 관찰자에게 더 나은 지각적 사실성을 보여주었습니다[3,55,68,76].FR 시스템을 오도하는 제한 없는 적대적 예시를 생성하기 위한 여러 가지 노력이 있었습니다(표 1 참조)[22,25,39,72]. 이 중에서 적대적 메이크업 기반 방법[22, 72]은 보다 자연스러운 방식으로 적대적 수정을 내장할 수 있기 때문에 점점 더 주목을 받고 있습니다.이러한 접근 방식은 생성적 적대 네트워크[15](GANS)를 사용하여 주어진 참조 이미지의 메이크업을 사용자의 얼굴 이미지로 적대적으로 전송하면서 대상 신원을 가장합니다.그러나 적대적 메이크업 전송을 기반으로 하는 기존 기술에는 다음과 같은 한계가 있습니다.(i) 이러한 방법의 적대적 독성은 메이크업 전송 모듈의 성능을 방해하여 메이크업 아티팩트가 있는 부자연스러운 얼굴을 생성합니다(그림 1 참조).(ii) 원하는 메이크업 스타일을 정의하기 위해 참조 이미지를 사용하면 이 접근 방식의 실용성에 영향을 미칩니다.(iii) 모든 새로운 대상 신원에 대해 이러한 접근 방식은 대규모 메이크업 데이터 세트를 사용하여 처음부터 종단 간 재교육이 필요합니다. 그리고 (iv) 이러한 방법의 대부분은 주로 대상 신원을 사칭하는 것을 목표로 하는 반면, 원하는 개인 정보 보호 목적은 회피입니다.즉, 다양한 소셜 미디어 사이트에서 스크래핑한 사용자 얼굴의 여러 이미지가 서로 일치하지 않아야 합니다.위의 문제를 완화하기 위해 온라인 플랫폼에서 사용자 얼굴 개인 정보를 보호하는 새로운 접근 방식을 제안합니다(3절).제안된 접근 방식은 얼굴 이미지를 생성하도록 훈련된 생성 모델이 학습한 저차원 매니폴드에서 적대적 잠재 코드를 검색하는 것을 목표로 합니다[2, 27].저희의 주요 기여는 다음과 같습니다.• 적대적 잠재 코드를 사용한 얼굴 개인 정보 보호 프레임워크: 얼굴 이미지가 주어지면 생성 모델(예: StyleGAN)이 적대적 잠재 코드를 검색하는 새로운 2단계 방법을 제안합니다.이 코드는 블랙박스 FR 시스템을 속이는 동시에 인간이 인식하는 신원과 일치하는 높은 시각적 품질의 얼굴 이미지를 생성하는 데 사용할 수 있습니다. • 텍스트 프롬프트를 사용한 적대적 메이크업 전송: 위 프레임워크의 중요한 구성 요소는 사용자 정의 텍스트(메이크업) 프롬프트를 활용하여 생성 모델의 잠재 매니폴드를 탐색하고 전송 가능한 적대적 잠재 코드를 찾는 기술입니다. 저희의 접근 방식은 대규모 메이크업 데이터 세트나 다른 대상 ID에 대한 모델 재교육 없이도 원하는 메이크업 스타일로 공격 정보를 효과적으로 숨깁니다. • ID 보존 정규화: 저희는 생성 모델의 잠재 공간 내에서 ID 관련 속성을 보존하고 보호된 얼굴 이미지가 시각적으로 원래 얼굴과 유사하도록 하는 정규화기를 제안합니다. 얼굴 검증 및 식별 시나리오에 대한 광범위한 실험(4.1절)은 블랙박스 FR 모델과 온라인 상용 얼굴 인식 API(4.2절)에 대한 저희 접근 방식의 효과를 보여줍니다. 또한 저희는 저희 접근 방식의 다양한 구성 요소의 성능을 분석하기 위해 자세한 절제 분석을 제공합니다(4.3절). 2.
--- RELATED WORK ---
난처
--- METHOD ---
s는 세 번째 행에 표시됩니다. 노란색 텍스트는 보호된 이미지를 오른쪽 하단에 표시된 대상 ID와 일치시킬 때 상용 API(Face++)에서 출력한 신뢰도 점수(높을수록 좋음)를 나타냅니다. [22]에서 메이크업 전송에 사용한 참조 이미지는 해당 적대적 이미지의 하단 모서리에 표시됩니다. 초록 딥 러닝 기반 얼굴 인식 시스템의 성공은 디지털 세계에서 사용자를 무단으로 추적할 수 있는 기능으로 인해 심각한 개인 정보 보호 문제가 발생했습니다. 개인 정보 보호를 강화하기 위한 기존 방법은 사용자 경험을 손상시키지 않고 얼굴 개인 정보를 보호할 수 있는 &quot;자연스러운&quot; 이미지를 생성하지 못합니다. 사전 학습된 생성 모델의 저차원 매니폴드에서 적대적 잠재 코드를 찾는 것에 의존하는 얼굴 개인 정보 보호를 위한 새로운 2단계 접근 방식을 제안합니다. 첫 번째 단계는 주어진 얼굴 이미지를 잠재 공간으로 반전하고 생성 모델을 미세 조정하여 잠재 코드에서 주어진 이미지를 정확하게 재구성합니다. 이 단계는 좋은 초기화를 생성하여 주어진 ID와 유사한 고품질 얼굴의 제안된 대상 생성을 돕습니다. 그 후, 사용자 정의 메이크업 텍스트 프롬프트와 신원 보존 정규화를 사용하여 잠재 공간에서 적대적 코드 검색을 안내합니다. 광범위한
--- EXPERIMENT ---
s는 우리의 접근 방식으로 생성된 얼굴이 얼굴 검증 작업에서 최첨단 얼굴 프라이버시 보호 접근 방식보다 12.06%의 절대 이득을 보이며 더 강력한 블랙박스 전이성을 가지고 있음을 보여줍니다. 마지막으로, 우리는 제안된 접근 방식이 상업용 얼굴 인식 시스템에 효과적임을 보여줍니다. 우리의 코드는 https://github.com/fahadshamshad/Clip2Protect에서 사용할 수 있습니다. 1. 서론 딥 러닝 기반 얼굴 인식(FR) 시스템[43, 61]은 여러 응용 프로그램에서 널리 사용되었습니다(표 1). 자연스러운 출력, 블랙박스 설정, 얼굴 검증 및 식별 작업에서의 실험, 제한 없음(의미적으로 의미 있음), 보다 유연한 텍스트 유도 적대자에 대한 다양한 얼굴 프라이버시 보호 방법 간의 비교. 영어: Adv-Makeup [71] TIP-IM [70] AMT-GAN [22] Ours Natural outputs Yes Partially Partially Yes Black box Yes Yes Yes Yes Verification Yes No Yes Yes Identification No Yes No Yes Unrestricted Text guide Yes No Yes Yes No No No Yes 보안[63], 생체 인식[38], 범죄 수사[45]를 포함하여 많은 시나리오에서 인간보다 우수한 성과를 보입니다[12, 48, 61]. 이 기술의 긍정적인 측면에도 불구하고 FR 시스템은 대량 감시 기능을 제공할 수 있는 잠재력 때문에 디지털 세계에서 개인의 보안과 프라이버시를 심각하게 위협합니다[1,67]. 예를 들어, 정부와 민간 기관은 FR 시스템을 사용하여 Twitter, Linkedin, Facebook과 같은 소셜 미디어 프로필에서 얼굴 이미지를 스크래핑하여 사용자 관계와 활동을 추적할 수 있습니다[18,20]. 이러한 기관은 일반적으로 사양이 대중에게 알려지지 않은 독점적인 FR 시스템(블랙박스 모델)을 사용합니다. 따라서 이러한 알려지지 않은 FR 시스템으로부터 얼굴 프라이버시를 보호하는 효과적인 접근 방식에 대한 시급한 필요성이 있습니다. 이상적인 얼굴 개인 정보 보호 알고리즘은 자연스러움과 개인 정보 보호 간의 적절한 균형을 맞춰야 합니다[70, 77]. 이 맥락에서 &quot;자연스러움&quot;은 인간 관찰자가 쉽게 인지할 수 있는 노이즈 아티팩트가 없고 인간이 인지하는 신원이 보존되는 것으로 정의됩니다. &quot;개인 정보 보호&quot;는 보호된 이미지가 블랙박스 악성 FR 시스템을 속일 수 있어야 한다는 사실을 말합니다. 즉, 보호된 이미지는 주어진 얼굴 이미지와 매우 유사해야 하며 인간 관찰자에게는 아티팩트가 없어야 하지만 동시에 알려지지 않은 자동화된 FR 시스템을 속일 수 있어야 합니다. 자연스러운 얼굴을 생성하지 못하면 소셜 미디어 플랫폼에서 사용자 경험에 상당한 영향을 미칠 수 있으므로 개인 정보 보호 향상 알고리즘을 채택하기 위한 필수 전제 조건입니다. 최근 연구에서는 적대적 공격[57]을 이용하여 원래 얼굴 이미지에 노이즈 제약(경계) 적대적 교란을 중첩하여 사용자 신원을 은폐합니다[6,53,74]. 적대적 예시는 일반적으로 이미지 공간에서 최적화되므로 자연스러움과 프라이버시를 동시에 달성하기 어려운 경우가 많습니다[70]. 노이즈 기반 방법과 달리 제한 없는 적대적 예시는 이미지 공간의 섭동 크기에 의해 제약을 받지 않으며 적대적으로 효과적이면서도 인간 관찰자에게 더 나은 지각적 사실성을 보여주었습니다[3,55,68,76]. FR 시스템을 오도하는 제한 없는 적대적 예시를 생성하기 위한 여러 가지 노력이 있었습니다(표 1 참조)[22,25,39,72]. 이 중에서 적대적 메이크업 기반 방법[22, 72]은 보다 자연스러운 방식으로 적대적 수정을 내장할 수 있기 때문에 점점 더 주목을 받고 있습니다. 이러한 접근 방식은 생성적 적대 네트워크[15](GANS)를 사용하여 대상 신원을 가장하면서 주어진 참조 이미지에서 사용자의 얼굴 이미지로 메이크업을 적대적으로 전송합니다. 그러나 적대적 메이크업 전송을 기반으로 하는 기존 기술은 다음과 같은 한계가 있습니다.(i) 이러한 방법의 적대적 독성은 메이크업 전송 모듈의 성능을 방해하여 메이크업 아티팩트가 있는 부자연스러운 얼굴을 생성합니다(그림 1 참조).(ii) 원하는 메이크업 스타일을 정의하기 위해 참조 이미지를 사용하면 이 접근 방식의 실용성에 영향을 미칩니다.(iii) 모든 새로운 대상 ID에 대해 이러한 접근 방식은 대규모 메이크업 데이터 세트를 사용하여 처음부터 종단 간 재교육이 필요합니다.(iv) 이러한 방법의 대부분은 주로 대상 ID의 사칭을 목표로 하는 반면, 원하는 개인 정보 보호 목표는 회피입니다.즉, 다양한 소셜 미디어 사이트에서 스크래핑한 사용자 얼굴의 여러 이미지가 서로 일치하지 않아야 합니다.위의 문제를 완화하기 위해 온라인 플랫폼에서 사용자 얼굴 개인 정보를 보호하는 새로운 접근 방식을 제안합니다(3절).제안된 접근 방식은 얼굴 이미지를 생성하도록 훈련된 생성 모델이 학습한 저차원 매니폴드에서 적대적 잠재 코드를 검색하는 것을 목표로 합니다[2, 27]. 우리의 주요 기여는 다음과 같습니다. • 적대적 잠재 코드를 사용한 얼굴 개인 정보 보호 프레임워크: 얼굴 이미지가 주어지면 생성 모델(예: StyleGAN)에서 적대적 잠재 코드를 검색하는 새로운 2단계 방법을 제안합니다. 이 적대적 잠재 코드는 블랙박스 FR 시스템을 속이는 동안 인간이 인식하는 신원과 일치하는 높은 시각적 품질의 얼굴 이미지를 생성하는 데 사용할 수 있습니다. • 텍스트 프롬프트를 사용한 적대적 메이크업 전송: 위 프레임워크의 중요한 구성 요소는 사용자 정의 텍스트(메이크업) 프롬프트를 활용하여 생성 모델의 잠재 매니폴드를 탐색하고 전송 가능한 적대적 잠재 코드를 찾는 기술입니다. 우리의 접근 방식은 대규모 메이크업 데이터 세트나 다른 대상 신원에 대한 모델 재교육이 필요 없이 원하는 메이크업 스타일에서 공격 정보를 효과적으로 숨깁니다. • 신원 보존 정규화: 생성 모델의 잠재 공간 내에서 신원 관련 속성을 보존하고 보호된 얼굴 이미지가 원래 얼굴과 시각적으로 유사하도록 하는 정규화기를 제안합니다. 영어: 얼굴 검증 및 식별 시나리오 모두에 대한 광범위한 실험(4.1절)은 블랙박스 FR 모델과 온라인 상용 얼굴 인식 API에 대한 우리 접근 방식의 효과를 입증합니다(4.2절). 나아가, 우리 접근 방식의 다양한 구성 요소의 성능을 분석하기 위해 자세한 생략적 분석을 제공합니다(4.3절). 2. 관련 연구 난독화 방법: 난독화는 사용자의 얼굴 프라이버시를 보호하는 데 가장 널리 사용되는 기술[38]입니다. 이전의 난독화 접근 방식은 일반적으로 마스킹[52, 64], 필터링[33, 78], 이미지 변환[8, 36, 62]과 같은 간단한 작업을 적용하여 원본 얼굴 이미지의 품질을 저하시킵니다. 이러한 비교적 간단한 난독화 기술은 감시 애플리케이션에는 적합하지만 사용자 경험이 중요한 온라인/소셜 미디어 플랫폼에는 적합하지 않습니다[41]. 심층 학습 기반 난독화 접근 방식은 보다 사실적인 이미지를 생성하지만[4,7,56,58], 종종 원본 이미지와 비교하여 신원이 변경되고 가끔 바람직하지 않은 아티팩트가 생성됩니다[30,31,34].노이즈 기반 적대적 예: 적대적 공격은 사용자를 무단 FR 모델로부터 보호하는 데 사용되었습니다.일부 방법[6,53]은 데이터 포이즈닝에 의존하여 대상 FR 모델을 속이지만, 종종 알 수 없는 FR 시스템의 훈련 데이터나 갤러리 세트에 액세스할 수 없기 때문에 덜 실용적입니다.다른 접근 방식은 화이트박스 설정에서 게임 이론 관점[42]이나 개인별 개인 정보 보호 마스크(사람당 마스크 하나)를 사용하여 동일한 사용자의 여러 이미지를 얻는 대가로 보호된 이미지를 생성했습니다[77].반대로, 우리는 단일 이미지만 사용하여 블랙박스 FR 모델을 속이는 것을 목표로 합니다.TIPIM[70]에서 대상 최적화를 사용하여 자연스러움 제약 조건을 도입하여 알 수 없는 FR 모델에 대한 개인 정보 보호 마스크를 생성했습니다. 이 접근 방식은 효과적인 프라이버시를 제공하지만 사용자 경험에 영향을 줄 수 있는 인지 가능한 노이즈가 있는 출력 이미지를 생성합니다[70].제한 없는 적대적 예: 제한 없는 적대적 공격(UAA)은 섭동 규범에 의해 제약을 받지 않으며 크지만 의미적으로 의미 있는 섭동을 유발할 수 있습니다.이러한 공격은 이미지 분류 문헌에서 광범위하게 연구되었으며[3,35,55,68,73,76] UAA를 통해 생성된 출력은 노이즈 기반 적대적 공격에 비해 인간 관찰자에게 인지하기 어렵다는 것이 밝혀졌습니다.이러한 관찰에 의해 동기를 부여받은 패치 기반 제한 없는 공격은 FR 모델을 속이기 위해 다채로운 안경[54], 모자[29] 또는 무작위 패치[69]와 같은 착용 가능한 적대적 액세서리를 생성하기 위해 제안되었지만 이러한 합성 패치는 일반적으로 제한된 편집 영역으로 인해 전달성이 약하고 큰 가시적 패턴은 자연스러움을 손상하고 사용자 경험에 영향을 미칩니다. 최근, 생성 모델[24, 50]이 FR 모델에 대한 UAA를 만드는 데 활용되었습니다. 그러나 이러한 생성적 접근 방식은 화이트박스 설정[46, 79]을 위해 설계되었거나 쿼리 없는 블랙박스 설정[25]에서 제한된 성능을 보입니다. 메이크업 기반 UAA[17, 72]도 자연스러운 메이크업 효과에 섭동을 임베드하여 FR 시스템에 대해 제안되었습니다. 이러한 메이크업 기반 공격은 사용자 얼굴 이미지에 적대적 메이크업을 적용하여 사용자 개인 정보를 보호하는 데에도 악용되었습니다[22]. 그러나 적대적 섭동과 메이크업 전송 간의 간섭은 출력 이미지에 바람직하지 않은 메이크업 아티팩트를 생성할 수 있습니다. 게다가 이러한 공격은 일반적으로 모델을 훈련하기 위해 대규모 메이크업 데이터 세트에 액세스할 수 있다고 가정하고 참조 메이크업 이미지가 필요합니다. 이와 대조적으로, 우리의 접근 방식은 메이크업 텍스트 프롬프트의 안내를 통해 블랙박스 설정에서 자연스러운 이미지 매니폴드에서 적대적 얼굴을 찾아 아티팩트에 덜 취약하고(그림 1 참조) 더 실용적입니다. 시각-언어 모델링: 최근 몇 년 동안 크로스 모달 시각 언어 모델링이 상당한 주목을 받았습니다[13]. OpenAI는 대조적 목적을 사용하여 4억 개의 이미지-텍스트 쌍에서 훈련되고 이미지와 텍스트를 공동 멀티모달 임베딩 공간에 매핑하는 CLIP[47]을 도입했습니다. CLIP의 강력한 표현 임베딩을 통해 텍스트 안내로 이미지를 조작하는 여러 방법이 제안되었습니다. StyleCLIP[44]과 DiffusionCLIP[28, 40]은 StyleGAN과 확산 모델의 강력한 생성 기능을 활용하여 텍스트 프롬프트로 이미지를 조작합니다. 이와 유사한 다른 작업으로는 HairCLIP[66], CLIP-NeRF[60], CLIPstyler[32], CLIPDraw[14]가 있습니다. 이러한 방법은 CLIP의 텍스트 안내 기능에 초점을 맞추는 반면, 우리의 접근 방식은 블랙박스 FR 모델에 대한 개인 정보 보호를 위해 생성 모델의 잠재 공간에서 적대적 잠재 코드를 찾는 것을 목표로 합니다. 3. 얼굴 개인 정보 보호를 위한 제안된 접근 방식 우리의 목표는 사용자의 온라인 경험을 손상시키지 않으면서 알려지지 않은(블랙박스) FR 모델로부터 온라인 플랫폼에서 사용자 얼굴 개인 정보를 보호하는 것입니다. 제안된 접근 방식은 자연스러운 얼굴 이미지로 훈련된 사전 훈련된 생성 모델의 저차원 잠재 공간을 적대적으로 탐색하여 보호된 얼굴을 찾습니다. 보호된 이미지에서 아티팩트를 피하기 위해 생성 모델에서 학습한 깨끗한 이미지 매니폴드에 가까운 적대적 얼굴에 대한 검색을 제한합니다. 게다가, 잠재 공간에서 신원 보존 잠재 코드에 대해서만 최적화할 것을 제안합니다. 이를 통해 자동화된 시스템에 대한 높은 개인 정보 보호를 제공하는 동시에 공격 중에 인간이 인식하는 신원을 효과적으로 보존합니다. 나아가, 텍스트 프롬프트의 안내를 통해 자연스러운 메이크업과 같은 섭동을 사용하여 참조 이미지 기반 적대적 메이크업 전송[22]에 비해 사용자에게 더 많은 유연성을 제공합니다. 3.1. 예비 사항 = x XCR은 주어진 원본/실제 얼굴 이미지를 나타냅니다. f(x) : X → Rd를 고정 길이의 정규화된 특징 표현을 추출하는 FR 모델이라고 하자.D(x1, x2) D(f(x1), f(x2))는 두 얼굴 이미지 x와 x2 사이의 차이점을 각각의 표현 f(x1)과 f(x2)를 기반으로 측정하는 거리 메트릭이다.일반적으로 FR 시스템은 검증과 식별의 두 가지 모드로 작동할 수 있다.얼굴 검증 잠재 코드 초기화 x ForwardWinv Winv Backward Frozen |Learned I 잠재 손실 L Ge 텍스트 기반 역 최적화 적대적 손실 Repel Attract tx Go (w) f G₁* (w) makeup Go⭑ 텍스트 손실 tmakeup EL ET 방향 손실 G₁= (w) 그림 2. 사용자의 얼굴 프라이버시를 보호하기 위해 제안된 접근 방식의 전체 파이프라인. 제안된 접근 방식은 생성 매니폴드에서 적대적 잠재 코드를 검색하여 개인 정보 보호를 위해 알려지지 않은 FR 시스템을 속일 수 있는 적대적 얼굴을 재구성합니다. 이 접근 방식은 사용자 정의 텍스트 프롬프트를 통해 적대적 방식으로 &quot;메이크업&quot; 편집을 허용하여 사용자의 온라인 경험을 향상시킵니다. 텍스트 기반 목적은 원래의 신원을 보존하면서 이러한 잠재 코드를 검색합니다. 시스템은 D(x1, x2) ≤ T인 경우 두 얼굴이 동일한 신원에 속한다고 예측합니다. 여기서 7은 시스템 임계값입니다. 반면 (폐쇄된 집합) 얼굴 식별 시스템은 입력 이미지(프로브)를 얼굴 이미지 집합(갤러리)과 비교하여 프로브와 가장 유사한 표현을 가진 신원을 출력합니다. 공격자는 블랙박스 FR 모델을 사용하여 사용자 신원을 확인하기 위해 검증 또는 식별을 사용할 수 있으므로 보호 접근 방식은 두 시나리오 모두에서 사용자의 신원을 숨겨야 합니다. 사칭 또는 공격을 회피하여 악의적인 FR 모델을 오도함으로써 사용자 개인 정보를 보호할 수 있습니다. 검증의 맥락에서, 사칭(거짓 일치)은 보호된 얼굴이 특정 대상 신원의 얼굴과 일치함을 의미하고, 회피(거짓 불일치)는 보호된 얼굴이 같은 사람의 다른 이미지와 일치하지 않음을 의미합니다.마찬가지로, 얼굴 식별의 경우, 사칭은 보호된 이미지가 갤러리 세트의 지정된 대상 신원과 일치하도록 보장하는 반면, 회피는 보호된 얼굴이 갤러리의 같은 사람의 이미지와 일치하지 않도록 방지합니다.문제 진술: 원래 얼굴 이미지 x가 주어졌을 때, 우리의 목표는 D(x, x)가 크고(성공적인 회피 공격의 경우) D(x, xt)가 작은(대상 얼굴 xt를 성공적으로 사칭하는 경우) 보호된 얼굴 이미지 xp를 생성하는 것입니다.여기서 0(x) = 0(x²)이고 O는 진정한 신원 레이블을 제공하는 오라클입니다.동시에, H(x, x)를 최소화하려고 합니다.여기서 H는 보호된 이미지 xp에 원래 이미지 x와 관련하여 도입된 비자연스러움의 정도를 정량화합니다. 형식적으로, 우리가 풀고자 하는 최적화 문제는 다음과 같습니다. min L(x) = D(x³, xt) - D(x³, x) xP st H(x², x) ≤ € (1) (a) 원본 (b) 인코더 반전 (c) 생성기 미세 조정 그림 3. 생성기 미세 조정을 통해 LFW 데이터 세트 샘플을 거의 완벽하게 재구성할 수 있습니다. 이는 사용자의 온라인 경험에 매우 중요합니다. Face++ API에서 반환된 일치 점수는 인코더 및 생성기 미세 조정 반전에 대해 각각 62.38 및 98.96입니다. 여기서 Є는 적대적 섭동에 대한 경계입니다. 노이즈 기반 접근 방식의 경우 H(x³, x) = || x - x³ ||p이고, 여기서 || · ||p는 Lp 규범을 나타냅니다. 그러나 섭동 제약 조건을 직접 적용하면 시각적 아티팩트가 발생하여 시각적 품질과 사용자 경험에 영향을 미칩니다. 효과적인 이미지 사전을 사용하여 솔루션 검색 공간을 자연스러운 이미지 매니폴드로 제한하면 더욱 사실적인 이미지를 생성할 수 있습니다. 거리 메트릭 D는 블랙박스 FR 시스템을 속이는 것이 목표이므로 알 수 없습니다.3.2. 메이크업 텍스트 기반 적대적 얼굴 우리의 접근 방식은 보호된 얼굴 P의 솔루션 공간을 깨끗한 얼굴 매니폴드 X에 가깝게 제한합니다.이 매니폴드는 실제 인간 얼굴에 대해 학습된 생성 모델을 사용하여 학습할 수 있습니다.특히, Go(w) : W→ R”이 가중치 0인 사전 학습된 생성 모델을 나타내며, 여기서 W는 잠재 공간입니다.제안하는 접근 방식은 (i) 잠재 코드 초기화(3.2.1절) 및 (ii) 텍스트 기반 적대적 최적화(3.2.2절)의 두 단계로 구성됩니다. 제안된 접근 방식의 전체 파이프라인은 그림 2에 나와 있습니다.3.2.1 잠재 코드 초기화 잠재 코드 초기화 단계는 GAN 역전을 기반으로 하며, 이는 원본 이미지 x를 잠재 공간 W로 역전하는 것을 목표로 합니다.즉, Go(winy)x인 잠재 코드 winy EW를 찾습니다.이를 달성하기 위해 먼저 e4e[59]라는 인코더 기반 역전을 사용하여 x에서 W의 winy를 추론합니다.즉, Winv = 16(x)입니다.여기서 I : X → W는 가중치가 있는 사전 학습된 인코더입니다(그림 2 참조).Xinv = 강력한 합성 능력과 잠재 공간의 풀린 구조로 인해 얼굴 이미지의 고해상도 데이터 세트에서 학습된 StyleGAN을 사전 학습된 생성 모델 Go로 사용합니다.역전 중의 중요한 과제는 원본 이미지의 동일성을 유지하는 것입니다.즉, O(x) O(inv). 일반적으로 최적화 및 인코더 기반 역전 접근 방식은 재구성 후 신원을 유지하는 데 어려움을 겪습니다[49](그림 3b 참조). 게다가 이러한 접근 방식을 사용할 때 역전 오류는 극단적인 포즈와 관점을 가진 도메인 외부 얼굴 이미지의 경우 클 수 있으며, 이는 소셜 미디어 애플리케이션에서 매우 일반적입니다. 따라서 이러한 접근 방식은 x를 역전하는 데 직접 적용할 수 없습니다. 대신 사전 학습된 생성기 가중치를 약간 변경해도 거의 완벽한 재구성을 달성하는 동시에 편집 기능에 해를 끼치지 않는다는 최근 관찰[49]에 동기를 부여받아 인코더 가중치 대신 사전 학습된 생성기 가중치 &amp;를 미세 조정합니다. 구체적으로 winv = 1(x)를 고정하고 다음 손실을 사용하여 Ge를 미세 조정합니다. 0* = arg min LLPIPS(x, Go(Winv)) + A2L2(x, Go(Winv)),&#39;inv 여기서 LLPIPS는 지각적 손실이고 L2는 픽셀별 유사도를 나타냅니다. 최종적인 역전된 이미지 xy(그림 3c 참조)는 미세 조정된 생성기, 즉 xv Go(Winv)를 통해 winv의 전방 패스를 수행하여 얻을 수 있습니다. 3.2.= 텍스트 기반 적대적 최적화 역전된 잠재 코드 winy와 미세 조정된 생성기 Go(.)가 주어졌을 때, 저희의 목표는 저차원 생성 다양체 W에서 이 잠재 코드 Winv를 적대적으로 교란하여 텍스트 프롬프트 tmakeup의 화장 스타일을 모방하면서 블랙박스 FR 모델을 속이는 보호된 얼굴을 생성하는 것입니다. 이러한 목표를 달성하기 위해 다음 질문을 조사합니다. (i) tmakeup에서 메이크업 스타일 정보를 효과적으로 추출하여 적대적 방식으로 얼굴 이미지 x에 적용하는 방법은?, (ii) 출력 얼굴 이미지가 질적으로 손상되지 않도록 최적화 프로세스를 정규화하는 방법은?, (iii) 블랙박스 FR 모델을 오도하는 효과적인 적대적 섭동을 만드는 방법은?, (iv) 높은 프라이버시를 보장하는 동시에 원래 얼굴 이미지의 인간이 인식하는 정체성 O(x)를 보존하는 방법은? 첫 번째 문제는 사전 학습된 시각 언어 모델의 임베딩 공간에서 출력 적대적 이미지를 텍스트 프롬프트 tmakeup과 정렬하여 해결할 수 있습니다. 두 번째 문제는 적대적 잠재 코드가 초기화 Winy에 가깝게 유지되도록 적용하여 해결합니다. 세 번째 문제는 화이트박스 대체 모델(또는 모델 앙상블)에서 이전 가능한 텍스트 가이드 적대적 얼굴을 제작하여 블랙박스 FR 모델에서 속이는 비율을 높이는 목표로 해결합니다. 마지막으로 생성 모델에서 잠재 공간의 풀린 특성을 활용하고 신원 보존 정규화를 통합하여 원래의 시각적 신원을 효과적으로 유지합니다. 이제 위의 아이디어를 통합하는 데 사용된 손실 함수의 세부 정보를 제시합니다. 텍스트 손실: 제안된 접근 방식의 핵심 요소는 메이크업 효과에 적대적 섭동을 눈에 띄지 않게 숨기기 위한 텍스트 기반 가이드입니다. 이는 사전 훈련된 시각 언어 모델(예: CLIP [47])의 공통 임베딩 공간에서 tmakeup과 적대적 얼굴 Go* (w)의 표현을 정렬하여 순진하게 달성할 수 있습니다. 그러나 이 접근 방식은 전체 출력 이미지를 tmakeup의 메이크업 스타일을 따르도록 변환하여 다양성이 낮아집니다. 따라서 원본 이미지와 적대적 이미지의 텍스트-이미지 쌍 사이의 CLIP 공간 방향을 맞추는 방향성 CLIP 손실을 사용합니다. 구체적으로, 여기서 AT = LclipΔΙ· ΔΤ |AI ||AT|&#39; ET(tmakeup) = (2) = ET(tsc)이고 AI E1(Go*(w)) – E1(x)입니다. 여기서 ET와 E는 CLIP 모델의 텍스트와 이미지 인코더이고 tsrc는 입력 이미지 x의 의미 텍스트입니다. 얼굴을 다루고 있으므로 tsrc를 간단히 &quot;얼굴&quot;로 설정할 수 있습니다. 이 손실은 프라이버시에 영향을 주지 않고 메이크업 전송(예: 빨간 립스틱)을 국소화합니다. 적대적 손실: 목표는 잠재 공간 W를 횡단하여 얼굴 특징 표현이 대상 이미지의 표현에 가깝고 원본 이미지 자체와는 멀리 있는 생성 매니폴드의 적대적 잠재 코드를 찾는 것입니다. 즉, D(x², x) &gt; D(x², xt). 따라서 적대적 손실은 Lady D(Go(w), x) - D(G₁*(w), x), (3) 여기서 D(x1, x2) 1 cos[f(x1), f(x2))]는 코사인 거리입니다. 악성 FR 모델은 블랙박스 설정에서 알려지지 않았으므로 Eq. 3을 직접 풀 수 없습니다. 대신 AMT-GAN[22]에 따라 화이트박스 대체 모델 앙상블에서 적대적 최적화를 수행하여 알려지지 않은 FR 모델의 결정 경계를 모방합니다. 동일성 유지 손실: 생성 매니폴드에 대한 최적화는 보호 이미지 P가 자연스러움, 즉 아티팩트가 없음을 보장하지만, 인간 관찰자와 관련하여 원본 이미지의 동일성을 보존하도록 보호 이미지를 명시적으로 적용하지는 않습니다. 이 문제를 완화하기 위해 StyleGAN이 잠재 공간에서 보여주는 의미 제어를 활용합니다. 잠재 코드 w Є W는 출력 이미지에서 다양한 수준의 의미를 제어하여 이미지 생성에 영향을 미칩니다. 구체적으로 StyleGAN의 초기 계층에 해당하는 잠재 코드는 포즈, 일반적인 헤어스타일, 얼굴 모양과 같은 상위 수준을 제어합니다[27]. 이러한 잠재 계층을 적대적으로 교란하면 이러한 속성이 변경되어 정체성이 변경될 수 있습니다(4.3절 참조). StyleGAN의 더 깊은 계층에 해당하는 잠재 코드는 메이크업 스타일과 같은 세부 수준의 제어와 연관됩니다[2]. 따라서 StyleGAN의 더 깊은 계층과 연관된 잠재 코드만 교란하여 적대적 얼굴을 정체성 보존 매니폴드로 제한합니다. 다음 정규화를 사용하여 잠재 코드가 초기 값 winy에 가깝게 유지되도록 추가로 제한합니다. Llatent = || (w mid) Winv mid)||2, (4) 여기서 는 요소별 곱을 나타내고 mid는 초기 계층의 경우 0이고 잠재 코드의 더 깊은 계층의 경우에만 0인 정체성 보존 마스크입니다. StyleGAN에는 18개의 레이어가 있으며, 각 레이어의 차원은 512입니다. 신원 보존 마스크는 레이어 8에서 18까지만 1로 설정됩니다. 마지막으로 세 가지 손실 함수를 결합하면 total = ady Lady + Aclip Lclip + latent Llatent, (5)가 됩니다. 여기서 adv., clip 및 latent는 하이퍼파라미터입니다. Lady는 Eq. 1에서 적대적 목적을 설명하는 반면, 텍스트 기반 메이크업 전송(clip) 및 신원 보존 정규화(latent)는 Eq. 1의 자연스러움 제약 조건을 암묵적으로 적용합니다. 4. 실험 구현 세부 정보: 모든 실험에서 FFHQ 얼굴 데이터 세트에서 사전 학습된 StyleGAN2를 생성 모델로 사용합니다. 적대적 텍스트 안내의 경우 비전 변환기 기반 CLIP 모델을 사용합니다. 잠재 코드 초기화 단계에서 생성기 미세 조정의 경우 Eq. 2의 값 2를 0.5로 설정하여 450회 반복을 사용합니다. 메이크업 텍스트 입력을 위해 다양한 성격의 메이크업 스타일을 기반으로 40개의 텍스트 프롬프트를 수집합니다(보충 자료 참조).적대적 최적화를 위해 B1과 B2를 각각 0.9와 0.999로 설정하고 학습률을 0.01로 설정한 Adam 옵티마이저를 사용합니다.보호된 얼굴을 만들기 위해 옵티마이저를 50번 반복 실행합니다.adv, Aclip, latent의 값을 각각 1, 0.5, 0.01로 설정합니다.모든 실험은 메모리가 40GB인 A100 GPU에서 수행합니다.데이터 집합: 얼굴 검증과 식별 설정에 대한 실험을 수행합니다.얼굴 검증: 사칭 공격에 CelebA-HQ[26]와 LADN[16]을 사용합니다.CelebA-HQ에서 1,000개 이미지의 하위 집합을 선택하고 [22]에서 제공한 4개의 대상 ID에 대한 평균 결과를 보고합니다. 마찬가지로 LADN의 경우 사용 가능한 332개 이미지를 4개 그룹으로 나누고, 각 그룹의 이미지는 [22]에서 제공한 대상 신원을 가장하는 것을 목표로 합니다.공격 회피의 경우 CelebA-HQ [26] 및 LFW [23] 데이터 세트를 사용합니다.특히, 무작위로 500명의 피험자를 선택하고 각 피험자는 얼굴 쌍을 갖습니다.얼굴 식별: 사칭 및 회피의 경우 CelebA-HQ [26] 및 LFW [23]를 평가 세트로 사용합니다.두 데이터 세트 모두 각각 얼굴 쌍을 가진 500명의 피험자를 무작위로 선택합니다.쌍 중 한 이미지를 갤러리 세트에 할당하고 다른 이미지를 프로브 세트에 할당합니다.사칭 및 회피 공격은 모두 프로브 세트에서 수행됩니다.사칭의 경우 [22]에서 제공한 4개의 대상 신원을 갤러리 세트에 삽입합니다.모든 데이터 세트와 사전 처리 단계에 대한 더 자세한 설명은 보충 자료에 제공됩니다. 대상 모델: 블랙박스 설정에서 다양한 백본을 가진 4개의 FR 모델을 공격하여 사용자 얼굴 개인 정보를 보호하는 것을 목표로 합니다. 대상 모델에는 IRSE50[21], IR152[9], FaceNet[51], MobileFace[5]가 포함됩니다. 표준 프로토콜에 따라 MTCNN[75]을 사용하여 얼굴 이미지를 정렬하고 자른 다음 FR 모델에 입력으로 제공합니다. 또한 Face++ 및 Tencent Yunshentu FR 플랫폼을 포함한 상용 FR API를 기반으로 개인 정보 보호 성능도 보고합니다. 평가 지표: [70]에 따라 보호 성공률(PSR)을 사용하여 제안된 접근 방식을 평가합니다. PSR은 악성 FR 시스템에 의해 잘못 분류된 보호 얼굴의 비율로 정의됩니다. PSR을 평가하기 위해 얼굴 검증 및 식별을 위해 각각 임계값 설정 및 폐쇄 세트 전략을 사용합니다. 얼굴 식별을 위해, 우리는 또한 순위 N 대상 신원 성공률(순위-NT)과 비대상 신원 성공률(순위-NU)을 사용합니다. 여기서 순위-NT는 대상 이미지 xt가 갤러리에서 선정된 상위 N 후보에 적어도 한 번 나타날 것임을 의미하고, 순위-NU는 상위 N 후보 목록이 원본 이미지 x와 동일한 신원을 갖지 않음을 의미합니다. 우리는 또한 방법의 인지 불가능성을 평가하기 위해 PSNR(dB), SSIM 및 FID[19] 점수의 결과를 보고합니다. 큰 PSNR 및 SSIM[65]은 원본 이미지와 더 잘 일치함을 나타내는 반면, 낮은 FID 점수는 더 사실적인 이미지를 나타냅니다. 상용 API의 경우, 우리는 각 서버에서 반환한 신뢰도 점수를 직접 보고합니다. 기준 방법: 우리는 우리의 접근 방식을 최근의 노이즈 기반 및 메이크업 기반 얼굴 프라이버시 보호 접근 방식과 비교합니다. 노이즈 기반 방법에는 PGD[37], MI-FGSM[10], TI-DIM[11] 및 TIP-IM[70]이 포함되는 반면, 메이크업 기반 접근 방식은 Adv-Makeup[71] 및 AMTGAN[22]입니다. 우리는 TIP-IM과 AMTGAN이 각각 노이즈 기반 및 제한 없는 설정에서 블랙박스 FR 시스템에 대한 얼굴 개인 정보 보호를 위한 최첨단(SOTA)으로 간주된다는 점을 강조하고 싶습니다. TIP-IM은 또한 여러 대상 중에서 최적의 대상 이미지를 찾기 위해 최적화에 다중 대상 목적을 통합합니다. 공정한 비교를 위해 단일 대상 변형을 사용합니다. 4.1. 실험 결과 이 섹션에서는 4가지 서로 다른 사전 학습된 블랙박스 설정에서 접근 방식의 실험 결과를 제시합니다. 표 2. 얼굴 검증 작업에서 블랙박스 사칭 공격의 보호 성공률(PSR %). 각 열에 대해 다른 세 가지 FR 시스템이 보호된 얼굴을 생성하는 대리자로 사용됩니다. 방법 CelebA-HQ LADN-데이터 세트 평균 IRSE50 IRFaceNet MobileFace IRSEIRFaceNet MobileFace Clean 7.3.1.12.2.3.0.5.4.Inverted 5.2.0.13.6.4.0.11.5.PGD [37] 36.20.1.43.40.19.3.41.25.MI-FGSM [10] 45.25.2.45.48.25.6.45.30.TI-DIM [11] 63.36.15.57.56.34.22.48.41.Adv-Makeup (IJCAI&#39;21) [71] 21.9.1.22.29.10.0.22.14.TIP-IMCCV&#39;21) [70] 54.37.40.48.65.43.63.46.50.AMT-GAN(CVPR 22) [22] 76.35.16.50.89.49.32.72.52.우리의 81.10 48.41.75.91.57 53.47.79.64.표 3. LFW 데이터 세트에 대한 얼굴 식별 작업에서 블랙박스 회피(위) 및 사칭(아래) 공격의 보호 성공률(PSR %) [23]. 각 열의 경우 다른 세 가지 FR 시스템이 대리자로 사용되어 보호된 얼굴을 생성합니다. R1-U: 순위 1-대상 없음, R5-U: 순위 5-대상 없음, R1-T: 순위 1-대상, R5-T: 순위 5-대상. 방법 IRSEIRFaceNet MobileFace 평균 R1-U R5-U R1-U R5-U R1-U R5-U R1-U R5-U R1-U R5-U MI-FGSM [10] 70.42.58.41.59.34.68.47.63.41.TI-DIM [11] 79.51.67.54.74.52.79.61.75.54.TIP-IM (ICCV&#39;21) [70] 81.52.71.54.76.49.82.63.77.54.우리의 86.59.73.56.83.51.85.66.82.58.R1-T R5-T R1-T R5-T R1-T R5-T R1-T R5-T R1-T R5-T MI-FGSM [10] 4.10.3.14.9.18.8.22.6.16.TI-DIM [11] 4.13.7.19.18.32.21.39.12.26.TIP-IM (ICCV&#39;21) [70] 8.28.11.31.25.56.34.51.19.41.우리의 11.37.16.51.27.54.39.61.23.51.방법 FID↓↓ PSR 이득 ↑ Adv-Makeup [71] 4.TIP-IM [70] AMT-GAN [22] 38.35.34.38.우리의 26.50.표 4. FID 비교. PSR Gain은 얼굴 검증 및 식별 작업에서 Adv-Makeup.FR 모델에 대한 PSR의 절대 이득입니다. 보호된 이미지를 생성하기 위해 세 개의 FR 모델을 대리모형으로 사용하여 네 번째 FR 모델의 결정 경계를 모방합니다. 모든 결과는 보충 자료에 제공된 5가지 텍스트 기반 메이크업 스타일을 통해 평균화됩니다. 얼굴 검증 실험의 경우 각 FR 모델에 대해 시스템 임계값을 0.01의 거짓 일치율로 설정했습니다. 즉, IRSE50(0.241), IR152(0.167), FaceNet(0.409), MobileFace(0.302)입니다. 얼굴 검증 작업에서 사칭 공격에 대한 PSR 측면의 정량적 결과는 표 2에 나와 있습니다. 우리의 접근 방식은 각각 SOTA 제한 없는[22] 및 노이즈 기반[70] 얼굴 프라이버시 보호 방법에 비해 약 12% 및 14%의 평균 절대 이득을 달성할 수 있습니다. 그림 1에 정성적 결과가 나와 있는데, 이는 우리의 접근 방식으로 생성된 보호된 얼굴이 더 현실적임을 보여줍니다. 얼굴 검증에서 공격을 회피한 결과는 보충 자료에 나와 있습니다. 표 3에서는 회피(대상이 지정되지 않음) 및 사칭 공격에 대한 얼굴 식별 작업에서 PSR 값도 제공합니다. 우리의 접근 방식은 랭크 1과 랭크 5 설정에서 모두 최근 방법보다 지속적으로 우수한 성과를 보입니다. 우리는 보다 실용적인 식별 설정에서 대상 지정되지 않은 개인 정보 보호(회피)를 제공하는 생성 모델의 효과를 보여준 최초의 사례라고 강조합니다. AMT-GAN과 Adv-Makeup은 원래 검증 작업에서 대상 신원을 사칭하도록 훈련되었으므로 표 3에 포함시키지 않았습니다. LFW와 CelebA에 대한 정성적 결과는 보충 자료에 나와 있습니다. 우리는 자연스러움을 측정하기 위해 CelebA와 LADN 데이터 세트에 대한 우리 접근 방식의 FID 점수(낮을수록 좋음)를 표 4에 보고합니다. Adv-Makeup은 얼굴의 나머지 부분을 변경하지 않고 눈 부위에만 메이크업을 적용하기 때문에 FID 점수가 가장 낮습니다. 그러나 이런 종류의 제한은 PSR이 낮습니다. 저희 방법은 TIP-IM 및 AMT-GAN에 비해 FID가 낮고 가장 높은 PSR을 달성합니다. 저희는 보충 자료에서 PSNR 및 SSIM 결과를 제공합니다. 4.2. 실제 응용 프로그램에서의 효과성 이제 검증 모드에서 작동하는 Face++ 및 Tencent Yunshentu FR 플랫폼과 같은 상업용 API에 대해 얼굴 이미지를 보호하는 저희 접근 방식의 효과성을 보여줍니다. 이러한 API는 두 이미지가 유사한지 여부를 측정하기 위해 0~100 사이의 신뢰도 점수를 반환하며, 높은 신뢰도 점수는 높은 유사성을 나타냅니다. 이러한 적절한 FR 모델의 훈련 데이터와 모델 매개변수가 알려지지 않았기 때문에 Clean Adv-Makeup PGD MI-FGSM TI-DIM TIP-IM AMT-GAN67.59.8 61.48.42.39.40 33.28.31.52.48.44.Proposed 65.2 67.73.27.Original w/o text guidance w text guidance CelebA-HQ LADN 데이터 세트 그림 4. 사칭 공격을 위해 실제 얼굴 확인 API인 Face++에서 반환한 평균 신뢰도 점수(높을수록 좋음). 우리의 접근 방식은 최첨단 메이크업 및 노이즈 기반 얼굴 프라이버시 보호 방법보다 신뢰도 점수가 더 높습니다.Alatent 표 5. FID 점수 및 PSR에 대한 latent의 영향. 0.5 0.1 0.05 0.01 0.005 0.FID 11.6 21.4 25.2 27.8 30.1 38.4 43.실제 시나리오를 효과적으로 모방합니다.기준선과 제안된 방법을 사용하여 CelebA-HQ에서 무작위로 선택한 얼굴을 보호합니다.그림 4에서 이러한 이미지에 대해 Face++가 반환한 평균 신뢰도 점수를 보여줍니다.이러한 결과는 우리 방법이 기준선에 비해 높은 PSR을 가지고 있음을 나타냅니다.Tencent Yunshentu API에 대한 자세한 내용과 결과는 보충 자료에서 설명합니다.4.3. 절제 연구 다음으로 손실 구성 요소의 기여도를 평가하기 위해 일부 절제를 보고합니다.메이크업 기반 텍스트 안내: 그림 5(위)에서 볼 수 있듯이 텍스트 안내가 없는 경우 결과 이미지에는 적대적 목적에 의해 유도된 섭동 증가로 인해 아티팩트가 포함될 수 있습니다. 텍스트 안내는 메이크업의 섭동을 효과적으로 숨겨 더 자연스럽게 보이는 이미지를 만들어냅니다. 또한 참조 이미지에 비해 사용자가 원하는 메이크업 스타일을 선택할 수 있는 유연성을 더 제공합니다. 신원 보존 정규화: 전체 잠재 공간에 대한 최적화는 더 많은 자유도를 제공하고 PSR을 증가시킵니다. 그러나 그림 5(아래)에 표시된 것처럼 사용자 신원을 보존하기 위한 적대적 최적화를 명시적으로 적용하지는 않습니다. 제안된 신원 보존 정규화는 원하는 메이크업 스타일을 모방하는 동시에 신원을 효과적으로 보존합니다. 잠재 손실 가중치의 영향: 잠재 손실 잠재에 할당된 가중치를 줄이면 FID 점수와 PSR이 모두 증가합니다(그 반대의 경우도 마찬가지). 잠재가 주어진 얼굴 이미지의 초기 역전된 잠재 코드에서 더 많이 벗어나도록 하면 종종 적대적 손실로 인해 아티팩트가 발생하여 자연스러움이 떨어지지만 프라이버시가 향상됩니다. 텍스트 변형에 대한 견고성. 마지막으로 PSR에 대한 다양한 텍스트 스타일의 영향을 평가합니다. 원본 w/o ID 정규화 w ID 정규화 그림 5. 위: 메이크업 기반 텍스트 안내가 출력 이미지의 시각적 품질에 미치는 영향. 출력 이미지는 얼굴 확인을 위해 대상 신원을 가장할 수 있습니다. 텍스트 프롬프트는 &quot;빨간 립스틱을 바른 태닝 메이크업&quot;입니다. 아래: 모든 잠재 코드에 대한 최적화는 보호된 이미지의 신원을 변경합니다. 신원 보존 정규화는 메이크업 효과의 교란을 숨기는 동시에 시각적 신원을 보존하는 잠재 코드를 검색하기 위해 적대적 최적화를 시행합니다. 표 6. PSR에 대한 다양한 텍스트 메이크업 스타일의 영향. 메이크업 스타일은 &quot;태닝&quot;, &quot;창백&quot;, &quot;분홍색 아이섀도&quot;, &quot;빨간 립스틱&quot; 및 &quot;매트&quot;입니다. 표준편차는 표준편차를 나타냅니다. 메이크업으로 메이크업으로 메이크업으로 메이크업 메이크업 메이크업 t¹ PSR 74.77.78.78.표준편차 79.2 1. 우리 방법을 사용하여 CelebA-HQ의 1000개 이미지를 보호하기 위해 텍스트 기반 메이크업 스타일 5개를 선택합니다. 표에 결과가 나와 있습니다. 6은 PSR이 다양한 메이크업 스타일에서 크게 변하지 않는다는 점(낮은 표준 편차)을 보여주는데, 이는 다양한 텍스트 기반 메이크업 스타일과 관련하여 우리 접근 방식이 견고하다는 것을 나타냅니다. 5.
--- CONCLUSION ---
우리는 사전 훈련된 생성 모델의 저차원 잠재 매니폴드에서 적대적 코드를 신중하게 검색하여 온라인 플랫폼에서 얼굴 이미지의 개인 정보를 보호하는 프레임워크를 제안했습니다. 우리는 메이크업 텍스트 유도 손실과 신원 보존 정규화를 통합하면 메이크업 스타일의 적대적 섭동을 효과적으로 숨기고 고품질의 이미지를 제공하며 인간이 인식하는 신원을 보존한다는 것을 보여주었습니다. 이 접근 방식은 사용자 정의 텍스트 프롬프트와 대상 신원에 강력하지만 텍스트 프롬프트와 대상 신원이 주어진 얼굴 이미지를 기반으로 자동으로 선택될 수 있다면 유익할 것입니다. 우리 방법의 한계에는 보호된 얼굴을 생성할 때 높은 계산 비용이 포함됩니다. 참고문헌 [1] Shane Ahern, Dean Eckles, Nathaniel S Good, Simon King, Mor Naaman, Rahul Nair. 과다 노출? 온라인 및 모바일 사진 공유에서의 개인 정보 패턴과 고려 사항. SIGCHI 컨퍼런스의 진행 사항, 컴퓨팅 시스템의 인간 요인, 357-366페이지, 2007.[2] Amit H Bermano, Rinon Gal, Yuval Alaluf, Ron Mokady, Yotam Nitzan, Omer Tov, Oren Patashnik, Daniel Cohen-Or. 스타일간의 아키텍처, 방법 및 응용 분야의 최신 기술. Computer Graphics Forum, 41권, 591-611페이지. Wiley Online Library, 2022. 2,[3] Anand Bhattad, Min Jin Chong, Kaizhao Liang, Bo Li, David A Forsyth. 의미 조작을 통한 제한 없는 적대적 예. arXiv 사전 인쇄본 arXiv:1904.06347, 2019. 2,[4] Jia-Wei Chen, Li-Ju Chen, Chia-Mu Yu, Chun-Shien Lu. Perceptual indistinguishability-net(pi-net): 조작 가능한 의미론을 사용한 얼굴 이미지 난독화. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 논문집, 6478-6487페이지, 2021.[5] Sheng Chen, Yang Liu, Xiang Gao, Zhen Han. Mobilefacenets: 모바일 기기에서 정확한 실시간 얼굴 검증을 위한 효율적인 CNN. 중국 생체 인식 컨퍼런스, 428-438페이지. Springer, 2018.[6] Valeriia Cherepanova, Micah Goldblum, Harrison Foley, Shiyuan Duan, John P Dickerson, Gavin Taylor, Tom Goldstein. Lowkey: 적대적 공격을 활용하여 소셜 미디어 사용자를 얼굴 인식으로부터 보호. International Conference on Learning Representations, 2020. 2,[7] William L Croft, Jörg-Rüdiger Sack, and Wei Shi. 생성적 적대적 네트워크를 통한 차별적 개인 정보 보호 얼굴 난독화. Future Generation Computer Systems, 129:358379, 2022.[8] Ali Dabouei, Sobhan Soleymani, Jeremy Dawson, and Nasser Nasrabadi. 빠른 기하학적으로 교란된 적대적 얼굴. 2019 IEEE Winter Conference on Applications of Computer Vision(WACV), 1979-1988쪽. IEEE, 2019.[9] Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos Zafeiriou. Arcface: 심층적 얼굴 인식을 위한 가산 각도 마진 손실. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스의 진행 사항, 4690-4699페이지, 2019.[10] Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu 및 Jianguo Li. 모멘텀을 통한 적대적 공격 강화. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스(CVPR&#39;18)의 진행 사항, 9185-9193페이지, 2018. 6,[11] Yinpeng Dong, Tianyu Pang, Hang Su 및 Jun Zhu. 변환 불변 공격을 통한 이전 가능한 적대적 사례에 대한 방어 회피. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스(CVPR&#39;19) 회의록, 4312-4321페이지, 2019. 6,[12] Hang Du, Hailin Shi, Dan Zeng, Xiao-Ping Zhang, Tao Mei. 종단 간 딥 얼굴 인식의 요소: 최근 진전 조사. ACM 컴퓨팅 설문 조사(CSUR), 54(10초): 1-42, 2022.[13] Yifan Du, Zikang Liu, Junyi Li, Wayne Xin Zhao. 시각 언어 사전 학습 모델 조사. arXiv 사전 인쇄본 arXiv:2202.10936, 2022.[14] Kevin Frans, Lisa B Soros, Olaf Witkowski. Clipdraw: 언어-이미지 인코더를 통한 텍스트-드로잉 합성 탐색. arXiv 사전 인쇄본 arXiv:2106.14843, 2021.[15] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron C. Courville, Yoshua Bengio. 생성적 적대적 네트워크. CoRR, abs/1406.2661, 2014.[16] Qiao Gu, Guanzhi Wang, Mang Tik Chiu, Yu-Wing Tai, Chi-Keung Tang. Ladn: 얼굴 화장 및 탈화장을 위한 로컬 적대적 풀림 네트워크. IEEE/CVF 컴퓨터 비전 국제 컨퍼런스 회의록, 10481-10490페이지, 2019.[17] Nitzan Guetta, Asaf Shabtai, Inderjeet Singh, Satoru Momiyama, Yuval Elovici. 신중하게 만든 천연 메이크업을 사용하여 공격을 피함. arXiv 사전 인쇄본 arXiv:2109.06467, 2021.[18] Rebecca Heilweil. 세계에서 가장 무서운 얼굴 인식 회사에 대한 설명. Vox, 2020년 5월 8일.[19] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Sepp Hochreiter. 두 시간 척도 업데이트 규칙으로 훈련된 Gans는 로컬 내쉬 균형으로 수렴함. 신경 정보 처리 시스템의 발전, 30, 2017.[20] Kashmir Hill. 우리가 아는 프라이버시를 종식시킬 수 있는 비밀스러운 회사. The New York Times, 18:2020, 2020.[21] Jie Hu, Li Shen, Gang Sun. Squeeze-and-excitation 네트워크. IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 7132-7141페이지, 2018.[22] Shengshan Hu, Xiaogeng Liu, Yechao Zhang, Minghui Li, Leo Yu Zhang, Hai Jin, Libing Wu. 얼굴 프라이버시 보호: 스타일이 강력한 메이크업 전송을 통해 적대적 신원 마스크 생성. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 15014-15023페이지, 2022. 1, 2, 3, 5, 6,[23] Gary B Huang, Marwan Mattar, Tamara Berg, Eric Learned-Miller. 야생에서 레이블이 지정된 얼굴: 제약 없는 환경에서 얼굴 인식을 연구하기 위한 데이터베이스. Workshop on faces in &#39;Real-Life&#39;Images: detection, alignment, and awareness, 2008. 6,[24] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. 조건부 적대적 네트워크를 사용한 이미지 간 변환. IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 1125–1134페이지, 2017.[25] Kazuya Kakizaki와 Kosuke Yoshida. 적대적 이미지 변환: 얼굴 인식 시스템의 제한 없는 적대적 사례. arXiv 사전 인쇄본 arXiv:1905.03421, 2019. 2,[26] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. 개선된 품질, 안정성 및 변형을 위한 gan의 점진적 성장. International Conference on Learning Representations, 2018.[27] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, Timo Aila. 스타일간의 이미지 품질 분석 및 개선. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 논문집, 8110-8119쪽, 2020. 2,[28] Gwanghyun Kim, Taesung Kwon, Jong Chul Ye. Diffusionclip: 강력한 이미지 조작을 위한 텍스트 유도 확산 모델. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 논문집, 2426-2435쪽, 2022.[29] Stepan Komkov와 Aleksandr Petiushko. Advhat: arcface 얼굴 ID 시스템에 대한 실제 적대적 공격. 2020년 제25회 국제 패턴 인식 컨퍼런스(ICPR), 819-826쪽. IEEE, 2021.[30] Zhenzhong Kuang, Zhiqiang Guo, Jinglong Fang, Jun Yu, Noboru Babaguchi, and Jianping Fan. 이미지 개인 정보 보호를 위한 눈에 띄지 않는 합성 얼굴 대체. Neurocomputing, 457:322-333, 2021.[31] Zhenzhong Kuang, Huigui Liu, Jun Yu, Aikui Tian, Lei Wang, Jianping Fan, and Noboru Babaguchi. 얼굴 익명화를 위한 효과적인 익명화 생성적 적대 네트워크. 제29회 ACM 국제 멀티미디어 컨퍼런스 논문집, 3182-3191쪽, 2021.[32] Gihyun Kwon, Jong Chul Ye. Clipstyler: 단일 텍스트 조건을 사용한 이미지 스타일 전송. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 18062-18071페이지, 2022.[33] Tao Li 및 Min Soo Choi. Deepblur: 자연스러운 이미지 난독화를 위한 간단하고 효과적인 방법. arXiv 사전 인쇄본 arXiv:2104.02655, 1, 2021.[34] Tao Li 및 Lei Lin. Anonymousnet: 측정 가능한 프라이버시를 갖춘 자연스러운 얼굴 익명화. IEEE/CVF 컴퓨터 비전 및 패턴 인식 워크숍 컨퍼런스 회의록, 0-0페이지, 2019.[35] Fangcheng Liu, Chao Zhang 및 Hongyang Zhang. 최소한의 변경으로 이전 가능한 제한 없는 적대적 사례를 향해. arXiv 사전 인쇄본 arXiv:2201.01102, 2022.[36] Suolan Liu, Lizhi Kong, Hongyuan Wang. 감시 비디오에서 개인 정보 보호를 위한 얼굴 감지 및 암호화. 중국 패턴 인식 및 컴퓨터 비전(PRCV) 컨퍼런스, 162-172쪽. Springer, 2018.[37] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu. 적대적 공격에 저항하는 딥 러닝 모델을 향해. 제6회 국제 학습 표현 컨퍼런스(ICLR&#39;18) 회의록, 2018. 6,[38] Blaž Meden, Peter Rot, Philipp Terhörst, Naser Damer, Arjan Kuijper, Walter J Scheirer, Arun Ross, Peter Peer, Vitomir Štruc. 개인 정보 보호 강화 얼굴 생체 인식: 포괄적 조사. IEEE Transactions on Information Forensics and Security, 2021. 2,[39] Dongbin Na, Sangwoo Ji, and Jong Kim. 제한된 쿼리를 사용하는 gan을 사용한 제한 없는 블랙박스 적대적 공격. arXiv 사전 인쇄본 arXiv:2208.11613, 2022.[40] Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen. Glide: 텍스트 유도 확산 모델을 사용한 사실적인 이미지 생성 및 편집을 향해. arXiv 사전 인쇄본 arXiv:2112.10741, 2021.[41] Seong Joon Oh, Rodrigo Benenson, Mario Fritz, and Bernt Schiele. 얼굴 없는 사람 인식: 소셜 미디어에서의 개인 정보 보호 의미. 유럽 컴퓨터 비전 컨퍼런스, 19-35쪽. Springer, 2016.[42] Seong Joon Oh, Mario Fritz, Bernt Schiele. 게임 이론 관점에서 프라이버시 보호를 위한 적대적 이미지 교란. 2017년 IEEE 국제 컴퓨터 비전 컨퍼런스(ICCV), 1491-1500페이지. IEEE, 2017.[43] Omkar M Parkhi, Andrea Vedaldi, Andrew Zisserman. 심층 얼굴 인식. 2015.[44] Or Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, Dani Lischinski. Styleclip: 스타일간 이미지의 텍스트 기반 조작. IEEE/CVF 국제 컴퓨터 비전 컨퍼런스 회의록, 2085-2094페이지, 2021.[45] P Jonathon Phillips, Amy N Yates, Ying Hu, Carina A Hahn, Eilidh Noyes, Kelsey Jackson, Jacqueline G Cavazos, Géraldine Jeckeln, Rajeev Ranjan, Swami Sankaranarayanan 외. 법의학 감정관, 초인식자 및 얼굴 인식 알고리즘의 얼굴 인식 정확도. 미국 과학 아카데미 회보, 115(24):6171-6176, 2018.[46] Omid Poursaeed, Tianxing Jiang, Harry Yang, Serge Belongie 및 Ser-Nam Lim. 생성적 적대적 훈련을 통한 견고성 및 일반화. IEEE/CVF 컴퓨터 비전 국제 회의 회보, 15711-15720페이지, 2021.[47] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark 등. 자연어 감독에서 이전 가능한 시각적 모델 학습. 기계 학습 국제 컨퍼런스, 8748-8763페이지. PMLR, 2021. 3,[48] Rajeev Ranjan, Swami Sankaranarayanan, Ankan Bansal, Navaneeth Bodla, Jun-Cheng Chen, Vishal M Patel, Carlos D Castillo, Rama Chellappa. 얼굴 이해를 위한 딥 러닝: 기계는 인간만큼 훌륭하거나 더 훌륭할 수 있습니다. IEEE Signal Processing Magazine, 35(1):66– 83, 2018.[49] Daniel Roich, Ron Mokady, Amit H Bermano, Daniel Cohen-Or. 실제 이미지의 잠재 기반 편집을 위한 피벗 튜닝. ACM Transactions on Graphics(TOG), 42(1):1–13, 2022.[50] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen. Gans 훈련을 위한 개선된 기술. 신경 정보 처리 시스템의 발전, 29, 2016.[51] Florian Schroff, Dmitry Kalenichenko, James Philbin. Facenet: 얼굴 인식 및 클러스터링을 위한 통합 임베딩. IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 815-823페이지, 2015.[52] Sachith Seneviratne, Nuran Kasthuriarachchi, Sanka Rasnayaka, Danula Hettiachchi, Ridwan Shariffdeen. 얼굴 마스크가 내 개인 정보를 보호합니까?: 마스크를 쓴 얼굴 이미지에서 보호된 속성을 예측하는 딥 러닝. Australasian Joint Conference on Artificial Intelligence, 91-102쪽. Springer, 2022.[53] Shawn Shan, Emily Wenger, Jiayun Zhang, Huiying Li, Haitao Zheng, Ben Y Zhao. Fawkes: Protecting privacy against unauthorized deep learning models. 제29회 USENIX 보안 심포지엄(USENIX Security 20), 1589-1604쪽, 2020. 2,[54] Mahmood Sharif, Sruti Bhagavatula, Lujo Bauer, Michael K Reiter. A general framework for adversarial examples with objectives. ACM Transactions on Privacy and Security(TOPS), 22(3):1-30, 2019.[55] Yang Song, Rui Shu, Nate Kushman, Stefano Ermon. Constructing unrestricted adversarial examples with generative models. 신경 정보 처리 시스템의 발전, 31, 2018. 2,[56] Qianru Sun, Liqian Ma, Seong Joon Oh, Luc Van Gool, Bernt Schiele, Mario Fritz. 머리 인페인팅을 통한 자연스럽고 효과적인 난독화. IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 5050-5059페이지, 2018.[57] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, Rob Fergus. 신경망의 흥미로운 속성. 국제 학습 표현 컨퍼런스, 2014.[58] Huan Tian, Tianqing Zhu, Wanlei Zhou. 얼굴 이미지의 공정성 및 개인 정보 보호: Gan 기반 방법. Computers &amp; Security, 122:102902, 2022.[59] Omer Tov, Yuval Alaluf, Yotam Nitzan, Or Patashnik, Daniel Cohen-Or. 스타일간 이미지 조작을 위한 인코더 설계. ACM Transactions on Graphics(TOG), 40(4):1-14, 2021.[60] Can Wang, Menglei Chai, Mingming He, Dongdong Chen, Jing Liao. Clip-nerf: 신경 광도장의 텍스트 및 이미지 구동 조작. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 3835-3844페이지, 2022.[61] Mei Wang 및 Weihong Deng. 심층 얼굴 인식: 조사. Neurocomputing, 429:215-244, 2021. 1,[62] Shunxin Wang, Una M Kelly, Raymond NJ Veldhuis. 얼굴 변형을 통한 성별 난독화. IEEE 생체 인식 및 법의학 국제 워크숍(IWBF), 1-6페이지. IEEE, 2021.[63] Ya Wang, Tianlong Bao, Chunhui Ding, Ming Zhu. 딥 러닝 방법을 사용한 실제 감시 비디오의 얼굴 인식. 2017년 제2회 이미지, 비전 및 컴퓨팅 국제 컨퍼런스(icivc), 239-243페이지. IEEE, 2017.[64] Yinggui Wang, Jian Liu, Man Luo, Le Yang, Li Wang. 주파수 영역에서 개인 정보를 보호하는 얼굴 인식. 2022.[65] Zhou Wang, Alan C Bovik, Hamid R Sheikh, Eero P Simoncelli. 이미지 품질 평가: 오류 가시성에서 구조적 유사성까지. IEEE 이미지 처리 거래, 13(4):600-612, 2004.[66] Tianyi Wei, Dongdong Chen, Wenbo Zhou, Jing Liao, Zhentao Tan, Lu Yuan, Weiming Zhang, Nenghai Yu. 헤어클립: 텍스트와 참조 이미지로 헤어 디자인. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 18072-18081페이지, 2022.[67] Emily Wenger, Shawn Shan, Haitao Zheng, Ben Y Zhao. Sok: 얼굴 인식 기술. arXiv 사전 인쇄본 arXiv:2112.04558, 2021.[68] Chaowei Xiao, Jun-Yan Zhu, Bo Li, Warren He, Mingyan Liu, Dawn Song. 공간적으로 변환된 적대적 예. arXiv 사전 인쇄본 arXiv:1801.02612, 2018. 2,[69] Zihao Xiao, Xianfeng Gao, Chilin Fu, Yinpeng Dong, Wei Gao, Xiaolu Zhang, Jun Zhou 및 Jun Zhu. 생성 모델을 사용하여 얼굴 인식에서 적대적 패치의 이전성 개선. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 11845-11854페이지, 2021.[70] Xiao Yang, Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu, Yuefeng Chen 및 Hui Xue. 적대적 신원 마스크 생성을 통한 얼굴 암호화를 향해. 2021 IEEE/CVF 컴퓨터 비전 국제 컨퍼런스(ICCV&#39;21)의 회의록, 3897-3907페이지, 2021. 1, 2, 3, 6,[71] Bangjie Yin, Wenxuan Wang, Taiping Yao, Junfeng Guo, Zelun Kong, Shouhong Ding, Jilin Li, Cong Liu. Advmakeup: 얼굴 인식에 대한 새로운 감지 불가능하고 이전 가능한 공격. 제30회 국제 인공지능 공동 컨퍼런스(IJCAI&#39;21)의 회의록, 1252-1258페이지, 2021. 2, 6,[72] Bangjie Yin, Wenxuan Wang, Taiping Yao, Junfeng Guo, Zelun Kong, Shouhong Ding, Jilin Li, Cong Liu. Advmakeup: 얼굴 인식에 대한 새로운 감지 불가능하고 이전 가능한 공격. arXiv 사전 인쇄본 arXiv:2105.03162, 2021. 2,[73] Shengming Yuan, Qilong Zhang, Lianli Gao, Yaya Cheng, Jingkuan Song. 자연스러운 색상 바보: 블랙박스 무제한 공격을 강화하기 위해. arXiv 사전 인쇄본 arXiv:2210.02041, 2022.[74] Jiaming Zhang, Jitao Sang, Xian Zhao, Xiaowen Huang, Yanfeng Sun, Yongli Hu. 적대적 개인 정보 보호 필터. 제28회 ACM 국제 멀티미디어 컨퍼런스 회의록, 1423-1431페이지, 2020.[75] Kaipeng Zhang, Zhanpeng Zhang, Zhifeng Li, Yu Qiao. 멀티태스크 계단식 합성곱 네트워크를 사용한 공동 얼굴 감지 및 정렬. IEEE 신호 처리 편지, 23(10):1499-1503, 2016.[76] Zhengyu Zhao, Zhuoran Liu, Martha Larson. 지각적 색상 거리를 가진 크지만 눈에 띄지 않는 적대적 이미지 교란에 대하여. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 1039-1048페이지, 2020. 2,[77] Yaoyao Zhong 및 Weihong Deng. Opom: 얼굴 개인 정보 보호를 위한 맞춤형 보이지 않는 망토. IEEE 패턴 분석 및 머신 인텔리전스 트랜잭션, 2022. 2,[78] Jizhe Zhou 및 Chi-Man Pun. 비디오 라이브 스트리밍에서 무관한 얼굴 추적 및 픽셀화를 통한 개인 정보 보호. IEEE 정보 포렌식 및 보안 트랜잭션, 16:1088-1103, 2020.[79] Zheng-An Zhu, Yun-Zhong Lu, Chen-Kuo Chiang. 얼굴 인식에 대한 메이크업 공격을 통한 적대적 사례 생성. 2019 IEEE 국제 이미지 처리 컨퍼런스(ICIP), 2516-2520쪽. IEEE, 2019.
