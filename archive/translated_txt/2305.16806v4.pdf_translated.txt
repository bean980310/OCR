--- ABSTRACT ---
GPT3와 같은 대규모 언어 모델(LLM)은 많은 자연어 생성 또는 이해 작업을 처리할 수 있는 범용 언어 모델로 등장했습니다. 기계 번역(MT) 작업에서 여러 연구에서 LLM에서 더 나은 번역을 이끌어내기 위한 few-shot prompting 메커니즘을 조사했습니다. 그러나 이러한 번역이 표준 신경망 기계 번역(NMT) 모델에서 생성된 번역과 질적으로 어떻게 다른지에 대한 조사는 비교적 적었습니다. 이 연구에서 우리는 두 시스템에서 생성된 번역의 문자적 의미 측면에서 이러한 차이점을 조사합니다. 단어 정렬 및 단조성을 포함하는 문자적 의미 측정을 사용하여 GPT에서 영어(EX)로 번역한 것은 문자적 의미가 덜한 반면 MT 품질 지표에서 비슷하거나 더 나은 점수를 보이는 경향이 있음을 발견했습니다. 우리는 이 발견이 인간 평가에서도 입증된다는 것을 보여줍니다. 그런 다음 이러한 차이점은 관용 표현이 포함된 문장을 번역할 때 특히 두드러진다는 것을 보여줍니다. 1
--- EXPERIMENT ---
아래의 모든 세부 사항. 데이터 세트 우리는 공식 WMT21 En-De, DeEn, En-Ru 및 Ru-En 뉴스 번역 테스트 세트를 사용합니다. 시스템 소스 이란 핵 협상에 시간이 촉박합니다. 독일은 이란 핵 협상에 시간이 촉박합니다. 독일은 MS라고 말합니다. GPT MS 천만에요. 잠시만 기다려 주세요. 번역 이란 핵 협상에 시간이 촉박하다고 독일이 말했습니다. 독일은 이란 핵 협상에 시간이 촉박하다고 말했습니다. 천만에요. 잠시만 기다려주세요. 자, 잠시만 기다려 주세요. GPT 천만에요. 잠시만 기다려 주세요. 표 2: WMT-22 En-De 테스트 세트의 MS-Translator(낮음) 및 text-davinci-003 번역(높음)에 대해 서로 다른 Non-Monotonicity(NM) 및 Unaligned Source Word(USW) 점수를 사용한 번역 예 삽화. 평가를 위해(Barrault et al., 2021). 품질 측정 우리는 번역의 유창성과 적절성을 정량화하기 위해 품질 추정(QE) 측정(Fomicheva et al., 2020)으로 COMET-QE1(Rei et al., 2020)를 사용합니다. QE를 측정 기준으로 사용하면 관련 서열 변환 작업에서 LLM 출력 품질을 추정하는 데 해로운 것으로 밝혀진 참조 편향의 존재를 배제한다는 이점이 있습니다(Goyal et al., 2022). 반면, 메트릭으로서의 COMETQE는 오류 복사에 대한 명백한 맹목(즉, 모델이 소스 언어로 출력을 생성하는 경우)으로 인해 어려움을 겪습니다(He et al., 2022). 이를 완화하기 위해 번역 출력에 언어 식별자(Joulin et al., 2017)를 적용하고 번역 언어가 소스 언어와 동일한 경우 번역을 null로 설정합니다. 따라서 이 메트릭의 이름을 COMET-QE + LID로 지정합니다. 번역 리터럴성 측정 번역 리터럴성을 정량화하는 데 적합한 높은 상관 관계를 갖는 알려진 측정 항목은 없습니다. 우리는 말뭉치 수준에서 두 가지 자동 측정을 제안하고 고려합니다. 1. 정렬되지 않은 원본 단어(USW): 유창성과 타당성이 매우 유사한 두 번역은 원본과 번역 사이의 단어 대 단어 정렬을 계산하여 문자 그대로의 측면에서 구별될 수 있습니다. , 정렬되지 않은 상태로 남아 있는 소스 단어의 수를 측정합니다. 품질을 제어할 때 문자 그대로의 번역이 적을수록 정렬되지 않은 원본 단어가 더 많이 포함될 가능성이 높습니다(그림 1에서 제안된 대로). 2. 번역 비단조성(NM): 문자성의 또 다른 척도는 번역이 원본의 단어 순서를 얼마나 밀접하게 추적하는지입니다. 우리는 Schioppa et al.에서 제안된 비단조성 측정법을 사용합니다. (2021)은 단어 대 단어 정렬의 대각선 편차를 비단조성 측정값으로 계산합니다. wmt20-comet-qe-da 이는 (정규화된) 정렬 교차로 해석될 수도 있으며, 이는 번역 비문자성과 상관관계가 있는 것으로 나타났습니다(Schaeffer and Carl, 2014). 우리는 다국어 BERT 기반 awesomealigner(Devlin et al., 2019; Dou and Neubig, 2021)를 사용하여 소스와 번역 간의 단어 간 정렬을 얻습니다. 표 2는 다양한 시스템에서 얻은 다양한 USW 및 NM 점수²를 사용한 번역을 보여줍니다. 평가 중인 시스템 우리는 다음 네 가지 시스템(NMT 및 LLM)을 실험합니다. 1. WMT-21-SOTA: Facebook 다국어 시스템(Tran et al., 2021)이 WMT-News 번역 작업(Barrault et al., 2021)에서 승리했습니다. ), 이는 WMT&#39;21 테스트 세트에서 가장 강력한 NMT 시스템을 나타냅니다. 2. 마이크로소프트 번역기: MS 번역기는 공개적으로 사용 가능한 가장 강력한 상용 NMT 시스템 중 하나입니다(Raunak et al., 2022). 3. text-davinci-002: text-davinci-002 모델은 GPT 계열의 명령어 미세 조정 모델입니다(Brown et al., 2020). 이는 공개적으로 접근 가능한 가장 강력한 LLM 중 하나를 나타냅니다(Liang et al., 2022). 4. text-davinci-003: text-davinci-003 모델은 많은 작업에 대해 text-davinci-002를 더욱 향상시킵니다³(Liang et al., 2022). 두 GPT 모델 모두에 대해 해당 WMT-21 개발 세트에서 무작위로 8개의 샘플을 선택하고 이를 GPT에서 모든 번역을 얻기 위한 데모로 프롬프트에 사용합니다. 결과 우리는 WMT-21 테스트 세트에서 네 가지 시스템의 성능을 비교했습니다. 그림 1은 이 비교 결과를 보여줍니다. 주요 관찰은 GPT 기반 번역이 언어 쌍(En-Ru 제외)에서 Microsoft 번역기보다 우수한 COMET-QE+LID 점수를 달성하는 반면 2가지 측정항목: https://github.com/vyraun/literalness 3LLM: https ://beta.openai.com/docs/models/ 번역 비단조성(NM) 정렬되지 않은 소스 단어 백분율(USW COMET-QE+LID 점수 (C-QE)MS-번역기 WMT-21-SOTA davinci-davinci-Tual EN-DE DE-EN MS-번역기 WMT-21-SOTA davinci-davinci-RU-EN WMT&#39;21 데이터 세트 EN-RU است EN-DE DE-EN WMT&#39;21 데이터 세트 MS-번역기 WMT-21-SOTA davinci-davinci-언어 쌍: En-De, En-Ru, En-Zh 및 De-En, Ru-En, Zh-En 각 언어 쌍에 대해 MS-Translator(강력한 상용 NMT 시스템) 및 텍스트에서 얻은 번역을 사용하여 100개의 소스-번역 쌍을 무작위로 샘플링합니다. -davinci-(강력한 상업용 LLM)(Hendy et al., 2023) 각 경우에 우리는 인간 주석자(Zh-En의 이중 언어 사용자, 대상 언어 원어민 및 이중 언어 사용자)에게 GPT와 MS-Translator의 100개 번역에 주석을 달고 두 번역 중 더 나은 번역을 선택하도록 요청합니다. 오자. 휴먼 주석 인터페이스는 부록 A에 설명되어 있습니다. 표 3의 결과는 주석 작성자가 GPT 번역을 덜 문자 그대로 평가한다는 것을 보여줍니다. Lang-Pair MS-번역기 Davinci-003 Equal Diff RU-EN EN-RU En-DeEn-ZhEn-RuDe-EnZh-EnRu-En++++++EN-DE DE-EN RU-EN WMT&#39;21 데이터 세트 EN -RU 그림 1: 측정: NMT 시스템과 GPT 모델은 유사한 COMET-QE+LID 점수를 달성했습니다(상단). 정렬되지 않은 소스 단어 수에 상당한 격차가 있습니다. (USW) 데이터 세트 전체(하단). 또한 GPT 번역은 EX 번역에 대해 더 높은 비단조성 점수를 얻습니다(중간). 또한 정렬되지 않은 소스 단어를 훨씬 더 많이 지속적으로 얻습니다. 이 결과는 WMT-21-SOTA와 GPT 시스템 간의 비교에도 적용됩니다. 또한 GPT 번역은 E→X 번역에 대해 일관되게 더 높은 비단조성을 보여줍니다. 그러나 영어로 번역하는 경우에는 그렇지 않습니다. 여기서 다국어 WMT-21-SOTA 시스템은 매우 가까운 비단조성 측정값을 얻습니다. 이러한 측정값을 결합하여 해석하면 GPT가 문자 그대로의 E→X 번역을 덜 생성한다는 것을 알 수 있습니다. 인간 평가
--- CONCLUSION ---
그림 1의 결과에서 6개의 WMT-표 3: 다양한 언어 쌍에 대한 인간 평가 결과에서 어느 것이 더 문자적인 번역인지에 대한 번역 문자성에 대한 인간 평가를 수행하여: 숫자는 MS-Translator와 Davinci-003에서 얻은 100개의 번역에 대한 주석에서 가져왔습니다.최고의 WMT-22 NMT 시스템에 대한 실험 나아가, 우리는 또한 WMT-22 일반 기계 번역 작업(Kocmi et al., 2022)에서 WMT-Best 시스템으로 실험했습니다.우리는 De-En, Ja-En, En-Zh 및 Zh-En에서 USW와 NM을 평가합니다.이러한 각 언어 쌍에서 text-davinci-003의 few-shot 성능은 Hendy et al.(2023)에서 수행된 평가를 기반으로 COMET-22(Rei et al., 2022)에 따른 WMT-Best 시스템의 성능과 매우 유사하기 때문입니다. 우리는 표 4에 결과를 보고하는데, 이는 우리의 이전 연구 결과가 언어 쌍 전체에서 반복되었음을 보여줍니다. 예를 들어, text-davinci-003은 이러한 언어 쌍에서 최상의 WMT 시스템보다 0.2~0.6 더 높은 COMET 점수를 얻었음에도 불구하고, 한 가지 비교(En-De의 NM)를 제외한 모든 비교에서 일관되게 더 높은 USW 점수와 더 높은 NM 점수를 얻었습니다. 중국어와 일본어의 NM 점수 차이는 문자 수준 정렬에서 측정된 정렬 편차로 인해 규모가 더 크다는 점에 유의하십시오. 또한, 우리는 독자들에게 text-davinci-003과 MS-Translator의 번역에 대한 유사한 USW 및 NM 비교를 위해 Hendy et al. (2023)을 참조할 것을 권장합니다. 언어 쌍 USW Diff NM Diff + 4.+ 12.En-Zh De-En +1.-0.Zh-En + 4.+ 13.Ja-En + 6.+11.표 4: WMT-22 테스트 세트에서 WMT-Best에 대한 text-davinci003의 USW 및 NM 점수 차이.MT 시스템 C-QE↑ USW↓↓ NM↓ MS-Translator 21.13.70 9.WMT&#39;21 SOTA 23.text-davinci-23.14.47 10.18.08 11.표 5: 자연스러운 관용적 문장: MAGPIE, EPIE, PIE(5,712개 문장)에 대한 결합 결과.3 비유적 구성성에 대한 효과 이 섹션에서는 GPT 모델에서 생성된 E→X 번역의 덜 문자적인 특성을 활용하여 특정 입력에 대해 더 높은 품질의 번역을 생성할 수 있는지 살펴봅니다. 우리는 관용어의 비구성적 의미(Dankers et al., 2022a)를 문장 내의 구성적 구성 요소의 의미로 구성하는 현상을 비유적 구성성으로 가정합니다. 따라서 더 큰 비유적 구성성을 보이는 모델은 소스 문장의 관용적 표현의 의미를 추상화하고 관용어 의미의 비문자적(의역) 표현을 통해 또는 대상 언어의 동등한 관용어를 통해 비문자적으로 대상 언어로 표현할 수 있습니다. 더 큰 비문자적성이 더 나은 비유적 구성성을 의미하지 않는다는 점에 유의하세요. 번역의 비문자적성은 잠재적으로 원하는 비유적 번역과 다른 번역의 변형으로 인해 생성될 수 있습니다. 3. 관용어 데이터 세트를 사용한 번역 이 섹션에서는 기존 NMT 시스템과 GPT 모델 간의 관용어가 있는 문장 번역의 차이점을 정량화합니다. 관용어가 있는 문장에 전념하는 영어 중심의 병렬 코퍼스는 없습니다. 따라서 우리는 관용어가 있는 단일 언어(영어) 문장을 실험합니다. 번역은 섹션 2에서 동일한 프롬프트로 생성됩니다. 자연스러운 관용어 문장이 있는 데이터 세트는 아래와 같습니다. • MAGPIE(Haagsma et al., 2020)에는 관용어성이 주석된 문장 세트가 포함되어 있습니다. • 신뢰도 점수와 함께. 우리는 퍼센트 주석자 신뢰도로 관용어로 표시된 뉴스 도메인과 관련된 문장(총 3,666개 문장)을 사용합니다. EPIE(Saxena and Paul, 2020)에는 관용어와 그 사용법을 보여주는 예문 문장이 포함되어 있습니다. 우리는 정적 관용어에 사용 가능한 문장(총 1,046개 문장)을 사용합니다. • PIE 데이터 세트(Zhou et al., 2021)에는 관용어와 그 사용법이 포함되어 있습니다. 우리는 코퍼스에서 1,000개 문장을 무작위로 샘플링합니다. 결과 결과는 표 5에 제시되어 있습니다. text-davinci-002는 WMT&#39;21 SOTA 시스템보다 더 나은 품질의 번역을 생성하며, 정렬되지 않은 단어의 수가 더 많고 비단조성이 더 높습니다. 추가 분석 번역 품질의 향상을 특히 관용어의 더 나은 번역에 직접적으로 기인하는 것은 어렵습니다. 또한 COMETQE와 같은 유사성 기반 품질 지표 자체가 BLEU 또는 ChrF와 같은 표면 수준 지표보다 그럴 가능성이 낮음에도 불구하고 비문자적 표현에 페널티를 줄 수 있습니다(Papineni et al., 2002b; Popović, 2015). 따라서 자연 단일 언어 데이터 세트는 비유적 구성성 능력을 조사하는 데 유용한 테스트베드를 제공하지만 시스템 간의 비유적 구성성을 명시적으로 비교하는 것은 매우 어렵습니다. 따라서 입력 문장의 세분화된 속성을 명시적으로 제어하는 합성 데이터에 대한 실험도 수행합니다. 우리는 합성 데이터 생성에서 입력 문장들 간의 대부분의 변화를 특정 구성 표현에 할당함으로써 이를 수행합니다. 3.2 합성 실험 다음 실험을 위해 우리는 각각 특정 유형의 표현을 포함하는 합성 영어 문장을 생성합니다: (i) 이름, (ii) 무작위 설명 문구, (iii) 관용구. 우리는 text-davinci002에 제로샷 방식으로 프롬프트를 보내 이러한 각 유형의 다른 인스턴스화를 사용하여 문장을 생성하도록 요청합니다(자세한 내용은 부록 B에 있음). 그런 다음 우리는 이러한 문장을 다른 시스템을 사용하여 번역하여 시스템 간 및 유형 간 문자적 측정 기준에 대한 상대적 효과를 조사합니다. 각 통제 실험에서 우리는 합성 영어 문장을 독일어로 번역합니다. 표현 C-QE 무작위 구문 -2.명명된 개체 관용구 -1.+5.USW↓ NM↓ +1.62 +0.+0.81 +0.+2.82 +1.표 6: 관용구를 포함한 합성 문장 대 다른 표현을 포함한 합성 문장: GPT(text-davinci-002) 성능과 NMT 성능(Microsoft Translator)의 차이를 보고합니다.합성 데이터 세트 1 설명한 대로, 우리는 세 가지 유형의 표현, 즉 명명된 개체(예: Jessica Alba), 무작위 설명 구문(예: 접시 위의 큰 케이크) 및 관용구(예: a shot in the dark)를 포함하는 문장을 생성합니다. 표현 소스와 추가 데이터 생성 세부 정보는 부록 B에 나와 있습니다. 결과는 표 6에 나와 있습니다. 관용어 수 USW17.58 18.39 18.28 18.표 7: 여러 관용어가 있는 합성 문장(1-4): 관용어의 수를 늘리면 text-davinci-002 번역에서 정렬되지 않은 소스 단어의 수가 늘어납니다. 합성 데이터 세트 2 여러 관용어(1~4)가 포함된 문장을 생성합니다. 프롬프트와 예는 부록 B에 나와 있습니다. 결과는 표 7에 나와 있습니다. 결과 표 6은 관용어의 경우 정렬되지 않은 소스 단어의 비율이 가장 높고, 그 다음으로 무작위 설명적 문구 및 명명된 엔터티가 뒤따릅니다. 이 결과는 탐색된 GPT 모델이 덜 문자적인 E→X 번역을 생성한다는 가설과 일치합니다. 왜냐하면 문장의 명명된 엔터티나 설명적 문구는 관용어가 있는 문장과 달리 더 문자적인 번역을 허용할 것이기 때문입니다. Davinci-002는 관용어가 있는 문장의 번역에서 훨씬 더 높은 COMET-QE 점수를 얻지만 정렬되지 않은 소스 단어의 비율이 더 높습니다. 마찬가지로 관용어의 경우 비단조성 점수의 차이도 상당히 높습니다. 이러한 결과는 GPT 모델의 개선된 결과와 더 낮은 문자적 숫자가 관용어 표현의 올바른 번역에서 비롯된다는 증거를 제공합니다. 표 7은 이 효과가 관용어의 수에 따라 증가한다는 것을 보여줍니다. 4 논의 다양한 NMT 시스템과 GPT 모델에서 수행한 실험에서 GPT가 일반적으로 E→X에 대해 더 큰 문자적 의미를 갖는 번역을 생성한다는 증거를 발견했습니다. 이에 대한 잠재적 원인이 여러 가지 있을 수 있습니다. 아래에 두 가지 가능한 가설을 나열합니다. 병렬 데이터 편향 NMT 모델은 종종 매우 문자적인 웹 수집 출력을 포함하는 병렬 데이터에서 학습됩니다. 이 중 일부는 이전 세대 MT 시스템의 출력일 수도 있는데, 이는 널리 채택되고 감지하기 어렵습니다. 또한 병렬 데이터의 고품질 대상 텍스트조차도 항상 원래 해당 언어로 작성된 텍스트와 구별되는 아티팩트, 즉 &#39;번역어&#39; 효과(Gellerstam, 2005)를 포함합니다. 이러한 요소는 NMT 번역을 비교적 더 문자 그대로 만드는 데 기여할 가능성이 있습니다. 언어 모델링 편향 GPT의 번역 기능은 사전 훈련 단계에서 작업에 대한 명확한 감독이 없는 경우 발생합니다. 따라서 GPT가 번역을 생성하는 데 활용하는 계산 메커니즘은 NMT 모델과 다를 수 있으며, 더 큰 추상화 능력을 부여할 수 있습니다. 이는 생성된 번역에서 측정 가능한 징후가 있을 수 있습니다(예: 번역의 문자 그대로). E→X와 X→E의 차이 E→X에서 유사한 품질의 GPT 번역이 덜 문자 그대로이고 X→E 방향에서 몇 가지 이상 현상이 관찰됩니다. 그림 1의 X→E의 경우, 한 가지 비교(De-En의 WMT-21-SOTA 대 GPT)를 제외한 모든 비교에서 GPT는 비문자성에 대해 더 높은 측정값을 얻습니다. 반면, E→X 방향의 추세에는 이상치가 나타나지 않았습니다. 실험 설정의 변화 불용어에 대한 정렬을 사용하지 않는 USW와 NM의 변형도 실험했습니다. 각각의 결과는 동일하게 유지되었으며, 크기는 비교적 미미했지만 시스템 순위에는 변화가 없었습니다. 마찬가지로, 다양한 NMT 시스템에서 비교했을 때, few-shot 및 zero-shot 설정 모두에서 GPT 번역에서 문자성이 낮아지는 경향이 더 컸습니다. 5 요약 및 결론 우리는 GPT 패밀리의 LLM을 통해 얻은 번역이 번역 문자성의 속성을 정량화하여 질적으로 어떻게 다른지 조사했습니다. E→X 번역의 경우 GPT 번역에서 문자성이 낮아지는 경향이 더 크다는 것을 발견했습니다. 특히, 이러한 경향은 GPT 시스템이 관용어를 비유적으로 번역하는 능력에서 분명해진다.6 감사의 말 인간 평가를 수행하는 데 도움을 준 Hitokazu Matsushita에게 감사드립니다.7 한계 번역 문자성 측정은 잘 연구되지도 이해되지도 않았습니다.우리는 가설과 그 의미를 조사하기 위해 여러 측정의 결합된 해석에 의존합니다.이로 인해 번역 문자성에 대한 높은 상관관계를 가진 지표가 없기 때문에 시스템을 비교하기 어렵기 때문에 강력한 주장을 할 수 있는 범위가 제한됩니다.우리는 우리의 조사가 GPT 번역에서 비문자성 경향이 있음을 나타낸다고만 주장할 수 있지만, 번역 특성을 더욱 모호하게 하기 위해 더 강력한 결과가 필요했을 것입니다.또한 표준 제로샷 및 퓨어샷 설정에서 GPT 번역만 비교하며, 보다 구체적이고 자세한 지침이 LLM이 다른 특성을 가진 번역을 생성하도록 지시할 수 있다는 것은 충분히 상상할 수 있습니다. 참고문헌 Loic Barrault, Ondrej Bojar, Fethi Bougares, Rajen Chatterjee, Marta R. Costa-jussa, Christian Federmann, Mark Fishel, Alexander Fraser, Markus Freitag, Yvette Graham, Roman Grundkiewicz, Paco Guzman, Barry Haddow, Matthias Huck, Antonio Jimeno Yepes, Philipp Koehn, Tom Kocmi, Andre Martins, Makoto Morishita, Christof Monz, 편집자. 2021. 제6회 기계 번역 컨퍼런스 회의록. Association for Computational Linguistics, 온라인. Eleftheria Briakou, Colin Cherry, George Foster. 2023. 건초더미에서 바늘 찾기: 손바닥의 번역 능력에서 우연적 이중언어 사용의 역할에 관하여. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei. 2020. 언어 모델은 few-shot 학습자입니다. 신경 정보 처리 시스템의 발전, 33권, 1877-1901페이지. Curran Associates, Inc. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with paths. Verna Dankers, Elia Bruni, and Dieuwke Hupkes. 2022a. The paradox of the compositionality of natural language: A neural machine translation case study. Association for Computational Linguistics(Volume 1: Long Papers)의 제60회 연례 회의록(Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics)(제1권: 장문 논문), 4154-4175쪽, 더블린, 아일랜드. Association for Computational Linguistics. Verna Dankers, Christopher Lucas, and Ivan Titov. 2022b. 변환기가 너무 구성적일 수 있을까? 신경망 기계 번역에서 관용구 처리 분석. 제60회 연례 총회 회의록(제1권: 장문 논문), 3608-3626쪽, 아일랜드 더블린. 전산 언어학 협회. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. 2019. BERT: 언어 이해를 위한 딥 양방향 변환기의 사전 학습. 전산 언어학 협회 북미 지부 회의록 2019: 인간 언어 기술, 제1권(장문 및 단문 논문), 4171-4186쪽, 미네소타 미니애폴리스. 전산 언어학 협회. Zi-Yi Dou와 Graham Neubig. 2021. 병렬 코퍼스에서 임베딩 미세 조정을 통한 단어 정렬. 제16차 유럽 지부 회의록: 주요 권, 2112-2128쪽, 온라인. Association for Computational Linguistics. Marina Fomicheva, Shuo Sun, Lisa Yankovskaya, Frédéric Blain, Francisco Guzmán, Mark Fishel, Nikolaos Aletras, Vishrav Chaudhary, Lucia Specia. 2020. 신경망 기계 번역을 위한 비지도 품질 추정. Association for Computational Linguistics의 거래, 8:539-555. Martin Gellerstam. 2005. 13장. 번역의 지문, 201-213쪽. Multilingual Matters, Bristol, Blue Ridge Summit. Tanya Goyal, Junyi Jessy Li, Greg Durrett. 2022. gpt-3 시대의 뉴스 요약 및 평가. arXiv 사전 인쇄본 arXiv:2209.12356. Hessel Haagsma, Johan Bos, Malvina Nissim. 2020. MAGPIE: 잠재적으로 관용적인 표현의 대규모 코퍼스. 제12회 언어 자원 및 평가 컨퍼런스 회의록, 279-287페이지, 프랑스 마르세유. 유럽 언어 자원 협회. Tianxing He, Jingyu Zhang, Tianle Wang, Sachin Kumar, Kyunghyun Cho, James Glass, Yulia Tsvetkov. 2022. 텍스트 생성을 위한 모델 기반 평가 지표의 맹점에 관하여. arXiv 사전 인쇄본 arXiv:2212.10020. Amr Hendy, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita, Young Jin Kim, Mohamed Afify, and Hany Hassan Awadalla. 2023. 기계 번역에서 gpt 모델의 성능은? 종합 평가. arXiv 사전 인쇄본 arXiv:2302.09210. Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. 2017. 효율적인 텍스트 분류를 위한 여러 가지 요령. 제15차 유럽 지부 학회 회의록: 제2권, 단편 논문, 427-431쪽, 스페인 발렌시아. Association for Computational Linguistics. Tom Kocmi, Rachel Bawden, Ondřej Bojar, Anton Dvorkovich, Christian Federmann, Mark Fishel, Thamme Gowda, Yvette Graham, Roman Grundkiewicz, Barry Haddow, Rebecca Knowles, Philipp Koehn, Christof Monz, Makoto Morishita, Masaaki Nagata, Toshiaki Nakazawa, Michal Novák, Martin Popel, Maja Popović. 2022. 기계 번역에 대한 컨퍼런스 결과(WMT22). 제7회 기계 번역 컨퍼런스(WMT) 회의록, 1-45페이지, 아랍에미리트 아부다비(하이브리드). 계산 언어학 협회. Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et al. 2022. 언어 모델의 전체적 평가. arXiv 사전 인쇄본 arXiv:2211.09110. Kishore Papineni, Salim Roukos, Todd Ward, WeiJing Zhu. 2002a. Bleu: 기계 번역의 자동 평가 방법. 미국 펜실베이니아주 필라델피아에서 열린 제40회 전산언어학 협회 연례 회의록, 311~318쪽. 전산언어학 협회. Kishore Papineni, Salim Roukos, Todd Ward, WeiJing Zhu. 2002b. Bleu: 기계 번역의 자동 평가 방법. 40th Annual Meeting of the Association for Computational Linguistics 회의록, 311-318쪽, 미국 펜실베이니아주 필라델피아. Association for Computational Linguistics. Maja Popović. 2015. chrF: 자동 MT 평가를 위한 문자 n-gram F-점수. 제10회 통계 기계 번역 워크숍 회의록, 392-395쪽, 포르투갈 리스본. Association for Computational Linguistics. Vikas Raunak, Matt Post, and Arul Menezes. 2022. Salted: 두드러진 롱테일 번역 오류 감지를 위한 프레임워크. Ricardo Rei, José GC de Souza, Duarte Alves, Chrysoula Zerva, Ana C Farinha, Taisiya Glushkova, Alon Lavie, Luisa Coheur, and André FT Martins. 2022. COMET-22: 메트릭 공유 과제에 대한 Unbabel-IST 2022 제출. 제7회 기계 번역 회의(WMT) 회의록, 578-585페이지, 아랍에미리트 아부다비(하이브리드). 계산 언어학 협회. Ricardo Rei, Craig Stewart, Ana C Farinha, Alon Lavie. 2020. COMET: MT 평가를 위한 신경 프레임워크. 2020년 자연어 처리 경험적 방법 회의(EMNLP) 회의록, 2685-2702페이지, 온라인. 계산 언어학 협회. Prateek Saxena와 Soma Paul. 2020. Epie 데이터 세트: 가능한 관용 표현에 대한 코퍼스. Moritz Schaeffer와 Michael Carl. 2014. 문자적 번역 프로세스의 인지적 노력 측정. EACL 2014 Workshop on Humans and Computer-assisted Translation의 회의록, 2937페이지, 스웨덴 예테보리. Association for Computational Linguistics. Andrea Schioppa, David Vilar, Artem Sokolov, and Katja Filippova. 2021. 첨가적 개입을 통한 다중 속성에 대한 기계 번역 제어. 2021 Conference on Empirical Methods in Natural Language Processing의 회의록, 6676-6696페이지, 온라인 및 도미니카 공화국 푼타카나. Association for Computational Linguistics. Simone Tedeschi and Roberto Navigli. 2022. MultiNERD: 명명된 엔터티 인식(및 모호성 해소)을 위한 다국어, 다중 장르 및 세분화된 데이터 세트. Association for Computational Linguistics: NAACL 2022의 결과, 801-812페이지, 미국 시애틀. Association for Computational Linguistics. Chau Tran, Shruti Bhosale, James Cross, Philipp Koehn, Sergey Edunov, and Angela Fan. 2021. Facebook AI의 WMT21 뉴스 번역 과제 제출. 제6회 기계 번역 컨퍼런스 회의록, 205-215페이지, 온라인. Association for Computational Linguistics. David Vilar, Markus Freitag, Colin Cherry, Jiaming Luo, Viresh Ratnakar, and George Foster. 2022. 번역을 위한 손바닥 촉구: 전략과 성과 평가. Chenyun Wu, Zhe Lin, Scott Cohen, Trung Bui, and Subhransu Maji. 2020. Phrasecut: 야생에서의 언어 기반 이미지 분할. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 10216-10225페이지. Jianing Zhou, Hongyu Gong, Suma Bhat. 2021. PIE: 관용적 문장 생성 및 의역을 위한 병렬 관용적 표현 코퍼스. 제17차 다중 단어 표현 워크숍(MWE 2021) 진행 과정, 33-48페이지, 온라인. 전산언어학협회. 출처: 당은 의회에서 과반수 의석을 끌어내리기 위해 반군을 실격시키지 못했습니다. 시스템 A: Die Partei war nicht in der Lage, die Rebellen zu disqualifizieren, um die Mehrheitsmarke in der Versammlung zu senken. 시스템 B: Die Partei war bisher nicht in der Lage, die Rebellen von der Wahl zu disqualifizieren, um die Mehrheitsmarke im Parlament zu senken. 1 시스템 A 번역은 더 문자 그대로입니다 합성 데이터 집합 2: 그림 6은 프롬프트의 예와 두 개의 관용어가 포함된 생성된 합성 문장의 예를 보여줍니다. 프롬프트: Q: 뉴스 기사 문장 형태로 &quot;white chair&quot;라는 문구가 포함된 문장을 생성하세요. \n A: 출력: 연구에 참여한 대부분의 참가자는 &quot;white chair&quot;가 편안한 것으로 나타났습니다. 그림 5: 합성 데이터 집합 1: 예(구문)O 시스템 B 번역은 더 문자 그대로입니다 두 번역 모두 똑같이 문자 그대로입니다 그림 2: 인간 평가를 위한 주석 인터페이스 스크린샷. 번역은 편향된 평가를 방지하기 위해 평가 대상 시스템 간에 무작위로 지정됩니다. A 인간 주석 인터페이스 그림 2의 주석 인터페이스를 사용하여 주석 작성자에게 두 번역을 평가하도록 요청합니다. 이중 언어 사용자와 원어민 주석 작성자는 사내에서 모집되었습니다. B 합성 데이터 집합 세부 정보 합성 데이터 집합 1: 세 가지 표현 유형 각각에 대해 100개의 합성 문장이 생성됩니다. 그림 3, 4, 5는 예를 보여줍니다. 명명된 엔터티와 설명적 구문 표현의 소스는 각각 MultiNERD(Tedeschi 및 Navigli, 2022) 및 PhraseCut(Wu et al., 2020) 데이터 세트입니다. 프롬프트: 질문: 관용어가 포함된 문장을 뉴스 기사 문장 형태로 생성하세요. \n A: 출력: 그 남자는 짧은 퓨즈를 가진 것으로 알려졌고, 종종 경고 없이 분노에 휩싸였습니다. 그림 3: 합성 데이터 세트 1: 예(관용어) 프롬프트: 질문: 두 가지 관용어를 사용하여 문장을 생성하세요: off the wall, claim to fame을 뉴스 기사 문장 형태로 생성하세요. \n A: 출력: 이 회사의 엉뚱한 마케팅 캠페인은 명성을 얻는 데 도움이 되었습니다. 그림 6: 합성 데이터 세트 2: 예(2개의 관용어구) C 정렬 및 문자성 Schaeffer와 Carl(2014)은 소스와 번역 간의 더 많은 정렬 교차(비단조성 측정법으로 측정)가 비문자적 번역을 처리하는 데 필요한 추가 인지적 노력(인간 번역자의 응시 시간을 사용하여 측정)에 비례한다는 것을 발견했습니다. 이는 정렬 교차(비단조성 측정은 정규화된 정렬 교차)를 더 큰 비문자성과 연결합니다. 프롬프트: Q: 뉴스 기사 문장의 형태로 엔터티 Wolfgang Amadeus Mozart가 포함된 문장을 생성합니다. \n A: 출력: 세계적으로 유명한 작곡가 Wolfgang Amadeus Mozart가 오늘 35세의 나이로 사망했습니다. 그림 4: 합성 데이터 세트 1: 예(엔터티)
