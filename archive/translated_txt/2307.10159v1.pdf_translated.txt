--- ABSTRACT ---
시각적 콘텐츠 생성이 점점 더 머신 러닝에 의해 주도되는 시대에, 인간 피드백을 생성 모델에 통합하면 사용자 경험과 출력 품질을 향상시킬 수 있는 중요한 기회가 제공됩니다. 이 연구에서는 반복적인 인간 피드백을 확산 기반 텍스트-이미지 모델의 생성 프로세스에 통합하기 위한 전략을 탐구합니다. 우리는 가장 널리 사용되는 아키텍처에 존재하는 자기 주의 계층을 활용하여 피드백 이미지 세트에 대한 확산 프로세스를 조건화하는 광범위한 인기 있는 확산 모델에 적용 가능한 훈련 없는 접근 방식인 FABRIC을 제안합니다. 접근 방식에 대한 엄격한 평가를 보장하기 위해 인간 피드백을 통합하는 생성 시각적 모델의 성능을 정량화하는 강력한 메커니즘을 제공하는 포괄적인 평가 방법론을 소개합니다. 우리는 생성 결과가 철저한 분석을 통해 반복적인 피드백을 여러 번 거치면서 개선되고, 암묵적으로 임의의 사용자 선호도를 최적화한다는 것을 보여줍니다. 이러한 연구 결과의 잠재적인 응용 분야는 개인화된 콘텐츠 생성 및 사용자 지정과 같은 분야로 확장됩니다.
--- INTRODUCTION ---
인공 지능(AI) 분야는 생성적 시각적 모델에 대한 관심이 급증했는데, 이는 주로 콘텐츠 생성, 사용자 정의, 데이터 증강 및 가상 현실을 포함하는 수많은 응용 분야에서 혁신적 잠재력이 있기 때문입니다. 이러한 모델은 GAN(Goodfellow et al., 2014) 및 VAE(Kingma &amp; Welling, 2022)와 같은 고급 딥 러닝 방법론을 활용하여 주어진 입력 또는 설명에서 충실도가 높고 시각적으로 매력적인 이미지를 생성합니다(Brock et al. (2019); Razavi et al. (2019). 생성적 시각적 모델의 상당한 발전은 컴퓨터 비전, 자연어 처리 및 인간-컴퓨터 상호 작용 분야에서 새로운 가능성에 대한 탐구를 촉진했습니다(Radford et al. (2016). 특히 확산 모델은 이미지 합성 분야에서 강력한 도구로 등장하여 종종 GAN 및 VAE에서 생성된 결과와 비슷하거나 더 뛰어난 결과를 제공합니다(Ho et al. (2020); Rombach 등(2022). 이러한 모델은 다양한 시각적으로 일관된 이미지를 생성하는 기능이 특징이며, 훈련 단계에서 뛰어난 안정성과 감소된 모드 붕괴를 보여줍니다. Song 등(2021). 이로 인해 널리 채택되었습니다. *동등한 기여 프롬프트 피드백 이미지 피드백 출처 초원에서 달리는 개 사진 U-Net 레이어(N) z~N(0, 1) 자기 주의 ResNet 블록 H 교차 주의 FFN 그림 2: 제안된 접근 방식의 그림. FABRIC은 주의 기반 조절 메커니즘을 통해 사용자 피드백을 통합하여 생성된 결과를 개선합니다. 생성적 시각 모델링의 최전선을 조사하는 연구자들 사이에서. 게다가 확산 모델의 유용성은 이미지 합성을 넘어 인페인팅, 초고해상도, 스타일 전송과 같은 다양한 다른 도메인에서 응용 프로그램을 찾습니다. Chan 등(2020); Park 등(2019). 텍스트 컨디셔닝은 생성적 시각 모델의 중요한 구성 요소로 작용하여 인간이 읽을 수 있는 설명을 기반으로 이미지를 합성할 수 있습니다(Reed et al., 2016). 그러나 광범위한 이미지를 생성하는 확산 모델의 강력한 기능에도 불구하고 모델을 특정 원하는 출력으로 조종하는 데는 어려움이 따를 수 있습니다(Luccioni et al., 2023). 사용자는 종종 의도한 결과를 달성하기 위해 즉각적인 개선의 반복적 프로세스를 시작하고, 텍스트 형태로 개인적 선호도를 표현하는 것은 복잡한 작업이 될 수 있습니다. 그럼에도 불구하고 사용자는 생성된 이미지의 품질을 쉽게 평가할 수 있는 능력을 가지고 있습니다. 이를 통해 희소한 인간 피드백을 생성 프로세스에 통합할 가능성이 열리고, 이를 활용하여 결과를 향상시키고 사용자 선호도와 더 잘 맞출 수 있습니다. 확산 모델이 제공하는 생성 프로세스의 안정성과 제어 가능성을 감안할 때, 확산 모델은 인간 피드백을 통합하여 텍스트-이미지 생성 프로세스를 개선하기 위한 이상적인 플랫폼을 제공합니다. 이 작업에서 우리는 이 반복적 워크플로에 초점을 맞추고 생성 프로세스를 바람직하고 바람직하지 않은 결과에서 벗어나도록 조종하는 데 도움이 되는 희소 피드백 기반 기술을 제안합니다. 이는 긍정적 및 부정적 피드백 이미지(예: 이전 세대에서 수집)를 사용하여 참조 이미지 컨디셔닝을 통해 미래 결과를 조작함으로써 달성됩니다. 설정을 반복하기만 하면 임의의 피드백 소스(인간 피드백 포함)를 기반으로 생성된 이미지를 반복적으로 정제할 수 있습니다. 우리의 기여는 세 가지입니다. a • 우리는 명시적 훈련이 필요 없이 반복적 피드백을 생성 프로세스에 통합할 수 있는 FABRIC(Feedback via Attention-Based Reference Image Conditioning)이라는 새로운 접근 방식을 소개하며, 이는 안정적 확산에 대한 많은 다른 확장과 결합할 수 있습니다. • • 우리는 여러 라운드에 걸쳐 생성적 시각 모델의 자동 평가를 용이하게 하는 두 가지 실험 설정을 제안합니다. 이러한 제안된 설정을 사용하여 FABRIC을 평가하고 기준 방법보다 우수함을 보여줍니다. 2
--- RELATED WORK ---
2.1 텍스트 반전 및 스타일 변환 인기 있는
--- METHOD ---
영어: ology는 인간 피드백을 통합하는 생성적 시각 모델의 성능을 정량화하는 강력한 메커니즘을 제공합니다. 우리는 생성 결과가 철저한 분석을 통해 여러 라운드의 반복적 피드백을 통해 개선되어 임의의 사용자 선호도를 암묵적으로 최적화한다는 것을 보여줍니다. 이러한 결과의 잠재적 응용 분야는 개인화된 콘텐츠 생성 및 사용자 지정과 같은 분야로 확장됩니다. 서론 인공 지능(AI) 분야는 생성적 시각 모델에 대한 관심이 급증했는데, 이는 주로 콘텐츠 생성, 사용자 지정, 데이터 증강 및 가상 현실을 포함하는 수많은 응용 분야에서 혁신적 잠재력이 있기 때문입니다. 이러한 모델은 GAN(Goodfellow et al., 2014) 및 VAE(Kingma &amp; Welling, 2022)와 같은 고급 딥 러닝 방법론을 활용하여 주어진 입력 또는 설명에서 충실도가 높고 시각적으로 매력적인 이미지를 생성합니다(Brock et al. (2019); Razavi et al. (2019). 생성적 시각 모델의 중요한 발전은 컴퓨터 비전, 자연어 처리 및 인간-컴퓨터 상호작용 Radford et al. (2016)의 영역에서 새로운 가능성에 대한 탐구를 촉진했습니다. 특히 확산 모델은 이미지 합성 분야에서 강력한 도구로 등장하여 종종 GAN 및 VAE에서 생성된 결과와 비슷하거나 더 뛰어난 결과를 제공합니다. Ho et al. (2020); Rombach et al. (2022). 이러한 모델은 다양한 시각적으로 일관된 이미지를 생성하는 기능이 특징이며, 훈련 단계에서 뛰어난 안정성과 감소된 모드 붕괴를 보여줍니다. Song et al. (2021). 이로 인해 광범위한 채택이 이루어졌습니다. *동일한 기여 프롬프트 피드백 이미지 피드백 소스 초원에서 달리는 개 사진 U-Net 레이어 (N) z~N(0, 1) 셀프 어텐션 ResNet 블록 H 크로스 어텐션 FFN 그림 2: 제안된 접근 방식의 그림. FABRIC은 주의 기반 컨디셔닝 메커니즘을 통해 사용자 피드백을 통합하여 생성된 결과를 개선합니다. 생성적 시각 모델링의 최전선을 조사하는 연구자들 사이에서. 게다가, 확산 모델의 유용성은 이미지 합성을 넘어 인페인팅, 초고해상도, 스타일 전송과 같은 다양한 다른 도메인에서 응용 프로그램을 찾습니다. Chan et al. (2020); Park et al. (2019). 텍스트 컨디셔닝은 생성적 시각 모델의 중요한 구성 요소로 사용되어 사람이 읽을 수 있는 설명을 기반으로 이미지를 합성할 수 있습니다. Reed et al. (2016). 그러나 광범위한 이미지를 생성하는 확산 모델의 강력한 기능에도 불구하고 모델을 특정 원하는 출력으로 조종하는 데는 어려움이 따를 수 있습니다. Luccioni et al. (2023). 사용자는 종종 의도한 결과를 달성하기 위해 즉각적인 개선의 반복적 프로세스를 시작하고, 텍스트 형태로 개인적 선호도를 표현하는 것은 복잡한 작업이 될 수 있습니다. 그럼에도 불구하고 사용자는 생성된 이미지의 품질을 쉽게 평가할 수 있는 능력을 가지고 있습니다. 이를 통해 희소한 인간 피드백을 생성 프로세스에 통합할 가능성이 열리고, 이를 활용하여 결과를 향상시키고 사용자 선호도와 더 잘 일치시킬 수 있습니다. 확산 모델이 제공하는 생성 프로세스의 안정성과 제어 가능성을 감안할 때, 이는 텍스트-이미지 생성 프로세스를 개선하기 위해 인간 피드백을 통합하기 위한 이상적인 플랫폼을 제공합니다. 이 연구에서는 이 반복적 워크플로에 초점을 맞추고 생성 프로세스를 바람직한 결과로 이끌고 바람직하지 않은 결과에서 벗어나도록 돕는 것을 목표로 하는 희소 피드백 기반 기술을 제안합니다. 이는 긍정적 및 부정적 피드백 이미지(예: 이전 세대에서 수집)를 사용하여 참조 이미지 컨디셔닝을 통해 미래 결과를 조작함으로써 달성됩니다. 설정을 반복하기만 하면 임의의 피드백 소스(인간 피드백 포함)를 기반으로 생성된 이미지를 반복적으로 개선할 수 있습니다. 우리의 기여는 세 가지 측면이 있습니다. a • 우리는 명시적인 훈련이 필요 없이 생성 프로세스에 반복적 피드백을 통합할 수 있는 FABRIC(Feedback via Attention-Based Reference Image Conditioning)이라는 새로운 접근 방식을 소개합니다. 이 접근 방식은 안정 확산에 대한 많은 다른 확장과 결합될 수 있습니다. • • 우리는 두 가지를 제안합니다.
--- EXPERIMENT ---
여러 라운드에 걸쳐 생성적 시각적 모델의 자동 평가를 용이하게 하는 모든 설정. 제안된 설정을 사용하여 FABRIC을 평가하고 기준 방법보다 우수함을 입증합니다. 2 관련 작업 2.1 텍스트 반전 및 스타일 전송 텍스트-이미지 확산 모델을 개인화하는 인기 있는 방법은 텍스트 반전(Gal et al., 2023; Ruiz et al., 2023)으로, 공통된 주제나 스타일을 묘사하는 이미지에서 의미적 텍스트 임베딩을 학습하는 기술입니다. 이를 통해 원하는 특징 세트를 보존하면서 다양한 장면과 조건에서 사실적인 이미지를 합성할 수 있지만, 이러한 특징을 통합하는 여러 이미지와 의미적 임베딩을 학습하기 위한 추가 교육이 필요합니다. &#39;코드는 공개적으로 사용 가능합니다: https://github.com/sd-fabric/fabric.gitMokady et al. (2022) 텍스트 기반 확산 모델을 위한 정확한 역전 기법을 소개하여 텍스트 기반 실제 이미지 편집 기능을 가능하게 합니다. 제안된 접근 방식은 확산 모델을 위한 피벗 역전과 널 텍스트 최적화라는 두 가지 새로운 구성 요소로 구성되어 모델의 가중치를 조정하지 않고도 실제 이미지의 고충실도 편집이 가능합니다. StyleDrop(Sohn et al. (2023))은 텍스트-이미지 모델을 사용하여 특정 스타일을 준수하는 이미지를 합성하기 위해 Google Research에서 개발한 새로운 방법입니다. 이 방법은 색 구성표, 음영, 디자인 패턴, 로컬 및 글로벌 효과를 포함하여 사용자가 제공한 스타일의 복잡한 세부 사항을 캡처하고 인간 또는 자동화된 피드백을 사용하여 반복적인 학습을 통해 품질을 향상시켜 텍스트-이미지 모델을 스타일을 조정하는 다른 방법보다 성능이 뛰어납니다. Xu et al. (2023)은 텍스트 프롬프트 대신 사용자가 제공한 참조 이미지를 통합하는 새로운 접근 방식을 소개합니다. 프롬프트 없는 확산이라고 불리는 이 접근법은 의미적 맥락 인코더(SeeCoder)를 활용하여 이러한 입력을 의미 있는 시각적 임베딩으로 변환한 다음 이를 텍스트-이미지(T2I) 모델의 조건부 입력으로 사용하여 고품질의 맞춤형 출력을 생성합니다.2.2 인간 선호도 모델링 최근 생성 모델에서 인간 선호도를 모델링하는 데 주의가 증가했습니다.확산 모델 영역에서 Wu et al.(2023)은 25,000개가 넘는 프롬프트에서 수집한 거의 100,000개의 이미지가 포함된 새로운 데이터 세트를 제공합니다.데이터 세트의 샘플에는 2~4개의 이미지와 이 배치의 이미지가 제공될 때의 특정 사용자의 선택이 포함됩니다.저자는 선택한 이미지와 선택되지 않은 이미지를 분류하기 위해 CLIP(Radford et al.(2021)) 모델을 미세 조정합니다.인간 선호도 점수(HPS)는 이 분류기에서 파생됩니다. 그 외에도 저자는 안정된 확산(Rombach 등(2022))의 저순위 적응(LoRA, Hu 등(2021))을 미세 조정하여 이미지 품질을 크게 개선합니다.Kirstain 등(2023)은 웹 인터페이스의 실제 사용자로부터 수집한 텍스트-이미지 생성을 위한 대규모 사용자 선호도 데이터 세트인 Pick-a-Pic을 소개합니다.웹 앱은 사용자에게 프롬프트에 따라 생성된 두 개의 이미지를 제공하고 선호하는 옵션을 선택하거나 선호도가 강하지 않으면 동점을 표시하도록 요청합니다.거부된(선호하지 않는) 이미지는 새로 생성된 이미지로 대체되고 프로세스가 반복됩니다.14,000개의 선호도가 포함된 데이터 세트는 PickScore라는 채점 함수를 학습하는 데 사용됩니다.이 채점 함수는 사용자 선호도를 예측하는 데 있어 다른 사용 가능한 채점 함수보다 성능이 뛰어나며 전문적인 인간 주석자보다 뛰어납니다. 저자들은 텍스트-이미지 모델을 평가하는 데 Pick-a-Pic 프롬프트를 사용할 것을 옹호하며, 모델 평가, 이미지 품질 개선, 텍스트-이미지 모델 향상과 같은 다양한 응용 분야에서 데이터 세트의 잠재력을 강조합니다.Fan et al. (2023)은 온라인 강화 학습(RL)을 사용하여 텍스트-이미지 확산 모델을 미세 조정하기 위한 DPOK라는 접근 방식을 제안합니다.DPOK는 정책 최적화를 KL 정규화와 통합하고 정책 그래디언트를 사용하여 사전 학습된 모델을 업데이트하여 피드백 학습된 보상을 극대화합니다.저자들은 DPOK가 일반적으로 이미지-텍스트 정렬과 이미지 품질 측면에서 지도 미세 조정보다 성능이 우수함을 보여줍니다.2.3 반복적 피드백 생성 텍스트-이미지 워크플로에서 사용자는 일반적으로 프롬프트를 생각하고 해당 프롬프트로 이미지를 생성하고 결과를 검사하고 프롬프트를 조정하고 결과에 만족할 때까지 이 프로세스를 반복합니다.사용자에게서 이러한 부담을 제거하기 위해 Tang et al. (2023)은 랭킹 오라클을 통해 평가된 블랙박스 목적 함수 문제에 대한 이론적 보장을 갖춘 새로운 영차 최적화 알고리즘을 제안합니다. 여기에는 인간 피드백을 통한 강화 학습(RLHF)이 포함됩니다. 이 알고리즘의 효과는 인간 랭킹 피드백을 사용하여 확산 생성 모델에서 생성된 이미지 품질을 개선하는 데 입증되었으며, 기존 RLHF 방법에 대한 유망한 대안을 제공합니다. 요약하자면, 이 분야의 문헌은 주로 개념 학습, 참조 이미지에서의 스타일 전환, 모델을 미세 조정하기 위한 인간 선호도 모델링에 초점을 맞추었습니다. 그러나 모델 성능을 향상하고 인간 선호도와 일치시키는 데 잠재적으로 중요한 측면인 인간 피드백을 모델 학습 프로세스에 반복적으로 통합하는 것은 비교적 미개척 상태로 남아 있습니다.3 FABRIC 이제 생성 프로세스에 여러 라운드의 긍정적 및 부정적 인간 피드백을 통합하는 문제를 해결하는 제안 방법인 FABRIC을 소개합니다. 주의 기반 참조 이미지 컨디셔닝 FABRIC은 Zhang(2023)이 널리 사용하는 ControlNet 저장소에 대한 업데이트에서 구현한 기술에서 영감을 얻었으며, 일부 참조와 유사한 합성 이미지를 생성하는 기능을 도입했습니다. 이 방법은 U-Net의 셀프 어텐션 모듈을 활용합니다. 직감적으로 자기 주의 모듈의 가중치는 이미지의 다른 픽셀에 &quot;주의를 기울이는&quot; 법을 배웠습니다. 따라서 참조 이미지에서 추가 키와 값을 추가하면 추가 정보를 주입할 수 있는 방법이 제공됩니다. 노이즈 제거 프로세스의 특정 시간 단계에서 생성된 이미지와 호환되기 위해 참조 잠복 이미지는 현재 시간 단계 t까지 부분적으로 노이즈가 제거됩니다(표준 랜덤 순방향 노이즈 제거 프로세스 사용: . Zref √√āt xref + √√1 − āt · N(0, 1)) . (1) 그러나 이미지를 단순히 연결하는 것만으로는 작동하지 않기 때문에 U-Net 계층에서 참조 이미지의 키와 값을 계산하는 방법은 즉시 명확하지 않습니다. 따라서 주입을 위한 키와 값(또는 바로 앞의 숨겨진 상태, 알고리즘 0 참조)은 노이즈가 제거된 참조 이미지를 안정 확산의 U-Net을 통해 전달하여 계산합니다. 모든 키와 값은 U-Net의 자기 주의 계층에 저장됩니다. 그런 다음 특정 U-Net에 대해 사용자 프롬프트의 노이즈 제거 단계와 현재 부분적으로 노이즈가 제거된 잠재 이미지 Zt+1에서 저장된 키와 값은 해당 U-Net 계층의 셀프 어텐션에 추가됩니다. 이런 방식으로 노이즈 제거 프로세스는 참조 이미지에 주의를 기울이고 의미 정보를 포함할 수 있습니다. 어텐션 점수를 재가중함으로써(식 2 참조) 참조 영향의 강도에 대한 제어도 추가로 얻습니다. 참조 이미지의 은닉 상태를 미리 계산하려면 추가 U-Net 순방향 패스가 필요하여 추론 시간이 약 두 배가 됩니다. 또한 셀프 어텐션 계층에서 추가 키와 값을 연결하면 추론 시간도 늘어나고 피드백 이미지 수에 따라 필요한 메모리가 이차적으로(또는 메모리 효율적인 어텐션 구현이 사용되는 경우 선형적으로) 확장됩니다(Dao et al., 2022; Rabe &amp; Staats, 2022). 생성 프로세스에 피드백 통합 이전 섹션에서 설명한 방법은 생성 프로세스에 참조 이미지를 통합했습니다. 이제 다중 라운드 긍정적 및 부정적 피드백을 통합하기 위한 확장을 제공합니다.좋아하는 이미지와 싫어하는 이미지 세트가 주어지면, 우리는 모든 좋아하는 이미지와 싫어하는 이미지에 대해 별도의 U-Net 패스를 수행합니다.좋아하는 이미지와 싫어하는 이미지의 키와 값은 각각 조건부 및 무조건부 U-Net 패스에 연결됩니다(분류기 없는 지침, Ho &amp; Salimans(2022) 참조).더 나아가, 우리는 조건부 패스인지 무조건부 패스인지와 노이즈 제거 프로세스의 현재 시간 단계에 따라 요인으로 주의 점수를 재가중합니다.ControlNet(Zhang, 2023) 접근 방식과 달리, 우리는 또한 이 선형 보간을 탐구하는데, 이를 통해 거친 특징(t&gt; aT에 대한 큰 참조 주의 가중치를 가짐)이나 참조에서 미세한 세부 사항(즉, t ≤ aT일 때 더 큰 주의 가중치)을 강조할 수 있습니다.피드백 프로세스는 노이즈 제거 단계에 따라 예약될 수 있습니다.이를 통해 일부 노이즈 제거 단계에서만 피드백을 포함할 수 있습니다. 우리는 잡음 제거 프로세스의 전반부에 피드백을 통합할 때 가장 좋은 결과를 얻을 수 있다는 것을 발견했습니다.적응된 피드백 일정을 사용한 추가 실험은 섹션 5.3에서 찾을 수 있습니다.반복적 피드백으로 확장하기 이제 긍정적 및 부정적 피드백 참조 이미지를 모두 통합할 수 있으므로 여러 라운드에 대해 알고리즘을 조정합니다.처음에는 피드백 이미지가 없는 이미지를 생성하여 바닐라 안정적 확산 생성을 생성합니다.이러한 이미지에서 좋아하는 이미지와 싫어하는 이미지 세트를 각각 긍정적 및 부정적 피드백에 추가합니다.이 피드백을 얻는 방법은 임의적이지만 피드백 소스가 인간 또는 자동화된 프로세스라고 생각합니다.그런 다음 제공된 피드백을 사용하여 새 이미지 배치를 생성합니다.매 라운드마다 이 프로세스를 반복하여 좋아하는 이미지와 싫어하는 이미지 세트를 확장하고 이에 따라 다음 배치를 개선합니다.4 평가 4.1 패브릭 모델 우리는 연구에서 두 가지 버전의 FABRIC에 대한 평가를 수행합니다. 첫 번째 버전은 FABRIC이라고 하며, 섹션 3에 설명된 방법론을 활용하며, 미세 조정된 Stable Diffusion 1.5 체크포인트(dreamlike-photoreal-2.0)를 기반으로 구축되었습니다. 두 번째 버전은 FABRIC+HPS LORA라고 하며, Wu et al.(2023)이 제안한 Human Preference Score를 기반으로 하는 Stable Diffusion 1.5의 Low-Rank Adaptation(LORA) 위에 적용하여 FABRIC 접근 방식을 더욱 향상시킵니다. 우리는 인간의 선호도와 밀접하게 일치하는 이미지를 생성하는 입증된 능력으로 인해 FABRIC+HPS LORA 버전을 평가에 포함하기로 했습니다. 4. 기준선 여러 라운드에 걸쳐 수집된 반복적 피드백을 통합하도록 설계된 방법은 우리가 아는 한 존재하지 않으므로 제안된 방법을 다음과 같은 방식으로 표준 Stable Diffusion 모델과 비교합니다. 먼저, Stable Diffusion 1.5(기본 모델² 또는 HPS LORA 체크포인트가 있거나 없는 Dreamlike Photoreal³이라는 미세 조정 버전 사용)를 N번 실행하고 각각 다른 시드를 사용하여 N개의 이미지 배치를 생성합니다. 그런 다음 각 라운드에서 생성된 배치에 대한 원하는 평가 메트릭을 수집하고 이 값을 사용하여 FABRIC과 정량적 비교를 수행합니다. 각 라운드의 이미지를 우리 방법에 대한 미래 라운드에 대한 피드백으로 추가할 수 있지만, 베이스라인에는 피드백을 미래 세대에 통합하는 메커니즘이 없다는 점에 유의하는 것이 중요합니다. 따라서 베이스라인 모델은 이전 라운드를 고려하지 않고 각 라운드에서 독립적으로 이미지를 생성합니다. 고려된 모든 모델의 개요는 표 1에서 확인할 수 있습니다.체크포인트 LORA 이름 SD 버전 FABRIC 기준선 1.stable-diffusion-v1.х Dreamlike Photoreal 1.dreamlike-photoreal-2.HPS LORA 1.dreamlike-photoreal-2.0 HPS LORA ✓ FABRIC(SD) 1.stable-diffusion-v1.FABRIC 1.dreamlike-photoreal-2.FABRIC + HPS LORA 1.dreamlike-photoreal-2.Χ HPS LORA 표 1: 평가에 사용된 FABRIC 모델 및 기준선의 세부 사항 4. 지표 4.3. 선호도 모델 실험을 자동으로 평가하기 위해 2절에서 소개한 PickScore를 일반적인 인간의 선호도에 대한 대리 점수로 사용합니다. 4.3.2 피드백 이미지에 대한 클립 유사도 피드백을 생성 프로세스에 통합하는 효과를 평가하기 위해 생성된 이미지와 이전의 긍정적, 부정적 피드백 이미지 간의 CLIP 유사도를 계산합니다.(k) (1) (k) 생성된 이미지 x에 대해 피드백 이미지 ypos, ..., ypos 또는 (1) Yneg, Yneg에 대한 평균 CLIP 유사도를 계산합니다.특히 CLIP(x, y)가 x와 y의 CLIP 임베딩 간의 코사인 유사도를 나타내도록 합니다.그러면 긍정적 CLIP 유사도는 다음과 같이 정의됩니다.kSpos(x) = Σ CLIP(x, ypos) (i) i=2https://huggingface.co/runwayml/stable-diffusion-v1-https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.부정적 유사도 sneg(x)도 유사하게 정의됩니다. 4.3.3 배치 내 이미지 다양성 사용자 선호도에 맞춰 이미지 생성을 조정하는 과정에서 탐색(사용자 선택을 위한 다양한 이미지 옵션 제공)과 활용(이전 피드백에 맞춰 이미지 생성)의 균형을 맞추는 것이 중요합니다. 여러 라운드에서 이 두 요소 간의 균형을 정량화하기 위해 배치 내 이미지 다양성이라는 메트릭을 도입합니다. 배치 이미지 x1,...,xn에 대해 배치 내 이미지 간의 평균 CLIP 유사성을 기반으로 배치 내 다양성을 정의합니다. 구체적으로, 위에서 정의된 CLIP 유사도를 사용하면 배치 내 이미지 다양성 d는 다음과 같이 정의됩니다.n id(x1,...,xn) =n(n - 1) Σ CLIP (xi, xj) i = 2 j = 여기서 &quot;(n-1)은 상삼각 코사인 유사도 행렬의 요소 수입니다.실험 모델의 기능을 평가하기 위해 두 가지 실험 설정을 설계했으며, 각각 라운드 동안 피드백 이미지를 선택하기 위한 다른 기준을 사용했습니다.5.1절에서는 선호도 점수를 사용하여 좋아하는 이미지와 싫어하는 이미지를 선택하는 선호도 모델 기반 접근 방식을 제시합니다.5.2절에서는 실험 시작 시 제공된 대상 이미지와의 유사도에 따라 피드백을 선택하는 대상 이미지 기반 접근 방식을 제시합니다(하지만 피드백으로 직접 사용하지는 않음).두 실험 모두 배치 크기 4를 사용하고 3라운드의 생성으로 구성됩니다.각 라운드가 끝나면 한 이미지는 좋아하는 것으로 선택되고 다른 이미지는 싫어하는 것으로 선택됩니다.다음을 보여주기 위해 피드백 강도에 대한 견고성, 선호도 모델 기반 설정은 w = 0.1의 피드백 강도를 사용하는 반면 대상 이미지 기반 설정은 w = 0.8을 사용합니다. 5. 선호도 모델 기반 피드백 선택 첫 번째 실험은 보편적 선호도 점수를 통해 사람들이 일반적으로 생성된 이미지를 어떻게 인식하는지 평가하여 FABRIC을 평가하는 것을 목표로 했습니다. 따라서 이 실험은 모든 사람이 피드백을 제공할 때 동일한 선호도를 가지고 있다는 가정 하에 진행되며, 이는 일반적으로 항상 유지되지 않을 수 있으며 두 번째 실험에서 도전합니다. 실제로 실험은 다음과 같이 수행됩니다. 먼저 HPS 데이터 세트(Wu et al., 2023)에서 1000개의 프롬프트의 무작위 집합을 샘플링합니다. 다음으로, 각 프롬프트에 대해 사용자의 좋아하고 싫어하는 이미지를 빈 집합으로 초기화한 후 모델과 사용자 간의 3라운드 상호 작용을 시뮬레이션합니다. 각 라운드에서 다음 단계가 수행됩니다. 먼저 프롬프트 및 피드백 이미지를 입력으로 사용하여 FABRIC을 실행하여 4개의 이미지 배치를 생성합니다. 그런 다음 생성된 각 이미지의 인간 선호도 점수가 계산됩니다. 이러한 점수를 인간 피드백의 대리로 사용하여 가장 높은 점수를 받은 생성된 이미지를 좋아하는 이미지 세트에 추가하고 가장 낮은 점수를 받은 이미지를 싫어하는 이미지에 추가합니다. 생성된 이미지의 각 배치에 대해 평균 PickScore와 긍정적 및 부정적 이미지에 대한 평균 CLIP 유사도를 측정합니다. 각 FABRIC 모델(dreamlike-photoreal-2.0 및 HPS LORA)을 이 두 점수 측면에서 각각의 기준선과 비교합니다. 실험 결과는 그림 3에 나와 있습니다. 그림 3a에서는 여러 라운드를 실행하고 더 높은 이미지 다양성을 달성하면 최대 PickScore가 증가할 수 있다는 우려를 다룹니다. 실제로 일반적으로 이 값이 라운드에 따라 증가하더라도 모델이 두 기준선 모두보다 성능이 우수함을 보여줍니다. 그림 3b에서 두 번째 라운드부터 모델이 최대 PickScore 측면에서뿐만 아니라 평균 및 최소값 측면에서도 기준선보다 성능이 우수하여 생성된 이미지의 품질이 전반적으로 향상되었음을 나타냅니다. 그림 3c에서 생성된 이미지의 긍정적 및 부정적 피드백에 대한 유사성을 평가합니다.단 한 라운드 후에도 CLIP 유사성 점수가 긍정적 샘플에 대해 더 높고 PickScore 21.221.20.820.620.420.2라운드 21.21.20.20.PickScore 20.20.SD 1.FABRIC(SD) 20.Dreamlike Photoreal FABRIC 19.8-x-HPS LORA HPS LORA + FABRIC 19.6 분 라운드 FABRIC HPS LORA HPS LORA + FABRIC 2라운드의 피드백 이미지 유사성 긍정적 부정적 SD 1.FABRIC(SD) Dreamlike Photoreal FABRIC HPS LORA FABRIC+ HPS LORA (a) 이전 모든 라운드에서 생성된 이미지의 가장 높은 PickScore. (b) 최소. (점선), 평균(점선) (c) 생성된 이미지의 유사성과 각 긍정/부정 피드백 라운드의 최대(실선) PickScore. 그림 3: 선호도 모델 기반 피드백 선택의 결과. CLIP 점수 78라운드 SD 1. FABRIC(SD) 몽환적 사진처럼 사실적인 FABRIC 라운드최대 HPS LORA 평균 ▾ FABRIC + HPS LORA ..... 최소 라운드 그림 4: 대상 이미지 기반 피드백 선택의 결과. 긍정적 피드백은 기준선에 비해 대상 유사성을 개선하고 긍정적 및 부정적 피드백을 모두 사용하면 더욱 개선됩니다. 동시에 모든 종류의 피드백은 생성된 이미지의 다양성을 크게 줄입니다. 기준선과 비교하여 부정적인 경우 더 낮습니다. 이는 FABRIC이 제공된 피드백을 기반으로 생성 방향을 효과적으로 조절한다는 것을 확인합니다. 5.2 대상 이미지 기반 피드백 선택 이 실험에서 우리는 모든 사람이 같은 선호도를 가지고 있으며 그에 따라 좋아하거나 싫어하는 이미지를 선택한다는 가정에 도전합니다. 대신, 우리는 사용자가 마음속으로 어떤 대상 이미지, 표현하고 싶은 상상의 그림을 가지고 있다고 가정합니다. 이 시나리오를 반영하기 위해, 우리는 AI-아트-공유 플랫폼 prompthero.com에서 프롬프트-이미지 쌍의 데이터 세트를 수동으로 수집합니다. 여기서 사용자는 이미지를 생성하는 데 사용된 프롬프트와 함께 자신이 좋아하는 세대를 게시합니다. 이러한 생존 편향으로 인해, 우리는 공유된 이미지가 주어진 프롬프트에 대한 각 사용자의 창의적 비전을 표현하거나, 보다 일반적으로 사용자의 선호도에 해당한다고 가정하는 것이 적절하다고 주장합니다. 데이터 세트는 공개 GitHub 저장소에서 제공됩니다. 실험하는 동안, 우리는 데이터 세트의 프롬프트를 사용하여 이미지 배치를 생성하고 연관된 대상 이미지와의 CLIP 유사성에 따라 피드백 이미지를 선택합니다. 가장 유사하고 가장 유사하지 않은 이미지는 각각 긍정적 피드백과 부정적 피드백으로 선택됩니다. 데이터 세트의 이미지는 다양한 모델과 설정으로 생성되므로 평가된 모델이 대상 이미지의 정확한 복제본을 생성하지 못합니다. 우리는 SD-1.5와 Dreamlike Photoreal 베이스라인(피드백 없음)을 지정된 대상 이미지와의 유사성 및 배치 내 이미지 다양성 측면에서 일반 FABRIC과 비교합니다. 이 결과는 그림 4에 나와 있습니다. 우리는 둘 다 각각의 베이스라인보다 성능이 뛰어나며, 라운드 2와 3에서 최상의 경우와 최악의 경우 결과를 모두 개선한다는 것을 발견했습니다. 특히 라운드당 최소 유사성은 어떤 종류의 피드백이 도입될 때 베이스라인보다 크게 개선됩니다. 이 실험의 정성적 결과는 부록 A.2에 나와 있습니다. 한국어: https://github.com/sd-fabric/fabricCLIP 유사도 모든 라운드에서 최대 CLIP 유사도 84.-dropout 0.dropout=0.84.0-83.83.082.82.081.581.Round 배치 내 다양성라운드당 배치 내 이미지 다양성라운드 -dropout 0.dropout=0.(a) 대상 이미지에 대한 최상의 CLIP 유사도에 대한 프롬프트 드롭아웃의 효과.(b) 배치 내 이미지 다양성에 대한 프롬프트 드롭아웃의 효과.그림 5: 프롬프트 드롭아웃은 생성 분포에서 더 많은 다양성을 위해 CLIP 유사도를 거래하는 효과적인 방법으로 보입니다.5.3 피드백 일정 조정 주요 부분에서 보고된 실험 외에도 피드백 일정 조정을 조사했습니다.FABRIC의 기본 구성은 모든 노이즈 제거 단계에 피드백을 추가합니다.우리의 연구 결과에 따르면 노이즈 제거 프로세스의 전반부에서 피드백을 제한하면 성능이 크게 향상됩니다. 반면, 노이즈 제거 프로세스의 후반부에만 피드백을 포함하면 성능이 저하됩니다.이로 인해 노이즈 제거 프로세스의 초기 단계에서는 피드백이 유용하지만 세부적인 세부 사항은 대체로 프롬프트에 의해 결정되고 피드백은 도움이 되지 않는다는 가설이 도출됩니다.5.4 프롬프트 드롭아웃으로 다양성 증가 부록 A.2에서 볼 수 있듯이 생성된 이미지의 다양성은 어떤 종류의 피드백이 도입되자마자 빠르게 붕괴됩니다.이는 모달을 참조와 매우 유사한 이미지를 생성하는 쪽으로 밀어붙이는 컨디셔닝 메커니즘 때문일 가능성이 큽니다.그러나 사용자 관점에서 볼 때 이러한 다양성 감소는 향후 반복에서 새롭고 더 나은 결과를 발견하는 것을 방해하므로 바람직하지 않습니다.우리는 프롬프트 드롭아웃, 즉 어느 정도 확률을 가지고 프롬프트의 모든 단어를 삭제하여 이러한 붕괴에 대처할 수 있는 한 가지 가능한 접근 방식을 조사합니다. 섹션 5.2와 동일한 설정을 사용하여 대상에 대한 최상의 CLIP 유사도와 p = 0.3의 프롬프트 드롭아웃을 사용한 경우와 사용하지 않은 경우(p = 0.0)의 배치 내 이미지 다양성을 비교합니다. CLIP 유사도와 다양성 간에 직접적인 상충 관계가 있음을 발견했습니다. p 0.3은 다양성을 상당히 증가시키지만 전체적으로 더 나쁜 이미지를 생성합니다. 특히 초기 다양성이 증가하면 피드백 이미지의 다양성도 증가하는데, 이는 3라운드 후에도 p = 0.3의 다양성이 p = 0.0의 초기 다양성보다 높은 이유를 설명할 수 있습니다. 더 다양한 피드백 덕분에 프롬프트 드롭아웃은 충분한 피드백이 제공되면 기준선을 따라잡을 수 있을 것입니다. = 6 토론 제한 사항 FABRIC은 실험에서 잘 작동하지만 몇 가지 제한 사항이 있습니다. FABRIC은 생성 분포를 선호하는 결과의 하위 집합으로 제한하는 데 효과적이지만 모델에서 제공한 초기 텍스트 조건 분포를 넘어 분포를 확장하는 데 어려움을 겪는다는 것을 알았습니다. 특히 피드백은 이미 모델의 출력에서 샘플링되므로 이러한 단점을 극복하기 위해 추가 수정이 필요할 것입니다.같은 이유로 생성된 이미지의 다양성은 피드백 이미지에 가까운 단일 모드로 빠르게 붕괴됩니다.가능한 해결책으로 프롬프트 드롭아웃을 제안하지만, 프롬프트에서 중요한 단어를 삭제하고 세대를 완전히 변경할 위험이 있습니다.또 다른 제한은 피드백을 수집하는 방식에 있습니다.현재는 사용자가 이미지에 대한 이진 선호도만 제공할 수 있으므로 이미지 생성 프로세스에서 특정 컨디셔닝을 허용하지 않습니다.향후 작업 향후 작업에서는 다양성을 높이거나 일반적으로 보다 원칙적인 방식으로 탐색-활용 트레이드오프를 제어하는 방법을 조사할 것입니다.이에 대한 흥미로운 방법은 외부 이미지 코퍼스(예: 사용자가 이전에 좋아했던 이미지 또는 일반적인 고품질 이미지 코퍼스)에서 후보 이미지를 검색하여 피드백 루프의 시드로 사용하는 것입니다. FABRIC의 가장 큰 장점은 체크포인트, LORA 가중치와 같은 대부분의 다른 안정적 확산 변화에 대한 직교성으로, 텍스트 컨디셔닝을 수정하거나 대체하는 동시에(Xu et al. (2023)) 이를 기반으로 상당한 개선을 이룬다는 것입니다(FABRIC + LoRA 참조). 궁극적으로는 좋아하거나 싫어하는 각 이미지에 대한 정확한 가중치를 지정하고 다소 거친 특징이나 세밀한 특징이 각각 좋아하거나 싫어하는지 평가할 수 있습니다. 이 방향으로의 잠재적인 개선 사항 중 하나는 사용자 선호도가 이미지의 구조 또는 스타일을 기반으로 표현되는지 여부를 지정하는 것입니다. 이러한 구분을 통해 이미지 생성 프로세스에서 보다 구체적인 컨디셔닝이 가능합니다. 또한 FABRIC은 생성된 결과에 영향을 줄 수 있는 다양한 매개변수가 있는 잘 정의된 동작 공간을 제공합니다. 이를 통해 임의의 목적(예: 직접적인 사용자 피드백 또는 선호도 모델에서 제공하는 점수)에 대한 베이지안 최적화를 수행할 수 있는 길이 열립니다. 7
--- CONCLUSION ---
우리는 반복적 피드백을 텍스트-이미지 모델의 생성 프로세스에 통합하여 주의 기반 참조 이미지 컨디셔닝을 활용하는 훈련 없는 방법인 FABRIC을 제시합니다. 우리의 실험 결과는 FABRIC이 인간의 선호도 및 지정된 대상 이미지와의 유사성과 같은 다양한 목적 함수를 암묵적으로 최적화할 수 있음을 시사합니다. 이러한 목적은 피드백 라운드가 많을수록 눈에 띄게 개선되어 FABRIC의 효과가 추가 피드백을 제공하지 않고 단순히 더 많은 이미지를 샘플링하는 것보다 훨씬 뛰어나다는 것을 보여줍니다. 놀랍게도 훈련이나 하이퍼파라미터 튜닝 없이도 FABRIC은 관련 메트릭에서 인간의 선호도를 최적화하도록 명시적으로 훈련된 모델인 HPS LORA보다 성능이 우수할 수 있습니다. 주목할 점은 FABRIC이 탐색을 활용으로 바꾸는 경향이 있으며, 종종 몇 번의 피드백 라운드 후에 균일한 분포로 붕괴됩니다. 우리는 이러한 붕괴를 완화하기 위한 몇 가지 전략을 검토했지만 이러한 상충 관계에 대한 추가 조사는 향후 작업의 전망으로 남아 있습니다. 반복적 설정은 생성적 시각적 모델이 실제로 사용되는 방식에 가장 중요합니다. 그럼에도 불구하고 텍스트-이미지 모델을 정렬하는 최근 연구는 대체로 탐구되지 않은 채로 남아 있습니다. 이 연구는 이 설정을 해결하기 위한 방법론을 고안하고 평가하는 데 도움이 되는 프레임워크를 형성하는 데 기여한다고 믿습니다. 윤리적 의미 텍스트-이미지 모델은 예술적 기술이나 기술적 전문성이 없는 개인이 시각적으로 매력적인 콘텐츠를 생성할 수 있도록 함으로써 모든 사람이 창의적인 시각적 표현을 보다 쉽게 접할 수 있도록 할 수 있는 잠재력이 있습니다. 제안하는 방법은 사용자 선호도를 이미지 생성 프로세스에 통합하여 이러한 모델의 접근성과 개인화를 더욱 향상시키는 것을 목표로 합니다. 이는 긍정적 및 부정적 피드백을 활용하여 사용자가 이전 이미지 또는 이전에 생성된 이미지를 기반으로 자연스럽고 직관적인 안내를 제공할 수 있도록 함으로써 달성됩니다. 이 접근 방식을 채택함으로써 사용자는 생성된 콘텐츠에 대한 제어력을 높여 윤리적 사용을 촉진합니다. 그러나 이러한 강화된 제어는 시스템의 오용 또는 남용 가능성에 대한 우려도 제기합니다. 이러한 우려를 해결하기 위해 커뮤니티와 사회 전체가 이러한 시스템의 합법적이고 윤리적인 활용에 대한 명확한 지침을 수립하는 것이 중요해집니다. 각 사용자에게 책임감 있고 윤리적인 사용을 보장하기 위한 책임을 부여함으로써, 위험을 완화하고 창의적 표현을 위한 긍정적이고 건설적인 환경을 조성할 수 있습니다.참고문헌 Andrew Brock, Jeff Donahue, Karen Simonyan. 고충실도 자연 이미지 합성을 위한 대규모 gan 훈련, 2019. Kelvin CK Chan, Xintao Wang, Xiangyu Xu, Jinwei Gu, Chen Change Loy. Glean: 대용량 인자 이미지 초고해상도를 위한 생성적 잠재 은행, 2020. Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, Christopher Ré. Flashattention: io-awareness를 통한 빠르고 메모리 효율적인 정확한 주의, 2022. Ying Fan, Olivia Watkins, Yuqing Du, Hao Liu, Moonkyung Ryu, Craig Boutilier, Pieter Abbeel, Mohammad Ghavamzadeh, Kangwook Lee, Kimin Lee. Dpok: 텍스트-이미지 확산 모델 미세 조정을 위한 강화 학습, 2023. Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit Haim Bermano, Gal Chechik, Daniel Cohen-or. 이미지는 단어 하나의 가치가 있다: 텍스트 역전을 사용하여 텍스트-이미지 생성 개인화. 제11회 학습 표현 국제 컨퍼런스, 2023. URL https://openreview.net/forum?id=NAQvF08TcyG. Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio. 생성적 적대 네트워크, 2014. Jonathan Ho와 Tim Salimans. 분류자 없는 확산 안내, 2022. Jonathan Ho, Ajay Jain, Pieter Abbeel. 확산 확률적 모델의 노이즈 제거, 2020. Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen. Lora: 대규모 언어 모델의 저순위 적응, 2021. Diederik P Kingma와 Max Welling. 자동 인코딩 변분 베이즈, 2022. Yuval Kirstain, Adam Polyak, Uriel Singer, Shahbuland Matiana, Joe Penna, Omer Levy. Pick-apic: 텍스트-이미지 생성을 위한 사용자 선호도의 오픈 데이터 세트, 2023. Alexandra Sasha Luccioni, Christopher Akiki, Margaret Mitchell, Yacine Jernite. 안정적 편향: 확산 모델에서 사회적 표현 분석. arXiv 사전 인쇄본 arXiv:2303.11408, 2023. Ron Mokady, Amir Hertz, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or. 유도 확산 모델을 사용하여 실제 이미지를 편집하기 위한 널 텍스트 반전, 2022. Taesung Park, Ming-Yu Liu, Ting-Chun Wang, and Jun-Yan Zhu. 공간적으로 적응적인 정규화를 사용한 의미적 이미지 합성, 2019. Markus N. Rabe and Charles Staats. 자기 주의는 o(n²) 메모리가 필요하지 않습니다, 2022. Alec Radford, Luke Metz, and Soumith Chintala. 딥 컨볼루션 생성적 적대 신경망을 사용한 비지도 표현 학습, 2016. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever. 자연어 감독을 통한 전이 가능한 시각적 모델 학습, 2021. Ali Razavi, Aaron van den Oord, Oriol Vinyals. vq-vae-2를 사용한 다양한 고화질 이미지 생성, 2019. Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, Honglak Lee. 생성적 적대 텍스트에서 이미지 합성, 2016. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer. 잠재 확산 모델을 사용한 고해상도 이미지 합성, 2022. Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, Kfir Aberman. Dreambooth: 주제 중심 생성을 위한 텍스트-이미지 확산 모델 미세 조정, 2023. Kihyuk Sohn, Nataniel Ruiz, Kimin Lee, Daniel Castro Chin, Irina Blok, Huiwen Chang, Jarred Barber, Lu Jiang, Glenn Entis, Yuanzhen Li, Yuan Hao, Irfan Essa, Michael Rubinstein, Dilip Krishnan. Styledrop: 모든 스타일의 텍스트-이미지 생성, 2023. Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, Ben Poole. 확률적 미분 방정식을 통한 점수 기반 생성 모델링, 2021. Zhiwei Tang, Dmitry Rybin, Tsung-Hui Chang. 0차 최적화가 인간의 피드백을 충족: 순위 오라클을 통한 증명 가능한 학습, 2023. Xiaoshi Wu, Keqiang Sun, Feng Zhu, Rui Zhao, Hongsheng Li. 인간의 선호도에 따라 텍스트-이미지 모델을 더 잘 정렬. ArXiv, abs/2303.14420, 2023. Xingqian Xu, Jiayi Guo, Zhangyang Wang, Gao Huang, Irfan Essa, Humphrey Shi. 프롬프트 없는 확산: 텍스트-이미지 확산 모델에서 &quot;텍스트&quot; 제거, 2023. . Lvmin Zhang. [주요 업데이트] 참조 전용 제어 · Mikubill/sd-webui-controlnet · 토론 #1236, 2023. URL https://github.com/Mikubill/sd-webui-controlnet/discussions/1236. 부록 A. 메서드 세부 정보 여기에서 FABRIC 알고리즘의 의사 코드를 제공합니다(알고리즘 0 참조). พ 가중 주의, (Q, K, V) = (~, พ ○ softmax || w ||(②KT)) VT (2) A.2 타겟 이미지 기반 피드백 선택 예제 여기서는 promthero 데이터 세트에서 몇 가지 피드백 궤적 예제를 제공합니다. 그림 A.3 FABRIC 워크플로 그림 7에서는 FABRIC의 고수준 워크플로를 보여줍니다. 알고리즘 1 FABRIC: 주의 기반 참조 이미지 조절을 통한 피드백 필요 사항: N은 피드백 라운드 수이고, n은 각 라운드에서 생성된 이미지의 배치 크기이며, 모델은 참조 조절이 가능한 확산 모델입니다. 1: FABRIC 프로시저 2: pos, neg · [], [] 3: i = {1,..., N}에 대해 do 4: prompt get_prompt(i) 5: images [GENERATE(prompt, pos, neg) for n times] 6: Xpos, neg get_feedback(images) 7: pos.put(xpos) 8: 9: ▷ 우리는 하나의 좋아요와 하나의 싫어요에 집중합니다 neg.put(xneg) end for 10: end procedure 11: GENERATE(prompt, positives, negatives) for t = {T, ………, 1} do hiddens {} for xref = {... positives, ... negatives} do Zref√√āt xref + √√1 − āt· € (t) . Cref ▷ 전방 확산 노이즈, e ref ~N(0,1) h← PRECOMPUTEHIDDENSTATES (Zref, t) hiddens.put(h) 12: ZT = initial_noise() 13: 14: 15: 16: 17: 18: 19: end for 20: 21: 22: 23: 24: end for 25: return zo (t) 피드백 설정에 따라 who와 who를 계산합니다.(t) Єcond,t-1 ← MODIFIEDUNET(zt, t, get_positive(hiddens), wptos) (t) Euncond,t-1 ← MODIFIEDUNET(zt, t, get_negative(hiddens), weg) Zt-1 step_with_cfg(zt, Єcond,t, uncond,t) ▷ 조상 우리의 경우 Euler 샘플링 26: 함수 종료 27: 함수 PRECOMPUTEHIDDENSTATES(z, t) hiddens [] Unet의 i번째 층에 대해 z에 ResNet 블록을 적용합니다.hiddens.put(i, z) 28: 29: 30: 31: 32: 33: 34: 종료 35: z를 반환합니다.z에 셀프 어텐션을 적용합니다.z에 크로스 어텐션과 FFN을 적용합니다(셀프 어텐션 바로 앞) ▷ hiddens에 대해 36: 함수 종료 37: 함수 MODIFIED UNET(z, t, hiddens, w) 38: 39: 40: 41: 42: 43: 44: 45: 46: 47: Unet의 i번째 층에 대해 hhiddens.at(i) z에 ResNet 블록을 적용합니다.Q+W().z KWconcat(z, h) V← W().concat(z, h) z WeightedAttention (Q, K,V) z end에 교차 어텐션과 FFN을 적용하여 z 48을 반환합니다. end function= 이 함수는 표준 U-Net 대상 이미지 라운드입니다. 라운드 k 그림 6: 대상 이미지 기반 실험의 피드백 라운드 예. 어텐션 기반 참조 이미지 컨디셔닝을 통한 피드백 Unet 레이어 III × 1. 조건부 노이즈 제거 단계 × 0.8 × 일정 그림 7: FABRIC: 참조 이미지에 특정 단계까지 노이즈를 처리하고, 추출된 키와 값은 노이즈 제거 프로세스 중에 U-Net의 셀프 어텐션에 주입됩니다.
