--- ABSTRACT ---
생성된 텍스트와 자연스러운 텍스트를 구별하는 것은 점점 더 어려워지고 있습니다. 이러한 맥락에서 워터마킹은 텍스트를 특정 생성 모델에 귀속시키는 유망한 기술로 부상하고 있습니다. 이는 샘플링 생성 프로세스를 변경하여 출력에 보이지 않는 흔적을 남겨 나중에 감지하기 쉽게 합니다. 이 연구는 세 가지 이론적 및 경험적 고려 사항을 기반으로 대규모 언어 모델에 대한 워터마크를 통합합니다. 첫째, 낮은 거짓 양성률(106 미만)에서도 유효한 강력한 이론적 보장을 제공하는 새로운 통계적 테스트를 도입합니다. 둘째, 자연어 처리 분야의 고전적 벤치마크를 사용하여 워터마크의 효과를 비교하여 실제 적용 가능성에 대한 통찰력을 얻습니다. 셋째, LLM에 액세스할 수 있는 시나리오와 다중 비트 워터마킹에 대한 고급 감지 체계를 개발합니다. 색인 용어-워터마킹, 대규모 언어 모델 I.
--- INTRODUCTION ---
ChatGPT [1], Claude [2] 또는 오픈 소스 LLAMA [3]와 같은 대규모 언어 모델(LLM)의 오용은 가용성과 기능이 확장됨에 따라 위협이 될 수 있습니다 [4][6]. LLM은 대규모로 허위 정보를 퍼뜨리는 데 드는 비용을 줄임으로써 가짜 뉴스를 생성하는 데 도움이 될 수 있으며 [7], [8], 여론과 민주적 결과에 잠재적인 영향을 미칠 수 있습니다 [9]. LLM은 사람을 사칭하거나 사기를 조장하거나 [10] 학생 평가를 불가능하게 만들 수 있습니다. 규정과 기술적 수단을 통해 공정하고 책임감 있는 사용을 시행하는 것이 유용할 것입니다. 수동 포렌식으로 LLM 사용을 모니터링하는 것은 생성된 텍스트가 사람이든 알고리즘이든 실제 텍스트와 거의 구별되지 않기 때문에 어렵습니다 [11], [12]. 워터마킹은 생성 이미지 모델 [13]–[15] 및 생성 텍스트 LLM [16]-[19]에 대해 탐색되는 유망한 기술입니다. 이 경우 워터마킹은 샘플 생성 프로세스[16], [19]를 변경하거나 생성된 토큰의 확률 분포[17]를 변경하여 생성된 텍스트에 눈에 띄지 않는 흔적을 남깁니다. 그런 다음 이 문헌은 생성된 토큰을 분석하여 분포가 워터마크로 유도된 분포를 따르는지 확인하는 감지 메커니즘을 설명합니다. 현재 문헌을 통합하기 위해 다음 단락과 섹션 각각에 대해 하나씩 세 가지 기여를 소개합니다. 각 부분은 독립적으로 읽을 수 있습니다. 첫째, 거짓 양성은 결과의 무결성과 정확성이 필수적인 맥락에서 심각한 결과를 초래할 수 있습니다. 예를 들어 사용자가 가짜 뉴스를 제작했다고 거짓 비난하거나 학생이 시험에서 부정행위를 했다고 거짓 비난하는 것과 같습니다. 그러나 현재의 접근 방식[17], [18]은 연구를 민감도(진양성률: TPR)에 집중합니다.메일: pierre.fernandez@inria.fr - 코드: facebookresearch/three_bricks/ 해싱 시드 RNG 워터마크 컨텍스트 x(-h)x(-2)x(-1) ☐ LLM 컨텍스트 샘플 로짓 1= (1,...) x(0) 생성 감지 시드 RNG 워터마크 컨텍스트 LLM 해싱 x(0) x (1)... x(h) x (h+1)... x(T) 현재 토큰 점수 그림 1: LLM에 대한 워터마킹의 일반적인 설명(위: 생성, 아래: 감지). 세부 정보 및 표기법은 특이성(FPR: 거짓양성률과 연결됨)이 아닌 섹션 II-B에 있습니다.FPR은 흥미로운 척도(1,000개 이상의 부정적 예)에서 경험적으로 확인된 적이 없습니다. 대규모 실험 결과, 이전 연구의 가설은 성립하지 않으며, 감지 임계값이 낮은 FPR에서 거짓 양성을 크게 과소평가한다는 사실이 밝혀졌습니다. 이 연구는 이론적으로 거짓 양성률과 실제 환경에서 정확한 p값을 보장하는 근거 있는 통계적 테스트를 제공합니다. 이를 경험적으로 검증하고 낮은 값(&lt; 10-6)에서도 FPR을 거의 완벽하게 제어할 수 있음을 보여줍니다. 둘째, 워터마킹 방법을 비교하여 기존 자연어 처리(NLP) 벤치마크에 대한 워터마크의 실제적 의미를 분석합니다. 실제로 현재 워터마크 평가는 주로 원래 LLM 분포와의 편차를 고려합니다(예: 퍼플렉시티 사용). 이는 LLM 문헌과 대조되는데, LLM 문헌에서는 모델이 효과적인 유용성(예: 질문 답변과 같은 자유형 완성 작업)에 따라 평가됩니다. 이러한 평가는 다운스트림 작업에 사용될 때 모델의 실제 능력에 대해 훨씬 더 많은 정보를 제공합니다. 셋째, 이러한 알고리즘을 고급 감지 체계로 확장합니다. 감지 시점에 LLM에 액세스할 수 있는 경우 최적의 통계적 테스트를 제공합니다. 영어: 또한 현재 접근 방식이 0비트 워터마킹만 처리하는 경우 다중 비트 워터마킹(워터마크로 바이너리 메시지를 숨김)을 조사합니다.이를 통해 텍스트가 워터마크가 있는 LLM에서 생성되었는지 확인할 수 있을 뿐만 아니라 어떤 버전의 모델에서 생성했는지 식별할 수도 있습니다.II. 기술적 배경 A. 대규모 언어 모델(LLM) LLM은 컨텍스트가 주어졌을 때 토큰 시퀀스를 생성할 가능성을 계산하여 텍스트를 생성하는 신경망입니다[21].이 논문은 디코더 전용 모델, 즉 자기 회귀 LLM에 초점을 맞춥니다.토큰은 어휘 V의 단어 조각입니다.컨텍스트 x (-C), x(-1)에서 모델은 V의 각 토큰이 다음 토큰일 확률을 추정합니다.로짓의 벡터 RV를 계산하여 Є (P (X(0) = x|x(-),...,x(-1))) ZEV ·(−1))) rey = softmax(l;0) (1)로 변환합니다.여기서 는 온도입니다. 컨텍스트에서 시퀀스를 생성하면 이 분포에서 토큰을 샘플링한 다음 컨텍스트에 추가하고 프로세스를 반복합니다.탐욕적 검색, 빔 검색, 상위 k 샘플링[22], [23], 핵 샘플링(상위 p)[24] 등 다양한 샘플링 방식이 있습니다.B. 워터마킹 텍스트 생성 1) 분포 수정[17], [18], [20]: 원래 분포(1)는 약칭 p로 표시되며 k가 비밀 키이고 F가 임의의 함수인 유사한 분포 q F(p, k)로 대체됩니다.Kirchenbauer 등의 작업[17]에서 비밀 키는 V = Gk Uk의 분할을 결정합니다.greenlist Gk에는 y = [0,1]인 7|V| 토큰이 포함됩니다.greenlist의 모든 토큰의 로짓은 8 &gt; 0만큼 증가하고 softmax 연산자는 q를 출력합니다.그런 다음 샘플링은 평소와 같이 진행됩니다. 직관적으로, 이는 그린리스트 토큰을 생성할 확률을 높입니다.반면에, E[F(p, K)] = p 이므로 암호화 키 집합에 대한 기대치에 따라 워터마킹은 단어의 전역 분포에 편향을 주지 않습니다(K는 키를 나타내는 확률 변수).탐지는 텍스트를 토큰화하고 그린리스트에 있는 토큰의 수를 계산합니다.더 공식적으로, T개 토큰의 텍스트에 대해 점수 ST는 그린리스트 토큰의 수입니다(x(t)와 k(t)는 각각 t번째 토큰과 키를 나타냄): T ST=1 (2) €).Σι (t)).t=1/pv 2) 샘플링 수정 [16], [19]: 워터마크 임베딩은 결정론적 프로세스로 기존 샘플링 방식을 대체합니다.예를 들어, Aaronson et al. [16] x(0) = arg maxvЄV rv를 계산하여 다음 토큰을 선택합니다.여기서 p¹는 분포(1)이고 r = [0,1] V는 비밀 키 k에서 생성된 비밀 벡터입니다.직관적으로, 이는 높은 r₁ 및 pv 값을 모두 갖는 토큰 생성을 장려합니다.또한 [0,1] ||에 균일하게 분포될 때 비밀 벡터의 무작위성에 대해 Vv Є V, P(X(0) = v) = P₁라는 흥미로운 속성을 나타냅니다(부록 A의 데모).다시 말해, 이 워터마킹은 비밀 벡터에 대한 기대에 대한 분포를 편향시키지 않습니다.탐지는 T개 토큰에 대해 다음 점수를 계산합니다.ST T -Σ(1-r%).t=x(t) 1 (핵 샘플링은 p를 생성하기 전에 적용될 수 있음) (3) C. 품질-견고성 트레이드오프 두 방법 모두 워터마킹 강도를 변경하여 생성 품질과 견고성을 트레이드오프할 수 있습니다. [17]에서 ♪ 매개변수를 늘리면 가능성이 낮은 토큰이 포함될 위험이 있지만 녹색 토큰 생성이 늘어납니다.[16]에서 온도 0을 늘리면 확률 벡터(1)가 평평해져 rv에 대한 p₁의 상대적 중요도가 감소하므로 동일한 효과가 있습니다.D. 키 관리 [17]에서 녹색리스트 Gk를 생성하거나 [16]에서 r을 샘플링하는 비밀 키 k는 광범위한 다양성을 가져야 합니다.고정 키는 보안 문제를 일으키고 텍스트 생성에 편향을 일으킵니다.한 가지 가능성은 [19]에서 제안한 것처럼 시간 t에 따라 달라지게 하는 것입니다.그러면 비밀 키는 토큰마다 다릅니다.그러나 이렇게 하면 감지 단계에서 동기화 문제가 발생합니다(예: 문장이 삭제될 때).그림 1에 나와 있는 자체 동기화를 보장하는 일반적인 관행은 키를 h개의 이전 토큰 창에 따라 달라지게 합니다.k(t)H(x(t−1) ., x(th), k), 여기서 H는 암호화 해시 함수이고 k는 마스터 키입니다. 이 비밀은 시간 t에서 난수 생성기(RNG)를 초기화하는 시드입니다. 차례로, RNG는 그린리스트 Gk(t)를 생성하거나 r(t)를 샘플링하는 데 사용됩니다. 이 창의 너비는 키의 다양성과 워터마킹의 견고성 간의 균형을 정의합니다. h 0인 특정한 경우, 키는 모든 토큰에 대해 동일합니다(k(t) = k). 이는 워터마킹을 텍스트 편집에 특히 견고하게 만듭니다[25]. E. Z-테스트 = 탐지는 가설 Ho: &quot;텍스트가 자연스럽습니다&quot;(인간이 쓴 것 또는 워터마크 없이 쓴 것)를 H₁: &quot;텍스트가 워터마크와 함께 생성되었습니다&quot;에 대해 테스트합니다. 현재 접근 방식[16], [17]은 Z-테스트를 사용하여 점수 ST의 기본 분포를 근사합니다. 이 통계적 가설 테스트는 표준 편차가 알려져 있을 때 표본 평균이 기대치와 크게 다른지 여부를 판별합니다. 이는 소위 Z 통계량을 계산합니다.Z = ST/T-HO 00/√T (4) 여기서 μo 및 σ0는 귀무 가설 Ho 하에서 토큰당 기대값 및 표준 편차입니다.즉, 분석된 텍스트에 워터마크가 없는 경우입니다.Z-검정은 중심 극한 정리 덕분에 귀무 가설 하에서 정규 분포를 가정하여 일반적으로 대규모 표본 크기에 사용됩니다.이 가정은 p-값, 즉 귀무 가설 하에서 관찰된 값 z보다 적어도 극단적인 Z 값을 관찰할 확률을 계산하는 데 중요합니다.p-value(z) = P(Z &gt; z|Ho) = 1 − §(z), (5) 여기서 는 정규 분포의 누적 분포 함수입니다.탐지 시점에 거짓 양성률(FPR)을 고정하고 p-value(z) &lt; FPR인 경우 텍스트를 워터마크가 있는 것으로 표시합니다.경험적 FPR10-10-10-10-10-경험적 FPR10-1110-Aaronson et al. 10-Kirchenbauer 등.10-이론적 FPR 10-4 10-10-10-10-(a) Z-검정 Aaronson 등.Kirchenbauer 등.10-10-이론적 FPR (b) III-B의 검정 경험적 FPR 10-시드 시딩 시 컨텍스트 폭:10-Aaronson 등.Kirchenbauer 등.10-10-10-이론적 FPR 10-(c) III-C로 수정된 III-B의 검정 그림 2: 다양한 워터마크와 컨텍스트 폭 h의 값에 대한 거짓 양성률의 경험적 확인.결과는 Wikipedia에서 샘플링한 256개 토큰의 100k 시퀀스 × 오버마스터 키로 계산한 것입니다.다음 세 가지 탐지 검정을 비교합니다.(왼쪽) Z-검정 사용;(가운데) III-B에 제시된 새로운 통계적 검정 사용; (오른쪽) III-C의 수정된 채점 전략을 사용한 새로운 통계적 검정 사용. 이론적 값은 h 값이 높은 경우에도 Z 검정에 실제로 적용되지 않으며 경험적 FPR은 이론적 값과 일치하지 않습니다. 이는 근거 있는 통계적 검정 및 분석적 p 값을 기반으로 탐지를 수행하고 채점 전략을 수정하여 해결합니다. III. 탐지의 신뢰성 이 섹션에서는 FPR의 대규모 평가가 이론과 실제 간의 차이를 보여줍니다. 새로운 통계적 검정과 채점 방법을 수정하여 이 차이를 메웁니다. A. Z 점수를 사용한 FPR의 경험적 검증 지금까지 FPR은 약 음성 샘플에서만 확인되었습니다[17], [18], [20]. 이를 더욱 확장하여 다국어 위키피디아에서 100,000개의 텍스트를 선택하여 자연스러운 텍스트의 분포를 포함합니다. LLAMA의 토크나이저로 토큰화하고 T = 256개의 토큰/텍스트를 사용합니다. RNG를 시딩할 때 다양한 윈도우 길이 h로 탐지 테스트를 실행합니다. 10개의 다른 마스터 키로 이를 반복하면 각 방법과 h 값에 대해 Ho에서 1M 탐지 결과가 나옵니다. 그린리스트 워터마크 탐지의 경우 Y = 0.25를 사용합니다. 그림 2a는 경험적 FPR과 이론적 FPR을 비교합니다. 이론적 보장은 실제로 유지되지 않습니다. 경험적 FPRS가 이론적 FPRS보다 훨씬 높습니다. 또한 p 값의 분포가 균일하지 않은 것을 관찰했습니다(Ho에서 그래야 함). 게다가 워터마킹 컨텍스트 윈도우 h가 클수록 이론적 보장에 더 가까워집니다. 실제로 신뢰할 수 있는 p 값을 얻으려면 h &gt;&gt; 8이 필요하지만 이렇게 하면 동기화에 영향을 미치기 때문에 생성된 텍스트에 대한 공격에 대한 워터마킹 방법이 덜 강력해집니다. B. 새로운 비점근적 통계적 테스트 Z-테스트의 가우스 가정은 짧거나 반복적인 텍스트에서는 무너집니다. 다음은 두 방법에 대한 비점근적 검정으로, 특히 그림 2에서 보인 것처럼 낮은 FPR 값에서 경험적 FPR과 이론적 FPR 간의 격차를 줄이는 데 유용합니다.1) Kirchenbauer et al.[17]: Ho에서 이벤트 x(t) = k(t)가 확률 Y로 발생하고 이러한 이벤트가 iid라고 가정합니다.따라서 ST(2)는 매개변수 T와 y의 이항 분포를 따릅니다.점수가 s인 검토 대상 텍스트를 고려합니다.p 값은 Ho에서 s보다 높은 점수를 얻을 확률로 정의됩니다.p 값(s) = P(ST &gt; s|Ho) = I√(s, T − s + 1), (6) cdf가 Ix(a, b)로 표현되는 SB(T,)이기 때문입니다.정규화된 불완전 베타 함수.~ 2) Aaronson et al. [16]: Ho에서 우리는 조사 대상 텍스트와 비밀 벡터가 독립적이라고 가정하므로 rx(t) U(0, 1)입니다. 따라서 ST(3)은 г(T, 1) 분포를 따릅니다. 점수 s와 관련된 p 값은 다음과 같습니다. iid ~ p-값(s) = P(ST &gt; s|Ho) : г(T, s) F(T) (7) 여기서 I는 상부 불완전 감마 함수입니다. H1에서 점수는 App. A에서 증명된 대로 더 높을 것으로 예상되므로 p 값은 작을 가능성이 높습니다. C. 감지 점수 수정 근거 통계적 검정을 사용하더라도 경험적 FPR은 여전히 이론적 FPR보다 높습니다. 사실, Kirchenbauer et al. [17]은 반복되는 창이 동일한 비밀을 생성하기 때문에 난수 변수는 의사 난수일 뿐이라고 언급합니다. 이는 짧은 텍스트에서도 발생할 수 있으며 특히 형식화된 데이터에서 발생할 수 있습니다. 예를 들어, 글머리 기호 목록에서 토큰 \n\n* _ 시퀀스는 그림 3에서와 같이 많이 반복됩니다. 반복은 p-값을 계산하는 데 필요한 독립성 가정을 무너뜨립니다. 우리는 탐지 단계에서 이 문제를 완화하는 두 가지 간단한 휴리스틱을 실험했습니다. 첫 번째는 탐지 중에 워터마크 컨텍스트 창이 아직 보이지 않은 경우에만 토큰을 고려합니다. 두 번째는 {워터마크 컨텍스트 + 현재 토큰}으로 형성된 h + 1-튜플이 아직 보이지 않은 토큰에 점수를 매깁니다. 후자는 [17]에 있지만 절제되지 않고 Nes oth rips는 Ph la e oth rip idae과에 속한 th rips의 속입니다. \n \n ## 종 \n \n * N es oth rips a lex andra e \n * N es oth rips a orist us \n * N es oth rips ar to car pi \n * N es oth rips bad ius \n * N es oth rips bar row i \n * N es oth rips bre vic oll is \n * N es oth rips brig al owi \n * N es oth rips cap ric orn is \n * N es oth rips car ver i \n * N es oth rips co or ong i \n 그림 3: 반복 토큰으로 인해 p-값이 낮은 바닐라 텍스트의 일반적인 예. 256개 토큰에서 y = 1/4, h = 2인 그린리스트 워터마크를 사용하여 10-21입니다(텍스트의 절반만 표시). 표 I: 워터마킹으로 완료했을 때의 클래식 자유형 생성 벤치마크 성능. h는 워터마크 컨텍스트 너비입니다. 다음 방법에 대한 결과를 보고합니다. Aaronson et al. [16] / Kirchenbauer et al. [17]. &quot;-&quot;는 워터마킹 없음을 의미합니다. GSM8K Human Eval MathQA 모델 h 7B MBPP NQ TQA 평균 10.10.3 / 11.10.4 / 10.12.12.8/9.12.8/9.13B 17.15.17.2 / 17.15.2 / 14.17.2 / 16.15.215.30B 35.35.3 / 35.35.1 / 34.20.20.7 / 20.20.1 / 22.3.2.9 / 2.3.0/2.4.4.3 / 3.4.2 / 4.6.6.9 / 7.6.9/7.18.18.2 / 16.17.8 / 16.23.22.8 / 21.22.6 / 21.21.21.8 / 19.21.8/ 20.56.56.9 / 55.56.9 / 55.20.20.5 / 19.20.419.28.28.2 / 25.28.2 / 24.63.63.6 / 62.63.6 / 62.25.25.2 / 24.25.2 / 24.29.29.6 / 28.29.8 / 28.33.33.5 31.33.5 / 31.70.32.70.0 / 69.70.0 / 68.32.7 / 32.32.6 / 32. 추가 실험에 사용됩니다. 두 가지 중에서 두 번째 것이 더 나은데, 더 많은 ngram을 계산하고 따라서 더 나은 TPR을 갖기 때문입니다. 또한 h = 0의 특정 사례도 처리할 수 있습니다. = 그림 2c는 이미 본 h + 1-튜플을 평가하지 않기로 선택할 때의 경험적 및 이론적 FPRS를 보고합니다. 이제 FPR이 여전히 약간 과소평가된 h O를 제외하고는 완벽하게 일치합니다. 간단히 말해, 새로운 통계적 테스트와 {워터마크 컨텍스트 + 현재 토큰}이 평가되지 않은 토큰만 평가하여 FPR을 보장합니다. IV. 워터마크 평가 이 섹션에서는 개정된 통계적 테스트를 통한 평가를 소개하고 LLM 워터마킹이 기존 NLP 벤치마크에 미치는 영향을 조사합니다. A. 견고성 분석 이제 워터마크가 있는 텍스트를 감지할 때 TPR을 분석하여 워터마킹 방법을 비교합니다. 감지를 위해 이전의 통계적 테스트와 점수 매기기 전략을 사용합니다. p-값이 10-5보다 낮으면 텍스트를 워터마크로 표시하여 FPR=10-5를 보장합니다. 이러한 실험의 경우 챗봇 시나리오에 가깝게 유지합니다. 우리는 Alpaca 데이터 세트[27]의 첫 번째 1k 프롬프트를 사용하여 LLAMA의 미세 조정된 명령어 버전인 Guanaco-7b[26]를 프롬프트합니다. 생성을 위해 p = 0.95인 top-p 샘플링을 사용하고 [17]의 경우 온도 0 = 0.8 및 y = 1/4를 사용합니다. 우리는 확률 0으로 토큰을 무작위로 대체하여 동의어 공격을 시뮬레이션합니다.(다른 공격은
--- RELATED WORK ---
[18]). 표 II는 워터마크의 다양한 강도에 대한 TPR(섹션 II-C 참조)과 워터마크가 있는 생성된 텍스트와 없는 생성된 텍스트 간의 S-BERT [28] 유사도 점수를 보고하여 워터마크로 인한 의미적 왜곡을 측정합니다. 표 II의 결과는 다른 동작을 보여줍니다. 예를 들어, [17]은 워터마크 강도와 품질 간의 균형을 더 세밀하게 제어합니다. TPR 값은 0.0~0.9인 반면 [16]은 더 일관적이지만 S-BERT 점수가 많이 저하된 경우에도 0.8보다 높은 TPR을 달성하지 못합니다. 워터마크 컨텍스트 너비도 큰 영향을 미칩니다. 그의 낮음에서 생성이 토큰의 특정 반복에 쉽게 편향되기 때문에 반복이 더 자주 발생하는 것을 관찰했습니다. 이는 평균 S-BERT 점수가 0.5 미만이고 완성이 사용 불가능하게 됩니다. 반면에 낮은 h는 특히 [17]의 경우 워터마크를 더 강력하게 만듭니다. 또한 h가 워터마크의 수에 영향을 미친다는 점도 주목해야 합니다.표 II: 수정된 통계적 테스트를 통한 워터마크의 견고성 분석.우리는 TPR@FPR=10¯5와 워터마크의 강도를 제어하는 다양한 하이퍼파라미터([17]에서 8, [16]에서 0 - 섹션 II-C 참조)에 대해 10 × 1k 완료에 대한 S-BERT 점수를 보고합니다.&#39;TPR 증가&#39;는 토큰을 확률 0.3으로 무작위로 대체하여 텍스트가 감지되기 전에 공격을 받았을 때의 TPR입니다.Kirchenbauer et al.[17] 8: 1.0 2.3.0 4.0.63 0.61 0.57 0.0.00 0.16 0.58 0.0.00 0.02 0.20 0.h 메트릭 S-BERT TPR 0 : 0.TPR 증가 Aaronson et al. [16] 0.9 1.0 1.0.60 0.56 0.52 0.0.20 0.31 0.42 0.0.04 0.06 0.09 0.S-BERT 0.62 0.61 0.0.TPR TPR 증가.S-BERT TPR TPR 증가. 0.35 0.51 0.66 0.0.04 0.10 0.20 0.0.62 0.62 0.61 0.0.43 0.59 0.71 0.0.01 0.02 0.06 0.0.63 0.62 0.60 0.0.02 0.41 0.77 0.0.00 0.05 0.30 0.0.62 0.62 0.60 0.0.02 0.44 0.76 0.0.00 0.00 0.03 0. 분석된 토큰의 경우 h+ 1-튜플이 이전에 확인되지 않은 토큰에 대해서만 점수를 매기기 때문입니다(섹션 III-C 참조). h가 높으면 이러한 튜플의 거의 대부분이 새롭지만, h가 낮으면 튜플이 반복될 가능성이 증가합니다.예를 들어, 우리의 경우, 채점된 토큰의 평균 수는 h = 0의 경우 약 100이고, h = 1 및 h = 4의 경우 150입니다.B. 자유형 생성 작업에 대한 워터마크의 영향 이전 연구에서는 표 II에서 수행된 것처럼 복잡도나 유사도 점수와 같은 왜곡 지표를 사용하여 품질에 대한 영향을 측정합니다.그러나 이러한 지표는 LLM의 실제 관심사가 있는 다운스트림 작업[24]에 대한 모델의 유용성에 대한 정보를 제공하지 않습니다.실제로 LLM에 워터마킹을 하는 것은 매우 정확한 답변이 필요한 작업에 해로울 수 있습니다.이 섹션에서는 워터마킹의 실용성을 평가하기 위해 일반적인 NLP 벤치마크에 미치는 영향을 정량화합니다.LLM은 일반적으로 일반 생성 샘플을 대상 참조 집합(자유형 생성)과 비교하거나 다중 선택형 질문 방식으로 미리 정의된 옵션 집합의 가능성을 비교하여 평가합니다. 후자는 샘플링에만 영향을 미치는 워터마킹의 경우에는 거의 의미가 없습니다.따라서 우리는 평가를 자유형 생성 작업으로 제한합니다.LLAMA의 평가 설정을 사용합니다.1) 폐쇄형 질문 답변(Natural Questions [29], TriviaQA [30]): 5샷 정확 일치 성능을 보고합니다.2) 수학적 추론(MathQA [31], GSM8k [32]), 다수결 투표 없이 정확 일치 성능을 보고합니다.3) 코드 생성(HumanEval [33], MBPP [34]), pass@1 점수를 보고합니다.[17]의 경우 탐욕적 디코딩 전에 d = 1로 로짓을 이동합니다.[16]의 경우 확률 벡터에 0.95에서 top-p를 적용한 다음 워터마크 샘플링을 적용합니다.표 I은 워터마크가 있는 경우와 없는 경우, 그리고 다른 창 크기 h에 대해 앞서 언급한 벤치마크에서 LLAMA 모델의 성능을 보고합니다. LLM의 성능은 워터마킹에 의해 크게 영향을 받지 않습니다. Kirchenbauer et al.(II-B1)의 접근 방식은 Aaronson et al.(II-B2)의 접근 방식보다 약간 더 해롭지만 바닐라 모델과의 차이는 작습니다. 흥미롭게도 이 차이는 모델 크기가 커질수록 줄어듭니다. 생성 기능이 더 높은 모델은 워터마킹의 영향을 덜 받습니다. 가능한 설명은 더 큰 모델의 글로벌 분포가 더 좋고 따라서 작은 섭동에 더 강하다는 것입니다. 전반적으로 다운스트림 작업을 평가하면 워터마킹이 혼란이나 유사도 점수로 잘 포착되지 않는 사실 오류를 유발할 수 있음을 지적합니다. V. 고급 감지 계획 이 섹션에서는 III절의 감지 계획에 대한 개선 사항을 소개합니다. 즉, LLM에 대한 액세스가 허용될 때의 통계적 테스트와 다중 비트 디코딩을 개발합니다. A. Neyman-Pearson 및 단순화된 점수 함수 다음은 Aaronson et al.의 계획에 대한 구체적인 내용입니다. [16] (비슷한 작업이 [18]과 함께 수행될 수 있음). Ho에서 rv U[0,1]인 반면 H₁에서 r₁ Beta(1/pv, 1)입니다(부록 A의 추론(14) 참조). 따라서 최적의 Neyman-Pearson 점수 함수는 다음과 같습니다. T ~ ~ T fH₁ (rx(t)) ST = In = fHo (rx(t)) Px(t) -1) In(rx(t)) + A t=t=여기서 A는 r에 의존하지 않으므로 버릴 수 있습니다. 두 가지 단점이 있습니다. (1) 감지에는 Px(t)를 계산하기 위한 LLM이 필요합니다. (2) p-값에 대한 폐쇄형 공식이 없습니다. 이 마지막 요점은 견고성에 대한 보장 없이 Chernoff 경계에 의지하여 수정할 수 있습니다.p-값(들) ≤ yet &quot; eΣ In-cs c 솔루션 Σ+(c++)-1 = -s 및 At = Px(t)/(1 − Px(t)). 실험 결과 이 감지는 워터마크가 있는 텍스트에 대해 매우 낮은 p-값을 생성하지만 취약합니다.모든 공격은 생성된 로짓이 전체 LLM 컨텍스트에 민감하기 때문에 원래 감지 체계(3) 수준으로 증가시키거나 더 높을 수도 있습니다.대안은 가중치를 제거하는 것입니다.T ST Σ In (rx(t)), t = p-값은 다음과 같습니다.p-값(들) = T(T) (8) Y(T,-s).우리의 실험에서 이 점수 함수는 [16]에서 제시된 원래 감지와 일치하지 않습니다.B. 다중 비트 워터마킹 1) 이론: 0비트 워터마킹 체계를 다중 비트 워터마킹으로 전환하는 것은 다소 쉽습니다. 메시지당 비밀 키를 연결합니다. 디코딩은 모든 키로 감지를 실행하고 디코딩된 메시지는 가장 낮은 p-값 p를 제공하는 키와 연결된 메시지입니다. 전역 p-값은 1(1 - p)이 되며, 여기서 M은 가능한 메시지 수입니다. 알고리즘 1 LLM을 위한 다중 비트 워터마킹 필요 사항: 모델 LLM, 비밀의 차원 d = max(M, |V|), 워터마크 컨텍스트 너비 h, 메시지 m = {0,..., M – 1} 생성(한 단계): logits + LLM (x(-),...,x (-1)) 시드 Hash(xh), -,x (-1)) r← RNGseed (d) (rm,, rd, ro,.., rm-1) r(m) CyclicShift(r, m) (0)Sample(l, r(m) 1,...,\v\) x 식별: tЄ {h,..., T}에 대한 S← Od: 시드 r(t) Hash(x(th), RNGseed (d) x(t-1)) S+S+ CyclicShift(f(r(t)), x(t)) pp-값 (S1,...,M) margmin(p) p1 (1pm)M M개의 키에 대한 감지를 실행하는 것은 비밀 벡터의 M세대가 필요하기 때문에 비용이 많이 듭니다.이는 메시지 m = {0, . . ., M – 1}의 비밀 벡터가 r = = r(0)의 m개 인덱스의 순환 이동으로 제작되도록 함으로써 해결됩니다.r(m) CyclicShift(r, m) = = (rm, rm+1, .., rd, ro, .., rm−1).། d ≥ |V|인 d차원 벡터로 r을 생성하면 각 순환 이동 벡터의 처음 |V| 차원만 유지하여 M ≤ d개의 다른 메시지를 포함할 수 있습니다.따라서 메시지 수가 토큰 어휘 |V|의 크기를 초과할 수 있습니다. 또한, 스코어링 함수(2)(3)은 다음과 같이 다시 쓸 수 있다. T Sr(m) = Σ ƒ (r&quot;) (m)). t=x(t) (9) 여기서 f Rd Rd는 성분별 함수이고, x(t)는 감지 중에 선택된 토큰이다. 이는 위치 x(t)에서 f (r(t) (m))의 선택을 나타낸다. 다른 관점에서, f (r(t))를 x(t)만큼 이동하면 m =의 스코어는 첫 번째 성분, m = 1의 스코어는 두 번째 성분 등이 된다. 다음과 같이 쓸 수도 있다. T ST = CyclicShift (f(r()), 2(t)), t = (10) ST의 처음 M 성분은 각 m의 스코어이다. 참고로, 이는 Kalker et al. [35]에서 도입한 병렬 계산의 특별한 경우이다. 2) 실험: 추적 시나리오에서 메시지는 사용자 또는 모델 버전의 식별자이다. 목표는 다음을 결정하는 것이다. 영어: 모든 사용자 또는 모델이 주어진 텍스트(탐지)를 생성했으며, 그렇다면 어떤 텍스트(식별)를 생성했는지입니다. 오류에는 3가지 유형이 있습니다. 거짓 양성: 바닐라 텍스트를 플래그 지정; 거짓 음성: 워터마크가 있는 텍스트를 놓침; 거짓 고발: 워터마크가 있는 텍스트를 플래그 지정하지만 잘못된 식별자를 선택. Guanaco-7b 모델을 사용하여 각각 100개의 워터마크가 있는 텍스트를 생성하는 M&#39;=1000명의 사용자를 시뮬레이션합니다. 그런 다음 식별자를 추가하여 M&#39; 식별자를 넘어 정확도를 외삽할 수 있습니다. 표 III: 워터마킹을 통한 사용자 추적의 식별 정확도. 시퀀스는 4~252개 토큰 길이이고 평균 149개입니다. 1020.72 0.0.77 0. 사용자 수 MFPR= 10-FPR= 10-Aaronson 등 [16] Kirchenbauer 등 [17] Aaronson 등 [16] Kirchenbauer 등 [17]0.0.0.0.0.61 0.56 0.51 0.0.69 0.64 0.59 0.우리는 연관된 텍스트 없이 =를 사용하여 총 M &gt; M&#39; 사용자를 얻습니다. 텍스트 생성은 0.95에서 top-p를 사용하는 핵 샘플링을 사용합니다. [17]의 경우 3.0, y = 1/4이고 온도는 0에서 0.8입니다. [16]의 경우 1.0입니다. 두 경우 모두 컨텍스트 너비는 h = 4입니다. 텍스트는 점수가 주어진 글로벌 FPR에 대해 설정된 임계값을 넘으면 워터마크가 있는 것으로 간주됩니다(III 참조). 그런 다음 소스는 p 값이 가장 낮은 사용자로 식별됩니다. 표 III은 워터마킹이 성능이 충분히 억제적이기 때문에 식별이 가능하다는 것을 보여줍니다. 예를 들어, 105명의 사용자 중에서 텍스트가 공격을 받지 않는 한 FPR을 10-6으로 유지하면서 50%의 시간 동안 워터마크가 있는 텍스트의 소스를 성공적으로 식별했습니다. 이 규모에서 거짓 고발률은 0(생성된 텍스트를 플래그로 표시하면 잘못된 식별이 없음)인데, FP를 피하기 위해 임계값을 높게 설정했기 때문에 거짓 고발이 발생할 가능성이 낮기 때문입니다. M이 증가하면 식별 정확도가 감소하는데, FP를 피하기 위해 필요한 임계값이 높아지기 때문입니다. 간단히 말해서, 여러 메시지를 인코딩할 수 있는 가능성을 제공함으로써 사용자를 식별하는 능력에 대한 탐지 정확도를 일부 포기했습니다. VI. 결론 이 연구는 LLM을 위한 워터마크에 대한 문헌에서 제외된 이론적, 경험적 통찰력을 제공합니다. 즉, 기존의
--- METHOD ---
s, 기존 자연어 처리(NLP) 벤치마크에 대한 워터마크의 실제적 의미를 분석합니다. 실제로 현재 워터마크 평가는 주로 원래 LLM 분포와의 편차를 고려합니다(예: 퍼플렉시티 사용). 이는 LLM 문헌과 대조되는데, 여기서 모델은 오히려 효과적인 유용성(예: 질문 답변과 같은 자유형 완성 작업)에 따라 평가됩니다. 이러한 평가는 다운스트림 작업에서 사용될 때 모델의 실제 능력에 대해 훨씬 더 많은 정보를 제공합니다. 셋째, 이러한 알고리즘을 고급 탐지 체계로 확장합니다. 탐지 시점에 LLM에 액세스할 수 있는 경우 최적의 통계적 테스트를 제공합니다. 또한 현재 접근 방식이 0비트 워터마킹만 처리하는 경우 다중 비트 워터마킹(바이너리 메시지를 워터마크로 숨김)을 조사합니다. 이를 통해 텍스트가 워터마크가 있는 LLM에서 생성되었는지 확인할 수 있을 뿐만 아니라 모델의 어느 버전이 생성했는지 식별할 수도 있습니다. II. 기술적 배경 A. 대규모 언어 모델(LLM) LLM은 컨텍스트가 주어졌을 때 토큰 시퀀스를 생성할 가능성을 계산하여 텍스트를 생성하는 신경망입니다[21]. 이 논문은 디코더 전용 모델, 즉 자기 회귀 LLM에 초점을 맞춥니다. 토큰은 어휘 V의 단어 조각입니다. 컨텍스트 x (-C), x(-1)에서 모델은 V의 각 토큰이 다음 토큰일 확률을 추정합니다. 로짓의 벡터 RV를 계산하여 Є (P (X(0) = x|x(-),...,x(-1))) ZEV ·(−1))) rey = softmax(l;0) (1)로 변환합니다. 여기서 는 온도입니다. 컨텍스트에서 시퀀스를 생성하면 이 분포에서 토큰을 샘플링한 다음 컨텍스트에 추가하고 프로세스를 반복합니다. 다양한 샘플링 방식이 존재합니다: 탐욕적 탐색, 빔 탐색, 상위 k 샘플링[22], [23], 핵 샘플링(상위 p)[24] 등.B. 워터마킹 텍스트 생성 1) 분포 수정[17], [18], [20]: 원래 분포(1)는 약칭 p로 표시되며, k가 비밀 키이고 F가 임의 함수인 유사한 분포 q F(p, k)로 대체됩니다.Kirchenbauer 등의 작업[17]에서 비밀 키는 V = Gk Uk의 분할을 결정합니다.greenlist Gk에는 y = [0,1]인 7|V| 토큰이 포함됩니다.greenlist의 모든 토큰의 로짓은 8 &gt; 0만큼 증가하고 softmax 연산자는 q를 출력합니다.그런 다음 샘플링은 평소와 같이 진행됩니다.직관적으로 이것은 greenlist 토큰을 생성할 확률을 높입니다. 한편, E[F(p, K)] = p 이므로 암호화 키 집합에 대한 기대치에 따라 워터마킹은 단어의 전역 분포에 편향을 주지 않습니다(K는 키를 나타내는 확률 변수). 탐지는 텍스트를 토큰화하고 그린리스트에 있는 토큰의 수를 계산합니다. 보다 공식적으로, T개 토큰의 텍스트에 대해 점수 ST는 그린리스트 토큰의 수입니다(x(t)와 k(t)는 각각 t번째 토큰과 키를 나타냄): T ST=1 (2) €). Σι (t)). t=1/pv 2) 샘플링 수정[16], [19]: 워터마크 임베딩은 결정적 프로세스를 통해 기존 샘플링 방식을 대체합니다. 예를 들어, Aaronson et al.[16]은 x(0) = arg maxvЄV rv를 계산하여 다음 토큰을 선택합니다. 여기서 p¹는 분포(1)이고 r = [0,1] V는 비밀 키 k에서 생성된 비밀 벡터입니다. 직관적으로 이는 높은 r₁ 및 pv 값을 모두 갖는 토큰 생성을 장려합니다. 또한 비밀 벡터의 무작위성에 대해 Vv Є V, P(X(0) = v) = P₁라는 흥미로운 속성을 제시합니다. 이는 [0,1] ||에 균일하게 분포될 때입니다(부록 A의 데모). 즉, 이 워터마킹은 비밀 벡터에 대한 기대에 대한 분포를 편향시키지 않습니다. 탐지는 T 토큰에 대해 다음 점수를 계산합니다. ST T -Σ(1-r%). t=x(t) 1 (핵 샘플링은 p를 생성하기 전에 적용될 수 있음) (3) C. 품질-견고성 트레이드오프 두 방법 모두 워터마킹 강도를 변경하여 생성 품질과 견고성을 트레이드오프할 수 있습니다. [17]에서 ♪ 매개변수를 늘리면 가능성이 낮은 토큰을 포함할 위험이 있지만 녹색 토큰 생성이 늘어납니다. [16]에서 온도 0을 증가시키는 것은 확률 벡터(1)를 평탄화하여 rv에 대한 p₁의 상대적 중요도를 감소시키기 때문에 동일한 효과를 냅니다.D. 키 관리 [17]에서 greenlist Gk를 생성하거나 [16]에서 r을 샘플링하는 비밀 키 k는 광범위한 다양성을 가져야 합니다.고정 키는 보안 문제를 일으키고 텍스트 생성에 편향을 줍니다.한 가지 가능성은 [19]에서 제안한 것처럼 시간 t에 따라 달라지게 하는 것입니다.그러면 비밀 키는 토큰마다 다릅니다.그러나 이렇게 하면 감지 단계에서 동기화 문제가 발생합니다(예: 문장이 삭제될 때).그림 1에 나와 있는 자체 동기화를 보장하는 일반적인 관행은 키를 h개의 이전 토큰의 창에 따라 달라지게 합니다.k(t)H(x(t−1) ., x(th), k), 여기서 H는 암호화 해시 함수이고 k는 마스터 키입니다.이 비밀은 시간 t에서 난수 생성기(RNG)를 초기화하는 시드입니다. 차례로, RNG는 그린리스트 Gk(t)를 생성하거나 r(t)를 샘플링하는 데 사용됩니다. 이 창의 너비는 키의 다양성과 워터마킹의 견고성 간의 균형을 정의합니다. h 0인 특정한 경우, 키는 모든 토큰에 대해 동일합니다(k(t) = k). 이는 워터마킹을 텍스트 편집에 특히 견고하게 만듭니다[25]. E. Z-테스트 = 탐지는 가설 Ho: &quot;텍스트가 자연스럽습니다&quot;(인간이 쓴 것 또는 워터마크 없이 쓴 것)를 H₁: &quot;텍스트가 워터마크와 함께 생성되었습니다&quot;에 대해 테스트합니다. 현재 접근 방식[16], [17]은 Z-테스트를 사용하여 점수 ST의 기본 분포를 근사합니다. 이 통계적 가설 검정은 표준 편차가 알려져 있을 때 표본 평균이 기대치와 크게 다른지 여부를 판별합니다. 이는 소위 Z 통계량을 계산합니다.Z = ST/T-HO 00/√T (4) 여기서 μo 및 σ0는 귀무 가설 Ho 하에서 토큰당 기대값 및 표준 편차입니다.즉, 분석된 텍스트에 워터마크가 없는 경우입니다.Z-검정은 중심 극한 정리 덕분에 귀무 가설 하에서 정규 분포를 가정하여 일반적으로 대규모 표본 크기에 사용됩니다.이 가정은 p-값, 즉 귀무 가설 하에서 관찰된 값 z보다 적어도 극단적인 Z 값을 관찰할 확률을 계산하는 데 중요합니다.p-value(z) = P(Z &gt; z|Ho) = 1 − §(z), (5) 여기서 는 정규 분포의 누적 분포 함수입니다.탐지 시점에 거짓 양성률(FPR)을 고정하고 p-value(z) &lt; FPR인 경우 텍스트를 워터마크가 있는 것으로 표시합니다.경험적 FPR10-10-10-10-10-경험적 FPR10-1110-Aaronson et al. 10-Kirchenbauer 등.10-이론적 FPR 10-4 10-10-10-10-(a) Z-검정 Aaronson 등.Kirchenbauer 등.10-10-이론적 FPR (b) III-B의 검정 경험적 FPR 10-시드 시딩 시 컨텍스트 폭:10-Aaronson 등.Kirchenbauer 등.10-10-10-이론적 FPR 10-(c) III-C로 수정된 III-B의 검정 그림 2: 다양한 워터마크와 컨텍스트 폭 h의 값에 대한 거짓 양성률의 경험적 확인.결과는 Wikipedia에서 샘플링한 256개 토큰의 100k 시퀀스 × 오버마스터 키로 계산한 것입니다.다음 세 가지 탐지 검정을 비교합니다.(왼쪽) Z-검정 사용;(가운데) III-B에 제시된 새로운 통계적 검정 사용; (오른쪽) III-C의 수정된 채점 전략을 사용한 새로운 통계적 검정 사용. 이론적 값은 h 값이 높은 경우에도 Z 검정에 실제로 적용되지 않으며 경험적 FPR은 이론적 값과 일치하지 않습니다. 이는 근거 있는 통계적 검정 및 분석적 p 값을 기반으로 탐지를 수행하고 채점 전략을 수정하여 해결합니다. III. 탐지의 신뢰성 이 섹션에서는 FPR의 대규모 평가가 이론과 실제 간의 차이를 보여줍니다. 새로운 통계적 검정과 채점 방법을 수정하여 이 차이를 메웁니다. A. Z 점수를 사용한 FPR의 경험적 검증 지금까지 FPR은 약 음성 샘플에서만 확인되었습니다[17], [18], [20]. 이를 더욱 확장하여 다국어 위키피디아에서 100,000개의 텍스트를 선택하여 자연스러운 텍스트의 분포를 포함합니다. LLAMA의 토크나이저로 토큰화하고 T = 256개의 토큰/텍스트를 사용합니다. RNG를 시딩할 때 다양한 윈도우 길이 h로 탐지 테스트를 실행합니다. 10개의 다른 마스터 키로 이를 반복하면 각 방법과 h 값에 대해 Ho에서 1M 탐지 결과가 나옵니다. 그린리스트 워터마크 탐지의 경우 Y = 0.25를 사용합니다. 그림 2a는 경험적 FPR과 이론적 FPR을 비교합니다. 이론적 보장은 실제로 유지되지 않습니다. 경험적 FPRS가 이론적 FPRS보다 훨씬 높습니다. 또한 p 값의 분포가 균일하지 않은 것을 관찰했습니다(Ho에서 그래야 함). 게다가 워터마킹 컨텍스트 윈도우 h가 클수록 이론적 보장에 더 가까워집니다. 실제로 신뢰할 수 있는 p 값을 얻으려면 h &gt;&gt; 8이 필요하지만 이렇게 하면 동기화에 영향을 미치기 때문에 생성된 텍스트에 대한 공격에 대한 워터마킹 방법이 덜 강력해집니다. B. 새로운 비점근적 통계적 테스트 Z-테스트의 가우스 가정은 짧거나 반복적인 텍스트에서는 무너집니다. 다음은 두 방법에 대한 비점근적 검정으로, 특히 그림 2에서 보인 것처럼 낮은 FPR 값에서 경험적 FPR과 이론적 FPR 간의 격차를 줄이는 데 유용합니다.1) Kirchenbauer et al.[17]: Ho에서 이벤트 x(t) = k(t)가 확률 Y로 발생하고 이러한 이벤트가 iid라고 가정합니다.따라서 ST(2)는 매개변수 T와 y의 이항 분포를 따릅니다.점수가 s인 검토 대상 텍스트를 고려합니다.p 값은 Ho에서 s보다 높은 점수를 얻을 확률로 정의됩니다.p 값(s) = P(ST &gt; s|Ho) = I√(s, T − s + 1), (6) cdf가 Ix(a, b)로 표현되는 SB(T,)이기 때문입니다.정규화된 불완전 베타 함수.~ 2) Aaronson et al. [16]: Ho에서 우리는 조사 대상 텍스트와 비밀 벡터가 독립적이라고 가정하므로 rx(t) U(0, 1)입니다. 따라서 ST(3)은 г(T, 1) 분포를 따릅니다. 점수 s와 관련된 p 값은 다음과 같습니다. iid ~ p-값(s) = P(ST &gt; s|Ho) : г(T, s) F(T) (7) 여기서 I는 상부 불완전 감마 함수입니다. H1에서 점수는 App. A에서 증명된 대로 더 높을 것으로 예상되므로 p 값은 작을 가능성이 높습니다. C. 감지 점수 수정 근거 통계적 검정을 사용하더라도 경험적 FPR은 여전히 이론적 FPR보다 높습니다. 사실, Kirchenbauer et al. [17]은 반복되는 창이 동일한 비밀을 생성하기 때문에 난수 변수는 의사 난수일 뿐이라고 언급합니다. 이는 짧은 텍스트에서도 발생할 수 있으며 특히 형식화된 데이터에서 발생할 수 있습니다. 예를 들어, 글머리 기호 목록에서 토큰 시퀀스 \n\n* _는 그림 3에 표시된 것처럼 많이 반복됩니다. 반복은 p-값을 계산하는 데 필요한 독립성 가정을 무너뜨립니다.
--- EXPERIMENT ---
s는 이전 연구의 가설이 성립하지 않으며, 해당 연구의 탐지 임계값이 낮은 FPR에서 거짓 양성을 크게 과소평가한다는 것을 보여줍니다. 이 연구는 이론적으로 거짓 양성률과 실제 체제에서 정확한 p값을 보장하는 근거 있는 통계적 테스트를 제공합니다. 우리는 이를 경험적으로 검증하고 낮은 값(&lt; 10-6)에서도 FPR을 거의 완벽하게 제어할 수 있음을 보여줍니다. 둘째, 워터마킹 방법을 비교하여 기존 자연어 처리(NLP) 벤치마크에 대한 워터마크의 실제적 의미를 분석합니다. 실제로 현재 워터마크 평가는 주로 원래 LLM 분포와의 편차를 고려합니다(예: 퍼플렉시티 사용). 이는 LLM 문헌과 대조되는데, 여기서 모델은 오히려 효과적인 유용성(예: 질문 답변과 같은 자유형 완성 작업)에 따라 평가됩니다. 이러한 평가는 다운스트림 작업에 사용될 때 모델의 실제 능력에 대해 훨씬 더 많은 정보를 제공합니다. 셋째, 이러한 알고리즘을 고급 탐지 체계로 확장합니다. 탐지 시점에 LLM에 액세스할 수 있는 경우 최적의 통계적 테스트를 제공합니다. 영어: 또한 현재 접근 방식이 0비트 워터마킹만 처리하는 경우 다중 비트 워터마킹(워터마크로 바이너리 메시지를 숨김)을 조사합니다.이를 통해 텍스트가 워터마크가 있는 LLM에서 생성되었는지 확인할 수 있을 뿐만 아니라 어떤 버전의 모델에서 생성했는지 식별할 수도 있습니다.II. 기술적 배경 A. 대규모 언어 모델(LLM) LLM은 컨텍스트가 주어졌을 때 토큰 시퀀스를 생성할 가능성을 계산하여 텍스트를 생성하는 신경망입니다[21].이 논문은 디코더 전용 모델, 즉 자기 회귀 LLM에 초점을 맞춥니다.토큰은 어휘 V의 단어 조각입니다.컨텍스트 x (-C), x(-1)에서 모델은 V의 각 토큰이 다음 토큰일 확률을 추정합니다.로짓의 벡터 RV를 계산하여 Є (P (X(0) = x|x(-),...,x(-1))) ZEV ·(−1))) rey = softmax(l;0) (1)로 변환합니다.여기서 는 온도입니다. 컨텍스트에서 시퀀스를 생성하면 이 분포에서 토큰을 샘플링한 다음 컨텍스트에 추가하고 프로세스를 반복합니다.탐욕적 검색, 빔 검색, 상위 k 샘플링[22], [23], 핵 샘플링(상위 p)[24] 등 다양한 샘플링 방식이 있습니다.B. 워터마킹 텍스트 생성 1) 분포 수정[17], [18], [20]: 원래 분포(1)는 약칭 p로 표시되며 k가 비밀 키이고 F가 임의의 함수인 유사한 분포 q F(p, k)로 대체됩니다.Kirchenbauer 등의 작업[17]에서 비밀 키는 V = Gk Uk의 분할을 결정합니다.greenlist Gk에는 y = [0,1]인 7|V| 토큰이 포함됩니다.greenlist의 모든 토큰의 로짓은 8 &gt; 0만큼 증가하고 softmax 연산자는 q를 출력합니다.그런 다음 샘플링은 평소와 같이 진행됩니다. 직관적으로, 이는 그린리스트 토큰을 생성할 확률을 높입니다.반면에, E[F(p, K)] = p 이므로 암호화 키 집합에 대한 기대치에 따라 워터마킹은 단어의 전역 분포에 편향을 주지 않습니다(K는 키를 나타내는 확률 변수).탐지는 텍스트를 토큰화하고 그린리스트에 있는 토큰의 수를 계산합니다.더 공식적으로, T개 토큰의 텍스트에 대해 점수 ST는 그린리스트 토큰의 수입니다(x(t)와 k(t)는 각각 t번째 토큰과 키를 나타냄): T ST=1 (2) €).Σι (t)).t=1/pv 2) 샘플링 수정 [16], [19]: 워터마크 임베딩은 결정론적 프로세스로 기존 샘플링 방식을 대체합니다.예를 들어, Aaronson et al. [16] x(0) = arg maxvЄV rv를 계산하여 다음 토큰을 선택합니다.여기서 p¹는 분포(1)이고 r = [0,1] V는 비밀 키 k에서 생성된 비밀 벡터입니다.직관적으로, 이는 높은 r₁ 및 pv 값을 모두 갖는 토큰 생성을 장려합니다.또한 [0,1] ||에 균일하게 분포될 때 비밀 벡터의 무작위성에 대해 Vv Є V, P(X(0) = v) = P₁라는 흥미로운 속성을 나타냅니다(부록 A의 데모).다시 말해, 이 워터마킹은 비밀 벡터에 대한 기대에 대한 분포를 편향시키지 않습니다.탐지는 T개 토큰에 대해 다음 점수를 계산합니다.ST T -Σ(1-r%).t=x(t) 1 (핵 샘플링은 p를 생성하기 전에 적용될 수 있음) (3) C. 품질-견고성 트레이드오프 두 방법 모두 워터마킹 강도를 변경하여 생성 품질과 견고성을 트레이드오프할 수 있습니다. [17]에서 ♪ 매개변수를 늘리면 가능성이 낮은 토큰이 포함될 위험이 있지만 녹색 토큰 생성이 늘어납니다.[16]에서 온도 0을 늘리면 확률 벡터(1)가 평평해져 rv에 대한 p₁의 상대적 중요도가 감소하므로 동일한 효과가 있습니다.D. 키 관리 [17]에서 녹색리스트 Gk를 생성하거나 [16]에서 r을 샘플링하는 비밀 키 k는 광범위한 다양성을 가져야 합니다.고정 키는 보안 문제를 일으키고 텍스트 생성에 편향을 일으킵니다.한 가지 가능성은 [19]에서 제안한 것처럼 시간 t에 따라 달라지게 하는 것입니다.그러면 비밀 키는 토큰마다 다릅니다.그러나 이렇게 하면 감지 단계에서 동기화 문제가 발생합니다(예: 문장이 삭제될 때).그림 1에 나와 있는 자체 동기화를 보장하는 일반적인 관행은 키를 h개의 이전 토큰의 창에 따라 달라지게 합니다.k(t)H(x(t−1) ., x(th), k), 여기서 H는 암호화 해시 함수이고 k는 마스터 키입니다. 이 비밀은 시간 t에서 난수 생성기(RNG)를 초기화하는 시드입니다. 차례로, RNG는 그린리스트 Gk(t)를 생성하거나 r(t)를 샘플링하는 데 사용됩니다. 이 창의 너비는 키의 다양성과 워터마킹의 견고성 간의 균형을 정의합니다. h 0인 특정한 경우, 키는 모든 토큰에 대해 동일합니다(k(t) = k). 이는 워터마킹을 텍스트 편집에 특히 견고하게 만듭니다[25]. E. Z-테스트 = 탐지는 가설 Ho: &quot;텍스트가 자연스럽습니다&quot;(인간이 쓴 것 또는 워터마크 없이 쓴 것)를 H₁: &quot;텍스트가 워터마크와 함께 생성되었습니다&quot;에 대해 테스트합니다. 현재 접근 방식[16], [17]은 Z-테스트를 사용하여 점수 ST의 기본 분포를 근사합니다. 이 통계적 가설 테스트는 표준 편차가 알려져 있을 때 표본 평균이 기대치와 크게 다른지 여부를 판별합니다. 이는 소위 Z 통계량을 계산합니다.Z = ST/T-HO 00/√T (4) 여기서 μo 및 σ0는 귀무 가설 Ho 하에서 토큰당 기대값 및 표준 편차입니다.즉, 분석된 텍스트에 워터마크가 없는 경우입니다.Z-검정은 중심 극한 정리 덕분에 귀무 가설 하에서 정규 분포를 가정하여 일반적으로 대규모 표본 크기에 사용됩니다.이 가정은 p-값, 즉 귀무 가설 하에서 관찰된 값 z보다 적어도 극단적인 Z 값을 관찰할 확률을 계산하는 데 중요합니다.p-value(z) = P(Z &gt; z|Ho) = 1 − §(z), (5) 여기서 는 정규 분포의 누적 분포 함수입니다.탐지 시점에 거짓 양성률(FPR)을 고정하고 p-value(z) &lt; FPR인 경우 텍스트를 워터마크가 있는 것으로 표시합니다.경험적 FPR10-10-10-10-10-경험적 FPR10-1110-Aaronson et al. 10-Kirchenbauer 등.10-이론적 FPR 10-4 10-10-10-10-(a) Z-검정 Aaronson 등.Kirchenbauer 등.10-10-이론적 FPR (b) III-B의 검정 경험적 FPR 10-시드 시딩 시 컨텍스트 폭:10-Aaronson 등.Kirchenbauer 등.10-10-10-이론적 FPR 10-(c) III-C로 수정된 III-B의 검정 그림 2: 다양한 워터마크와 컨텍스트 폭 h의 값에 대한 거짓 양성률의 경험적 확인.결과는 Wikipedia에서 샘플링한 256개 토큰의 100k 시퀀스 × 오버마스터 키로 계산한 것입니다.다음 세 가지 탐지 검정을 비교합니다.(왼쪽) Z-검정 사용;(가운데) III-B에 제시된 새로운 통계적 검정 사용; (오른쪽) III-C의 수정된 채점 전략을 사용한 새로운 통계적 검정 사용. 이론적 값은 h 값이 높은 경우에도 Z 검정에 실제로 적용되지 않으며 경험적 FPR은 이론적 값과 일치하지 않습니다. 이는 근거 있는 통계적 검정 및 분석적 p 값을 기반으로 탐지를 수행하고 채점 전략을 수정하여 해결합니다. III. 탐지의 신뢰성 이 섹션에서는 FPR의 대규모 평가가 이론과 실제 간의 차이를 보여줍니다. 새로운 통계적 검정과 채점 방법을 수정하여 이 차이를 메웁니다. A. Z 점수를 사용한 FPR의 경험적 검증 지금까지 FPR은 약 음성 샘플에서만 확인되었습니다[17], [18], [20]. 이를 더욱 확장하여 다국어 위키피디아에서 100,000개의 텍스트를 선택하여 자연스러운 텍스트의 분포를 포함합니다. LLAMA의 토크나이저로 토큰화하고 T = 256개의 토큰/텍스트를 사용합니다. RNG를 시딩할 때 다양한 윈도우 길이 h로 탐지 테스트를 실행합니다. 10개의 다른 마스터 키로 이를 반복하면 각 방법과 h 값에 대해 Ho에서 1M 탐지 결과가 나옵니다. 그린리스트 워터마크 탐지의 경우 Y = 0.25를 사용합니다. 그림 2a는 경험적 FPR과 이론적 FPR을 비교합니다. 이론적 보장은 실제로 유지되지 않습니다. 경험적 FPRS가 이론적 FPRS보다 훨씬 높습니다. 또한 p 값의 분포가 균일하지 않은 것을 관찰했습니다(Ho에서 그래야 함). 게다가 워터마킹 컨텍스트 윈도우 h가 클수록 이론적 보장에 더 가까워집니다. 실제로 신뢰할 수 있는 p 값을 얻으려면 h &gt;&gt; 8이 필요하지만 이렇게 하면 동기화에 영향을 미치기 때문에 생성된 텍스트에 대한 공격에 대한 워터마킹 방법이 덜 강력해집니다. B. 새로운 비점근적 통계적 테스트 Z-테스트의 가우스 가정은 짧거나 반복적인 텍스트에서는 무너집니다. 다음은 두 방법에 대한 비점근적 검정으로, 특히 그림 2에서 보인 것처럼 낮은 FPR 값에서 경험적 FPR과 이론적 FPR 간의 격차를 줄이는 데 유용합니다.1) Kirchenbauer et al.[17]: Ho에서 이벤트 x(t) = k(t)가 확률 Y로 발생하고 이러한 이벤트가 iid라고 가정합니다.따라서 ST(2)는 매개변수 T와 y의 이항 분포를 따릅니다.점수가 s인 검토 대상 텍스트를 고려합니다.p 값은 Ho에서 s보다 높은 점수를 얻을 확률로 정의됩니다.p 값(s) = P(ST &gt; s|Ho) = I√(s, T − s + 1), (6) cdf가 Ix(a, b)로 표현되는 SB(T,)이기 때문입니다.정규화된 불완전 베타 함수.~ 2) Aaronson et al. [16]: Ho에서 우리는 조사 대상 텍스트와 비밀 벡터가 독립적이라고 가정하므로 rx(t) U(0, 1)입니다. 따라서 ST(3)은 г(T, 1) 분포를 따릅니다. 점수 s와 관련된 p 값은 다음과 같습니다. iid ~ p-값(s) = P(ST &gt; s|Ho) : г(T, s) F(T) (7) 여기서 I는 상부 불완전 감마 함수입니다. H1에서 점수는 App. A에서 증명된 대로 더 높을 것으로 예상되므로 p 값은 작을 가능성이 높습니다. C. 감지 점수 수정 근거 통계적 검정을 사용하더라도 경험적 FPR은 여전히 이론적 FPR보다 높습니다. 사실, Kirchenbauer et al. [17]은 반복되는 창이 동일한 비밀을 생성하기 때문에 난수 변수는 의사 난수일 뿐이라고 언급합니다. 이는 짧은 텍스트에서도 발생할 수 있으며 특히 형식화된 데이터에서 발생할 수 있습니다. 예를 들어, 글머리 기호 목록에서 토큰 \n\n* _ 시퀀스는 그림 3에서와 같이 많이 반복됩니다. 반복은 p-값을 계산하는 데 필요한 독립성 가정을 무너뜨립니다. 우리는 탐지 단계에서 이 문제를 완화하는 두 가지 간단한 휴리스틱을 실험했습니다. 첫 번째는 탐지 중에 워터마크 컨텍스트 창이 아직 보이지 않은 경우에만 토큰을 고려합니다. 두 번째는 {워터마크 컨텍스트 + 현재 토큰}으로 형성된 h + 1-튜플이 아직 보이지 않은 토큰에 점수를 매깁니다. 후자는 [17]에 있지만 절제되지 않고 Nes oth rips는 Ph la e oth rip idae과에 속한 th rips의 속입니다. \n \n ## 종 \n \n * N es oth rips a lex andra e \n * N es oth rips a orist us \n * N es oth rips ar to car pi \n * N es oth rips bad ius \n * N es oth rips bar row i \n * N es oth rips bre vic oll is \n * N es oth rips brig al owi \n * N es oth rips cap ric orn is \n * N es oth rips car ver i \n * N es oth rips co or ong i \n 그림 3: 반복 토큰으로 인해 p-값이 낮은 바닐라 텍스트의 일반적인 예. 256개 토큰에서 y = 1/4, h = 2인 그린리스트 워터마크를 사용하여 10-21입니다(텍스트의 절반만 표시). 표 I: 워터마킹으로 완료했을 때의 클래식 자유형 생성 벤치마크 성능. h는 워터마크 컨텍스트 너비입니다. 다음 방법에 대한 결과를 보고합니다. Aaronson et al. [16] / Kirchenbauer et al. [17]. &quot;-&quot;는 워터마킹 없음을 의미합니다. GSM8K Human Eval MathQA 모델 h 7B MBPP NQ TQA 평균 10.10.3 / 11.10.4 / 10.12.12.8/9.12.8/9.13B 17.15.17.2 / 17.15.2 / 14.17.2 / 16.15.215.30B 35.35.3 / 35.35.1 / 34.20.20.7 / 20.20.1 / 22.3.2.9 / 2.3.0/2.4.4.3 / 3.4.2 / 4.6.6.9 / 7.6.9/7.18.18.2 / 16.17.8 / 16.23.22.8 / 21.22.6 / 21.21.21.8 / 19.21.8/ 20.56.56.9 / 55.56.9 / 55.20.20.5 / 19.20.419.28.28.2 / 25.28.2 / 24.63.63.6 / 62.63.6 / 62.25.25.2 / 24.25.2 / 24.29.29.6 / 28.29.8 / 28.33.33.5 31.33.5 / 31.70.32.70.0 / 69.70.0 / 68.32.7 / 32.32.6 / 32. 추가 실험에 사용됩니다. 두 가지 중에서 두 번째 것이 더 나은데, 더 많은 ngram을 계산하고 따라서 더 나은 TPR을 갖기 때문입니다. 또한 h = 0의 특정 사례도 처리할 수 있습니다. = 그림 2c는 이미 본 h + 1-튜플을 채점하지 않기로 선택할 때의 경험적 및 이론적 FPRS를 보고합니다. 이제 FPR이 여전히 약간 과소평가된 h O를 제외하고는 완벽하게 일치합니다. 간단히 말해, 새로운 통계적 테스트와 {워터마크 컨텍스트 + 현재 토큰}이 채점되지 않은 토큰만 채점하여 FPR을 보장합니다. IV. 워터마크 평가 이 섹션에서는 개정된 통계적 테스트를 통한 평가를 소개하고 LLM 워터마킹이 기존 NLP 벤치마크에 미치는 영향을 조사합니다. A. 견고성 분석 이제 워터마크가 있는 텍스트를 감지할 때 TPR을 분석하여 워터마킹 방법을 비교합니다. 감지를 위해 이전의 통계적 테스트와 채점 전략을 사용합니다. p-값이 10-5보다 낮으면 텍스트를 워터마크로 표시하여 FPR=10-5를 보장합니다. 이러한 실험의 경우 챗봇 시나리오에 가깝게 유지합니다. 우리는 Alpaca 데이터 세트[27]의 첫 번째 1k 프롬프트를 사용하여 LLAMA의 미세 조정된 버전인 Guanaco-7b[26]를 프롬프트합니다. 생성을 위해 p = 0.95인 top-p 샘플링을 사용하고 [17]의 경우 온도 0 = 0.8, y = 1/4를 사용합니다. 우리는 확률 0으로 토큰을 무작위로 대체하여 동의어 공격을 시뮬레이션합니다.(다른 공격은 관련 작업[18]에서 연구됩니다.) 표 II는 워터마크의 다른 강도에 대한 TPR(섹션 II-C 참조)과 워터마크가 있는 생성된 텍스트와 없는 생성된 텍스트 간의 S-BERT[28] 유사도 점수를 보고하여 워터마크에 의해 유도된 의미적 왜곡을 측정합니다. 표 II의 결과는 다른 동작을 보여줍니다. 예를 들어, [17]은 워터마크 강도와 품질 간의 균형을 더 세밀하게 제어합니다. TPR 값은 0.0~0.9 범위인 반면 [16]은 더 일관적이지만 S-BERT 점수가 많이 저하되더라도 0.8보다 높은 TPR을 달성하지 못합니다.워터마크 컨텍스트 너비도 큰 영향을 미칩니다.그것이 낮을 때, 생성이 토큰의 특정 반복에 쉽게 편향되기 때문에 반복이 더 자주 발생하는 것을 관찰했습니다.그것은 0.5 미만의 평균 S-BERT 점수와 사용할 수 없는 완성으로 이어집니다.반면에, 낮은 h는 또한 워터마크를 더욱 견고하게 만듭니다.특히 [17]의 경우입니다.h가 워터마크의 수에 영향을 미친다는 점도 알아두는 것이 중요합니다.표 II: 수정된 통계적 테스트를 사용한 워터마크의 견고성 분석.워터마크의 강도를 제어하는 다양한 하이퍼파라미터([17]의 8 및 [16]의 0 - 섹션 II-C 참조)에 대해 TPR@FPR=10¯5 및 10 × 1k 완성에 대한 S-BERT 점수를 보고합니다. &#39;TPR 증가분&#39;은 토큰을 확률 0.3으로 무작위로 대체하여 감지 전에 텍스트가 공격을 받았을 때의 TPR입니다.Kirchenbauer et al.[17] 8: 1.0 2.3.0 4.0.63 0.61 0.57 0.0.00 0.16 0.58 0.0.00 0.02 0.20 0.h 메트릭 S-BERT TPR 0 : 0.TPR 증가분 Aaronson et al.[16] 0.9 1.0 1.0.60 0.56 0.52 0.0.20 0.31 0.42 0.0.04 0.06 0.09 0.S-BERT 0.62 0.61 0.0.TPR TPR 증가분 S-BERT TPR TPR 증가분 0.35 0.51 0.66 0.0.04 0.10 0.20 0.0.62 0.62 0.61 0.0.43 0.59 0.71 0.0.01 0.02 0.06 0.0.63 0.62 0.60 0.0.02 0.41 0.77 0.0.00 0.05 0.30 0.0.62 0.62 0.60 0.0.02 0.44 0.76 0.0.00 0.00 0.03 0. 분석된 토큰의 경우 h+ 1-튜플이 이전에 확인되지 않은 토큰에 대해서만 점수를 매기기 때문입니다(섹션 III-C 참조). h가 높으면 이러한 튜플의 거의 대부분이 새롭지만, h가 낮으면 튜플이 반복될 가능성이 증가합니다.예를 들어, 우리의 경우, 채점된 토큰의 평균 수는 h = 0의 경우 약 100이고, h = 1 및 h = 4의 경우 150입니다.B. 자유형 생성 작업에 대한 워터마크의 영향 이전 연구에서는 표 II에서 수행된 것처럼 복잡도나 유사도 점수와 같은 왜곡 지표를 사용하여 품질에 대한 영향을 측정합니다.그러나 이러한 지표는 LLM의 실제 관심사가 있는 다운스트림 작업[24]에 대한 모델의 유용성에 대한 정보를 제공하지 않습니다.실제로 LLM에 워터마킹을 하는 것은 매우 정확한 답변이 필요한 작업에 해로울 수 있습니다.이 섹션에서는 워터마킹의 실용성을 평가하기 위해 일반적인 NLP 벤치마크에 미치는 영향을 정량화합니다.LLM은 일반적으로 일반 생성 샘플을 대상 참조 집합(자유형 생성)과 비교하거나 다중 선택형 질문 방식으로 미리 정의된 옵션 집합의 가능성을 비교하여 평가합니다. 후자는 샘플링에만 영향을 미치는 워터마킹의 경우에는 거의 의미가 없습니다.따라서 우리는 평가를 자유형 생성 작업으로 제한합니다.LLAMA의 평가 설정을 사용합니다.1) 폐쇄형 질문 답변(Natural Questions [29], TriviaQA [30]): 5샷 정확 일치 성능을 보고합니다.2) 수학적 추론(MathQA [31], GSM8k [32]), 다수결 투표 없이 정확 일치 성능을 보고합니다.3) 코드 생성(HumanEval [33], MBPP [34]), pass@1 점수를 보고합니다.[17]의 경우 탐욕적 디코딩 전에 d = 1로 로짓을 이동합니다.[16]의 경우 확률 벡터에 0.95에서 top-p를 적용한 다음 워터마크 샘플링을 적용합니다.표 I은 워터마크가 있는 경우와 없는 경우, 그리고 다른 창 크기 h에 대해 앞서 언급한 벤치마크에서 LLAMA 모델의 성능을 보고합니다. LLM의 성능은 워터마킹에 의해 크게 영향을 받지 않습니다. Kirchenbauer et al.(II-B1)의 접근 방식은 Aaronson et al.(II-B2)의 접근 방식보다 약간 더 해롭지만 바닐라 모델과의 차이는 작습니다. 흥미롭게도 이 차이는 모델 크기가 커질수록 줄어듭니다. 생성 기능이 더 높은 모델은 워터마킹의 영향을 덜 받습니다. 가능한 설명은 더 큰 모델의 글로벌 분포가 더 좋고 따라서 작은 섭동에 더 강하다는 것입니다. 전반적으로 다운스트림 작업을 평가하면 워터마킹이 혼란이나 유사도 점수로 잘 포착되지 않는 사실 오류를 유발할 수 있음을 지적합니다. V. 고급 감지 계획 이 섹션에서는 III절의 감지 계획에 대한 개선 사항을 소개합니다. 즉, LLM에 대한 액세스가 허용될 때의 통계적 테스트와 다중 비트 디코딩을 개발합니다. A. Neyman-Pearson 및 단순화된 점수 함수 다음은 Aaronson et al.의 계획에 대한 구체적인 내용입니다. [16] (비슷한 작업이 [18]과 함께 수행될 수 있음). Ho에서 rv U[0,1]인 반면 H₁에서 r₁ Beta(1/pv, 1)입니다(부록 A의 추론(14) 참조). 따라서 최적의 Neyman-Pearson 점수 함수는 다음과 같습니다. T ~ ~ T fH₁ (rx(t)) ST = In = fHo (rx(t)) Px(t) -1) In(rx(t)) + A t=t=여기서 A는 r에 의존하지 않으므로 버릴 수 있습니다. 두 가지 단점이 있습니다. (1) 감지에는 Px(t)를 계산하기 위한 LLM이 필요합니다. (2) p-값에 대한 폐쇄형 공식이 없습니다. 이 마지막 요점은 견고성에 대한 보장 없이 Chernoff 경계에 의지하여 수정할 수 있습니다.p-값(들) ≤ yet &quot; eΣ In-cs c 솔루션 Σ+(c++)-1 = -s 및 At = Px(t)/(1 − Px(t)). 실험 결과 이 감지는 워터마크가 있는 텍스트에 대해 매우 낮은 p-값을 생성하지만 취약합니다.모든 공격은 생성된 로짓이 전체 LLM 컨텍스트에 민감하기 때문에 원래 감지 체계(3) 수준으로 증가시키거나 더 높을 수도 있습니다.대안은 가중치를 제거하는 것입니다.T ST Σ In (rx(t)), t = p-값은 다음과 같습니다.p-값(들) = T(T) (8) Y(T,-s).우리의 실험에서 이 점수 함수는 [16]에서 제시된 원래 감지와 일치하지 않습니다.B. 다중 비트 워터마킹 1) 이론: 0비트 워터마킹 체계를 다중 비트 워터마킹으로 전환하는 것은 다소 쉽습니다. 메시지당 비밀 키를 연결합니다. 디코딩은 모든 키로 감지를 실행하고 디코딩된 메시지는 가장 낮은 p-값 p를 제공하는 키와 연결된 메시지입니다. 전역 p-값은 1(1 - p)이 되며, 여기서 M은 가능한 메시지 수입니다. 알고리즘 1 LLM을 위한 다중 비트 워터마킹 필요 사항: 모델 LLM, 비밀의 차원 d = max(M, |V|), 워터마크 컨텍스트 너비 h, 메시지 m = {0,..., M – 1} 생성(한 단계): logits + LLM (x(-),...,x (-1)) 시드 Hash(xh), -,x (-1)) r← RNGseed (d) (rm,, rd, ro,.., rm-1) r(m) CyclicShift(r, m) (0)Sample(l, r(m) 1,...,\v\) x 식별: tЄ {h,..., T}에 대한 S← Od: 시드 r(t) Hash(x(th), RNGseed (d) x(t-1)) S+S+ CyclicShift(f(r(t)), x(t)) pp-값 (S1,...,M) margmin(p) p1 (1pm)M M개의 키에 대한 감지를 실행하는 것은 비밀 벡터의 M세대가 필요하기 때문에 비용이 많이 듭니다.이는 메시지 m = {0, . . ., M – 1}의 비밀 벡터가 r = = r(0)의 m개 인덱스의 순환 이동으로 제작되도록 함으로써 해결됩니다.r(m) CyclicShift(r, m) = = (rm, rm+1, .., rd, ro, .., rm−1).། d ≥ |V|인 d차원 벡터로 r을 생성하면 각 순환 이동 벡터의 처음 |V| 차원만 유지하여 M ≤ d개의 다른 메시지를 포함할 수 있습니다.따라서 메시지 수가 토큰 어휘 |V|의 크기를 초과할 수 있습니다. 또한, 스코어링 함수(2)(3)은 다음과 같이 다시 쓸 수 있다. T Sr(m) = Σ ƒ (r&quot;) (m)). t=x(t) (9) 여기서 f Rd Rd는 성분별 함수이고, x(t)는 감지 중에 선택된 토큰이다. 이는 위치 x(t)에서 f (r(t) (m))의 선택을 나타낸다. 다른 관점에서, f (r(t))를 x(t)만큼 이동하면 m =의 스코어는 첫 번째 성분, m = 1의 스코어는 두 번째 성분 등이 된다. 다음과 같이 쓸 수도 있다. T ST = CyclicShift (f(r()), 2(t)), t = (10) ST의 처음 M 성분은 각 m의 스코어이다. 참고로, 이는 Kalker et al. [35]에서 도입한 병렬 계산의 특별한 경우이다. 2) 실험: 추적 시나리오에서 메시지는 사용자 또는 모델 버전의 식별자이다. 목표는 다음을 결정하는 것이다. 영어: 모든 사용자 또는 모델이 주어진 텍스트(탐지)를 생성했으며, 그렇다면 어떤 텍스트(식별)를 생성했는지입니다. 오류에는 3가지 유형이 있습니다. 거짓 양성: 바닐라 텍스트를 플래그 지정; 거짓 음성: 워터마크가 있는 텍스트를 놓침; 거짓 고발: 워터마크가 있는 텍스트를 플래그 지정하지만 잘못된 식별자를 선택. Guanaco-7b 모델을 사용하여 각각 100개의 워터마크가 있는 텍스트를 생성하는 M&#39;=1000명의 사용자를 시뮬레이션합니다. 그런 다음 식별자를 추가하여 M&#39; 식별자를 넘어 정확도를 외삽할 수 있습니다. 표 III: 워터마킹을 통한 사용자 추적의 식별 정확도. 시퀀스는 4~252개 토큰 길이이고 평균 149개입니다. 1020.72 0.0.77 0. 사용자 수 MFPR= 10-FPR= 10-Aaronson 등 [16] Kirchenbauer 등 [17] Aaronson 등 [16] Kirchenbauer 등 [17]0.0.0.0.0.61 0.56 0.51 0.0.69 0.64 0.59 0.우리는 연관된 텍스트 없이 =를 사용하여 총 M &gt; M&#39; 사용자를 얻습니다. 텍스트 생성은 0.95에서 top-p를 사용하는 핵 샘플링을 사용합니다. [17]의 경우 3.0, y = 1/4이고 온도는 0에서 0.8입니다. [16]의 경우 1.0입니다. 두 경우 모두 컨텍스트 너비는 h = 4입니다. 텍스트는 점수가 주어진 글로벌 FPR에 대해 설정된 임계값을 넘으면 워터마크가 있는 것으로 간주됩니다(III 참조). 그런 다음 소스는 p 값이 가장 낮은 사용자로 식별됩니다. 표 III은 워터마킹이 성능이 충분히 억제적이기 때문에 식별이 가능하다는 것을 보여줍니다. 예를 들어, 105명의 사용자 중에서 텍스트가 공격을 받지 않는 한 FPR을 10-6으로 유지하면서 50%의 시간 동안 워터마크가 있는 텍스트의 소스를 성공적으로 식별했습니다. 이 규모에서 거짓 고발률은 0입니다(생성된 텍스트를 플래그하면 잘못된 식별이 없음). FP를 피하기 위해 임계값이 높게 설정되어 거짓 고발이 발생할 가능성이 낮기 때문입니다. M이 증가하면 식별 정확도가 감소합니다. FP를 피하기 위해 필요한 임계값이 높아지기 때문입니다. 간단히 말해서, 여러 메시지를 인코딩할 수 있는 가능성을 제공함으로써 사용자를 식별하는 능력에 대한 감지 정확도를 일부 포기합니다. VI.
--- CONCLUSION ---
이 연구는 LLM의 워터마크에 대한 문헌에서 제외된 이론적, 경험적 통찰력을 제공합니다. 즉, 기존 방법은 편향된 통계적 테스트에 의존하여 잘못된 거짓 양성률을 제공합니다. 이는 근거 있는 통계적 테스트와 수정된 채점 전략으로 수정됩니다. 또한 LLM의 워터마크를 통합하기 위한 평가 설정과 탐지 체계를 도입합니다. 추가 작업에서는 이러한 방법으로 생성이 상당히 더 나은 품질을 제공하기 때문에 보다 복잡한 샘플링 체계(예: [17]의 빔 검색)에 워터마크를 적용하는 방법을 조사할 수 있습니다. 전반적으로 워터마킹은 신뢰할 수 있고 실용적이라고 생각합니다. 생성 모델 맥락에서 비교적 새로운 기술이지만 LLM 출력을 식별하고 추적하는 기술로서 이미 많은 가능성을 가지고 있습니다. 감사의 말 ANR/AID에서 Chaire SAIDA ANR20-CHIA-0011에 따라 지원한 연구. 또한 이 작업 전반에 걸쳐 통찰력을 제공해준 Thomas Scialom, Hervé Jégou, Matthijs Douze에게 감사드립니다. 참고문헌 [1] OpenAI, &quot;ChatGPT: 대화를 위한 언어 모델 최적화.,❞ 2022. [2] AnthropicAI, &quot;Claude 소개,&quot; 2023. [3] H. Touvron 등, &quot;Llama: 개방적이고 효율적인 기반 언어 모델,&quot; arXiv, 2023. [4] L. Weidinger 등, &quot;언어 모델이 제기하는 위험 분류,&quot; ACM 공정성, 책임성 및 투명성 컨퍼런스, 2022. [5] E. Crothers, N. Japkowicz, 및 H. Viktor, &quot;기계 생성 텍스트: 위협 모델 및 탐지 방법에 대한 포괄적 조사,&quot; arXiv, 2022. [6] JP Cardenuto, J. Yang, R. Padilha, R. Wan, D. Moreira, H. Li, S. Wang, F. Andaló, S. Marcel, 및 A. Rocha, &quot;합성 현실의 시대: 도전과 기회,&quot; arXiv, 2023. [7] K. Kertysova, &quot;인공지능과 허위 정보: AI가 허위 정보의 생산, 유포 및 대응 방식을 어떻게 바꾸는가,&quot; 안보 및 인권, 제29권, 제1호. 1-4, 2018. [8] S. Kreps, RM McCain, 및 M. Brundage, &quot;제작하기에 적합한 모든 뉴스: 미디어 오보 도구로서의 Ai 생성 텍스트&quot;, Journal of experiment politics science, 2022. [9] E. Kušen 및 M. Strembeck, &quot;정치, 감정 및 오보: 2016년 오스트리아 대선에 대한 트위터 토론 분석&quot;, Online Social Networks and Media, 2018. [10] MT 리뷰, &quot;AI 생성 텍스트로 가득 찬 정크 웹사이트는 프로그래매틱 광고에서 수익을 올리고 있습니다&quot;, 2023. [11] D. Ippolito, D. Duckworth, C. Callison-Burch, 및 D. Eck, &quot;인간이 속았을 때 생성된 텍스트의 자동 감지가 가장 쉽습니다&quot;, arXiv, 2019. [12] E. Mitchell, Y. Lee, A. Khazatsky, CD Manning, and C. Finn, &quot;Detectgpt: 확률 곡률을 사용한 제로샷 머신 생성 텍스트 감지,&quot; arXiv, 2023. [13] N. Yu, V. Skripniuk, D. Chen, L. Davis, and M. Fritz, &quot;확장 가능한 지문을 사용한 생성 모델의 책임 있는 공개,&quot; ICLR, 2022. [14] P. Fernandez, G. Couairon, H. Jégou, M. Douze, and T. Furon, &quot;안정적인 서명: 잠재 확산 모델의 루팅 워터마크,&quot; ICCV, 2023. [15] Y. Wen, J. Kirchenbauer, J. Geiping, and T. Goldstein, &quot;트리 링 워터마크: 보이지 않고 견고한 확산 이미지의 지문,&quot; arXiv, 2023. [16] S. Aaronson and H. Kirchner, &quot;GPT 출력 워터마킹&quot;, 2023. [17] J. Kirchenbauer, J. Geiping, Y. Wen, J. Katz, I. Miers, and T. Goldstein, &quot;대규모 언어 모델을 위한 워터마크&quot;, ICML, 2023. [18] J. Kirchenbauer, J. Geiping, Y. Wen, M. Shu, K. Saifullah, K. Kong, K. Fernando, A. Saha, M. Goldblum, and T. Goldstein, &quot;대규모 언어 모델을 위한 워터마크의 신뢰성에 관하여&quot;, 2023. [19] M. Christ, S. Gunn, and O. Zamir, &quot;언어 모델을 위한 탐지 불가능한 워터마크&quot;, Cryptology ePrint Archive, 2023. [20] X. Zhao, P. Ananth, L. Li, and Y.-X. 영어: Wang, “AI 생성 텍스트를 위한 입증 가능한 견고한 워터마킹,&quot; arXiv, 2023. [21] Y. Bengio, R. Ducharme 및 P. Vincent, “신경 확률적 언어 모델,&quot; NeurIPS, vol. 13, 2000. [22] A. Fan, M. Lewis 및 Y. Dauphin, &quot;계층적 신경 스토리 생성,&quot; arXiv, 2018. [23] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever 외, &quot;언어 모델은 비지도 멀티태스크 학습기,&quot; OpenAI, 2019. [24] A. Holtzman, J. Buys, L. Du, M. Forbes 및 Y. Choi, &quot;신경 텍스트 퇴화의 흥미로운 사례,&quot; arXiv, 2019. [25] X. Zhao, Y.-X. Wang 및 L. Li, &quot;보이지 않는 워터마킹을 통한 언어 생성 모델 보호&quot;, arXiv, 2023. [26] T. Dettmers, A. Pagnoni, A. Holtzman 및 L. Zettlemoyer, &quot;Qlora: 양자화된 Ilms의 효율적인 미세 조정&quot;, arXiv, 2023. [27] R. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin, P. Liang 및 TB Hashimoto, &quot;Stanford Alpaca: LLAMA 모델을 따르는 명령&quot;, 2023. [28] N. Reimers 및 I. Gurevych, &quot;Sentence-bert: 샴 bert 네트워크를 사용한 문장 임베딩&quot;, arXiv, 2019. [29] T. Kwiatkowski et al., &quot;Natural 영어: 질문: 질문에 답하는 연구를 위한 벤치마크,&quot; ACL 논문, 7권, 2019년. [30] M. Joshi, E. Choi, DS Weld, L. Zettlemoyer, &quot;Triviaqa: 독해 능력을 위한 대규모 원격 감독 챌린지 데이터 세트,&quot; arXiv, 2017년. [31] D. Hendrycks, C. Burns, S. Kadavath, A. Arora, S. Basart, E. Tang, D. Song, J. Steinhardt, &quot;수학 데이터 세트를 사용하여 수학적 문제 해결 측정,&quot; arXiv, 2021년. [32] K. Cobbe 외, &quot;수학 단어 문제를 풀기 위한 검증자 훈련,&quot; arXiv, 2021년. [33] M. Chen 외, &quot;코드로 훈련된 대규모 언어 모델 평가,&quot; arXiv, 2021년. [34] J. Austin, A. Odena, M. Nye, M. Bosma, H. Michalewski, D. Dohan, E. Jiang, C. Cai, M. Terry, Q. Le, and C. Sutton, “대규모 언어 모델을 사용한 프로그램 합성,” 2021. [35] T. Kalker, G. Depovere, J. Haitsma, and M. Maes, “방송 모니터링을 위한 비디오 워터마킹 시스템,” SPIE 논문집, 멀티미디어 콘텐츠의 보안 및 워터마킹, vol. 3657, 1999. 부록 A. [16]에 대한 데모 1) 샘플링 확률 = 명제. 이산 분포 p를 고려하세요. V* R/P라고 합시다. 그러면 P(V* = v) = Pv. = arg maxv iid (P1,, pv)이고 V개의 확률 변수 R = (R1,..., Ry) st Rv U[0,1]. == In(R). Pv에 의한 증명. 모든 v € V에 대해, R₁ id U[0,1]이므로, - In(R₁)은 지수 분포 ε(1)을 따릅니다. 밀도 fz, (z) = p₁e Pvz인 Zv 구성, Z₁, ~ ε(pv)를 둡니다. 이제 다음이 있습니다.V* = arg max Rev Pv = arg min Zv. v (11) บ 지수 법칙에 대한 잘 알려진 결과는 다음과 같습니다(다음 줄에 대한 gumbel 트릭 참조): Z = min Zv บ P(V* = v) = Pu Σ; Ρ; ~ εΣ ) = ε (1), (Σp) = Pv. (12) (13) 이는 주어진 비밀 벡터 r에 대해 워터마킹이 가능성이 낮을 수 있는 단어(낮은 확률 pv)를 선택함을 보여줍니다. 그러나 비밀 키에 대한 기대에 따라, 즉 rv R (R1,..., 1,..., Ry)에 대해 선택된 토큰의 분포는 LLM에서 주어진 분포를 따릅니다. = 추론. Ry* 증명. ~ Beta(1/pv*, 1).Z = Zy⭑ == PV⭑ - ln(Ry×) ~ E(1), 이는 Ry* = e¯PvE로 변환되고 E ~ Ɛ(1), pdf fRv⋆(r) 2) 감지 -г PV⭑ = PV⭑ 따라서 Ry* ~ (14) Beta(1/py*, 1). = x(t) R(t)이고 시간 단계 t에서 Pt=Px(t) (t)입니다. 점수는 텍스트의 토큰 시퀀스를 x(1), ..., x (T), LLM에서 출력한 확률 벡터를 p(t), 시간 단계 t에서 키 난수 벡터를 나타냅니다. Rt를 ln(1 – Rt)로 정의합니다. R(t) = [0,1] ST = = 명제(Ho 하의 p-값). 점수 s와 관련된 p-값은 다음과 같이 정의됩니다. p-값(s) = P(ST &gt; s|Ho) г(T, s) г(T) &quot; (15) 여기서 (T, s)는 상위 불완전 감마 함수입니다. iid 증명. Ho 하에서 가정은 st Rt U[0,1]입니다. 그러면 In(1 - Rt)는 지수 분포 ε(1)을 따릅니다. 따라서 S~F(T,1)(감마 분포의 합 참조). 따라서 점수 s와 관련된 p-값은 p-값(s) =Y(T, s) г(T) г(T, s) г(T) &quot; 여기서 Ã(T, s)는 상위 불완전 감마 함수이고 y(T, s)는 하위 불완전 감마 함수입니다. 추론. 토큰 당 (16) Ho = E(ST/T|H0) = 1, σ = V(ST/T|Ho) = 1/T. (17) 명제(H1에서 예상 점수에 따라 제한됨). H₁에서 E(ST) ≥ T + 는 완료의 엔트로피입니다.(쯩-1) HT, 여기서 HT = Σ_1 Pt ln(pt) 증명. (14)에서 R₁ = exp(−ptE)이고 E ~ Ɛ(1)이므로: T (PE))] E(S) = -E Σ In(1 exp(−ptE)) T t=-Ptx -x - e11/pt-1 (-In(1 − r))drPt (변수 x = -1/pt ln(r)을 변경하여) 그런 다음 u = 1 − r¹/Pt 및 v = ln(1 − r)인 부분별 적분을 사용하면 적분이 다음과 같이 됩니다. = H1/pt 1/Pt-Pt &#39; ln(1 − r)dr = √ 1 — r1/Pt 1- r dr 여기서 H₂는 z번째 고조파 수이며 H₂ = Σn=1로도 정의됩니다. 따라서 다음이 있습니다. n+z - S ∞/pt-1 In(1 − r)dr = ΣJo Pt n n+1/pt n=∞ 이제 Vn EN*, 우리는 다음을 얻습니다: (n + 1)² (+= n+1/pt = 1+ n=n+1 n+1/pt (n+1)(n+1/pt) − (n + 1)² 1+n 1/pt + n 1+n n+1/pt (1/pt - 1) 1/pt + n &gt; - pt ln(pt).In(pt) 따라서 모든 t = [1,T]에 대해 합산하면 Σ E(S) ≥T + Σ =T+ n=(n + 1)² (쯩-1)HT. T t=-Pt t ln(pt) 명제(H₁ 하의 점수 분산).V(ST) ≤T П²증명.Rt ~ Beta(1/pt, 1)에 대해: V(ln(1 − Rt)) = ¥₁ (1) − ¥1 (1 + 1/pt) (18) 여기서 1은 삼각 함수는 다음과 같이 표현할 수 있습니다. 시리즈 41(z) = x²-01/(n + z)². 그러면 V1(1) : π²/6 및 ₁(1+1/pt) &gt; 0이므로 V(ln(1 − Rt)) ≤ π²/6입니다. 결과는 샘플링된 토큰이 독립적이기 때문에 나옵니다. = B. 자유형 평가 표 IV에 다양한 모델의 자유형 평가에 대한 전체 결과를 제공합니다. 이는 본 논문의 표 I 결과를 확장한 것입니다. 모델은 LLaMA와 동일한 평가 프로토콜로 평가됩니다. 표 IV GSM8K 인간 평가 수학QA MBPP NQ TQA 평균 모델 WM 방법 h 7B 없음 10.12.2.18.00 21.72 56.20.Aaronson et al.10.12.3.18.00 21.56.20.10.12.2.18.20 21.75 56.20.10.12.2.18.00 21.75 56.20.10.12.2.18.20 21.69 56.20.10.12.2.17.80 21.80 56.20.10.12.2.18.00 21.56.20.10.12.2.18.20 21.56.20.키르헨바우어 외 9.12.2.16.20 20.55.19.11.9.2.16.00 19.55.19.11.6.2.16.00 20.55.18.10.10.2.14.40 20.55.18.10.9.2.76 16.20.17 55.19.10.9.3.17.00 20.54.19.11.11.2.16.40 20.55.19.13B 없음 17.15.4.23.00 28.63.25.Aaronson 외 17.15.4.22.80 28.63.25.17.15.4.22.80 28.63.25.17.15.4.22.80 28.20 63.25.17.15.4.22.60 28.63.25.17.15.4.22.60 28.20 63.25.16.15.4.23.20 28.23 63.25.17.15.4.22.80 28.20 63.25.키르헨바우어 등.14.14.3.20.80 24.62.23.17.14.3.62 21.20 25.62.24.16.11.3.20.60 25.54 62.23.17.16.3.19.80 25.90 62.24.16.15.4.21.20 24.49 62.24.15.14.4.18.20 26.32 62.23.17.14.3.21.00 25.62.24.30B 없음 35.20.6.29.80 33.70.32.Aaronson 등 35.20.6.29.80 33.52 69.32.35.20.6.29.60 33.52 70.32.35.20.6.30.00 33.70.32.35.20.6.30.00 33.52 70.32.35.20.6.29.80 33.70.32.35.20.6.29.80 33.49 69.32.35.20.6.30.00 33.52 70.32.키르헨바우어 외 31.21.6.28.40 31.66 69.31.35.20.7.28.80 31.58 68.32.33.17.6.27.40 31.83 69.30.33.24.6.27.80 32.49 69.32.34.22.6.28.80 31.55 68.32.34.24.7.29.80 31.63 69.32.34.20.7.27.20 32.08 69.31.
