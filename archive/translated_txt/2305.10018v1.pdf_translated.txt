--- ABSTRACT ---
세분화된 분류는 동일한 범주 내의 객체 간의 미묘한 차이점을 식별하는 어려운 작업입니다. 이 작업은 데이터가 부족한 시나리오에서 특히 어렵습니다. 시각 변환기(ViT)는 최근 셀프 어텐션 메커니즘을 사용하여 시각 데이터의 매우 표현력 있는 표현을 학습하는 능력으로 인해 이미지 분류를 위한 강력한 도구로 등장했습니다. 이 작업에서 우리는 반지도 학습 기술을 사용하여 미세 조정된 ViT 모델인 Semi-ViT를 탐구합니다. 이 모델은 주석이 달린 데이터가 부족한 상황에 적합합니다. 이는 이미지는 쉽게 구할 수 있지만 레이블에 노이즈가 있거나 존재하지 않거나 얻는 데 비용이 많이 드는 전자 상거래에서 특히 일반적입니다. 우리의 결과는 Semi-ViT가 제한된 주석이 달린 데이터로 미세 조정된 경우에도 기존의 합성곱 신경망(CNN)과 ViT보다 성능이 우수하다는 것을 보여줍니다. 이러한 결과는 Semi-ViT가 시각 데이터의 정확하고 세분화된 분류가 필요한 애플리케이션에 상당한 가능성을 가지고 있음을 나타냅니다. 1.
--- INTRODUCTION ---
최근 몇 년 동안 딥 신경망의 개발로 컴퓨터 비전 분야에서 상당한 진전이 이루어졌습니다[16]. 그러한 아키텍처 중 하나는 이미지 피처 간의 장거리 종속성을 모델링하기 위해 셀프 어텐션 메커니즘을 활용하는 Visual Transformer(ViT)[5]입니다. 수작업으로 계층적 피처 추출에 의존하는 기존의 합성곱 신경망(CNN)[7, 10, 26]과 달리, 비주얼 트랜스포머는 보다 효율적이고 효과적인 방식으로 이미지 피처 간의 전역적 공간 관계를 학습할 수 있습니다. 이를 통해 다양한 시각 인식 작업에서 최첨단 방법보다 우수한 성과를 낼 수 있었습니다[18]. 그러나 실제 시나리오에서는 레이블이 지정된 데이터가 부족하고 얻기가 비쌀 수 있습니다. 따라서 semi*Joint first authors.supervised learning(SSL)[40]은 레이블이 지정되지 않은 데이터를 활용하여 딥 신경망의 성능을 개선하는 강력한 기술로 등장했습니다. CNN 방법은 이 분야를 상당히 발전시켰고 [1, 3, 15, 27, 32] ViT 아키텍처는 최근에야 SSL을 사용하여 유망한 결과[2,33]를 보여주었습니다. 이 논문에서는 ViT 아키텍처와 함께 사용할 때 SSL의 효과를 조사합니다. 구체적으로, 우리는 Semi-ViT 아키텍처[2]를 사용하여 전자상거래 데이터의 세분화된 분류를 위한 전이 학습을 수행합니다. 전자상거래 데이터를 사용하면 레이블이 지정되지 않은 이미지를 쉽게 사용할 수 있으므로 SSL에 고유한 이점이 있습니다. 그러나 연관된 레이블은 종종 노이즈가 있거나 전혀 없습니다. 전통적으로 이 문제는 수동 큐레이터를 사용하여 해결되었는데, 이는 비용이 많이 들고 기존 시장에서 주로 접근이 가능합니다. 라틴 아메리카와 같은 신흥 시장에서는 신뢰할 수 있는 레이블이 지정된 데이터가 부족하여 더 큰 문제가 됩니다. 우리는 레이블이 지정되고 레이블이 지정되지 않은 이미지가 포함된 전자상거래 데이터에서 세 개의 데이터 세트를 수집합니다. 우리는 조끼의 목 스타일(Vest Neck Style), 휴대전화 케이스의 패턴(Phone Case Pattern), 앞치마와 음식 턱받이의 패턴(Apron Food Bib Pattern)에 대한 세분화된 분류를 수행합니다. 각 데이터 세트에는 각각 29K, 30K, 33K의 레이블이 지정된 이미지와 227K, 287K, 284K의 레이블이 지정되지 않은 이미지가 포함되어 있습니다. 레이블은 크라우드 소싱 방법을 사용하여 수집되었습니다. 우리는 잘 알려진 ResNet 아키텍처[10], ViT, Semi-ViT 아키텍처의 세 가지 다른 모델을 미세 조정합니다. 모두 ImageNet[4]에서 사전 학습되었습니다. ViT 및 SemiViT 아키텍처의 경우, 우리는 또한 각 데이터 세트에 대해 레이블이 지정된 데이터의 25%, 50%, 75%를 사용하여 추가로 미세 조정되는 다른 레이블이 지정된 데이터 체제를 설정했습니다. 우리는 각 작업에 대해 총 9개의 다른 모델을 훈련합니다. 2.
--- RELATED WORK ---
Visual Transformers Visual Transformers(ViT)는 최근 많은 컴퓨터 비전 작업에서 최첨단 성능을 달성했습니다[5, 19, 31]. 이들은 셀프 어텐션 메커니즘을 이미지 도메인에 적용하여 장거리 종속성과 상황 정보를 더 잘 포착할 수 있게 합니다. ViT는 지식 증류[29], 토큰 수준 및 패치 수준 변환기 계층[8]을 사용하거나 이미지를 점진적으로 다운샘플링하여 확장되었습니다[37]. ViT에 대한 포괄적인 검토는 Khan et al.의 작업에서 찾을 수 있습니다.[11]. 이 작업에서 우리는 미세 분류를 위한 지도 및 반지도 기술로 미세 조정된 ViT 아키텍처와 기존 CNN의 성능을 탐구하고 비교합니다. 전이 학습 전이 학습은 사전 학습된 모델을 활용하여 새로운 도메인에 적용합니다[13, 22, 25,41]. Yosinski et al.[35, 36]은 다양한 작업에서 딥 신경망이 학습한 기능의 전이성을 조사하여 그 효과를 입증했습니다. 전이 학습은 객체 탐지 및 의미 분할[6]과 비지도 도메인 적응[30]에도 적용되었습니다. 우리는 미세 조정을 사용합니다.
--- METHOD ---
영어: 다양한 시각적 인식 작업에서 [18]. 그러나 실제 시나리오에서 레이블이 지정된 데이터는 부족하고 얻기가 비쌀 수 있습니다. 따라서 semi*Joint first authors. 지도 학습(SSL) [40]은 레이블이 지정되지 않은 데이터를 활용하여 딥 신경망의 성능을 개선하는 강력한 기술로 등장했습니다. CNN 방법은 이 분야를 크게 발전시켰고 [1, 3, 15, 27, 32] ViT 아키텍처는 최근에야 SSL을 사용하여 유망한 결과를 보여주었습니다 [2,33]. 이 논문에서는 ViT 아키텍처와 함께 사용할 때 SSL의 효과를 조사합니다. 구체적으로 Semi-ViT 아키텍처 [2]를 사용하여 전자 상거래 데이터의 세밀한 분류를 위한 전이 학습을 수행합니다. 레이블이 지정되지 않은 이미지를 쉽게 사용할 수 있으므로 전자 상거래 데이터를 사용하면 SSL에 고유한 이점이 있습니다. 그러나 연관된 레이블은 종종 노이즈가 있거나 전혀 없습니다. 전통적으로 이 문제는 수동 큐레이터를 사용하여 해결되었으며, 이는 비용이 많이 들고 기존 마켓플레이스에서 주로 액세스할 수 있습니다. 라틴 아메리카와 같은 신흥 시장에서 신뢰할 수 있는 레이블이 지정된 데이터의 부족은 더 큰 과제로 작용합니다.우리는 레이블이 지정된 이미지와 레이블이 지정되지 않은 이미지가 포함된 전자 상거래 데이터에서 세 가지 데이터 세트를 수집합니다.우리는 조끼의 목 스타일(Vest Neck Style), 휴대전화 케이스의 패턴(Phone Case Pattern), 앞치마와 음식 턱받이의 패턴(Apron Food Bib Pattern)에 대한 세분화된 분류를 수행합니다.각 데이터 세트에는 각각 29K, 30K, 33K의 레이블이 지정된 이미지와 227K, 287K, 284K의 레이블이 지정되지 않은 이미지가 포함됩니다.레이블은 크라우드 소싱 방법을 사용하여 수집되었습니다.우리는 잘 알려진 ResNet 아키텍처[10], ViT, Semi-ViT 아키텍처의 세 가지 다른 모델을 미세 조정합니다.모두 ImageNet[4]에서 사전 학습되었습니다. ViT 및 SemiViT 아키텍처의 경우, 각 데이터 세트에 대해 레이블이 지정된 데이터의 25%, 50%, 75%를 사용하여 추가로 미세 조정되는 다른 레이블이 지정된 데이터 체제도 설정했습니다. 총 9개의 다른 모델을 각 작업에 대해 훈련했습니다. 2. 관련 작업 시각 변환기 시각 변환기(ViT)는 최근 많은 컴퓨터 비전 작업에서 최첨단 성능을 달성했습니다[5, 19, 31]. 이들은 셀프 어텐션 메커니즘을 이미지 도메인에 적용하여 장거리 종속성과 상황 정보를 더 잘 포착할 수 있도록 합니다. ViT는 지식 증류[29], 토큰 수준 및 패치 수준 변환기 계층[8]을 사용하거나 이미지를 점진적으로 다운샘플링하여 확장되었습니다[37]. ViT에 대한 포괄적인 검토는 Khan et al.의 작업[11]에서 찾을 수 있습니다. 이 연구에서 우리는 ViT 아키텍처와 전통적인 CNN의 성능을 탐색하고 비교하며, 미세 분류를 위해 지도 학습 및 반지도 학습 기법을 미세 조정했습니다.전이 학습 전이 학습은 사전 학습된 모델을 활용하여 새로운 도메인에 적응시킵니다[13, 22, 25,41].Yosinski et al.[35, 36]은 다양한 작업에서 딥 러닝 신경망이 학습한 기능의 전이성을 조사하여 그 효과를 입증했습니다.전이 학습은 또한 객체 감지 및 의미 분할[6]과 비지도 도메인 적응[30]에도 적용되었습니다.우리는 ResNet, ViT 및 Semi-Vit[2] 아키텍처에서 미세 조정 방법을 사용하여 세 가지 다른 데이터 세트에서 미세 분류를 수행합니다.반지도 학습반지도 학습(SSL)은 레이블이 지정된 데이터가 부족할 때 레이블이 지정된 데이터와 레이블이 지정되지 않은 데이터를 사용하여 모델 성능을 개선합니다[14, 34, 38]. 일관성 정규화와 함께 지능형 데이터 증강 기술을 활용하여 성능을 개선합니다[1, 20,32,39]. 다른 접근 방식은 의사 레이블링[17], 교사-학생 모델[24,28], 앙상블[15] 또는 적대적 훈련[12,21]에 의존합니다. 레이블이 지정된 데이터는 비용이 많이 들지만 많은 양의 레이블이 지정되지 않은 샘플을 검색할 수 있는 전자 상거래 이미지에 SSL을 적용합니다. SSL의 적용 가능성을 보여주고 레이블이 지정된 데이터의 필요성을 줄이는 데 효과적인지 보여줍니다. 3. 데이터 수집 저희의 목표는 많은 양의 레이블이 지정되지 않은 데이터를 가질 수 있는 전자 상거래 이미지에서 기존 CNN과 ViT 아키텍처의 성능을 비교하는 것입니다. 그러나 레이블이 지정된 데이터는 노이즈가 많거나 존재하지 않으므로 이를 레이블링하기 위한 크라우드 소싱 작업이 필요합니다. 우리는 세 가지 다른 데이터 세트를 사용하여 세분화된 분류를 수행합니다. 조끼의 목 스타일(조끼 목 스타일), 휴대전화 케이스의 패턴(전화 케이스 패턴), 음식 턱받이의 패턴(앞치마 음식 턱받이 Pataprons tern)을 예측합니다. 모든 이미지는 Amazon의 마켓플레이스에서 제공됩니다. 이미지에 레이블을 지정하기 위해 Amazon Mechanical Turk에 의존합니다. 레이블이 지정된 각 이미지에는 세 명의 다른 사람의 답변이 있습니다. 두 개 이상의 레이블이 같으면 이미지를 레이블이 지정된 것으로 간주하고, 그렇지 않으면 레이블을 버리고 레이블이 지정되지 않은 것으로 간주합니다. 주석의 품질을 보장하기 위해 이전에 예비 시험을 통과한 작업자만 허용했습니다.데이터 세트 데이터 세트 요약 레이블 지정됨 레이블 지정되지 않음 클래스 VestNeckStyle Phone Case Pattern Apron FoodBibPattern 29K 227K37K 287K39K 284K표 1. 전자 상거래 데이터에서 수집한 각 데이터 세트에 대한 레이블이 지정된 이미지, 레이블이 지정되지 않은 이미지의 수와 클래스 수의 요약. 모든 데이터 세트에는 other라는 이름의 클래스가 있습니다. 이 클래스는 앞서 언급한 데이터에 속하지 않는 이미지, 즉 조끼 목 스타일에서 조끼가 아닌 것을 보여주는 이미지에 레이블을 지정하는 데 사용됩니다. 친구 Häa 조끼 목 스타일 휴대전화 케이스 패턴 앞치마 음식 턱받이 패턴. 그림 1. 데이터 세트에 대해 수집된 이미지의 예. 위에서 아래로 조끼 목 스타일, 휴대전화 케이스 패턴, 앞치마 음식 턱받이 패턴에 대한 예를 볼 수 있습니다. 1차 테스트 작업. 표는 데이터 세트 통계에 대한 요약을 보여줍니다. 세 가지 작업 각각에 대해 수집한 이미지의 예는 그림 1에서 볼 수 있습니다. 4. 방법론 우리의 목표는 CNN과 최신 ViT 아키텍처의 성능을 비교하는 것입니다. 또한 모든 사용 가능한 레이블이 지정된 데이터를 사용하여 학습하는 동안 ViT(SemiViT)를 사용한 반지도 학습의 영향을 연구하고 ViT 및 Semi-ViT의 성능에서 더 제한적인 데이터 체제의 영향을 조사합니다. 모델 우리는 세 가지 다른 모델을 사용합니다.CNN(ResNet[10]) 모델, ViT[5] 모델, semi-ViT 모델[2](SSL로 학습된 ViT 모델)입니다.CNN의 경우 잘 알려진 ResNet18[10] 모델을 사용합니다.이 모델은 매개변수가 덜한 ResNet 모델이면서도 다양한 컴퓨터 비전 작업에서 놀라운 성능을 보였습니다.ViT 아키텍처에서 Masked Autoencoders(MAE)[9] ViT-Base 모델에 의존했습니다.ResNet과 유사한 접근 방식을 따르면 이는 매개변수 효율성이 가장 높은 MAE입니다.Semi-ViT 모델[2]의 경우에도 동일한 MAE VIT-Base 모델을 사용합니다.반지도 학습 단계에서 지수 이동 평균(EMA) Teacher 프레임워크와 확률적 의사 혼합[39] 방법을 함께 채택하여 레이블이 지정되지 않은 샘플과 해당 의사 레이블을 보간하여 더 나은 정규화를 구현합니다.데이터 레이블이 지정된 데이터는 학습, 검증 및 테스트로 구분됩니다. 전자상거래 데이터를 수집하기 때문에 기본 레이블 분포는 알 수 없고, 학습 및 검증 세트는 이미지 전체에 걸쳐 레이블이 균일하게 분포되지 않습니다. 모든 레이블에 대해 동일한 수의 이미지를 갖도록 테스트 세트를 샘플링합니다. 데이터 분포는 학습, 검증 및 테스트에 대해 각각 약 75%, 15% 및 10%입니다. 미세 조정 세 가지 모델 모두 ImageNet[4]에서 사전 학습되었습니다. 레이블이 지정된 샘플의 100%에서 모든 모델을 미세 조정합니다. ViT 및 Semi-ViT의 경우에도
--- EXPERIMENT ---
학습 데이터의 25%, 50%, 75%로 튜닝합니다. 성능을 공정하게 비교하기 위해 검증 및 테스트 세트는 동일하게 유지합니다. Semi-ViT의 경우 레이블이 지정된 데이터와 레이블이 지정되지 않은 데이터를 모두 사용하여 미세 조정한 후 반지도 학습을 수행합니다. SageMaker g5 인스턴스를 사용하여 모든 모델의 미세 조정을 조율하고, 세 모델의 학습 코드에서 제공된 원래 값 주변의 하이퍼 매개변수를 검색하도록 구성된 베이지안 검색[23]이 있는 하이퍼 매개변수 튜너에 의존합니다. 평균적으로 ResNet의 경우 모델을 학습하는 데 1시간, ViT의 경우 4시간, Semi-ViT의 경우 12시간이 걸렸습니다. 5. 결과 이 섹션에서는 세 가지 작업 모두에서 미세 조정된 모델에서 얻은 결과를 제시합니다. 표 2는 조끼 목 스타일, 전화 케이스 패턴, 앞치마 턱받이 패턴 작업에서 모든 모델에 대한 결과를 보여줍니다. 각각에 대해 학습에 사용된 데이터 비율, 정확도 top-(Acc@1) 및 top-5(Acc@5), 교차 엔트로피(CE) 오류를 보여줍니다. 모든 값은 테스트 세트에서 얻습니다. Semi-ViT 모델이 세 가지 작업 모두에서 다른 모델보다 성능이 뛰어나 SSL이 더 나은 일반화를 달성하는 데 도움이 된다는 것을 보여줍니다. 반면에 ResNet18은 최악의 성능을 얻는 모델입니다. 또 다른 흥미로운 발견은 일반적으로 ViT/50%의 성능이 Semi-ViT/25%와 동일하다는 것입니다. 따라서 anMethod ViT/100% ViT/75% VEST NECK STYLE Acc@1 Acc@Loss (CE) ResNet18/100% 79.736 98.0.81.244 99.0.81.056 98.0.80.584 98.0.76.343 96.0.Semi-ViT/100% 85.297 99.Semi-ViT/75% 83.129 98.Semi-ViT/50% 81.433 98.Semi-ViT/25% 81.244 97.0.0.0.0.ViT/50% ViT/25% PHONE CASE PATTERN Acc@1 Acc@Method Loss (CE) ResNet18/100% 72.931 97.0.ViT/100% ViT/75% ViT/50% 79.005 98.0.77.810 98.0.77.97.0.ViT/25% 74.175 97.0.Semi-ViT/100% 81.540 98.Semi-ViT/75% 80.010 98.Semi-ViT/50% 79.149 98.Semi-ViT/25% 76.279 97.0.0.0.0.방법 앞치마 음식 턱받이 패턴 Acc@1 Acc@ResNet18/100% 73.766 95.ViT/100% 78.ViT/75% 78.301 97.ViT/50% ViT/25% 손실(CE) 0.97.0.0.75.96.0.69.898 94.1.Semi-ViT/100% 81.814 97.0.Semi-ViT/75% 81.547 97.0.Semi-ViT/50% Semi-ViT/25% 77.234 97.73.499 94.0.0.표 2. 전자상거래 소스(이미지)와 크라우드 소싱 실험(레이블)에서 얻은 세 가지 데이터 세트에 대해 다양한 데이터 체제를 사용하는 ResNet18, ViT 및 Semi-ViT 모델을 사용한 결과. SSL 기술을 사용하는 시각적 변환기 모델인 Semi-ViT가 모든 작업에서 최상의 성능을 얻는 방법을 확인할 수 있습니다(녹색으로 강조 표시). 또한, 전자상거래에서 일반적인 시나리오인 희소 데이터 체제(예: 훈련 데이터의 50%)를 갖춘 Semi-ViT 모델이 두 배의 데이터 양으로 훈련된 ViT 모델과 비슷한 성능을 얻는 것을 볼 수 있습니다. 마찬가지로 Semi-ViT/50%의 성능은 ViT/100%와 동일하거나 더 우수합니다. 5.1. 클래스당 성능 Semi-ViT/100%를 사용하여 세 가지 작업 각각의 클래스당 성능을 분석하면 일반적으로 모델이 높은 정확도 상위 1값, 보통 레이블당 90% 이상을 달성하는 것을 알 수 있습니다. 훈련 세트에서 과소 표현된 레이블에서는 성능이 50% 미만입니다. Apron Food Bib Pattern 작업의 경우 성능이 낮은 세 가지 레이블(paisley, patched, trellis)은 각각 18.18%, 11.11%, 40.00%의 상위 1값 정확도를 보입니다. 그러나 이들은 각각 훈련 데이터의 0.17%, 0.07%, 0.56%에 불과합니다. Phone Case Pattern의 경우, 우리는 또한 paisley를 성과가 낮은 클래스로 관찰했지만, 훈련에서는 데이터의 0.71%에 불과했습니다. 흥미로운 사례 중 하나는 다른 클래스에서는 레이블을 지정할 수 없는 전화 케이스를 나타내는 불확실한 레이블입니다. 이 모델은 클래스가 샘플의 3.17%를 나타내는 경우에도 45.78%의 정확도를 보여줍니다. 우리는 이러한 낮은 성과가 이미지 간에 높은 수준의 변동성을 발견할 수 있는 &quot;와일드카드&quot; 클래스라는 사실 때문이라고 주장합니다. 마지막으로 Vest Neck Style의 경우, 밴드 칼라 레이블만 성과가 낮은 것으로 나타났습니다(17.65%). 이 레이블은 훈련 데이터의 0.82%에 불과했습니다. 5.2. 마켓플레이스별 성과 전자 상거래 데이터를 다운로드할 때, 이 이미지가 있는 마켓플레이스와 같은 메타데이터도 저장했습니다. 라틴 아메리카에서는 멕시코와 브라질에서 데이터를 얻었습니다. Vest Neck Style의 경우, Semi-ViT/100% 모델의 정확도 top-1이 멕시코에서 85.18%, 브라질에서 82.92%로 다른 지역과 비슷한 수준임을 발견했습니다.Phone Case Pattern의 경우 정확도 top-1은 멕시코에서 80.56%, 브라질에서 60.00%입니다.이 경우 다른 지역보다 브라질에서 상당히 적은 이미지를 발견했습니다.따라서 학습할 이미지가 적어 모델이 이 마켓플레이스의 이미지 특성을 제대로 학습하지 못했습니다.Apron Food Bib Pattern의 경우 정확도 top-1은 멕시코에서 78.88%, 브라질에서 81.91%로 다른 마켓플레이스와 비슷한 수준입니다.5.3. 레이블이 지정되지 않은 데이터 양에 미치는 영향 전자 상거래 데이터를 사용하므로 레이블이 지정되지 않은 새 이미지를 얻는 것은 매우 쉬운 프로세스입니다.따라서 레이블이 지정되지 않은 추가 데이터가 모델 성능에 미치는 영향을 조사합니다. 우리는 레이블이 지정된 데이터의 50%를 사용하여 Semi-ViT 모델을 선택했고(Semi-ViT/50%), 레이블이 지정되지 않은 데이터의 200%, 300%, 400%로 SSL을 사용하여 학습시켰습니다. 결국, Apron Food Bib Pattern 작업을 위해 총 1139K개의 레이블이 지정되지 않은 이미지를 추가로 수집했습니다. 표 3에서 레이블이 지정되지 않은 이미지를 추가하면 사용 가능한 레이블이 지정되지 않은 이미지의 200% 및 300%의 경우 성능이 향상되는 결과가 나오는 것을 알 수 있습니다. 그러나 성능이 감소하는 400%에서는 붕괴되는 것처럼 보이며 레이블이 지정되지 않은 데이터의 100%를 사용하는 것과 동일합니다. 추가 레이블이 지정되지 않은 Acc@1 Acc@5 손실(CE) 레이블이 지정되지 않음 284K(100%) 77.234 97.0.569K(200%). 78.301 97.0.79.146 96.77.679 96.0.0.854K(300%) 1139K(400%) 표 3. SemiViT/50% 모델을 사용하고 레이블이 지정되지 않은 데이터의 양을 늘린 Apron Food Bib Pattern에 대한 결과. 더 많은 데이터를 추가함에 따라 정확도와 손실 측면에서 성능이 어떻게 향상되는지 확인할 수 있습니다. 그러나 레이블이 지정되지 않은 데이터의 400%에서는 성능이 붕괴됩니다. 이는 레이블이 지정된 데이터의 비율이 레이블이 지정되지 않은 데이터보다 상당히 작아 레이블이 지정되지 않은 데이터가 학습을 주도하고 추가 일반화를 허용하지 않기 때문일 수 있다고 가정합니다. 레이블이 지정된 데이터는 레이블이 지정되지 않은 데이터에 비해 매우 작은 비율을 나타내므로 후자의 데이터가 모델의 학습을 주도하여 성능이 저하된다고 주장합니다. 6.
--- CONCLUSION ---
우리는 전자상거래 데이터에서 수집한 세 가지 데이터 세트에서 ResNet, ViT, Semi-Vit의 세 가지 모델로 실험을 수행했습니다. 전자상거래 데이터를 사용하면 레이블이 지정된 이미지와 레이블이 지정되지 않은 이미지를 조합하여 SSL의 영향을 평가할 수 있는 현실적인 설정이 제공되었습니다. 실험 결과 Semi-ViT는 다른 아키텍처에 비해 세분화된 분류 작업에서 SSL의 이점을 효과적으로 활용하여 성능을 개선할 수 있음을 보여주었습니다. Semi-ViT가 두 배의 데이터로 학습한 ViT 모델과 유사한 정확도 값을 얻는 방법을 확인할 수 있습니다. 이러한 결과는 레이블이 지정된 데이터의 필요성을 줄이면서도 높은 성능을 유지할 수 있는 가능성을 보여주는 데이터 세트에서 공유됩니다. 그럼에도 불구하고 탐색할 만한 열린 장소가 있습니다. 크라우드 소싱 레이블의 노이즈를 손실 함수에 통합하여 보다 강력한 모델을 만들거나, 세 가지 작업을 모두 단일 모델에서 수행하는 다중 속성 모델에 대한 SSL 기술을 만드는 것을 탐색할 수 있습니다. 참고문헌 [1] David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, Colin A Raffel. Mixmatch: 반지도 학습에 대한 전체론적 접근 방식. 신경 정보 처리 시스템의 발전, 32, 2019. 1,[2] Zhaowei Cai, Avinash Ravichandran, Paolo Favaro, Manchen Wang, Davide Modolo, Rahul Bhotika, Zhuowen Tu, Stefano Soatto. 규모에 따른 반지도 비전 변환기. arXiv 사전 인쇄본 arXiv:2208.05688, 2022. 1, 2,[3] Zhaowei Cai, Avinash Ravichandran, Subhransu Maji, Charless Fowlkes, Zhuowen Tu, Stefano Soatto. 자기 지도 및 반지도 학습을 위한 지수 이동 평균 정규화. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 194-203페이지, 2021.[4] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei. Imagenet: 대규모 계층적 이미지 데이터베이스. 2009년 IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스, 248-255페이지. IEEE, 2009. 1,[5] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. 이미지는 16x16 단어의 가치가 있습니다. 대규모 이미지 인식을 위한 변압기. arXiv 사전 인쇄본 arXiv:2010.11929, 2020. 1,[6] Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik. 정확한 객체 감지 및 의미 분할을 위한 풍부한 기능 계층. IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 580-587페이지, 2014.[7] Ian Goodfellow, Yoshua Bengio, Aaron Courville. 딥 러닝. MIT 출판부, 2016.[8] Kai Han, An Xiao, Enhua Wu, Jianyuan Guo, Chunjing Xu, Yunhe Wang. 변압기의 변압기. 신경 정보 처리 시스템의 발전, 34:15908-15919, 2021.[9] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, Ross Girshick. 마스크 자동 인코더는 확장 가능한 비전 학습기입니다. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 16000~16009페이지, 2022년.[10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. 이미지 인식을 위한 심층 잔여 학습. IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 770~778페이지, 2016년. 1, 2,[11] Salman Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, Fahad Shahbaz Khan, Mubarak Shah. 비전의 변압기: 조사. ACM 컴퓨팅 조사(CSUR), 54(10s):1~41, 2022년.[12] Abhishek Kumar, Prasanna Sattigeri, Tom Fletcher. 반지도 학습과 gans: 개선된 추론을 통한 매니폴드 불변성. 신경 정보 처리 시스템의 발전, 30, 2017.[13] Manuel Lagunas 및 Elena Garces. 일러스트레이션 분류를 위한 전이 학습. arXiv 사전 인쇄본 arXiv:1806.02682, 2018.[14] Manuel Lagunas, Sandra Malpica, Ana Serrano, Elena Garces, Diego Gutierrez 및 Belen Masia. 재료 외관에 대한 유사성 측정. ACM Transactions on Graphics(TOG, Proc. SIGGRAPH), 2019.[15] Samuli Laine 및 Timo Aila. 반지도 학습을 위한 시간적 앙상블. arXiv 사전 인쇄본 arXiv:1610.02242, 2016. 1,[16] Yann LeCun, Yoshua Bengio 및 Geoffrey Hinton. 딥 러닝. nature, 521(7553):436–444, 2015.[17] Dong-Hyun Lee et al. Pseudo-label: The simple and efficient ring-supervised learning method for deep neural networks. In Workshop on challenges in representation learning, ICML, volume 3, page 896, 2013.[18] Yang Liu, Yao Zhang, Yixin Wang, Feng Hou, Jin Yuan, Jiang Tian, Yang Zhang, Zhongchao Shi, Jianping Fan, and Zhiqiang He. A survey of visual transformers. arXiv preprint arXiv:2111.06091, 2021.[19] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows. IEEE/CVF 국제 컴퓨터 비전 컨퍼런스 논문집, 10012-10022페이지, 2021.[20] Takeru Miyato, Toshiki Kataoka, Masanori Koyama, Yuichi Yoshida. 생성적 적대적 네트워크를 위한 스펙트럼 정규화. arXiv 사전 인쇄본 arXiv:1802.05957, 2018.[21] Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, Shin Ishii. 가상 적대적 학습: 지도 학습 및 반지도 학습을 위한 정규화 방법. IEEE 패턴 분석 및 머신 인텔리전스 거래, 41(8):1979-1993, 2018.[22] Maxime Oquab, Leon Bottou, Ivan Laptev, Josef Sivic. 합성곱 신경망을 사용하여 중간 수준 이미지 표현 학습 및 전송. IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 1717-1724페이지, 2014년.[23] Valerio Perrone, Huibin Shen, Aida Zolic, Iaroslav Shcherbatyi, Amr Ahmed, Tanya Bansal, Michele Donini, Fela Winkelmolen, Rodolphe Jenatton, Jean Baptiste Faddoul 외. Amazon sagemaker 자동 모델 튜닝: 확장 가능한 그래디언트 없는 최적화. 지식 발견 및 데이터 마이닝에 관한 제27회 ACM SIGKDD 컨퍼런스 회의록, 3463-3471페이지, 2021년.[24] Siyuan Qiao, Wei Shen, Zhishuai Zhang, Bo Wang, Alan Yuille. 반지도 이미지 인식을 위한 심층 공동 학습. 유럽 컴퓨터 비전 컨퍼런스(ECCV) 회의록, 135-152페이지, 2018년.[25] Matthia Sabatelli, Mike Kestemont, Walter Daelemans, Pierre Geurts. 아트 분류 문제를 위한 심층 전이 학습. 유럽 컴퓨터 비전 컨퍼런스(ECCV) 워크숍 회의록, 0-0페이지, 2018년.[26] Karen Simonyan, Andrew Zisserman. 대규모 이미지 인식을 위한 매우 깊은 합성곱 네트워크. arXiv 사전 인쇄본 arXiv:1409.1556, 2014년.[27] Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang, Colin A Raffel, Ekin Dogus Cubuk, Alexey Kurakin, Chun-Liang Li. Fixmatch: 일관성과 확신을 갖춘 반지도 학습 간소화. 신경 정보 처리 시스템의 발전, 33:596608, 2020.[28] Antti Tarvainen 및 Harri Valpola. 평균적인 교사가 더 나은 롤 모델입니다. 가중치 평균 일관성 목표는 반지도 딥 러닝 결과를 개선합니다. 신경 정보 처리 시스템의 발전, 30, 2017.[29] Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles 및 Hervé Jégou. 주의를 통한 데이터 효율적인 이미지 변환기 및 증류 교육. 기계 학습에 관한 국제 컨퍼런스, 10347-10357페이지. PMLR, 2021.[30] Eric Tzeng, Judy Hoffman, Kate Saenko 및 Trevor Darrell. 적대적 차별 도메인 적응. IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 7167-7176페이지, 2017.[31] Ashish Vaswani, Prajit Ramachandran, Aravind Srinivas, Niki Parmar, Blake Hechtman, Jonathon Shlens. 매개변수 효율적 시각적 백본을 위한 로컬 자기 주의 확장. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스 회의록, 12894-12904페이지, 2021.[32] Qizhe Xie, Zihang Dai, Eduard Hovy, Thang Luong, Quoc Le. 일관성 훈련을 위한 비지도 데이터 증강. 신경 정보 처리 시스템의 발전, 33:6256-6268, 2020. 1,[33] Zhen Xing, Qi Dai, Han Hu, Jingjing Chen, Zuxuan Wu, Yu-Gang Jiang. Svformer: 액션 인식을 위한 반지도 비디오 변환기. arXiv 사전 인쇄본 arXiv:2211.13222, 2022.[34] Xiangli Yang, Zixing Song, Irwin King, Zenglin Xu. 딥 반지도 학습에 대한 조사. IEEE 지식 및 데이터 공학 저널, 2022.[35] Jason Yosinski, Jeff Clune, Yoshua Bengio, Hod Lipson. 딥 신경망의 특징은 얼마나 이전 가능한가? 신경 정보 처리 시스템의 발전, 27, 2014.[36] Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, Hod Lipson. 심층적 시각화를 통한 신경망 이해. arXiv 사전 인쇄본 arXiv:1506.06579, 2015.[37] Xiaoyu Yue, Shuyang Sun, Zhanghui Kuang, Meng Wei, Philip HS Torr, Wayne Zhang, Dahua Lin. 점진적 샘플링을 통한 비전 변환기. IEEE/CVF 국제 컴퓨터 비전 컨퍼런스 회의록, 387-396페이지, 2021.[38] Brayan S Zapata-Impata 및 Pablo Gil. 변형 가능한 물체에 대한 시각을 통한 촉각 지각 예측. 2020.[39] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, David Lopez-Paz. 혼동: 경험적 위험 최소화를 넘어서. arXiv 사전 인쇄 arXiv:1710.09412, 2017. 2,[40] Xiaojin Jerry Zhu. 준지도 학습 문헌 조사. 2005.[41] Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui Xiong 및 Qing He. 전이학습에 관한 종합적인 조사입니다. IEEE 간행물, 109(1):43-76, 2020.
