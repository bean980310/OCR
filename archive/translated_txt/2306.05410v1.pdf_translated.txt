--- ABSTRACT ---
NeRF 모델이 야외에서 광범위하게 배포되는 것을 막는 중요한 장애물은 정확한 카메라 포즈에 대한 의존성입니다. 결과적으로 NeRF 모델을 확장하여 카메라 포즈와 장면 표현을 공동으로 최적화하는 데 대한 관심이 커지고 있으며, 이는 잘 알려진 실패 모드가 있는 기성품 SfM 파이프라인에 대한 대안을 제공합니다. 포즈가 없는 NeRF에 대한 기존 접근 방식은 사전 포즈 분포 또는 거친 포즈 초기화와 같은 제한적인 가정 하에 작동하여 일반적인 설정에서 덜 효과적입니다. 이 작업에서 우리는 포즈 구성에 대한 느슨한 가정을 사용하여 카메라 포즈와 신경 광도장을 공동으로 추정하는 새로운 접근 방식인 LU-NeRF를 제안합니다. 우리의 접근 방식은 로컬에서 글로벌로의 방식으로 작동하며, 여기서 먼저 &quot;미니 장면&quot;이라고 하는 데이터의 로컬 하위 집합을 최적화합니다. LU-NeRF는 이 어려운 몇 샷 작업에 대한 로컬 포즈와 지오메트리를 추정합니다. 미니 장면 포즈는 강력한 포즈 동기화 단계를 통해 글로벌 참조 프레임으로 가져오며, 여기서 포즈와 장면의 최종 글로벌 최적화를 수행할 수 있습니다. 우리는 우리의 LU-NeRF 파이프라인이 포즈 사전에 제한적인 가정을 하지 않고도 포즈를 취하지 않은 NeRF에 대한 이전 시도보다 성능이 뛰어나다는 것을 보여줍니다. 이를 통해 베이스라인과 달리 일반적인 SE(3) 포즈 설정에서 작동할 수 있습니다. 우리의 결과는 또한 우리의 모델이 낮은 텍스처 및 낮은 해상도 이미지에서 COLMAP과 유리하게 비교되므로 피처 기반 SfM 파이프라인을 보완할 수 있음을 나타냅니다. 1.
--- INTRODUCTION ---
NERF[35]는 신경 장면 표현과 사실적인 뷰 합성을 학습하는 문제를 해결하는 강력한 방법으로 소개되었으며, 이후 연구는 더 광범위한 사용 사례에 적용 가능성을 확장하기 위해 한계를 해결하는 데 중점을 두었습니다(설문 조사는 [55, 60] 참조). 야외에서 뷰 합성을 위한 몇 안 되는 남은 장애물 중 하나는 정확한 현지화의 필요성입니다. 야외에서 촬영한 이미지에는 포즈가 알려지지 않았기 때문에 이러한 ap*Google에서 인턴십을 하는 동안 수행한 작업. 프로젝트 웹사이트 접근 방식은 종종 구조-동작-기반(SfM)[49, 41]을 사용하여 카메라 포즈를 결정합니다. SfM이 실패하면 종종 구제책이 없으며(예는 그림 7 참조) 사실 카메라 포즈 추정의 작은 부정확성조차도 사실성에 극적인 영향을 미칠 수 있습니다. 이전에 포즈 추정을 NeRF 프레임워크 내에 직접 통합하여 SfM에 대한 의존도를 줄이려는 시도는 거의 없었습니다. 그러나 이 문제는 심각하게 제약이 부족하고(그림 1 참조) 현재의 접근 방식은 문제를 다루기 쉽게 만들기 위해 추가적인 가정을 합니다. 예를 들어, NeRf-- [57]는 정면 구성에서 포즈 추정에 초점을 맞추고, BARF [30] 초기화는 실제 포즈에 가까워야 하며, GNeRF [33]는 2D 카메라 모델(반구에 있는 수직 카메라)을 가정합니다. 우리는 이전에 가능했던 것보다 더 일반적인 카메라 구성을 허용하면서 단일 장면의 이미지에서 카메라 포즈와 장면 표현을 공동으로 추정하는 접근 방식을 제안합니다. 개념적으로, 우리의 접근 방식은 NeRF를 사용하여 로컬-글로벌 학습 프레임워크로 구성됩니다. 로컬 처리 단계에서 우리는 장면을 겹치는 하위 집합으로 분할하고, 각각은 몇 개의 이미지만 포함합니다(이러한 하위 집합을 미니 장면이라고 합니다). 미니 장면의 이미지가 대부분 근처에 있다는 것을 아는 것은 포즈와 장면의 공동 추정을 동일한 작업을 전역적으로 수행하는 것보다 더 나은 조건화로 만듭니다. 글로벌 스테이지에서 겹치는 미니 장면은 포즈 동기화를 통해 공통 참조 프레임에 등록되고, 이어서 모든 포즈를 공동으로 정제하고 글로벌 장면 표현을 학습합니다.미니 장면으로의 이러한 구성에는 몇 개의 로컬 비포즈 이미지에서 학습이 필요합니다.몇 개의 샷으로 구성된 새로운 뷰 합성[62, 28, 39, 21, 13, 12]을 위한 방법과 알려지지 않은 포즈를 최적화하기 위한 별도의 방법[30, 33, 57]이 있지만, 결합된 설정은 새로운 과제를 제시합니다.우리의 모델은 로컬 비포즈 설정에서 널리 퍼진 모호성, 특히 두 개의 별개의 3D 장면과 카메라 구성이 아핀 투영에서 유사한 이미지를 생성하는 거울 대칭 모호성[40]을 조정해야 합니다.우리는 이러한 과제를 원칙적인 방식으로 해결하기 위해 로컬 비포즈 NeRF(LU-NeRF) 모델을 도입합니다. LU-NeRF(추정 포즈, 신뢰도 및 거울 대칭 분석)의 정보는 모든 camBARF를 등록하는 데 사용됩니다.포즈 오류: 25.05°(R), 0.54(T) 참고: 초기 포즈 오류 43°(R), 0.71(T) GNERF 포즈 오류: 8.77°(R), 0.53(T) 참고: 2D 카메라, 고도 범위(-90°, 90°) LU-NeRF+Sync(저희) 포즈 오류: 0.09°(R), 0.00(T) 참고: 제약 없는 LU-NeRF, 전체 SO(3) 평균화 저희 모델에서 합성된 새로운 뷰.그림 1. 전체 장면에서 카메라 포즈와 장면 표현을 공동으로 최적화하는 것은 어렵고 제약이 부족합니다.이 예는 Blender 데이터 세트의 100개 이미지가 있는 Lego 장면입니다. 왼쪽: 실제 카메라 위치에 대한 노이즈가 있는 관찰이 제공되면 BARF[30]는 올바른 포즈로 수렴할 수 없습니다. 가운데: GNERF[33]는 정확히 같은 구성(구면 위의 수직 카메라)을 가진 Blender 데이터 세트에 대해 정확한 2D 카메라 표현(방위, 고도)을 가정합니다. 그러나 GNeRF는 샘플링을 위해 포즈에 대한 정확한 사전 분포도 요구합니다. Lego 이미지는 한 반구에 있지만 GNeRF의 사전 분포가 전체 구인 경우 이미지를 정확하게 지역화하지 못합니다. 오른쪽: 전체 모델인 LU-NeRF+Sync는 이 특정 예에서 포즈를 거의 완벽하게 복구할 수 있습니다. 로컬-글로벌 접근 방식을 취함으로써 카메라 표현이나 포즈 사전 확률에 대한 강력한 가정을 피합니다. 각 방법에 대한 [30, 33] 포즈 오류는 추정된 포즈를 기준 진실 포즈에 대한 최적의 전역 정렬 후 보고됩니다. 변환 오류를 맥락에 맞게 설명하기 위해 Blender 카메라는 반지름 4.03의 구에 있습니다. 영어: 포즈 동기화[20, 43, 24]를 통해 공통 참조 프레임에서 시대를 학습한 후, 모든 이미지를 사용하여 포즈를 개선하고 신경 장면 표현을 최적화합니다.요약하면, 우리의 주요 기여는 다음과 같습니다.• 일반 구성의 카메라 포즈와 포즈를 취하지 않은 이미지 세트에서만 신경 장면 표현을 모두 학습하는 로컬-글로벌 파이프라인.• 소수 샷 로컬 비포즈 NeRF를 위한 새로운 모델인 LU-NeRF.LU-NERF는 거울 대칭 구성을 조정하는 것과 같이 이 설정에서 확인한 고유한 과제에 맞게 조정되었습니다.로컬-글로벌 프로세스의 각 단계는 견고성을 염두에 두고 설계되었으며, 그 결과 초기 미니 장면에 빈번한 이상치가 포함되어 있어도 파이프라인이 성공할 수 있습니다(다른 미니 장면 구성 기술에 대한 논의는 섹션 4 참조).우리 방법의 성능은 카메라 포즈와 장면 표현을 함께 최적화하는 이전 작업을 능가하는 동시에 이전 기술과 달리 일반 SE(3) 포즈 설정에서 작동할 만큼 유연합니다. 실험 결과, 해당 파이프라인은 NeRF 모델을 초기화하는 데 사용된 피처 기반 SfM 파이프라인을 보완하며, 텍스처가 낮거나 해상도가 낮은 환경에서 더욱 안정적이라는 것이 밝혀졌습니다. 2.
--- RELATED WORK ---
동작으로부터의 구조(SfM). 3D 장면을 공동으로 복구하고 장면의 여러 뷰에서 카메라 포즈를 추정하는 것은 컴퓨터 비전의 고전적인 문제입니다[25]. 순서 없는 이미지 컬렉션과 순차적 데이터에 대한 시각적 SLAM[54, 38]을 사용하여 SfM[41, 49]에 대한 수많은 기술이 제안되었습니다. 이러한 기술은 주로 로컬 기능[32, 45, 22, 52]에 기반하며 이미지 전체에서 정확한 탐지 및 매칭이 필요합니다. 이러한 기술의 성공으로 인해 널리 채택되었으며, 장면 표현 및 새로운 뷰 합성을 위한 기존의 딥 러닝 접근 방식은 SfM 기술이 실제로 정확한 포즈를 제공한다는 암묵적인 가정 하에 설계되었습니다. 예를 들어, NeRF[35]와 그 많은 후속 기술(예: [5, 6, 37])은 COLMAP[49, 31]을 사용하여 오프라인으로 추정된 포즈를 활용합니다. 그러나 COLMAP은 텍스처가 없는 영역과 저해상도 이미지에서는 실패할 수 있습니다. 이 연구에서 제안하는 로컬-글로벌 프레임워크는 &quot;분할 정복&quot; SfM 및 SLAM에서 영감을 받았습니다.
--- METHOD ---
영어: 신경 장면 표현과 사실적인 뷰 합성을 학습하는 문제를 해결하기 위해 후속 연구는 더 광범위한 사용 사례에 적용 가능성을 확장하기 위해 한계를 해결하는 데 중점을 두었습니다(설문 조사는 [55, 60] 참조). 야외에서 뷰 합성을 위한 몇 안 되는 남은 장애물 중 하나는 정확한 현지화가 필요하다는 것입니다. 야외에서 촬영한 이미지에는 포즈가 알려지지 않았기 때문에 이러한 ap*Google에서 인턴십을 하는 동안 수행한 작업. 프로젝트 웹사이트 접근 방식은 종종 구조-동작-기반(SfM)[49, 41]을 사용하여 카메라 포즈를 결정합니다. SfM이 실패하면 종종 구제책이 없으며(예는 그림 7 참조) 사실 카메라 포즈 추정의 작은 부정확성조차도 사실성에 극적인 영향을 미칠 수 있습니다. 포즈 추정을 NeRF 프레임워크 내에서 직접 통합하여 SfM에 대한 의존도를 줄이려는 이전 시도는 거의 없었습니다. 그러나 이 문제는 심각하게 제약이 부족하고(그림 1 참조) 현재의 접근 방식은 문제를 다루기 쉽게 만들기 위해 추가적인 가정을 합니다. 예를 들어, NeRf-- [57]는 정면 구성에서 포즈 추정에 초점을 맞추고, BARF [30] 초기화는 실제 포즈에 가까워야 하며, GNeRF [33]는 2D 카메라 모델(반구에 있는 수직 카메라)을 가정합니다. 우리는 이전에 가능했던 것보다 더 일반적인 카메라 구성을 허용하면서 단일 장면의 이미지에서 카메라 포즈와 장면 표현을 공동으로 추정하는 접근 방식을 제안합니다. 개념적으로, 우리의 접근 방식은 NeRF를 사용하여 로컬-글로벌 학습 프레임워크로 구성됩니다. 로컬 처리 단계에서 우리는 장면을 겹치는 하위 집합으로 분할하고, 각각은 몇 개의 이미지만 포함합니다(이러한 하위 집합을 미니 장면이라고 합니다). 미니 장면의 이미지가 대부분 근처에 있다는 것을 아는 것은 포즈와 장면의 공동 추정을 동일한 작업을 전역적으로 수행하는 것보다 더 나은 조건화로 만듭니다. 글로벌 스테이지에서 겹치는 미니 장면은 포즈 동기화를 통해 공통 참조 프레임에 등록되고, 이어서 모든 포즈를 공동으로 정제하고 글로벌 장면 표현을 학습합니다.미니 장면으로의 이러한 구성에는 몇 개의 로컬 비포즈 이미지에서 학습이 필요합니다.몇 개의 샷으로 구성된 새로운 뷰 합성[62, 28, 39, 21, 13, 12]을 위한 방법과 알려지지 않은 포즈를 최적화하기 위한 별도의 방법[30, 33, 57]이 있지만, 결합된 설정은 새로운 과제를 제시합니다.우리의 모델은 로컬 비포즈 설정에서 널리 퍼진 모호성, 특히 두 개의 별개의 3D 장면과 카메라 구성이 아핀 투영에서 유사한 이미지를 생성하는 거울 대칭 모호성[40]을 조정해야 합니다.우리는 이러한 과제를 원칙적인 방식으로 해결하기 위해 로컬 비포즈 NeRF(LU-NeRF) 모델을 도입합니다. LU-NeRF(추정 포즈, 신뢰도 및 거울 대칭 분석)의 정보는 모든 camBARF를 등록하는 데 사용됩니다.포즈 오류: 25.05°(R), 0.54(T) 참고: 초기 포즈 오류 43°(R), 0.71(T) GNERF 포즈 오류: 8.77°(R), 0.53(T) 참고: 2D 카메라, 고도 범위(-90°, 90°) LU-NeRF+Sync(저희) 포즈 오류: 0.09°(R), 0.00(T) 참고: 제약 없는 LU-NeRF, 전체 SO(3) 평균화 저희 모델에서 합성된 새로운 뷰.그림 1. 전체 장면에서 카메라 포즈와 장면 표현을 공동으로 최적화하는 것은 어렵고 제약이 부족합니다.이 예는 Blender 데이터 세트의 100개 이미지가 있는 Lego 장면입니다. 왼쪽: 실제 카메라 위치에 대한 노이즈가 있는 관찰이 제공되면 BARF[30]는 올바른 포즈로 수렴할 수 없습니다. 가운데: GNERF[33]는 정확히 같은 구성(구면 위의 수직 카메라)을 가진 Blender 데이터 세트에 대해 정확한 2D 카메라 표현(방위, 고도)을 가정합니다. 그러나 GNeRF는 샘플링을 위해 포즈에 대한 정확한 사전 분포도 요구합니다. Lego 이미지는 한 반구에 있지만 GNeRF의 사전 분포가 전체 구인 경우 이미지를 정확하게 지역화하지 못합니다. 오른쪽: 전체 모델인 LU-NeRF+Sync는 이 특정 예에서 포즈를 거의 완벽하게 복구할 수 있습니다. 로컬-글로벌 접근 방식을 취함으로써 카메라 표현이나 포즈 사전 확률에 대한 강력한 가정을 피합니다. 각 방법에 대한 [30, 33] 포즈 오류는 추정된 포즈를 기준 진실 포즈에 대한 최적의 전역 정렬 후 보고됩니다. 변환 오류를 맥락에 맞게 설명하기 위해 Blender 카메라는 반지름 4.03의 구에 있습니다. 영어: 포즈 동기화[20, 43, 24]를 통해 공통 참조 프레임에서 시대를 학습한 후, 포즈를 개선하고 모든 이미지를 사용하여 신경 장면 표현을 최적화합니다.요약하면, 우리의 주요 기여는 다음과 같습니다.• 일반 구성의 카메라 포즈와 포즈를 취하지 않은 이미지 세트에서만 신경 장면 표현을 모두 학습하는 로컬-글로벌 파이프라인.• 소수 샷 로컬 비포즈 NeRF를 위한 새로운 모델인 LU-NeRF.LU-NERF는 거울 대칭 구성을 조정하는 것과 같이 이 설정에서 식별한 고유한 과제에 맞게 조정되었습니다.로컬-글로벌 프로세스의 각 단계는 견고성을 염두에 두고 설계되었으며, 그 결과 초기 미니 장면에 빈번한 이상치가 포함되어 있어도 파이프라인이 성공할 수 있습니다(다른 미니 장면 구성 기술에 대한 논의는 4절 참조).우리 방법의 성능은 카메라 포즈와 장면 표현을 함께 최적화하는 이전 작업을 능가하는 동시에 이전 기술과 달리 일반 SE(3) 포즈 설정에서 작동할 만큼 유연합니다.우리의
