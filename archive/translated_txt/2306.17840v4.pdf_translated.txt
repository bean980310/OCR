--- ABSTRACT ---
―지능형 로봇에 복잡한 추론 기능을 부여하기 위해 대규모 언어 모델을 사용하는 데 대한 연구 관심이 상당했습니다. 기존 연구는 로봇의 행동과 관찰의 이력에 대해 추론하는 능력을 활용하는 데 중점을 두고 있습니다. 이 논문에서는 대규모 언어 모델이 로봇 계획에 도움이 될 수 있는 새로운 차원을 탐구합니다. 특히, 대규모 언어 모델이 종종 관찰할 수 없는 세계 상태에 대한 추정을 유지하고 새로운 작업이 수행됨에 따라 전환을 추적하도록 하는 프레임워크인 Statler를 제안합니다. 그런 다음 프레임워크는 각 작업을 현재 세계 상태에 대한 추정에 따라 조건을 지정합니다. 개념적으로 간단함에도 불구하고 Statler 프레임워크는 여러 로봇 계획 작업에서 강력한 경쟁 방법(예: Codeas-Policies)보다 상당히 우수한 성능을 보입니다. 또한 더 어려운 장기적 계획 작업으로 확장할 수 있는 잠재적 이점이 있습니다. 여기에서 코드를 공개합니다. I.
--- INTRODUCTION ---
대규모 언어 모델(LLM)은 대화 및 코드 생성과 같은 광범위한 다운스트림 작업을 수행하는 데 활용되는 강력한 추론 기능을 보여줍니다[13]. 로봇 커뮤니티는 최근 로봇에 LLM을 부여하여 *동등한 기여를 나타냄; 각 저자의 기여는 부록에서 찾을 수 있습니다. 자연어 명령을 이해하고 정교한 추론이 필요한 작업을 수행할 수 있도록 하는 데 상당한 관심을 보였습니다[4-7]. 그러나 기존 방법은 모델이 없습니다. 즉, LLM을 정책 함수로 사용하여 이전 작업과 관찰에만 조건이 지정된 미래 작업을 생성합니다. 이 논문에서는 간단하면서도 효과적인 모델 기반 접근 방식을 제안합니다. Statler라는 이름의 프레임워크는 대규모 언어 모델을 촉구하여 세계 상태에 대한 실행 추정을 유지하고 추정된 상태에 따라 다단계 구체화된 추론을 수행합니다. 그림 1은 이 프레임워크를 보여줍니다. 특히, Statler는 프롬프트 LLM 쌍을 활용합니다. 몇 가지 데모에 의해 지시된 세계 상태 판독기는 사용자 쿼리를 입력으로 받고 추정된 세계 상태를 읽고 실행 가능한 작업(예: 코드 조각)을 생성합니다. 다른 데모 세트에 의해 지시된 세계 상태 작성기는 작업에 따라 세계 상태 추정치를 업데이트합니다. 이 메커니즘은 도메인별 형식 언어가 기호 세계 상태를 추적하는 방식[8]과 유사하지만 사전 학습된 대규모 언어 모델은 도메인과 무관한 것으로 알려져 있기 때문에 더 큰 유연성을 누립니다. 곧 섹션 IV에서 볼 수 있듯이 실험의 프롬프트는 일반적이며 프레임워크 사용자는 최소한의 설계 작업 부하를 갖습니다. Statler 프레임워크는 주로 고전적인 1 #23 초기 상태 2개의 컵 [거짓, 참, 거짓] 3 컵 1과 컵4 교환 컵 0과 컵5 교환 컵 1과 컵6 교환 컵 = [참, 거짓, 거짓]1 #3 초기 상태 2개의 컵 [거짓, 참, 거짓] 3 컵 1과 컵4 교환 컵 0과 컵5 교환 컵 1과 컵6 교환 컵 = [거짓, 거짓, 참] 7개의 컵 = [참, 거짓, 거짓] 8개의 컵 = [참, 거짓, 거짓] 1 # 초기 상태 2개의 컵 [거짓, 참, 거짓] 3 컵 1과 컵4 교환 컵 [거짓, 거짓, 참] 5 컵 0과 컵6 교환 컵 [참, 거짓, 거짓] 7 컵 1과 컵8 교환 컵 [참, 거짓, 거짓] 프롬프트 1: 프롬프트와 원하는 출력 프롬프트 2: 프롬프트와 원하는 출력 프롬프트 3: 바닐라 LLM의 프롬프트와 원하는 출력. LLM+COT. 모델 기반 강화 학습. 모델 기반 접근 방식에서 환경(또는 세계) 모델은 환경의 역학(예: 작업의 가능한 결과)을 포착하는 방법을 학습하여 모델 상태에 따라 조건화된 정책이 보다 정보에 입각한 작업을 수행합니다[9]. 저희 프레임워크에서 LLM은 사전 학습을 통해 엄청난 양의 상식적 지식을 습득했으며 몇 가지 데모를 통해 환경 모델처럼 작동하여 세계 상태를 추정하고 의사 결정을 용이하게 하도록 유도됩니다. 저희 설계의 또 다른 동기는 누락된 데이터를 처리하는 것입니다. 로봇 작업에서 우리는 종종 직접 관찰할 수 없는 잠재적 세계 역학에 대처해야 합니다. 이러한 시나리오에서 추정된 세계 상태를 명시적으로 유지하면 추정이 불완전할 수 있지만 의사 결정이 개선됩니다. 이것은 잠재 변수가 있는 그래픽 모델과 유사합니다.잠재 변수를 설명하고 값을 대입하는 것은 종종 대상 변수에 대한 추론에 도움이 되지만 대입이 완벽하지 않을 수 있습니다[10].상태 유지 설계의 최종 동기는 장기적 계획 작업으로 확장할 수 있는 잠재력입니다.다단계 추론 및 계획에서 LLM은 내부 표현에서 세계 상태를 암묵적으로 유지해야 하는데, 이는 이전 작업에서 어려운 것으로 입증되었습니다[11–17].추정된 세계 상태를 명시적으로 유지함으로써 프레임워크는 추론 및 계획의 모든 단계에서 세계 상태를 추적하고 참조하기가 더 쉬워지므로 장기적 작업에서 성공할 가능성이 더 높습니다.다음 섹션에서는 프레임워크가 예상대로 수행되는지 보여드리겠습니다.섹션 II에서는 교육적 예를 통해 개념을 시연합니다.섹션 III에서는 Statler 프레임워크를 소개합니다.섹션 IV에서는 실험을 제시하는데, 이 실험에서 프레임워크는 Code-as-Policies[5]와 같은 강력한 경쟁 방법보다 상당히 우수한 성과를 보입니다.II. 동기를 부여하는 사례 우리는 간단한 쉘 게임인 three-cups-and-a-ball을 사용하여 상태 유지 아이디어의 효과를 보여줍니다. 이 게임에서 공은 세 개의 동일한 컵 중 하나로 덮여 있으며 공의 초기 위치는 플레이어에게 알려져 있습니다. K라운드 각각에서 우리는 두 개의 컵의 위치를 무작위로 바꿉니다. 마지막으로, 우리는 플레이어에게 공의 위치를 추측하도록 요청합니다. 우리는 GPT-3(정확히는 text-davinci-003)를 사용하여 이 게임을 플레이하기 위해 LLM을 사용하는 세 가지 별도의 사례를 제시합니다. Prompt는 가장 간단한 사례를 보여줍니다. 우리는 &quot;공이 여기 있다&quot;를 나타내는 True를 갖는 부울 변수로 상태를 표현합니다. 우리는 초기 상태와 K라운드의 스왑을 GPT3에 공급하여 최종 상태를 완료하도록 지시합니다. Prompt 2는 개선된 방법입니다. K라운드의 스왑을 읽은 후, GPT-LLM+State의 절대 정확도. 1.1.10.8. 0.0.6. LLM -0.LLM+COT 0.LLM+State 0.J0.-0.0.0.스왑 수 상대 정확도: 그림 2: 3컵 앤 어 볼 쉘 게임의 모델 정확도.LLM+State는 제안된 Statler 프레임워크의 단순화된 버전입니다.각 방법에서 실선은 정확도 a(n)이 스왑 수 n에 따라 어떻게 변하는지 보여줍니다.점선은 상대 정확도입니다.r(n) = a(n)/a(1).직관적으로, 이는 가설적으로 완벽한 1스왑 성능에서 성능이 얼마나 빨리 감소하는지 측정합니다.LLM+State가 실제로 a(1) = 100%를 달성한다는 점에 유의하세요.게임에서 모든 중간 상태를 제공하라는 요청을 받았습니다.이 버전은 중간 추론 단계를 설명하도록 요청하여 LLM의 성능을 개선하는 Chain-of-Thought 프롬프팅[18]에서 영감을 받았습니다. 마지막으로, Prompt는 상태 유지 아이디어의 간단한 인스턴스입니다. GPT-3에 각 라운드의 스왑을 읽은 직후 현재 상태를 반환하도록 요청하여 게임이 진행됨에 따라 모델이 상태를 추적하고 업데이트하도록 자극합니다. 이러한 방법을 K 범위로 평가합니다. 각 K와 각 방법에 대해 다양한 수의 스왑을 사용한 30개의 데모를 모델에 제공하고 실험을 100번 반복합니다. 그림 2는 평균 정확도를 시각화합니다. 상태 유지 방법은 다른 방법보다 상당히 우수하며 성능 격차는 K에 따라 증가합니다. III. 방법 섹션 II에서 예시한 것처럼 접근 방식의 핵심은 LLM이 각 사용자 쿼리에 응답하는 동안 다음 상태를 설명할 수 있도록 하는 것입니다. 동기를 부여하는 예는 다음 상태가 응답이라는 점에서 간단합니다. 대신 이제 LLM에 상태 업데이트를 추적하고 응답을 생성하는 데 상당한 부담이 있는 보다 일반적인 시나리오를 고려합니다. (그림 3). 일반적인 사례에서 우리는 부담을 여러 개의 서로 다른 프롬프트 LLM으로 분할하는 것을 제안합니다. 정확히 말해서, 우리는 각 하위 작업(즉, 상태 추적 또는 쿼리)에 대한 지침과 데모를 포함하는 별도의 프롬프트를 유지합니다. 블록을 파란색 그릇에 넣어 파란색 그릇에 있는 블록의 총 무게가 회색 그릇에 있는 블록의 무게보다 작아지도록 합니다. 9.# state = { 2 # &quot;objects&quot;: [&quot;cyan block&quot;, &quot;yellow block&quot;, &quot;brown block&quot;, &quot;purple block&quot;, &quot;blue block&quot;, &quot;green bowl&quot;, &quot;red bowl&quot;, &quot;disinfector&quot;],# 4 # €9.9.5 # 6 # 7 # 8.# 9 # 10 # Statler(저희) 11 # 12 # } 6.6.2.2.Initial State Code-as-Policies는 블록을 보라색 그릇에 넣어 총 무게가 회색 그릇에 있는 블록의 무게와 동일해지도록 합니다. 1.4.4.4.2.2.1.2.Initial State Code-as-Policies는 모든 더러운 블록을 테이블에 놓습니다. &quot;relations&quot;: [], &quot;disinfector&quot;: {&quot;contains&quot;: []}, &quot;cyan block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, &quot;yellow block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;brown block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;purple block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, &quot;blue block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;green bowl&quot;: {}, &quot;red bowl&quot;: {} 13 # 쿼리: 노란색 블록 위에 시안색 블록을 놓으세요 14 put_first_on_second(&quot;cyan block&quot;, &quot;yellow block&quot;) 15 update_wm(&quot;노란색 블록 위에 시안색 블록을 놓으세요&quot;) 프롬프트 4: 세계 상태 판독기. 녹색으로 강조 표시된 텍스트는 모델이 생성할 것으로 예상되는 부분을 나타냅니다. # state = { 4.# &quot;objects&quot;: [&quot;cyan block&quot;, &quot;yellow block&quot;, &quot;brown block&quot;, &quot;purple block&quot;, &quot;blue block&quot;, &quot;green bowl&quot;, &quot;red bowl&quot;, &quot;disinfector&quot;], &quot;relations&quot;: [], &quot;disinfector&quot;: {&quot;contains&quot;: []}, &quot;cyan block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, &quot;yellow block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;brown block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;purple block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, Statler(우리)## 5 # 6 # 7 # 8 # 9 # 10 # &quot;blue block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;green bowl&quot;: {}, 11 # 12 # } 초기 상태 Code-as-Policies Statler(우리) &quot;red bowl&quot;: {} 13 # 쿼리: 노란색 블록 위에 청록색 블록을 놓으세요. 14 # 상태 = { 15 # &quot;objects&quot;: [&quot;청록색 블록&quot;, &quot;노란색 블록&quot;, &quot;갈색 블록&quot;, &quot;자주색 블록&quot;, &quot;파란색 블록&quot;, &quot;녹색 그릇&quot;, &quot;빨간색 그릇&quot;, &quot;소독기&quot;], &quot;relations&quot;: [[&quot;청록색 블록이 노란색 블록 위에 있습니다&quot;]], &quot;소독기&quot;: {&quot;포함&quot;: []}, 그림 3: Codeas-Policies와 상태 유지 Statler 알고리즘을 사용하여 다양한 자연어 명령어를 실행한 결과를 보여주는 시뮬레이션의 예. 응답) 그런 다음 프롬프트를 사용하여 특정 하위 작업을 수행하는 LLM을 유도합니다. 곧 논의하겠지만, 프레임워크에는 사용자 쿼리에 응답하는 세계 상태 판독기와 상태 표현을 업데이트하는 세계 상태 작성기가 포함됩니다. 프레임워크(그림 1)는 적용할 수 있는 도메인에 근본적인 제한을 두지 않습니다. 우리의 접근 방식은 CaP(Code-as-Policies)의 모델 기반 확장으로 간주될 수 있는데, CaP의 핵심 기능(예: 계층적 코드 생성)을 유지하고 추정된 세계 상태를 명시적으로 유지하는 수단을 통합한다는 의미입니다. 리더 및 작성자 모델의 작동을 이해하려면 예제 프롬프트를 고려하는 것이 유용합니다. 프롬프트는 세계 상태 리더에 전달된 입력의 예입니다. 처음에는 객체 지향 원칙에 대한 참조로 JSON 형식의 상태를 초기화합니다. 사용자 쿼리 &quot;노란색 블록 위에 청록색 블록을 놓으세요&quot;(13행)와 현재 상태 표현(1-12행)이 주어지면, 세계 상태 판독기는 현재 상태를 고려하여 쿼리에 응답하는 코드를 생성해야 합니다. 생성될 것으로 예상되는 코드는 녹색으로 강조 표시됩니다. 코드를 생성한 후 모델은 이를 실행하여 쿼리를 완료합니다. 상태를 업데이트해야 하는 경우 생성된 코드에는 16 # 17 # 18 # 19 # 20 # 21 # 22 # &quot;cyan block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, &quot;yellow block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, &quot;brown block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;purple block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, &quot;blue block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;green bowl&quot;: {}, 23 # 24 # 25 # } &quot;red bowl&quot;: {}, 프롬프트 5: 세계 상태 작성자. 파란색으로 렌더링된 텍스트는 상태의 업데이트된 부분을 강조 표시합니다. 인수에 지정된 쿼리. 프롬프트 5에서 세계 상태 작성자에 대한 해당 예를 보여줍니다. 리더와 유사하게 사용자 쿼리 앞에 현재 상태 표현을 추가하면 모델이 업데이트된 상태 표현(녹색으로 강조 표시됨)을 생성합니다. 작성자가 상태 표현을 업데이트할 때마다 외부 메모리에 저장하고 현재 상태라고 합니다. IV. 실험 3개의 테이블탑 조작 도메인(그림 4)에서 최첨단 LLM 모델과 함께 Statler의 기능을 평가합니다. 즉, 픽 앤 플레이스, 블록 소독 및 상대적 가중치 추론입니다. 각 도메인에 대해 컨텍스트 내 예제를 설계하고 각각 5~16개의 연속적인 사용자 쿼리 단계로 구성된 20개의 평가 에피소드를 고려합니다. 모든 에피소드에는 상호 작용 기록에 대한 추론이 필요한 쿼리가 하나 이상 포함되어 있습니다(즉, 단계에 걸쳐 &quot;메모리&quot;가 필요함).이로 인해 작업이 상당히 어렵습니다.파란색 블록 바로 위에 있는 블록의 색상은 무엇입니까?정책으로서의 코드: 아무것도 생성하지 못함 (a) 픽앤플레이스 (b) 살균 (c) 무게 추론 그림 4: 고려하는 시뮬레이션 도메인에는 다음이 포함됩니다.(a) 픽앤플레이스;(b) 블록 살균, 블록 주변의 반투명 구가 블록의 더러움을 나타냄(로봇에게는 보이지 않음);(c) 상대적 무게 추론, 각 블록 아래에 있는 디스크의 반경이 무게를 나타냄(로봇에게는 보이지 않음).A. 시뮬레이션된 테이블탑 조작 도메인 픽앤플레이스 도메인에는 로봇 팔이 블록을 순차적으로 집어 올려 다른 블록, 그릇 또는 테이블에 놓아야 하는 시나리오가 포함됩니다.모델은 블록 위치를 기억하고 추론해야 합니다. 예시 사용자 쿼리는 &quot;빨간색 그릇에 녹색 블록을 넣으세요.&quot;, &quot;분홍색 블록 아래에 있는 블록의 색상은 무엇인가요?&quot;, &quot;녹색 그릇에 블록이 몇 개 있나요?&quot;입니다. 블록 소독 도메인에서 로봇이 상태를 관찰할 수 없는 블록이 더럽거나 깨끗할 수 있는 시나리오를 고려합니다. 깨끗한 블록이 더러운 블록에 닿으면(예: 한 블록을 다른 블록 위에 쌓아 놓은 결과) 깨끗한 블록이 더러워집니다. 테이블에는 그 안에 놓인 모든 블록을 세척하는 소독기가 있습니다. 이 시나리오는 로봇에게 더러운 접시를 식기 세척기에 넣거나 더러운 옷을 세탁기에 넣으라고 요청할 수 있는 청소 작업을 에뮬레이트합니다. 사용자 쿼리에는 픽 앤 플레이스 도메인과 유사한 픽 앤 플레이스 명령과 &quot;깨끗한 블록을 모두 녹색 그릇에 넣으세요.&quot;와 같이 어떤 블록이 깨끗하고 더러운지 추론해야 하는 텍스트 발화가 포함됩니다. 이 도메인은 모델이 각 블록의 청결도를 추적하고 더러운 블록이 다른 깨끗한 블록과 접촉할 때 발생하는 상태 변화를 정확하게 포착해야 하기 때문에 특별한 과제를 제시합니다. 상대적 가중치 추론은 블록의 상대적 가중치를 암기하고 추론하는 것을 포함합니다. 사용자 쿼리는 블록의 무게에 대한 정보를 제공합니다(예: &quot;빨간색 블록은 청동 블록의 무게의 두 배입니다.&quot;). 그 뒤에 무게에 대한 추론이 필요한 쿼리가 이어집니다(예: &quot;블록을 보라색 그릇에 넣어 총 무게가 회색 그릇에 있는 것과 같아지게 하세요.&quot;). 제안하는 접근 방식인 Statler를 두 가지 강력한 경쟁 방식인 정책으로서의 코드[5](CaP)와 사고의 사슬 프롬프트가 있는 CaP[18](CaP+CoT)와 비교합니다. CaP는 과거 동작을 기반으로 각 단계에서 현재 질문에 대한 코드를 생성하지만 상태를 유지하지는 않습니다. CoT 프레임워크에 따라 모든 단계에서 CaP+CoT는 초기 상태와 과거 동작을 기반으로 중간 상태를 추론하여 현재 코드를 생성합니다. 이를 사고로 간주합니다. 하지만 이는 중복 추론으로 이어지고 프롬프트의 길이를 늘려 LLM의 컨텍스트 창을 초과할 수 있습니다. Statler(저희): &quot;빨간색&quot; 그릇에 없는 블록이 몇 개입니까? Code-as-Policies: &quot;그릇에 없는 블록이 두 개 있습니다. 갈색 블록과 노란색 블록입니다.&quot; Statler(저희): &quot;블록 세 개&quot; 그림 5: 상태가 유지된 LLM과 유지되지 않은 LLM을 쿼리한 결과를 보여주는 예. 첫 번째 시나리오에서 CaP는 답을 생성하지 못하는 반면, 저희 Statler 모델은 올바른 응답을 생성합니다. 두 번째 예에서 블록 하나가 보이지 않고 CaP는 두 블록을 그릇이 아닌 것으로 잘못 식별합니다. 지속적인 세계 상태를 유지함으로써 저희 방법은 세 번째 블록을 인식하고 쿼리에 올바르게 답합니다. 크기 제한. 게다가 추론이 길어지면 더 길고 복잡한 데모 예제 프롬프트가 필요하여 개발자의 노력이 증가합니다. 저희는 각 모델에 제공된 데모(즉, 컨텍스트 내 예제)가 동등하도록 합니다. 즉, 상태 표현과 같은 설계로 인한 필수적인 차이점을 제외하고는 동일한 사용자 쿼리 및 코드 스니펫 시퀀스를 사용합니다. 표 I: 각 순차적 작업에 대한 에피소드 성공률 및 개별 단계 성공률(괄호 안). *는 컨텍스트 제한이 종종 초과되었음을 나타냅니다. CaP CaP+COT Statler(저희) 소독 픽앤플레이스 0.00(0.54) 0.25(0.76) 0.50(0.88) 가중치 0.00(0.68) 0.00(0.84) 0.00(0.20)† 0.40(0.82) 0.30(0.88) 0.55(0.93) 표 I은 각 방법의 에피소드 성공률과 개별 단계의 성공률을 보고합니다. 모델이 에피소드에서 사용자 쿼리 중 하나에 응답하지 못하면 해당 에피소드는 실패로 간주됩니다. Cap 기준선은 각 도메인의 개별 단계의 절반 이상을 올바르게 처리하지만, 어떤 에피소드도 성공적으로 완료하지 못합니다. 나중에 보여드리겠지만, CaP는 이전 단계에 대한 추론이 필요 없는 대부분의 쿼리(예: &quot;빨간색 블록을 파란색 블록 위에 놓으세요.&quot;)를 올바르게 처리하지만, 과거 단계에 대한 추론이 필요한 쿼리(예: &quot;더러운 블록을 모두 분홍색 그릇에 넣으세요.&quot; 및 &quot;보라색 블록 아래에 있는 블록의 색상은 무엇인가요?&quot;)에 대한 응답에서는 잘못된(또는 전혀 없는) 코드를 생성하는 경향이 있습니다(그림 5(위) 참조). CaP+CoT는 Pick-and-Place 및 상대적 가중치 추론에서 약간 더 나은 성과를 거두었지만, 여전히 대부분의 에피소드에서 실패합니다. 반면, Statler는 이러한 쿼리의 대부분을 성공적으로 처리하여 다른 쿼리에 비해 크게 개선되었음을 보여줍니다. LLM 기반 모델에 도전적인 쿼리를 명시적으로 선택했다는 점에 유의해야 하며, 이는 모델의 점수가 개선의 여지가 있는 이유를 부분적으로 설명합니다. 표 II: 비시간적 및 시간적 쿼리에 대한 Code-as-Policies(CaP) 및 Statler의 성공률. 비시간적 시간적 CaP Code-as-Policies 검은색 컵을 노란색 블록. 노란색 블록을 루빅 큐브에 올려놓습니다. Pick &amp; Place 소독 무게 CaP Statler(저희) 1.00(62/62) 1.00(68/68) 0.99(148/149) 0.98(164/168) 1.00(107/107) 1.00(107/107) Statler(저희) 0.31(9/29) 0.83(48/58) 0.05(1/20) 0.65(15/23) 0.00(0/20) 0.55(11/20) Code-as-Policies와 비교하여 Statler의 동작을 더 잘 이해하기 위해 사용자 쿼리 유형에 따라 성공률을 분석합니다. 구체적으로, 우리는 질의에 응답하는 데 시간적 추론이 필요한지 여부에 따라 각 질의를 시간적 또는 비시간적으로 분류합니다. 우리는 고려하는 기준선을 포함한 현대적 방법이 평가를 위해 비시간적 질의를 사용한다는 점을 강조합니다. 표 II는 결과적인 정확도를 요약합니다. 모델은 종종 에피소드의 다른 단계에서 실패합니다. 우리는 정확도를 계산할 때 모델이 올바른 코드를 생성하지 못할 때까지 단계 순서만 고려한다는 점에 유의합니다. 이는 분모의 불일치를 설명합니다. 두 모델 모두 시간적 추론이 필요하지 않은 명령에서 거의 완벽한 성능을 달성하는 것을 알 수 있습니다. 그러나 CaP의 성능은 과거에 대한 추론이 필요한 작업에서 눈에 띄게 감소합니다. 반면 Statler는 Pickand-Place에서 83%(CaP의 경우 31%), Block Disinfection에서 65%(CaP의 경우 5%), Relative Weight Reasoning에서 55%(CaP의 경우 0%)의 성공률을 달성합니다. 우리의 방법은 기준 방법보다 더 나은 견고성을 누리지만, 성능을 저해하는 대규모 언어 모델의 몇 가지 문제를 물려받았습니다. 예를 들어, 블록의 청결도가 명시적으로 설명되지 않은 경우 블록 조건(예: 깨끗함 또는 더러움) 또는 위치를 환각합니다. 게다가, 모델의 추론 전략은 수학적 계산을 실행하기보다는 주로 무게를 가벼운 것과 무거운 것과 같은 추상적인 개념으로 취급하는 것으로 보입니다. 이 약점은 모델에 그릇에 블록을 모아서 총 무게가 다른 그릇의 무게를 넘을 때까지 모으라고 요청했을 때 분명하지만, 모델은 그릇을 채우지 못합니다. 소독 도메인에서, 우리 모델은 &quot;다른 블록은 깨끗합니다&quot;와 같은 질의에서 &quot;기타&quot;와 같은 모호한 용어를 이해하는 데 어려움을 겪습니다. 또한, 후자의 청결도와 관계없이 블록을 위에 놓으면 아래쪽 블록이 더러워진다고 훈련 프롬프트에서 잘못 추론할 수도 있습니다. B. 실제 로봇 실험 실제 로봇에서 Statler를 검증하기 위해, 시뮬레이션 실험과 유사한 테이블탑 도메인에서 UR5 팔에 구현합니다. 우리는 그리퍼에 장착된 RealSense 카메라로 촬영한 RGB 이미지 내의 객체에 대한 분할 마스크를 얻기 위해 개방형 어휘 분할 모델인 MDETR[19]을 사용합니다. 예측된 객체 마스크와 깊이 이미지를 사용하여 객체 포인트 클라우드를 얻을 수 있으며, 이를 통해 객체의 중심 위치와 경계 상자를 추정합니다. 모든 기본 함수는 시뮬레이션에서 사용된 것과 동일합니다. 이 도메인에서 로봇은 객체를 쌓으라는 요청을 받습니다. 시간 그림 6: 주어진 다중 문장 지침에 대한 실제 로봇 실험에 대한 (위) Codeas-Policies와 (아래) Statler 모델의 결과 동작 비교. 프레임은 로봇이 객체를 배치한 인스턴스에 해당합니다. 지침을 성공적으로 수행하려면 로봇이 노란색 블록을 덮은 후 즉시 검은색 컵을 제거하여 루빅 큐브에 노란색 블록을 놓아야 합니다. 그러나 기준선 Code-as-Policies(위쪽 행, 세 번째 프레임)는 검은색 컵을 옆으로 옮기지 못해 노란색 블록이 덮여 있습니다. 그런 다음 루빅 큐브 위에 잘못된 개체를 놓습니다.1 귀하의 작업은 JSON 사전을 사용하여 이러한 항목의 상태를 유지하고 새 쿼리 후에 해당 항목의 상태를 업데이트하는 것입니다.2 이 JSON 사전은 주석 처리되므로 각 줄의 시작 문자는 #입니다.프롬프트 6: Statler-Auto 프롬프트의 일부입니다.그리고 다른 색상의 컵으로 개체를 덮습니다.어느 시점에서든 개체는 최대 하나의 개체나 덮개로만 덮일 수 있습니다.로봇이 아래쪽 개체를 조작하도록 요청받으면 위쪽 개체를 치워야 합니다.새 덮개나 개체를 그 위에 쌓으려면 기존 덮개나 개체를 제거해야 합니다.10개의 에피소드를 사용하여 실제 로봇 도메인에서 Statler와 CaP의 성능을 평가합니다.Statler는 40%(70%)의 에피소드 및 단계(괄호 안) 성공률을 달성하며, 여기서 실패 사례의 67%는 LLM 추론 때문이고 다른 사례는 지각 또는 조작 문제로 인해 발생합니다. CaP의 성공률은 20%(46%)이고, LLM 추론이 실패의 88%를 차지합니다.그림 6에서는 CaP 기준선이 실패하는 짧은 예도 제공합니다.어려움은 노란색 블록이 검은색 컵 아래에 숨겨져 있다는 것을 인식하는 데 있으며, Statler가 올바르게 발견했으므로 노란색 블록을 집어 올리기 전에 제거해야 합니다.대신 CaP는 이를 인식하지 못하고 그럼에도 불구하고 노란색 블록을 집어 올리려고 하며, 이로 인해 MDETR이 노란색이 있는 장난감 바퀴를 노란색 블록으로 잘못 감지합니다.C. 상태 유지 절제 Statler의 상태 유지 전략을 더 잘 이해하기 위해 상태를 추적하는 세 가지 다른 접근 방식을 고려합니다.첫 번째(Statler-Unified)는 Statler의 판독기 및 작성기 프롬프트를 섞어서 프롬프트를 사용하는 단일 LLM을 세계 상태 판독기와 작성기로 사용합니다.각 단계에서 LLM은 먼저 동작을 생성한 다음 해당 동작을 실행하여 발생하는 상태를 예측합니다. LLM은 다음 쿼리를 추론할 때 결과 상태를 사용합니다.단일 LLM을 사용하는 것은 개념적으로 간단하지만 추론 및 일반화에 대한 부담이 추가됩니다.InstructGPT [20]에서 영감을 받은 두 번째(Statler-Auto)는 세계 상태 작성자에 대한 컨텍스트 내 상태 업데이트 예를 수신하지 않습니다.대신 상태를 유지해야 하는 방법에 대한 자연어 설명을 제공합니다.프롬프트 6은 프롬프트의 관련 부분을 보여줍니다.지시와 컨텍스트 내 상태 업데이트 예가 없는 경우 동일한 작업 집합에서 모델을 실행했습니다.세 번째(Statler w/o State)는 Statler의 세계 상태 유지 관리 구성 요소를 완전히 제거하여 Code-as-Policies로 축소되는 모델을 생성합니다.표 III: 제거 에피소드(개별 단계) 성공률. Pick &amp; Place 소독 가중치 Statler w/o State Statler-Unified 0.00(0.54) 0.00(0.68) 0.40(0.85) 0.35(0.79) Statler-Auto 0.75(0.88) Statler(저희) 0.50(0.88) 0.45(0.82) 0.40(0.82) 0.00(0.84) 0.50(0.92) 0.40(0.90) 0.55(0.93) 표 III에서는 각 도메인에 대해 20개의 에피소드를 사용한 전체 에피소드 완료율과 개별 단계 성공율 측면에서 Statler의 성능을 세 가지 변형과 비교합니다. 세계 상태를 유지하지 않으면 Statler w/o State는 어떤 에피소드도 완료하지 못하고(에피소드 중에 모델이 사용자 쿼리 중 하나에 응답하지 못하면 에피소드가 실패로 간주됨을 기억하세요) Statler보다 상당히 낮은 개별 단계 성공률을 초래합니다. 한편, Statler가 세계 상태 리더와 세계 상태 작성자에 대해 별도의 LLM을 사용하면 통합 리더와 작성자(Statler-Unified)를 사용할 때보다 일관되게 더 높은 에피소드 성공률을 보입니다. 개별 단계 성공률은 Pick-and-Place와 Block Disinfection의 경우 더 높고 상대적 가중치 추론의 경우 비슷합니다. Statler가 세계 상태 작성자와 독자에 대해 별도의 LLM을 사용하는 것과 관련하여, 컨텍스트 내 학습은 프롬프트 템플릿, 예제 순서 및 사용된 예제의 변화에 민감한 것으로 나타났습니다[21, 22]. 이를 감안할 때, 독자와 작성자를 나누어 얻은 성능 향상은 부분적으로 이러한 민감성에 기인할 수 있으며, 이를 통해 모델이 실제로 각자의 작업에 특화될 수 있습니다. 흥미롭게도 Statler-Auto는 Pick-and-Place 및 Block Disinfection 도메인에서 에피소드 성공률 측면에서 Statler 및 Statler-Unified보다 눈에 띄게 더 나은 성능을 보였지만 개별 성공률 측면에서는 Statler와 비슷했고 Relative Weight Reasoning에서는 더 나빴습니다. V.
--- RELATED WORK ---
로봇공학을 위한 언어 이해 로봇 에이전트를 위한 언어 이해를 위한 일반적인 접근 방식에는 기호 접지[23]가 포함됩니다. 여기서 구문은 로봇의 세계 모델에서 기호에 매핑됩니다. 초기 작업[24, 25]은 이 매핑을 수행하기 위해 수작업으로 설계된 규칙에 의존합니다. 최근
--- METHOD ---
영어: 여러 로봇 계획 작업에 s(예: Codeas-Policies)를 사용합니다. 또한 더 어려운 장기적 계획 작업으로 확장할 수 있는 잠재적 이점이 있습니다. 여기에서 코드를 공개합니다. I. 서론 대규모 언어 모델(LLM)은 대화 및 코드 생성과 같은 광범위한 다운스트림 작업을 수행하는 데 활용되는 강력한 추론 기능을 보여줍니다[13]. 로봇 커뮤니티는 최근 로봇에 LLM을 부여하여 *동등한 기여를 나타냄; 각 저자의 기여는 부록에서 찾을 수 있습니다. 자연어 명령을 이해하고 정교한 추론이 필요한 작업을 수행할 수 있도록 하는 데 상당한 관심을 보였습니다[4-7]. 그러나 기존 방법은 모델이 없습니다. 즉, LLM을 정책 함수로 사용하여 이전 작업 및 관찰에만 조건이 지정된 미래 작업을 생성합니다. 이 논문에서는 간단하면서도 효과적인 모델 기반 접근 방식을 제안합니다. Statler라는 이름의 프레임워크는 대규모 언어 모델을 촉구하여 세계 상태에 대한 실행 추정을 유지하고 추정된 상태에 따라 다단계 구체화된 추론을 수행합니다. 그림 1은 이 프레임워크를 설명합니다. 특히 Statler는 프롬프트 LLM 쌍을 활용합니다. 몇 가지 데모에 의해 지시된 세계 상태 판독기는 사용자 쿼리를 입력으로 받고 추정된 세계 상태를 읽고 실행 가능한 작업(예: 코드 조각)을 생성합니다. 다른 데모 세트에 의해 지시된 세계 상태 작성기는 작업에 따라 세계 상태 추정치를 업데이트합니다. 이 메커니즘은 도메인별 형식 언어가 기호 세계 상태를 추적하는 방식[8]과 유사하지만 사전 학습된 대규모 언어 모델은 도메인과 무관한 것으로 알려져 있기 때문에 더 큰 유연성을 누립니다. 곧 섹션 IV에서 볼 수 있듯이 우리의 프롬프트는
--- EXPERIMENT ---
s는 일반적이며 프레임워크를 사용하는 사용자는 최소한의 디자인 작업 부담만 겪게 됩니다. Statler 프레임워크는 주로 고전적인 1 #23 초기 상태 2개의 컵 [거짓, 참, 거짓] 3 컵 1과 컵4 교환 컵 0과 컵5 교환 컵 1과 컵6 교환 컵 = [참, 거짓, 거짓]1 #3 초기 상태 2개의 컵 [거짓, 참, 거짓] 3 컵 1과 컵4 교환 컵 0과 컵5 교환 컵 1과 컵6 교환 컵 = [거짓, 거짓, 참] 7개의 컵 = [참, 거짓, 거짓] 8개의 컵 = [참, 거짓, 거짓] 1 # 초기 상태 2개의 컵 [거짓, 참, 거짓] 3 컵 1과 컵4 교환 컵 [거짓, 거짓, 참] 5 컵 0과 컵6 교환 컵 [참, 거짓, 거짓] 7 컵 1과 컵8 교환 컵 [참, 거짓, 거짓] 프롬프트 1: 프롬프트와 원하는 출력 프롬프트 2: 프롬프트와 원하는 출력 프롬프트 3: 바닐라 LLM의 프롬프트와 원하는 출력. LLM+COT. 모델 기반 강화 학습. 모델 기반 접근 방식에서 환경(또는 세계) 모델은 환경의 역학(예: 작업의 가능한 결과)을 포착하는 방법을 학습하여 모델 상태에 따라 조건화된 정책이 보다 정보에 입각한 작업을 수행합니다[9]. 저희 프레임워크에서 LLM은 사전 학습을 통해 엄청난 양의 상식적 지식을 습득했으며 몇 가지 데모를 통해 환경 모델처럼 작동하여 세계 상태를 추정하고 의사 결정을 용이하게 하도록 유도됩니다. 저희 설계의 또 다른 동기는 누락된 데이터를 처리하는 것입니다. 로봇 작업에서 우리는 종종 직접 관찰할 수 없는 잠재적 세계 역학에 대처해야 합니다. 이러한 시나리오에서 추정된 세계 상태를 명시적으로 유지하면 추정이 불완전할 수 있지만 의사 결정이 개선됩니다. 이것은 잠재 변수가 있는 그래픽 모델과 유사합니다.잠재 변수를 설명하고 값을 대입하는 것은 종종 대상 변수에 대한 추론에 도움이 되지만 대입이 완벽하지 않을 수 있습니다[10].상태 유지 설계의 최종 동기는 장기적 계획 작업으로 확장할 수 있는 잠재력입니다.다단계 추론 및 계획에서 LLM은 내부 표현에서 세계 상태를 암묵적으로 유지해야 하는데, 이는 이전 작업에서 어려운 것으로 입증되었습니다[11–17].추정된 세계 상태를 명시적으로 유지함으로써 프레임워크는 추론 및 계획의 모든 단계에서 세계 상태를 추적하고 참조하기가 더 쉬워지므로 장기적 작업에서 성공할 가능성이 더 높습니다.다음 섹션에서는 프레임워크가 예상대로 수행되는지 보여드리겠습니다.섹션 II에서는 교육적 예를 통해 개념을 시연합니다.섹션 III에서는 Statler 프레임워크를 소개합니다.섹션 IV에서는 실험을 제시하는데, 이 실험에서 프레임워크는 Code-as-Policies[5]와 같은 강력한 경쟁 방법보다 상당히 우수한 성과를 보입니다.II. 동기를 부여하는 사례 우리는 간단한 쉘 게임인 three-cups-and-a-ball을 사용하여 상태 유지 아이디어의 효과를 보여줍니다. 이 게임에서 공은 세 개의 동일한 컵 중 하나로 덮여 있으며 공의 초기 위치는 플레이어에게 알려져 있습니다. K라운드 각각에서 우리는 두 개의 컵의 위치를 무작위로 바꿉니다. 마지막으로, 우리는 플레이어에게 공의 위치를 추측하도록 요청합니다. 우리는 GPT-3(정확히는 text-davinci-003)를 사용하여 이 게임을 플레이하기 위해 LLM을 사용하는 세 가지 별도의 사례를 제시합니다. Prompt는 가장 간단한 사례를 보여줍니다. 우리는 &quot;공이 여기 있다&quot;를 나타내는 True를 갖는 부울 변수로 상태를 표현합니다. 우리는 초기 상태와 K라운드의 스왑을 GPT3에 공급하여 최종 상태를 완료하도록 지시합니다. Prompt 2는 개선된 방법입니다. K라운드의 스왑을 읽은 후, GPT-LLM+State의 절대 정확도. 1.1.10.8. 0.0.6. LLM -0.LLM+COT 0.LLM+State 0.J0.-0.0.0.스왑 수 상대 정확도: 그림 2: 3컵 앤 어 볼 쉘 게임의 모델 정확도.LLM+State는 제안된 Statler 프레임워크의 단순화된 버전입니다.각 방법에서 실선은 정확도 a(n)이 스왑 수 n에 따라 어떻게 변하는지 보여줍니다.점선은 상대 정확도입니다.r(n) = a(n)/a(1).직관적으로, 이는 가설적으로 완벽한 1스왑 성능에서 성능이 얼마나 빨리 감소하는지 측정합니다.LLM+State가 실제로 a(1) = 100%를 달성한다는 점에 유의하세요.게임에서 모든 중간 상태를 제공하라는 요청을 받았습니다.이 버전은 중간 추론 단계를 설명하도록 요청하여 LLM의 성능을 개선하는 Chain-of-Thought 프롬프팅[18]에서 영감을 받았습니다. 마지막으로, Prompt는 상태 유지 아이디어의 간단한 인스턴스입니다. GPT-3에 각 라운드의 스왑을 읽은 직후 현재 상태를 반환하도록 요청하여 게임이 진행됨에 따라 모델이 상태를 추적하고 업데이트하도록 자극합니다. 이러한 방법을 K 범위로 평가합니다. 각 K와 각 방법에 대해 다양한 수의 스왑을 사용한 30개의 데모를 모델에 제공하고 실험을 100번 반복합니다. 그림 2는 평균 정확도를 시각화합니다. 상태 유지 방법은 다른 방법보다 상당히 우수하며 성능 격차는 K에 따라 증가합니다. III. 방법 섹션 II에서 예시한 것처럼 접근 방식의 핵심은 LLM이 각 사용자 쿼리에 응답하는 동안 다음 상태를 설명할 수 있도록 하는 것입니다. 동기를 부여하는 예는 다음 상태가 응답이라는 점에서 간단합니다. 대신 이제 LLM에 상태 업데이트를 추적하고 응답을 생성하는 데 상당한 부담이 있는 보다 일반적인 시나리오를 고려합니다. (그림 3). 일반적인 사례에서 우리는 부담을 여러 개의 서로 다른 프롬프트 LLM으로 분할하는 것을 제안합니다. 정확히 말해서, 우리는 각 하위 작업(즉, 상태 추적 또는 쿼리)에 대한 지침과 데모를 포함하는 별도의 프롬프트를 유지합니다. 블록을 파란색 그릇에 넣어 파란색 그릇에 있는 블록의 총 무게가 회색 그릇에 있는 블록의 무게보다 작아지도록 합니다. 9.# state = { 2 # &quot;objects&quot;: [&quot;cyan block&quot;, &quot;yellow block&quot;, &quot;brown block&quot;, &quot;purple block&quot;, &quot;blue block&quot;, &quot;green bowl&quot;, &quot;red bowl&quot;, &quot;disinfector&quot;],# 4 # €9.9.5 # 6 # 7 # 8.# 9 # 10 # Statler(저희) 11 # 12 # } 6.6.2.2.Initial State Code-as-Policies는 블록을 보라색 그릇에 넣어 총 무게가 회색 그릇에 있는 블록의 무게와 동일해지도록 합니다. 1.4.4.4.2.2.1.2.Initial State Code-as-Policies는 모든 더러운 블록을 테이블에 놓습니다. &quot;relations&quot;: [], &quot;disinfector&quot;: {&quot;contains&quot;: []}, &quot;cyan block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, &quot;yellow block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;brown block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;purple block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, &quot;blue block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;green bowl&quot;: {}, &quot;red bowl&quot;: {} 13 # 쿼리: 노란색 블록 위에 시안색 블록을 놓으세요 14 put_first_on_second(&quot;cyan block&quot;, &quot;yellow block&quot;) 15 update_wm(&quot;노란색 블록 위에 시안색 블록을 놓으세요&quot;) 프롬프트 4: 세계 상태 판독기. 녹색으로 강조 표시된 텍스트는 모델이 생성할 것으로 예상되는 부분을 나타냅니다. # state = { 4.# &quot;objects&quot;: [&quot;cyan block&quot;, &quot;yellow block&quot;, &quot;brown block&quot;, &quot;purple block&quot;, &quot;blue block&quot;, &quot;green bowl&quot;, &quot;red bowl&quot;, &quot;disinfector&quot;], &quot;relations&quot;: [], &quot;disinfector&quot;: {&quot;contains&quot;: []}, &quot;cyan block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, &quot;yellow block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;brown block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;purple block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, Statler(우리)## 5 # 6 # 7 # 8 # 9 # 10 # &quot;blue block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;green bowl&quot;: {}, 11 # 12 # } 초기 상태 Code-as-Policies Statler(우리) &quot;red bowl&quot;: {} 13 # 쿼리: 노란색 블록 위에 청록색 블록을 놓으세요. 14 # 상태 = { 15 # &quot;objects&quot;: [&quot;청록색 블록&quot;, &quot;노란색 블록&quot;, &quot;갈색 블록&quot;, &quot;자주색 블록&quot;, &quot;파란색 블록&quot;, &quot;녹색 그릇&quot;, &quot;빨간색 그릇&quot;, &quot;소독기&quot;], &quot;relations&quot;: [[&quot;청록색 블록이 노란색 블록 위에 있습니다&quot;]], &quot;소독기&quot;: {&quot;포함&quot;: []}, 그림 3: Codeas-Policies와 상태 유지 Statler 알고리즘을 사용하여 다양한 자연어 명령어를 실행한 결과를 보여주는 시뮬레이션의 예. 응답)한 다음 프롬프트를 사용하여 특정 하위 작업을 수행하는 LLM을 유도합니다. 곧 논의하겠지만, 프레임워크에는 사용자 쿼리에 응답하는 세계 상태 판독기와 상태 표현을 업데이트하는 세계 상태 작성기가 포함됩니다. 프레임워크(그림 1)는 적용할 수 있는 도메인에 근본적인 제한을 두지 않습니다. 우리의 접근 방식은 CaP(Code-as-Policies)의 모델 기반 확장으로 간주될 수 있는데, CaP의 핵심 기능(예: 계층적 코드 생성)을 유지하고 추정된 세계 상태를 명시적으로 유지하는 수단을 통합한다는 의미입니다. 리더 및 작성자 모델의 작동을 이해하려면 예제 프롬프트를 고려하는 것이 유용합니다. 프롬프트는 세계 상태 리더에 전달된 입력의 예입니다. 처음에는 객체 지향 원칙에 대한 참조로 JSON 형식의 상태를 초기화합니다. 사용자 쿼리 &quot;노란색 블록 위에 청록색 블록을 놓으세요&quot;(13행)와 현재 상태 표현(1-12행)이 주어지면, 세계 상태 판독기는 현재 상태를 고려하여 쿼리에 응답하는 코드를 생성해야 합니다. 생성될 것으로 예상되는 코드는 녹색으로 강조 표시됩니다. 코드를 생성한 후 모델은 이를 실행하여 쿼리를 완료합니다. 상태를 업데이트해야 하는 경우 생성된 코드에는 16 # 17 # 18 # 19 # 20 # 21 # 22 # &quot;cyan block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, &quot;yellow block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, &quot;brown block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;purple block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, &quot;blue block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;green bowl&quot;: {}, 23 # 24 # 25 # } &quot;red bowl&quot;: {}, 프롬프트 5: 세계 상태 작성자. 파란색으로 렌더링된 텍스트는 상태의 업데이트된 부분을 강조 표시합니다. 인수에 지정된 쿼리. 프롬프트 5에서 세계 상태 작성자에 대한 해당 예를 보여줍니다. 리더와 유사하게 사용자 쿼리 앞에 현재 상태 표현을 추가하면 모델이 업데이트된 상태 표현(녹색으로 강조 표시됨)을 생성합니다. 작성자가 상태 표현을 업데이트할 때마다 외부 메모리에 저장하고 현재 상태라고 합니다. IV. 실험 3개의 테이블탑 조작 도메인(그림 4)에서 최첨단 LLM 모델과 함께 Statler의 기능을 평가합니다. 즉, 픽 앤 플레이스, 블록 소독 및 상대적 가중치 추론입니다. 각 도메인에 대해 컨텍스트 내 예제를 설계하고 각각 5~16개의 연속적인 사용자 쿼리 단계로 구성된 20개의 평가 에피소드를 고려합니다. 모든 에피소드에는 상호 작용 기록에 대한 추론이 필요한 쿼리가 하나 이상 포함되어 있습니다(즉, 단계에 걸쳐 &quot;메모리&quot;가 필요함).이로 인해 작업이 상당히 어렵습니다.파란색 블록 바로 위에 있는 블록의 색상은 무엇입니까?정책으로서의 코드: 아무것도 생성하지 못함 (a) 픽앤플레이스 (b) 살균 (c) 무게 추론 그림 4: 고려하는 시뮬레이션 도메인에는 다음이 포함됩니다.(a) 픽앤플레이스;(b) 블록 살균, 블록 주변의 반투명 구가 블록의 더러움을 나타냄(로봇에게는 보이지 않음);(c) 상대적 무게 추론, 각 블록 아래에 있는 디스크의 반경이 무게를 나타냄(로봇에게는 보이지 않음).A. 시뮬레이션된 테이블탑 조작 도메인 픽앤플레이스 도메인에는 로봇 팔이 블록을 순차적으로 집어 올려 다른 블록, 그릇 또는 테이블에 놓아야 하는 시나리오가 포함됩니다.모델은 블록 위치를 기억하고 추론해야 합니다. 예시 사용자 쿼리는 &quot;빨간색 그릇에 녹색 블록을 넣으세요.&quot;, &quot;분홍색 블록 아래에 있는 블록의 색상은 무엇인가요?&quot;, &quot;녹색 그릇에 블록이 몇 개 있나요?&quot;입니다. 블록 소독 도메인에서 로봇이 상태를 관찰할 수 없는 블록이 더럽거나 깨끗할 수 있는 시나리오를 고려합니다. 깨끗한 블록이 더러운 블록에 닿으면(예: 한 블록을 다른 블록 위에 쌓아 놓은 결과) 깨끗한 블록이 더러워집니다. 테이블에는 그 안에 놓인 모든 블록을 세척하는 소독기가 있습니다. 이 시나리오는 로봇에게 더러운 접시를 식기 세척기에 넣거나 더러운 옷을 세탁기에 넣으라고 요청할 수 있는 청소 작업을 에뮬레이트합니다. 사용자 쿼리에는 픽 앤 플레이스 도메인과 유사한 픽 앤 플레이스 명령과 &quot;깨끗한 블록을 모두 녹색 그릇에 넣으세요.&quot;와 같이 어떤 블록이 깨끗하고 더러운지 추론해야 하는 텍스트 발화가 포함됩니다. 이 도메인은 모델이 각 블록의 청결도를 추적하고 더러운 블록이 다른 깨끗한 블록과 접촉할 때 발생하는 상태 변화를 정확하게 포착해야 하기 때문에 특별한 과제를 제시합니다. 상대적 가중치 추론은 블록의 상대적 가중치를 암기하고 추론하는 것을 포함합니다. 사용자 쿼리는 블록의 무게에 대한 정보를 제공합니다(예: &quot;빨간색 블록은 청동 블록의 무게의 두 배입니다.&quot;). 그 뒤에 무게에 대한 추론이 필요한 쿼리가 이어집니다(예: &quot;블록을 보라색 그릇에 넣어 총 무게가 회색 그릇에 있는 것과 같아지게 하세요.&quot;). 제안하는 접근 방식인 Statler를 두 가지 강력한 경쟁 방식인 정책으로서의 코드[5](CaP)와 사고의 사슬 프롬프트가 있는 CaP[18](CaP+CoT)와 비교합니다. CaP는 과거 동작을 기반으로 각 단계에서 현재 질문에 대한 코드를 생성하지만 상태를 유지하지는 않습니다. CoT 프레임워크에 따라 모든 단계에서 CaP+CoT는 초기 상태와 과거 동작을 기반으로 중간 상태를 추론하여 현재 코드를 생성합니다. 이를 사고로 간주합니다. 하지만 이는 중복 추론으로 이어지고 프롬프트의 길이를 늘려 LLM의 컨텍스트 창을 초과할 수 있습니다. Statler(저희): &quot;빨간색&quot; 그릇에 없는 블록이 몇 개입니까? Code-as-Policies: &quot;그릇에 없는 블록이 두 개 있습니다. 갈색 블록과 노란색 블록입니다.&quot; Statler(저희): &quot;블록 세 개&quot; 그림 5: 상태가 유지된 LLM과 유지되지 않은 LLM을 쿼리한 결과를 보여주는 예. 첫 번째 시나리오에서 CaP는 답을 생성하지 못하는 반면, 저희 Statler 모델은 올바른 응답을 생성합니다. 두 번째 예에서 블록 하나가 보이지 않고 CaP는 두 블록을 그릇이 아닌 것으로 잘못 식별합니다. 지속적인 세계 상태를 유지함으로써 저희 방법은 세 번째 블록을 인식하고 쿼리에 올바르게 답합니다. 크기 제한. 게다가 추론이 길어지면 더 길고 복잡한 데모 예제 프롬프트가 필요하여 개발자의 노력이 증가합니다. 저희는 각 모델에 제공된 데모(즉, 컨텍스트 내 예제)가 동등하도록 합니다. 즉, 상태 표현과 같은 설계로 인한 필수적인 차이점을 제외하고는 동일한 사용자 쿼리 및 코드 스니펫 시퀀스를 사용합니다. 표 I: 각 순차적 작업에 대한 에피소드 성공률 및 개별 단계 성공률(괄호 안). *는 컨텍스트 제한이 종종 초과되었음을 나타냅니다. CaP CaP+COT Statler(저희) 소독 픽앤플레이스 0.00(0.54) 0.25(0.76) 0.50(0.88) 가중치 0.00(0.68) 0.00(0.84) 0.00(0.20)† 0.40(0.82) 0.30(0.88) 0.55(0.93) 표 I은 각 방법의 에피소드 성공률과 개별 단계의 성공률을 보고합니다. 모델이 에피소드에서 사용자 쿼리 중 하나에 응답하지 못하면 해당 에피소드는 실패로 간주됩니다. Cap 기준선은 각 도메인의 개별 단계의 절반 이상을 올바르게 처리하지만, 어떤 에피소드도 성공적으로 완료하지 못합니다. 나중에 보여드리겠지만, CaP는 이전 단계에 대한 추론이 필요 없는 대부분의 쿼리(예: &quot;빨간색 블록을 파란색 블록 위에 놓으세요.&quot;)를 올바르게 처리하지만, 과거 단계에 대한 추론이 필요한 쿼리(예: &quot;더러운 블록을 모두 분홍색 그릇에 넣으세요.&quot; 및 &quot;보라색 블록 아래에 있는 블록의 색상은 무엇인가요?&quot;)에 대한 응답에서는 잘못된(또는 전혀 없는) 코드를 생성하는 경향이 있습니다(그림 5(위) 참조). CaP+CoT는 Pick-and-Place 및 상대적 가중치 추론에서 약간 더 나은 성과를 거두었지만, 여전히 대부분의 에피소드에서 실패합니다. 반면, Statler는 이러한 쿼리의 대부분을 성공적으로 처리하여 다른 쿼리에 비해 크게 개선되었음을 보여줍니다. LLM 기반 모델에 도전적인 쿼리를 명시적으로 선택했다는 점에 유의해야 하며, 이는 모델의 점수가 개선의 여지가 있는 이유를 부분적으로 설명합니다. 표 II: 비시간적 및 시간적 쿼리에 대한 Code-as-Policies(CaP) 및 Statler의 성공률. 비시간적 시간적 CaP Code-as-Policies 검은색 컵을 노란색 블록. 노란색 블록을 루빅 큐브에 올려놓습니다. Pick &amp; Place 소독 무게 CaP Statler(저희) 1.00(62/62) 1.00(68/68) 0.99(148/149) 0.98(164/168) 1.00(107/107) 1.00(107/107) Statler(저희) 0.31(9/29) 0.83(48/58) 0.05(1/20) 0.65(15/23) 0.00(0/20) 0.55(11/20) Code-as-Policies와 비교하여 Statler의 동작을 더 잘 이해하기 위해 사용자 쿼리 유형에 따라 성공률을 분석합니다. 구체적으로, 우리는 질의에 응답하는 데 시간적 추론이 필요한지 여부에 따라 각 질의를 시간적 또는 비시간적으로 분류합니다. 우리는 고려하는 기준선을 포함한 현대적 방법이 평가를 위해 비시간적 질의를 사용한다는 점을 강조합니다. 표 II는 결과적인 정확도를 요약합니다. 모델은 종종 에피소드의 다른 단계에서 실패합니다. 우리는 정확도를 계산할 때 모델이 올바른 코드를 생성하지 못할 때까지 단계 순서만 고려한다는 점에 유의합니다. 이는 분모의 불일치를 설명합니다. 두 모델 모두 시간적 추론이 필요하지 않은 명령에서 거의 완벽한 성능을 달성하는 것을 알 수 있습니다. 그러나 CaP의 성능은 과거에 대한 추론이 필요한 작업에서 눈에 띄게 감소합니다. 반면 Statler는 Pickand-Place에서 83%(CaP의 경우 31%), Block Disinfection에서 65%(CaP의 경우 5%), Relative Weight Reasoning에서 55%(CaP의 경우 0%)의 성공률을 달성합니다. 우리의 방법은 기준 방법보다 더 나은 견고성을 누리지만, 성능을 저해하는 대규모 언어 모델의 몇 가지 문제를 물려받았습니다. 예를 들어, 블록의 청결도가 명시적으로 설명되지 않은 경우 블록 조건(예: 깨끗함 또는 더러움) 또는 위치를 환각합니다. 게다가, 모델의 추론 전략은 수학적 계산을 실행하기보다는 주로 무게를 가벼운 것과 무거운 것과 같은 추상적인 개념으로 취급하는 것으로 보입니다. 이 약점은 모델에 그릇에 블록을 모아서 총 무게가 다른 그릇의 무게를 넘을 때까지 모으라고 요청했을 때 분명하지만, 모델은 그릇을 채우지 못합니다. 소독 도메인에서, 우리 모델은 &quot;다른 블록은 깨끗합니다&quot;와 같은 질의에서 &quot;기타&quot;와 같은 모호한 용어를 이해하는 데 어려움을 겪습니다. 또한, 후자의 청결도와 관계없이 블록을 위에 놓으면 아래쪽 블록이 더러워진다고 훈련 프롬프트에서 잘못 추론할 수도 있습니다. B. 실제 로봇 실험 실제 로봇에서 Statler를 검증하기 위해, 시뮬레이션 실험과 유사한 테이블탑 도메인에서 UR5 팔에 구현합니다. 우리는 그리퍼에 장착된 RealSense 카메라로 촬영한 RGB 이미지 내의 객체에 대한 분할 마스크를 얻기 위해 개방형 어휘 분할 모델인 MDETR[19]을 사용합니다. 예측된 객체 마스크와 깊이 이미지를 사용하여 객체 포인트 클라우드를 얻을 수 있으며, 이를 통해 객체의 중심 위치와 경계 상자를 추정합니다. 모든 기본 함수는 시뮬레이션에서 사용된 것과 동일합니다. 이 도메인에서 로봇은 객체를 쌓으라는 요청을 받습니다. 시간 그림 6: 주어진 다중 문장 지침에 대한 실제 로봇 실험에 대한 (위) Codeas-Policies와 (아래) Statler 모델의 결과 동작 비교. 프레임은 로봇이 객체를 배치한 인스턴스에 해당합니다. 지침을 성공적으로 수행하려면 로봇이 노란색 블록을 덮은 후 즉시 검은색 컵을 제거하여 루빅 큐브에 노란색 블록을 놓아야 합니다. 그러나 기준선 Code-as-Policies(위쪽 행, 세 번째 프레임)는 검은색 컵을 옆으로 옮기지 못해 노란색 블록이 덮여 있습니다. 그런 다음 루빅 큐브 위에 잘못된 개체를 놓습니다.1 귀하의 작업은 JSON 사전을 사용하여 이러한 항목의 상태를 유지하고 새 쿼리 후에 해당 항목의 상태를 업데이트하는 것입니다.2 이 JSON 사전은 주석 처리되므로 각 줄의 시작 문자는 #입니다.프롬프트 6: Statler-Auto 프롬프트의 일부입니다.그리고 다른 색상의 컵으로 개체를 덮습니다.어느 시점에서든 개체는 최대 하나의 개체나 덮개로만 덮일 수 있습니다.로봇이 아래쪽 개체를 조작하도록 요청받으면 위쪽 개체를 치워야 합니다.새 덮개나 개체를 그 위에 쌓으려면 기존 덮개나 개체를 제거해야 합니다.10개의 에피소드를 사용하여 실제 로봇 도메인에서 Statler와 CaP의 성능을 평가합니다.Statler는 40%(70%)의 에피소드 및 단계(괄호 안) 성공률을 달성하며, 여기서 실패 사례의 67%는 LLM 추론 때문이고 다른 사례는 지각 또는 조작 문제로 인해 발생합니다. CaP의 성공률은 20%(46%)이고, LLM 추론이 실패의 88%를 차지합니다.그림 6에서는 CaP 기준선이 실패하는 짧은 예도 제공합니다.어려움은 노란색 블록이 검은색 컵 아래에 숨겨져 있다는 것을 인식하는 데 있으며, Statler가 올바르게 발견했으므로 노란색 블록을 집어 올리기 전에 제거해야 합니다.대신 CaP는 이를 인식하지 못하고 그럼에도 불구하고 노란색 블록을 집어 올리려고 하며, 이로 인해 MDETR이 노란색이 있는 장난감 바퀴를 노란색 블록으로 잘못 감지합니다.C. 상태 유지 절제 Statler의 상태 유지 전략을 더 잘 이해하기 위해 상태를 추적하는 세 가지 다른 접근 방식을 고려합니다.첫 번째(Statler-Unified)는 Statler의 판독기 및 작성기 프롬프트를 섞어서 프롬프트를 사용하는 단일 LLM을 세계 상태 판독기와 작성기로 사용합니다.각 단계에서 LLM은 먼저 동작을 생성한 다음 해당 동작을 실행하여 발생하는 상태를 예측합니다. LLM은 다음 쿼리를 추론할 때 결과 상태를 사용합니다.단일 LLM을 사용하는 것은 개념적으로 간단하지만 추론 및 일반화에 대한 부담이 추가됩니다.InstructGPT [20]에서 영감을 받은 두 번째(Statler-Auto)는 세계 상태 작성자에 대한 컨텍스트 내 상태 업데이트 예를 수신하지 않습니다.대신 상태를 유지해야 하는 방법에 대한 자연어 설명을 제공합니다.프롬프트 6은 프롬프트의 관련 부분을 보여줍니다.지시와 컨텍스트 내 상태 업데이트 예가 없는 경우 동일한 작업 집합에서 모델을 실행했습니다.세 번째(Statler w/o State)는 Statler의 세계 상태 유지 관리 구성 요소를 완전히 제거하여 Code-as-Policies로 축소되는 모델을 생성합니다.표 III: 제거 에피소드(개별 단계) 성공률. Pick &amp; Place 소독 가중치 Statler w/o State Statler-Unified 0.00(0.54) 0.00(0.68) 0.40(0.85) 0.35(0.79) Statler-Auto 0.75(0.88) Statler(저희) 0.50(0.88) 0.45(0.82) 0.40(0.82) 0.00(0.84) 0.50(0.92) 0.40(0.90) 0.55(0.93) 표 III에서는 각 도메인에 대해 20개의 에피소드를 사용한 전체 에피소드 완료율과 개별 단계 성공율 측면에서 Statler의 성능을 세 가지 변형과 비교합니다. 세계 상태를 유지하지 않으면 Statler w/o State는 어떤 에피소드도 완료하지 못하고(에피소드 중에 모델이 사용자 쿼리 중 하나에 응답하지 못하면 에피소드가 실패로 간주됨을 기억하세요) Statler보다 상당히 낮은 개별 단계 성공률을 초래합니다. 한편, Statler가 세계 상태 리더와 세계 상태 작성자에 대해 별도의 LLM을 사용하면 통합 리더와 작성자(Statler-Unified)를 사용할 때보다 일관되게 더 높은 에피소드 성공률을 보입니다. 개별 단계 성공률은 Pick-and-Place와 Block Disinfection의 경우 더 높고 상대적 가중치 추론의 경우 비슷합니다. Statler가 세계 상태 작성자와 독자에 대해 별도의 LLM을 사용하는 것과 관련하여, 컨텍스트 내 학습은 프롬프트 템플릿, 예제 순서 및 사용된 예제의 변화에 민감한 것으로 나타났습니다[21, 22]. 이에 비추어 볼 때 독자와 작성자를 나누어 달성한 성능 향상은 부분적으로 이러한 민감도에 기인할 수 있으며, 이를 통해 모델이 실제로 각각의 작업에 특화될 수 있습니다.흥미롭게도 Statler-Auto는 Pick-and-Place 및 Block Disinfection 도메인의 에피소드 성공률 측면에서 Statler 및 Statler-Unified보다 눈에 띄게 더 나은 성능을 보였지만 개별 성공률 측면에서는 Statler와 비슷했고 상대적 가중치 추론의 경우 더 나빴습니다.V. 관련 연구 로봇 공학을 위한 언어 이해 로봇 에이전트를 위한 언어 이해를 위한 일반적인 접근 방식에는 기호 접지[23]가 포함되며, 여기서 구문은 로봇의 세계 모델에 있는 기호에 매핑됩니다.초기 작업[24, 25]은 이 매핑을 수행하기 위해 수작업으로 만든 규칙에 의존합니다.최근 방법에서는 이러한 규칙을 주석이 달린 코퍼스[26-37]에서 매개변수를 학습한 통계 모델로 대체합니다. 다른 방법은 신경망 기반 아키텍처를 사용하여 자연어 발화와 장면에 대한 에이전트의 (시각적) 관찰을 공동으로 추론합니다[38-42].로봇공학을 위한 LLM LLM은 인터넷 스케일 코퍼스로 훈련되므로 주입된 상식은 객체 조작[44, 45]과 탐색 작업[46-49] 모두에 대한 자연어 지침[4, 5, 43]에서 고수준 계획을 수립하는 측면에서 로봇공학 분야에 도움이 되는 것으로 나타났습니다.LLM을 표현력 있는 시각 언어 임베딩과 결합하면 인상적인 기능도 사용할 수 있습니다[50].이로 인해 일반적인 다중 모달 구현 모델을 추진하려는 노력이 있었습니다[51, 52].LLMS를 사용한 코드 생성 코드 생성은 LLM의 가장 성공적인 사용 사례 중 하나였습니다[2, 3, 53–56]. 코드는 계산, 비전 및 조작을 포함한 작업을 위해 실행 가능한 API와 연결할 수 있기 때문에 많은 작업이 다양한 도구를 사용한 코드 생성에 집중되었습니다[57-59]. 특히 Code-as-policies[5]는 로봇 컨텍스트 내에서 코드 생성을 사용한 최초의 방법 중 하나입니다. 추론에서의 상태 표현 상태 표현을 사용하면 알고리즘 추론 작업에 도움이 되는 것으로 나타났습니다[60, 61]. 전체 코드 조각에 대한 실행 결과를 예측하기 위해 하나의 정방향 패스를 사용하는 대신 Nye et al.[60]은 최종 실행 결과를 유추하는 데 도움이 되는 단계별 중간 출력을 설명하는 것을 제안합니다. 가능한 미래 토큰을 롤아웃하여 언어 모델링을 향상하는 것을 목표로 하는 연구 노력도 관련이 있습니다[62]. 언어 모델 및 계획 최근 연구에 따르면 바닐라 및 명령어 조정 LLM은 계획이 좋지 않습니다[14, 16, 17]. 일부 연구에서는 자연어와 도메인별 프로그래밍 언어 사이의 중개자로 LLM을 사용한 다음 기존 플래너를 사용하는 것을 제안합니다[15, 16, 63]. Silver et al.[17]은 생성된 플랜에 대한 피드백을 제공하는 Chain-of-Thought 및 반복적 리프로프팅을 사용하지만 좋은 성능을 위해 GPT-4가 필요합니다. Xiang et al.[64]은 월드모델의 추적을 기반으로 LLM의 매개변수 효율적인 미세 조정을 사용하고 관련 작업에서 향상된 성능을 보여줍니다.VI.
--- CONCLUSION ---
우리는 더 긴 지평선 로봇 추론 작업을 지원하기 위해 상태를 명시적으로 표현하는 언어 모델인 Statler를 제시했습니다. Statler에 필수적인 것은 현재 내부 상태를 고려하여 사용자 쿼리에 응답하는 세계 상태 리더와 세계 상태를 유지하는 세계 상태 작성기입니다. 다양한 시뮬레이션 및 실제 로봇 조작 작업에 대한 평가 결과, Statler는 과거에 대한 추론이 필요한 비사소한 작업에서 현대 모델보다 상당히 우수한 성능을 보였습니다. 절제는 세계 상태 리더와 작성기의 기여를 보여주며, 상태 표현에 대한 Statler의 유연성을 시사합니다. VII. 감사의 말 우리는 HDR TRIPODS(No. 2216899)에 따라 이 작업을 가능하게 해준 National Science Foundation과 Adobe Research 기부금을 통해 Hongyuan Mei를 지원해준 Adobe에 감사드립니다. 프로젝트 초기 단계에서 도움을 준 Luzhe Sun과 Richard Xu에게 감사드립니다. 참고문헌 [1] T. Kojima, SS Gu, M. Reid, Y. Matsuo, 및 Y. Iwasawa, &quot;대규모 언어 모델은 제로샷 추론기입니다.&quot; arXiv 사전 인쇄본 arXiv:2205.11916, 2022. [2] M. Chen, J. Tworek, H. Jun, Q. Yuan, HP de Oliveira Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, A. Ray, R. Puri, G. Krueger, M. Petrov, H. Khlaaf, G. Sastry, P. Mishkin, B. Chan, S. Gray, N. Ryder, M. Pavlov, A. Power, L. Kaiser, M. Bavarian, C. Winter, P. Tillet, FP Such, D. Cummings, M. Plappert, F. Chantzis, E. Barnes, A. HerbertVoss, WH Guss, A. Nichol, A. Paino, N. Tezak, J. Tang, I. Babuschkin, S. Balaji, S. Jain, W. Saunders, C. Hesse, AN Carr, J. Leike, J. Achiam, V. Misra, E. Morikawa, A. Radford, M. Knight, M. Brundage, M. Murati, K. Mayer, P. Welinder, B. McGrew, D. Amodei, S. McCandlish, I. Sutskever, W. Zaremba, &quot;코드로 학습된 대규모 언어 모델 평가,&quot; arXiv 사전 인쇄본 arXiv:2107.03374, 2021. [3] OpenAI, &quot;GPT-4 기술 보고서,&quot; arXiv 사전 인쇄본 arXiv:2303.08774, 2023. [4] M. Ahn, A. Brohan, N. Brown, Y. Chebotar, O. Cortes, B. David, C. Finn, C. Fu, K. Gopalakrishnan, K. Hausman, A. Herzog, D. Ho, J. Hsu, J. Ibarz, B. Ichter, A. Irpan, E. Zhang, RJ Ruano, K. Jeffrey, S. Jesmonth, NJ Joshi, R. Julian, D. Kalashnikov, Y. Kuang, K.-H. Lee, S. Levine, Y. Lu, L. Luu, C. Parada, P. Pastor, J. Quiambao, K. Rao, J. Rettinghouse, D. Reyes, P. Sermanet, N. Sievers, C. Tan, A. Toshev, V. Vanhoucke, F. Xia, T. Xiao, P. Xu, S. Xu, M. Yan, A. Zeng, &quot;내가 할 수 있는 대로 하라, 내가 말하는 대로 하지 마라: 로봇의 가능성에 대한 언어 기반,&quot; arXiv 사전 인쇄본 arXiv:2204.01691, 2022. [5] J. Liang, W. Huang, F. Xia, P. Xu, K. Hausman, B. Ichter, PR Florence, A. Zeng, &quot;정책으로서의 코드: 구체화된 제어를 위한 언어 모델 프로그램,&quot; arXiv 사전 인쇄본 arXiv:2209.07753, 2022. [6] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, PR Florence, A. Zeng, J. Tompson, I. Mordatch, Y. Chebotar, P. Sermanet, N. Brown, T. Jackson, L. Luu, S. Levine, K. Hausman, B. Ichter, &quot;내면의 독백: 언어 모델을 통한 계획을 통한 체화된 추론&quot;, 로봇 학습 컨퍼런스(CORL) 회의록, 2022. [7] S. Yang, O. Nachum, Y. Du, J. Wei, P. Abbeel, D. Schuurmans, &quot;의사 결정을 위한 기초 모델: 문제, 방법 및 기회&quot;, arXiv 사전 인쇄본 arXiv:2303.04129, 2023. [8] A. Nordmann, N. Hochgeschwender, SB Wrede, &quot;로봇공학의 도메인 특정 언어에 대한 조사&quot;, 시뮬레이션, 모델링 및 자율 로봇 프로그래밍, 2014. [9] RS Sutton 및 AG Barto, 강화 학습: 소개. 매사추세츠주 캠브리지: MIT 출판부, 1998. [10] D. Koller 및 N. Friedman, 확률적 그래픽 모델: 원리 및 기술, 2009. [11] &quot;Anthropic에서 100k 컨텍스트 창 소개,&quot; https://www.anthropic.com/index/100k-context-windows, 액세스: 2023-05-11. [12] NF Liu, K. Lin, J. Hewitt, A. Paranjape, M. Bevilacqua, F. Petroni, P. Liang, &quot;중간에서 길을 잃다: 언어 모델이 긴 컨텍스트를 사용하는 방법,&quot; arXiv 사전 인쇄본 arXiv:2307.03172, 2023. [13] S. Sun, K. Krishna, A. Mattarella-Micke, M. Iyyer, &quot;장거리 언어 모델이 실제로 장거리 컨텍스트를 사용합니까?&quot; arXiv 사전 인쇄본 arXiv: 2109.09115, 2021. [14] K. Valmeekam, S. Sreedharan, M. Marquez, A. Olmo, S. Kambhampati, &quot;대규모 언어 모델의 계획 능력에 관하여(제안된 벤치마크가 있는 중요한 조사),&quot; arXiv 사전 인쇄본 arXiv:2302.06706, 2023. [15] L. Guan, K. Valmeekam, S. Sreedharan 및 S. Kambhampati, &quot;모델 기반 작업 계획을 위한 세계 모델을 구성하고 활용하기 위해 사전 훈련된 대규모 언어 모델 활용&quot;, arXiv 사전 인쇄본 arXiv:2305.14909, 2023. [16] B. Liu, Y. Jiang, X. Zhang, Q. Liu, S. Zhang, J. Biswas 및 P. Stone, &quot;Llm+ p: 최적의 계획 능력을 갖춘 대규모 언어 모델 강화&quot;, arXiv 사전 인쇄본 arXiv:2304.11477, 2023. [17] T. Silver, S. Dan, K. Srinivas, JB Tenenbaum, LP Kaelbling 및 M. Katz, &quot;사전 훈련된 대규모 언어 모델을 사용한 PDDL 도메인의 일반화된 계획&quot;, arXiv 사전 인쇄본 arXiv:2305.11014, 2023. [18] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia, EH Chi, QV Le, D. Zhou, &quot;Chain-ofthought prompting elicits reasoning in large language models,&quot; Neural Information Processing Systems(NeurIPS)의 발전, 2022. [19] A. Kamath, M. Singh, Y. LeCun, G. Synnaeve, I. Misra, N. Carion, &quot;MDETR Modulated detection for end-to-end multi-modal understanding,&quot; 국제 컴퓨터 비전 컨퍼런스(ICCV) 회의록, 2021. [20] L. Ouyang, J. Wu, X. Jiang, D. Almeida, CL Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton, L. Miller, M. Simens, A. Askell, P. Welinder, P. Christiano, J. Leike, and R. Lowe, &quot;인간의 피드백을 통해 지시를 따르도록 언어 모델 훈련하기&quot;, 2022. [21] Q. Dong, L. Li, D. Dai, C. Zheng, Z. Wu, B. Chang, X. Sun, J. Xu, and Z. Sui, &quot;상황 내 학습을 위한 설문 조사&quot;, arXiv 사전 인쇄본 arXiv:2301.00234, 2022. [22] Z. Zhao, E. Wallace, S. Feng, D. Klein, and S. Singh, &quot;사용 전 교정: 언어 모델의 few-shot 성능 개선&quot;, 국제 기계 학습 컨퍼런스. PMLR, 2021, pp. 12697–12706. [23] S. Harnad, &quot;기호 접지 문제&quot;, Physica D, vol. 42, pp. 335–346, 1990. [24] T. Winograd, &quot;자연어 이해를 위한 컴퓨터 프로그램의 데이터 표현으로서의 절차&quot;, 박사 학위 논문, 매사추세츠 공과대학교, 1971. [25] M. MacMahon, B. Stankiewicz, 및 B. Kuipers, &quot;Walk the talk: Connecting language, knowledge, and action in route instruction&quot;, National Conference on Artificial Intelligence(AAAI) 회의록, 2006. [26] T. Kollar, S. Tellex, D. Roy, 및 N. Roy, &quot;자연어 지시를 이해하기 위하여&quot;, ACM/IEEE International Conference on HumanRobot Interaction(HRI) 회의록, 2010. [27] C. Matuszek, D. Fox, 및 K. Koscher, &quot;통계적 기계 번역을 사용하여 지시 따르기&quot;, ACM/IEEE 국제인간-로봇 상호작용(HRI) 컨퍼런스 회의록, 2010. [28] DL Chen 및 RJ Mooney, &quot;관찰을 통해 자연어 탐색 지침을 해석하는 법 배우기&quot;, 인공 지능 국가 컨퍼런스 회의록(AAAI), 2011. [29] S. Tellex, T. Kollar, S. Dickerson, MR Walter, AG Banerjee, S. Teller 및 N. Roy, &quot;로봇 탐색 및 모바일 조작을 위한 자연어 명령 이해&quot;, 인공 지능 국가 컨퍼런스 회의록(AAAI), 2011. [30] C. Matuszek, E. Herbst, L. Zettlemoyer 및 D. Fox, &quot;로봇 제어 시스템에 대한 자연어 명령 구문 분석하기&quot;, 국제실험로봇심포지엄(ISER), 2012. [31] J. Thomason, S. Zhang, RJ 영어: Mooney 및 P. Stone, &quot;인간-로봇 대화를 통해 자연어 명령을 해석하는 법 배우기&quot;, 국제인공지능공동회의(IJCAI) 회의록, 2015년. [32] TM Howard, S. Tellex 및 N. Roy, &quot;모바일 조작기를 위한 자연어 플래너 인터페이스&quot;, IEEE 국제로봇자동화회의(ICRA) 회의록, 2014년. [33] DK Misra, J. Sung, K. Lee 및 A. Saxena, &quot;Tell me Dave: 조작 지침에 대한 자연어의 문맥별 접지&quot;, 국제로봇연구저널, 제35권, 제1호(2015년 12월). 1-3, 281-300쪽, 2016년 1월. [34] J. Thomason, J. Sinapov, M. Svetlik, P. Stone, 및 RJ Mooney, &quot;I spy&quot; 놀이를 통해 다중 모달 기반 언어 의미론 학습&quot;, 인공 지능 국제 공동 컨퍼런스(IJCAI) 회의록, 2016년. [35] J. Thomason, J. Sinapov, RJ Mooney, 및 P. Stone, &quot;언어 설명의 다중 모달 기반을 위한 탐색 행동 안내&quot;, 인공 지능 국가 컨퍼런스(AAAI) 회의록, 2018년. [36] M. Shridhar 및 D. Hsu, &quot;인간-로봇 상호 작용을 위한 참조 표현의 상호 작용적 시각적 기반&quot;, 로봇 과학 및 시스템 회의록(RSS), 2018년. [37] R. Paul, J. Arkin, D. Aksaray, N. Roy 및 TM Howard, &quot;로봇 플랫폼과의 자연어 상호작용을 위한 추상적 공간 개념의 효율적 기초&quot;, International Journal of Robotics Research, 제37권, 제1호. 10, pp. 1269-1299, 2018년 6월. [38] H. Mei, M. Bansal, 및 M. Walter, &quot;Listen, attention, and walk: Neural mapping of navigational instruction to action sequences,&quot; National Conference on Artificial Intelligence(AAAI)의 회의록, 2016년. [39] P. Anderson, Q. Wu, D. Teney, J. Bruce, M. Johnson, N. Sünderhauf, ID Reid, S. Gould, 및 A. van den Hengel, &quot;Vision-and-language navigation: Interpreting visual-grounded navigation instruction in real environments,&quot; IEEE/CVF Conference on Computer Vision and Pattern Recognition(CVPR)의 회의록, 2017년. [40] D. Fried, R. Hu, V. Cirik, A. Rohrbach, J. Andreas, LP Morency, T. Berg-Kirkpatrick, K. Saenko, D. Klein, 및 T. Darrell, &quot;시각 및 언어 탐색을 위한 화자-추종자 모델&quot;, 신경 정보 처리 시스템의 발전(NeurIPS), 2018년 12월. [41] F. Zhu, Y. Zhu, X. Chang, 및 X. Liang, &quot;자기 감독 보조 추론 작업을 통한 시각 언어 탐색&quot;, IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스(CVPR) 회의록, 2020년 6월. [42] SY Min, DS Chaplot, P. Ravikumar, Y. Bisk, 및 R. Salakhutdinov, &quot;영화: 모듈식 방법을 사용하여 언어의 지시 따르기&quot;,&quot; arXiv 사전 인쇄본 arXiv:2110.07342, 2021. [43] W. Huang, P. Abbeel, D. Pathak, 및 I. Mordatch, 영어: &quot;제로샷 플래너로서의 언어 모델: 구체화된 에이전트를 위한 실행 가능한 지식 추출&quot;, 국제 머신 러닝 컨퍼런스(ICML) 회의록, 2022. [44] R. Wang, J. Mao, J. Hsu, H. Zhao, J. Wu, 및 Y. Gao, &quot;프로그래밍적으로 기반을 두고 구성적으로 일반화 가능한 로봇 조작&quot;, 국제 학습 표현 컨퍼런스(ICLR) 회의록, 2023. [45] AZ Ren, B. Govil, T.-Y. Yang, KR Narasimhan 및 A. Majumdar, &quot;도구 조작의 가속화된 학습을 위한 언어 활용&quot;, 로봇 학습 컨퍼런스(CoRL) 회의록, 2023년. [46] A. Majumdar, A. Shrivastava, S. Lee, P. Anderson, D. Parikh 및 D. Batra, &quot;웹의 이미지-텍스트 쌍을 사용하여 비전 및 언어 탐색 개선&quot;, 유럽 컴퓨터 비전 컨퍼런스(ECCV) 회의록, 2020년. [47] SY Gadre, M. Wortsman, G. Ilharco, L. Schmidt 및 S. Song, &quot;목초지의 소: 언어 기반 제로샷 객체 탐색을 위한 기준선 및 벤치마크&quot;, IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스(CVPR) 회의록, 2023년. [48] D. Shah, B. Osiński, S. Levine 외, &quot;LM-Nav: 언어, 비전 및 동작의 대규모 사전 훈련된 모델을 사용한 로봇 탐색&quot;, 로봇 학습 컨퍼런스(CoRL) 회의록, 2023. [49] C. Huang, O. Mees, A. Zeng, W. Burgard, &quot;로봇 탐색을 위한 시각적 언어 맵&quot;, arXiv 사전 인쇄본 arXiv:2210.05714, 2022. [50] M. Shridhar, L. Manuelli, D. Fox, &quot;CLIPort: 로봇 조작을 위한 무엇 및 어디 경로&quot;, arXiv 사전 인쇄본 arXiv:2109.12098, 2021. [51] A. Zeng, AS Wong, S. Welker, K. Choromanski, F. Tombari, A. Purohit, MS Ryoo, V. Sindhwani, J. Lee, V. Vanhoucke, PR 플로렌스, &quot;소크라테스 모델: 언어로 제로샷 멀티모달 추론 구성하기,&quot; arXiv 사전 인쇄본 arXiv:2204.00598, 2022. [52] D. Driess, F. Xia, MS Sajjadi, C. Lynch, A. Chowdhery, B. Ichter, A. Wahid, J. Tompson, Q. Vuong, T. Yu et al., &quot;PALM-E: 체화된 멀티모달 언어 모델,&quot; arXiv 사전 인쇄본 arXiv:2303.03378, 2023. [53] D. Hendrycks, S. Basart, S. Kadavath, M. Mazeika, A. Arora, E. Guo, C. Burns, S. Puranik, H. He, DX Song, J. Steinhardt, &quot;APPS로 코딩 과제 역량 측정하기,&quot; arXiv 사전 인쇄본 arXiv:2105.09938, 2021. [54] Y. Li, DH Choi, J. Chung, N. Kushman, J. Schrittwieser, R. Leblond, Tom, Eccles, J. Keeling, F. Gimeno, AD Lago, T. Hubert, P. Choy, C. de, M. d&#39;Autume, I. Babuschkin, X. Chen, 추신. Huang, J. Welbl, S. Gowal, Alexey, Cherepanov, J. Molloy, DJ Mankowitz, ES Robson, P. Kohli, N. de, Freitas, K. Kavukcuoglu 및 O. Vinyals, &quot;AlphaCode를 사용한 경쟁 수준 코드 생성&quot;, Science, vol. 378, pp. 1092–1097, 2022. [55] B. Chen, F. Zhang, A. Nguyen, D. Zan, Z. Lin, J.-G. Lou 및 W. Chen, &quot;CodeT: 생성된 테스트를 사용한 코드 생성,&quot; arXiv 사전 인쇄본 arXiv:2207.10397, 2022. [56] TB Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, TJ Henighan, R. Child, A. Ramesh, DM Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever 및 D. Amodei, &quot;언어 모델은 소수 샷 학습자입니다,&quot; arXiv 사전 인쇄본 arXiv:2005.14165, 2020. [57] T. Schick, J. Dwivedi-Yu, R. Dessì, R. Raileanu, M. Lomeli, L. Zettlemoyer, N. Cancedda, and T. Scialom, &quot;Toolformer: 언어 모델은 스스로 도구를 사용하도록 가르칠 수 있습니다.&quot; arXiv 사전 인쇄본 arXiv:2302.04761, 2023. [58] D. Sur&#39;is, S. Menon, and C. Vondrick, &quot;ViperGPT: 추론을 위한 Python 실행을 통한 시각적 추론&quot; arXiv 사전 인쇄본 arXiv:2303.08128, 2023. [59] SG Patil, T. Zhang, X. Wang, and JE Gonzalez, &quot;Gorilla: 대규모 API와 연결된 대규모 언어 모델&quot; arXiv 사전 인쇄본 arXiv:2305.15334, 2023. [60] M. Nye, A. Andreassen, G. Gur-Ari, H. Michalewski, J. Austin, D. Bieber, D. Dohan, A. Lewkowycz, M. Bosma, D. Luan, C. Sutton, and A. Odena, &quot;Show your work: Scratchpads for intermediate computing with language models,&quot; arXiv 사전 인쇄본 arXiv:2112.00114, 2021. [61] AJH Nam, M. Ren, C. Finn, and JL McClelland, &quot;Learning to reason with relationshipal abstractions,&quot; arXiv 사전 인쇄본 arXiv:2210.02615, 2022. [62] L. Du, H. Mei, and J. Eisner, &quot;Lookahead attention을 통한 자기회귀 모델링,&quot; arXiv 사전 인쇄본 arXiv:2305.12272, 2023. [63] L. Wong, G. Grand, AK Lew, ND Goodman, VK Mansinghka, J. Andreas, JB Tenenbaum, &quot;단어 모델에서 세계 모델로: 자연어에서 확률적 사고 언어로 번역,&quot; arXiv 사전 인쇄본 arXiv:2306.12672, 2023. [64] J. Xiang, T. Tao, Y. Gu, T. Shu, Z. Wang, Z. Yang, Z. Hu, &quot;언어 모델은 세계 모델을 만난다: 체화된 경험은 언어 모델을 강화한다,&quot; arXiv 사전 인쇄본 arXiv:2305.10626, 2023. 부록 I 저자 기여 • Takuma Yoneda가 프로젝트를 주도했습니다. 그는 Jiading Fang과 논의하고 시드 아이디어를 생각해냈습니다. 그는 또한 초기 단계부터 실험 설계를 제공했고 프로젝트 내내 논의와 노력을 주도했습니다. • • • • • Jiading Fang은 이 프로젝트의 원동력이 된 해커톤을 시작했고, 시드 아이디어를 공유했으며, 글쓰기에 기여했습니다. Peng Li는 동기 부여 실험을 구현하고 수행했습니다. 그는 또한 대부분의 절제 실험을 설계하고 수행했습니다. Huanyu Zhang은 프로젝트 초기 단계부터 평가 에피소드를 설계하고 정량적, 정성적 분석을 수행했습니다. Tianchong Jiang은 실험을 위한 PyBullet 시뮬레이션 환경을 개발하고 해당 시각화를 만들었습니다. Shengjie Lin은 작업 설계, 신속한 개발, 인식 통합 및 평가 실행과 관련하여 실제 로봇 실험을 주도했습니다. ⚫ Ben Picker는 평가 에피소드를 설계하고 생성 및 평가의 부분적 자동화를 도왔습니다. 또한 관련 연구 및 논문 편집에도 기여했습니다. • David Yunis는 Shengjie Lin과 함께 실제 로봇 실험을 개발하고 실행했습니다. 그는 또한 관련 연구를 식별하고 편집했으며, 대부분의 관련 연구 논의와 실제 로봇 실험 섹션을 작성했습니다. • Hongyuan Mei는 프로젝트를 감독했습니다. 그는 또한 초록과 서론을 재구성하는 데 크게 기여했습니다. • Matthew R. Walter는 초기 해커톤부터 논문 제출까지 프로젝트를 감독하고 안내했습니다. 그는 또한 Takuma가 프로젝트 구성원 간의 작업 부하를 관리하고 분배하도록 도왔는데, 이는 이 규모에서 협업을 용이하게 하는 데 중요했습니다. 부록 II 예제 에피소드 시퀀스 이 섹션에서는 Statler가 테스트 시간에 처리해야 하는 작업을 더 잘 이해하기 위해 세 가지 예제 평가 에피소드(도메인당 하나씩)를 보여줍니다. 에피소드는 프롬프트 7과 9에 나와 있습니다. 올바르게 답하기 위해 시간적 추론이 필요한 시간적 쿼리는 파란색으로 강조 표시됩니다. [골드 코드] 아래의 Python 스니펫은 모델이 생성할 것으로 예상되는 &quot;올바른&quot; 코드를 보여줍니다. 이 모델은 여기 골드 코드에 포함되지 않은 주석, noop 및 update_wm 함수(Statler의 경우)도 출력할 수 있습니다. 전체 에피소드 세트(도메인당 20개 에피소드)는 https://github의 GitHub 저장소에서 찾을 수 있습니다. com/ripl/statler.3 # &quot;[초기 상태] # 상태 = { &quot;objects&quot;: [&quot;녹색 블록&quot;, &quot;주황색 블록&quot;, &quot;흰색 블록&quot;, 시안색 블록&quot;, &quot;황금 그릇&quot;, &quot;빨간색 그릇&quot;], &quot;relations&quot;: [], &quot;녹색 블록&quot;: {}, 4 # 5 # 6 # &quot;주황색 블록&quot;: {}, 7 # &quot;흰색 블록&quot;: {}, 8 # &quot;시안색 블록&quot;: {},# 10 # 11 # } &quot;황금 그릇&quot;: {}, &quot;빨간색 그릇&quot;: {}, 12 [사용자 쿼리 1] 흰색 블록을 황금색 그릇에 넣으세요 13 [금색 코드] 14 put_first_on_second(&quot;흰색 블록&quot;, &quot;황금 그릇&quot;) [사용자 쿼리 2] 녹색 블록 위에 시안색 블록을 넣으세요 16 [금색 코드]put_first_on_second(&quot;시안색 블록&quot;, &quot;녹색 블록&quot;) [사용자 쿼리 3] 주황색을 넣으세요 빈 그릇의 블록 19 [골드 코드]put_first_on_second(&quot;오렌지색 블록&quot;, &quot;빨간색 그릇&quot;) [사용자 쿼리 4] 황금색 그릇에 있는 블록을 빨간 그릇에 있는 블록 위에 놓으세요 22 [골드 코드] put_first_on_second(&quot;흰색 블록&quot;, &quot;오렌지색 블록&quot;) [사용자 쿼리 5] 녹색 블록이 흰색 블록보다 높은 위치에 있습니까?[골드 코드]say(&quot;아니요&quot;) 27 [사용자 쿼리 6] 녹색 블록이 주황색 블록 바로 위에 있습니까?28 [골드 코드]say(&quot;아니요&quot;) 프롬프트 7: 평가 에피소드 예시(픽앤플레이스 도메인). 파란색 쿼리는 시간적 추론이 필요합니다. [초기 상태] # 상태 = { &quot;objects&quot;: [&quot;teal block&quot;, &quot;black block&quot;, &quot;cyan block&quot;, &quot;blue block&quot;, &quot;tan bowl&quot;, &quot;disinfector&quot;], &quot;relations&quot;: [], &quot;disinfector&quot;: {&quot;contains&quot;: []},3 # 4 # 5 # 6 # &quot;teal block&quot;: {}, 7 # &quot;black block&quot;: {},# &quot;cyan block&quot;: {}, 9 # &quot;blue block&quot;: {}, 10 # &quot;tan bowl&quot;: {} 11 # } 12 [사용자 쿼리 1] 청록색 블록과 검은색 블록은 더럽습니다. [사용자 질의 2] 다른 블록은 깨끗합니다14 [사용자 질의 3] 우습게도 누군가 실수로 시안색 블록과 파란색 블록을 오염시켰습니다15 [사용자 질의 4] 틸색 블록 위에 시안색 블록을 올려놓으세요16 [골드 코드]put_first_on_second(&quot;시안색 블록&quot;, &quot;틸색 블록&quot;) 18 [사용자 질의 5] 파란색 블록과 검은색 블록을 소독기에 넣으세요19 [골드 코드]put_first_on_second(&quot;파란색 블록&quot;, &quot;소독기&quot;) put_first_on_second(&quot;검은색 블록&quot;, &quot;소독기&quot;) 22 [사용자 질의 6] 파란색 블록을 황갈색 그릇에 넣으세요23 [골드 코드]put_first_on_second(&quot;파란색 블록&quot;, &quot;황갈색 그릇&quot;) 25 [사용자 질의 7] 파란색 블록을 테이블 위에 올려놓으세요. 26 [골드 코드]put_first_on_second(&quot;파란색 블록&quot;, &quot;테이블&quot;) 28 [사용자 쿼리 8] 파란색 블록 위에 검은색 블록을 놓으세요. 29 [골드 코드]put_first_on_second(&quot;검은색 블록&quot;, &quot;파란색 블록&quot;) 31 [사용자 쿼리 9] 모든 더러운 블록을 테이블에 놓으세요. [골드 코드]put_first_on_second(&quot;청록색 블록&quot;, &quot;테이블&quot;) put_first_on_second(&quot;시안색 블록&quot;, &quot;테이블&quot;) 프롬프트 8: 평가 에피소드 예시(소독 도메인). 파란색 쿼리는 시간적 추론이 필요합니다.[초기 상태] # 상태 = {## 7 # &quot;objects&quot;: [&quot;black block&quot;, &quot;orange block&quot;, green block&quot;, &quot;red block&quot;, &quot;gray bowl&quot;, &quot;blue bowl&quot;], &quot;relations&quot;: [], &quot;black block&quot;: {}, &quot;orange block&quot;: {}, &quot;green block&quot;: {}, &quot;red block&quot;: {}, &quot;gray bowl&quot;: {}, 실수로 &quot;dirty&quot;로 표시했습니다(빨간색으로 강조 표시됨). 이 오류 1 다음에서 로봇은 더럽고 깨끗한 블록을 처리합니다. 2 깨끗한 블록은 다른 더럽게 된 블록을 만지면 더럽게 됩니다. 3 여기에는 더럽게 된 블록이 깨끗한 블록 위에 쌓인 경우와 더럽게 된 블록이 깨끗한 블록 바로 아래에 있는 경우가 포함됩니다.9 ## &quot;blue bowl&quot;: {},# }[사용자 쿼리 1] 검은색 블록은 녹색 블록의 무게의 두 배입니다.14 [사용자 쿼리 2] 주황색 블록을 회색 bowl[Gold Code]put_first_on_second(&quot;orange block&quot;, &quot;gray bowl&quot;) 17 [사용자 쿼리 3] 빨간색 블록은 주황색 블록의 무게의 두 배입니다.18 [사용자 쿼리 4] 빨간색 블록은 검은색 블록과 무게가 같습니다.19 [사용자 쿼리 5] 빨간색 블록을 회색 그릇에 넣으세요.20 [Gold Code]put_first_on_second(&quot;red block&quot;, &quot;gray bowl&quot;) 22 [사용자 쿼리 6] 블록을 파란색 그릇에 넣어 총 무게가 회색 그릇의 무게와 같아지도록 하세요.23 [Gold Code]put_first_on_second(&quot;black block&quot;, &quot;blue bowl&quot;) put_first_on_second(&quot;green block&quot;, &quot;blue bowl&quot;) 프롬프트 9: 예제 평가 에피소드(상대적 가중치 도메인). 파란색의 쿼리에는 시간적 추론이 필요합니다.부록 III 프롬프트 각 도메인에 대해 사용자 쿼리의 예제 시퀀스와 예상 Python 코드로 구성된 맞춤형 프롬프트를 제공합니다. 프롬프트 디자인에 대한 구체적인 아이디어를 제공하기 위해 프롬프트 10과 11에서 소독 도메인에 대한 Code-as-Policies 및 Statler 프롬프트를 보여줍니다.부록 IV 실패 사례 사례 Statler가 실패하는 예를 수동으로 살펴보았습니다.모델이 언제, 왜 실패하는지에 대한 통찰력을 제공하는 것이 도움이 되겠지만, 많은 경우 모델의 실수를 해석하는 것이 사소한 일이 아니라는 것을 알게 되었습니다.이 섹션에서는 모델이 실패한 세 가지 에피소드(각 도메인당 하나씩)를 보여 실패 모드에 대한 몇 가지 아이디어를 제공합니다.A. 픽 앤 플레이스 생성된 상태와 코드가 있는 에피소드는 프롬프트 12에 표시됩니다.5번째 사용자 쿼리인 &quot;녹색 블록이 흰색 블록보다 높은 위치에 있습니까?&quot;가 주어지면 현재 상태는 흰색 블록과 녹색 블록의 위치를 모두 올바르게 식별합니다(즉, 흰색 블록은 빨간색 그릇 안에 있는 주황색 블록에 있고 녹색 블록은 테이블 위에 있습니다). 하지만 이 정보를 사고 과정에서 보여준 대로 올바르게 수용하더라도 상태 독자는 여전히 녹색 블록이 더 낮은 위치에 있다는 것을 인식하지 못합니다. B. 소독 생성된 상태와 코드가 있는 에피소드는 프롬프트 13에 있습니다. 여덟 번째 사용자 쿼리인 &quot;파란색 블록 위에 검은색 블록을 놓으세요&quot;가 주어졌을 때 현재 상태가 두 블록(검정색과 파란색)이 모두 깨끗하다고 올바르게 인식하더라도 생성된 다음 상태 테이블, 그릇, 로봇 그리퍼는 더러움으로부터 보호되므로 영원히 깨끗하게 유지됩니다. 더러운 블록을 소독기에 넣으면 즉시 깨끗해집니다. 7 지침: 8 내장된 파이썬 함수와 명령문 외에 로봇은 다음 함수만 실행할 수 있습니다. &#39;put_first_on_second&#39;, &#39;say&#39; 및 &#39;noop&#39;.11 각 코드는 이러한 모든 요구 사항을 충족하도록 전문가가 신중하게 설계했습니다.=== 13 # 객체 = [&quot;cyan block&quot;, &quot;yellow block&quot;, &quot;brown block&quot;, purple block&quot;, &quot;blue block&quot;, &quot;green bowl&quot;, &quot;red bowl&quot;, disinfector&quot;] 14 # 쿼리: cyan block과 purple block은 더럽습니다. 15 noop() 16 # 쿼리: 다른 블록은 깨끗합니다 17 noop() 18 # 쿼리: 노란색 블록 위에 청록색 블록을 놓습니다 19 put_first_on_second(&quot;청록색 블록&quot;, &quot;노란색 블록&quot;) 20 # 쿼리: 녹색 그릇에 갈색 블록을 놓습니다 21 put_first_on_second(&quot;갈색 블록&quot;, &quot;녹색 그릇&quot;) &quot; 22 # 쿼리: 앗, 누군가 갈색 블록을 꺼내서 더러운 곳에 떨어뜨렸네요 23 noop() 24 # 쿼리: 청록색 블록을 집어서 테이블 위에 놓습니다 25 put_first_on_second(&quot;청록색 블록&quot;, &quot;테이블&quot;) 26 # 쿼리: 노란색 블록을 소독기로 옮깁니다 27 put_first_on_second(&quot;노란색 블록&quot;, &quot;소독기&quot;) 28 # 쿼리: 깨끗한 블록을 모두 녹색 그릇에 놓습니다 29 # 생각해보세요: 깨끗한 블록은 노란색 블록과 보라색 블록입니다 30 put_first_on_second(&quot;파란색 블록&quot;, &quot;녹색 그릇&quot;) 31 put_first_on_second(&quot;노란색 블록&quot;, &quot;녹색 그릇&quot;) 32 # 쿼리: 시안색과 보라색 블록을 소독기에 넣으세요. 33 put_first_on_second(&quot;시안색 블록&quot;, &quot;소독기&quot;) 34 put_first_on_second (&quot;보라색 블록&quot;, &quot;소독기&quot;) 35 # 쿼리: 더러운 블록을 빨간색 그릇에 넣으세요. 36 # 생각해보세요: 더러운 블록은 갈색 블록뿐입니다. 37 put_first_on_second(&quot;갈색 블록&quot;, &quot;빨간색 그릇&quot;) 38 # 쿼리: 파란색 블록을 골라 테이블 위에 올려놓으세요. 39 put_first_on_second(&quot;파란색 블록&quot;, &quot;테이블&quot;) 40 # 쿼리: 노란색 블록을 테이블에 놓으세요. 41 put_first_on_second(&quot;노란색 블록&quot;, &quot;테이블&quot;) 42 # 쿼리: 갈색 블록을 녹색 그릇에 놓으세요. 43 put_first_on_second(&quot;시안색 블록&quot;, &quot;녹색 그릇&quot;) 44 # 쿼리: 빨간색 그릇에는 몇 개의 블록이 있나요? 45 # 생각해보세요: 빨간색 그릇은 비어 있습니다. 46 say (&quot;빨간색 그릇에 블록이 없습니다.&quot;) 47 === 프롬프트 10: 상태 작성자의 정책으로서의 코드(소독 도메인)에 대한 프롬프트로 인해 다음 단계에서 코드 생성이 실패합니다. C. 상대적 가중치 추론 생성된 상태와 코드가 있는 에피소드는 프롬프트 14에 있습니다. 모델은 사용자 쿼리 5까지 성공합니다. 다음 사용자 쿼리 &quot;블록을 파란색 그릇에 넣어 총 무게가 회색 그릇에 있는 것과 같아지도록 하세요&quot;가 주어졌을 때, 생성된 코드에 대한 #3 THINK: 주석에서 관찰할 수 있는 추론 프로세스에는 환각이 포함됩니다(빨간색으로 강조 표시됨). 현재 상태에서는 파란색 그릇이 비어 있음을 올바르게 식별하지만, 모델은 녹색 블록이 그 안에 있다고 생각하여 결과적으로 파란색 그릇으로 옮기지 못합니다. 1 다음에서 로봇은 더럽고 깨끗한 블록을 처리합니다. 2 깨끗한 블록은 다른 더럽게 된 블록을 만지면 더럽게 됩니다. 3 여기에는 더럽게 된 블록이 깨끗한 블록 위에 쌓이는 경우와 더럽게 된 블록이 깨끗한 블록 바로 아래에 있는 경우가 포함됩니다. 4 테이블, 그릇, 로봇 그리퍼는 더러움으로부터 보호되므로 영원히 깨끗하게 유지됩니다. 5 더럽게 된 블록을 소독기에 넣으면 즉시 깨끗해집니다. 7 지침: 8 내장된 Python 함수와 명령문 외에 로봇은 다음 함수만 실행할 수 있습니다: 9 &#39;put_first_on_second&#39;, &#39;say&#39; 및 &#39;update_wm&#39;.11 각 코드는 이러한 모든 요구 사항을 충족하도록 전문가가 신중하게 설계했습니다. 12 === # state = {# &quot;objects&quot; [&quot;cyan block&quot;, &quot;yellow block&quot;, &quot;brown block&quot;, &quot;purple block&quot;, &quot;blue block&quot;, &quot;green bowl&quot;, &quot;red bowl&quot;, &quot;disinfector&quot;], 15 # 16 # 17 ## 19 # 20 # 21 # 22 # 23 # 24 # } &quot;relations&quot;: [], &quot;disinfector&quot;: {&quot;contains&quot;: []}, &quot;cyan block&quot;: {}, &quot;yellow block&quot;: {}, &quot;brown block&quot;: {}, &quot;purple block&quot;: {}, &quot;blue block&quot;: {}, &quot;green bowl&quot;: {}, &quot;red bowl&quot;: {} 25 # query: cyan block과 purple block은 더럽습니다. 26 update_wm(&quot;The cyan and purple blocks are dirty&quot;) 27 #3 state = { ignored ... 28 # query: 다른 블록은 깨끗합니다. 29 update_wm(&quot;갈색 블록, 노란색 블록, 파란색 블록은 깨끗합니다.&quot;) 30 #23 state = { 생략됨 ... 31 # 쿼리: 노란색 블록 위에 청록색 블록을 놓으세요 32 put_first_on_second(&quot;청록색 블록&quot;, &quot;노란색 블록&quot;) 33 update_wm(&quot;노란색 블록 위에 청록색 블록을 놓으세요.&quot;) 34 # state = { 35 # &quot; &quot;objects&quot; [&quot;청록색 블록&quot;, &quot;노란색 블록&quot;, &quot;갈색 블록&quot;, &quot;보라색 블록&quot;, &quot;파란색 블록&quot;, &quot;녹색 그릇&quot;, &quot;빨간색 그릇&quot;, 소독기&quot;], 36 # &quot;relations&quot;: [[&quot;청록색 블록이 노란색 블록 위에 있습니다.&quot;]], &quot;소독기&quot;: {&quot;포함&quot;: []}, 37 # 38 # 39 # 40 ## 42 # 43 # 44 # 45 # } &quot;청록색 블록&quot;: {&quot;있습니다&quot;: [&quot;더러운&quot;]}, &quot;노란색 block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, &quot;brown block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;purple block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, &quot;blue block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;green bowl&quot;: {}, &quot;red bowl&quot;: {} 46 # 쿼리: 갈색 블록을 녹색 그릇에 넣으세요 47 put_first_on_second (&quot;갈색 블록&quot;, &quot;green bowl&quot;) 48 update_wm(&quot;갈색 블록을 녹색 그릇에 넣으세요&quot;) 49 # state = { 생략 . . . 50 # 쿼리: 앗, 누군가 갈색 블록을 꺼내서 더러운 곳에 떨어뜨렸어요 51 update_wm(&quot;갈색 블록을 테이블 위에 놓고 더럽게 만들어요 &quot;) 52 #23 state = { . . . 생략 . . . 53 # 쿼리: 청록색 블록을 골라서 테이블 위에 올려놓으세요. 54 put_first_on_second(&quot;시안색 블록&quot;, &quot;테이블&quot;) 55 update_wm(&quot;시안색 블록을 테이블 위에 놓으세요&quot;)# state = { 생략됨 . . . 57 # 쿼리: 노란색 블록을 소독기로 옮기세요 58 put_first_on_second(&quot;노란색 블록&quot;, &quot;소독기&quot;) 59 update_wm(&quot;노란색 블록을 소독기에 넣으세요&quot;)# state = { 생략됨 ... 생략됨 # 쿼리: 갈색 블록을 녹색 그릇에 넣으세요 63 put_first_on_second(&quot;시안색 블록&quot;, &quot;녹색 그릇&quot;) 64 update_wm(&quot;시안색 블록을 녹색 그릇에 넣으세요&quot;) 65 #state = { 생략됨 . . . 66 # 질의: 빨간 그릇에 블록이 몇 개 있나요?# 생각해보세요: 빨간 그릇은 비어 있습니다.68 say (&quot;빨간 그릇에 블록이 없습니다.&quot;) 1 [초기 상태] # 상태 = {# &quot;objects&quot;: [&quot;녹색 블록&quot;, &quot;주황색 블록&quot;, &quot;흰색 블록&quot;, &quot;청록색 블록&quot;, &quot;황금색 그릇&quot;, &quot;빨간색 그릇&quot;], &quot;relations&quot;: [], &quot;녹색 블록&quot;: {},## 6 # &quot;주황색 블록&quot;: {}, 7 # &quot;흰색 블록&quot;: {}, 8 # &quot;청록색 블록&quot;: {}, 9 # 10 ## }&quot;황금색 그릇&quot;: {}, &quot;빨간색 그릇&quot;: {}, 13 #상태 = { 생략됨 &quot;objects&quot;: [&quot;녹색 블록&quot;, &quot;주황색 블록&quot;, &quot;흰색 블록&quot;, &quot;청록색 블록&quot;, &quot;황금색 그릇&quot;, &quot;빨간색 그릇&quot;], &quot;relations&quot;: [&quot;청록색 블록이 녹색 블록 위에 있습니다.&quot;, &quot;흰색 블록이 주황색 블록 위에 있습니다.&quot;], 14 # 15 # 16 # &quot;녹색 블록&quot;: {}, 17 # &quot;주황색 블록&quot;: {}, 18 # &quot;흰색 블록&quot;: {}, 19 # &quot;청록색 블록&quot;: {}, 20 # 21 # 22 # } &quot;황금 그릇&quot;: {}, &quot;빨간색 그릇&quot;: {&quot;포함&quot;: [&quot;주황색 블록&quot;]}, 23 [사용자 질의 5] 녹색 블록이 흰색 블록보다 더 높은 위치에 있습니까?24 [생성된 코드]# 생각해보세요: 청록색 블록은 테이블 위에 있는 녹색 블록 위에 있습니다.26 # 생각해보세요: 흰색 블록은 빨간색 그릇에 있는 주황색 블록 위에 있습니다.27 # 생각해보세요: 따라서 녹색 블록은 더 높은 위치에 있습니다.28 say (&quot;예&quot;)30 [골드 코드] 31 say (&quot;아니요 (흰색 블록은 빨간색 그릇에 있는 주황색 블록 위에 있고 녹색 블록은 테이블 위에 있습니다.&quot;)&quot;)생략 프롬프트 12: 생성됨 평가 에피소드(픽 앤 플레이스 도메인)의 상태 및 코드. 잘못된 부분은 빨간색으로 강조 표시됩니다.# state = { 생략됨 ...=== 프롬프트 11: Statler(소독 도메인)에 대한 프롬프트. 복잡해지는 것을 피하기 위해 많은 줄이 생략되었습니다(&quot;생략됨&quot;으로 표시됨). 전체 버전은 저장소에서 확인하세요. 1 [초기 상태]5 # 6 #&quot;검은색 블록&quot;: {},# &quot;시안색 블록&quot;: {}, &quot;파란색 블록&quot;: {}, 10 # &quot;갈색 그릇&quot;: {}#3 }생략# 상태 = {##23 상태 = {# &quot;objects&quot;: [&quot;청록색 블록&quot;, &quot;검은색 블록&quot;, &quot;시안색 블록&quot;, 파란색 블록&quot;, &quot;갈색 그릇&quot;, &quot;소독기&quot;], &quot;관계&quot;: [], &quot;소독기&quot;: {&quot;포함&quot;: []}, &quot;청록색 블록&quot;: {}, 15 # 16 # 17 # &quot;청록색 블록&quot;: {&quot;있습니다&quot;: [&quot;더러운&quot;]}, 18 ## &quot;objects&quot;: [&quot;청록색 블록&quot;, &quot;검은색 블록&quot;, &quot;시안색 블록&quot;, &quot;파란색 블록&quot;, &quot;갈색 그릇&quot;, &quot;소독기&quot;], &quot;관계&quot;: [[&quot;시안색 블록이 청록색 블록 위에 있습니다&quot;]], &quot;disinfector&quot;: {&quot;contains&quot;: [&quot;black block&quot;]}, &quot;black block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;cyan block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]},# 5 # 6 # &quot;orange block&quot;: {}, 7 # &quot;green block&quot;: {}, 8 # &quot;red block&quot;: {}, 9 # &quot;gray bowl&quot;: {}, 10 # &quot;blue bowl&quot;: {}, 11 # }omitted [초기 상태] # 세계 상태 = {# &quot;objects&quot;: [&quot;black block&quot;, &quot;orange block&quot;, green block&quot;, &quot;red block&quot;, &quot;gray bowl&quot;, &quot;blue bowl&quot;], &quot;relations&quot;: [], &quot;black block&quot;: {}, 15 # 20 # 21 # &quot;blue block&quot;: {&quot;is&quot;: [&quot;clean&quot;]}, &quot;tan bowl&quot;: {} 16 # 13 [생성된 상태] 14 # state = { &quot;objects&quot;: [&quot;black block&quot;, &quot;orange block&quot;, green block&quot;, &quot;red block&quot;, &quot;gray bowl&quot;, &quot;blue bowl&quot;], &quot;relations&quot;: [], 17 # &quot;black block&quot;: {&quot;weight&quot;: red_block.weight}, 22 # } 18 # 23 [사용자 쿼리 8] black block을 blue block 위에 놓으세요 24 [생성된 코드] 19 # 20 # &quot;orange block&quot;: {&quot;weight&quot;: red_block.weight / 2}, &quot;green block&quot;: {&quot;weight&quot;: black_block.weight / 2}, &quot;red block&quot;: {&quot;weight&quot;: black_block. weight},put_first_on_second(&quot;검은색 블록&quot;, &quot;파란색 블록&quot;) 21 # &quot;회색 그릇&quot;: {&quot;포함&quot;: [&quot;주황색 블록&quot;, &quot;빨간색 블록&quot;]}, 26 update_wm(&quot;파란색 블록 위에 검은색 블록을 놓으세요&quot;) 27 [골드 코드]put_first_on_second(&quot;검은색 블록&quot;, &quot;파란색 블록&quot;) 29 [생성된 상태] 30 # 상태 = { 31 # &quot;객체&quot;: [&quot;청록색 블록&quot;, &quot;검은색 블록&quot;, &quot;청록색 블록&quot;, &quot;파란색 블록&quot;, &quot;갈색 그릇&quot;, &quot;소독기&quot;], 32 # &quot;관계&quot;: [[&quot;청록색 블록 위에 청록색 블록이 있습니다&quot;], [&quot;검은색 블록 위에 파란색 블록이 있습니다&quot;]], &quot;소독기&quot;: {&quot;포함&quot;: []}, &quot;청록색 블록&quot;: {&quot;있습니다&quot;: [&quot;더러운&quot;]}, 33 # 34 # 35 # &quot;검은색 블록&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, 36 # &quot;cyan block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, 37 # 38 # &quot;blue block&quot;: {&quot;is&quot;: [&quot;dirty&quot;]}, &quot;tan bowl&quot;: {} 39 # } 22 # 23 # } &quot;blue bowl&quot;: {}, 24 [사용자 쿼리 6] 파란색 그릇에 블록을 넣어 총 무게가 회색 그릇의 무게와 같아지도록 하세요 [생성된 코드]# 생각해보세요: 회색 그릇에는 주황색 블록과 빨간색 블록이 있습니다.# 생각해보세요: 파란색 그릇에는 녹색 블록이 있습니다.# 생각해보세요: 주황색 블록은 빨간색 블록의 무게가 절반입니다.# 생각해보세요: 녹색 블록은 검은색 블록의 무게가 절반입니다.# 생각해보세요: &#39;red_block.weight / 2&#39;인 블록을 놓아야 합니다.# 생각해보세요: &#39;red_block.weight&#39;인 블록. 무게 / 2&#39;는 검은색 블록put_first_on_second(&quot;검은색 블록&quot;, &quot;파란색 그릇&quot;)update_wm(&quot;검은색 블록을 파란색 그릇에 넣으세요.&quot;) 35 [골드 코드] put_first_on_second(&quot;검은색 블록&quot;, &quot;파란색 그릇&quot;) put_first_on_second(&quot;녹색 블록&quot;, &quot;파란색 그릇&quot;)40 [사용자 쿼리 9] 모든 더러운 블록을 테이블 위에 놓으세요. [생성된 코드]put_first_on_second(&quot;teal block&quot;, &quot;table&quot;)put_first_on_second(&quot;black block&quot;, &quot;table&quot;)put_first_on_second(&quot;cyan block&quot;, &quot;table&quot;)put_first_on_second(&quot;blue block&quot;, &quot;table&quot;) update_wm(&quot;Put all the dirty blocks on the table&quot;)48 [골드 코드]put_first_on_second(&quot;teal block&quot;, &quot;table&quot;)put_first_on_second(&quot;cyan block&quot;, &quot;table&quot;) 프롬프트 13: 평가 에피소드(소독 도메인)에서 생성된 상태 및 코드. 빨간색으로 강조 표시된 잘못된 부분은 프롬프트 14: 평가 에피소드(상대적 가중치 추론 도메인)에서 생성된 상태 및 코드입니다. 잘못된 부분은 빨간색으로 강조 표시됩니다.
