--- ABSTRACT ---
단어 사용 개선은 쓰기 지원에 필요한 기능입니다. 이 분야의 연구를 더욱 발전시키기 위해 이 논문에서는 &quot;Smart Word Suggestions&quot;(SWS) 과제와 벤치마크를 소개합니다. 다른 연구와 달리 SWS는 종단 간 평가를 강조하고 보다 현실적인 쓰기 지원 시나리오를 제시합니다. 이 과제에는 개선이 필요한 단어나 구문을 식별하고 대체 제안을 제공하는 것이 포함됩니다. 벤치마크에는 테스트를 위한 인간 레이블 데이터, 훈련을 위한 대규모 원격 감독 데이터 세트, 평가 프레임워크가 포함됩니다. 테스트 데이터에는 영어 학습자가 쓴 1,000개의 문장과 10명의 모국어 화자가 주석을 단 16,000개 이상의 대체 제안이 포함됩니다. 훈련 데이터 세트는 370만 개 이상의 문장과 규칙을 통해 생성된 1,270만 개의 제안으로 구성되어 있습니다. 7개의 기준선을 사용한 실험은 SWS가 어려운 과제임을 보여줍니다. 실험 분석을 기반으로 SWS에 대한 향후 연구를 위한 잠재적 방향을 제안합니다. 데이터 세트와 관련 코드는 https://github.com/microsoft/SmartWordSuggestions에서 사용할 수 있습니다. 1
--- INTRODUCTION ---
쓰기 지원은 수백만 명의 사람들에게 도움이 되는 자연어 처리(NLP)의 널리 사용되는 응용 프로그램입니다. 문법 오류 수정(Ng 등, 2014년; Bryant 등, 2017년), 의역(Fader 등, 2013년; Lin 등, 2014년) 및 자동 에세이 채점(Song 등, 2020년)과 같은 일반적인 기능 외에도 단어 제안을 제공하는 것은 글쓰기의 전반적인 품질을 향상시키는 데 필요한 기능입니다. 그림 1에서 볼 수 있듯이 첫 번째 문장의 &quot;intimate&quot;라는 단어는 &quot;close&quot;로 바꿔야 합니다. &quot;intimate&quot;는 동료 간의 관계를 설명하는 데 적합하지 않기 때문입니다. 1이 작업은 첫 번째 저자가 Microsoft Research Asia에서 인턴십을 하는 동안 수행되었습니다. 2교신 저자 문장: 그룹 구성원의 긴밀한 협조를 통해 새로운 방법을 개발했습니다. 개선 가능한 대상: 친밀한 대체 제안: 가까운 제안 유형: 정제 사용 이유: 단어 &quot;친밀한&quot;은 친구나 연인을 위한 것이므로 동료 간의 협력은 &quot;가까운&quot;을 사용해야 합니다. 문장: 다른 사람에게서 배우면 다른 사람과 소통하는 것이 더 가능할 것입니다. 개선 가능한 대상: 가능한 대체 제안: 가능성 있는 제안 유형: 정제 사용 이유: 이 문장은 &quot;have chance to&quot;보다는 &quot;more likely&quot;를 표현하고자 하며, &quot;likely&quot;가 더 적절합니다. 문장: 이렇게 하면 주의를 산만하게 할 것입니다. 개선 가능한 대상: 주의 대체 제안: 초점 제안 유형: 다양화 표현 이유: &quot;초점&quot;은 &quot;주의&quot;의 동의어입니다. 그림 1: 스마트 단어 제안(SWS)의 예. 모든 샘플은 여러 개의 개선 가능한 대상으로 주석이 달린 문장으로 구성되어 있으며, 각각은 여러 개의 대체 제안으로 추가 주석이 달렸습니다. 공간을 절약하기 위해 문장을 단순화하고 사례당 하나의 대상과 하나의 제안만 제시합니다. 제안은 3절에서 설명하는 정제-사용법과 다양화-표현법의 두 가지 유형으로 나눌 수 있습니다.이 논문에서는 스마트 단어 제안(SWS)의 작업과 벤치마크를 소개합니다.그림은 SWS의 정의를 보여줍니다.SWS의 목표는 주어진 맥락 내에서 단어나 구문의 형태로 잠재적으로 개선 가능한 대상을 식별하고 모든 개선 가능한 대상에 대한 대체 제안을 제공하는 것입니다.이러한 제안에는 부적절한 단어 사용 수정, 언어 사용이 표준 서면 규칙에 부합하는지 확인, 표현 향상 등이 포함될 수 있습니다.특히 이러한 제안을 정제-사용법과 다양화-표현법의 두 가지 유형으로 분류합니다.어휘 대체(LS)(McCarthy 및 Navigli, 2007; Kremer 등, 2014; Lee 등, 2021)는 입력 문장입니다.그룹 구성원의 긴밀한 협력의 도움으로 새로운 방법을 지적했습니다. 하위 작업 1: 개선 가능한 대상 감지 개선 가능한 대상 그룹 구성원의 긴밀한 협조를 통해 새로운 방법을 발견했습니다.하위 작업 2: 대체 제안 + 대체 제안 지원/도움/가이드/도움 긴밀한 협업 개발 그림 2: 스마트 단어 제안(SWS)의 작업 정의.SWS는 개선 가능한 대상 감지 및 대체 제안이라는 두 가지 하위 작업으로 구성됩니다.문장에는 여러 개선 가능한 대상이 포함되어 있으며 대상에는 여러 대체 제안이 있습니다.해당 분야에서 가장 관련성 있는 연구 벤치마크입니다.LS 시스템은 문장 내에서 주어진 단어의 원래 의미를 유지하는 대체 단어를 제공하는 것을 목표로 합니다.그러나 실제 상황에서는 개선 또는 대체할 수 있는 단어를 인식하는 것이 중요합니다.이러한 대상을 식별하는 것은 실제 사용에 필수적이며 정확한 대체 제안을 하는 데 필요한 단계입니다.실제 시나리오를 재현하기 위해 SWS를 문장을 입력으로 받고 모든 개선 가능한 대상에 대한 대체 제안을 출력으로 제공하는 종단 간 프로세스로 설계합니다. SWS 벤치마크에는 테스트를 위한 인간 레이블 데이터, 학습을 위한 대규모 원격 지도 학습 데이터 세트, 해당 평가 프레임워크가 포함됩니다. 테스트를 위해 영어 학습자의 에세이에서 1,000개의 세그먼트를 수집하고 10명의 주석자에게 개선 가능한 타겟을 식별하고 대체 제안을 제공하도록 요청합니다. 주석자 간의 높은 수준의 동의는 주석의 품질을 확인합니다. 약한 지도 학습의 경우 동의어 사전을 사용하여 코퍼스에서 단어를 무작위로 대체하여 대량의 원격 지도 학습 데이터를 컴파일합니다. 또한 종단 간 평가와 하위 작업 평가에 대한 설정을 제공합니다. 과제를 조사하기 위해 지식 기반 방법, 최첨단 어휘 대체 방법, SWS에 대한 종단 간 접근 방식을 포함한 7가지 기준을 구현했습니다. 실험 결과에 따르면 기존 어휘 대체 방법의 성능은 SWS에 적용하면 상당히 감소합니다. 또한 설계한 종단 간 방법은 타겟 단어나 구문을 식별하고 개선하는 데 어려움을 겪습니다. 결과에 대한 자세한 분석과 논의는 추가 연구를 위한 몇 가지 영역을 제안합니다. 결론적으로, 우리의 기여는 다음과 같습니다. • 쓰기 지원을 위한 SWS 과제를 소개하고, 고품질의 인간 레이블 테스트 데이터와 대규모 원격 감독 학습 데이터를 사용하여 벤치마크를 제공합니다. • SWS에 대한 평가 프레임워크를 개발하고 제공된 기준에 대한 광범위한 평가를 수행합니다. • 분석을 통해 SWS에 대한 추가 연구를 위한 여러 방향을 식별합니다. 2
--- RELATED WORK ---
s 먼저 SWS를 세 가지 관련 작업과 비교하여 작업의 고유한 가치를 강조합니다. 2.1 어휘 대체 어휘 대체(LS)(McCarthy 및 Navigli, 2007; Kremer 등, 2014; Lee 등, 2021)는 문장에서 특정 단어에 대한 대체 단어를 제공하는 작업입니다. SWS와 LS에는 몇 가지 주요 차이점이 있습니다. (1) LS에서는 대상 단어가 이미 제공되지만 SWS에서는 시스템이 먼저 개선 가능한 대상을 감지해야 합니다. (2) LS는 단어와 문장의 의미를 모두 유지하는 동의어를 찾는 데 중점을 둡니다. 반면, SWS는 쓰기 지원 시나리오를 위해 설계되었으므로 대체는 문장의 쓰기를 개선하는 것을 목표로 합니다. LS는 맥락에서 단어 의미의 모호성을 해소하는 데 중점을 두므로 &quot;개선&quot;이 필요하지 않습니다. 다음은 LS07 데이터 세트의 예입니다. 이것은 분명히 유엔 평화 유지에 대한 끔찍하고 부끄러운 오점입니다. 대체 중 하나는 &quot;terrible&quot; &quot;very bad&quot;입니다. 이 대체는 &quot;very bad&quot;를 사용하면 정확도가 떨어지고 쓰기가 나빠지기 때문에 SWS의 요구 사항을 충족하지 못합니다. (3) LS는 대상 단어와 대체에 대해 레마화된 주석을 사용하는 반면, SWS는 문장에서 직접 주석을 추출하고 대체가 문장 내에서 문법적으로 맞아야 모델의 종단 간 성능을 평가할 수 있습니다. 2.2 문법 오류 수정 문법 오류 수정(GEC)(Ng et al., 2014; Bryant et al., 2017)도 SWS와 몇 가지 유사점을 공유합니다. Ng et al.(2014)은 GEC의 수정 중 85% 이상이 단어 수준이며 이러한 수정이 사용자의 쓰기도 개선한다고 지적했습니다. 그러나 SWS가 제공하는 대체 제안에는 문법 오류를 수정하기 위한 제안이 포함되어 있지 않습니다. 대신 SWS는 단어나 구문 사용을 식별하고 개선하는 데 중점을 둡니다. SWS 테스트 세트의 소스 문장은 먼저 GEC 모델(Ge et al., 2018)에 의해 처리된 다음 인간 주석자가 추가로 확인하여 입력에 문법 오류가 없는지 확인합니다. 쓰기 도우미에서 SWS는 GEC 다음의 단계입니다. 2.3 의역 생성 의역 생성(PG)(Fader et al., 2013; Lin et al., 2014)은 주어진 문장의 의미적 의미를 보존하면서 해당 문장의 형식이나 구조를 변경하는 것을 목표로 합니다. PG는 데이터 증강(Iyyer et al., 2018), 쿼리 재작성(Dong et al., 2017), 중복 질문 감지(Shah et al., 2018)와 같은 다양한 잠재적 응용 분야가 있습니다. PG는 두 가지 주요 측면에서 SWS와 다릅니다. (1) SWS는 부적절한 단어 사용을 식별하고 수정하거나 다양한 표현 옵션을 제공하여 글쓰기 개선에 더 큰 중점을 둡니다. (2) SWS는 단어나 구문의 대체 제안에 초점을 맞추고 평가는 단어 수준을 기반으로 합니다. 반면에 PG는 문장 수준에서 성과를 직접 측정합니다. 3 데이터 수집 이 작업은 글쓰기 지원 시나리오를 정확하게 나타내는 Smart Word Suggestion 벤치마크를 구성하는 것입니다. 평가를 위해 영어 학습자의 문장을 수집하고 McCarthy와 Navigli(2007) 및 Kremer et al.(2014)에 따라 인간이 주석을 달았습니다. 훈련을 위해 Wikipedia에서 대규모 원격 감독 데이터 세트를 컴파일했습니다(Erxleben et al., 2014; Vrandečić and Krötzsch, 2014). 3.1 인간 주석 데이터 수집 인간 주석 데이터는 3단계 프로세스를 통해 수집됩니다. (1) 영어 학습자의 에세이에서 코퍼스 데이터 정리, (2) 개선 가능한 대상 및 해당 대체 제안에 레이블 지정, (3) 주석 병합 및 신뢰도가 낮은 주석 필터링. 1단계: 코퍼스 정리. 온라인 쓰기 지원 플랫폼 1을 통해 학부 영어 학습자가 쓴 에세이를 수집합니다. 이를 개별 문장으로 나눕니다. 주석자가 SWS를 넘어서는 수정을 하지 않도록 다음 작업으로 문장을 다듬습니다. (1) 의미가 불분명한 문장 제거. (2) 문법 오류 수정을 위해 수정 모델(Ge et al., 2018) 적용. (3) 인간 검토자에게 남아 있는 문법 오류가 있는지 다시 확인 요청. 또한 짧은 문장은 충분한 맥락을 제공하지 못하거나 개선할 만큼 충분한 단어가 포함되지 않을 수 있으므로 필터링합니다. 모든 문장을 철저히 검토하여 개인을 식별하거나 불쾌한 내용이 포함되지 않았는지 확인했습니다. 2단계: 인간 주석. 언어학을 전공하는 영어 원어민 학부생 10명을 주석자로 모집하여 각 문장에 독립적으로 주석을 달았습니다. 주석 품질을 보장하기 위해 모든 주석자는 주석에 참여하기 전에 테스트 과제를 통과해야 했습니다. 주석자는 세 단계로 주석을 달았습니다. (1) 문장에서 개선할 수 있는 단어나 구문 식별, (2) 식별된 각 대상에 대한 하나 이상의 제안 제공, (3) 대체 후 개선 유형 할당. 구체적으로 대체 제안을 두 가지 유형으로 정의합니다. (1) 정제된 사용은 모호한 의미를 갖거나 모국어가 아닌 표현이거나 영어를 잘못 사용하는 경우와 같이 특정 단어나 구문을 현재 맥락에서 사용하는 것이 부적절한 경우를 말합니다. 예를 들어, 그림 1에 표시된 두 번째 문장에서 &quot;가능성 있음&quot;이라는 단어는 &quot;가능성이 있음&quot;을 전달하기 위한 것이며 문장의 맥락에서 적절하지 않습니다. 주석자는 &quot;가능성 있음&quot;을 &quot;가능성이 있음&quot;으로 대체했습니다. 이러한 제안은 영어 학습자가 특정 맥락에서 단어 사용의 차이점을 이해하고 원어민과 더 일관된 방식으로 글을 쓸 수 있도록 돕기 위해 고안되었습니다. (2) Diversify-expression은 이 단어나 구문을 다른 단어나 구문으로 대체할 수 있는 경우를 말합니다. 이러한 &#39;https://aimwriting.mtutor.engkoo.com/ 제안은 사용자가 더 다양한 범위의 표현을 사용할 수 있도록 돕는 것을 목표로 합니다. 그림 1의 마지막 사례는 해당 예입니다. 주석자는 각 문장에 대해 최소 3개의 제안을 제공해야 했습니다. 1000개의 문장으로 구성된 전체 데이터 세트에 대해 각 주석자는 최소 1500개의 refine-usage 유형 제안을 제공해야 했습니다. 자세한 주석 지침은 부록 A에 있습니다. 3단계: 병합 및 필터링. 이전의 어휘 대체 작업(McCarthy 및 Navigli, 2007; Kremer et al., 2014)은 모든 주석자의 결과를 키-값 사전으로 병합했습니다. 여기서 값은 이 대체 제안을 제공한 주석자의 수를 나타냅니다. 우리는 비슷한 방식으로 10명의 주석자의 레이블링 결과를 병합했습니다. 두 주석자의 주석을 병합하는 것을 예로 들어보겠습니다. 하나는 {happy: glad/merry, likely}이고 다른 하나는 {help: possible: aid, possible: likely/probable}입니다. 병합 후의 결과는 다음과 같습니다. {happy: {glad: 1, merry: 1}, 동일한 품사의 동의어가 하나인 able 대상. 동의어 사전을 사용한 무작위 대체는 원래 텍스트보다 더 부적절한 단어나 구문 사용을 초래할 수 있습니다. 따라서 생성된 대체를 개선 가능한 대상으로, 원래 대상을 대체 제안으로 취급합니다. 인간이 주석을 단 데이터 세트와 달리, 원격 지도 학습 데이터 세트는 개선 가능한 각 대상에 대해 하나의 제안만 포함하고 제안 유형의 주석이 없습니다. 원격 지도 학습 데이터 세트를 생성하는 코드는 추가 연구를 위해 공개될 예정입니다. 3.3 데이터 통계 벤치마크 # 문장 # 대상 # 제안 # 레이블 SemEvalCOINCO15,112,12,167,SWORDS71,395,SWSSWSDS3,746,142 12,786,16,031 30,12,786,685 12,786,possible: {likely: 2, probable: 1}, help: {aid: 1}} 여기서 happy, possible, help는 개선 가능한 대상이고, 하위 수준 사전은 병합 후의 대체 제안입니다. 또한 대부분의 유형 라벨링을 취하여 각 개선 가능한 대상에 대한 refine-usage 또는 diversify-expression의 유형을 수집합니다. 주석자 간의 주관적 편견을 줄이기 위해 한 주석자에 의해서만 주석이 달린 모든 개선 가능한 대상을 버렸습니다. 마지막으로 데이터 세트를 200개 문장의 검증 세트와 800개 문장의 테스트 세트로 분할했습니다. 3.2 원격 지도 학습 데이터 수집 동의어 사전을 사용하여 코퍼스의 단어를 무작위로 대체하여 약한 지도 학습을 위한 대량의 원격 지도 학습 데이터를 수집합니다. 소스 코퍼스에는 Wikipedia²에서 가져온 370만 개의 문장이 포함되어 있습니다. 우리가 사용하는 동의어 사전은 PPDB(Pavlick et al., 2015)와 Merriam-Webster 동의어 사전³의 교집합입니다. 문장은 3단계로 처리됩니다. (1) 동의어 사전의 모든 단어나 구를 선택하여 개선 가능한 대상으로 처리합니다. (2) 태거를 사용하여 개선 가능한 대상의 품사를 찾습니다. (3) 개선 가능한 대상을 무작위로 대체합니다.2https://dumps.wikimedia.org/enwiki/20220720/ https://www.merriam-webster.com/thesaurus 표 1: SWS 및 LS 데이터 세트의 통계. SWSDS는 원격 감독 데이터 세트를 의미합니다. 표 1은 SWS와 어휘 대체 벤치마크를 비교한 것입니다. SWS 데이터 세트는 개선 가능한 대상의 7027개 인스턴스와 1000개 문장의 16031개 제안으로 구성되어 있습니다. 이 데이터 세트의 문장의 평균 길이는 27개 단어입니다. 이 데이터 세트의 개선 가능한 대상에는 명사 2601개, 동사 2186개, 형용사 1263개, 부사 367개, 구문 267개, 기타 품사 343개가 포함됩니다. 3.8%의 타겟과 3.3%의 제안이 여러 단어로 구성된 구문입니다. 63.0%의 타겟이 refine-usage 유형입니다. 표 2는 다른 품사를 가진 refine-usage 또는 diversify-expression 타겟의 비율을 보여줍니다. 품사 명사 동사 형용사 부사 구문 기타 총 개수 2601 2186 1263 367 267 343RU (%) 57.8 63.7 66.7 64.9 70.8 76.36.DE (%) 42.33.3 35.1 29.2 23. 표 2: 다른 품사를 가진 타겟의 통계. RU는 refine-usage 타겟의 비율을 나타내고 DE는 diversifyexpression의 비율을 나타냅니다. 원격 감독 데이터 세트 SWSDs에는 370만 개의 문장에서 1,270만 개 이상의 제안이 포함되어 있습니다. 2.67%는 여러 단어로 구성된 구이고, 제안의 0.3%는 여러 단어입니다.3.4 내부 주석자 일치 어휘 대체에 대한 이전 연구(McCarthy 및 Navigli, 2007; Kremer 등, 2014)는 주석자 간 일치(IAA)를 통해 데이터 집합의 품질을 평가했습니다.저희는 이 접근 방식을 채택하고 쌍별 주석자 간 일치(PA)를 계산하여 데이터 집합의 품질을 평가합니다.PA det는 개선 가능한 타겟을 식별하는 일관성을 측정합니다.PA det det = PA ij|P| det Σ PAd(i,j)EP N 18ns k=NIs Us 여기서 P는 주석자 쌍의 집합입니다.주석자가 10명이므로 |P| = C₁ = 45입니다.N은 모든 문장의 수이고, s½, 5%는 주석자 i와 j가 각각 식별한 문장 k의 개선 가능한 타겟 집합입니다. PA sug는 동일한 개선 가능한 대상의 대체 제안의 일관성을 측정합니다.PA sug PAS sug ij =|P| Σ ΡΑ (i,j)EP sug Mij 1 |țin ti₁ || Σ 1=Mij ti Ut 여기서 Mij는 주석자 i와 j가 식별한 개선 가능한 대상 세트의 교집합의 크기입니다.ti, t₁는 각각 주석자 i와 j가 제공한 대상 1에 대한 제안입니다.det SWS 벤치마크에서 PAd와 PA sug는 각각 23.2%와 35.4%입니다.PA sug는 이전 LS 데이터 세트인 SemEval(McCarthy 및 Navigli, 2007)의 27.7%와 COINCO(Kremer et al., 2014)의 19.3%에 비해 상당히 높아서 주석 품질을 확인했습니다. 3.5 원격 감독 데이터 세트의 데이터 품질 통계에 따르면 테스트 세트의 대체 중 71.8%가 훈련 세트에 나타나고 테스트 세트의 각 대체는 평균적으로 훈련 세트에 10.4회 나타납니다. 이러한 데이터는 훈련 세트의 대체가 테스트 세트의 대부분 대체를 포괄한다는 것을 보여주며, 이는 합성
--- METHOD ---
. 개선 가능한 대상: 친밀한 대체 제안: 가까운 제안 유형: 정제 사용 이유: 단어 &quot;친밀한&quot;은 친구나 연인을 위한 것이므로 동료 간의 협력은 &quot;가까운&quot;을 사용해야 합니다. 문장: 다른 사람에게서 배우면 다른 사람과 소통하는 것이 더 가능할 것입니다. 개선 가능한 대상: 가능한 대체 제안: 가능성 있는 제안 유형: 정제 사용 이유: 이 문장은 &quot;have chance to&quot;보다는 &quot;more likely&quot;를 표현하고자 하며, &quot;likely&quot;가 더 적절합니다. 문장: 이렇게 하면 주의를 산만하게 할 것입니다. 개선 가능한 대상: 주의 대체 제안: 초점 제안 유형: 다양화 표현 이유: &quot;초점&quot;은 &quot;주의&quot;의 동의어입니다. 그림 1: 스마트 단어 제안(SWS)의 예. 모든 샘플은 여러 개의 개선 가능한 대상으로 주석이 달린 문장으로 구성되어 있으며, 각각은 여러 개의 대체 제안으로 추가 주석이 달렸습니다. 공간을 절약하기 위해 문장을 단순화하고 사례당 하나의 대상과 하나의 제안만 제시합니다. 제안은 3절에서 설명하는 정제-사용법과 다양화-표현법의 두 가지 유형으로 나눌 수 있습니다.이 논문에서는 스마트 단어 제안(SWS)의 작업과 벤치마크를 소개합니다.그림은 SWS의 정의를 보여줍니다.SWS의 목표는 주어진 맥락 내에서 단어나 구문의 형태로 잠재적으로 개선 가능한 대상을 식별하고 모든 개선 가능한 대상에 대한 대체 제안을 제공하는 것입니다.이러한 제안에는 부적절한 단어 사용 수정, 언어 사용이 표준 서면 규칙에 부합하는지 확인, 표현 향상 등이 포함될 수 있습니다.특히 이러한 제안을 정제-사용법과 다양화-표현법의 두 가지 유형으로 분류합니다.어휘 대체(LS)(McCarthy 및 Navigli, 2007; Kremer 등, 2014; Lee 등, 2021)는 입력 문장입니다.그룹 구성원의 긴밀한 협력의 도움으로 새로운 방법을 지적했습니다. 하위 작업 1: 개선 가능한 대상 감지 개선 가능한 대상 그룹 구성원의 긴밀한 협조를 통해 새로운 방법을 발견했습니다.하위 작업 2: 대체 제안 + 대체 제안 지원/도움/가이드/도움 긴밀한 협업 개발 그림 2: 스마트 단어 제안(SWS)의 작업 정의.SWS는 개선 가능한 대상 감지 및 대체 제안이라는 두 가지 하위 작업으로 구성됩니다.문장에는 여러 개선 가능한 대상이 포함되어 있으며 대상에는 여러 대체 제안이 있습니다.해당 분야에서 가장 관련성 있는 연구 벤치마크입니다.LS 시스템은 문장 내에서 주어진 단어의 원래 의미를 유지하는 대체 단어를 제공하는 것을 목표로 합니다.그러나 실제 상황에서는 개선 또는 대체할 수 있는 단어를 인식하는 것이 중요합니다.이러한 대상을 식별하는 것은 실제 사용에 필수적이며 정확한 대체 제안을 하는 데 필요한 단계입니다.실제 시나리오를 재현하기 위해 SWS를 문장을 입력으로 받고 모든 개선 가능한 대상에 대한 대체 제안을 출력으로 제공하는 종단 간 프로세스로 설계합니다. SWS 벤치마크에는 테스트를 위한 인간 레이블 데이터, 학습을 위한 대규모 원격 지도 데이터 세트, 평가를 위한 해당 프레임워크가 포함됩니다. 테스트를 위해 영어 학습자의 에세이에서 1,000개의 세그먼트를 수집하고 10명의 주석자에게 개선 가능한 대상을 식별하고 대체 제안을 제공하도록 요청합니다. 주석자 간의 높은 수준의 동의는 주석의 품질을 확인합니다. 약한 지도 학습의 경우 동의어 사전을 사용하여 코퍼스에서 단어를 무작위로 대체하여 대량의 원격 지도 데이터를 컴파일합니다. 또한 종단 간 평가와 하위 작업 평가에 대한 설정을 제공합니다. 과제를 조사하기 위해 지식 기반 방법, 최첨단 어휘 대체 방법, SWS에 대한 종단 간 접근 방식을 포함한 7가지 기준을 구현했습니다.
--- EXPERIMENT ---
7개의 기준선을 가진 s는 SWS가 어려운 작업임을 보여줍니다. 실험 분석을 바탕으로 SWS에 대한 향후 연구를 위한 잠재적 방향을 제안합니다. 데이터 세트와 관련 코드는 https://github.com/microsoft/SmartWordSuggestions에서 사용할 수 있습니다. 1 서론 쓰기 지원은 수백만 명의 사람들에게 도움이 되는 널리 사용되는 자연어 처리(NLP) 응용 프로그램입니다. 문법 오류 수정(Ng 등, 2014년; Bryant 등, 2017년), 의역(Fader 등, 2013년; Lin 등, 2014년) 및 자동 에세이 채점(Song 등, 2020년)과 같은 일반적인 기능 외에도 단어 제안을 제공하는 것은 글쓰기의 전반적인 품질을 향상시키는 데 필요한 기능입니다. 그림 1에서 볼 수 있듯이 첫 번째 문장의 &quot;intimate&quot;라는 단어는 &quot;close&quot;로 바꿔야 합니다. &quot;intimate&quot;는 동료 간의 관계를 설명하는 데 적합하지 않기 때문입니다. 1이 연구는 제1저자가 Microsoft Research Asia에서 인턴으로 근무하는 동안 수행되었습니다.2교신 저자 문장: 그룹 구성원들의 긴밀한 협조 덕분에 새로운 방법을 개발했습니다.개선 가능한 목표: 친밀한 대체 제안: 가까운 제안 유형: 정제 사용 이유: 단어 &quot;친밀한&quot;은 친구나 연인에게 쓰는 단어로, 동료 간의 협조는 &quot;가까운&quot;을 사용해야 합니다.문장: 다른 사람에게서 배우면 다른 사람과 소통하기가 더 쉬울 것입니다.개선 가능한 목표: 가능한 대체 제안: 가능성 있는 제안 유형: 정제 사용 이유: 이 문장은 &quot;할 기회가 있다&quot;보다는 &quot;가능성이 더 높다&quot;를 표현하고 싶어 하며, &quot;가능성이 있는&quot;이 더 적절합니다.문장: 이렇게 하면 주의를 산만하게 할 수 있습니다.개선 가능한 목표: 주의 대체 제안: 초점 제안 유형: 다양화 표현 이유: &quot;초점&quot;은 &quot;주의&quot;의 동의어입니다.그림 1: 스마트 단어 제안(SWS)의 예. 모든 샘플은 여러 개선 가능한 타겟으로 주석이 달린 문장으로 구성되어 있으며, 각 타겟에는 여러 대체 제안이 추가로 주석으로 달렸습니다. 공간을 절약하기 위해 문장을 단순화하고 사례당 하나의 타겟과 하나의 제안만 제시합니다. 제안은 3절에서 설명하는 정제-사용 및 다양화-표현의 두 가지 유형으로 나눌 수 있습니다. 이 논문에서는 Smart Word Suggestion(SWS)의 작업과 벤치마크를 소개합니다. 그림은 SWS의 정의를 보여줍니다. SWS의 목표는 주어진 맥락 내에서 단어나 구문의 형태로 잠재적으로 개선 가능한 타겟을 식별하고 모든 개선 가능한 타겟에 대한 대체 제안을 제공하는 것입니다. 이러한 제안에는 부적절한 단어 사용 수정, 언어 사용이 표준 서면 규칙을 준수하도록 보장, 표현 향상 등이 포함될 수 있습니다. 구체적으로 이러한 제안을 정제-사용 및 다양화-표현의 두 가지 유형으로 분류합니다. 어휘 대체(LS)(McCarthy 및 Navigli, 2007; Kremer 등, 2014; Lee 등, 2021)는 입력 문장입니다. 그룹 구성원의 긴밀한 협조의 도움으로 새로운 방법을 지적했습니다. 하위 작업 1: 개선 가능한 대상 감지 개선 가능한 대상 그룹 구성원의 긴밀한 협조의 도움으로 새로운 방법을 지적했습니다. 하위 작업 2: 대체 제안 + 대체 제안 지원/도움/가이드/도움 긴밀한 협업 개발 그림 2: 스마트 단어 제안(SWS)의 작업 정의. SWS는 개선 가능한 대상 감지와 대체 제안이라는 두 가지 하위 작업으로 구성됩니다. 문장에는 여러 개선 가능한 대상이 포함되어 있으며 대상에는 여러 대체 제안이 있습니다. 이 분야에서 가장 관련성 있는 연구 벤치마크입니다. LS 시스템은 문장 내에서 주어진 단어의 원래 의미를 유지하는 대체 단어를 제공하는 것을 목표로 합니다. 그러나 실제 상황에서는 개선 또는 대체할 수 있는 단어를 인식하는 것이 중요합니다. 이러한 타겟을 식별하는 것은 실제 사용에 필수적이며 정확한 대체 제안을 하는 데 필요한 단계입니다. 실제 시나리오를 재현하기 위해 SWS를 입력으로 문장을 받고 모든 개선 가능한 타겟에 대한 대체 제안을 출력으로 제공하는 종단 간 프로세스로 설계합니다. SWS 벤치마크에는 테스트를 위한 인간 레이블 데이터, 교육을 위한 대규모 원격 감독 데이터 세트 및 해당 평가 프레임워크가 포함됩니다. 테스트를 위해 영어 학습자의 에세이에서 1,000개의 세그먼트를 수집하고 10명의 주석자에게 개선 가능한 타겟을 식별하고 대체 제안을 제공하도록 요청합니다. 주석자 간의 높은 수준의 동의는 주석의 품질을 확인합니다. 약하게 감독되는 교육의 경우 동의어 사전을 사용하여 코퍼스에서 단어를 무작위로 대체하여 대량의 원격 감독 데이터를 컴파일합니다. 또한 종단 간 평가와 하위 작업 평가에 대한 설정을 제공합니다. 과제를 조사하기 위해 지식 기반 방법, 최첨단 어휘 대체 방법, SWS에 대한 종단 간 접근 방식을 포함한 7가지 기준을 구현했습니다. 실험 결과에 따르면 기존 어휘 대체 방법의 성능은 SWS에 적용하면 상당히 떨어집니다. 또한, 우리가 설계한 종단 간 방법은 대상 단어나 구문을 식별하고 개선하는 데 어려움을 겪습니다. 결과에 대한 자세한 분석과 논의는 추가 연구가 필요한 여러 영역을 시사합니다. 결론적으로, 우리의 기여는 다음과 같습니다. • 쓰기 지원을 위한 SWS 작업을 소개하고, 고품질 인간이 레이블을 지정한 테스트 데이터와 대규모 원격 감독 학습 데이터가 있는 벤치마크를 제공합니다. • SWS에 대한 평가 프레임워크를 개발하고 제공된 기준에 대한 광범위한 평가를 수행합니다. • 분석을 통해 SWS에 대한 추가 연구를 위한 여러 방향을 식별합니다. 2 관련 연구 먼저 SWS를 세 가지 관련 작업과 비교하여 작업의 고유한 가치를 강조합니다. 2.1 어휘 대체 어휘 대체(LS)(McCarthy 및 Navigli, 2007; Kremer 등, 2014; Lee 등, 2021)는 문장에서 특정 단어에 대한 대체 단어를 제공하는 작업입니다. SWS와 LS에는 몇 가지 주요 차이점이 있습니다. (1) LS에서는 대상 단어가 이미 제공되지만 SWS에서는 시스템이 먼저 개선 가능한 대상을 감지해야 합니다. (2) LS는 단어와 문장의 의미를 모두 유지하는 동의어를 찾는 데 중점을 둡니다. 반면 SWS는 쓰기 지원 시나리오를 위해 설계되었으므로 대체는 문장의 쓰기를 개선하는 것을 목표로 합니다. LS는 맥락에서 단어 의미의 모호성을 해소하는 데 중점을 두므로 &quot;개선&quot;이 필요하지 않습니다. 다음은 LS07 데이터 세트의 예입니다. 이것은 분명히 유엔 평화 유지에 대한 끔찍하고 부끄러운 오점입니다. 대체 중 하나는 &quot;끔찍하다&quot; &quot;매우 나쁘다&quot;입니다. 이 대체는 &quot;매우 나쁘다&quot;를 사용하면 정확도가 떨어지고 쓰기를 악화시키기 때문에 SWS의 요구 사항을 충족하지 못합니다.(3) LS는 대상 단어와 대체에 대해 레마화된 주석을 사용하는 반면, SWS는 문장에서 직접 주석을 추출하고 대체가 문장 내에서 문법적으로 들어맞아 모델의 종단 간 성능을 평가해야 합니다.2.2 문법 오류 수정 문법 오류 수정(GEC)(Ng et al., 2014; Bryant et al., 2017)도 SWS와 몇 가지 유사점을 공유합니다.Ng et al.(2014)은 GEC의 수정의 85% 이상이 단어 수준이며 이러한 수정이 사용자의 쓰기도 개선한다고 지적했습니다.그러나 SWS가 제공하는 대체 제안에는 문법 오류를 수정하기 위한 제안이 포함되어 있지 않습니다.대신 SWS는 단어나 구문 사용을 식별하고 개선하는 데 중점을 둡니다. SWS 테스트 세트의 소스 문장은 먼저 GEC 모델(Ge et al., 2018)에 의해 처리된 다음, 입력에 문법적 오류가 없는지 확인하기 위해 인간 주석자에 의해 추가로 검토된다는 점에 주목할 가치가 있습니다.쓰기 도우미에서 SWS는 GEC에 이은 다음 단계입니다.2.3 의역 생성 의역 생성(PG)(Fader et al., 2013; Lin et al., 2014)은 주어진 문장의 의미적 의미를 보존하면서 해당 문장의 형식이나 구조를 변경하는 것을 목표로 합니다.PG에는 데이터 증강(Iyyer et al., 2018), 쿼리 재작성(Dong et al., 2017), 중복 질문 감지(Shah et al., 2018)와 같은 다양한 잠재적 응용 분야가 있습니다.PG는 두 가지 주요 측면에서 SWS와 다릅니다.(1) SWS는 부적절한 단어 사용을 식별하고 수정하거나 다양한 표현 옵션을 제공하여 글쓰기를 개선하는 데 더 큰 중점을 둡니다. (2) SWS는 단어나 구문의 대체 제안에 초점을 맞추고, 평가는 단어 수준을 기반으로 합니다. 반면, PG는 문장 수준에서 성과를 직접 측정합니다. 3 데이터 수집 이 작업은 쓰기 지원 시나리오를 정확하게 나타내는 Smart Word Suggestion 벤치마크를 구성하는 것입니다. 평가를 위해 영어 학습자의 문장을 수집하고 McCarthy와 Navigli(2007) 및 Kremer et al.(2014)에 따라 인간 주석을 사용합니다. 훈련을 위해 Wikipedia에서 대규모 원격 감독 데이터 세트를 컴파일합니다(Erxleben et al., 2014; Vrandečić and Krötzsch, 2014). 3.1 인간 주석 데이터 수집 인간 주석 데이터는 3단계 프로세스를 통해 수집됩니다. (1) 영어 학습자의 에세이에서 코퍼스 데이터 정리, (2) 개선 가능한 대상과 해당 대체 제안에 레이블 지정, (3) 주석 병합 및 신뢰도가 낮은 주석 필터링. 1단계: 코퍼스 정리. 온라인 쓰기 지원 플랫폼 1을 통해 학부 영어 학습자가 쓴 에세이를 수집합니다. 개별 문장으로 나눕니다. 주석자가 SWS를 넘어서 수정하는 것을 방지하기 위해 문장은 다음과 같은 작업으로 정제됩니다. (1) 의미가 불분명한 문장을 제거합니다. (2) 문법 오류를 수정하기 위해 수정 모델(Ge et al., 2018)을 적용합니다. (3) 인간 검토자에게 남아 있는 문법 오류를 다시 확인하도록 요청합니다. 또한 짧은 문장은 맥락을 충분히 제공하지 못하거나 개선할 만큼 충분한 단어가 포함되지 않을 수 있으므로 걸러냅니다. 모든 문장을 철저히 검토하여 개인을 식별할 수 있는 정보나 공격적인 내용이 포함되지 않았는지 확인했습니다. 2단계: 인간 주석. 언어학을 전공하는 영어 원어민 학부생 10명을 주석자로 모집하여 각 문장에 독립적으로 주석을 달았습니다. 주석 품질을 보장하기 위해 모든 주석자는 주석에 참여하기 전에 테스트 과제를 통과해야 했습니다. 주석자들은 세 단계로 주석을 달았습니다. (1) 문장에서 개선할 수 있는 단어나 구문 식별, (2) 식별된 각 대상에 대한 하나 이상의 제안 제공, (3) 대체 후 개선 유형 할당. 구체적으로 대체 제안을 두 가지 유형으로 정의합니다. (1) 정제 사용은 모호한 의미를 갖거나, 모국어가 아닌 표현이거나, 영어를 잘못 사용한 경우와 같이 특정 단어나 구문을 현재 맥락에서 사용하는 것이 부적절한 경우를 말합니다. 예를 들어, 그림 1에 표시된 두 번째 문장에서 &quot;가능성 있음&quot;이라는 단어는 &quot;가능성이 있음&quot;이라는 의미를 전달하기 위한 것이며 문장의 맥락에서 적절하지 않습니다. 주석자들은 &quot;가능성 있음&quot;을 &quot;가능성 있음&quot;으로 대체했습니다. 이러한 제안은 영어 학습자가 특정 맥락에서 단어 사용의 차이점을 이해하고 원어민과 더 일관된 방식으로 글을 쓸 수 있도록 돕기 위해 고안되었습니다. (2) Diversify-expression은 이 단어나 구문이 다른 단어나 구문으로 대체될 수 있는 경우를 말합니다. 이러한 &#39;https://aimwriting.mtutor.engkoo.com/ 제안은 사용자가 더 다양한 범위의 표현을 사용할 수 있도록 돕는 것을 목표로 합니다. 그림 1의 마지막 사례는 해당 예입니다. 주석자는 각 문장에 대해 최소 3개의 제안을 제공해야 했습니다. 1000개의 문장으로 구성된 전체 데이터 세트에 대해 각 주석자는 최소 1500개의 refine-usage 유형 제안을 제공해야 했습니다. 자세한 주석 지침은 부록 A에 있습니다. 3단계: 병합 및 필터링. 이전의 어휘 대체 작업(McCarthy 및 Navigli, 2007; Kremer et al., 2014)은 모든 주석자의 결과를 키-값 사전에 병합했는데, 여기서 값은 이 대체 제안을 제공한 주석자의 수를 나타냅니다. 우리는 비슷한 방식으로 10명의 주석자의 레이블링 결과를 병합했습니다. 두 주석자의 주석을 병합하는 것을 예로 들어보겠습니다. 하나는 {happy: glad/merry, likely}이고 다른 하나는 {help: possible: aid, possible: likely/probable}입니다. 병합 후의 결과는 다음과 같습니다. {happy: {glad: 1, merry: 1}, 동일한 품사의 동의어가 하나인 able 대상. 동의어 사전을 이용한 무작위 대체는 원래 텍스트보다 더 부적절한 단어나 구문 사용을 초래할 수 있습니다. 따라서 생성된 대체를 개선 가능한 대상으로, 원래 대상을 대체 제안으로 취급합니다. 인간이 주석을 단 데이터 세트와 달리, 원격 감독 데이터 세트는 개선 가능한 대상마다 하나의 제안만 포함하고 제안 유형의 주석이 없습니다. 원격 감독 데이터 세트를 생성하는 코드는 추가 연구를 위해 공개될 예정입니다. 3.3 데이터 통계 벤치마크 # 문장 # 대상 # 제안 # 레이블 SemEvalCOINCO15,112,12,167,SWORDS71,395,SWSSWSDS3,746,142 12,786,16,031 30,12,786,685 12,786,possible: {likely: 2, probable: 1}, help: {aid: 1}} 여기서 happy, possible, help는 개선 가능한 대상이고, 하위 수준 사전은 병합 후 대체 제안입니다. 또한 대부분의 유형 레이블을 사용하여 각 개선 가능한 대상에 대한 refine-usage 또는 diversify-expression의 유형을 수집합니다. 주석자 간의 주관적 편견을 줄이기 위해 한 주석자에 의해서만 주석이 달린 모든 개선 가능한 대상을 버렸습니다. 마지막으로, 데이터 세트는 200개 문장의 검증 세트와 800개 문장의 테스트 세트로 분할되었습니다.3.2 원격 지도 학습 데이터 수집 우리는 동의어 동의어 사전을 사용하여 코퍼스에서 단어를 무작위로 대체하여 약한 지도 학습을 위한 대량의 원격 지도 학습 데이터를 수집합니다.소스 코퍼스에는 Wikipedia²에서 가져온 370만 개의 문장이 포함되어 있습니다.우리가 사용하는 동의어 동의어 사전은 PPDB(Pavlick et al., 2015)와 Merriam-Webster 동의어 사전³의 교집합입니다.문장은 3단계로 처리됩니다.(1) 동의어 동의어 사전에서 모든 단어나 구를 선택하여 개선 가능한 대상으로 처리합니다.(2) 태거를 사용하여 개선 가능한 대상의 품사를 찾습니다. (3) improv2를 무작위로 대체하기 https://dumps.wikimedia.org/enwiki/20220720/ https://www.merriam-webster.com/thesaurus 표 1: SWS 및 LS 데이터 세트의 통계. SWSDS는 원격 감독 데이터 세트를 의미합니다. 표 1은 SWS와 어휘 대체 벤치마크를 비교한 것입니다. SWS 데이터 세트는 1000개 문장에서 개선 가능한 타겟 7027개와 제안 16031개로 구성되어 있습니다. 이 데이터 세트의 문장 평균 길이는 27개 단어입니다. 이 데이터 세트의 개선 가능한 타겟에는 명사 2601개, 동사 2186개, 형용사 1263개, 부사 367개, 구문 267개, 기타 품사 343개가 포함됩니다. 타겟의 3.8%와 제안의 3.3%는 여러 단어 구문입니다. 63.0%의 타겟이 refine-usage 유형입니다.표 2는 다른 품사를 가진 refine-usage 또는 diversify-expression 타겟의 비율을 보여줍니다.품사 명사 동사 형용사 부사구 기타 총 개수 2601 2186 1263 367 267 343RU (%) 57.8 63.7 66.7 64.9 70.8 76.36.DE (%) 42.33.3 35.1 29.2 23.표 2: 다른 품사를 가진 타겟의 통계.RU는 refine-usage 타겟의 비율을 나타내고 DE는 diversifyexpression의 비율을 나타냅니다.원격 감독 데이터 세트 SWSDs에는 370만 개의 문장에서 1,270만 개 이상의 제안이 포함되어 있습니다.2.67%는 여러 단어로 구성된 구이고 제안의 0.3%는 여러 단어입니다. 3.4 내부 주석자 일치 어휘 대체에 대한 이전 연구(McCarthy 및 Navigli, 2007; Kremer et al., 2014)는 주석자 간 일치(IAA)를 통해 데이터 집합의 품질을 평가했습니다.본 연구에서는 이 접근 방식을 채택하고 쌍별 주석자 간 일치(PA)를 계산하여 데이터 집합의 품질을 평가합니다.PA det는 개선 가능한 타겟을 식별하는 일관성을 측정합니다.PA det det = PA ij|P| det Σ PAd(i,j)EP N 18ns k=NIs Us 여기서 P는 주석자 쌍의 집합입니다.주석자가 10명이므로 |P| = C₁ = 45입니다.N은 모든 문장의 수이고 s½, 5%는 주석자 i와 j가 각각 식별한 문장 k의 개선 가능한 타겟 집합입니다.PA sug는 동일한 개선 가능한 타겟에 대한 대체 제안의 일관성을 측정합니다.PA sug PAS sug ij =|P| Σ ΡΑ (i,j)EP sug Mij 1 |țin ti₁ || Σ 1=Mij ti Ut 여기서 Mij는 주석자 i와 j가 식별한 개선 가능한 대상 세트의 교집합의 크기입니다. ti, t₁는 각각 주석자 i와 j가 제공한 대상 1에 대한 제안입니다. det SWS 벤치마크에서 PAd와 PA sug는 각각 23.2%와 35.4%입니다. 당사의 PA sug는 이전 LS 데이터 세트인 SemEval(McCarthy 및 Navigli, 2007)의 27.7%와 COINCO(Kremer et al., 2014)의 19.3%에 비해 상당히 높아서 주석 품질을 확인했습니다. 3.5 원격 감독 데이터 세트의 데이터 품질 통계에 따르면 테스트 세트의 치환 중 71.8%가 훈련 세트에 나타나고 테스트 세트의 각 치환은 평균적으로 훈련 세트에 10.4회 나타납니다. 이러한 데이터는 훈련 세트의 치환이 테스트 세트의 대부분 치환을 포괄한다는 것을 보여주며, 이는 합성 방법이 실제 시나리오에 가깝다는 것을 검증합니다. 4 평가 이 섹션에서는 엔드투엔드 평가와 하위 작업 평가를 포함하여 SWS의 평가 설정과 메트릭을 소개합니다. 엔드투엔드 평가 및 개선 가능한 타겟 감지 하위 작업의 경우 정밀도, 재현율 및 F0.5를 메트릭으로 소개합니다. 치환 제안 하위 작업의 경우 정확도를 활용하여 예측된 치환의 품질을 평가합니다. 메트릭을 계산하는 예는 부록 B에서 찾을 수 있습니다. 4. 엔드투엔드 평가 엔드투엔드 평가는 각 치환 제안을 기반으로 계산됩니다. 참된 예측은 탐지된 개선 가능한 대상이 주석이 달린 개선 가능한 대상 세트에 존재하고 제안된 대체가 대상의 주석이 달린 대체에 존재하는 경우에만 계산됩니다. N Mk Tpe2 = 1 if Skl Є Sk elsek=1 l=여기서 N은 모든 문장의 개수이고, Mk는 문장 k에 있는 대상의 개수이며, Sk는 문장 k에 대한 주석이 달린 제안 세트이고, skl은 문장 k에 대한 1번째 예측 제안입니다. 영어: 종단 간 평가를 위한 정확도(Pe2e)와 재현율(Re2e)은 다음과 같이 계산합니다. pe2e Тре2е Np Re2e &quot; = TPe2e NG 여기서 Np와 NG는 각각 예측된 제안과 주석이 달린 제안의 수입니다. 쓰기 지원 시나리오에서 정확도는 재현율보다 더 중요하므로 Fee를 전반적인 메트릭으로 계산합니다. Feze 0.1.25 pe2e Re2e 0.25 Pe2e+ Re2e 4.2 하위 작업 평가 0. 개선 가능한 타겟 감지. 이 작업에서 모델은 문장에서 주석이 달린 모든 개선 가능한 타겟을 찾아야 합니다. 감지를 위한 정확도(Pdet)와 재현율(Rdet)은 다음과 같이 계산합니다. N pdet - Sket k=ΣΕ&quot; Rdet N Σ=1 | Skn sk Σk=18k 여기서 Sk와 s½는 각각 문장 k에 대한 주석이 달린 개선 가능 대상 집합과 예측된 개선 가능 대상 집합입니다. 종단 간 평가와 동일하게 Fdet를 계산하여 개선 가능 대상 감지 성능을 평가합니다. Fdet 0.0.1.25 Pdet Rdet . 0.25 Pdet Rdet 대체 제안. 이 작업에서 모델은 각 개선 가능 대상에 대한 제안을 제공해야 합니다. 올바르게 감지된 대상에 대한 제안의 정확도를 계산합니다. Accsug ΙΣΟΣ Σ 1 if t₁ = T₁ else 0) 여기서 T는 대상 1의 주석이 달린 추천 집합이고, t는 대상 1에 대한 예측 추천이며, M은 문장 k에서 올바르게 감지된 대상의 총 수입니다. 5 실험 5.1 기준선 SWS에서 7가지 방법을 테스트합니다. 이 방법은 세 그룹으로 나눌 수 있습니다. (1) 제안을 제공하기 위해 외부 지식 채택. (2) 최첨단 어휘 대체 방법. (3) 종단 간 SWS 기준선. 또한 참조를 위해 인간 성과를 나열합니다. 외부 지식 방법. 외부 지식을 사용하여 제안을 제공하는 두 가지 방법이 있습니다. (1) 원격 감독 데이터를 구성하는 방법으로 규칙 기반 동의어 대체. 모든 항목이 대체되는 탐욕적 대체 전략을 채택합니다. (2) 방대한 데이터로 학습하고 인간의 피드백으로 더욱 미세 조정된 대규모 언어 모델인 ChatGPT4. ChatGPT에 모든 제공 문장에서 제안을 직접 생성하도록 요청합니다. ChatGPT를 활용하기 위한 프롬프트와 세부 정보는 부록 C에서 찾을 수 있습니다. Sp,Sv 어휘 대체 방법. 최첨단 어휘 대체 방법 두 가지가 SWS, 즉 BERT(Zhou et al., 2019) 및 LexSubCon(Michalopoulos et al., 2022)에서 테스트되었습니다. 우리는 LexSubCon의 오픈 소스 코드를 사용하고 BERTsp, Sv를 다시 구현합니다.우리는 모델이 각 단어에 대한 대체를 제공하게 하고, 대체가 원래 단어와 다르면 그 단어는 탐지된 개선 가능한 대상으로 간주됩니다.https://openai.com/blog/chatgpt/ 종단 간 기준선.종단 간 프레임워크에서 우리는 SWS를 세 가지 훈련 패러다임으로 취급하고 각각에 대해 하나의 기준선을 제공합니다.(1) 마스크 언어 모델링(MLM): 우리는 MLM 헤드를 기준선으로 하는 BERT-baseuncased(Devlin et al., 2019)를 사용합니다.(2) 시퀀스 대 시퀀스 생성: 우리는 BART-base(Lewis et al., 2020)를 기준선으로 사용합니다.(3) 토큰 수준 재작성: 우리는 CMLM(Marjan Ghazvininejad, Omer Levy, Yinhan Liu, Luke Zettlemoyer, 2019)을 기준선으로 사용합니다. 원격 감독 데이터 세트는 엔드투엔드 베이스라인을 훈련하는 데 활용됩니다. 개선 가능한 대상의 경우 모델은 제안을 학습할 것으로 예상됩니다. 그렇지 않은 경우 모델은 원래 단어를 유지할 것으로 예상됩니다. 5.2 주요 결과 표 3은 베이스라인의 실험 결과를 보여주며, 이를 통해 다음과 같은 관찰 결과를 얻을 수 있습니다. (1) 규칙 기반 접근 방식은 원격 감독 데이터를 만드는 과정과 유사합니다. 원격 감독 데이터를 사용하여 훈련된 규칙 기반 방식과 엔드투엔드 베이스라인은 모두 높은 pdet 값과 낮은 Rdet 값을 갖습니다. 이는 이 작업에서 사용된 동의어 사전의 품질은 높지만 적용 범위가 낮음을 시사합니다. (2) 규칙 기반 방식과 비교할 때, 원격 감독 데이터 세트에서 훈련된 엔드투엔드 모델은 개선 가능한 대상 탐지 성능이 감소했지만 대체 제안 성능이 증가했습니다. 원격 감독 데이터의 개선 가능한 대상은 개선이 필요한 단어나 구문을 정확하게 반영하지 않아 모델을 효과적으로 탐지하는 데 어려움을 겪습니다. 그러나 원격 지도 학습 데이터의 대체 제안은 위키피디아의 원래 단어에서 파생되어 모델이 맥락에서 비교적 적절한 단어 사용을 학습할 수 있게 합니다. (3) CMLM 모델의 결과는 사전 학습된 모델인 BERT 및 BART에 비해 성능이 저하되었음을 보여줍니다. 특히 대체 제안 측면에서 그렇습니다. 의미 지식의 사전 학습은 이 작업에 대한 사전 학습된 모델의 우수한 성능에 기여할 수 있습니다. (4) LS 방법의 경우 SWS가 눈에 띄게 감소합니다. 더욱이, 다양한 LS 방법은 개선 가능한 대상을 탐지하는 데 상당한 차이가 있습니다. 입력 문장의 단어 중 2.1%만 외부 지식 방법 어휘 대체 방법 모델 종단 간 방법 규칙 기반 ChatGPT pdet Rdet 0.585 0.344 0.0.451 0.418 0.Fdet 0.하위 작업 평가 종단 간 평가 Accsug pe2e Re2e Fe2e 0.0.314 0.183 0.108 0.0.427 0.193 0.179 0.BERTS Sp,Sv LexSubCon CMLM BART BERT 0.511 0.050 0.0.438 0.667 0.0.512 0.222 0.0.555 0.243 0.0.585 0.249 0.0.441 0.225 0.022 0.0.281 0.123 0.188 0.0.236 0.121 0.052 0.0.446 0.248 0.108 0.0.436 0.255 0.108 0.Human* 0.709 0.313 0.0.0.449 0.0.표 3: SWS의 평가 결과.*: 참고로, 10라운드의 평가 평균을 내어 인간의 성과를 제공합니다. 각 라운드에서 각 주석자는 다른 주석자의 결합된 주석과 비교됩니다.는 BERT, Sp, Sv에 의해 개선 가능한 대상으로 식별되는 반면 LexSubCon은 32.4%를 감지합니다. 현재 LS 방법은 SWS 작업과 호환되지 않습니다. (5) ChatGPT의 결과는 370만 개의 문장으로 훈련된 종단 간 기준선과 비슷하지만 여전히 개선의 여지가 있습니다.(6) 인간의 성능은 기준선보다 훨씬 뛰어납니다. 우리는 기준선이 개선될 여지가 많다고 믿습니다.6 분석 우리는 두 가지 질문으로 실험 결과를 분석합니다: (1) 모델은 개선이 필요한 단어를 정확하게 식별할 수 있는 기능이 있습니까, 아니면 단순히 무작위로 추측합니까?(2) 모델은 각 대상 단어에 대해 여러 가지 유용한 제안을 제공할 수 있습니까?6.1 감지 분석 투표 지수 및 가중 정확도. 주석을 병합한 후 각 개선 가능한 대상에 대한 투표 지수, 즉 단어나 구문을 식별한 주석 작성자의 수를 결정합니다. 투표 지수는 단어에 대한 필요한 대체 수준을 반영합니다.그림 3은 서로 다른 투표 지수를 가진 개선 가능한 대상에 대한 Rdet를 보여줍니다.그림 3에서 볼 수 있듯이 더 많은 수의 주석 작성자가 식별한 개선 가능한 대상은 모델에서 더 쉽게 감지됩니다. 다음으로, 투표 지수를 가중치 인자로 사용하여 탐지 성능을 평가하기 위한 가중 정확도(WA)를 설계합니다.WA det = k=ΣΚΙΣΜΑ wk if sul E s. elseMk ΣΚΙΣΜΑ ωκι k=Rdet BERT의 Rdet LexSubCon의 규칙 기반 Rdet의 Rdet 대상 번호 0.0.0.0.0.0.0.2 3 4 5 6 7투표 지수 9det 그림 3: 대상 수와 Rde 투표 지수. 다른 대상 수 여기서 s는 문장 k의 예측된 개선 가능한 대상 집합, skl은 문장 k에서 1번째로 주석이 달린 대상, wkl은 skl의 투표 지수, N은 전체 문장 수, Mk는 문장 k의 주석이 달린 개선 가능한 대상 집합의 크기입니다. det 표 4는 기준 방법의 Rdet 및 WA det를 보여줍니다. 다양한 투표 지수에 대한 Rdet의 추세와 일관되게, WA는 Rdet보다 상대적으로 높습니다. 이러한 결과는 기준 방법이 높은 신뢰도의 개선 가능한 타겟을 더 잘 감지할 수 있음을 보여줍니다. 개선 가능 비율. 개선 가능 비율(ImpR)은 감지된 개선 가능한 단어 수를 문장의 총 단어 수로 나눈 비율로 정의됩니다. 표 4에서 볼 수 있듯이, Rdet WA det는 ImpR과 양의 상관 관계가 있습니다. 모델 규칙 기반 0.125 0.ImpR Rdet WA det 0.0.ChatGPT 0.224 0.0.0.BERT 0.021 0.0.Sp,Sv LexSubCon 0.324 0.0.0.CMLM 0.094 0.0.BART 0.102 0.0.0.BERT 인간 0.093 0.0.0.BERT의 NDCGm 규칙 기반 ✓ LexSubCon의 NDCGm 0.# 제안 표 4: SWS 벤치마크 세트에서 개선 가능한 대상 탐지에 대한 개선 가능 비율(ImpR), 탐지 재현율(Rdet) 및 가중 정확도(WA). 그림 4: 다양한 m의 BERT, 규칙 기반 방법 및 LexSubCon에 대한 NDCGm. 원하는 ImpR을 달성하기 위해 모델을 제어하는 방법을 조사하기 위해 학습을 위한 또 다른 원격 감독 데이터 세트를 빌드합니다. 3.2절에서 설명한 데이터 집합 구축과 달리, 우리는 PPDB(Pavlick et al., 2015)와 Merriam-Webster 동의어 사전의 합집합을 대규모 동의어 사전으로 사용합니다. 동의어 사전 크기가 커짐에 따라 구축된 데이터에서 인공적으로 개선 가능한 타겟이 13.2%에서 25.4%로 증가합니다. 두 데이터 집합에서 학습된 BERT의 결과는 표 5에 나와 있습니다. 두 실험을 비교해보면, 학습 세트에서 구축된 개선 가능한 타겟의 수가 거의 두 배로 늘어난 반면, 학습된 모델의 ImpR은 9.3%에서 13.6%로만 증가합니다. ImpR을 제어하는 것은 어렵습니다. 따라서 연구 중인 한 가지 방향은 좋은 성능을 유지하면서도 원하는 ImpR을 달성하도록 모델을 제어하는 것입니다. 6.2 다중 제안 분석 사용자에게는 각 개선 가능한 타겟에 대해 여러 제안이 있는 것이 유익할 수 있습니다. 따라서 우리는 시스템이 탐지된 각 개선 가능한 타겟에 대해 여러 대체 제안을 제공할 수 있도록 하는 다중 제안 설정을 설계합니다. 출력 제안이 순서대로 순위가 매겨지므로, 우리는 검색 엔진에서 일반적으로 사용되는 메트릭인 정규화된 할인 누적 이득(NDCG)을 사용하여 순위가 매겨진 목록과 가중치가 있는 목록 간의 유사성을 측정할 것을 제안합니다. NDCGm = MM k=DCGm (T) DCGm (Tk) DCGm (Tk) = DCGm (T) = mi=Σisi Wi log(1 + i) m Σj ≤ j wj log (1+ j) j=w&#39;; = w¿ if t&#39;kj Є Tk else 이 공식에서 M은 실제로 예측된 개선 가능한 타겟의 총 수이고, m은 개선 가능한 타겟에 대한 제안 수를 지정하는 매개변수입니다. 분자에서 우리는 첫 번째에서 마지막까지 예측된 제안에 대한 가중치를 누적합니다. 추천 i&#39;가 인간 주석에 없으면 가중치는 0으로 설정됩니다. 그렇지 않으면 가중치는 투표 지수로 설정됩니다. 분모는 m개의 예측을 제공하기 위한 최적 조건을 나타내는 투표 지수에 따라 정렬된 목록입니다. 부록 D에서 NDCG를 계산하는 예를 제공합니다. = SWS 벤치마크에서 개선 가능한 각 대상에 대한 대체 제안의 평균 수는 3.3입니다. m이 주어진 대상에 대한 대체 수를 초과하면 DCGm(Tk)은 일정하게 유지됩니다. 따라서 NDCGm은 m 1, 2, 3, 4에 대해서만 계산됩니다. 그림 4는 다양한 기준선에 대한 NDCGm을 나열합니다. BERT는 다른 방법보다 성능이 더 좋을 수 있지만 제안 수 m이 증가함에 따라 BERT의 NDCGm은 상당히 떨어집니다. 이는 BERT가 여러 제안을 제공할 때 어려움을 겪는다는 것을 시사합니다. 이는 원격 감독 데이터 세트에 여러 대체 제안이 없기 때문일 수 있습니다. 향후 연구는 여러 대체 제안을 제공하는 모델의 기능을 개선하는 데 집중할 수 있습니다. 데이터 세트 pdet Rdet Wiki-13.2% 0.585 0.Wiki-25.4% 0.568 0.0.Fdet ImpR WA det 0.460 0.093 0.0.506 0.136 0.pe2e Re2e Fe2e 0.Accsug 0.436 0.255 0.108 0.0.243 0.138 0.086 0.표 5: 두 개의 원격 지도 데이터 세트에서 학습한 BERT 비교. 접미사는 데이터 세트의 구성된 개선 가능 대상 비율을 나타냅니다. 개선 가능한 대상이 더 많은 데이터 세트에서 학습한 모델은 더 높은 ImpR과 더 높은 Rdet을 생성하지만 대체 제안에서 성능이 떨어집니다. 문장: 대부분의 학생들은 충분한 자기 통제력이 없어서 비디오 게임을 하거나 하루 종일 TV를 보거나 며칠 동안 밖에서 놀게 되는 등 더 나쁜 상황에 처하게 됩니다.&quot; Ground Truth: situation →{&quot;circumstances&quot;: 5, &quot;conditions&quot;: 2}, BERT Prediction: Target not found 문장: 직접적으로. Ground Truth: knowing {&quot;following&quot;, &quot;memorizing&quot;, &quot;recalling&quot;, &quot;studying&quot;} BERT Prediction: knowing → understanding 무관한 사건을 아는 것이 우리 삶에 편리함을 제공하지 않는다는 것은 사실일 수 있습니다. 그림 5: BERT의 예측 사례 연구. 6. 사례 연구 그림 5는 BERT의 예측 사례 두 가지를 보여줍니다. 첫 번째 사례에서 BERT는 이 개선 가능한 대상을 감지하지 못했습니다. 그러나 원격 감독 학습 데이터에는 &quot;상황&quot;을 &quot;상황&quot;으로 대체하는 수십 개의 사례가 있습니다. 감지의 주도권을 제어하는 것이 연구할 가치가 있는 방향이라고 생각합니다. 두 번째 사례에서 BERT는 맥락을 무시하면 &quot;알고 있다&quot;에 가장 가까운 단어인 &quot;이해하다&quot;를 제안합니다. 그러나 &quot;사건을 알고 있다&quot;는 맥락에서는 올바른 의미가 아닙니다. 우리는 현재의 원격 감독 학습 데이터로 다른 맥락에서 단어 사용을 인식하는 모델을 학습하는 것이 어렵다고 생각합니다. 왜냐하면 우리는 1대체 1 데이터가 단어 사용에 대한 모델 학습에 충분한 정보를 제공하지 않는다고 생각하기 때문입니다. 우리는 이것을 미래의 연구 방향으로 간주합니다. 7
--- CONCLUSION ---
이 논문은 맥락에서 개선 가능한 대상을 탐지하고 대체를 제안하는 Smart Word Suggestions(SWS)의 첫 번째 벤치마크를 소개합니다. 이전 벤치마크와 달리 SWS는 쓰기 지원 시나리오를 보다 사실적으로 표현합니다. 저희의 실험과 분석은 향후 연구에 대한 다양한 과제를 강조하고 향후 작업에서 개선할 수 있는 기회를 제안합니다. 저희는 보다 현실적인 교육 데이터 구축, 더 나은 데이터 증강 전략 설계, SWS에 대한 비지도 또는 자체 지도 방법 개발에 대한 추가 연구를 장려합니다. 8 한계 SWS 벤치마크에는 두 가지 한계가 있습니다. (1) SWS 테스트 세트의 문장은 학생의 에세이에서 가져온 것이므로 시스템이 법률이나 의학과 같은 다른 특정 영역에서 성능을 테스트하는 능력이 제한됩니다. (2) SWS 코퍼스는 문장 수준이지만 일부 쓰기 제안은 전체 기사를 읽은 후에만 할 수 있으며, 이는 저희의 SWS 데이터 세트에 포함되지 않습니다. 참고문헌 Christopher Bryant, Mariano Felice, Ted Briscoe. 2017. 문법적 오류 수정을 위한 오류 유형의 자동 주석 및 평가. Association for Computational Linguistics의 55회 연례 회의록(제1권: 장문 논문), 793-805쪽, 캐나다 밴쿠버. Association for Computational Linguistics. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. 2019. BERT: 언어 이해를 위한 심층 양방향 변환기의 사전 학습. Association for Computational Linguistics의 북미 지부 2019년 회의록: 인간 언어 기술, 제1권(장문 및 단문 논문), 4171-4186쪽, 미네소타주 미니애폴리스. Association for Computational Linguistics. Li Dong, Jonathan Mallinson, Siva Reddy, Mirella Lapata. 2017. 질의응답을 위한 의역 학습. 2017년 자연어 처리 경험적 방법 컨퍼런스 회의록, 875-886쪽, 덴마크 코펜하겐. 계산언어학 협회. 프레도 에르슬레벤, 미카엘 귄터, 마르쿠스 크뢰츠치, 줄리안 멘데스, 데니 브란데치치. 2014. 링크된 데이터 웹에 위키데이터 소개. 의미 웹 - ISWC 2014, 50-65쪽, 샴. 스프링거 인터내셔널 퍼블리싱. 앤서니 페이더, 루크 제틀모이어, 오렌 에치오니. 2013. 개방형 질의응답을 위한 의역 중심 학습. 51회 연례 총회 의사록(제1권: 장문 논문), 1608-1618쪽, 불가리아 소피아. 학회, 2018. 신경 문법 오류 수정을 위한 유창성 향상 학습 및 추론. 56회 연례 총회 의사록(제1권: 장문 논문), 1055-1065쪽, 호주 멜버른. 학회, 2018. 구문적으로 제어되는 의역 네트워크를 사용한 적대적 예 생성. 2018년 북미 컴퓨터 언어학회 회의록: 인간 언어 기술, 제1권(긴 논문), 1875-1885쪽, 루이지애나주 뉴올리언스. 컴퓨터 언어학회. Gerhard Kremer, Katrin Erk, Sebastian Padó, Stefan Thater. 2014. 대체물이 알려주는 것 - &quot;모든 단어&quot; 어휘 대체 코퍼스 분석. 제14회 유럽 컴퓨터 언어학회 회의록, 540-549쪽, 스웨덴 예테보리. 컴퓨터 언어학회. Mina Lee, Chris Donahue, Robin Jia, Alexander Iyabor, Percy Liang. 2021. Swords: 향상된 데이터 범위와 품질을 갖춘 어휘 대체의 벤치마크. 2021년 북미 컴퓨터 언어학회 학술 대회 회의록: 인간 언어 기술, 4362-4379쪽, 온라인. 컴퓨터 언어학회. Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer. 2020. BART: 자연어 생성, 번역 및 이해를 위한 시퀀스 간 사전 학습의 노이즈 제거. 컴퓨터 언어학회 제58회 연례 회의 회의록, 7871-7880쪽, 온라인. 컴퓨터 언어학회. Tsung-Yi Lin, Michael Maire, Serge J. Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C. Lawrence Zitnick. 2014. Microsoft coco: Common Objects in context. ECCV에서. Marjan Ghazvininejad, Omer Levy, Yinhan Liu, Luke Zettlemoyer. 2019. Mask-Predict: Parallel Decoding of Conditional Masked Language Models. 2019 Conference on Empirical Methods in Natural Language Processing의 회의록에서. Diana McCarthy and Roberto Navigli. 2007. SemEval2007 task 10: 영어 어휘 대체 task. 제4회 국제 의미 평가 워크숍(SemEval-2007)의 회의록에서, 4853쪽, 체코 프라하. Association for Computational Linguistics. George Michalopoulos, Ian McKillop, Alexander Wong, and Helen Chen. 2022. LexSubCon: 어휘 리소스의 지식을 어휘 대체를 위한 문맥적 임베딩으로 통합. Association for Computational Linguistics(제1권: 장문 논문)의 제60회 연례 회의록, 1226-1236쪽, 더블린, 아일랜드. Association for Computational Linguistics. Hwee Tou Ng, Siew Mei Wu, Ted Briscoe, Christian Hadiwinoto, Raymond Hendy Susanto, and Christopher Bryant. 2014. 문법적 오류 수정에 대한 CoNLL-2014 공유 과제. 제18회 Computational Natural Language Learning 컨퍼런스의 회의록: 공유 과제, 1-14쪽, 볼티모어, 메릴랜드. Association for Computational Linguistics. Ellie Pavlick, Pushpendre Rastogi, Juri Ganitkevitch, Benjamin Van Durme, Chris Callison-Burch. 2015. PPDB 2.0: 더 나은 의역 순위, 세분화된 함축 관계, 단어 임베딩 및 스타일 분류. 제53회 계산 언어학 협회 연례 회의록 및 제7회 자연어 처리 국제 공동 컨퍼런스(제2권: 단편 논문), 425-430쪽, 중국 베이징. 계산 언어학 협회. Darsh Shah, Tao Lei, Alessandro Moschitti, Salvatore Romeo, Preslav Nakov. 2018. 중복 질문 감지를 위한 적대적 도메인 적응. 2018년 자연어 처리 경험적 방법 컨퍼런스록, 1056-1063쪽, 벨기에 브뤼셀. Association for Computational Linguistics. Wei Song, Ziyao Song, Lizhen Liu, and Ruiji Fu. 2020. 논증적 학생 에세이의 조직 평가를 위한 계층적 멀티태스크 학습. 제29회 국제 인공지능 공동 학술대회 회의록, IJCAI20, 3875-3881쪽. 국제 인공지능 조직 공동 학술대회. 본론. Denny Vrandečić and Markus Krötzsch. 2014. Wikidata: 무료 협업 지식 기반. Communications of the ACM, 57(10):78–85. Wangchunshu Zhou, Tao Ge, Ke Xu, Furu Wei, and Ming Zhou. 2019. BERT 기반 어휘 대체. 57회 연례 총회 의사록, 3368-3373쪽, 이탈리아 피렌체.Associational Linguistics 협회.A 주석 지침 문장에서 &quot;변경할 단어/구&quot;를 최소 3개 찾아야 하며, 각각에 대한 &quot;대체 단어/구&quot;를 제시해야 합니다. 모든 대체 단어는 improve-usage 또는 diversify-expression으로 분류해야 합니다.A.1 변경해야 할 단어/구는 무엇입니까? 저희의 목표는 쓰기 시나리오에서 더 나아져야 할 단어/구문을 찾는 것입니다. 여러분이 교사이고, 지금은 언어 학습자들의 영어 쓰기 능력을 향상시키도록 돕고 있다고 가정해 보겠습니다. &quot;변경할 단어&quot;는 대체 단어가 다음과 같은 영향을 미치기 때문에 정의합니다. • 원래의 의미적 의미를 더 적절하게 표현하기 위해. • 단어 사용을 모국어 화자에게 훨씬 더 가깝게 만들기 위해. • 구어를 문어로 바꾸기 위해. • 더 나은 표현을 위해 단어 사용을 다양화하기 위해. 영어: 대체는 다음과 같이 영향을 미쳐서는 안 됩니다.• 단어나 구문 대신 문장을 더 나은 표현으로 다시 쓰세요(예: &quot;it is recommended&quot; &quot;advisably,&quot;).• 문장의 실수를 바로잡으세요(예: &quot;There are a lot of valuable tips&quot; 문장에서 &quot;a lot&quot; &quot;a lot of&quot;).• 단어를 동의어로 대체하지만 영어 학습자의 글쓰기를 돕지 마세요.정의 후에 참조할 수 있는 몇 가지 규칙도 제공합니다.• 변경해야 할 단어/구는 일반적으로 3개 단어 미만입니다.• 변경해야 할 단어/구는 일반적으로 형용사/부사/명사/동사입니다.• 변경해야 할 단어/구는 일반적으로 명명된 엔터티가 아닙니다.A.2 대체를 제공하는 방법은?대체는 다음과 같아야 합니다.• &quot;변경할 단어&quot;와 동일한 의미적 의미를 가져야 합니다.• 문장의 의미를 변경하지 않아야 합니다.특히 대체에는 두 가지 시나리오가 있습니다.• 변경할 단어가 일반적이며 문장의 의미를 명확하게 이해할 수 있는 경우 이 경우 대체는 더 정확해야 합니다.(예: &quot;중국 북서부의 학교는 우리의 주요 지원 개인이며 여름방학이 시작되면 종종 학교에서 시작합니다.&quot; &quot;aiding&quot;→&quot;helping&quot;은 좋은 대체입니다.) • 변경할 단어가 혼란스럽고 문장의 의미를 추측만 할 수 있는 경우. 이 경우 대체는 더 일반적이어야 합니다.(예: &quot;성공한 개인은 ...을 포함한 다양한 장점이 특징입니다.&quot; &quot;various&quot;→&quot;plentiful&quot;은 나쁜 대체입니다.) 대체 후 문장은 원래 문장만큼 유창해야 합니다. 전치사 결합, 시제 및 신화의 오류는 피해야 합니다.(예: &quot;in a nutshell&quot;, &quot;nutshell&quot; → &quot;essence&quot;는 올바르지 않으며 &quot;in a nutshell&quot; → &quot;in essence&quot;로 해야 합니다.) A.3 주석 지침 • 그리드의 대체는 &quot;;&quot;로 연결해야 합니다(&#39;,&#39;가 아닙니다!). • 원래 문장에 문법 또는 오타 문제가 있는 경우 문장을 삭제하면 됩니다. • 주석 표에서 &quot;변경할 단어&quot; 열의 내용은 원래 문장의 단어/구문과 정확히 동일해야 하며 구두점이 없어야 합니다(여러 대체 단어를 연결하는 &quot;;&quot; 제외) • 나눌 수 없는 경우가 아니면 가장 짧은 범위의 단어로 대체합니다. (예: &quot;I think you deserve it again&quot; → &quot;I think you deserve another chance&quot;는 나쁜 경우이며, &quot;it again&quot; → &quot;another chance&quot;가 되어야 합니다. &quot;in a nutshell&quot; → &quot;in essence&quot;는 좋은 경우입니다. &quot;in a nutshell&quot;은 구이기 때문입니다.) • 문장을 의역할 필요가 없습니다. • &quot;대체 단어&quot;와 &quot;변경할 단어&quot;가 동일한 시제, 복수형 및 품사를 가지고 있는지 확인하십시오. B 평가 지표의 예 예를 들어, &quot;이전에 질문하신 것에 답하기 위해 글을 쓰고 있습니다.&quot;라는 문장이 주어졌을 때 이 문장의 주석 결과는 다음과 같습니다. answer: {respond to: 3, reply to: 1}, writing: {connecting with: 3}, to answer: {in response to: 2}, questions: {queries: 2} 개선 가능한 타겟 감지에서 Sk는 {answer, writing, to answer, questions}입니다. 예측 S가 {answer, previous}이면 pdet 1/2이고 Ret = 1/4입니다. 대체 제안 지표에서 실제 예측 타겟 답변을 예로 들어 보겠습니다. 예측된 제안이 {respond to, reply to, then Accsug 1, Otherwise Accug = 0. = 엔드투엔드 평가에서 예측된 제안이 {answer: respond, writing: connect with, asked: gave}이면 Pe2e = 1/이고 Re2e = 1/4입니다. C ChatGPT에 대한 프롬프트 프롬프트 we 사용법은 다음과 같습니다.다음 문장에서 단어 사용을 개선하기 위한 몇 가지 제안을 해주세요.&quot;원래 단어&quot;의 json 형식으로 결과를 제공해 주세요: [&quot;제안 1&quot;, &quot;제안 2&quot;], 그리고 &quot;원래 단어&quot;는 문장에서 직접 추출해야 합니다.[s] 여기서 [s]는 문장입니다.놀랍게도 ChatGPT는 키값 형식으로 대체 제안을 생성할 수 있습니다.우리는 정규 표현식을 사용하여 대체 제안을 추출합니다.결과가 비어 있으면 대체 제안을 받을 때까지 다시 생성합니다.D NDCG의 예 NDCG5의 예를 들어보겠습니다.개선 가능한 타겟이 감지된 경우, 투표 인덱스가 {respond to : 3, respond: 2, response: 1, reply to: 1}이고 T&#39;; 순서가 {응답, 응답, 말하기, 응답, 해결책}일 때 DCG(T)와 DCG(T;)는 다음과 같이 계산되고 NDCG5 = 4.4/5.1 = 86.3%입니다. 순서 하위 이득 DCG5(T½) 응답2 = 2 × 응답3.92+3 x 0. 말하기3.9 3.90 × 0. 응답4.43.9+1 × 0. 해결책4.4 = 4.4+0 × 0. 순서 하위 이득 DCG5(Tk) 응답3 = 3 x 응답4.2 = 3 + 2 x 0. 응답= 4.7 4.2+1 × 0. 응답5.1 = 4.7 + 1 × 0. NULL5.1 5.1 +0 × 0.
