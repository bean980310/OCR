--- ABSTRACT ---
GPT3 및 GPT-4와 같은 대규모 언어 모델(LLM)은 강력하지만 가중치는 종종 공개적으로 사용할 수 없고 엄청난 크기 때문에 일반 하드웨어로 모델을 조정하기 어렵습니다. 결과적으로 대규모 지도 학습 데이터로 이러한 모델을 효과적으로 조정하는 것은 어려울 수 있습니다. 대안으로, 컨텍스트 내 학습(ICL)은 컨텍스트 길이 제한으로 인해 소수의 지도 학습 예제만 사용할 수 있습니다. 이 논문에서는 블랙박스 LLM이 로컬로 미세 조정된 소규모 모델과 함께 작동하여 지도 학습 작업에서 뛰어난 성능을 낼 수 있도록 하는 Super In-Context Learning(SuperICL)을 제안합니다. 실험 결과 SuperICL은 컨텍스트 내 학습의 불안정성 문제를 해결하는 동시에 최첨단 미세 조정 모델보다 성능을 향상시킬 수 있음을 보여줍니다. 더욱이 SuperICL은 다국어성 및 해석 가능성과 같은 소규모 모델의 기능을 향상시킬 수 있습니다.¹
--- INTRODUCTION ---
GPT-3(Brown et al., 2020) 및 GPT-4(OpenAI, 2023)와 같은 대규모 사전 학습된 언어 모델은 광범위한 NLP 작업에서 놀라운 역량을 보여주었습니다. 최근에 출시된 이러한 모델의 인상적인 성능에도 불구하고, 크기와 모델 가중치의 제한된 접근성으로 인해 이러한 모델을 지도 학습 데이터로 미세 조정하는 데 어려움이 있을 수 있습니다. 이는 모델을 특정 작업에 맞게 조정하는 효과적인 방법입니다(Liu et al., 2019). 대안적인 접근 방식인 컨텍스트 내 학습(ICL, Brown et al., 2020)은 몇 가지 레이블이 지정된 예제를 테스트 입력과 연결하여 모델이 컨텍스트에서 학습할 수 있도록 합니다. 그러나 ICL은 LLM의 최대 컨텍스트 길이에 의해 제한되어 사용할 수 있는 예제 수가 제한됩니다. 결과적으로 ICL은 일반적으로 16개 또는 32개의 예제로 few-shot 학습을 수행할 수 있지만, * Microsoft에서 인턴십 중에 수행한 작업. 코드는 https://aka.ms/SuperICL에서 제공됩니다. 수백 또는 수천 개의 예가 있는 경우 지도 학습 데이터를 완전히 활용할 수 없습니다. 이러한 한계를 해결하기 위해 블랙박스 언어 모델(예: GPT3.5)이 로컬로 미세 조정된 소규모 모델(예: ROBERTA, Liu et al., 2019)과 함께 작동하여 지도 학습 작업의 성능을 향상시킬 수 있는 새로운 접근 방식인 Super In-Context Learning(SuperICL)을 제안합니다. SuperICL은 ICL의 성능 저하 및 불안정성이라는 과제를 극복하도록 설계되었습니다. SuperICL은 ICL의 장점을 기반으로 하며 한계를 완화합니다. 그림 1에서 볼 수 있듯이 SuperICL은 플러그인 역할을 하는 소규모 모델과 LLM의 조합을 활용하여 지도 학습 작업을 효율적으로 수행합니다. 구체적으로 플러그인 모델을 사용하여 컨텍스트 내 예에 대한 레이블을 확신을 가지고 예측하고 이를 입력 텍스트 및 기준 진실 레이블과 컨텍스트로 연결합니다. 테스트 예의 경우 플러그인 모델의 예측 및 확신을 테스트 입력에 추가하고 LLM이 최종 레이블과 설명을 예측하도록 합니다. 이러한 플러그인 모델은 작업별 데이터에 따라 미세 조정되었으므로 대규모 사전 학습된 모델과 작업별 데이터 간의 브리지 역할을 하여 효과적인 지식 전달과 향상된 성능을 가능하게 합니다.우리는 자연어 이해를 위한 표준 벤치마크인 GLUE(Wang et al., 2019)에서 SuperICL의 효과를 평가하기 위해 광범위한 실험을 수행했습니다.우리의 결과에 따르면 SuperICL은 (1) 최첨단 미세 조정 모델 및 LLM과 비교하여 우수한 성능을 달성합니다.(2) 플러그인 모델이 작업별 정보를 흡수할 수 있도록 하면서 LLM이 보다 일반적인 언어 이해에 집중할 수 있도록 하여 ICL의 불안정성 문제를 해결합니다.(3) 다국어 기능을 확장하여 더 광범위한 언어를 포괄하는 등 플러그인 모델의 기능을 향상시킵니다.(4) 플러그인 모델에서 내린 예측을 무시하는 이유에 대한 설명을 제공하여 LLM을 통해 해석 가능성을 제공합니다. 지도 학습 샘플 데이터 집합 입력 기준 진실 문맥 내 예제 + 테스트 입력 LLM (a) ICL 지도 학습 샘플 데이터 집합 입력 기준 진실 문맥 내 예제 플러그인 모델 입력 예측 레이블 신뢰도 기준 진실 구성된 컨텍스트 + 테스트 입력 플러그인 모델 테스트 입력 예측 레이블 신뢰도 (b) SuperICL LLM 최종 예측 최종 예측 설명 그림 1: ICL 및 SuperICL의 워크플로. SuperICL에는 세 단계가 있습니다. (1) 학습 데이터에서 무작위로 샘플링하고 예측 레이블과 해당 신뢰도 점수를 포함하여 플러그인 모델의 예측을 통합하여 컨텍스트를 구성합니다. (2) 테스트 입력은 플러그인 모델의 예측이 첨부된 컨텍스트 뒤에 연결됩니다. (3) 마지막으로 언어 모델은 선택적 설명과 함께 최종 예측을 생성합니다. 그런 다음 각 구성 요소가 SuperICL의 최종 성능에 어떻게 기여하는지, 그리고 컨텍스트 내 예제의 수에 미치는 영향에 대한 철저한 분석을 수행합니다. 또한 플러그인 모델에 대한 적대적 공격의 효과와 이것이 SuperICL의 성능에 어떤 영향을 미치는지 살펴봅니다. 저희의 연구 결과는 대규모와 소규모, 클라우드와 로컬 모델을 결합하는 잠재력을 보여주며, 대규모 언어 모델 시대에 감독 학습을 위한 유망한 새로운 패러다임을 밝혀냅니다. 2
--- RELATED WORK ---
문맥 내 학습 원래 GPT-3 논문(Brown et al., 2020)에서 제안된 문맥 내 학습(ICL)은 모델의 매개변수를 업데이트하지 않고도 새로운 과제에서 LLM을 활용하는 새로운 패러다임으로 간주됩니다. 대규모 언어 모델이 패턴을 찾고 예측을 &quot;학습&quot;할 수 있도록 테스트 입력 앞에 몇 가지 샷 학습 예제를 프롬프트로 추가합니다. 기계 번역(Lin et al., 2021; Agrawal et al., 2022) 및 데이터 생성(Ye et al., 2022)과 같은 다운스트림 과제에서 ICL의 성공적인 적용이 있었습니다. 몇 가지 샷 학습에서의 성공에도 불구하고 ICL의 주요 단점은 불안정성입니다. ICL의 성능은 선택된 문맥 내 예제(Zhao et al., 2021)와 심지어 그 순서(Lu et al., 2022)에 민감합니다. 이러한 발견을 바탕으로 문맥 구성에 초점을 맞춘 일련의 연구가 있습니다. LM-BFF(Gao et al., 2021)와 KATE(Liu et al., 2022)는 테스트 예제와 의미적으로 유사한 학습 예제를 선택합니다. 또 다른 연구 분야(Su et al., 2022; Levy et al., 2022; Ye et al., 2023)는 학습 세트에서 다양하고 대표적인 예제를 마이닝하는 데 중점을 둡니다. Zhang et al.(2022)은 능동 학습과 강화 학습을 활용하여 ICL에 대한 예제를 선택합니다. 자체 적응형 ICL(Wu et al., 2022, 2023b)은 별도의 검증 세트를 사용하지 않고도 각 테스트 입력에 대한 최적의 컨텍스트 내 예제를 얻기 위한 2단계 검색 프레임워크를 제안합니다. 이러한 연구와 달리 SuperICL은 더 작은 모델을 감독 작업을 위한 대규모 언어 모델에 통합할 수 있음을 보여줍니다. 영어: 이는 이전 연구와 직교적이기는 하지만, 플러그인 모델을 전체 학습 세트로 미세 조정함으로써 SuperICL은 학습 세트에서 최적의 예제를 선택할 필요성을 줄입니다.게다가 이전 연구에서는 ICL을 위한 언어 모델을 준비하는 방법도 조사했습니다.Zhao et al.(2021)은 레이블 분포와 순서의 영향을 줄이기 위해 빈 테스트 입력으로 보정을 제안했습니다.MetaICL(Min et al., 2022a)은 언어 모델을 메타 학습하여 보이지 않는 작업으로 일반화하여 더 나은 ICL 성능을 제공합니다.Chen et al.(2022)은 ICL에서 언어 모델의 성능을 개선하기 위해 중간 작업으로 4개의 자기 감독 목표를 제안했습니다.특히, Min et al. (2022a) 알고리즘 1 슈퍼 인 컨텍스트 학습(SuperICL) 필요 사항: 학습 세트 D = {(x1,y1), ..., (xn, Yn)}, LLM M, 미리 학습된 작은 언어 모델 P 보장: 예측 레이블 yt 및 선택적 설명 et 1: D에서 P를 미세 조정하여 미세 조정된 플러그인 모델 P&#39;를 얻음 2: D에서 예제 세트(xi, yi)를 무작위로 샘플링하여 인 컨텍스트 예제 세트 D&#39;를 만듬 3: D&#39;의 각 예제(xi, yi)에 대해 다음을 수행 4: y½가 예측 레이블이고 c¿가 신뢰 점수인 P&#39;로 y&#39; 및 c¿를 예측 5: 종료 6: 모든 (xi, Yi, Ci, Yi)를 연결하여 컨텍스트 C를 구성 7: 각 테스트 예제 xt에 대해 다음을 수행 8: 9: 10: 11: 테스트 예제에 대해 P&#39;로 y½ 및 ct를 예측 영어: 완전한 입력 I = C = (xt, Yt, Ct)를 공식화합니다.여기서 는 연결을 나타냅니다.M을 사용하여 I에서 yt를 예측합니다.(선택 사항) yt yt인 경우 M에 P&#39; 12의 예측을 재정의하기 위한 설명 et를 생성하도록 요청합니다.끝 및 Chen et al.(2022)은 가중치를 업데이트해야 하므로 GPT-3/4와 같은 대규모 블랙박스 모델에는 적용할 수 없습니다.ICL의 성능을 개선하기 위한 연구 외에도 일부 연구에서는 ICL의 기본 메커니즘을 분석했습니다.Min et al.(2022b)은 레이블 공간, 입력 텍스트의 분포 및 시퀀스의 전체 형식이 ICL 성능의 핵심 요소라는 것을 발견했습니다.또한 그들은 기본 레이블이 ICL 성능에 중요하지 않다고 주장하지만 이 결론은 후속 연구(Yoo et al., 2022)와 모순됩니다. 또한 이전 연구에 따르면 ICL은 암묵적으로 베이지안 추론(Xie 등, 2022) 또는 경사 하강(Akyürek 등, 2022; von Oswald 등, 2022; Dai 등, 2022)을 수행할 수 있습니다.언어 모델 플러그인 대규모 언어 모델은 외부 도구를 활용하여 기능을 개선할 수 있습니다.Toolformer(Schick 등, 2023)는 대규모 언어 모델이 외부 API를 호출하여 작업을 완료할 수 있도록 하는 특수 기호를 도입합니다.Visual ChatGPT(Wu 등, 2023a)는 비전 모델을 ChatGPT에 연결하여 멀티모달 생성을 허용합니다.HuggingGPT(Shen 등, 2023)는 ChatGPT를 사용하여 작업 계획을 수행하고 Hugging Face에서 사용 가능한 기능 설명에 따라 모델을 선택하고, 선택한 AI 모델로 각 하위 작업을 실행하고, 실행 결과에 따라 응답을 요약합니다. 이러한 연구와 달리, 저희의 연구는 고전적인 지도 학습을 따르며, 때로는 작은 언어 모델에 의해 &quot;해결된&quot; 것으로 간주되는 텍스트 분류와 같은 과제조차도 대규모 언어 모델과 결합하면 여전히 이점을 얻을 수 있음을 보여줍니다.3 Super In-Context Learning Super In-Context Learning(SuperICL)은 LLM을 로컬로 미세 조정된 소규모 모델과 결합하여 함께 작동하여 지도 과제의 성능을 개선할 수 있습니다. 소규모 모델은 플러그인 역할을 하여 과제별 지식과 예측을 제공하는 반면, 대규모 사전 학습된 모델은 일반적인 언어 이해에 초점을 맞춥니다. SuperICL의 전체 워크플로는 그림 1에 표시되어 있으며 전체 알고리즘은 알고리즘 1에 나와 있습니다. 플러그인 모델 미세 조정 SuperICL 프로세스의 첫 번째 단계는 과제별 레이블이 지정된 데이터에서 ROBERTa(Liu et al., 2019)와 같은 소규모 NLP 모델을 미세 조정하는 것입니다. 전체 학습 데이터에 대한 이러한 미세 조정 프로세스는 모델의 크기가 작고 로컬에서 액세스할 수 있기 때문에 가능해졌습니다. 이는 레이블이 지정된 데이터의 사용이 LLM의 컨텍스트 길이에 의해 심각하게 제한되는 ICL과는 대조적입니다. 미세 조정된 작은 모델은 다음과 같이 후속 단계에서 LLM의 플러그인으로 통합됩니다. 컨텍스트 구성 다음으로, LLM이 작은 모델에서 제공하는 작업별 지식을 활용할 수 있도록 컨텍스트를 구성합니다. 이 컨텍스트는 훈련 데이터에서 무작위로 샘플링한 예제 집합과 작은 플러그인 모델의 해당 예측으로 구성됩니다. 예측에는 예측된 레이블과 연관된 신뢰도 점수가 모두 포함됩니다. 예는 표 1에 나와 있습니다. 한편, 플러그인 모델의 예측된 레이블을 통합함으로써 LLM은 입력 시험(a) 컨텍스트 (b) 테스트 입력 (c) 레이블 예측 (d) 설명 간의 관계를 더 잘 이해할 수 있습니다. 문장 1: 연방 요원 빌 폴리크로노풀로스는 30세의 남자가 기소될지 여부는 알려지지 않았다고 말했습니다. 문장 2: 연방 요원 빌 폴리크로노풀로스는 어젯밤 멜버른 사건에 연루된 남자가 무장하지 않았다고 말했습니다. ROBERTa-Large 예측: 동일(신뢰도: 0.51) 라벨: 동일하지 않음 문장 1: 수요일에 메사 카운티 보건부는 서나일 바이러스의 인간 감염 사례 5건을 추가로 보고했습니다. 문장 2: 이번 주까지 45개 카운티에서 103건의 서나일 인간 감염 사례가 보건부에 보고되었습니다. ROBERTa-Large 예측: 동일하지 않음(신뢰도: 0.98) 라벨: 동일하지 않음 ... 문장 1: 쿨리는 무함마드도 말보의 공판 전 심리에서 증인으로 소환될 것으로 예상한다고 말했습니다. 문장 2: 리 보이드 말보는 수요일에 동료 저격수 용의자 존 앨런 무함마드의 공판 전 심리에서 증인으로 소환될 예정입니다. ROBERTa-Large 예측: 동일(신뢰도: 0.82) 레이블: 동일하지 않음 예측 재정의에 대한 설명: 두 문장은 John Allen Muhammad와 Lee Boyd Malvo라는 다른 사람에 대해 이야기하고 있으므로 예측은 not_equivalent여야 합니다.표 1: MRPC 데이터 세트에서 구성된 컨텍스트 및 추론 절차의 예.먼저 감독 데이터 세트에서 샘플링하여 컨텍스트를 구성하고 플러그인 모델의 예측을 첨부합니다.그런 다음 각 테스트 예제에 대해 대형 언어 모델에 입력과 플러그인 모델의 예측을 기반으로 레이블을 예측하도록 요청합니다.프롬프트를 사용하여 플러그인 모델에서 예측한 레이블이 재정의되는 경우 모델에 결정을 설명하도록 요청합니다.텍스트 필드 이름(예: 문장 1)은 데이터 세트에 제공된 원래 필드 이름입니다.플, 기준 진실 레이블 및 플러그인 모델의 전문 지식을 기반으로 합니다.이는 후속 의사 결정 프로세스에서 LLM이 최종 예측을 생성하는 데 도움이 됩니다. 반면, 신뢰도 점수는 플러그인 모델의 예측 불확실성을 측정하는 척도를 제공합니다. 이러한 점수를 컨텍스트에 통합함으로써 LLM은 플러그인 모델이 매우 신뢰하는 예측을 신뢰하고 플러그인 모델이 불확실한 경우 더 조심할 수 있습니다. 나아가 신뢰도 점수는 LLM의 주의를 더 어려운 컨텍스트 내 사례로 유도하여 이러한 어려운 사례에서 배우고 잠재적으로 작업에 대한 전반적인 성과를 개선할 수 있도록 도울 수 있습니다. 요약하자면, 예측된 레이블과 플러그인 모델의 연관된 신뢰도를 모두 고려하여 LLM은 주어진 예측을 따를지 아니면 작업에 대한 자체 이해에 의존할지 결정하여 전반적으로 더 정확한 예측을 이끌어냅니다. 추론 컨텍스트가 구성되면 테스트 입력(표 1(b)에 표시된 예)이 컨텍스트와 연결되어 대규모 언어 모델에 대한 완전한 입력을 형성합니다. 예측된 레이블과 신뢰도 점수를 포함한 테스트 입력에 대한 플러그인 모델의 예측도 입력에 첨부됩니다. 따라서 LLM의 입력에는 컨텍스트, 테스트 입력 및 플러그인 모델의 예측이 포함됩니다. 그런 다음 LLM은 표 1(c)에 표시된 대로 테스트 입력에 대한 최종 예측을 생성합니다. 선택적으로 표 1(d)에 표시된 대로 LLM은 예측에 대한 설명을 제공하여 플러그인 모델의 예측을 무시하거나 따르기로 선택한 이유에 대한 통찰력을 제공할 수도 있습니다. 이러한 추가적인 해석 가능성은 결합된 SuperICL 모델의 의사 결정 프로세스를 이해하는 데 중요할 수 있습니다. 4 실험 4.1 실험 설정 벤치마크 전체 교육 세트에 액세스할 수 있는 전체 감독 설정에 중점을 둡니다. 널리 사용되는 두 가지 벤치마크에 대한 실험을 수행합니다. 자연어 이해 작업을 위한 GLUE 벤치마크(Wang et al., 2019)와 제로샷 교차 언어 자연어 추론 작업을 위한 XNLI 벤치마크(Conneau et al., 2018)로, 모델은 영어로 교육되고 다른 언어로 테스트됩니다. 우리의 목표는 표준 벤치마크에서 SuperICL의 학습 능력을 조사하고 다국어 기능을 통해 소규모 모델을 강화할 수 있는지 확인하는 것입니다. ICL과
--- METHOD ---
s MNLI-m MNLI-mm GPT-3.5 ICL ROBERTa-Large 80.88.82.89.SuperICL 89.89.SST-2 QNLI MRPC QQP COLA RTE 평균 91.39 80.52 60.05 81.64 60.51 86.28 81.96.44 94.07 83.09 92.11 64.55 87.00 88.96.79 94.16 86.03 92.14 64.57 87.73 89.표 2:
--- EXPERIMENT ---
s는 SuperICL이 컨텍스트 내 학습의 불안정성 문제를 해결하는 동시에 최첨단 미세 조정 모델보다 성능을 향상시킬 수 있음을 보여줍니다.또한 SuperICL은 다국어성 및 해석 가능성과 같은 소규모 모델의 기능을 향상시킬 수 있습니다.¹ 서론 GPT-3(Brown et al., 2020) 및 GPT-4(OpenAI, 2023)와 같은 대규모 사전 학습된 언어 모델은 광범위한 NLP 작업에서 놀라운 기능을 보여주었습니다.최근 출시된 이러한 모델의 인상적인 성능에도 불구하고 크기와 모델 가중치의 제한된 접근성으로 인해 이러한 모델을 지도 학습 데이터로 미세 조정하는 데 어려움이 있을 수 있으며, 이는 모델을 특정 작업에 맞게 조정하는 효과적인 방법입니다(Liu et al., 2019).대안적인 접근 방식인 컨텍스트 내 학습(ICL, Brown et al., 2020)은 몇 가지 레이블이 지정된 예제를 테스트 입력과 연결하여 모델이 컨텍스트에서 학습할 수 있도록 합니다. 그러나 ICL은 LLM의 최대 컨텍스트 길이에 의해 제한되어 활용할 수 있는 예제 수가 제한됩니다. 결과적으로 ICL은 일반적으로 16개 또는 32개의 예제로 few-shot learning을 수행할 수 있지만, * Microsoft에서 인턴십하는 동안 수행한 작업. 코드는 https://aka.ms/SuperICL에서 제공됩니다. 수백 또는 수천 개의 예제가 있는 경우 지도 학습 데이터를 완전히 활용할 수 없습니다. 이러한 제한 사항을 해결하기 위해 블랙박스 언어 모델(예: GPT3.5)이 로컬에서 미세 조정된 더 작은 모델(예: ROBERTA, Liu et al., 2019)과 함께 작동하여 지도 학습 작업에서 성능이 향상되는 새로운 접근 방식인 Super In-Context Learning(SuperICL)을 제안합니다. SuperICL은 ICL의 성능 저하 및 불안정성이라는 과제를 극복하도록 설계되었습니다. SuperICL은 ICL의 장점을 기반으로 하면서 제한 사항을 완화합니다. 그림 1에서 볼 수 있듯이 SuperICL은 플러그인 역할을 하는 더 작은 모델과 LLM의 조합을 활용하여 지도 학습 작업을 효율적으로 수행합니다. 구체적으로, 우리는 플러그인 모델을 사용하여 컨텍스트 내 예제에 대한 레이블을 확신을 가지고 예측하고 이를 입력 텍스트 및 기준 진실 레이블과 컨텍스트로 연결합니다.테스트 예제의 경우, 우리는 또한 플러그인 모델의 예측과 확신을 테스트 입력에 추가하고 LLM이 최종 레이블과 설명을 예측하게 합니다.이러한 플러그인 모델은 작업별 데이터에 따라 미세 조정되었으므로 대규모 사전 학습된 모델과 작업별 데이터 간의 브리지 역할을 하여 효과적인 지식 전달과 향상된 성능을 가능하게 합니다.우리는 자연어 이해를 위한 표준 벤치마크인 GLUE(Wang et al., 2019)에서 SuperICL의 효과를 평가하기 위해 광범위한 실험을 수행합니다.우리의 결과에 따르면 SuperICL은 (1) 최첨단 미세 조정 모델 및 LLM에 비해 우수한 성능을 달성합니다.(2) 플러그인 모델이 작업별 정보를 흡수하는 동시에 LLM이 보다 일반적인 언어 이해에 집중할 수 있도록 하여 ICL의 불안정성 문제를 해결합니다. (3) 다국어 기능을 확장하여 더 광범위한 언어를 포괄하는 등 플러그인 모델의 기능을 향상시킵니다.(4) 플러그인 모델에서 만든 예측을 재정의하는 이유에 대한 설명을 제공하여 LLM을 통해 해석 가능성을 제공합니다.지도 학습 샘플 데이터 세트 입력 기준 진실 컨텍스트 내 예제 + 테스트 입력 LLM (a) ICL 지도 학습 샘플 데이터 세트 입력 기준 진실 컨텍스트 내 예제 플러그인 모델 입력 예측 레이블 신뢰도 기준 진실 구성된 컨텍스트 + 테스트 입력 플러그인 모델 테스트 입력 예측 레이블 신뢰도 (b) SuperICL LLM 최종 예측 최종 예측 설명 그림 1: ICL 및 SuperICL의 워크플로.SuperICL에는 세 단계가 있습니다.(1) 컨텍스트는 학습 데이터에서 무작위로 샘플링하고 예측 레이블과 해당 신뢰도 점수를 포함하여 플러그인 모델의 예측을 통합하여 구성됩니다.(2) 테스트 입력은 플러그인 모델의 예측이 첨부된 컨텍스트 뒤에 연결됩니다. (3) 마지막으로 언어 모델은 선택적 설명과 함께 최종 예측을 생성합니다. 그런 다음 각 구성 요소가 SuperICL의 최종 성능에 어떻게 기여하는지, 그리고 컨텍스트 내 예제의 수에 따른 영향에 대한 철저한 분석을 수행합니다. 또한 플러그인 모델에 대한 적대적 공격의 효과와 이것이 SuperICL의 성능에 어떤 영향을 미치는지 살펴봅니다. 저희의 연구 결과는 대규모와 소규모, 클라우드와 로컬 모델을 결합할 수 있는 잠재력을 보여주며 대규모 언어 모델 시대에 지도 학습을 위한 유망한 새로운 패러다임을 보여줍니다. 2 관련 연구 컨텍스트 내 학습 원래 GPT-3 논문(Brown et al., 2020)에서 제안된 컨텍스트 내 학습(ICL)은 모델의 매개변수를 업데이트하지 않고도 새 작업에 LLM을 활용하는 새로운 패러다임으로 간주됩니다. 대규모 언어 모델이 패턴을 찾고 예측을 &quot;학습&quot;할 수 있도록 테스트 입력 앞에 몇 가지 샷 학습 예제를 프롬프트로 추가합니다. ICL은 기계 번역(Lin et al., 2021; Agrawal et al., 2022) 및 데이터 생성(Ye et al., 2022)과 같은 다운스트림 작업에 성공적으로 적용되었습니다. Few-shot 학습에서의 성공에도 불구하고 ICL의 주요 단점은 불안정성입니다. ICL의 성능은 선택된 컨텍스트 내 예제(Zhao et al., 2021)와 심지어 그 순서(Lu et al., 2022)에 민감합니다. 이러한 발견을 바탕으로 컨텍스트 구성에 초점을 맞춘 일련의 연구가 있습니다. LM-BFF(Gao et al., 2021)와 KATE(Liu et al., 2022)는 테스트 예제와 의미적으로 유사한 학습 예제를 선택합니다. 또 다른 연구 계열(Su et al., 2022; Levy et al., 2022; Ye et al., 2023)은 학습 세트에서 다양하고 대표적인 예제를 마이닝하는 데 중점을 둡니다. Zhang 등(2022)은 능동 학습과 강화 학습을 활용하여 ICL에 대한 예제를 선택합니다. 자가 적응형 ICL(Wu 등, 2022, 2023b)은 별도의 검증 세트를 사용하지 않고도 각 테스트 입력에 대한 최적의 컨텍스트 내 예제를 얻기 위한 2단계 검색 프레임워크를 제안합니다. 이러한 연구와 달리 SuperICL은 더 작은 모델을 감독 작업을 위한 대규모 언어 모델에 통합할 수 있음을 보여줍니다. 이러한 이전 연구와는 직교적이지만, 플러그인 모델을 전체 학습 세트로 미세 조정함으로써 SuperICL은 학습 세트에서 최적의 예제를 선택할 필요성을 줄입니다. 게다가 이전 연구에서는 ICL을 위한 언어 모델을 준비하는 방법도 조사합니다. Zhao 등(2021)은 레이블 분포와 순서의 영향을 줄이기 위해 빈 테스트 입력으로 교정을 제안합니다. MetaICL(Min 등, 2022a)은 언어 모델을 메타 학습하여 보이지 않는 작업으로 일반화하여 더 나은 ICL 성능을 제공합니다. Chen 등 (2022)는 ICL에서 언어 모델의 성능을 개선하기 위해 중간 작업으로 4개의 자기 감독 목표를 제안했습니다. 주목할 점은 Min et al. (2022a) 알고리즘 1 슈퍼 인 컨텍스트 학습(SuperICL) 필요 사항: 학습 세트 D = {(x1,y1), ..., (xn, Yn)}, LLM M, 미리 학습된 작은 언어 모델 P 보장: 예측 레이블 yt 및 선택적 설명 et 1: D에서 P를 미세 조정하여 미세 조정된 플러그인 모델 P&#39;를 얻음 2: D에서 예제 세트(xi, yi)를 무작위로 샘플링하여 인 컨텍스트 예제 세트 D&#39;를 만듬 3: D&#39;의 각 예제(xi, yi)에 대해 다음을 수행 4: y½가 예측 레이블이고 c¿가 신뢰 점수인 P&#39;로 y&#39; 및 c¿를 예측 5: 종료 6: 모든 (xi, Yi, Ci, Yi)를 연결하여 컨텍스트 C를 구성 7: 각 테스트 예제 xt에 대해 다음을 수행 8: 9: 10: 11: 테스트 예제에 대해 P&#39;로 y½ 및 ct를 예측 완전한 입력 I = C = (xt, Yt, Ct) 공식화 여기서 는 연결을 나타냄 M을 사용하여 I에서 yt를 예측(선택 사항) yt yt이면 M에게 P&#39; 12의 예측을 재정의하는 것에 대한 설명 et를 생성하도록 요청합니다. 끝 및 Chen et al.(2022)은 가중치를 업데이트해야 하므로 GPT-3/4와 같은 대규모 블랙박스 모델에는 적용할 수 없습니다. ICL의 성능을 개선하기 위한 연구 외에도 일부 연구에서는 ICL의 기본 메커니즘을 분석했습니다. Min et al.(2022b)은 레이블 공간, 입력 텍스트의 분포 및 시퀀스의 전체 형식이 ICL 성능의 핵심 요소라는 것을 발견했습니다. 또한 그들은 기본 레이블이 ICL 성능에 중요하지 않다고 주장하지만,
--- CONCLUSION ---
후속 연구(Yoo et al., 2022)와 모순됩니다. 또한 이전 연구에 따르면 ICL은 암묵적으로 베이지안 추론(Xie et al., 2022) 또는 경사 하강(Akyürek et al., 2022; von Oswald et al., 2022; Dai et al., 2022)을 수행할 수 있습니다. 언어 모델 플러그인 대규모 언어 모델은 외부 도구를 활용하여 기능을 개선할 수 있습니다. Toolformer(Schick et al., 2023)는 대규모 언어 모델이 외부 API를 호출하여 작업을 완료할 수 있도록 하는 특수 기호를 도입합니다. Visual ChatGPT(Wu et al., 2023a)는 비전 모델을 ChatGPT에 연결하여 멀티모달 생성을 허용합니다. HuggingGPT(Shen et al., 2023)는 ChatGPT를 사용하여 작업 계획을 수행하고 Hugging Face에서 사용 가능한 기능 설명에 따라 모델을 선택하고, 선택한 AI 모델로 각 하위 작업을 실행하고, 실행 결과에 따라 응답을 요약합니다. 이러한 작업과 달리, 저희의 작업은 고전적인 지도 학습을 기반으로 하며, 때로는 작은 언어 모델에서 &quot;해결된&quot; 것으로 간주되는 텍스트 분류와 같은 작업조차도 대규모 언어 모델과 결합하면 여전히 이점을 얻을 수 있음을 보여줍니다.3 Super In-Context Learning Super In-Context Learning(SuperICL)은 LLM을 로컬로 미세 조정된 소규모 모델과 결합하여 함께 작동하여 지도 작업의 성능을 개선할 수 있습니다. 소규모 모델은 플러그인 역할을 하여 작업별 지식과 예측을 제공하는 반면, 대규모 사전 학습된 모델은 일반적인 언어 이해에 초점을 맞춥니다. SuperICL의 전체 워크플로는 그림 1에 나와 있으며 전체 알고리즘은 알고리즘 1에 나와 있습니다.플러그인 모델 미세 조정 SuperICL 프로세스의 첫 번째 단계는 작업별 레이블이 지정된 데이터에서 ROBERTa(Liu et al., 2019)와 같은 작은 NLP 모델을 미세 조정하는 것입니다.전체 교육 데이터에 대한 이 미세 조정 프로세스는 모델의 크기가 작고 로컬 접근성이 뛰어나기 때문에 가능합니다.이는 레이블이 지정된 데이터의 사용이 LLM의 컨텍스트 길이에 의해 심각하게 제한되는 ICL과는 대조적입니다.미세 조정된 작은 모델은 다음과 같이 후속 단계에서 LLM의 플러그인으로 통합됩니다.컨텍스트 구성 다음으로, 작은 모델에서 제공하는 작업별 지식을 활용하기 위해 LLM에 대한 컨텍스트를 구성합니다.이 컨텍스트는 교육 데이터에서 무작위로 샘플링된 일련의 예제와 작은 플러그인 모델의 해당 예측으로 구성됩니다.예측에는 예측된 레이블과 연관된 신뢰 점수가 모두 포함됩니다. 표 1에 예가 나와 있습니다. 한편, 플러그인 모델에서 예측한 레이블을 통합함으로써 LLM은 입력 시험(a) 맥락 (b) 시험 입력 (c) 레이블 예측 (d) 설명 문장 1: 연방 요원 빌 폴리크로노풀로스는 30세 남자가 기소될지 여부는 알 수 없다고 말했습니다. 문장 2: 연방 요원 빌 폴리크로노풀로스는 어젯밤 멜버른 사건에 연루된 남자가 비무장이었다고 말했습니다. ROBERTa-Large 예측: 동일(신뢰도: 0.51) 레이블: 동일하지 않음 문장 1: 수요일에 메사 카운티 보건부는 서나일 바이러스의 인간 감염 사례 5건을 추가로 보고했습니다. 문장 2: 이번 주까지 45개 카운티에서 103건의 서나일 인간 감염 사례가 보건부에 보고되었습니다. ROBERTa-Large 예측: not_equivalent (신뢰도: 0.98) 레이블: not equivalent ... 문장 1: Cooley는 Muhammad도 Malvo의 공판 전 심리에서 증인으로 소환될 것으로 예상한다고 말했습니다. 문장 2: Lee Boyd Malvo는 수요일에 동료 저격수 용의자 John Allen Muhammad의 공판 전 심리에서 증인으로 소환될 예정입니다. ROBERTa-Large 예측: equivalent (신뢰도: 0.82) 레이블: not equivalent 예측을 재정의하는 데 대한 설명: 두 문장은 John Allen Muhammad와 Lee Boyd Malvo라는 다른 사람에 대해 이야기하고 있으므로 예측은 not_equivalent여야 합니다. 표 1: MRPC 데이터 세트에서 구성된 컨텍스트 및 추론 절차의 예. 먼저 감독 데이터 세트에서 샘플링하여 컨텍스트를 구성하고 플러그인 모델의 예측을 첨부합니다. 그런 다음 각 테스트 예제에 대해 대규모 언어 모델에 입력과 플러그인 모델의 예측을 기반으로 레이블을 예측하도록 요청합니다. 프롬프트를 사용하여 플러그인 모델에서 예측한 레이블이 재정의된 경우 모델에 결정을 설명하도록 요청합니다. 텍스트 필드 이름(예: 문장 1)은 데이터 세트에 제공된 원래 필드 이름입니다. ples, ground-truth 레이블 및 플러그인 모델의 전문 지식입니다. 이를 통해 LLM이 후속 의사 결정 프로세스에서 최종 예측을 생성하는 데 도움이 됩니다. 반면 신뢰도 점수는 플러그인 모델의 예측 불확실성을 측정합니다. 이러한 점수를 컨텍스트에 통합함으로써 LLM은 플러그인 모델이 매우 확신하는 예측을 신뢰하고 플러그인 모델이 불확실한 경우 더욱 신중할 수 있습니다. 또한 신뢰도 점수는 LLM의 주의를 더 어려운 컨텍스트 내 예제로 유도하여 이러한 어려운 사례에서 학습하고 잠재적으로 작업에 대한 전반적인 성능을 개선할 수 있습니다. 요약하자면, 예측된 레이블과 플러그인 모델의 연관된 신뢰도를 모두 고려하여 LLM은 주어진 예측을 따를지 아니면 작업에 대한 자체 이해에 의존할지 결정하여 전반적으로 더 정확한 예측을 도출합니다. 추론 컨텍스트가 구성되면 테스트 입력(표 1(b)에 표시된 예)이 컨텍스트와 연결되어 대규모 언어 모델에 대한 완전한 입력이 형성됩니다. 예측된 레이블과 신뢰도 점수를 포함하여 테스트 입력에 대한 플러그인 모델의 예측도 입력에 첨부됩니다. 따라서 LLM의 입력에는 컨텍스트, 테스트 입력 및 플러그인 모델의 예측이 포함됩니다. 그런 다음 LLM은 표 1(c)에 표시된 대로 테스트 입력에 대한 최종 예측을 생성합니다. 선택적으로 표 1(d)에 표시된 대로 LLM은 예측에 대한 설명을 제공하여 플러그인 모델의 예측을 무시하거나 따르기로 선택한 이유에 대한 통찰력을 제공할 수도 있습니다. 이러한 추가적인 해석 가능성은 결합된 SuperICL 모델의 의사 결정 프로세스를 이해하는 데 중요할 수 있습니다. 4 실험 4.1 실험 설정 벤치마크 우리는 전체 교육 세트에 액세스할 수 있는 전체 지도 설정에 중점을 둡니다.우리는 널리 사용되는 두 가지 벤치마크에 대한 실험을 수행합니다.자연어 이해 과제를 위한 GLUE 벤치마크(Wang et al., 2019)와 제로샷 교차 언어 자연어 추론 과제를 위한 XNLI 벤치마크(Conneau et al., 2018)로, 모델은 영어로 교육되고 다른 언어로 테스트됩니다.우리의 목표는 표준 벤치마크에서 SuperICL의 학습 능력을 조사하고 다국어 기능으로 더 작은 모델을 강화할 수 있는지 여부를 조사하는 것입니다.ICL과 방법 모두 MNLI-m MNLI-mm GPT-3.5 ICL ROBERTa-Large 80.88.82.89.SuperICL 89.89.SST-2 QNLI MRPC QQP COLA RTE Avg. 91.39 80.52 60.05 81.64 60.51 86.28 81.96.44 94.07 83.09 92.11 64.55 87.00 88.96.79 94.16 86.03 92.14 64.57 87.73 89.표 2: GLUE(Wang et al., 2019) 개발 세트에 대한 실험 결과. CoLA에 대한 메트릭은 Matthews Correlation이고 다른 모든 작업은 정확도를 사용합니다. Lang. GPT-3.5 ICL XLM-V SuperICL en 74.83.83.ar 60.70.72.bg 67.77.77.de 71.75.80.el 65.72.74.es 76.77.81.fr 74.77.77.hi 56.69.70.ru 65.73.76.SW 56.67.68.th 57.68.69.tr 66.72.72.ur 51.63.57.vi 62.72.74.zh 67.73.74.Avg. 64.73.74.표 3: XNLI(Conneau et al., 2018) 테스트 세트의 실험 결과. 측정 기준은 정확도입니다. SuperICL의 경우 생성된 레이블이 사전 정의된 레이블과 정확히 일치하는 경우에만 예측이 올바른 것으로 간주합니다.분석 실험의 경우 예산 제약으로 인해 MNLI, SST-2 및 MRPC의 세 가지 대표적 작업으로 구성된 GLUE 하위 집합에서 모델을 평가합니다.대규모 언어 모델 및 플러그인 OpenAI의 text-davinci-003 언어 모델(GPT-3.5라고도 함)을 사용합니다.GLUE 벤치마크의 경우 플러그인 모델로 ROBERTa-large(Liu et al., 2019)를 사용합니다.XNLI 벤치마크의 경우 플러그인 모델로 XLM-V(Liang et al., 2023)를 사용합니다.두 모델 모두 SuperICL의 플러그인 역할을 하도록 해당 작업에 맞게 미세 조정되었습니다.GLUE 작업의 경우 학습 세트에서 무작위로 32개의 예를 선택합니다.XNLI의 경우 입력이 다국어이므로 GPT-3.5에서 사용된 BPE 토크나이저는 더 긴 토큰 시퀀스를 생성합니다. 따라서 각 언어에 대해 최대 16개의 예를 사용합니다. 일부 언어(예: 태국어)의 경우 GPT-3.5의 최대 허용 시퀀스 길이인 4,096에 가능한 한 많은 예를 맞추었기 때문에 컨텍스트 내 예가 16개보다 적습니다. 주요 실험과 모든 분석 실험에서 동일한 컨텍스트 내 예와 플러그인 모델만으로 예측한 결과에 대해 SuperICL과 ICL(Brown et al., 2020)의 성능을 비교합니다. 4.2 주요 결과 GLUE 표 2에서 볼 수 있듯이 SuperICL은 GPT-3.5 ICL과 플러그인 모델 ROBERTa-Large보다 성능이 뛰어나며 각각 GLUE에서 평균 8과 1.22의 이점을 보였습니다. SuperICL은 모든 작업에서 기준선보다 일관되게 성능이 뛰어나 플러그인 모델의 성능을 저하시키지 않는 신뢰할 수 있는 선택이라는 점에 주목할 가치가 있습니다. XNLI XNLI의 경우, 표 3에 제시된 대로 XLM-V(Liang et al., 2023)는 다국어 작업을 위해 특별히 설계되었지만 GPT-3와 결합하면 대부분 언어에서 상당한 개선이 이루어질 수 있습니다. 그러나 SuperICL은 우르두어에 대한 XLM-V의 성능을 향상시키지 못합니다. GPT-3.5 ICL도 우르두어에 대한 성능이 좋지 않아 GPT-3.5가 우르두어와 같은 자원이 부족한 언어에 대한 기능이 부족할 수 있음을 언급할 가치가 있습니다. 이는 또한 GPT-3.5/ChatGPT(Lai et al., 2023)의 다국어성에 대한 최근 분석과 일치합니다. 또한 GPT3.5에서 사용된 BPE 토크나이저는 라틴어가 아닌 언어에 대해 더 많은 토큰을 생성하기 때문에 컨텍스트 내 예제의 수가 제한되어 모델의 성능에 부정적인 영향을 미칩니다. 우리는 다국어 토크나이저를 사용하고, 더 많은 비영어 데이터로 학습하고, 더 긴 최대 컨텍스트를 갖는 후속 GPT 모델이 교차 언어 SuperICL에 대해 더 나은 성능을 달성할 수 있다고 믿습니다.4.3 절제 연구 우리는 SuperICL에서 각 구성 요소의 효과를 이해하기 위해 절제 연구를 수행합니다.우리는 SuperICL에서 세 가지 구성 요소의 성능을 조사합니다.(a) 컨텍스트 내 예제로 구성된 컨텍스트 (b) 컨텍스트 내 예제와 테스트 입력 모두에서 플러그인 모델의 신뢰도 점수 (c) 테스트 입력에 대한 플러그인 모델의 예측.실험 결과는 표 4에 나와 있습니다.구성 요소 MNLI SST-2 MRPC (a) Ctxt.(b) Conf.(c) Ref. GPT-3.5 ICL ROBERTa-Large (1) ✓ (2) ✓ (3) X ✓ (4) X ✓ ✓ 80.80 91.39 60.88.68 96.44 83.81.23 92.43 65.88.75 96.83.88.89 96.44 83.88.84 96.44 83.89.31 96.79 86.표 4: 절제 연구의 실험 결과. (a) Ctxt.는 훈련 세트의 컨텍스트 내 예제를 의미합니다. (b) Conf.는 플러그인 모델의 신뢰 점수를 나타냅니다. (c) Ref.는 테스트 입력에 플러그인 모델의 예측을 사용하는지 여부를 의미합니다. 방법 MNLI SST-2 MRPC 0.22% 0.23% 12.50% %Overriden Overridden Accuracy 81.81% 100.00% 64.71% 표 5: 재정의된 예측의 통계.&quot;%Overridden&quot;은 전체 예제 수에서 플러그인 모델의 예측과 다른 최종 예측의 백분율을 나타냅니다. &quot;Overridden Accuracy&quot;는 재정의된 예측 중 올바른 예측의 백분율을 나타냅니다.모두 재정의됨(1) 먼저 테스트 입력에 대한 플러그인 모델의 예측을 제거하려고 시도합니다. 이는 컨텍스트 내 예제와 테스트 입력 간에 불일치를 생성하므로 ICL 성능에 상당한 부정적인 영향을 미칩니다. 흥미로운 점은 테스트 입력에 대한 플러그인 모델을 제거하더라도 SuperICL이 여전히 ICL보다 성능이 우수할 수 있다는 것입니다. 우리는 이것이 미세 조정된 ROBERTa에서 GPT-3.5로 작업 지식을 전송하는 지식 증류(Hinton et al., 2015)와 유사한 맥락 내 효과 때문이라고 생각합니다.(2) 우리는 SuperICL에서 신뢰도 점수를 제거하려고 시도하는데, 이로 인해 성능이 저하됩니다. 이는 GPT-3.5가 ROBERTA의 불확실성을 인식하지 못하고 결과적으로 예측을 재정의할 시기를 결정할 수 없기 때문입니다. 또한 지식 증류에서 소프트맥스 점수를 제거하는 것과 유사하게 신뢰도 점수를 제거하면 지식 전송이 덜 효과적입니다.(3) 모든 맥락 내 예제를 제거할 때 SuperICL은 본질적으로 테스트 입력에 대해 제로 샷 추론을 수행합니다. ROBERTa에 비해 약간 개선되었지만 맥락 내 예제를 추가하면 SuperICL이 신뢰도를 보정하고 ROBERTa의 예측을 재정의하는 방법을 배우는 데 도움이 됩니다. 또한 ICL 대 제로 샷 추론과 유사하게 맥락 내 예제를 추가하면 GPT-3.5가 자체 작업별 성능을 개선하는 데 도움이 됩니다. (4) 제로 샷 추론에서 신뢰도 점수를 추가로 제거해도 성능이 약간 감소합니다.4. 예측 재정의에 대한 분석 또한 표 5에 표시된 대로 GPT-3.5에 의해 재정의된 예측의 통계를 분석합니다.다양한 데이터 세트 간에 상당한 차이를 관찰할 수 있습니다.MNLI와 SST-2 모두에서 GPT-3.overrides는 최소한의 예제(ap#Examples0.0.0.0.0.1.Confidence 그림 2: 재정의에 대한 플러그인 모델 신뢰도의 효과. 그림은 모든 예제(파란색)와 MRPC에서 GPT-3.5에 의해 재정의된 최종 예측이 있는 예제(주황색)에 대한 ROBERTa 신뢰도의 분포입니다. 약 0.2%)이지만 정확도는 높습니다.반대로 GPT-3.5는 ROBERTa에 의해 만들어진 예측의 12.5%에 달하는 상당한 비율을 재정의하지만 정확도는 낮습니다. 이러한 결과는 SuperICL의 오버라이드 동작이 특정 데이터 세트와 플러그인 모델의 성능에 크게 의존한다는 것을 시사합니다. 플러그인 모델의 예측을 오버라이드하는 LLM의 의사 결정 프로세스에 대한 통찰력을 얻기 위해 그림 2에서와 같이 ROBERTa가 나타내는 신뢰 수준의 분포와 GPT-3.5가 이를 오버라이드하는 정도를 조사합니다. 결과에 따르면 플러그인 모델의 신뢰도가 낮을 때 GPT-3.5가 예측을 오버라이드하는 경향이 있는 패턴이 있습니다. 이러한 동작은 우리의 동기를 뒷받침하며 GPT-3가 신뢰도 점수를 통해 플러그인 모델의 예측과 관련된 불확실성을 인식한다는 것을 나타냅니다. 4.5 예제 선택에 대한 분석 우리는 다양한 컨텍스트 내 예제의 민감도를 분석하여 ICL과 SuperICL을 비교합니다. 공정한 비교를 위해, 우리는 다른 난수 시드를 사용하여 각 데이터 세트에 대해 컨텍스트 내 예제의 5개 배치를 무작위로 샘플링하여 동일한 MNLI SST-MRPC⚫ICL ROBERTa-Large SuperlCL ICL ROBERTa-Large -SuperICL ICL ROBERTa-Large -SuperICL 그림 3: ICL 및 SuperICL 성능에 대한 예제 수의 영향. 결과는 3회 실행의 평균입니다. MRPC SST-MNLI 방법 ICL ICL 난수 시드 방법 MNLI SST-MRPC Var.ICL 80.80 91.39 60.ROBERTa-Large SuperICL + ROBERTa 88.68 96.44 83.89.31 96.79 86.DeBERTa V3-Large 90.49 96.56 90.80.80 81.26 79.74 81.26 80.79 0.ROBERTa 88.68 88.68 88.68 88.SuperICL 89.31 88.94 88.79 89.17 88.78 0.91.39 94.04 94.38 93.12 93.46 1.ROBERTa 96.44 96.44 96.44 96.44 96.44 96.SuperICL 96.79 96.56 96.56 96.56 0.60.05 73.53 73.28 73.28 65.44 37.ROBERTa 83.09 83.09 83.09 83.09 83.SuperICL 86.03 87.99 87.75 84.31 86.52 2.ICL 표 6: 서로 다른 시드로 무작위로 샘플링한 예제 선택을 통한 ICL 및 SuperICL의 정확도 및 분산. SuperICL + DeBERTa 90.76 96.79 90.표 7: 다양한 플러그인 모델을 사용한 SuperICL의 실험 결과.테스트 세트 # 예제 ICL RR2 RAll 1000 1200 ICL과 SuperICL 모두에 컨텍스트 내 예제가 사용됩니다.표 I에 표시된 대로 결과에 따르면 ICL은 특히 MRPC에서 SuperICL에 비해 분산이 더 크고, 컨텍스트 내 예제 선택에 따라 성능이 크게 영향을 받습니다.반면에 SuperICL은 더 안정적인 성능을 유지하면서도 ICL과 ROBERTa보다 일관되게 성능이 우수합니다.SuperICL의 향상된 안정성은 대규모 지도 학습 세트에서 학습된 플러그인 모델의 추가 참조 예측 때문이라고 주장합니다.이를 통해 LLM은 ROBERTa의 예측을 수정하고 필요할 때 이를 재정의하는 방법에 집중하여 컨텍스트 내 예제의 차이로 인한 차이를 최소화할 수 있습니다. 4.6 예제 수에 대한 분석 그림 3에서 ICL과 SuperICL의 성능에 대한 예제 수의 효과를 비교합니다.보여진 바와 같이 SuperICL은 이미 단지 2개 또는 4개의 예제로 최상의 정확도를 달성할 수 있는 반면, ICL은 합리적인 정확도를 달성하기 위해 더 많은 예제가 필요합니다.또한, 더 어려운 데이터 세트에서59.50 52.40 52.58 54.ROBERTa-Large 41.60 27.40 24.58 30.SuperICL 56.10 42.70 44.17 47.표 8: ANLI에 대한 제로샷 결과(Nie et al., 2019).ICL과 SuperICL은 MNLI에서 샘플링한 컨텍스트 내 예제를 사용합니다.ROBERTa-Large 모델은 MNLI에서 미세 조정되었습니다.R1, R2 및 R3은 각각 첫 번째, 두 번째 및 세 번째 라운드의 적대적 공격을 나타냅니다. MRPC, SuperICL은 더 많은 맥락 내 예제가 있을 때 ROBERTA의 성능을 큰 폭으로 개선할 수 있습니다.4.7 플러그인 모델 분석 또한 플러그인 모델을 데이터 세트에서 미세 조정된 최첨단 모델인 DeBERTa V3-Large(He et al., 2021)로 대체하려고 시도했습니다.표 7에 제시된 결과는 SuperICL이 ROBERTa에 비해 개선 폭이 작지만 최첨단 모델의 성능을 계속 향상시킨다는 것을 보여줍니다.이러한 감소는 소형 모델과 대형 모델 간의 기능 격차가 작기 때문일 수 있습니다.그러나 앞으로 훨씬 더 진보된 대형 언어 모델을 사용하면 이 문제가 해결될 것으로 예상합니다.(1) MNLI 전제: 그런 다음 그는 술을 끊었습니다.가설: 그는 항상 술을 끊었습니다. ROBERTA 예측: 중립(신뢰도: 0.7) X 최종 예측: 모순 ✓ 설명: 전제는 그가 술을 끊었다고 말하는데, 이는 그가 전에 술을 끊지 않았다는 것을 의미하지만, 가설은 그가 항상 술을 끊었다고 말하는데, 이는 전제와 모순됩니다.(2) MNLI 전제: 할인이 없다면 아무도 주식을 사지 않을 것입니다.가설: 할인이 있다면 아무도 주식을 사지 않을 것입니다.ROBERTA 예측: 모순(신뢰도: 0.6) ✓ 최종 예측: 함축 X 설명: 전제와 가설은 본질적으로 동일한 진술이지만, 전제는 부정적 진술이고 가설은 긍정적 진술입니다.모델은 이를 모순으로 해석하지만 함축이어야 합니다.(3) SST-문장: 최근 기억 속의 스크린 판타지 모험은 클론의 마지막 45분만큼 화려한 쇼맨십을 보여주지 못했습니다. ROBERTA 예측: 부정적(신뢰도: 0.54) X 최종 예측: 긍정적 ✓ 설명: 이 문장은 실제로 긍정적인 진술로, 영화의 마지막 45분간의 쇼맨십을 칭찬합니다. 이 문장에는 부정적인 감정으로 해석될 수 있는 &quot;아니오&quot;라는 단어가 포함되어 있기 때문에 예측이 뒤집혔습니다. 표 9: SuperICL의 예측 및 설명 예. 맥락은 생략되었습니다. 여기의 프롬프트는 명확성을 위해 수정되었습니다. 원래 프롬프트 템플릿은 표 1에 나와 있습니다. 올바른 예측과 잘못된 예측은 각각 ✔와 X로 표시됩니다. 4.8 적대적 견고성 분석 또한 ANLI(Nie et al., 2019)에서 테스트하여 SuperICL의 적대적 견고성을 분석합니다. ANLI는 자연어 추론(NLI) 모델의 견고성과 일반화를 평가하기 위한 데이터 세트입니다. 16개의 전제-가설 쌍으로 구성되어 있으며, 이는 함의, 모순, 중립의 세 가지 클래스로 분류됩니다. 데이터 세트는 세 라운드(R1, R2, R3)로 구성되므로 세 가지 분할이 있으며, R3가 가장 어렵고 다양합니다. ANLI는 인간-모델-인-더-루프(human-and-model-in-the-loop) 훈련 방법을 사용하여 수집되며, 여기서 인간 주석자는 적대자 역할을 하여 다른 인간이 이해할 수 있는 동안에도 모델을 잘못 분류하도록 속이려고 시도합니다. 이 벤치마크는 ROBERTA가 데이터 구성의 R2 및 R3에서 공격을 받기 때문에 ROBERTa를 포함한 언어 모델에 도전하도록 설계되었습니다. 표 8에서 볼 수 있듯이 GPT-3.5 ICL은 다소 견고한 반면 ROBERTa-Large는 적대적 공격에 취약합니다. 그러나 이는 SuperICL에 직접적인 부정적인 영향을 미칩니다. SuperICL은 ROBERTa-Large보다 성능이 우수하지만 ICL보다 성능이 떨어집니다. 이 발견은 SuperICL의 성능이 통합된 플러그인 모델의 성능에 의존하고 플러그인 모델에 대한 적대적 공격이 SuperICL의 급격한 성능 저하로 이어질 수 있음을 시사합니다.5 사례 연구 우리는 SuperICL의 동작을 더 잘 이해하기 위해 사례 연구를 수행했으며, 표 9에 세 가지 예를 제시했습니다. 우리는 명확한 작업 지시가 없더라도 GPT-3.5가 작업을 이해하고 자체 추론을 설명하는 능력을 보여준다는 것을 발견했습니다.표 9의 첫 번째 예에서 GPT-3.5는 &quot;그&quot;가 술에 취하지 않았다는 전제의 의미를 효과적으로 파악합니다.그러나 두 번째 예에서 GPT-3.5는 부정으로 인한 혼란으로 인해 예측을 잘못 뒤집습니다.이 현상은 Hosseini et al.(2021) 및 Jang et al.(2023)에서 지적한 것처럼 LLM의 일반적인 결함으로 인식되었습니다. 마지막 예에서 GPT-3는 RoBERTa의 예측을 성공적으로 수정할 뿐만 아니라 ROBERTA가 잘못된 예측을 하는 이유를 설명하는 분석도 제공합니다.6 결론 및 향후 작업 이 논문에서는 대규모 언어 모델 API를 로컬에서 미세 조정된 플러그인 모델과 결합하는 간단하면서도 효과적인 방법인 SuperICL을 제안합니다.향후 작업에서는 대규모 언어 모델을 사용하여 보이지 않는 작업에 대한 로컬 플러그인 모델의 미세 조정을 계획하고 전체 워크플로를 자동화하는 방법을 살펴보고자 합니다.또한 이론적 분석은 SuperICL의 내부 메커니즘을 추가로 밝히는 데 중요할 수 있습니다.제한 사항 추가 지연 및 비용 SuperICL에는 직렬화된 소규모 및 대규모 모델이 포함되므로 총 추론 지연은 두 모델의 추론 지연의 합과 같습니다.또한 대규모 언어 모델의 API를 호출하는 것은 로컬에 배포된 소규모 모델을 사용하는 것에 비해 비용이 많이 들 수 있습니다.적대적 취약성 섹션 4.8에서 논의한 것처럼 플러그인 모델의 적대적 공격에 대한 취약성은 SuperICL에 상속될 수 있습니다. 따라서 플러그인 모델이 적대적 공격을 받을 때 전체 시스템은 ICL보다 성능이 떨어질 수 있습니다.제한된 평가 작업 공간과 예산 제한으로 인해 이 논문에서는 텍스트 분류만 조사합니다.그러나 텍스트 요약, 질의 응답 및 의미 구문 분석과 같은 생성 작업도 살펴보는 것이 흥미로울 것입니다.더 광범위한 영향 개선된 예측을 위해 크고 작은 언어 모델을 결합하는 기술인 SuperICL은 언어 모델의 잠재적인 사회적 편향을 공유합니다.우리의 접근 방식은 다른 방법에 비해 이러한 편향을 증폭시킬 가능성은 없지만 SuperICL이 편향을 증가 또는 감소시키는 데 영향을 미치는지 조사하는 것이 중요합니다.또한 작은 모델을 대규모 언어 모델의 추론에 플러그인으로 통합하면 탄소 발자국이 약간 더 높아져 환경에 부정적인 영향을 미칠 수 있습니다.따라서 실무자는 SuperICL을 사용할 때 성능 향상과 환경 비용 간의 상충 관계를 신중하게 고려해야 합니다.감사의 말 토론에 참여해 주신 Junheng Hao, Ziyi Yang, Dan Iter 및 Daya Guo에게 감사드립니다. 참고문헌 Sweta Agrawal, Chunting Zhou, Mike Lewis, Luke Zettlemoyer, and Marjan Ghazvininejad. 2022. Incontext examples selection for machine translation. arXiv 사전 인쇄본 arXiv:2212.02437. Ekin Akyürek, Dale Schuurmans, Jacob Andreas, Tengyu Ma, and Denny Zhou. 2022. What learning algorithm is in-context learning? investigations with linear models. arXiv 사전 인쇄본 arXiv:2211.15661. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei. 2020. 언어 모델은 few-shot 학습자입니다. NeurIPS에서. Mingda Chen, Jingfei Du, Ramakanth Pasunuru, Todor Mihaylov, Srini Iyer, Veselin Stoyanov, Zornitsa Kozareva. 2022. 자기 지도 학습을 통한 맥락 내 소수 학습 개선. NAACLHLT, 3558-3573페이지. Association for Computational Linguistics. Alexis Conneau, Guillaume Lample, Ruty Rinott, Adina Williams, Samuel R Bowman, Holger Schwenk, Veselin Stoyanov. 2018. Xnli: 언어 간 문장 표현 평가. arXiv 사전 인쇄본 arXiv:1809.05053. Damai Dai, Yutao Sun, Li Dong, Yaru Hao, Zhifang Sui, Furu Wei. 2022. GPT가 맥락 내 학습을 할 수 있는 이유는? 언어 모델은 메타 최적화 도구로 비밀리에 경사 하강을 수행합니다. arXiv 사전 인쇄본 arXiv:2212.10559. Tianyu Gao, Adam Fisch, Danqi Chen. 2021. 사전 훈련된 언어 모델을 더 나은 few-shot 학습자로 만들기. ACL-IJCNLP, 3816-3830페이지. Association for Computational Linguistics. Pengcheng He, Jianfeng Gao, Weizhu Chen. 2021. Debertav3: 그래디언트 분산 임베딩 공유를 사용한 일렉트라 스타일 사전 훈련을 사용하여 deberta 개선. arXiv 사전 인쇄본 arXiv:2111.09543. Geoffrey Hinton, Oriol Vinyals, Jeff Dean. 2015. 신경망에서 지식 증류. arXiv 사전 인쇄본 arXiv:1503.02531. Arian Hosseini, Siva Reddy, Dzmitry Bahdanau, R. Devon Hjelm, Alessandro Sordoni, Aaron C. Courville. 2021. 이해하지 못함으로 이해: 언어 모델에서 부정 모델링. NAACL-HLT, 1301-1312쪽. Association for Computational Linguistics. Joel Jang, Seonghyeon Ye, Minjoon Seo. 2023. 대규모 언어 모델이 실제로 프롬프트를 이해할 수 있을까? 부정 프롬프트가 있는 사례 연구. Transfer Learning for Natural Language Processing Workshop, 52-62쪽. PMLR. Viet Dac Lai, Nghia Trung Ngo, Amir Pouran Ben Veyseh, Hieu Man, Franck Dernoncourt, Trung Bui, Thien Huu Nguyen. 2023. 영어를 넘어서는 Chatgpt: 다국어 학습에서 대규모 언어 모델에 대한 포괄적 평가를 향해. arXiv 사전 인쇄 arXiv:2304.05613. 이타이 레비(Itay Levy), 벤 보긴(Ben Bogin), 조나단 베란트(Jonathan Berant). 2022. 다양한 데모를 통해 상황 내 구성 일반화가 개선됩니다. arXiv 사전 인쇄 arXiv:2212.06800. Davis Liang, Hila Gonen, Yuning Mao, Rui Hou, Naman Goyal, Marjan Ghazvininejad, Luke Zettlemoyer 및 Madian Khabsa. 2023. Xlm-v: 다국어 마스크 언어 모델의 어휘 병목 현상을 극복합니다. arXiv 사전 인쇄 arXiv:2301.10472. Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du 등 2021. 다국어 언어 모델을 사용한 Few-shot learning. arXiv 사전 인쇄본 arXiv:2112.10668. Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, Weizhu Chen. 2022. gpt-3에 대한 좋은 컨텍스트 내 예제는 무엇입니까? DeeLIO@ACL, 100-114페이지. Association for Computational Linguistics. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov. 2019. Roberta: 견고하게 최적화된 bert 사전 학습 접근 방식. arXiv 사전 인쇄본 arXiv:1907.11692. Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, Pontus Stenetorp. 2022. 환상적으로 정렬된 프롬프트와 그것을 찾는 방법: 소수의 프롬프트 순서 민감성 극복. ACL, 8086-8098페이지. Association for Computational Linguistics. Sewon Min, Mike Lewis, Luke Zettlemoyer, Hannaneh Hajishirzi. 2022a. Metaicl: 맥락에서 학습하는 법. NAACL-HLT, 2791-2809페이지. Association for Computational Linguistics. Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, Luke Zettlemoyer. 2022b. 시범의 역할 재고: 맥락 내 학습을 작동시키는 것은 무엇인가? EMNLP, 11048-11064페이지. Association for Computational Linguistics. Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, Douwe Kiela. 2019. Adversarial nli: 자연어 이해를 위한 새로운 벤치마크. arXiv 사전 인쇄본 arXiv: 1910.14599. OpenAI. 2023. Gpt-4 기술 보고서. Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, Thomas Scialom. 2023. Toolformer: 언어 모델은 스스로 도구를 사용하도록 학습할 수 있습니다. arXiv 사전 인쇄본 arXiv:2302.04761. Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, Yueting Zhuang. 2023. Hugginggpt: huggingface에서 chatgpt와 그 친구들을 사용하여 AI 작업 해결. arXiv 사전 인쇄본 arXiv:2303.17580. Hongjin Su, Jungo Kasai, Chen Henry Wu, Weijia Shi, Tianlu Wang, Jiayi Xin, Rui Zhang, Mari Ostendorf, Luke Zettlemoyer, Noah A Smith, et al. 2022. 선택적 주석은 언어 모델을 더 나은 fewshot 학습자로 만듭니다. arXiv 사전 인쇄본 arXiv:2209.01975. Johannes von Oswald, Eyvind Niklasson, Ettore Randazzo, João Sacramento, Alexander Mordvintsev, Andrey Zhmoginov, and Max Vladymyrov. 2022. Transformers learn in-context by gradient descent. arXiv 사전 인쇄본 arXiv:2212.07677. Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R. Bowman. 2019. GLUE: 자연어 이해를 위한 다중 작업 벤치마크 및 분석 플랫폼. ICLR에서. OpenReview.net. Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, Nan Duan. 2023a. Visual chatgpt: Visual Foundation 모델을 사용한 대화, 그림 그리기 및 편집. arXiv 사전 인쇄본 arXiv:2303.04671. Zhenyu Wu, YaoXiang Wang, Jiacheng Ye, Jiangtao Feng, Jingjing Xu, Yu Qiao, Zhiyong Wu. 2023b. Openicl: 맥락 내 학습을 위한 오픈소스 프레임워크. arXiv 사전 인쇄본 arXiv:2303.02913. Zhiyong Wu, Yaoxiang Wang, Jiacheng Ye, Lingpeng Kong. 2022. 자가 적응형 상황별 학습. arXiv 사전 인쇄 arXiv:2212.10375. Sang Michael Xie, Aditi Raghunathan, Percy Liang, Tengyu Ma. 2022. 암시적 베이지안 추론으로서의 맥락 내 학습에 대한 설명. ICLR에서. 오픈리뷰.net. Jiacheng Ye, Jiahui Gao, Zhiyong Wu, Jiangtao Feng, Tao Yu 및 Lingpeng Kong. 2022. Progen: 상황 내 피드백을 통한 점진적인 제로샷 데이터 세트 생성. EMNLP(조사 결과), 3671~3683페이지. 전산언어학협회. Jiacheng Ye, Zhiyong Wu, Jiangtao Feng, Tao Yu 및 Lingpeng Kong. 2023. 문맥 내 학습을 위한 구성적 예시. arXiv 사전 인쇄본 arXiv:2302.05698. 강민 유, 준엽 김, 형준 김, 현수 조, 휘열 조상, 이상우 이, 상구 이, 태욱 김. 2022. 실제 레이블이 중요합니다: 입력 레이블 데모에 대한 심층적 고찰. EMNLP, 2422-2437페이지. 계산 언어학 협회. 이밍 장, 시 펭, 첸하오 탄. 2022. 문맥 내 학습을 위한 활성 예제 선택. EMNLP, 9134-9148페이지. 계산 언어학 협회. 자오 자오, 에릭 월리스, 시 펭, 댄 클라인, 사미르 싱. 2021. 사용 전 교정: 언어 모델의 few-shot 성능 개선. ICML, 기계 학습 연구 논문집 제139권, 12697-12706쪽. PMLR.
