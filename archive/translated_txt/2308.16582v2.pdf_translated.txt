--- ABSTRACT ---
¹노스웨스턴 폴리테크닉 대학교 2화웨이 노아의 방주 연구실 3화웨이 UKRD 텍스트-이미지 합성에 사용되는 생성 모델인 안정적 확산은 다양한 크기의 이미지를 생성할 때 해상도로 인한 구성 문제에 자주 부딪힌다. 이 문제는 주로 모델이 단일 스케일 이미지 쌍과 해당 텍스트 설명에서 학습되기 때문에 발생한다. 게다가 무제한 크기의 이미지에 대한 직접 학습은 엄청난 수의 텍스트-이미지 쌍이 필요하고 상당한 계산 비용이 수반되기 때문에 실행 불가능하다. 이러한 과제를 극복하기 위해 ASD(Any-Size-Diffusion)라는 2단계 파이프라인을 제안한다. 이 파이프라인은 고메모리 GPU 리소스에 대한 필요성을 최소화하면서 모든 크기의 잘 구성된 이미지를 효율적으로 생성하도록 설계되었다. 구체적으로, ARAD(Any Ratio Adaptability Diffusion)라는 초기 단계는 제한된 비율 범위의 선택된 이미지 세트를 활용하여 텍스트 조건부 확산 모델을 최적화하고, 이를 통해 다양한 이미지 크기에 맞게 구성을 조정하는 기능을 개선한다. 원하는 크기로 이미지를 생성할 수 있도록 지원하기 위해 후속 단계에서 Fast Seamless Tiled Diffusion(FSTD)이라는 기술을 추가로 도입합니다. 이 방법을 사용하면 ASD 출력을 고해상도 크기로 빠르게 확대하여 씨밍 아티팩트나 메모리 오버로드를 피할 수 있습니다. LAION-COCO 및 MM-CelebA-HQ 벤치마크의 실험 결과는 ASD가 임의 크기의 잘 구조화된 이미지를 생성할 수 있으며 기존 타일 알고리즘에 비해 추론 시간을 2배 단축할 수 있음을 보여줍니다.
--- INTRODUCTION ---
텍스트-이미지 합성에서 안정적 확산(SD)(Rombach et al. 2022)이 중요한 진전으로 떠올랐습니다. 기존 SD 모델(Ruiz et al. 2023; Meng et al. 2023)은 이미지 구성 요소에 맞춰 정렬된 텍스트를 일반적으로 512 x 512픽셀 크기의 고품질 이미지로 변환합니다. 이러한 모델은 다양한 크기를 처리할 수 있는 기능이 있지만 해상도 변경에 눈에 띄게 어려움을 겪어 구성이 좋지 않습니다(예: 부적절한 자르기 및 부자연스러운 모양). 이는 그림 1(a)에서 보여지는 문제입니다. 이 문제의 근원은 주로 균일한 크기의 텍스트와 이미지 쌍으로 학습된 모델에 있으며, 여러 해상도에서 이미지를 처리하는 복잡성을 간과하고 있습니다. 결과적으로 이미지 구성에 결함이 관찰되었습니다. 텍스트 설명에 따라 임의의 종횡비에서 잘 구성된 이미지를 생성하기 위해 Mul* Equal Contribution *Contact 흰색 벽 앞에 있는 귀여운 테디베어. 테디베어는 부드럽고 푹신해 보이는 따뜻한 갈색 털을 가지고 있으며 갈색 나무 탁자 위에 앉아 있습니다.(c) 우리의 ASD (b) MD2.(a) SD2.900 x1024 x1024 x그림 1: 해상도로 인한 구성 불량.텍스트가 주어졌을 때, (a) SD2.1과 (b) MultiDiffusion 모델인 MD2.1은 다양한 크기의 이미지를 합성할 때 빨간색 상자에 구성 불량 문제를 제기하는 반면 (c) 우리의 ASD와는 대조적입니다.tiDiffusion 방법론(Bar-Tal et al. 2023)은 사전 학습된 텍스트 조건부 확산(예: 안정 확산)을 참조 모델로 활용하고 여러 참조 확산 프로세스를 활용하여 이미지 합성을 제어합니다.놀랍게도 전체 프로세스는 추가 학습이나 미세 조정 없이 실현됩니다.효율적이기는 하지만 참조 모델의 다중 해상도 이미지를 처리하는 데 따른 제한을 완전히 해결하지는 못합니다.결과적으로 이미지 생성은 최적이 아닌 구성 품질을 보일 수 있습니다. 근본적인 이유는 그림 1(b)에서 설명한 것처럼 단일 스케일 크기로 제한된 이미지에 대한 참조 모델의 학습과도 관련이 있습니다. 이 문제에 대한 직접적이고 매력적인 해결책은 모든 가능한 이미지 크기에 대처하도록 SD 모델을 학습시키는 것입니다. 그러나 이 접근 방식은 즉각적이고 상당한 장벽에 부딪힙니다. 즉, 이미지 비율의 무한한 다양성으로 인해 실질적으로 실행 불가능합니다. 게다가 광범위한 고해상도 이미지와 해당 텍스트 쌍을 수집하는 것도 어렵습니다. 사용 가능한 고품질 데이터 세트가 많더라도 SD의 고유한 픽셀 기반 특성은 상당한 계산 리소스를 필요로 하며, 특히 다양한 크기의 고해상도 이미지를 처리할 때 그렇습니다. SD 학습에 메가픽셀 이미지를 사용하는 경우 문제는 더욱 심각해집니다. 여기에는 RGB 이미지의 고차원 공간에서 광범위한 반복 함수 방정식과 기울기 계산이 포함되기 때문입니다(Ho, Jain, and Abbeel 2020). 학습된 모델이 준비된 경우에도 추론 단계는 시간이 많이 걸리고 메모리 집약적입니다. 경험적 관찰을 통해, 우리는 SD 모델을 사용하여 4K HD 이미지를 생성하려는 시도가 32GB 용량의 GPU에서 실행될 때 메모리 부족 오류를 유발한다는 것을 발견했습니다. 이 논문의 핵심 통찰력은 두 단계로 실행되는 선구적인 Any-Size-Diffusion(ASD) 모델을 소개하는 것입니다. 이 모델은 텍스트 프롬프트에서 임의의 크기의 고해상도 이미지를 합성할 수 있는 기능을 갖추고 있습니다. 이중 단계 접근 방식에서 ASD는 해상도로 인한 불량 구성을 효율적으로 처리할 뿐만 아니라 메모리 부족 문제를 성공적으로 회피합니다. 처음에는 상상할 수 있는 모든 이미지 크기를 수용해야 하는 복잡성에 직면하게 되는데, 이는 다루기 힘들어 보일 수 있는 문제입니다. 이를 해결하기 위해 첫 번째 단계에서 잘 정의되고 관리 가능한 비율 범위 내에서 작동하는 다중 종횡비 학습 전략을 도입합니다. 이 전략은 제안된 Any Ratio Adaptability Diffusion(ARAD) 모델을 최적화하는 데 사용됩니다. 결과적으로 지정된 범위 내에서 모든 크기에 적응할 수 있는 잘 구성된 이미지를 제작하는 동시에 GPU 메모리 소모를 줄일 수 있습니다. 모든 크기에 맞는 이미지를 생성하기 위해 두 번째 단계에서 이전 ARAD에서 생성된 이미지 출력을 확대하는 Fast Seamless Tiled Diffusion(FSTD)이라는 추가 방법을 제안합니다. 이음매 문제를 해결하지만 추론 속도는 저하되는 기존의 타일 확산 방법(Álvaro Barbero Jiménez 2023)과 달리 제안하는 FSTD는 타일 샘플링 확산 프로세스 내에서 암묵적 중첩을 설계합니다. 이 혁신은 일반적인 이음매 문제 없이 추론 속도를 높여 고화질 이미지 확대를 달성합니다. 요약하자면 이 논문의 기여는 다음과 같습니다. • 우리는 텍스트에서 모든 크기의 고해상도 이미지를 합성하는 2단계 파이프라인인 Any-Size-Diffusion(ASD) 모델을 개발한 최초의 회사로, 구성과 메모리 문제를 모두 해결합니다. • 정의된 비율 범위 내에서 구현된 다중 종횡비 훈련 전략을 도입하여 ARAD를 최적화하고, 지정된 범위 내에서 모든 크기에 적응 가능한 잘 구성된 이미지를 생성할 수 있습니다. • FSTD에서 암묵적 오버랩을 제안하여 이미지를 임의의 크기로 확대하여 이음 문제를 효과적으로 완화하고 동시에 기존 타일 알고리즘에 비해 추론 시간을 2배 단축합니다.
--- RELATED WORK ---
안정적 확산. 잠재 확산 모델(LDM)(Rombach et al. 2022)이 마련한 기초를 바탕으로, 확산 모델(Ho, Jain, and Abbeel 2020; Song et al. 2021)은 텍스트-이미지 생성(Nichol et al. 2022; Ramesh et al. 2022; Saharia et al. 2022), 이미지-이미지 변환(Dhariwal and Nichol 2021; Nichol and Dhariwal 2021) 및 다중 모달 생성(Ruan et al. 2023)을 포함한 다양한 도메인에서 상당한 성공을 거두었습니다. 복잡한 분포를 포착하고 다양하고 고품질의 샘플을 생성하는 강력한 능력 덕분에 확산 모델은 다른 생성 모델보다 뛰어납니다.
--- METHOD ---
ASD 출력을 고해상도 크기로 빠르게 확대하여 영상 끊김 현상이나 메모리 과부하를 방지합니다.
--- EXPERIMENT ---
영어: LAION-COCO 및 MM-CelebA-HQ 벤치마크에 대한 모든 결과는 ASD가 임의 크기의 잘 구조화된 이미지를 생성하여 기존 타일링 알고리즘에 비해 추론 시간을 2배 단축할 수 있음을 보여줍니다.소개 텍스트-이미지 합성에서 안정적 확산(SD)(Rombach et al. 2022)이 중요한 진전으로 등장했습니다.기존 SD 모델(Ruiz et al. 2023; Meng et al. 2023)은 이미지 구성 요소에 맞춰 정렬된 텍스트를 일반적으로 512 x 512픽셀 크기의 고품질 이미지로 변환합니다.이러한 모델은 다양한 크기를 처리할 수 있지만 해상도 변경에 눈에 띄게 어려움을 겪어 구성이 좋지 않습니다(예: 부적절한 자르기 및 자연스럽지 않은 모양).이 문제는 그림 1(a)에서 확인할 수 있습니다.이 문제의 근원은 주로 균일한 크기의 텍스트와 이미지 쌍으로 학습된 모델에 있으며 여러 해상도에서 이미지를 처리하는 복잡성을 간과하고 있습니다.결과적으로 이미지 구성에 결함이 관찰됩니다. 영어: 텍스트 설명에 따라 임의의 종횡비에서 잘 구성된 이미지를 생성하기 위해 Mul* Equal Contribution *Contact 흰색 벽 앞에 있는 귀여운 테디베어. 테디베어는 부드럽고 푹신해 보이는 따뜻한 갈색 털을 가지고 있으며 갈색 나무 탁자 위에 앉아 있습니다. (c) 우리의 ASD (b) MD2.(a) SD2.900 x1024 x1024 x그림 1: 해상도로 인한 열악한 구성. 텍스트가 주어지면 (a) SD2.1 및 (b) MultiDiffusion 모델인 MD2.1은 다양한 크기의 이미지를 합성할 때 빨간색 상자에 열악한 구성 문제를 제기하는 반면 (c) 우리의 ASD와 대조적입니다. tiDiffusion 방법론(Bar-Tal et al. 2023)은 사전 학습된 텍스트 조건부 확산(예: 안정적 확산)을 참조 모델로 활용하고 여러 참조 확산 프로세스를 활용하여 이미지 합성을 제어합니다. 놀랍게도, 전체 프로세스는 추가 교육이나 미세 조정 없이 실현됩니다. 효율적이기는 하지만 참조 모델의 다중 해상도 이미지를 처리하는 것과 관련된 제한을 완전히 해결하지는 못합니다. 결과적으로 이미지 생성은 최적이 아닌 구성 품질을 보일 수 있습니다. 근본적인 이유는 그림 1(b)에서 볼 수 있듯이 단일 스케일 크기로 제한된 이미지에 대한 참조 모델의 교육과도 관련이 있습니다. 이 문제에 대한 직접적이고 매력적인 해결책은 SD 모델을 모든 가능한 이미지 크기에 대처하도록 교육하는 것입니다. 그러나 이 접근 방식은 즉각적이고 중요한 장벽에 부딪힙니다. 즉, 이미지 비율의 무한한 다양성으로 인해 실질적으로 실행 불가능합니다. 게다가 광범위한 고해상도 이미지와 해당 텍스트 쌍을 수집하는 것도 어렵습니다. 사용 가능한 고품질 데이터 세트가 넘쳐나더라도 SD의 고유한 픽셀 기반 특성은 상당한 계산 리소스를 필요로 하며, 특히 다양한 크기의 고해상도 이미지를 처리할 때 그렇습니다. 이 문제는 SD 학습을 위해 메가픽셀 이미지를 사용하는 것을 고려할 때 더욱 심각해집니다.이는 RGB 이미지의 고차원 공간에서 광범위한 반복 함수 방정식과 기울기 계산을 포함하기 때문입니다(Ho, Jain, and Abbeel 2020).학습된 모델이 준비된 경우에도 추론 단계는 시간이 많이 걸리고 메모리 집약적입니다.경험적 관찰을 통해 32GB 용량의 GPU에서 SD 모델을 사용하여 4K HD 이미지를 생성하려고 하면 메모리 부족 오류가 발생한다는 것을 발견했습니다.이 논문의 핵심 통찰력은 두 단계로 실행되는 선구적인 Any-Size-Diffusion(ASD) 모델을 소개하는 것입니다.이 모델은 텍스트 프롬프트에서 임의의 크기의 고해상도 이미지를 합성할 수 있는 기능을 갖추고 있습니다.듀얼페이즈 방식에서 ASD는 해상도로 인한 불량 구성을 효율적으로 처리할 뿐만 아니라 메모리 부족 문제를 성공적으로 회피합니다.처음에는 상상할 수 있는 모든 이미지 크기를 수용하는 복잡성에 직면하게 되는데, 이는 난제로 보일 수 있습니다. 이를 해결하기 위해 첫 번째 단계에서 잘 정의되고 관리 가능한 비율 범위 내에서 작동하는 다중 종횡비 학습 전략을 도입합니다. 이 전략은 제안된 Any Ratio Adaptability Diffusion(ARAD) 모델을 최적화하는 데 사용됩니다. 결과적으로 지정된 범위 내에서 모든 크기에 적응할 수 있는 잘 구성된 이미지를 생성할 수 있으며 GPU 메모리 소비도 줄어듭니다. 모든 크기에 맞는 이미지를 생성하기 위해 두 번째 단계에서 이전 ARAD에서 생성된 이미지 출력을 확대하는 Fast Seamless Tiled Diffusion(FSTD)이라는 추가 방법을 제안합니다. 이음매 문제를 해결하지만 추론 속도는 저하되는 기존의 타일 확산 방법(Álvaro Barbero Jiménez 2023)과 달리 제안된 FSTD는 타일 샘플링 확산 프로세스 내에서 암묵적 중첩을 설계합니다. 이 혁신은 일반적인 이음매 문제 없이 추론 속도를 높여 충실도가 높은 이미지 확대를 달성합니다. 요약하자면, 이 논문의 기여는 다음과 같습니다. • 우리는 텍스트에서 모든 크기의 고해상도 이미지를 합성하는 2단계 파이프라인인 Any-Size-Diffusion(ASD) 모델을 개발한 최초의 기업으로, 구성 및 메모리 문제를 모두 해결합니다. • 우리는 정의된 비율 범위 내에서 구현되는 다중 종횡비 학습 전략을 도입하여 ARAD를 최적화하여 지정된 범위 내의 모든 크기에 적응 가능한 잘 구성된 이미지를 생성할 수 있습니다. • 우리는 FSTD에서 암묵적 오버랩을 제안하여 이미지를 임의의 크기로 확대하여 이음 문제를 효과적으로 완화하고 동시에 기존 타일 알고리즘에 비해 추론 시간을 2배 단축합니다. 관련 연구 안정적 확산. 잠재 확산 모델(LDM)(Rombach et al. 2022)이 마련한 기초를 바탕으로, 확산 모델(Ho, Jain, and Abbeel 2020; Song et al. 2021)은 텍스트-이미지 생성(Nichol et al. 2022; Ramesh et al. 2022; Saharia et al. 2022), 이미지-이미지 변환(Dhariwal and Nichol 2021; Nichol and Dhariwal 2021) 및 다중 모달 생성(Ruan et al. 2023)을 포함한 다양한 도메인에서 상당한 성공을 거두었습니다. 복잡한 분포를 포착하고 다양하고 고품질의 샘플을 생성하는 강력한 능력 덕분에 확산 모델은 다른 생성 방법보다 뛰어납니다(Goodfellow et al. 2014). 이 분야에서 안정적 확산(SD)(Rombach et al. 2022)은 텍스트에서 사실적인 이미지를 생성하는 선도적인 모델로 부상했습니다. 특정 크기(예: 512×512)에서 자연스러운 이미지를 생성하는 데 능숙하지만 이 임계값을 초과하는 크기에서는 종종 비자연스러운 출력을 생성합니다. 이러한 제약은 기존의 안정적 확산 모델이 고정된 크기의 이미지에 대해서만 독점적으로 학습되어 다른 크기에서는 고품질 구성이 부족하다는 사실에서 주로 비롯됩니다. 이 논문에서는 크기 제약 없이 고화질 이미지를 생성하도록 설계된 Any-Size-Diffusion(ASD) 모델을 소개합니다. 확산 기반 이미지 초고해상도. 이미지 초고해상도(SR)의 목적은 해당하는 저해상도(LR) 대응 이미지에서 고해상도(HR) 이미지를 유추하는 것입니다. 생성 모델을 사용하여 이미지를 확대하면 종종 저하에 대한 특정 가정이 생략되어 실제 응용 프로그램에서 어려운 상황이 발생합니다. 최근, 확산 기반 방법(Sahak et al. 2023; Saharia et al. 2023; Li et al. 2023; Ma et al. 2023)은 이러한 모델 내에서 생성적 사전 확률을 활용하여 실제 SR에서 주목할 만한 성공을 거두었습니다. 이러한 접근 방식은 효과적이기는 하지만 훈련 중에 상당한 계산 복잡성을 도입하며 잠재 공간 크기가 증가함에 따라 계산 요구 사항이 2차적으로 증가합니다. StableSR(Wang et al. 2023)이라는 최적화된 방법은 GPU 메모리 소비를 줄이는 동시에 성능을 향상시키기 위해 개발되었습니다. 그러나 이 방법은 여러 개의 겹치는 영역으로 나뉜 이미지를 처리할 때 시간 효율이 떨어질 수 있습니다. ASD 파이프라인의 다음 단계에서는 이미지 SR에서 추론 시간을 가속화하는 것을 목표로 하는 빠르고 매끄러운 타일 확산 기술을 제시합니다. 방법 모든 텍스트 프롬프트에서 다양한 크기의 고화질 이미지를 만들 때 해상도로 인한 구성 불량 문제를 해결하기 위해 ASD(Any Size Diffusion)라는 간단하면서도 효율적인 접근 방식을 제안합니다. 이 접근 방식은 텍스트-이미지 합성 과정을 두 단계로 나누어 단순화합니다(그림 2 참조).• 단계 I은 모든 비율 적응성 확산(ARAD)으로, 여러 종횡비 이미지에서 학습하고 텍스트 설명과 노이즈 크기에 따라 이미지를 생성하여 구성 불량 문제를 방지합니다.입력 텍스트 일치 크기 조정 단계 I: 모든 비율 적응성 확산 동결 LORA 트레이너 텍스트 조건 L ε +0000D T 단계 (a) 다중 종횡비 학습 생성된 이미지 GT 비율 집합 텍스트 조건 반지의 제왕의 간달프 입력 텍스트 및 크기 0000 0000; T-steps Embedding WxH~N(0,1) D (b) 추론 2단계: t단계에서 tT-steps로 빠르고 매끄러운 타일 확산 복사 D 다양한 크기 오프셋의 이미지 - ε 업스케일 모든 크기 이미지 t -t (c) 타일 샘플링의 암묵적 중첩 비중첩 타일 그림 2: 다음을 포함하는 모든 크기 확산(ASD) 파이프라인: 1) 1단계, 모든 비율 적응성 확산은 다양한 종횡비에 맞게 텍스트를 이미지로 변환하고 2) 1단계의 저해상도 이미지를 지정된 크기의 고해상도 버전으로 변환합니다.절차 (c) 타일 샘플링의 암묵적 중첩의 경우 실선 녹색 선 영역만 현재 노이즈 제거를 위해 UNetModel로 전송됩니다.2단계에서 점선 녹색 화살표는 이전의 노이즈 제거된 잠재 이미지에서 직접 복사된 영역을 나타내므로 전체 프로세스 내에서 효율성과 일관성을 향상시킬 수 있습니다. • FSTD(Fast Seamless Tiled Diffusion)로 알려진 2단계는 1단계의 이미지를 미리 정해진 더 큰 크기로 확대하여 궁극적으로 지정된 크기로 조정 가능한 고해상도 합성 이미지를 생성합니다. 파이프라인 그림 2에서 볼 수 있듯이 ARAD는 임의 비율 이미지 합성을 위한 텍스트 조건 잠재 확산 모델(LDM)(Rombach et al. 2022)을 기반으로 구현됩니다. 추론 프로세스 동안 ARAD는 사용자 정의 텍스트 프롬프트와 노이즈 크기(예: &quot;반지의 제왕으로부터 온 간달프&quot;)를 수신합니다. 처음에는 사전 학습된 텍스트 인코더(Cherti et al. 2023)가 이 프롬프트를 처리하도록 조정된 다음 텍스트 임베딩 Te(y)라고 하는 맥락적 표현을 생성합니다. 그런 다음 e로 표시되는 기본 해상도 크기의 랜덤 노이즈가 초기화됩니다. 텍스트 임베딩 p(e|y)에 조건화된 노이즈가 있는 입력은 UNetModel(Cherti et al. 2023)에 의해 점진적으로 노이즈가 제거됩니다. 이 프로세스는 T번 반복되며, DDPM 알고리즘(Song, Meng, Ermon 2020)을 활용하여 지속적으로 노이즈를 제거하고 잠재 표현 z를 복원합니다. 궁극적으로 디코더 D를 사용하여 노이즈가 제거된 잠재 이미지를 IE RH×W×3 이미지로 다시 변환합니다. 여기서 H와 W는 각각 이미지의 높이와 너비를 나타냅니다. 그런 다음 FSTD 모델은 이전 단계에서 생성된 이미지를 입력으로 받아들이고 이미지 조건 확산을 기반으로 추론을 수행합니다(Wang et al. 2023). 자세히 말하면, 이미지는 지정된 크기만큼 확대됩니다. 사전 학습된 시각 인코더 ε를 사용하여 결과 이미지 I&#39; Є RH&#39;×&#39;×³를 잠재 표현 z = E(I&#39;)로 매핑합니다. 정규 분포 기반 노이즈 ε ~ ·N(0, 1)을 더하면 노이즈가 있는 잠재 변수 z&#39; A(z)가 생성됩니다. 자체 p(z&#39;|2)에 조건 지어진 이미지는 UNetModel에 의해 점진적으로 반복되며, 제안된 타일 샘플링 I Є RH×W×³를 T 사이클 동안 활용합니다. 마지막으로 디코더 D를 사용하여 노이즈가 제거된 잠재 변수를 최종 출력으로 투영하여 잠재 공간을 효과적으로 이미지 영역으로 다시 변환합니다. 모든 비율 적응성 확산(ARAD) 이 단계에서는 ARAD를 제안하여 모델이 다양한 종횡비에 맞게 조정 가능한 이미지를 생성할 수 있는 기능을 제공하여 해상도로 인한 구성 불량 문제를 해결합니다. 이 단계는 주로 설계된 다중 종횡비 학습 전략을 통해 달성됩니다. 다중 종횡비 학습. 원본 이미지와 텍스트 쌍에서 직접 학습하는 대신 종횡비 전략을 사용하여 원본 이미지를 특정 비율의 이미지로 매핑합니다. 더 정확하게 말해서, 각각 특정 크기 {S1, S2, ..., Sn}에 해당하는 비율 집합 {1, 2, ..., rn}을 정의합니다. 여기서 n은 미리 정의된 종횡비의 수를 나타냅니다. 각 학습 이미지 x = RH×W×³에 대해 이미지 비율을 r = H/W로 계산합니다. 이 비율은 t=T t=T t-(a) 겹치지 않음 t-(b) 명시적으로 겹침 Z (x, y) (x+Ax, y + Ay) t=T t-seam | fast seamless | slow seamless | fast (c) 우리의 방법은 암묵적으로 겹침 그림 3: 다양한 타일링 전략의 비교: (a) 겹치지 않음, (b) 명시적으로 겹침, (c) 암묵적으로 겹침. 녹색 타일은 명시적 겹침이고 주황색 타일은 t-1 단계에서 암묵적으로 겹친 것입니다. 그런 다음 각 미리 정의된 비율과 비교하여 가장 작은 거리를 가진 m 하나를 참조 비율로 선택합니다. 인덱스 m은 arg min f(m) = {|r1−r|, · · ·,|rm−r|,···,|rn—r|}, (1) m에 의해 결정됩니다. 여기서 f(m)은 현재 비율과 사전 정의된 비율 사이의 가장 작은 거리를 나타냅니다. 따라서 이미지의 비율이 m번째 사전 정의된 크기 sm과 비슷한 경우 학습 이미지의 원래 크기가 sm으로 조정됩니다. 순방향 ARAD 프로세스. 학습 프로세스 동안 이미지와 해당 텍스트(x, y)로 구성된 쌍이 처리됩니다. 여기서 x는 RGB 공간 RH×W×³의 이미지를 나타내고 y는 연관된 텍스트를 나타냅니다. 고정된 시각적 인코더 Ɛ는 크기가 조정된 이미지 sm을 공간 잠재 코드 z로 변환하는 데 사용됩니다. 한편, 해당 텍스트는 OpenCLIP(Cherti et al. 2023)을 통해 텍스트 표현 70(y)으로 변환됩니다. 영어: 총 단계 T에 대해 p(zt|y), t = 1.T 형태의 조건부 분포는 잡음 제거 자동 인코더 ε0(zt, t, y)를 사용하여 모델링할 수 있습니다. 결과적으로 제안된 ARAD는 목적 함수 LARAD = E(x), ue~N(0,1)을 사용하여 학습할 수 있습니다.[||— €(zt, t, To(y))||}]. (2) ~N(0,1),t 고속 원활한 타일 확산(FSTD) 두 번째 단계에서는 StableSR(Wang et al. 2023)을 기반으로 구축된 학습이 필요 없는 접근 방식인 FSTD를 제안합니다. 이 접근 방식은 ARAD에서 생성된 이미지를 원하는 크기로 증폭합니다. 추론 중에 많은 계산 요구 사항 없이 효율적인 이미지 초고해상도를 달성하기 위해 타일 샘플링 방법 내에서 암묵적 오버랩 기술을 고안합니다. 타일 샘플링. 명확성을 위해, 확대된 이미지 I Є RH&#39;W&#39;x ‚가 M개의 작은 타일로 분할되어 {Pi Є Rh×w×³ | 1 ≤ i ≤ M}으로 표시되는 것을 고려해 보겠습니다. 여기서 w와 h는 각 타일의 너비와 높이를 나타냅니다. 먼저 각 타일 &#39;xP를 인코딩합니다. 인코더 함수 ε를 사용하여 랜덤 노이즈를 추가하여 노이즈가 있는 잠재 표현 Z = {Zi : E(Pi) + €i | Ei ~ · N(0, 1), 1 ≤ i ≤ M} 세트를 생성합니다. 그런 다음 각 노이즈 타일은 T 단계 동안 원래 타일을 기준으로 UNetModel에서 처리되어 노이즈가 제거된 잠재 표현 Z&#39; {Z&#39;i ei N(0, 1), 1 ≤ i ≤ M} 세트가 생성됩니다. 마지막으로 디코더 fD를 적용하여 이를 다시 이미지 공간으로 변환하고, 최종적으로 재구성된 이미지 = ~ I&#39; = {P} = Rh×w×³ | P{ = ƒd(Z;), 1 ≤i≤M}. (3) 여기서 P는 해당 노이즈 제거 잠재 타일에서 디코딩된 i번째 타일을 나타냅니다. 그러나 그림 3(a)에 나와 있듯이 세트의 두 타일이 분리되어 있는 경우 이음매 문제가 발생합니다. 이를 해결하기 위해 공통 픽셀을 공유하는 이웃 타일 간에 오버랩을 구현합니다(그림 3(b)). 명시적 오버랩을 늘리면 이 문제를 효과적으로 완화할 수 있지만 노이즈 제거 시간이 상당히 늘어납니다. 결과적으로 추론 시간은 겹치는 패치가 증가함에 따라 이차적으로 증가합니다. 실제로 추론 시간과 오버랩 양 사이의 균형을 맞추는 것이 실질적으로 중요합니다. 타일 샘플링의 암시적 오버랩. 이음매 문제를 피하면서 추론 시간을 단축하기 위해 타일 샘플링에서 암시적 오버랩을 제안합니다. 그림 3(c)에 나와 있듯이 확대된 이미지는 L개의 겹치지 않는 타일로 나뉘고 역 샘플링 프로세스 동안 분리된 노이즈 잠재 변수의 양을 일정하게 유지합니다. 각 샘플링 단계 전에 각 타일에 랜덤 오프셋을 적용하여 Z를 효과적으로 두 개의 구성 요소, 즉 Zs(타일링이 있는 이동된 영역)와 Zº(타일링이 없는 상수 영역)로 분할합니다.이는 수학적으로 Z = ZSUZc로 표현할 수 있습니다.초기 시간 단계에서 Zº = 0이라는 점에 유의하세요.각 샘플링에서 이동된 부분 Z³는 L개의 분리된 타일의 모음으로, Zs {Z | 1 ≤ i ≤ L}로 표시됩니다.여기서 각 Z는 이동된 타일을 나타냅니다.이동된 부분 Z³는 샘플링 프로세스 전체에서 동적으로 변경되는 L개의 분리된 타일로 구성됩니다.이 세그먼트 내에서 각 타일은 Zx,y Zyi+Ayi,xi+Axi(1 ≤ i ≤ L)로 표현됩니다.여기서 Ax와 y는 이전 단계에서 구현된 타일 Z에 대한 랜덤 오프셋을 나타냅니다.타일링이 없는 상수 섹션인 ZC의 경우 픽셀 값은 이전 샘플링 단계의 해당 잠재 변수에서 가져옵니다. 각 시간 단계 후에 Zc가 비어 있지 않고 Z° ± Ø로 기호적으로 표현된다는 점에 주목할 가치가 있습니다. 이 접근 방식은 타일 샘플링 중에 암묵적 중첩을 보장하여 이음 문제를 효과적으로 해결합니다. = 실험 실험 설정 데이터 세트. ASD의 ARAD는 다양한 종횡비의 90k 텍스트 이미지 쌍을 사용하여 LAION-Aesthetic(Schuhmann 2022)의 하위 집합에서 학습됩니다. 21개 비율에 걸쳐 21,000개 이미지(LAION-COCO(Schuhmann et al. 2022)에서 선택)와 해당 비율에 대한 2,100개 이미지가 포함된 MS-COCO(Lin et al. 2014)에서 구축된 MA-COCO에서 평가됩니다. 낮은 해상도와 높은 해상도 모두에서 2,824개 얼굴 이미지 쌍으로 구성된 MMCelebA-HQ(Xia et al. 2021)의 테스트 분할을 사용하여 FSTD와 전체 파이프라인을 평가합니다. 영어: Disney의 푸른 하늘 아래 펼쳐진 꿈의 성.[1024 x 2048] (a) SR-Plus (b) SR-Tile (c) SR-Tile-Plus (d) AR-Plus (e) AR-Tile (f) ASD(Ours) 화창한 날의 복잡한 디테일이 담긴 흰색의 웅장하고 우아한 빅토리아풍 저택.[4096 x 1024] (a) SR-Plus (b) SR-Tile (d) AR-Plus (e) AR-Tile (c) SR-Tile-Plus (f) ASD(Ours) 그림 4: (a) SR-Plus, (b) SR-Tile, (c) SR-Tile-Plus, (d) AR-Plus, (e) AR-Tile 및 (f) 제안하는 ASD를 포함한 다른 베이스라인과 제안하는 ASD 방법의 정성적 비교. 노란색 상자는 해상도로 인한 열악한 구성을 나타냅니다. 주황색 상자는 더 나은 구성을 나타냅니다. 빨간색 실선 상자는 빨간색 점선 상자를 확대한 것으로, 이음새 문제가 있는지 검사하는 것을 목표로 합니다. 당사의 ASD는 구성 품질과 추론 시간 모두에서 다른 제품보다 성능이 뛰어납니다. 표 1: 기준선에 대한 정량적 평가. (a) SR-Plus, (b) SR-Tile, (c) SR-Tile-Plus, (d) AR-Plus, (e) AR-Tile 및 (f) 당사의 ASD. &#39;S&#39;와 &#39;A&#39;는 각각 단일 비율과 임의 비율을 나타냅니다. 모든 테스트는 32G GPU에서 실행됩니다. 특히 동일한 GPU 메모리에서 당사의 ASD는 원래 SD 모델보다 최소 9배 더 높은 해상도를 달성합니다. 1단계 2단계 기능 경험치. 비율 타일 오버랩 구성 최대 해상도 이음매 FID↓ MM-CelebA-HQ IS ↑ CLIP↑ (a) S PoorN 118.2.27.S Х PoorY 111.96 (- 6.87) 2.46 (+0.35) 27.46 (+ 0.24) (c) S PoorN 111.06 (-7.77) 2.53 (+0.42) 27.55 (+ 0.33) (d) A ExcellentN 92.80 (- 26.03) 3.97 (+ 1.86) 29.15 (+ 1.93) (e) A ExcellentY 85.66 (-33.17) 3.98 (+ 1.87) 29.17 (+ 1.95) (f) A ExcellentN 85.34 (33.49) 4.04 (+ 1.93) 29.23 (+ 2.01) 구현 세부 정보. 제안하는 방법은 PyTorch(Paszke et al. 2019)에서 구현됩니다. 다중 종횡비 학습 방법을 활용하여 ARAD(LORA(Hu et al. 2021) 사용)를 배치 크기 8로 10,000단계로 미세 조정합니다. 최적화 도구로 Adam(Kingma and Ba 2014)을 사용하고 학습률을 1.0e-4로 설정합니다. FSTD(2단계 모델)는 학습이 필요 없으며 StableSR(Wang et al. 2023)을 기반으로 합니다. 추론하는 동안 ARAD에서 50단계의 DDIM 샘플러(Song, Meng, and Ermon 2020)를 채택하여 사용자가 정의한 종횡비에 따라 이미지를 생성합니다. 두 번째 단계에서는 StableSR을 따라 FSTD에 200단계 DDPM 샘플러(Ho, Jain, Abbeel 2020)를 사용합니다. 평가 지표. 벤치마크의 경우, FID(Heusel et al. 2017), IS(Salimans et al. 2016) 및 CLIP(Radford et al. 2021)를 포함하여 생성 텍스트-이미지 모델을 평가하기 위해 일반적인 지각 지표를 사용합니다. IS는 인간의 판단과 상관관계가 있으며, 충분히 많은 수의 샘플에서 지표를 평가하는 데 중요합니다. FID는 교란 수준을 매우 잘 포착하며 IS보다 노이즈 수준과 더 일관됩니다. CLIP 점수는 텍스트 프롬프트와 이미지 임베딩 간의 코사인 유사도를 측정하는 데 사용됩니다. 또한, 추가 메트릭(예: PSNR, SSIM(Wang et al. 2004) 및 LPIPS(Zhang et al. 2018))을 사용하여 ASD의 두 번째 단계의 초고해상도 능력을 평가합니다. PSNR 및 SSIM 점수는 YCbCr 색 공간의 휘도 채널에서 평가됩니다. LPIPS는 이미지 간의 지각적 차이를 정량화합니다. 기준선 비교 최신 확산 모델을 기반으로 비교를 위해 다음 6가지 기준선을 구축합니다. • SR-Plus: 다양한 크기의 텍스트 가이드 이미지를 직접 합성하기 위해 SD 2.1(Rombach et al. 2022)을 사용합니다. ⚫ SR-Tile: 타일 샘플링에서 비중첩이 있는 StableSR(Wang et al. 2023)을 사용하여 확대된 초기 이미지 생성에 SD 2.1을 사용합니다(Álvaro Barbero Jiménez 2023). ⚫ SR-Tile-Plus: SD 2.1(Rombach et al. 2022)로 시작하여 제안된 FSTD를 사용하여 출력을 정제하는 2단계 방법으로, 임의 차원의 이미지 합성을 용이하게 합니다.• AR-Plus: 다양한 크기에 걸쳐 직접 텍스트 기반 이미지 합성을 위해 제안된 ARAD 모델을 배포합니다.• AR-Tile: 초기 이미지 생성을 위해 ARAD 모델로 시작하여 타일 샘플링에서 비중복을 사용하는 StableSR을 통해 확대합니다.• ASD: 사용자 정의 가능한 차원의 이미지를 합성하도록 설계된 1단계의 ARAD와 2단계의 FTSD를 통합한 제안된 새로운 프레임워크입니다.양적 평가.표 1에 보고된 대로, 제안된 ASD 방법은 기준 방법보다 지속적으로 성능이 우수합니다.특히, ASD 모델은 (a) SR-Plus에 비해 FID 점수가 33.49 감소하고 IS 및 CLIP 점수가 각각 1.92 및 2.01 증가합니다. 32GB GPU에서 SR-Plus는 20482 해상도를 초과하는 이미지를 합성하지 못합니다. 반면, 당사의 ASD는 이러한 제약을 효과적으로 완화하여 동일한 하드웨어 조건에서 SR-Plus보다 최소 9배 더 높은 해상도를 달성합니다. 또한, 표 2: 당사의 ARAD와 다른 확산 기반 접근 방식의 비교. 21가지 다른 크기에 걸쳐 이미지 합성을 처리하는 구성적 능력을 비교합니다. MA-COCO 방법 MA-LAION-COCO FID↓ IS ↑ CLIP ↑ SD2.MD2.ARAD 14.32 31.25 31.14.57 28.95 32.13.98 34.03 32.FID↓ IS ↑ CLIP ↑ 42.50 30.20 31.43.25 28.92 30.40.28 29.77 31. 흰색 정장을 입은 마네킹. 576 X 768 512 XA 고급 스타일 장난감 스포츠 세단, CG 아트. 1024 XA 미니 티피 텐트 앞에 앉아 있는 포메라니안. (a) SD2.(b) MD2.1024 X(c) ARAD 그림 5: 시각적 결과 비교. (a) 안정 확산 2.1인 SD2.1, (b) SD 2.1을 기반으로 한 다중 확산인 MD2.1, (c) ARAD를 사용한 텍스트-이미지 합성의 구성 품질. 색상 상자는 구성이 좋지 않음을 나타냅니다. 우리는 또한 다음과 같은 관찰 결과를 얻었습니다.(i) 다중 종횡비 훈련 결과를 활용하면 다양한 비교에서 눈에 띄는 개선이 이루어졌으며, 특히 (a)-(d)에서 FID 점수가 118.83에서 92.80으로, (b)-(e)에서 111.96에서 85.66으로, (c)-(f)에서 111.06에서 85.34로 감소했습니다.(ii) 두 번째 단계에서 타일 알고리즘을 도입하면 무제한 해상도의 이미지를 생성할 수 있고 동시에 성능이 향상됩니다.예를 들어, (a)-(b)와 (d)-(c)를 비교할 때 FID 점수가 92.80에서 85.66으로 향상되었습니다.(iii) 타일 샘플링에서 오버랩을 구현하면 (b)-(c)와 (e)-(f)를 비교한 것에서 알 수 있듯이 이음매 문제가 효과적으로 해결됩니다.질적 비교.그림 4에서 볼 수 있듯이 ASD로 합성한 이미지는 다른 기준선 방법에 비해 뛰어난 구성 품질(예: 적절한 레이아웃)을 보입니다. 또한 ASD는 잘 구성되었을 뿐만 아니라 이음매 아티팩트가 없는 4K HD 이미지를 생성할 수 있습니다. 구체적으로, 텍스트 설명에 따라 AR-Plus 방법은 그림 4(a) 대 그림 4(d)에서 보여지듯이 SR-Plus보다 더 완전한 성을 생성하는 것으로 관찰되었습니다. SR-Plus와 비교했을 때 AR-Tile은 사실적인 이미지를 생성할 수 있지만 이음매 문제가 있다는 단점이 있습니다(그림 4(e) 참조). 반면, 그림 4(f)는 ASD가 이음매 아티팩트를 성공적으로 제거하고 잘 구성된 이미지를 생성하는 동시에 GPU 메모리 사용량을 최소화한다는 것을 보여줍니다. MA-LAION-COCO 유형 FID↓ 14.IS ↑ CLIP ↑ 32.53 32.14.10 33.모두 13.98 34.32.32.MA-COCO FID↓ IS ↑ CLIP↑ 41.28 29.58 31.40.25 29.63 31.40.28 29.77 31.표 3: 다양한 유형의 종횡비로 학습된 ARAD에서의 성능. &quot;모두&quot;는 9가지 종횡비를 나타냅니다. 표 4: FSTD에서 타일 샘플링의 다양성. MM-CelebA-HD 벤치마크에서 절제를 수행합니다. &quot;w/o&quot;, &quot;명시적&quot;, &quot;암시적&quot;은 각각 타일 샘플링에서 비중첩, 명시적, 암묵적 중첩을 설명합니다. &quot;고정&quot;, &quot;무작위&quot;는 다른 타일 오프셋 전략을 나타냅니다. 여기서, 인접한 두 타일의 겹침은 32×32입니다.MM-CelebA-HQ 시간 방법 겹침 및 오프셋 PSNR↑ SSIM↑ LPIPS↓↓ 겹침이 없는 프레임당 FID↓ 26.0.0.explicit 27.0.0.22.24.75.08s 166.8s implicit &amp; fixed 26.0.implicit &amp; random 27.0.0.08 21.37 75.01s 0.08 22.25 75.19s (a) 확대 LR (b) 겹침 없음 (c) 명시적 (d) 암묵적 그림 6: 다양한 방법에 대한 ×4의 초고해상도 결과. (a) 확대 LR(바이큐빅 방법), 타일 확산을 (b) 비중첩 및 (c) 명시적 겹침 타일과 시각적으로 비교합니다. (d) 타일 샘플링에서 암묵적 겹침을 사용하는 FSTD입니다. 특히 (d)는 (c)보다 2배 더 빠릅니다.ARAD 분석 제안한 ARAD가 해상도로 인한 구성 불량 문제를 해결하는 데 우수한지 확인하기 위해 특히 초기 단계에서 절제 연구를 수행합니다.ARAD의 영향.표 2는 ARAD의 성능을 강조하여 MA-LAION-COCO에서 원래 SD 2.1 및 MultiDiffusion(Bar-Tal et al. 2023)(MD2.1)에 비해 FID, IS 및 CLIP에서 각각 13.98, 34.03 및 32.의 개선을 보여줍니다.이러한 우수성은 그림 5에서 더 잘 설명됩니다.SD2.1과 MD2.1은 구성 문제가 있는 반면, ASD는 사용자가 정의한 텍스트 설명과 일치하는 이미지를 생성합니다.예를 들어, MD2.1은 흰색 옷에 대한 프롬프트에서 두 개의 겹친 파란색 옷을 잘못 생성하지만 이는 ASD 결과에 존재하지 않는 실수입니다.종횡비의 수에 대한 영향. 표 3은 다양한 종횡비에 따른 모델의 성능을 보여줍니다. 데이터에 따르면 학습 데이터 세트에서 종횡비 수를 늘리면 성능이 향상되고 FID 점수가 14.36에서 13.98로 감소합니다. 종횡비가 3개와 5개인 경우를 비교하면 FID 점수가 14.36에서 14.10으로 떨어지면서 상당한 개선이 나타났습니다. 종횡비를 더 늘리면 이러한 추세가 지속되어 FID 점수가 13.98로 감소합니다. 이 패턴은 모델 성능 향상에 있어 종횡비의 중요성을 강조합니다. FSTD 분석 그림 4와 표 1에서 제안된 FSTD의 효과를 증명했지만 이제 MM-CelebA-HD의 이미지 초고해상도 성능에서 이의 설계를 살펴보겠습니다. 표 4는 타일 샘플링의 다양성에 대한 절제 연구를 보고합니다. 자세한 내용은 보충 자료에서 확인하세요. 겹치는 타일의 중요성. 표 4의 처음 두 줄은 타일 샘플링에서 명시적 겹침과 겹치지 않음의 지각적 성능을 비교한 것입니다. 구체적으로, 명시적 중첩은 더 우수한 성능을 보입니다(예: PSNR에서 27.49 대 26.89). 그러나 비중첩 타일 샘플링은 명시적 중첩에 비해 약 2배 더 빠른 추론 시간을 제공합니다. 속도 면에서 이러한 이점이 있음에도 불구하고, 그림 6(b)는 비중첩 타일 샘플링과 관련된 이음매 문제를 명확히 드러내어 성능과 효율성 간의 상충 관계를 강조합니다. 암시적 중첩 대 명시적 중첩. 표 4와 그림 6(c)-(d)에 제시된 결과를 분석하면 타일 샘플링에서 암시적 중첩을 사용하면 지각적 지표와 시각적 표현에서 최상의 성능을 얻을 수 있음을 확인할 수 있습니다. 표의 마지막 열을 자세히 살펴보면 타일 샘플링에서 암시적 중첩에 대한 추론 시간이 중첩 없이 타일링하는 경우와 거의 동일함을 알 수 있습니다. 게다가 암시적 중첩을 구현하면 추론 시간이 166.8초에서 약 75.0초로 성공적으로 단축되었습니다. 이 절제 연구는 제안된 FSTD 방법의 우수성을 검증하여 성능 품질과 추론 시간 간의 최적의 균형을 달성하는 능력을 강조합니다. 다양한 오프셋 전략의 효과. 표 4의 마지막 두 줄은 암묵적 오버랩 타일 샘플링에서 랜덤 오프셋을 사용하는 이점을 보여줍니다. 구체적으로, 암묵적 오버랩에서 고정 및 랜덤 오프셋 방법을 비교할 때 랜덤 오프셋은 27.53의 PSNR 값을 생성하여 26.83으로 등록된 고정 오프셋보다 성능이 우수합니다. 다른 지각적 지표와 시각적 성능 지표에 대한 결과는 거의 동일한 것으로 나타났으며, 이 맥락에서 랜덤 오프셋을 선호한다는 것을 더욱 강조합니다.
--- CONCLUSION ---
이 연구에서는 모든 텍스트 프롬프트에서 고화질 이미지를 만드는 데 있어 해상도로 인한 구성 불량의 과제를 다룹니다. ARAD와 FSTD로 구성된 방법인 Any Size Diffusion(ASD)을 제안합니다. 다중 종횡비 이미지로 학습된 ARAD는 특정 크기 내에서 잘 구성된 이미지를 생성합니다. 타일 샘플링에서 암묵적 오버랩을 활용하는 FSTD는 이전 단계의 출력을 모든 크기로 확대하여 GPU 메모리 소비를 줄입니다. ASD는 실제 장면에서 양적, 질적으로 검증되어 향후 작업에 대한 귀중한 통찰력을 제공합니다. 부록 ASD 방법론 세부 정보 이 섹션에서는 제안된 Any Size Diffusion(ASD) 파이프라인에 대한 포괄적인 분석을 제시합니다. 먼저 1단계에서 구현된 다중 종횡비 학습 전략을 설명합니다. 그런 다음 2단계에서 채택한 타일 샘플링 방식에 내재된 암묵적 오버랩 특성을 철저히 검토합니다. 1단계: 모든 비율 적응성 확산(ARAD) 알고리즘 1은 제안하는 다중 종횡비 학습 전략에 대한 자세한 설명을 제공합니다. 각 키는 고유한 종횡비를 나타내고 각 값은 특정 크기에 해당하는 9개의 미리 정의된 키-값 쌍을 설정합니다. 크기가 다양한 학습 이미지는 알고리즘 1의 4-12행에 지정된 대로 이 다중 종횡비 전략에 따라 처리됩니다.알고리즘 1: 다중 종횡비 학습 전략 1 입력: 이미지 Ã € RH×W×³, 비율 크기 사전 Dr→s {r1 : 81, T2 : 82, · · ·, 19 : 89}; r→s= 2 출력: 모델 학습을 위한 크기 조정된 이미지; 3 이미지 비율 계산 r = 4 minValue = ∞ 초기화; 5 minIndex = 0 초기화; 영어: {1, 2, 에서 각 비율 r¿에 대해 6, 거리 계산 = H알고리즘 2: 제안하는 FSTD에 대한 절차. 입력: 이미지 I Є RH×W×³ 출력: 이미지 T&#39; Є RH×W×2 ► 1단계: 타일 샘플링 준비 3 입력 이미지 I를 M개의 분리된 타일 세트로 나눕니다. {Phxw×3 | 1≤i≤M}; {P1, P2, · ··‚Pм}에서 각 타일 P¿에 대해 4 do /* 잠재 노이즈에 랜덤 노이즈를 추가합니다. */ L₁ = E (Pi) + €i ;7 end; 8 따라서 M개의 분리된 잠재값 {L1, L2,, LM}이 있습니다.10 2단계: 암시적 중첩 타일 샘플링 11 Z³ = {L1, L2,, LM} 및 Zc 및 ZZS UZº이고 전체 단계는 T라고 가정합니다.13 Z = {L1, L2, 14 초기화 Z = 0; 15 초기화 ZT = ZU Z; , r9} do = | r — ri | ; 거리 minValue이면 = minIndex = imin Valuei = i + 1 ; 12 end; 거리; , LM}; 17 타일의 암시적 중첩 18 {T - 1,..., 0}에서 각 시간 단계 t에 대해 임의의 오프셋(Ax, Ay)을 설정합니다. {L1, L2, …, Lм}의 각 타일 Li에 대해 Li‚xi‚yi = Li‚xi+^xi‚Yi+^Yi; end; /* Zs 및 Zc 업데이트 */ = 0, Z$ = {L1,x1,y1, L2,x2,y2,···, LM,xm‚yм} 타일 개수는 일정하게 유지됨; 13 minIndex를 사용하여 Dr→s에서 rm, Sm을 검색함; 14 모델 학습을 위해 이미지 I의 크기를 sm으로 조정함 2단계: 빠른 원활한 타일 확산(FSTD). 알고리즘 2는 저해상도 이미지를 H x W의 대상 해상도로 효율적으로 업스케일링하도록 설계된 제안된 고속 연속 타일 확산(FSTD) 기술의 단계별 절차를 설명합니다. 처음에는 알고리즘 2의 1행에서 7행까지 설명된 대로 입력 저해상도 이미지를 M개의 겹치지 않는 타일로 분할하고 각각을 별도의 잠재 변수 {L1, L2, · · ·‚ĽM}·로 표현합니다. 이러한 잠재 변수는 8행에서 설명한 대로 집합 Z를 형성합니다. 특히 Z는 11행에서 가정한 대로 이동된 영역 Zs와 상수 영역 Zº의 두 가지 고유한 구성 요소로 구성됩니다. 전자는 타일링 노이즈 제거를 통해 처리하도록 지정되는 반면, 후자는 현재 시간 단계에서 타일링 프로세스에서 제외됩니다. AtZ = Zt+1 \ Z{ ;/* 업데이트된 잠재 노이즈 제거 */각 타일에 대해 Li,xi,yi in Zi do| UNetModel을 적용하여 (Li,xi,yi)의 노이즈를 제거합니다.끝; Z₁ = ZUZ 및 Z Ø; 31 끝; 33 T 시간 단계에 대한 노이즈를 제거한 후, Z&#39; = Zo; 34 결과적으로 Z&#39; 및 I&#39; = D(Z&#39;)가 됩니다. 13-15행에 표시된 대로 초기 7번째 시간 단계에서 Zs는 {L1, L2,,LM}으로 초기화되고 Zc는 공집합으로 초기화됩니다. 이는 각 타일의 초기 오프셋이 0으로 설정되기 때문입니다. 17-31행에서 보여지는 대로 알고리즘의 핵심에는 &#39;타일 샘플링의 암묵적 중첩&#39;이라는 새로운 메커니즘이 있습니다. 이 메커니즘은 안정된 확산 과정에서 사용되는 비타일 샘플링 방법에 비해 추론 시간과 GPU 메모리 소비를 크게 줄이도록 고안되었습니다. 각 시간 단계에 대해 알고리즘은 이러한 잠재 변수의 수량을 불변으로 유지하면서 해당 위치를 무작위로 오프셋합니다. 이는 Z¾ € {L1,x1,y1, L2,x2,y2?&#39; , LM,xм,чм}로 표시되는 업데이트된 이동 영역과 새로운 상수 영역 Z₁ = Zt+1 \ Z로 나타납니다. 특히 두 번째 노이즈 제거 단계부터 Z는 비어 있지 않은 집합이 되며 이 상수 영역 내의 각 픽셀은 이전 노이즈 제거 잠재 변수의 해당 픽셀과 동일한 값을 유지합니다. T 시간 단계 후에 반복적 절차는 Z&#39;로 표시되는 새로운 노이즈 제거 잠재 집합을 얻습니다. 마지막 단계에서 알고리즘은 이 잠재 집합 Z&#39;를 사용자 정의 크기 H×W×3의 이미지로 다시 디코딩하여 최종 초고해상도 출력 이미지를 생성합니다. Ꮇ 구현 세부 정보 이 섹션에서는 다중 종횡비 학습 접근 방식과 관련된 구현 세부 정보를 자세히 설명하고 타일 샘플링 전략에 필수적인 구성을 설명합니다. 다중 종횡비 학습. 우리는 표 5에 열거된 대로 각각 해당 크기 사양과 연관된 9개의 고유한 종횡비 세트를 설정합니다. 학습을 시작하기 전에 이미지는 알고리즘 1에서 규정한 대로 미리 정해진 차원으로 체계적으로 크기가 조정됩니다. 그런 다음 동일한 종횡비를 나타내는 이미지를 확률적 배치로 통합한 다음 모델 학습의 입력으로 사용합니다. 타일 샘플링의 명시적 및 암묵적 중첩. 타일 샘플링의 맥락에서 우리는 두 가지 고유한 전략, 즉 명시적 중첩 구성과 암묵적 중첩 구성을 살펴봅니다. 주목할 점은 두 전략 모두에서 입력 이미지와 타일의 크기를 사용자가 매개변수화할 수 있다는 것입니다. 명시적 중첩 구성의 경우 타일 수와 중첩 간의 관계를 다음과 같이 수학적으로 공식화합니다. Wimage Х Himage Ntiles ], (4) (Wtile - 중첩) (Htile 중첩) 여기서 Win image와 Himage는 각각 입력 이미지의 너비와 높이를 나타내고 Wtile과 Htile은 각 타일의 해당 크기를 나타냅니다. 대조적으로, 암묵적 오버랩 전략은 기존에 각 타일의 크기를 512x512로 구성하며 인접한 타일 간에 오버랩이 없습니다. 게다가 잠재 변수의 공간적 차원은 64x64입니다. 오버랩의 한 형태를 도입하기 위해, 우리는 이러한 타일링된 잠재 표현의 변환 이동을 제어하도록 설계된 랜덤 오프셋 전략을 채택하여 타일의 암묵적 오버랩을 달성합니다. 특히 MM-CelebA-HQ(Xia et al. 2021) 벤치마크에서, 우리는 256x256 크기의 저해상도 이미지와 함께 1024x1024 크기의 고해상도 이미지를 활용합니다. 표 5: 9개의 사전 정의된 비율-크기 쌍의 사전. 각 비율은 사전 정의된 이미지 크기에 해당합니다. 크기 # 비율 1.512 x 0.576 x 1.768 x 0.576 x 1.1024 x 0.640 × 1.1024 × 0.512 × 2.1024 × 표 6: FSTD에서 서로 다른 랜덤 오프셋 범위의 효과. 256 x 256 크기의 저해상도 이미지를 1024x1024로 업스케일링하여 MM-CelebA-HD 벤치마크에서 절제를 수행합니다. 랜덤 오프셋 범위는 16, 32 및 48입니다. 회색 행은 이 방법의 기본 설정입니다. MM-CelebA-HQ 오프셋 범위 PSNR↑ SSIM↑ LPIPS↓ FID↓ 이미지당 시간27.0.0.22.75.39초27.0.27.0.0.08 22.22.75.19초 75.21초 추가 절제 연구 이 섹션에서는 제안된 모델에 대한 심층 분석을 수행하기 위해 광범위한 절제 연구를 제시합니다.분석은 두 가지 주요 구성 요소로 나뉩니다.첫 번째 구성 요소는 특히 Fast Seamless Tiled Diffusion(FSTD) 기술에 초점을 맞추고 두 번째 구성 요소는 전체 파이프라인에 대한 포괄적인 평가를 포함하며, 이를 Any Size Diffusion(ASD)으로 표시합니다.FSTD에서 랜덤 오프셋 범위의 영향.표 6에서 자세한 분석을 제시하여 랜덤 오프셋 범위가 MM-CelebA-HQ 데이터 세트 내 이미지의 초고해상도 성능에 최소한의 영향을 미친다는 것을 보여줍니다. 구체적으로, 오프셋 범위가 16, 32, 48일 때 PSNR 점수는 놀라운 일관성을 보이며 각각 27.51, 27.53, 27.52의 값을 기록했습니다. 나아가, 이러한 별개의 오프셋 범위에 걸친 추론 시간은 비슷하게 균일하게 유지됩니다. 이 관찰 결과는 다양한 오프셋 매개변수에서 일관되게 좋은 성능을 보이므로 구성의 이 측면에서의 변화에 대한 회복성을 보여주기 때문에 우리 접근 방식의 견고성을 강조합니다. 표 7: 다양한 수의 명시적 타일에 걸친 성능 비교. 256 x 256의 저해상도 이미지를 1024x1024로 업스케일링하여 MMCelebA-HD 벤치마크에서 절제를 수행합니다. 겹침에 대한 전체 타일 수는 Eq 4에 의해 계산될 수 있다. 방법 겹침 N타일 PSNR↑ w/o26.0.27.50 (+0.61) 0.MM-CelebA-HQ SSIM↑ LPIPS↓ FID↓↓ 0.09 22.0.09 23. 이미지당 시간27.0.0.09 24.27.0.0.24.75.1초 148.7초 166.8초 182.6초 (+33.9) SR-Plus Ours ASD31.692 OOM OOM OOM OOM OOM31.30.802 31.28.27. CPU 메모리 비용(G)17.10.13.8 -10.258 강력한 신비로운 마법사 역의 엠마 왓슨, 번개 마법을 걸고, 세부적인 의상 5122 1024² 20482 4096² 81922 163842² 18432² 생성된 이미지 해상도(픽셀) 그림 7: GPU 메모리 비용(G) 대 이미지 해상도(픽셀) 측면에서 SR-Plus와 저희 ASD 비교. SR-Plus는 다양한 크기의 이미지를 생성하는 데 사용된 원래 SD 2.1 모델입니다. OOM은 메모리 부족 오류의 약자입니다. 실험은 32G GPU에서 수행되었습니다. 명시적 오버랩 타일 샘플링에서 타일 수 또는 오버랩 영역에 미치는 영향. 표 7은 이미지 초고해상도에서 타일 오버랩과 관련된 지각적 품질과 계산 효율성 간의 균형을 보여줍니다. 주목할 점은 타일 수가 증가함에 따라 지각적 지표가 상응하는 수준으로 향상되지만, 이는 계산 시간이 증가한다는 대가를 치릅니다. 예를 들어, 16픽셀 겹침이 있는 타일은 겹치지 않는 타일에 비해 더 우수한 지각적 지표를 나타내어 PSNR 점수에서 0.63의 현저한 향상을 보입니다. 그러나 이러한 향상에는 추론 시간이 75.1초에서 148.7초로 상당히 늘어납니다. 또한 표의 두 번째 행에 제시된 결과와 비교할 때 48픽셀의 타일 겹침은 PSNR 점수가 27.50에서 27.64로 향상되지만 추론 시간은 33.9초가 더 걸립니다. 다른 해상도의 이미지 생성 성능. 그림 7은 32G GPU 메모리 제약 하에서 작동하는 기준 SR-Plus 모델과 관련하여 제안된 Any Size Diffusion(ASD) 방법의 비교 효율성을 강조합니다. 구체적으로, 10242 및 2048² 크기의 이미지를 생성하는 맥락에서 ASD 알고리즘은 SR-Plus 모델보다 일관되게 더 효율적인 GPU 메모리 사용을 보입니다. 예를 들어, 1024² 크기의 이미지를 생성할 때 ASD는 13.44G의 메모리를 사용하는 반면 SR-Plus는 17.45G를 사용합니다. 20482개의 이미지의 경우 ASD의 메모리 사용량은 27.73G인 반면 SR-Plus의 사용량은 31.69G입니다. 중요한 점은 SR-Plus 모델이 최대 해상도가 20482로 제한되어 사용 가능한 GPU 메모리를 초과하는 반면, ASD 방식은 최대 18432²의 이미지 해상도를 수용하도록 개발되었다는 것입니다. 이는 SR-Plus 모델의 최대 용량보다 9배나 증가한 것입니다. (a) SR-Plus (b) AR-Plus 그림 8: 시각적 비교: SR-Plus(원래 SD 2.1) 대 AR-Plus(다중 종횡비 학습을 통한 미세 조정된 SD 2.1). 노란색 상자는 구성이 좋지 않음을 의미합니다. 4K 및 8K 이미지 해상도 달성. 그림은 원래 SD 2.1 모델인 SR-Plus(Rombach et al. 2022)와 대조하여 ASD 방법의 향상된 고해상도 이미지 생성 기능을 보여줍니다.SR-Plus는 512 x 512픽셀을 초과하는 해상도에서 구성이 저하됩니다.반면에 SD 2.1의 다중 종횡비 학습을 통해 개발된 AR-Plus는 이러한 저하를 해결하지만 32GB GPU 제약 하에서 2048 x 2048픽셀 출력으로 제한됩니다.겹치지 않는 타일 알고리즘은 이러한 제한을 개선하지만 그림 9(a)에서 볼 수 있듯이 이음매 아티팩트가 발생합니다.타일 샘플링에서 암묵적 겹침을 구현하는 솔루션은 이음매 문제를 해결하고 그림 9(b)에 결과가 나와 있습니다.따라서 ASD 방법은 고품질 4K 및 8K 이미지를 효과적으로 생성합니다.참고 문헌 Bar-Tal, O.;Yariv, L.;Lipman, Y.; 및 Dekel, T. 2023. MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation. ICML에서. Cherti, M.; Beaumont, R.; Wightman, R.; Wortsman, M.; Ilharco, G.; Gordon, C.; Schuhmann, C.; Schmidt, L.; 및 Jitsev, J. 2023. Reproducible Scaling Laws for Contrastive Language-Image Learning. CVPR에서, 2818-2829. Dhariwal, P.; 및 Nichol, A. 2021. Diffusion Models Beat Gans on Image Synthesis. NIPS, 34: 8780–8794. Goodfellow, I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.; 강력한 신비로운 마법사 역의 엠마 왓슨은 번개 마법을 걸고, 세부적인 의상을 표현합니다.(a) 4096 x(b) 4096 x(a) 2048 x(b) 2048 x(a) 2048 x(b) 2048 x(a) 2048 x(b) 2048 x그림 9: 타일 확산 기술의 비교 시각화: (a) 겹침이 없는 AR 타일 대 (b) 암묵적 겹침이 있는 ASD. ASD 방식을 사용하면 이음새 문제를 효과적으로 피하면서 4K 및 8K 이미지를 생성할 수 있습니다. Warde-Farley, D.; Ozair, S.; Courville, A.; Bengio, Y. 2014. Generative Adversarial Nets. NIPS, 27권. Heusel, M.; Ramsauer, H.; Unterthiner, T.; Nessler, B.; 및 Hochreiter, S. 2017. 2시간 규모 업데이트 규칙으로 훈련된 GAN은 로컬 내쉬 균형으로 수렴합니다.NIPS, 30. Ho, J.; Jain, A.; 및 Abbeel, P. 2020. 확산 확률적 모델의 잡음 제거.NIPS, 33: 6840-6851. Hu, EJ; Shen, Y.; Wallis, P.; Allen-Zhu, Z.; Li, Y.; Wang, S.; Wang, L.; 및 Chen, W. 2021. LORA: 대규모 언어 모델의 저순위 적응.arXiv 사전 인쇄본 arXiv:2106.09685. Kingma, DP; 및 Ba, J. 2014. Adam: 확률적 최적화 방법.arXiv 사전 인쇄본 arXiv:1412.6980. Li, R.; Zhou, Q.; Guo, S.; Zhang, J.; Guo, J.; Jiang, X.; Shen, Y.; 및 Han, Z. 2023. 사전 훈련된 확산 생성 모델에서 임의 규모의 초고해상도 기능 분석.arXiv 사전 인쇄본 arXiv:2306.00714. Lin, T.-Y.; Maire, M.; Belongie, S.; Hays, J.; Perona, P.; Ramanan, D.; Dollár, P.; 및 Zitnick, CL 2014. Microsoft COCO: 맥락 속의 공통 객체.ECCV에서, 740–755. Ma, Y.; Yang, H.; Yang, W.; Fu, J.; 및 Liu, J. 2023. 더 나은 이미지 초고해상도를 위한 최적 경계 조건으로 확산 ODE 해결.arXiv. Meng, C.; Rombach, R.; Gao, R.; Kingma, D.; Ermon, S.; Ho, J.; 및 Salimans, T. 2023. 유도 확산 모델의 증류에 관하여. CVPR, 14297-14306. Nichol, AQ; 및 Dhariwal, P. 2021. 개선된 노이즈 제거 확산 확률적 모델. ICML, 8162–8171. Nichol, AQ; Dhariwal, P.; Ramesh, A.; Shyam, P.; Mishkin, P.; Mcgrew, B.; Sutskever, I.; 및 Chen, M. 2022. GLIDE: 텍스트 유도 확산 모델을 사용한 사실적인 이미지 생성 및 편집을 향하여. ICML, 1678416804. Paszke, A.; Gross, S.; Massa, F.; Lerer, A.; Bradbury, J.; Chanan, G.; Killeen, T.; Lin, Z.; Gimelshein, N.; Antiga, L.; et al. 2019. Pytorch: 명령형 스타일의 고성능 딥러닝 라이브러리. NIPS, 32. Radford, A.; Wook Kim, J.; Hallacy, C.; Ramesh, A.; Goh, G.; Agarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.; Krueger, G.; and Sutskever, I. 2021. 자연어 감독에서 전이 가능한 시각적 모델 학습. ICML, 8821-8831. Ramesh, A.; Dhariwal, P.; Nichol, A.; Chu, C.; 및 Chen, M. 2022. CLIP Latents를 사용한 계층적 텍스트 조건부 이미지 생성. arXiv 사전 인쇄본 arXiv:2204.06125. Rombach, R.; Blattmann, A.; Lorenz, D.; Esser, P.; 및 Ommer, B. 2022. Latent Diffusion Models를 사용한 고해상도 이미지 합성. CVPR에서, 10684–10695. Ruan, L.; Ma, Y.; Yang, H.; He, H.; Liu, B.; Fu, J.; Yuan, NJ; Jin, Q.; 및 Guo, B. 2023. Mm-diffusion: 공동 오디오 및 비디오 생성을 위한 다중 모달 확산 모델 학습. CVPR에서, 10219-10228. Ruiz, N.; Li, Y.; Jampani, V.; Pritch, Y.; Rubinstein, M.; 및 Aberman, K. 2023. DreamBooth: 주제 중심 생성을 위한 텍스트-이미지 확산 모델 미세 조정. CVPR, 22500-22510. Sahak, H.; Watson, D.; Saharia, C.; 및 Fleet, D. 2023. 야생에서 견고한 이미지 초고해상도를 위한 노이즈 제거 확산 확률적 모델. arXiv 사전 인쇄본 arXiv:2302.07864. Saharia, C.; Chan, W.; Saxena, S.; Li, L.; Whang, J.; Denton, EL; Ghasemipour, K.; Gontijo Lopes, R.; Karagol Ayan, B.; Salimans, T.; et al. 2022. 심층적 언어 이해를 갖춘 사실적인 텍스트-이미지 확산 모델. NIPS, 35: 36479-36494. Saharia, C.; Ho, J.; Chan, W.; Salimans, T.; Fleet, DJ; 및 Norouzi, M. 2023. 반복적 정제를 통한 이미지 초고해상도. TPAMI, 45(4): 4713-4726. Salimans, T.; Goodfellow, I.; Zaremba, W.; Cheung, V.; Radford, A.; 및 Chen, X. 2016. GANS 훈련을 위한 개선된 기술. NIPS, 29. Schuhmann, C. 2022. LAION-AESTHETICS. https://laion.ai/blog/laion-aesthetics/. 액세스: 2022-8-16. Schuhmann, C.; Köpf, A.; Vencu, R.; Coombes, T.; 및 Beaumont, R. 2022. LAION COCO: LAION2B-EN의 600M 합성 캡션. https://laion.ai/blog/laion-coco/. 액세스: 2022-9-15. Song, J.; Meng, C.; 및 Ermon, S. 2020. 확산 암시적 모델의 노이즈 제거. ICLR에서. Song, Y.; Sohl-Dickstein, J.; Kingma, DP; Kumar, A.; Ermon, S.; 및 Poole, B. 2021. 확률적 미분 방정식을 통한 점수 기반 생성 모델링. ICLR에서. Wang, J.; Yue, Z.; Zhou, S.; Chan, KC; 및 Loy, CC 2023. 실제 세계 이미지 초고해상도를 위한 확산 사전 활용. arXiv 사전 인쇄본 arXiv:2305.07015. Wang, Z.; Bovik, A.; Sheikh, H.; Simoncelli, E. 2004. Image Quality Assessment: from Error Visibility to Structural Similarity. TIP, 13(4): 600–612. Xia, W.; Yang, Y.; Xue, J.-H.; Wu, B. 2021. TediGAN: 텍스트 기반 다양한 얼굴 이미지 생성 및 조작. CVPR, 2256–2265. Zhang, R.; Isola, P.; Efros, AA; Shechtman, E.; Wang, O. 2018. 지각적 지표로서 딥 피처의 비합리적인 효과. CVPR, 586–595. Álvaro Barbero Jiménez. 2023. 장면 구성 및 고해상도 이미지 생성을 위한 확산기 혼합. arXiv 사전 인쇄 arXiv:2302.02412.
