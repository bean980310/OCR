--- ABSTRACT ---
AI 작업은 광범위한 도메인과 분야를 포함합니다. 수많은 AI 모델이 특정 작업과 애플리케이션을 위해 설계되었지만, 종종 적절한 모델 아키텍처, 최적화 알고리즘 및 하이퍼파라미터를 찾는 데 상당한 인적 노력이 필요합니다. ChatGPT와 같은 대규모 언어 모델(LLM)의 최근 발전은 추론, 이해 및 상호 작용의 다양한 측면에서 놀라운 기능을 보여줍니다. 결과적으로, 우리는 작업 지향 프롬프트를 개발하고 LLM을 자동으로 활용하여 교육 파이프라인을 자동화할 것을 제안합니다. 이 개념을 구현하기 위해, 우리는 다양한 AI 모델로의 다리 역할을 하는 GPT를 사용하고 최적화된 하이퍼파라미터로 모델을 동적으로 교육하는 AutoML-GPT를 제시합니다. AutoML-GPT는 모델과 데이터 카드에서 사용자 요청을 동적으로 가져와 해당 프롬프트 단락을 구성합니다. 궁극적으로, 이 프롬프트 단락을 통해 AutoML-GPT는 데이터 처리에서 모델 아키텍처, 하이퍼파라미터 튜닝 및 예측 교육 로그에 이르기까지 실험을 자동으로 수행합니다. AutoML-GPT의 강력한 언어 기능과 사용 가능한 AI 모델을 활용하여 AutoML-GPT는 다양한 작업과 데이터 세트에서 수많은 복잡한 AI 작업을 처리할 수 있습니다. 이 접근 방식은 컴퓨터 비전, 자연어 처리 및 기타 어려운 분야에서 놀라운 결과를 달성합니다. 광범위한 실험과 절제 연구는 우리의 방법이 많은 AI 작업에 일반적이고 효과적이며 유익할 수 있음을 보여줍니다. 1
--- INTRODUCTION ---
인공 지능(AI)은 최근 상당한 발전을 이루었습니다. 이러한 발전 중 ChatGPT[OpenAI, 2023]는 추론, 이해 및 상호 작용 능력[Wu et al., 2023]으로 인해 특히 두드러졌습니다. 지침에 따라 새로운 작업을 실행하는 능력은 인공 일반 지능을 달성하기 위한 중요한 단계이며, 대규모 언어 모델(LLM)의 놀라운 기능은 맥락 내 학습[Ram et al., 2023; Xie et al., 2021], 사고 사슬 프롬프트[Pilault et al., 2023; Wei et al., 2022b], 검색 및 읽기[Izacard and Grave, 2020; Zhang et al., 2021, 2022], GPT 기반 지능형 시스템[Zheng et al., 2023]과 같은 수많은 새로운 연구 주제를 촉진했습니다. 이러한 영역은 LLM의 광대한 잠재력을 탐구하고 정교한 AI 시스템을 구축하기 위한 무한한 기회를 제공하는 것을 목표로 합니다. GPT-4[Brown et al., 2020; OpenAI, 2023], LLAMA[Touvron et al., 2023], Flan-T[Chung et al., 2022], PaLM[Chowdhery et al., 2022]과 같은 LLM은 자연어에 대한 심층적인 이해와 일관되고 상황에 맞는 응답을 생성하는 능력을 보여주었습니다. 이러한 진전은 이미지 및 텍스트 처리와 같은 다양한 도메인 데이터와 도메인별 지식의 통합을 포함하는 어려운 작업에 대한 새로운 잠재적 응용 프로그램을 열어주었습니다. 이러한 맥락에서 LLM은 자연어를 이해하고 생성하는 능력을 통해 AI가 광범위한 과제를 더 잘 이해하고 해결할 수 있도록 하기 때문에 중요한 역할을 합니다. 이 논문에서는 사용자 입력 및 설명이 있는 데이터 세트에서 모델을 자동으로 학습시키기 위해 LLM을 활용하는 AutoML-GPT라는 자동 머신 러닝(AutoML) 시스템을 개발하는 것을 목표로 합니다. LLM은 다양한 모델과 연결을 설정하고 입력을 처리하는 자동 학습 시스템으로 사용됩니다. 우리는 언어를 범용 인터페이스로 사용하고 LLM이 사용자와 상호 작용할 수 있도록 프롬프트를 제공할 것을 제안합니다. 데이터와 모델 설명을 모두 프롬프트에 통합함으로써 LLM은 데이터 처리, 모델 아키텍처 설계 및 하이퍼파라미터 튜닝을 위해 AI 모델을 관리할 수 있습니다. 필요에 따라 이러한 모델을 호출하여 AI 작업을 처리하고 예측된 학습 로그를 반환할 수 있습니다. 그러나 여러 AI 모델을 LLM에 통합하려면 상당한 수의 고품질 모델 설명이 필요합니다. 이러한 과제를 극복하기 위해 잘 정의된 모델 설명을 제공하는 모델 카드[Mitchell et al., 2019]와 특정 AI 작업을 위한 데이터 카드[Gebru et al., 2021]를 모두 활용하는 것이 좋습니다. 이 접근 방식을 사용하면 언어 기반 인터페이스를 통해 다양한 모델을 연결하여 복잡한 AI 작업을 쉽게 해결할 수 있습니다. 또한 모델과 데이터 세트의 유사성을 포착하여 모델과 데이터 세트 간의 이전성을 향상시킬 수도 있습니다. AutoML-GPT는 다양한 머신 러닝 모델, 학습 파이프라인, 데이터 세트를 연결하여 수많은 복잡한 AI 작업을 해결합니다. 보다 구체적으로, 해결하려는 각 AI 작업에 대해 해당 설명(예: 모델 카드 및 데이터 카드)을 사용하여 문단을 프롬프트로 사전 학습된 LLM(예: ChatGPT)에 융합하여 AutoML 파이프라인을 구축합니다. 그런 다음 시스템에서 LLM은 자동 학습을 수행하여 사용자의 입력 질문에 대한 예측 학습 로그를 반환합니다. 이러한 학습 로그를 기반으로 LLM과 추가로 상호 작용하여 그림 1에 표시된 요청(예: 하이퍼파라미터 튜닝)을 해결할 수 있습니다. 따라서 AutoML-GPT의 전체 프로세스는 1) 데이터 처리, 2) 모델 아키텍처 설계, 3) 예측 학습 로그를 사용한 하이퍼파라미터 튜닝, 4) 실험 데이터에 대한 인간 피드백의 네 단계로 나눌 수 있습니다. 이러한 설계의 이점을 활용하여 그림 1의 AutoML-GPT는 외부 모델을 사용할 수 있으므로 잘 알려진 벤치마크에서 여러 작업을 처리하고 메타데이터(데이터 카드)만 제공된 경우 알려지지 않은 개인 데이터 세트로 지식을 전송할 수 있습니다.또한 이 파이프라인을 통해 AutoML-GPT는 작업별 전문가의 권한을 계속 흡수하여 성장하고 확장 가능한 AI 기능을 구현할 수 있습니다.요약하면, 우리의 기여는 다음과 같습니다.• 대규모 언어 모델과 전문가 모델의 이점을 보완하기 위해 데이터 처리 및 모델 아키텍처 설계를 위한 시스템 역할을 하고 각 특정 작업에 대한 실험을 자동으로 수행하는 AutoML-GPT를 제안합니다.• 모델 카드와 모델 설명을 통합하고 데이터 카드를 데이터 설명과 통합하여 고정 형식의 프롬프트 단락을 제공하고 일반적인 AI 작업을 처리하는 교육 파이프라인을 구축합니다.• 언어, 비전 및 지속적 학습에 걸친 여러 AI 작업에 대한 광범위한 평가는 자동 교육에서 AutoML-GPT의 기능을 보여줍니다.또한 보이지 않거나 새로운 데이터 세트에 대한 하이퍼파라미터 튜닝을 제공하는 효과를 보여줍니다. 입력 문단 데이터 카드 모델 카드 평가 지표 및 데이터 추가 처리 모델 아키텍처 하이퍼파라미터 튜닝 예측된 교육 로그 그림 1: AutoML-GPT 개요. 일부 표기법은 해당 구성 요소와 함께 레이블이 지정됩니다. &#39;평가 지표 및 추가&#39;는 평가 지표 및 추가 요청을 나타냅니다. AutoML-GPT AutoML-GPT는 데이터 및 모델 정보를 사용하여 프롬프트 입력 문단을 포맷하는 협업 시스템입니다. LLM은 컨트롤러 역할을 하는 반면 수많은 전문가 모델은 협업 실행자 역할을 합니다. AutoML-GPT의 워크플로는 데이터 처리, 모델 아키텍처 설계, 하이퍼파라미터 튜닝 및 교육 로그 생성의 4단계로 구성됩니다. 구체적으로 AutoML-GPT에 대한 일반적인 레시피를 제안합니다. 1) 모델 카드와 데이터 카드가 모두 있는 고정 포맷 프롬프트 문단 생성, 2) 교육 파이프라인을 빌드하고 선택한 데이터 세트 및 모델 아키텍처에서 사용자 요청 처리, 3) 성능 교육 로그 생성 및 하이퍼파라미터 튜닝, 4) 자동 제안된 하이퍼파라미터로 모델 튜닝. 2.1 입력 분해 AutoML-GPT의 첫 번째 단계에서 LLM은 사용자로부터 입력을 받습니다. LLM의 성능을 높이고 효과적인 프롬프트를 생성하기 위해 입력 프롬프트에 대한 특정 지침을 사용합니다. 지침은 아래에 설명된 세 부분으로 구성되어 있습니다. 데이터 카드 데이터 세트의 의도된 사용 사례를 명확히 하고 적합하지 않은 컨텍스트에서 사용을 최소화하기 위해 이 데이터 세트에 대한 포괄적인 설명서를 제공하는 데이터 카드를 활용합니다. 그림 2에서 볼 수 있듯이 데이터 카드의 주요 구성 요소는 데이터 세트 이름, 입력 데이터 세트 유형(예: 이미지 데이터 또는 텍스트 데이터), 레이블 공간(예: 클래스 유형 또는 해상도) 및 기본 평가 메트릭으로 구성됩니다. 데이터 이름 ImageNet: 1000class 분류 ... 입력 데이터 유형 레이블 공간 Eval Image 클래스 유형: 상어 ... FiD 자연어 질문: 오픈 도메인 ... 답변이 포함되어 있거나 포함되지 않을 수 있는 텍스트 위키백과 ... 정확한 일치 ... 데이터 카드 COCO 데이터: 대형 이미지 스케일 객체 ... 객체 범주: 사람 ... 상자 AP L 그림 2: 데이터 카드에는 데이터 이름, 입력 데이터 유형, 레이블 공간 및 평가 메트릭이 포함됩니다. 데이터 카드 내에서 동일한 색상은 단일 데이터 세트에서 비롯된 정보를 나타냅니다.모델 카드 그림 3의 모델 카드는 앞서 설명한 &quot;데이터 카드&quot;를 보완하며, 데이터 세트를 학습하고 테스트하는 데 사용된 모델의 세부 정보를 보고하는 제안된 패러다임 중 하나로 사용됩니다.모델 카드는 모델 이름, 모델 구조(예: UperNet [Xiao et al., 2018] 헤드가 있는 Swin transformer [Liu et al., 2021]), 모델 설명 및 아키텍처 하이퍼파라미터로 구성됩니다.모델 카드는 이 정보를 제공함으로써 LLM에 사용된 머신 러닝 시스템과 사용자가 모델 아키텍처에 대해 원하는 유연성의 정도를 알려줍니다.이를 통해 LLM에서 보다 포괄적인 결과를 만들 수 있습니다. 모델 이름 모델 구조 모델 설명 아키텍처 Hyper Swin Transformer 다중 헤드 셀프 어텐션 윈도우... GELU가 있는 2층 MLP가 있는 이동된 윈도우... 윈도우 크기: 7... UNet 합성곱 네트... RELU와 풀링이 뒤따르는 두 개의 합성곱... 채널 수: 256... 모델 카드 DPR 질문 인코더... Dense 검색기는 biencoder입니다.... 인코더 시퀀스 길이: 350... 그림 3: 모델 카드는 모델 이름, 모델 구조, 모델 설명 및 아키텍처 하이퍼파라미터로 구성됩니다. 모델 카드에서 같은 색상은 단일 모델 카드의 정보를 나타냅니다. 평가 지표 및 추가 요청 사용자는 모델 카드와 데이터 카드 외에도 추가 평가 벤치마크, 지표 또는 모든 제약 조건을 요청할 수 있습니다. 기본 평가 지표를 제외하고 모델 아키텍처를 선택할 때 사용자의 요청에 따라 특정 지표나 제약 조건을 추가할 수 있습니다. 예를 들어, &quot;추론 시간이 10FPS보다 작음&quot;이라는 제약 조건이 주어지면 평가 지표와 제약 조건 하에서 사용자 요청을 처리합니다. 이러한 지침과 이러한 평가 지표 및 추가 요청에 대한 인간의 피드백을 활용하여 LLM은 지침을 더 잘 따를 수 있습니다.AutoML-GPT는 이러한 작업 사양을 LLM에 제공하여 사용자의 요청을 적절히 분석하기 위한 상위 수준 지침으로 제공합니다.2.2 데이터 처리 데이터 처리란 데이터의 품질과 파생된 유용한 정보가 모델의 학습 능력에 직접적인 영향을 미치기 때문에 머신 러닝에서 필수적인 단계입니다.따라서 모델에 데이터를 입력하기 전에 데이터를 처리하는 것이 중요합니다.예를 들어, 컴퓨터 비전에서 데이터 처리란 분석 또는 머신 러닝 알고리즘을 위해 원시 이미지 데이터를 준비하는 데 사용되는 기술과 방법의 집합을 말합니다.여기에는 이미지 크기 조정, 정규화, 증강 및 필터링이 포함될 수 있습니다.마찬가지로 자연어 처리(NLP) 프로젝트에서 데이터 처리란 머신 러닝 알고리즘이 쉽게 이해하고 처리할 수 있는 구조화되고 깔끔한 형식으로 원시 텍스트 데이터를 변환하는 것을 말합니다.토큰화, 불용어 제거, 소문자화, 특수 문자 및 숫자 제거와 같은 기술이 일반적으로 사용됩니다. 제공된 데이터 카드와 데이터 설명을 기반으로 AutoML-GPT는 프로젝트 요구 사항과 데이터의 특성에 따라 특정 프로세스 기술을 제공합니다.2.3 모델 아키텍처 AutoML-GPT는 작업 목록을 처리할 때 각 작업을 해당 모델과 일치시켜 기본적으로 목록의 모든 작업에 적합한 모델을 선택해야 합니다.이를 달성하기 위해 먼저 사용자 입력에서 모델 카드와 모델 설명을 수집합니다.그런 다음 컨텍스트 내 작업 모델 할당 메커니즘을 사용하여 모델을 작업에 동적으로 할당합니다.이 접근 방식은 증분 모델 액세스를 가능하게 하고 제공하는 모델 설명과 사용자 요청에 대한 더 나은 이해를 결합하여 더 큰 개방성과 유연성을 제공합니다.모델 아키텍처는 머신 러닝 모델의 설계, 구조 및 구성 요소에 대한 자세한 설명을 말합니다.이러한 설명에는 일반적으로 다음 요소가 포함됩니다.입력 및 출력 계층, 숨겨진 계층, 활성화 함수, 손실 함수 및 모델별 구성 요소(예: 주의 메커니즘, 합성곱 계층 또는 순환 계층). 2. 예측된 학습 로그를 사용한 하이퍼파라미터 튜닝 특정 데이터 세트에서 주어진 모델에 대해 최상의 성능을 내는 최적의 하이퍼파라미터 세트를 찾기 위해 하이퍼파라미터 튜닝은 머신 러닝에서 중요한 단계입니다. 하이퍼파라미터는 학습 프로세스 중에 학습되지 않지만 미리 정의되어 모델의 학습 동작의 다양한 측면을 제어하는 구성 설정입니다. 일반적인 하이퍼파라미터의 예로는 학습률, 배치 크기, 숨겨진 계층 수, 계층당 뉴런 수가 있습니다. 실제 머신에서 학습하지 않고 하이퍼파라미터를 튜닝하기 위해 제공된 데이터 카드와 모델 카드에 대해 주어진 하이퍼파라미터 설정에 대한 학습 로그를 생성하여 성능을 예측합니다. AutoML-GPT는 자동으로 학습을 수행하고 학습 로그를 반환합니다. 데이터 세트에서 모델 성능의 학습 로그는 학습 프로세스 중에 수집된 다양한 메트릭과 정보를 기록합니다. 이는 모델의 진행 상황을 이해하고, 잠재적인 문제를 식별하고, 선택한 아키텍처, 하이퍼파라미터 및 최적화 기술의 효과를 평가하는 데 도움이 됩니다. 일반적인 학습 로그에는 학습 및 검증 메트릭이 포함된 에포크 번호가 포함됩니다. 학습 로그를 검토하면 사용자 피드백에 따른 모델 성능에 대한 기본적인 이해를 얻을 수 있습니다.데이터 이름 새 데이터 세트: 객체 데이터 세트... 레이블 공간 객체 범주: 10개 클래스... 데이터 카드 텍스트 인코더 유사도 입력 데이터 유형 이미지 평가 모델 이름 Swin Transformer 모델 카드 모델 Des 상자 AP 2계층 MLP가 있는 이동된 창... 모델 구조 다중 헤드 셀프 어텐션... 아키텍처 하이퍼파라미터 창 크기: 7... 모델 매개변수 AutoML-GPT 프롬프트 단락 {유사도가 있는 데이터 카드 세트: 5개 이미지 클래스가 있는 새 데이터 세트...}가 있다고 가정하고 {모델 매개변수가 있는 해당 모델 카드 세트: ...가 있는 슬라이드 창 Swin Transformer}를 모델로 채택합니다. Auto ML GPT 예측 학습 로그 다음은 제안된 하이퍼파라미터를 사용하여 새 데이터 세트에서 학습된 ViT 모델에 대한 학습 로그입니다.에포크: [0][ 0/25] 에포크: [0][10/25] 시간 1.015(1.015) 데이터 0.353(0.353) 손실 0.4065e+00 가속@1 97.75(97.75) 가속@5 100.00(100.00) 시간 0.511(0.583) 데이터 0.000(0.032) 손실 0.3827e+00 가속@1 93.75(98.86) 가속@5 100.00(100.00) 그림 4: 보이지 않는 데이터 세트에 대한 AutoML-GPT 개요: 상단 블록은 데이터 카드와 모델 정보를 보여줍니다. 먼저 여러 데이터 세트에 대한 학습 정보를 기록합니다. 이러한 데이터 세트의 데이터 카드는 텍스트 인코더를 통해 처리되어 유사도 점수를 얻은 다음, 해당 학습된 모델의 모델 매개변수와 결합하여 AutoML-GPT 프롬프트 문단을 형성합니다. 하단 블록은 보이지 않는 데이터 세트에 대한 권장 하이퍼 매개변수 설정을 기반으로 예측된 학습 로그를 표시합니다. 보이지 않는 데이터 세트 보이지 않는 비공개 데이터 세트에 대한 하이퍼 매개변수 튜닝은 훨씬 더 어려울 수 있습니다. 보이지 않는 데이터 세트의 메타데이터가 주어지면 AutoML-GPT는 해당 데이터 세트에 효과적일 가능성이 높은 하이퍼 매개변수 구성을 추천할 수 있습니다. 데이터 카드를 사용하여 필요한 텍스트 설명을 활용하고 보이지 않는 데이터 세트와 기존 데이터 세트 간의 상관 관계를 식별합니다. 상관 관계를 기반으로 기존 데이터 세트의 하이퍼 매개변수 설정을 새 보이지 않는 데이터 세트로 전송합니다. 상관 관계를 계산하기 위해 텍스트 인코더를 사용하여 데이터 카드를 인코딩합니다. 구체적으로 데이터 카드에는 클래스 유형, 해상도, 이미지 크기 및 기타 관련 메타데이터와 같은 정보가 포함됩니다. 데이터 세트 규모, 작업 설명, 레이블 공간 및 입출력 데이터 유형을 텍스트 인코더(예: CLIP [Radford et al., 2021])의 입력으로 사용하고 인코딩된 잠재 표현의 유사도 점수를 사용하여 이 보이지 않는 데이터 세트와 기존 데이터 세트 간의 상관 관계를 설명합니다.3 실험 AutoML-GPT의 성능을 평가하고 ChatGPT(OpenAI의 &quot;GPT-4&quot; 버전)¹을 사용하여 구현합니다.다양한 사례 연구를 수행하여 여러 각도에서 접근 방식의 효과를 보여줍니다.3.1 보이지 않는 데이터 세트 그림 4에서는 AutoML-GPT를 사용하여 보이지 않는 데이터 세트에 대한 학습 결과를 보여줍니다.실제 사례에서 성능을 확인하기 위해 이미 학습된 데이터 세트와 일부 학습되지 않은 데이터 세트에 대한 성능 및 하이퍼 매개변수 세트를 구성합니다.이러한 학습되지 않은 데이터 세트에 대한 하이퍼 매개변수 구성을 예측합니다.Vinyals et al. [2016]에 설명된 분류 설정을 기반으로 테스트 환경을 만듭니다. 또한 MiniImageNet [Vinyals et al., 2016]을 따라 훈련 데이터 세트 [Deng et al., 2009]를 80%와 20% 부분으로 하위 샘플링하고 분할합니다. 80% 데이터에서 데이터 카드와 해당 모델 카드(모델 최상의 하이퍼파라미터 포함)를 구성합니다. 15개 클래스를 무작위로 선택하여 다양한 하위 세트 데이터 세트(예: 데이터 세트 A, B 등)를 만들고, 하이퍼파라미터를 그리드 검색하고, ViT 기본 모델을 미세 조정하고 [Dosovitskiy et al., 2020] 이러한 하위 세트 데이터 세트에서 최상의 성능을 기록합니다. 그런 다음 나머지 20% 데이터에서 10개의 이미지 클래스로 &quot;New&quot;라는 새 데이터 세트를 만듭니다. 한국어: https://platform.openai.com/Data Name Data Card COCO Data: 대규모 객체... Input Data Type Image Label Space Object Categories: person... Eval Box AP Model Card Model Name Swin Transformer Model Structure Multi-head self attention with ... Model Des Shifted window with a 2-layer MLP ... Architecture Hyperparameter Window size: 7 ... AutoML-GPT Prompt Paragraph {328K images and evaluation metric이 있는 데이터 카드: COCO 데이터 세트 ...}가 있다고 가정하고, {모델 카드: slided window swin transformer ...}를 모델로 채택합니다. {A: 데이터 처리} 및 {B: 모델 아키텍처} 스크립트를 사용하여 COCO 데이터 세트를 처리합니다. {리소스: 4 Nvidia a5000 GPU}의 하이퍼파라미터에 {C: 하이퍼파라미터}를 사용합니다. 그러면 {D: 예측된 학습 로그}가 생깁니다. 데이터 처리 COCO에서 swin transformer 기반 객체 감지를 위한 데이터 전처리에 사용하는 python 스크립트는 다음과 같습니다.import torch import torch optim as optim import torch optim.Ir_scheduler as Ir_scheduler from torch.utils.data import Datal.cader from torchvision datasets import CocoDetection from torchvision import transforms from models.detr import DETR setup data loaders train_transforms transforms.Compose([ transforms.Resize((800, 800)), transforms RandomHorizontalFlip(), transforms.To Tensor() transforms.Normalize([0.485, 0.456, 0.406], [0.229. 0.224.0.225]) 하이퍼파라미터 튜닝 제안하신 모델 카드와 데이터 카드를 사용합니다. 객체 감지를 위한 COCO 데이터 세트의 DETR 모델의 하이퍼파라미터는 다음과 같습니다.학습률: 0.가중치 감소: 1e-Optimizer: AdamW 스케줄러: 워밍업 기능이 있는 MultiStepLR ... AutoMLGPT 모델 아키텍처 변압기 기반 모델과 슬라이드 윈도우 방식을 사용하여 COCO 데이터 세트에서 객체를 감지하기 위해 DETR은 변압기 인코더와 디코더를 갖추고 있으며 단일 전방 패스에서 일련의 객체 쿼리와 해당 경계 상자 예측을 직접 출력하도록 설계되었습니다. 이를 통해 앵커 기반 또는 앵커 없는 감지 방법이 필요 없게 되고 COCO 객체 감지에서 최첨단 성능을 달성합니다... 예측된 학습 로그 ere는 제안된 하이퍼파라미터를 사용하여 COCO 데이터 세트에서 학습된 Swin Transformer Base 백본이 있는 DETR 모델에 대한 학습 로그입니다.Epoch: [1] [ 0/1000] eta: 1일, 6:54:48 Ir: 0.000100 loss: 4.8577 (4.8577) loss_ce: 3.9479 (3.9479) loss_bbox: 0.0363 (0.0363) loss_giou: 0.8735 (0.8735) loss_cls: 0.0000 (0.0000) acc: 0.0000 (0.0000) loss obj: 0.0000 (0.0000) loss_rpn_box: 0.0000 (0.0000) 시간: 25.7651 데이터: 3.7903 최대 mem:Epoch: [1] [10/1000] eta: 4:51:08 Ir: 0.000100 손실: 4.4567 (4.5028) loss_ce: 3.3551 (3.5238) loss_bbox: 0.0429 (0.0398) loss_giou: 0.9994 (0.9398) loss_cls: 0.0000 (0.0000) acc: 0.0000 (0.0000) 손실 obj: 0.0000 (0.0000) loss_rpn_box: 0.0000 (0.0000) 시간: 14.7129 데이터: 0.5279 최대 메모리:그림 5: 객체 감지를 위한 AutoML-GPT 개요: 상단 블록은 데이터 카드와 모델 카드를 표시합니다. 중간 블록은 데이터 카드와 모델 카드에서 파생된 AutoML-GPT 프롬프트 문단을 보여줍니다. 하단 블록은 데이터 처리, 모델 아키텍처, 하이퍼파라미터 튜닝, 예측된 교육 로그의 네 가지 단계를 설명합니다. 예측된 교육 로그를 사용하여 하이퍼파라미터를 튜닝한 다음 하이퍼파라미터를 사용자에게 피드백합니다. 보이지 않는 데이터 세트에 대한 접근 방식의 기능을 보여주기 위해 AutoML-GPT를 사용하여 제공된 데이터 카드와 모델 카드를 기반으로 &quot;새로운&quot; 데이터 세트에 대한 최상의 교육 구성을 추천합니다. 데이터 카드에서 레이블 공간, 즉 각 클래스에 대한 텍스트 설명을 기록합니다. 실제로 데이터 카드의 텍스트를 텍스트 인코더(예: CLIP 텍스트 인코더)를 통해 전달하고 유사도를 계산하여 두 데이터 카드 간의 유사도 점수를 통합합니다. 구체적으로 그림 4에서 &quot;새로운&quot; 데이터 세트는 데이터 세트 A와 60%의 레이블 공간 유사성을 갖고 데이터 세트 B와 40%의 레이블 공간 유사성을 갖는다고 명시합니다. 이 정보와 데이터 세트 A 및 B에 대한 데이터 카드의 하이퍼 매개변수 설정을 사용하여 AutoML-GPT는 &quot;새로운&quot; 데이터 세트에 대한 학습을 위한 적절한 하이퍼 매개변수 설정을 추천할 수 있습니다. 실험에서 평균 무작위 선택 하이퍼 매개변수를 사용한 80%의 Top 1 정확도와 비교하여 Top 1 예측에 대해 98%의 정확도를 달성했습니다. 게다가 추가 데이터 세트를 제공하지 않고 AutoML-GPT에서 제안한 하이퍼 매개변수 설정을 사용하여 모델을 초기화합니다. 이 구성을 사용하면 평균 무작위 선택 하이퍼 매개변수보다 나은 82%의 Top 1 정확도를 달성하지만 권장 설정만큼 좋지는 않습니다. 또한 ChatGPT가 특정 작업(예: 이미지 분류)에 대해 좋은 하이퍼 매개변수 설정을 제공할 수 있음을 시사합니다. 이는 보이지 않거나 새로운 데이터 세트에서도 머신 러닝 문제를 해결하는 데 제안한 자동 학습 접근 방식의 효과를 보여줍니다. 이러한 결과는 정확한 하이퍼파라미터 추천을 제공하여 머신 러닝을 향상시키는 자동 학습 방법의 잠재력을 강조합니다.3.2 객체 감지 그림 5는 객체 감지를 위한 COCO 데이터 세트[Lin et al., 2014]에 대한 결과를 보여줍니다.① 상단 블록은 사용자 입력을 기반으로 COCO 데이터 세트의 데이터 카드와 ImageNet의 모델 카드를 표시합니다.가운데 블록은 입력 분해에서 파생된 AutoML-GPT 프롬프트 문단을 보여줍니다.데이터 카드와 모델 카드의 정보는 자동으로 프롬프트 형식에 통합됩니다.데이터 처리, 모델 아키텍처 설계, 하이퍼파라미터 튜닝 및 학습 로그 생성에 대한 결과를 보고합니다.데이터 처리에서 AutoML-GPT는 입력 데이터 세트를 처리하기 위한 스크립트를 생성합니다.또한 그림 5에서 Python 스크립트 예제를 제공합니다.모델 아키텍처 설계의 경우 파이프라인은 후속 학습을 위한 모델 구성을 생성합니다. 데이터와 모델이 모두 준비되면 하이퍼파라미터 튜닝 단계에서 자세한 구성(예: 학습률: 10-4, 가중치 감소: 10-4)이 제공되고 예측된 학습 로그로 추가로 튜닝됩니다. ③ 이러한 결과는 우리 방법이 데이터 카드 데이터 이름 자연어 질문: 개방 도메인 ... 입력 데이터 유형 텍스트 레이블 공간 Eval Wikipedia that may or may not... 정확히 일치... 모델 카드 모델 이름 DPR 모델 Des Dense retriever bi-encoder.... 모델 구조 질문 인코더... 아키텍처 하이퍼파라미터 인코더 시퀀스 길이: 350 ... AutoML-GPT 프롬프트 단락 {데이터 카드: 자연어 질문이 개방되어 있습니다...}가 있다고 가정하고 {모델 카드: DPR with the dense retriever which is biencoder...}를 모델로 채택합니다. 자연어 질문에 답하는 데이터 세트를 처리하기 위해 {A: 데이터 처리} 및 {B: 모델 아키텍처} 스크립트를 사용합니다. {리소스: 8 Nvidia v100 GPU}의 하이퍼파라미터에 {C: 하이퍼파라미터}를 사용합니다.그러면 학습 로그 {D: 예측 학습 로그}가 생깁니다.또한 {추가 요청: DPR 검색기의 더 빠른 추론 시간}도 있습니다.데이터 처리 다음은 오픈 도메인 질의응답을 위한 NQ 데이터 세트에서 DPR의 데이터 전처리를 위한 Python 스크립트입니다.import json import random def load_data(file_path): with open(file_path, &#39;&#39;) as f data = json.load(f) def prepare_data(data): processed_data =[]AutoMLGPT 하이퍼파라미터 튜닝 제안하신 모델 카드와 데이터 카드를 사용합니다. DPR 모델의 하이퍼파라미터 o Natural Questions(NQ) 데이터 세트는 다음과 같습니다.모델 아키텍처 개방형 도메인 질의응답을 위한 Natural Questions(NQ) 데이터 세트의 DPR(Dense Passage Retrieval)에 대한 모델 아키텍처에는 두 가지 구성 요소가 포함됩니다.Retriever ... 예측된 학습 로그 다음은 제안된 하이퍼파라미터를 사용하여 NQ 데이터 세트에서 학습된 Retriever를 포함하는 DPK 모델에 대한 학습 로그입니다.학습 로그: poch 1: 100회 반복 - 손실: 6. 반복 200 - 손실: 4. 반복 300 - 손실: 3.6890... Retriever 학습 하이퍼파라미터: 배치 크기: 학습률: 1e-max_epochs: warmup_steps:. drop_out: 0.1 ... 추가 요청(예): DPR 검색기의 추론 시간 단축 성능을 크게 희생하지 않고 추론 시간을 단축하려면 특정 ... 모델을 학습하기 위한 제안된 구성은 다음과 같습니다.hatch size:learning rate: 1-max_epochs:# 추론을 가속화하기 위한 추가 하이퍼파라미터 model dimension: 256 #모델 차원 축소(BERT 기반 DPR의 경우 기본값은 768) max_sequence_length: 128 #입력 시퀀스 길이 제한(기본값은 512)... 그림 6: 질의 응답을 위한 AutoML-GPT 개요: 위 블록은 데이터 카드와 모델 정보를 제공하고 가운데 블록은 데이터 카드와 모델 카드에서 파생된 AutoML-GPT 프롬프트 문단을 강조 표시합니다. 아래 블록은 데이터 처리, 모델 아키텍처, 하이퍼파라미터 튜닝, 예측된 학습 로그의 네 가지 단계를 자세히 설명합니다. LLM을 다운스트림 작업에 유연하게 적용하기 위한 효과적인 파이프라인. 데이터와 모델 카드를 사용하여 AutoML-GPT 프롬프트 문단을 도출하는 우리의 접근 방식은 LLM 프롬프트 구성 요소를 향상시키는 데 중점을 둔 작업을 위한 보완 모듈로 간주될 수도 있습니다.3.3 질의 응답 우리는 그림 6에서 Natural Questions Open 데이터 세트[Kwiatkowski et al., 2019]에 대한 실험 결과를 제시합니다.우리는 Dense Passage Retrieval(DPR)[Karpukhin et al., 2020]을 활용합니다.데이터 카드의 경우 사용자는 데이터 이름, 입력 데이터 유형, 레이블 공간 및 평가 메트릭을 입력합니다.② 모델 카드의 경우 모델 이름, 모델 구조, 모델 설명 및 아키텍처 하이퍼파라미터를 포함합니다.③ 생성된 AutoML-GPT 프롬프트 문단을 사용하여 AutoML-GPT는 데이터 처리, 모델 아키텍처 생성, 하이퍼파라미터 튜닝을 수행하고 예측된 교육 로그를 생성합니다. &quot;하이퍼파라미터 튜닝&quot;에서 볼 수 있듯이 AutoML-GPT에서 생성한 하이퍼파라미터와 DPR에서 제공한 하이퍼파라미터는 긴밀하게 일치합니다. 예를 들어 학습률은 10-5이고 최대 에포크는 40입니다. ④예측된 학습 로그가 제공되면 사용자가 요구 사항에 따라 AutoML-GPT에 다양한 평가 지표나 모델 아키텍처를 요청할 수 있는 시나리오를 보여줍니다(그림 6 &quot;추가 요청: DPR 검색기의 빠른 추론 시간&quot; 참조). 그림 6에서 반환된 응답에서 볼 수 있듯이 AutoML-GPT는 &quot;성능을 너무 많이 희생하지 않고도&quot;와 같은 힌트도 제공합니다. AutoML-GPT는 이러한 요청과 예측된 로그를 기반으로 하이퍼파라미터를 추가로 튜닝합니다. 저희의 방법은 실험을 자동으로 수행하고 대화형 하이퍼파라미터 튜닝을 수행하는 강력한 기능을 보여줍니다. 또한 저희의 접근 방식이 다양한 데이터 세트에 적합하고 다양한 입력 유형과 도메인에서 일반화할 수 있음을 확인합니다. 3.4 분류 저희는 또한 UCI 성인 데이터 세트[Dua 및 Graff, 2017] XGBoost를 사용합니다. 이전과 마찬가지로 데이터 카드와 모델 카드를 제공하여 입력 프롬프트 문단을 생성합니다. 그림 7에서 볼 수 있듯이 동일한 교육 파이프라인이 여기에 적용됩니다. 또한 AutoML-GPT에서 제안한 하이퍼파라미터 설정을 준수하고 XGBoost 모델을 교육합니다. 이 교육의 최종 검증 손실은 0.277이고 정확도는 85.92%입니다. 입력과 작업이 다르지만 제안하는 AutoML-GPT는 분류에서 지속적으로 강력한 성능을 제공합니다. 이는 AutoML-GPT가 광범위한 machineData Name UCI Adult income dataset... Label Space Classification Data Card Input Data Type Categorical, Int... Eval AUC... Model Name XGBoost Model Des An optimized distributed ... Model Card Model Structure It is an ensemble learning... Architecture Hyperparameter Booster: tree-based methods... AutoML-GPT Prompt Paragraph 가정해 보자. {Data Card: UCI adut income dataset is...}, {Model Card: XGBoost is an ensemble learning...}을 모델로 채택한다. {A: Data Processing}과 {B: Model Architecture} 스크립트를 사용해 UCI ault income dataset을 처리한다. {C: Hyperparameter}를 사용해 {Resource: AMD EPYC 7702P 64-Core Processor}의 하이퍼파라미터를 처리한다. 그러면 학습 로그 {D: Predicted Training Log}가 생긴다. import pandas as pd import numpy as np 데이터 처리 모델 아키텍처 XGBoost(eXtreme Gradient Boosting)는 의사결정 트리를 기본 학습자로 활용하는 앙상블 방식입니다. XGBoost의 모델 아키텍처는 여러 의사결정 트리로 구성되어 있으며, 각 트리는 앙상블의 이전 트리의 오류를 수정하기 위해 반복적으로 추가됩니다. 최종 예측은 앙상블의 모든 트리의 예측 합계에 따라 이루어집니다... UCI 성인 데이터 세트에 대한 XGBoost의 데이터 전처리를 위한 Python 스크립트는 다음과 같습니다. from sklearn preprocessing import LabelEncoder from sklearn model_selection from xgboost import XGBC port train_test_split XGBClassifier from sklearn metrics import accuracy_score # 데이터 세트 로드 url=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data&quot; column_names=[&#39;age&quot;, &quot;workclass&quot;, &quot;fnlwgt&quot;, &quot;education&#39;, &#39;education-num&#39;, &#39;marital-status&#39;, &#39;occupation&#39;, &#39;relationship&#39;, &#39;race&#39;, &#39;sex&#39;, &#39;capital-gain&#39;, &#39;capital-loss&#39;, &#39;hours-per-week&#39;, &#39;native-country&#39;, &#39;income&#39;] .. 하이퍼파라미터 튜닝 귀하께서 제안하신 모델 카드와 데이터 카드를 사용합니다. UCI 성인 데이터 세트에 대한 XGBoost 모델의 하이퍼파라미터는 다음과 같습니다. xgb_params ={ &#39;objective&#39;: &#39;binary:logistic&#39;, # 이진 분류 문제 &#39;n estimators&#39;: 100, # 앙상블의 트리 수 &#39;max_depth&#39;: 6, # 각 트리의 최대 깊이 &#39;learning_rate&quot;: 0.3, # 최종 결과에 대한 각 트리의 기여도 ... AutoMLGPT 최종 Val Loss 0. 예측된 학습 로그 제안된 하이퍼파라미터를 사용한 UCI 성인 데이터 세트에 대한 XGBoost의 학습 로그는 다음과 같습니다. [0] validation_0-logloss:0.[1] validation_0-logloss:0.[2] validation 0-logloss:0.[3] validation_0-logloss:0.42562... 그림 7: 분류를 위한 AutoML-GPT 개요: 상단 블록은 데이터 카드와 모델 정보를 표시하고 중간 블록은 데이터 카드와 모델에서 파생된 AutoML-GPT 프롬프트 문단을 보여줍니다. 카드. 하단 블록은 데이터 처리, 모델 아키텍처, 하이퍼파라미터 튜닝, 예측된 교육 로그의 4단계를 설명합니다. 또한 AutoML-GPT의 하이퍼파라미터 권장 사항을 따르고 모델을 교육하는 최종 검증 결과를 포함합니다. 다양한 작업에 걸친 학습 문제. 4
--- RELATED WORK ---
고급 대규모 언어 모델 LLM은 1,000억을 초과하는 매개변수 크기를 갖는 제로샷 및 퓨샷 학습을 통해 견고성과 일반화 가능성을 보여주었습니다. LLM의 주목할 만한 예로는 5,300억 개의 매개변수를 갖는 Megatron-turing NLG [Smith et al., 2022], 2,800억 개의 매개변수를 갖는 Gopher [Rae et al., 2021], 5,400억 개의 매개변수를 갖는 PaLM [Chowdhery et al., 2022]이 있습니다. LLM의 확장은 이전에 더 작은 모델에서는 관찰되지 않았던 새로운 신생 능력을 잠금 해제했습니다 [Wei et al., 2022a]. 이러한 LLM은 제로샷 학습을 위한 LLM의 우수성을 입증했습니다. 기존 LLM 중에서 ChatGPT는 고유한 특성을 가지고 있습니다. 사전 학습에서 얻은 누적된 지식과 일반화 능력을 유지하면서 대화와 같은 방식으로 사용자와 상호 작용할 수 있는 기능을 가지고 있습니다. 한 걸음 더 나아가, 이 작업에서는 대화를 넘어 다른 과제에서 ChatGPT의 제로샷 학습 기능을 탐구합니다.사고의 사슬사고의 사슬(CoT) 프롬프팅은 LLM이 대답하기 전에 중간 추론 단계를 생성하도록 유도합니다[Wei et al., 2022b]. 현재 CoT 프롬프팅에 초점을 맞춘 두 가지 연구 라인이 있습니다. 한 라인은 수동으로 설계된 CoT를 탐구하는 것입니다.수동으로 설계된 CoT에서 LLM은 추론 프로세스에 수동으로 설계된 기능과 데모를 적용합니다[Wei et al., 2022b].Wang et al.[2022]은사고의 사슬 프롬프팅에서 사용되는 순진한 탐욕적 디코딩을 대체하기 위해 새로운 디코딩 전략인 자기 일관성을 제안합니다.최근에는 언어 간 조건 생성의 모호성을 해결하기 위해 대화형 사슬 프롬프팅[Pilault et al., 2023]이 도입되었습니다. 또 다른 라인은 제로샷 설정에 대한 연구를 수행하고 있으며, 여기서 STaR[Zelikman et al., 2022]은 자체 생성을 위해 도입되어 모델이 자체 개선하도록 돕고, 자동 추론 및 도구 사용(ART)[Paranjape et al., 2023]은 동결된 LLM을 사용하여 프로그램으로 중간 추론 단계를 자동으로 생성하는 프레임워크입니다.GPT 기반 시스템 GPT[Brown et al., 2020]는 유망한 성능 향상을 보여주었습니다.최근 연구 라인은 GPT 모델을 AI 시스템에 통합하는 데 중점을 두었습니다.HuggingGPT[Shen et al., 2023]는 HuggingFace 변환기 라이브러리로 구축되었으며 GPT를 상호 작용 에이전트로 활용합니다.VisualGPT[Wu et al., 2023]는 다양한 Visual Foundation 모델을 통합하여 사용자가 ChatGPT와 상호 작용할 수 있도록 합니다. 오픈소스 AGI 연구 플랫폼인 OpenAGI[Ge et al., 2023]는 복잡하고 여러 단계로 구성된 작업을 제공하고 작업별 데이터 세트를 수반하도록 설계되었습니다. 마찬가지로 GPT를 AutoML 파이프라인에 통합합니다. 검색 엔진의 추가 정보를 통합할 수 있는 또 다른 GPT 기반 시스템도 있습니다(예: AutoGPT²). AutoML-GPT는 자동 학습 관점에서 ChatGPT의 영향을 재고합니다. 학습 파이프라인을 구축하고 처음부터 끝까지 AutoML 시스템을 구축하는 데 중점을 둡니다. 5 결론 저희의 작업은 GPT에 AutoML 시스템을 구축하는 이점을 보여줍니다. 제안된
--- METHOD ---
영어: 많은 AI 작업에 대해 일반적이고 효과적이며 유익할 수 있습니다.1 서론 인공 지능(AI)은 최근 상당한 발전을 이루었습니다. 이러한 개발 중 ChatGPT[OpenAI, 2023]는 추론, 이해 및 상호 작용 능력으로 인해 특히 두드러졌습니다[Wu et al., 2023]. 지침에 따라 새로운 작업을 실행하는 능력은 인공 일반 지능을 달성하기 위한 중요한 단계이며, 대규모 언어 모델(LLM)의 놀라운 기능은 맥락 내 학습[Ram et al., 2023; Xie et al., 2021], 사고 사슬 프롬프트[Pilault et al., 2023; Wei et al., 2022b], 검색 및 읽기[Izacard and Grave, 2020; Zhang 등, 2021, 2022], GPT 기반 지능형 시스템[Zheng 등, 2023]. 이러한 분야는 LLM의 광대한 잠재력을 탐색하고 정교한 AI 시스템을 구축하기 위한 무한한 기회를 제공하는 것을 목표로 합니다. GPT-4[Brown 등, 2020; OpenAI, 2023], LLAMA[Touvron 등, 2023], Flan-T[Chung 등, 2022], PaLM[Chowdhery 등, 2022]과 같은 LLM은 자연어에 대한 심층적인 이해와 일관되고 상황에 맞는 응답을 생성하는 능력을 보여주었습니다. 이러한 진전은 이미지 및 텍스트 처리와 같은 다양한 도메인 데이터와 도메인별 지식의 통합을 포함하는 어려운 작업에 대한 새로운 잠재적 응용 프로그램을 열어주었습니다. 이러한 맥락에서 LLM은 자연어를 이해하고 생성하는 능력을 통해 AI가 광범위한 과제를 더 잘 이해하고 해결할 수 있도록 하기 때문에 중요한 역할을 합니다. 이 논문에서는 LLM을 활용하여 사용자 입력 및 설명이 있는 데이터 세트에서 모델을 자동으로 학습시키는 AutoML-GPT라는 자동 머신 러닝(AutoML) 시스템을 개발하는 것을 목표로 합니다. LLM은 다양한 모델과 연결을 설정하고 입력을 처리하는 자동 학습 시스템으로 사용됩니다. 우리는 언어를 범용 인터페이스로 사용하고 LLM이 사용자와 상호 작용할 수 있도록 프롬프트를 제공할 것을 제안합니다. 데이터와 모델 설명을 모두 프롬프트에 통합함으로써 LLM은 데이터 처리, 모델 아키텍처 설계 및 하이퍼파라미터 튜닝을 위해 AI 모델을 관리할 수 있습니다. 필요에 따라 이러한 모델을 호출하여 AI 작업을 해결하고 예측된 학습 로그를 반환할 수 있습니다. 그러나 여러 AI 모델을 LLM에 통합하려면 상당한 수의 고품질 모델 설명이 필요합니다. 이러한 과제를 극복하기 위해, 잘 정의된 모델 설명을 제공하는 모델 카드[Mitchell et al., 2019]와 특정 AI 작업을 위한 데이터 카드[Gebru et al., 2021]를 모두 활용하는 것을 권장합니다. 이 접근 방식을 사용하면 언어 기반 인터페이스를 통해 다양한 모델을 연결하여 복잡한 AI 작업의 솔루션을 용이하게 할 수 있습니다. 또한 유사성을 포착하여 모델과 데이터 세트 간의 이전성을 향상시킬 수도 있습니다. AutoML-GPT는 다양한 머신 러닝 모델, 학습 파이프라인 및 데이터 세트를 연결하여 수많은 복잡한 AI 작업을 해결합니다. 보다 구체적으로, 해결하려는 각 AI 작업에 대해 해당 설명(예: 모델 카드 및 데이터 카드)을 사용하여 문단을 프롬프트로 사전 학습된 LLM(예: ChatGPT)에 융합하여 AutoML 파이프라인을 구축합니다. 그런 다음 시스템에서 LLM이 자동 학습을 수행하여 사용자의 입력 질문에 대한 예측된 학습 로그를 반환합니다. 이러한 교육 로그를 기반으로 그림 1에 표시된 요청(예: 하이퍼파라미터 튜닝)을 해결하기 위해 LLM과 더욱 상호 작용할 수 있습니다. 따라서 AutoML-GPT의 전체 프로세스는 4단계로 나눌 수 있습니다. 1) 데이터 처리, 2) 모델 아키텍처 설계, 3) 예측된 교육 로그를 사용한 하이퍼파라미터 튜닝, 4) 인간 피드백
--- EXPERIMENT ---
데이터 처리부터 모델 아키텍처, 하이퍼파라미터 튜닝, 예측된 학습 로그까지. AutoML-GPT의 강력한 언어 기능과 사용 가능한 AI 모델을 활용하여 AutoML-GPT는 다양한 작업과 데이터 세트에서 수많은 복잡한 AI 작업을 처리할 수 있습니다. 이 접근 방식은 컴퓨터 비전, 자연어 처리 및 기타 어려운 분야에서 놀라운 결과를 얻습니다. 광범위한 실험과 절제 연구는 우리의 방법이 많은 AI 작업에 일반적이고 효과적이며 유익할 수 있음을 보여줍니다. 1 서론 인공 지능(AI)은 최근 상당한 발전을 이루었습니다. 이러한 발전 중 ChatGPT[OpenAI, 2023]는 추론, 이해 및 상호 작용 능력으로 인해 특히 두드러졌습니다[Wu et al., 2023]. 지침에 따라 새로운 작업을 실행하는 능력은 인공 일반 지능을 달성하기 위한 중요한 단계이며 대규모 언어 모델(LLM)의 놀라운 기능은 컨텍스트 내 학습[Ram et al., 2023; Xie 등, 2021], 사고 사슬 프롬프트[Pilault 등, 2023; Wei 등, 2022b], 검색 및 읽기[Izacard 및 Grave, 2020; Zhang 등, 2021, 2022], GPT 기반 지능형 시스템[Zheng 등, 2023]. 이러한 영역은 LLM의 광대한 잠재력을 탐색하고 정교한 AI 시스템을 구축하기 위한 무한한 기회를 제공하는 것을 목표로 합니다. GPT-4[Brown 등, 2020; OpenAI, 2023], LLAMA[Touvron 등, 2023], Flan-T[Chung 등, 2022], PaLM[Chowdhery 등, 2022]과 같은 LLM은 자연어에 대한 깊은 이해와 일관되고 상황에 맞는 응답을 생성하는 능력을 보여주었습니다. 이러한 진전은 이미지 및 텍스트 처리와 같은 다양한 도메인 데이터와 도메인별 지식의 통합을 포함하는 어려운 작업에 대한 새로운 잠재적 응용 프로그램을 열어주었습니다. 이러한 맥락에서 LLM은 자연어를 이해하고 생성하는 능력을 통해 AI가 광범위한 과제를 더 잘 이해하고 해결할 수 있도록 하기 때문에 중요한 역할을 합니다. 이 논문에서는 LLM을 활용하여 사용자 입력 및 설명이 있는 데이터 세트에서 모델을 자동으로 학습시키는 AutoML-GPT라는 자동 머신 러닝(AutoML) 시스템을 개발하는 것을 목표로 합니다. LLM은 다양한 모델과 연결을 설정하고 입력을 처리하는 자동 학습 시스템으로 사용됩니다. LLM이 사용자와 상호 작용할 수 있도록 언어를 범용 인터페이스 및 프롬프트로 사용할 것을 제안합니다. 데이터와 모델 설명을 모두 프롬프트에 통합함으로써 LLM은 데이터 처리, 모델 아키텍처 설계 및 하이퍼파라미터 튜닝을 위해 AI 모델을 관리할 수 있습니다. 필요에 따라 이러한 모델을 호출하여 AI 작업을 해결하고 예측된 학습 로그를 반환할 수 있습니다. 그러나 여러 AI 모델을 LLM에 통합하려면 상당한 수의 고품질 모델 설명이 필요합니다. 이러한 과제를 극복하기 위해, 잘 정의된 모델 설명을 제공하는 모델 카드[Mitchell et al., 2019]와 특정 AI 작업을 위한 데이터 카드[Gebru et al., 2021]를 모두 활용하는 것이 좋습니다. 이 접근 방식을 사용하면 언어 기반 인터페이스를 통해 다양한 모델을 연결하여 복잡한 AI 작업의 솔루션을 용이하게 할 수 있습니다. 또한 유사성을 포착하여 모델과 데이터 세트 간의 이전성을 향상시킬 수도 있습니다. AutoML-GPT는 다양한 머신 러닝 모델, 학습 파이프라인 및 데이터 세트를 연결하여 수많은 복잡한 AI 작업을 해결합니다. 보다 구체적으로, 해결하려는 각 AI 작업에 대해 해당 설명(예: 모델 카드 및 데이터 카드)을 사용하여 문단을 프롬프트로 사전 학습된 LLM(예: ChatGPT)에 융합하여 AutoML 파이프라인을 구축합니다. 그런 다음 시스템에서 LLM이 자동 학습을 수행하여 사용자의 입력 질문에 대한 예측된 학습 로그를 반환합니다. 이러한 학습 로그를 기반으로 LLM과 더욱 상호 작용하여 그림 1에 표시된 요청(예: 하이퍼파라미터 튜닝)을 해결할 수 있습니다. 따라서 AutoML-GPT의 전체 프로세스는 4단계로 나눌 수 있습니다. 1) 데이터 처리, 2) 모델 아키텍처 설계, 3) 예측된 학습 로그를 사용한 하이퍼파라미터 튜닝, 4) 실험 데이터에 대한 인간의 피드백. 이러한 설계의 이점을 활용하여 그림 1의 AutoML-GPT는 외부 모델을 사용할 수 있으므로 잘 알려진 벤치마크에서 여러 작업을 처리하고 메타데이터(데이터 카드)만 제공된 경우 알려지지 않은 개인 데이터 세트에 지식을 전송할 수 있습니다. 또한 이 파이프라인을 통해 AutoML-GPT는 작업별 전문가의 힘을 계속 흡수하여 성장하고 확장 가능한 AI 기능을 구현할 수 있습니다. 요약하면, 우리의 기여는 다음과 같습니다. • 대규모 언어 모델과 전문가 모델의 이점을 보완하기 위해 데이터 처리 및 모델 아키텍처 설계를 위한 시스템 역할을 하고 각 특정 작업에 대한 실험을 자동으로 수행하는 AutoML-GPT를 제안합니다. • 모델 카드와 모델 설명을 통합하고 데이터 카드와 데이터 설명을 통합하여 고정 형식의 프롬프트 문단을 제공하고 일반적인 AI 작업을 처리하는 교육 파이프라인을 구축합니다.• 언어, 비전 및 지속적 학습에 걸친 여러 AI 작업에 대한 광범위한 평가는 자동 교육에서 AutoML-GPT의 기능을 보여줍니다.또한 보이지 않거나 새로운 데이터 세트에 대한 하이퍼파라미터 튜닝을 제공하는 효과를 보여줍니다.입력 문단 데이터 카드 모델 카드 평가 지표 및 데이터 추가 처리 모델 아키텍처 하이퍼파라미터 튜닝 예측 교육 로그 그림 1: AutoML-GPT 개요.일부 표기법은 해당 구성 요소와 함께 레이블이 지정됩니다.&#39;평가 지표 및 추가&#39;는 평가 지표 및 추가 요청을 나타냅니다.AutoML-GPT AutoML-GPT는 데이터 및 모델 정보를 사용하여 프롬프트 입력 문단을 포맷하는 협업 시스템입니다.LLM은 컨트롤러 역할을 하는 반면 수많은 전문가 모델은 협업 실행자 역할을 합니다.AutoML-GPT의 워크플로는 데이터 처리, 모델 아키텍처 설계, 하이퍼파라미터 튜닝 및 교육 로그 생성의 네 단계로 구성됩니다. 구체적으로, AutoML-GPT에 대한 일반적인 레시피를 제안합니다.1) 모델 카드와 데이터 카드가 모두 있는 고정 형식 프롬프트 문단을 생성합니다.2) 학습 파이프라인을 빌드하고 선택한 데이터 세트와 모델 아키텍처에서 사용자 요청을 처리합니다.3) 성능 학습 로그를 생성하고 하이퍼파라미터를 조정합니다.4) 자동 제안된 하이퍼파라미터로 모델을 조정합니다.2.1 입력 분해 AutoML-GPT의 첫 번째 단계에서 LLM은 사용자로부터 입력을 받습니다.LLM의 성능을 높이고 효과적인 프롬프트를 생성하기 위해 입력 프롬프트에 대한 특정 지침을 사용합니다.지침은 아래에 설명된 세 부분으로 구성되어 있습니다.데이터 카드데이터 세트의 의도된 사용 사례를 명확히 하고 적합하지 않은 컨텍스트에서 사용을 최소화하기 위해 이 데이터 세트에 대한 포괄적인 설명서를 제공하는 데이터 카드를 활용합니다.그림 2에서 볼 수 있듯이 데이터 카드의 핵심 구성 요소는 데이터 세트 이름, 입력 데이터 세트 유형(예: 이미지 데이터 또는 텍스트 데이터), 레이블 공간(예: 클래스 유형 또는 해상도) 및 기본 평가 메트릭으로 구성됩니다. 데이터 이름 ImageNet: 1000class 분류 ... 입력 데이터 유형 레이블 공간 Eval Image 클래스 유형: 상어... FiD 자연어 질문: 오픈 도메인 ... 답변이 포함되어 있을 수도 있고 그렇지 않을 수도 있는 텍스트 Wikipedia ... 정확히 일치... 데이터 카드 COCO 데이터: 대형 이미지 스케일 객체 ... 객체 범주: 사람... 상자 AP L 그림 2: 데이터 카드에는 데이터 이름, 입력 데이터 유형, 레이블 공간 및 평가 지표가 포함됩니다. 데이터 카드 내에서 같은 색상은 단일 데이터 세트에서 비롯된 정보를 나타냅니다. 모델 카드 그림 3의 모델 카드는 앞서 설명한 &quot;데이터 카드&quot;를 보완하며, 데이터 세트를 학습하고 테스트하는 데 사용된 모델의 세부 정보를 보고하는 제안된 패러다임 중 하나입니다. 모델 카드는 모델 이름, 모델 구조(예: UperNet [Xiao et al., 2018] 헤드가 있는 Swin transformer [Liu et al., 2021]), 모델 설명 및 아키텍처 하이퍼파라미터로 구성됩니다. 모델 카드는 이 정보를 제공함으로써 LLM에 사용된 머신 러닝 시스템과 사용자가 모델 아키텍처에 대해 원하는 유연성의 정도를 알려줍니다.이를 통해 LLM에서 보다 포괄적인 결과를 만들 수 있습니다.모델 이름 모델 구조 모델 Des 아키텍처 Hyper Swin Transformer 윈도우가 있는 다중 헤드 셀프 어텐션... GELU가 있는 2층 MLP가 있는 이동된 윈도우... 윈도우 크기: 7... UNet 합성곱 네트... RELU와 풀링이 이어지는 두 개의 합성곱... 채널 수: 256... 모델 카드 DPR 질문 인코더... Dense 검색기는 biencoder입니다.... 인코더 시퀀스 길이: 350... 그림 3: 모델 카드는 모델 이름, 모델 구조, 모델 설명 및 아키텍처 하이퍼파라미터로 구성됩니다.모델 카드에서 같은 색상은 단일 모델 카드의 정보를 나타냅니다.평가 지표 및 추가 요청 사용자는 모델 카드와 데이터 카드 외에도 추가 평가 벤치마크, 지표 또는 모든 제약 조건을 요청할 수 있습니다. 기본 평가 지표를 제외하고 모델 아키텍처를 선택할 때 사용자의 요청에 따라 특정 지표나 제약 조건을 추가할 수 있습니다. 예를 들어, &quot;추론 시간이 10FPS보다 작음&quot;이라는 제약 조건이 주어지면 평가 지표와 제약 조건에 따라 사용자 요청을 처리합니다. 이 지침과 이러한 평가 지표와 추가 요청에 대한 인간의 피드백을 활용하여 LLM은 지침을 더 잘 따를 수 있습니다. AutoML-GPT는 이러한 작업 사양을 LLM에 제공하여 사용자의 요청을 적절히 분석하기 위한 고급 지침으로 제공합니다. 2.2 데이터 처리 데이터 처리란 데이터의 품질과 파생된 유용한 정보가 모델의 학습 능력에 직접적인 영향을 미치기 때문에 머신 러닝에서 필수적인 단계입니다. 따라서 모델에 데이터를 입력하기 전에 데이터를 처리하는 것이 중요합니다. 예를 들어, 컴퓨터 비전에서 데이터 처리란 분석 또는 머신 러닝 알고리즘을 위해 원시 이미지 데이터를 준비하는 데 사용되는 기술과 방법의 집합을 말합니다. 여기에는 이미지 크기 조정, 정규화, 증강 및 필터링이 포함될 수 있습니다. 마찬가지로 자연어 처리(NLP) 프로젝트에서 데이터 처리란 원시 텍스트 데이터를 머신 러닝 알고리즘이 쉽게 이해하고 처리할 수 있는 구조화되고 정리된 형식으로 변환하는 것을 말합니다. 토큰화, 불용어 제거, 소문자로 바꾸기, 특수 문자 및 숫자 제거와 같은 기술이 일반적으로 사용됩니다. 제공된 데이터 카드와 데이터 설명을 기반으로 AutoML-GPT는 프로젝트 요구 사항과 데이터의 특성에 따라 특정 프로세스 기술을 제공합니다. 2.3 모델 아키텍처 AutoML-GPT는 작업 목록을 처리할 때 각 작업을 해당 모델과 일치시켜 기본적으로 목록의 모든 작업에 적합한 모델을 선택해야 합니다. 이를 위해 먼저 사용자 입력에서 모델 카드와 모델 설명을 수집합니다. 그런 다음 컨텍스트 내 작업-모델 할당 메커니즘을 사용하여 모델을 작업에 동적으로 할당합니다. 이 접근 방식은 증분적 모델 액세스를 가능하게 하고 제공된 모델 설명과 사용자 요청에 대한 더 나은 이해를 결합하여 더 큰 개방성과 유연성을 제공합니다. 모델 아키텍처는 머신 러닝 모델의 설계, 구조 및 구성 요소에 대한 자세한 설명을 말합니다. 이러한 설명에는 일반적으로 다음 요소가 포함됩니다. 입력 및 출력 계층, 은닉 계층, 활성화 함수, 손실 함수 및 모델별 구성 요소(예: 주의 메커니즘, 합성곱 계층 또는 순환 계층). 2. 예측된 학습 로그를 사용한 하이퍼 매개변수 튜닝 특정 데이터 세트에서 주어진 모델에 대해 최상의 성능을 제공하는 최적의 하이퍼 매개변수 세트를 찾으려면 하이퍼 매개변수 튜닝이 머신 러닝에서 중요한 단계입니다. 하이퍼 매개변수는 학습 프로세스 중에 학습되지 않지만 미리 정의되어 모델의 학습 동작의 다양한 측면을 제어하는 구성 설정입니다. 일반적인 하이퍼 매개변수의 예로는 학습률, 배치 크기, 은닉 계층 수 및 계층당 뉴런 수가 있습니다. 실제 머신에서 학습하지 않고 하이퍼 매개변수를 튜닝하기 위해 제공된 데이터 카드 및 모델 카드에 대해 주어진 하이퍼 매개변수 설정에 대한 학습 로그를 생성하여 성능을 예측합니다. AutoML-GPT는 자동으로 학습을 수행하고 학습 로그를 반환합니다. 데이터 세트에서 모델 성능의 학습 로그는 학습 프로세스 중에 수집된 다양한 메트릭과 정보를 기록합니다. 모델의 진행 상황을 이해하고, 잠재적 문제를 식별하고, 선택한 아키텍처, 하이퍼파라미터, 최적화 기술의 효과를 평가하는 데 도움이 됩니다. 일반적인 학습 로그에는 학습 및 검증 메트릭이 있는 에포크 번호가 포함됩니다. 학습 로그를 검토하면 사용자 피드백에 따른 모델 성능에 대한 기본적인 이해를 형성할 수 있습니다. 데이터 이름 새 데이터 세트: 객체 데이터 세트... 레이블 공간 객체 범주: 10개 클래스... 데이터 카드 텍스트 인코더 유사도 입력 데이터 유형 이미지 평가 모델 이름 Swin Transformer 모델 카드 모델 Des Box AP 2계층 MLP가 있는 이동된 창... 모델 구조 다중 헤드 셀프 어텐션... 아키텍처 하이퍼파라미터 창 크기: 7... 모델 매개변수 AutoML-GPT 프롬프트 단락 {유사도가 있는 데이터 카드 세트: 5개 이미지 클래스가 있는 새 데이터 세트...}가 있다고 가정하고 {모델 매개변수가 있는 해당 모델 카드 세트: ...가 있는 슬라이드 창 Swin Transformer}를 모델로 채택합니다. Auto ML GPT 예측 학습 로그 다음은 제안된 하이퍼파라미터를 사용하여 새 데이터 세트에서 학습된 ViT 모델에 대한 학습 로그입니다.에포크: [0][ 0/25] 에포크: [0][10/25] 시간 1.015(1.015) 데이터 0.353(0.353) 손실 0.4065e+00 가속@1 97.75(97.75) 가속@5 100.00(100.00) 시간 0.511(0.583) 데이터 0.000(0.032) 손실 0.3827e+00 가속@1 93.75(98.86) 가속@5 100.00(100.00) 그림 4: 보이지 않는 데이터 세트에 대한 AutoML-GPT 개요: 상단 블록은 데이터 카드와 모델 정보를 보여줍니다. 먼저 여러 데이터 세트에 대한 학습 정보를 기록합니다. 이러한 데이터 세트의 데이터 카드는 텍스트 인코더를 통해 처리되어 유사도 점수를 얻은 다음, 해당 학습된 모델의 모델 매개변수와 결합하여 AutoML-GPT 프롬프트 문단을 형성합니다. 하단 블록은 보이지 않는 데이터 세트에 대한 권장 하이퍼 매개변수 설정을 기반으로 예측된 학습 로그를 표시합니다. 보이지 않는 데이터 세트 보이지 않는 비공개 데이터 세트에 대한 하이퍼 매개변수 튜닝은 훨씬 더 어려울 수 있습니다. 보이지 않는 데이터 세트의 메타데이터가 주어지면 AutoML-GPT는 해당 데이터 세트에 효과적일 가능성이 높은 하이퍼 매개변수 구성을 추천할 수 있습니다. 데이터 카드를 사용하여 필요한 텍스트 설명을 활용하고 보이지 않는 데이터 세트와 기존 데이터 세트 간의 상관 관계를 식별합니다. 상관 관계를 기반으로 기존 데이터 세트의 하이퍼 매개변수 설정을 새 보이지 않는 데이터 세트로 전송합니다. 상관 관계를 계산하기 위해 텍스트 인코더를 사용하여 데이터 카드를 인코딩합니다. 구체적으로 데이터 카드에는 클래스 유형, 해상도, 이미지 크기 및 기타 관련 메타데이터와 같은 정보가 포함됩니다. 데이터 세트 규모, 작업 설명, 레이블 공간 및 입출력 데이터 유형을 텍스트 인코더(예: CLIP [Radford et al., 2021])의 입력으로 사용하고 인코딩된 잠재 표현의 유사도 점수를 사용하여 이 보이지 않는 데이터 세트와 기존 데이터 세트 간의 상관 관계를 설명합니다.3 실험 AutoML-GPT의 성능을 평가하고 ChatGPT(OpenAI의 &quot;GPT-4&quot; 버전)¹을 사용하여 구현합니다.다양한 사례 연구를 수행하여 여러 각도에서 접근 방식의 효과를 보여줍니다.3.1 보이지 않는 데이터 세트 그림 4에서는 AutoML-GPT를 사용하여 보이지 않는 데이터 세트에 대한 학습 결과를 보여줍니다.실제 사례에서 성능을 확인하기 위해 이미 학습된 데이터 세트와 일부 학습되지 않은 데이터 세트에 대한 성능 및 하이퍼 매개변수 세트를 구성합니다.이러한 학습되지 않은 데이터 세트에 대한 하이퍼 매개변수 구성을 예측합니다.Vinyals et al. [2016]에 설명된 분류 설정을 기반으로 테스트 환경을 만듭니다. 또한 MiniImageNet [Vinyals et al., 2016]을 따라 훈련 데이터 세트 [Deng et al., 2009]를 80%와 20% 부분으로 하위 샘플링하고 분할합니다. 80% 데이터에서 데이터 카드와 해당 모델 카드(모델 최상의 하이퍼파라미터 포함)를 구성합니다. 15개 클래스를 무작위로 선택하여 다양한 하위 세트 데이터 세트(예: 데이터 세트 A, B 등)를 만들고, 하이퍼파라미터를 그리드 검색하고, ViT 기본 모델을 미세 조정하고 [Dosovitskiy et al., 2020] 이러한 하위 세트 데이터 세트에서 최상의 성능을 기록합니다. 그런 다음 나머지 20% 데이터에서 10개의 이미지 클래스로 &quot;New&quot;라는 새 데이터 세트를 만듭니다. 한국어: https://platform.openai.com/Data Name Data Card COCO Data: 대규모 객체... Input Data Type Image Label Space Object Categories: person... Eval Box AP Model Card Model Name Swin Transformer Model Structure Multi-head self attention with ... Model Des Shifted window with a 2-layer MLP ... Architecture Hyperparameter Window size: 7 ... AutoML-GPT Prompt Paragraph {328K images and evaluation metric이 있는 데이터 카드: COCO 데이터 세트 ...}가 있다고 가정하고, {모델 카드: slided window swin transformer ...}를 모델로 채택합니다. {A: 데이터 처리} 및 {B: 모델 아키텍처} 스크립트를 사용하여 COCO 데이터 세트를 처리합니다. {리소스: 4 Nvidia a5000 GPU}의 하이퍼파라미터에 {C: 하이퍼파라미터}를 사용합니다. 그러면 {D: 예측된 학습 로그}가 생깁니다. 데이터 처리 COCO에서 swin transformer 기반 객체 감지를 위한 데이터 전처리에 사용하는 python 스크립트는 다음과 같습니다.import torch import torch optim as optim import torch optim.Ir_scheduler as Ir_scheduler from torch.utils.data import Datal.cader from torchvision datasets import CocoDetection from torchvision import transforms from models.detr import DETR setup data loaders train_transforms transforms.Compose([ transforms.Resize((800, 800)), transforms RandomHorizontalFlip(), transforms.To Tensor() transforms.Normalize([0.485, 0.456, 0.406], [0.229. 0.224.0.225]) 하이퍼파라미터 튜닝 제안하신 모델 카드와 데이터 카드를 사용합니다. 객체 감지를 위한 COCO 데이터 세트의 DETR 모델의 하이퍼파라미터는 다음과 같습니다.학습률: 0.가중치 감소: 1e-Optimizer: AdamW 스케줄러: 워밍업 기능이 있는 MultiStepLR ... AutoMLGPT 모델 아키텍처 변압기 기반 모델과 슬라이드 윈도우 방식을 사용하여 COCO 데이터 세트에서 객체를 감지하기 위해 DETR은 변압기 인코더와 디코더를 갖추고 있으며 단일 전방 패스에서 일련의 객체 쿼리와 해당 경계 상자 예측을 직접 출력하도록 설계되었습니다. 이를 통해 앵커 기반 또는 앵커 없는 감지 방법이 필요 없게 되고 COCO 객체 감지에서 최첨단 성능을 달성합니다... 예측된 학습 로그 ere는 제안된 하이퍼파라미터를 사용하여 COCO 데이터 세트에서 학습된 Swin Transformer Base 백본이 있는 DETR 모델에 대한 학습 로그입니다.Epoch: [1] [ 0/1000] eta: 1일, 6:54:48 Ir: 0.000100 loss: 4.8577 (4.8577) loss_ce: 3.9479 (3.9479) loss_bbox: 0.0363 (0.0363) loss_giou: 0.8735 (0.8735) loss_cls: 0.0000 (0.0000) acc: 0.0000 (0.0000) loss obj: 0.0000 (0.0000) loss_rpn_box: 0.0000 (0.0000) 시간: 25.7651 데이터: 3.7903 최대 mem:Epoch: [1] [10/1000] eta: 4:51:08 Ir: 0.000100 손실: 4.4567 (4.5028) loss_ce: 3.3551 (3.5238) loss_bbox: 0.0429 (0.0398) loss_giou: 0.9994 (0.9398) loss_cls: 0.0000 (0.0000) acc: 0.0000 (0.0000) 손실 obj: 0.0000 (0.0000) loss_rpn_box: 0.0000 (0.0000) 시간: 14.7129 데이터: 0.5279 최대 메모리:그림 5: 객체 감지를 위한 AutoML-GPT 개요: 상단 블록은 데이터 카드와 모델 카드를 표시합니다. 중간 블록은 데이터 카드와 모델 카드에서 파생된 AutoML-GPT 프롬프트 문단을 보여줍니다. 하단 블록은 데이터 처리, 모델 아키텍처, 하이퍼파라미터 튜닝, 예측된 교육 로그의 네 가지 단계를 설명합니다. 예측된 교육 로그를 사용하여 하이퍼파라미터를 튜닝한 다음 하이퍼파라미터를 사용자에게 피드백합니다. 보이지 않는 데이터 세트에 대한 접근 방식의 기능을 보여주기 위해 AutoML-GPT를 사용하여 제공된 데이터 카드와 모델 카드를 기반으로 &quot;새로운&quot; 데이터 세트에 대한 최상의 교육 구성을 추천합니다. 데이터 카드에서 레이블 공간, 즉 각 클래스에 대한 텍스트 설명을 기록합니다. 실제로 데이터 카드의 텍스트를 텍스트 인코더(예: CLIP 텍스트 인코더)를 통해 전달하고 유사도를 계산하여 두 데이터 카드 간의 유사도 점수를 통합합니다. 구체적으로 그림 4에서 &quot;새로운&quot; 데이터 세트는 데이터 세트 A와 60%의 레이블 공간 유사성을 갖고 데이터 세트 B와 40%의 레이블 공간 유사성을 갖는다고 명시합니다. 이 정보와 데이터 세트 A 및 B에 대한 데이터 카드의 하이퍼 매개변수 설정을 사용하여 AutoML-GPT는 &quot;새로운&quot; 데이터 세트에 대한 학습을 위한 적절한 하이퍼 매개변수 설정을 추천할 수 있습니다. 실험에서 평균 무작위 선택 하이퍼 매개변수를 사용한 80%의 Top 1 정확도와 비교하여 Top 1 예측에 대해 98%의 정확도를 달성했습니다. 게다가 추가 데이터 세트를 제공하지 않고 AutoML-GPT에서 제안한 하이퍼 매개변수 설정을 사용하여 모델을 초기화합니다. 이 구성을 사용하면 평균 무작위 선택 하이퍼 매개변수보다 나은 82%의 Top 1 정확도를 달성하지만 권장 설정만큼 좋지는 않습니다. 또한 ChatGPT가 특정 작업(예: 이미지 분류)에 대해 좋은 하이퍼 매개변수 설정을 제공할 수 있음을 시사합니다. 이는 보이지 않거나 새로운 데이터 세트에서도 머신 러닝 문제를 해결하는 데 제안한 자동 학습 접근 방식의 효과를 보여줍니다. 이러한 결과는 정확한 하이퍼파라미터 추천을 제공하여 머신 러닝을 향상시키는 자동 학습 방법의 잠재력을 강조합니다.3.2 객체 감지 그림 5는 객체 감지를 위한 COCO 데이터 세트[Lin et al., 2014]에 대한 결과를 보여줍니다.① 상단 블록은 사용자 입력을 기반으로 COCO 데이터 세트의 데이터 카드와 ImageNet의 모델 카드를 표시합니다.가운데 블록은 입력 분해에서 파생된 AutoML-GPT 프롬프트 문단을 보여줍니다.데이터 카드와 모델 카드의 정보는 자동으로 프롬프트 형식에 통합됩니다.데이터 처리, 모델 아키텍처 설계, 하이퍼파라미터 튜닝 및 학습 로그 생성에 대한 결과를 보고합니다.데이터 처리에서 AutoML-GPT는 입력 데이터 세트를 처리하기 위한 스크립트를 생성합니다.또한 그림 5에서 Python 스크립트 예제를 제공합니다.모델 아키텍처 설계의 경우 파이프라인은 후속 학습을 위한 모델 구성을 생성합니다. 데이터와 모델이 모두 준비되면 하이퍼파라미터 튜닝 단계에서 자세한 구성(예: 학습률: 10-4, 가중치 감소: 10-4)이 제공되고 예측된 학습 로그로 추가로 튜닝됩니다. ③ 이러한 결과는 우리 방법이 데이터 카드 데이터 이름 자연어 질문: 개방 도메인 ... 입력 데이터 유형 텍스트 레이블 공간 Eval Wikipedia that may or may not... 정확히 일치... 모델 카드 모델 이름 DPR 모델 Des Dense retriever bi-encoder.... 모델 구조 질문 인코더... 아키텍처 하이퍼파라미터 인코더 시퀀스 길이: 350 ... AutoML-GPT 프롬프트 단락 {데이터 카드: 자연어 질문이 개방되어 있습니다...}가 있다고 가정하고 {모델 카드: DPR with the dense retriever which is biencoder...}를 모델로 채택합니다. 자연어 질문에 답하는 데이터 세트를 처리하기 위해 {A: 데이터 처리} 및 {B: 모델 아키텍처} 스크립트를 사용합니다. {리소스: 8 Nvidia v100 GPU}의 하이퍼파라미터에 {C: 하이퍼파라미터}를 사용합니다.그러면 학습 로그 {D: 예측 학습 로그}가 생깁니다.또한 {추가 요청: DPR 검색기의 더 빠른 추론 시간}도 있습니다.데이터 처리 다음은 오픈 도메인 질의응답을 위한 NQ 데이터 세트에서 DPR의 데이터 전처리를 위한 Python 스크립트입니다.import json import random def load_data(file_path): with open(file_path, &#39;&#39;) as f data = json.load(f) def prepare_data(data): processed_data =[]AutoMLGPT 하이퍼파라미터 튜닝 제안하신 모델 카드와 데이터 카드를 사용합니다. DPR 모델의 하이퍼파라미터 o Natural Questions(NQ) 데이터 세트는 다음과 같습니다.모델 아키텍처 개방형 도메인 질의응답을 위한 Natural Questions(NQ) 데이터 세트의 DPR(Dense Passage Retrieval)에 대한 모델 아키텍처에는 두 가지 구성 요소가 포함됩니다.Retriever ... 예측된 학습 로그 다음은 제안된 하이퍼파라미터를 사용하여 NQ 데이터 세트에서 학습된 Retriever를 포함하는 DPK 모델에 대한 학습 로그입니다.학습 로그: poch 1: 100회 반복 - 손실: 6. 반복 200 - 손실: 4. 반복 300 - 손실: 3.6890... Retriever 학습 하이퍼파라미터: 배치 크기: 학습률: 1e-max_epochs: warmup_steps:. drop_out: 0.1 ... 추가 요청(예): DPR 검색기의 추론 시간 단축 성능을 크게 희생하지 않고 추론 시간을 단축하려면 특정 ... 모델을 학습하기 위한 제안된 구성은 다음과 같습니다.hatch size:learning rate: 1-max_epochs:# 추론을 가속화하기 위한 추가 하이퍼파라미터 model dimension: 256 #모델 차원 축소(BERT 기반 DPR의 경우 기본값은 768) max_sequence_length: 128 #입력 시퀀스 길이 제한(기본값은 512)... 그림 6: 질의 응답을 위한 AutoML-GPT 개요: 위 블록은 데이터 카드와 모델 정보를 제공하고 가운데 블록은 데이터 카드와 모델 카드에서 파생된 AutoML-GPT 프롬프트 문단을 강조 표시합니다. 아래 블록은 데이터 처리, 모델 아키텍처, 하이퍼파라미터 튜닝, 예측된 학습 로그의 네 가지 단계를 자세히 설명합니다. LLM을 다운스트림 작업에 유연하게 적용하기 위한 효과적인 파이프라인. 데이터와 모델 카드를 사용하여 AutoML-GPT 프롬프트 문단을 도출하는 우리의 접근 방식은 LLM 프롬프트 구성 요소를 향상시키는 데 중점을 둔 작업을 위한 보완 모듈로 간주될 수도 있습니다.3.3 질의 응답 우리는 그림 6에서 Natural Questions Open 데이터 세트[Kwiatkowski et al., 2019]에 대한 실험 결과를 제시합니다.우리는 Dense Passage Retrieval(DPR)[Karpukhin et al., 2020]을 활용합니다.데이터 카드의 경우 사용자는 데이터 이름, 입력 데이터 유형, 레이블 공간 및 평가 메트릭을 입력합니다.② 모델 카드의 경우 모델 이름, 모델 구조, 모델 설명 및 아키텍처 하이퍼파라미터를 포함합니다.③ 생성된 AutoML-GPT 프롬프트 문단을 사용하여 AutoML-GPT는 데이터 처리, 모델 아키텍처 생성, 하이퍼파라미터 튜닝을 수행하고 예측된 교육 로그를 생성합니다. &quot;하이퍼파라미터 튜닝&quot;에서 볼 수 있듯이 AutoML-GPT에서 생성한 하이퍼파라미터와 DPR에서 제공한 하이퍼파라미터는 긴밀하게 일치합니다. 예를 들어 학습률은 10-5이고 최대 에포크는 40입니다. ④예측된 학습 로그가 제공되면 사용자가 요구 사항에 따라 AutoML-GPT에 다양한 평가 지표나 모델 아키텍처를 요청할 수 있는 시나리오를 보여줍니다(그림 6 &quot;추가 요청: DPR 검색기의 빠른 추론 시간&quot; 참조). 그림 6에서 반환된 응답에서 볼 수 있듯이 AutoML-GPT는 &quot;성능을 너무 많이 희생하지 않고도&quot;와 같은 힌트도 제공합니다. AutoML-GPT는 이러한 요청과 예측된 로그를 기반으로 하이퍼파라미터를 추가로 튜닝합니다. 저희의 방법은 실험을 자동으로 수행하고 대화형 하이퍼파라미터 튜닝을 수행하는 강력한 기능을 보여줍니다. 또한 저희의 접근 방식이 다양한 데이터 세트에 적합하고 다양한 입력 유형과 도메인에서 일반화할 수 있음을 확인합니다. 3.4 분류 저희는 또한 UCI 성인 데이터 세트[Dua 및 Graff, 2017] XGBoost를 사용합니다. 이전과 마찬가지로 데이터 카드와 모델 카드를 제공하여 입력 프롬프트 문단을 생성합니다. 그림 7에서 볼 수 있듯이 동일한 교육 파이프라인이 여기에 적용됩니다. 또한 AutoML-GPT에서 제안한 하이퍼파라미터 설정을 준수하고 XGBoost 모델을 교육합니다. 이 교육의 최종 검증 손실은 0.277이고 정확도는 85.92%입니다. 입력과 작업이 다르지만 제안하는 AutoML-GPT는 분류에서 지속적으로 강력한 성능을 제공합니다. 이는 AutoML-GPT가 광범위한 machineData Name UCI Adult income dataset... Label Space Classification Data Card Input Data Type Categorical, Int... Eval AUC... Model Name XGBoost Model Des An optimized distributed ... Model Card Model Structure It is an ensemble learning... Architecture Hyperparameter Booster: tree-based methods... AutoML-GPT Prompt Paragraph 가정해 보자. {Data Card: UCI adut income dataset is...}, {Model Card: XGBoost is an ensemble learning...}을 모델로 채택한다. {A: Data Processing}과 {B: Model Architecture} 스크립트를 사용해 UCI ault income dataset을 처리한다. {C: Hyperparameter}를 사용해 {Resource: AMD EPYC 7702P 64-Core Processor}의 하이퍼파라미터를 처리한다. 그러면 학습 로그 {D: Predicted Training Log}가 생긴다. import pandas as pd import numpy as np 데이터 처리 모델 아키텍처 XGBoost(eXtreme Gradient Boosting)는 의사결정 트리를 기본 학습자로 활용하는 앙상블 방식입니다. XGBoost의 모델 아키텍처는 여러 의사결정 트리로 구성되어 있으며, 각 트리는 앙상블의 이전 트리의 오류를 수정하기 위해 반복적으로 추가됩니다. 최종 예측은 앙상블의 모든 트리의 예측 합계에 따라 이루어집니다... UCI 성인 데이터 세트에 대한 XGBoost의 데이터 전처리를 위한 Python 스크립트는 다음과 같습니다. from sklearn preprocessing import LabelEncoder from sklearn model_selection from xgboost import XGBC port train_test_split XGBClassifier from sklearn metrics import accuracy_score # 데이터 세트 로드 url=&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data&quot; column_names=[&#39;age&quot;, &quot;workclass&quot;, &quot;fnlwgt&quot;, &quot;education&#39;, &#39;education-num&#39;, &#39;marital-status&#39;, &#39;occupation&#39;, &#39;relationship&#39;, &#39;race&#39;, &#39;sex&#39;, &#39;capital-gain&#39;, &#39;capital-loss&#39;, &#39;hours-per-week&#39;, &#39;native-country&#39;, &#39;income&#39;] .. 하이퍼파라미터 튜닝 귀하께서 제안하신 모델 카드와 데이터 카드를 사용합니다. UCI 성인 데이터 세트에 대한 XGBoost 모델의 하이퍼파라미터는 다음과 같습니다. xgb_params ={ &#39;objective&#39;: &#39;binary:logistic&#39;, # 이진 분류 문제 &#39;n estimators&#39;: 100, # 앙상블의 트리 수 &#39;max_depth&#39;: 6, # 각 트리의 최대 깊이 &#39;learning_rate&quot;: 0.3, # 최종 결과에 대한 각 트리의 기여도 ... AutoMLGPT 최종 Val Loss 0. 예측된 학습 로그 제안된 하이퍼파라미터를 사용한 UCI 성인 데이터 세트에 대한 XGBoost의 학습 로그는 다음과 같습니다. [0] validation_0-logloss:0.[1] validation_0-logloss:0.[2] validation 0-logloss:0.[3] validation_0-logloss:0.42562... 그림 7: 분류를 위한 AutoML-GPT 개요: 상단 블록은 데이터 카드와 모델 정보를 표시하고 중간 블록은 데이터 카드와 모델에서 파생된 AutoML-GPT 프롬프트 문단을 보여줍니다. 카드. 하단 블록은 데이터 처리, 모델 아키텍처, 하이퍼파라미터 튜닝, 예측된 학습 로그의 4단계를 설명합니다. 또한 AutoML-GPT의 하이퍼파라미터 권장 사항에 따라 최종 검증 결과를 포함하고 모델을 학습합니다. 다양한 작업에 걸친 학습 문제. 4 관련 작업 고급 대규모 언어 모델 LLM은 1,000억을 초과하는 매개변수 크기를 갖는 제로샷 및 퓨샷 학습을 통해 견고성과 일반화 가능성을 보여주었습니다. LLM의 주목할 만한 예로는 매개변수가 5,300억 개인 Megatron-turing NLG[Smith et al., 2022], 매개변수가 2,800억 개인 Gopher[Rae et al., 2021], 매개변수가 5,400억 개인 PaLM[Chowdhery et al., 2022]이 있습니다. LLM의 확장은 이전에 더 작은 모델에서는 관찰되지 않았던 새로운 신생 능력을 잠금 해제했습니다[Wei et al., 2022a]. 이러한 LLM은 제로샷 학습을 위한 LLM의 우수성을 입증했습니다. 기존 LLM 중에서 ChatGPT는 고유한 특성을 가지고 있습니다. 사전 학습을 통해 축적된 지식과 일반화 능력을 유지하면서 대화와 같은 방식으로 사용자와 상호 작용할 수 있습니다. 한 걸음 더 나아가 이 작업에서는 대화를 넘어 다양한 작업에 대한 ChatGPT의 제로샷 학습 기능을 탐구합니다. 사고의 사슬 사고의 사슬(CoT) 프롬핑은 LLM이 답변하기 전에 중간 추론 단계를 생성하도록 유도합니다[Wei et al., 2022b]. 현재 CoT 프롬핑에 초점을 맞춘 두 가지 연구 분야가 있습니다. 한 가지는 수동으로 설계된 CoT를 탐구하는 것입니다. 수동으로 설계된 CoT에서 LLM은 추론 프로세스에 수동으로 설계된 기능과 데모를 적용합니다[Wei et al., 2022b]. Wang et al.[2022]은 사고의 사슬 프롬핑에서 사용되는 순진한 탐욕적 디코딩을 대체하기 위해 새로운 디코딩 전략인 자기 일관성을 제안합니다. 최근, Interactive-Chain-Prompting [Pilault et al., 2023]이 교차 언어 조건 생성의 모호성을 해결하기 위해 도입되었습니다. 또 다른 라인은 제로 샷 설정에 대한 연구를 수행하고 있으며, 여기서 STaR [Zelikman et al., 2022]은 자체 생성을 위해 도입되어 모델이 자체 개선하도록 돕고, 자동 추론 및 도구 사용(ART) [Paranjape et al., 2023]은 동결된 LLM을 사용하여 프로그램으로 중간 추론 단계를 자동으로 생성하는 프레임워크입니다. GPT 기반 시스템 GPT [Brown et al., 2020]는 유망한 성능 향상을 보여주었습니다. 최근의 연구 라인은 GPT 모델을 AI 시스템에 통합하는 데 중점을 두었습니다. HuggingGPT [Shen et al., 2023]는 HuggingFace 변환기 라이브러리로 구축되었으며 GPT를 상호 작용 에이전트로 활용합니다. VisualGPT [Wu et al., 2023]는 사용자가 ChatGPT와 상호 작용할 수 있도록 다양한 Visual Foundation 모델을 통합합니다. 오픈소스 AGI 연구 플랫폼인 OpenAGI [Ge et al., 2023]는 복잡하고 여러 단계로 구성된 작업을 제공하고 작업별 데이터 세트를 수반하도록 설계되었습니다. 마찬가지로 GPT를 AutoML 파이프라인에 통합합니다. 검색 엔진의 추가 정보를 통합할 수 있는 또 다른 GPT 기반 시스템도 있습니다(예: AutoGPT²). AutoML-GPT는 자동 학습 관점에서 ChatGPT의 영향을 재고합니다. 학습 파이프라인을 구축하고 처음부터 끝까지 AutoML 시스템을 구축하는 데 중점을 둡니다. 5
--- CONCLUSION ---
저희의 연구는 GPT에 AutoML 시스템을 구축하는 이점을 보여줍니다. 제안된 방법은 자동으로 기계 학습 실험을 수행할 수 있습니다. 이 자동 학습은 학습 효율성을 획기적으로 개선하고 모델의 성능을 향상시킵니다. 저희는 컴퓨터 비전, 자연스러운 질문 답변 및 분류 벤치마크에 걸친 사용 사례를 보여줍니다. 저희는 보이지 않는 데이터 세트와 사용자와 AutoML-GPT 간의 추가 상호 작용을 사용하여 자세한 사용 사례를 추가로 수행합니다. 요약하자면, 제안된 AutoML-GPT는 효과적이고 일반적이며 다양한 작업에 대한 기계 학습 모델을 조정하기 위한 자연어 인터페이스를 만들 수 있는 잠재력이 있습니다. 앞으로는 1) 잘 알려진 벤치마크에 대한 모델과 데이터 카드를 자동으로 생성하여 시스템의 일부로 만들고, 2) ChatGPT의 도움을 받아 대규모 사전 학습된 모델에서 작업 인식 하위 네트워크를 추출할 것입니다. 참고문헌 Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. 언어 모델은 few-shot 학습자입니다. 신경 정보 처리 시스템의 발전, 33:1877–1901. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: 경로로 언어 모델링 확장. arXiv 사전 인쇄본 arXiv:2204.02311. Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. 스케일링 명령어-미세 조정 언어 모델. arXiv 사전 인쇄본 arXiv:2210.11416. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: 대규모 계층적 이미지 데이터베이스. 2009년 IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스, 248-255쪽. IEEE. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. 2020. 이미지는 16x16 단어의 가치가 있습니다. 대규모 이미지 인식을 위한 변환기. arXiv 사전 인쇄 arXiv:2010.11929. 데루 두아(Dheeru Dua)와 케이시 그라프(Casey Graff). 2017. UCI 머신러닝 저장소. Yingqiang Ge, Wenyue Hua, Jianchao Ji, Juntao Tan, Shuyuan Xu 및 Yongfeng Zhang. 2023. Openagi: Ilm이 도메인 전문가를 만날 때. arXiv 사전 인쇄 arXiv:2304.04370. Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé Iii 및 Kate Crawford. 2021. 데이터세트용 데이터시트. ACM 커뮤니케이션, 64(12):86-92. 2https://github.com/Significant-Gravitas/Auto-GPTGautier Izacard and Edouard Grave. 2020. 생성 모델을 사용한 구절 검색을 활용하여 오픈 도메인 질문 답변. arXiv 사전 인쇄본 arXiv:2007.01282. Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Ledell Wu, Sergey Edunov, Danqi Chen, Wen-tau Yih. 2020. 오픈 도메인 질문 답변을 위한 밀집 구절 검색. 자연어 처리(EMNLP)의 경험적 방법. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, Slav Petrov. 2019. Natural Questions: 질문 답변 연구의 벤치마크. TACL. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, C Lawrence Zitnick. 2014. Microsoft coco: 맥락 속의 공통 객체. Computer Vision-ECCV 2014: 제13회 유럽 컨퍼런스, 스위스 취리히, 2014년 9월 6일-12일, 회의록, 5부 13, 740-755쪽. Springer. Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo. 2021. Swin transformer: 이동된 창을 사용한 계층적 비전 변환기. IEEE/CVF 국제 컴퓨터 비전 컨퍼런스 회의록, 10012-10022쪽. Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, Timnit Gebru. 2019. 모델 보고를 위한 모델 카드. 공정성, 책임성 및 투명성에 대한 컨퍼런스의 진행 사항, 220-229페이지. OpenAI. 2023. Gpt-4 기술 보고서. arXiv. Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, Marco Tulio Ribeiro. 2023. Art: 대규모 언어 모델을 위한 자동 다단계 추론 및 도구 사용. arXiv 사전 인쇄본 arXiv:2303.09014. Jonathan Pilault, Xavier Garcia, Arthur Bražinskas, Orhan Firat. 2023. Interactive-chain-prompting: 상호 작용을 통한 교차 언어 조건 생성을 위한 모호성 해결. arXiv 사전 인쇄본 arXiv:2301.10309. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. 2021. 자연어 감독을 통한 전이 가능한 시각적 모델 학습. 기계 학습에 관한 국제 컨퍼런스, 8748-8763쪽. PMLR. Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. 2021. 언어 모델 확장: Gopher 학습을 통한 방법, 분석 및 통찰력. arXiv 사전 인쇄본 arXiv:2112.11446. Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, Yoav Shoham. 2023. 컨텍스트 내 검색 증강 언어 모델. arXiv 사전 인쇄본 arXiv:2302.00083. Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, Yueting Zhuang. 2023. Hugginggpt: huggingface에서 chatgpt와 그 친구들을 사용하여 AI 작업 해결. arXiv 사전 인쇄본 arXiv:2303.17580. Shaden Smith, Mostofa Patwary, Brandon Norick, Patrick LeGresley, Samyam Rajbhandari, Jared Casper, Zhun Liu, Shrimai Prabhumoye, George Zerveas, Vijay Korthikanti, et al. 2022. deepspeed와 megatron을 사용하여 대규모 생성 언어 모델인 megatron-turing nlg 530b를 학습합니다. arXiv 사전 인쇄본 arXiv:2201.11990.Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: 개방적이고 효율적인 기초 언어 모델. arXiv 사전 인쇄본 arXiv:2302.13971. Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. 2016. 원샷 학습을 위한 매칭 네트워크. 신경 정보 처리 시스템의 발전, 29. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Denny Zhou. 2022. 자기 일관성은 언어 모델에서 사고의 사슬 추론을 개선합니다. arXiv 사전 인쇄본 arXiv:2203.11171. Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022a. 대규모 언어 모델의 새로운 능력. arXiv 사전 인쇄본 arXiv:2206.07682. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, Denny Zhou. 2022b. 사고의 사슬 촉진은 대규모 언어 모델에서 추론을 이끌어낸다. arXiv 사전 인쇄본 arXiv:2201.11903. Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, Nan Duan. 2023. Visual chatgpt: Visual Foundation 모델을 사용한 대화, 그림 그리기 및 편집. arXiv 사전 인쇄본 arXiv:2303.04671. Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, Jian Sun. 2018. 장면 이해를 위한 통합 지각적 구문 분석. 유럽 컴퓨터 비전 컨퍼런스(ECCV) 회의록, 418-434쪽. Sang Michael Xie, Aditi Raghunathan, Percy Liang, Tengyu Ma. 2021. 암묵적 베이지안 추론으로서의 맥락 내 학습에 대한 설명. arXiv 사전 인쇄본 arXiv:2111.02080. Eric Zelikman, Yuhuai Wu, Jesse Mu, Noah Goodman. 2022. Star: 추론을 추론으로 부트스트래핑. 신경 정보 처리 시스템의 발전, 35:15476–15488. Shujian Zhang, Chengyue Gong, Eunsol Choi. 2021. 질문에 대해 더 많이 알면 도움이 될 수 있습니다. 질문 답변에서 교정 개선. arXiv 사전 인쇄본 arXiv:2106.01494. Shujian Zhang, Chengyue Gong, Xingchao Liu. 2022. Passage-mask: Retriever-Reader 모델을 위한 학습 가능한 정규화 전략. arXiv 사전 인쇄본 arXiv:2211.00915. Mingkai Zheng, Xiu Su, Shan You, Fei Wang, Chen Qian, Chang Xu, Samuel Albanie. 2023. gpt로 신경 구조 검색을 수행할 수 있을까요? arXiv 사전 인쇄본 arXiv:2304.10970.
