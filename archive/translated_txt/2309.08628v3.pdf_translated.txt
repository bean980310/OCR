--- ABSTRACT ---
모델 적응은 프록시 학습 데이터와 실제 사용자 수신 데이터 간의 불일치를 처리하는 데 중요합니다. 적응을 효과적으로 수행하기 위해 사용자의 텍스트 데이터는 일반적으로 서버나 로컬 장치에 저장되며, 여기에서 다운스트림 자연어 처리(NLP) 모델을 이러한 도메인 내 데이터를 사용하여 직접 학습할 수 있습니다. 그러나 이는 사용자 정보를 적대자에게 노출시킬 수 있는 추가 위험으로 인해 개인 정보 보호 및 보안 문제를 일으킬 수 있습니다. 텍스트 데이터의 식별 정보를 일반 마커로 대체하는 것이 최근에 탐구되었습니다. 이 연구에서는 대규모 언어 모델(LLM)을 활용하여 마스크된 토큰의 대체물을 제안하고 다운스트림 언어 모델링 작업에서 효과를 평가합니다. 구체적으로, 사전 학습되고 미세 조정된 여러 LLM 기반 접근 방식을 제안하고 이러한 방법을 비교하기 위해 다양한 데이터 세트에 대한 실증 연구를 수행합니다. 실험 결과에 따르면 난독화 코퍼스에서 학습된 모델은 개인 정보 보호 토큰 마스킹 없이 원본 데이터에서 학습된 모델과 비슷한 성능을 달성할 수 있습니다. 색인 용어 개인 정보를 보호하는 머신 러닝, 언어 모델링, 대규모 언어 모델, 자동 음성 인식 1.
--- INTRODUCTION ---
중앙 서버나 사용자 기기에 머신 러닝 모델을 배포한 후 발생하는 일반적인 문제는 훈련 데이터와 수신된 실제 사용자 데이터 간의 불일치입니다. 특히 자연어 처리(NLP) 응용 프로그램에서 실제 사용자의 텍스트 데이터의 의미적 특성과 주제는 모델 적응이 필수적인 시나리오인 서버 측 프록시 코퍼스와 매우 다를 수 있습니다[1, 2]. 모델 적응을 효과적으로 수행하기 위해 사용자의 텍스트 데이터는 일반적으로 서버나 해당 기기에 저장되며, 이러한 다운스트림 NLP 모델은 이러한 도메인 내 데이터를 사용하여 훈련됩니다. 그러나 사용자의 개인 데이터에는 이름, 주소, 신용 카드 번호와 같은 민감한 사용자 정보가 포함될 수 있습니다. 따라서 이러한 기존 사용자 데이터 저장 관행은 사용자 정보를 적대자에게 노출시킬 위험으로 인해 개인 정보 보호 및 보안 문제를 일으킬 수 있습니다. 또한 최근 연구에 따르면 훈련 데이터 세트의 민감한 정보를 감지한 다음 예상치 못한 방식으로 추출할 수 있음이 밝혀졌습니다[3, 4, 5, 6, 7]. 특히 언어 모델(LMS)은 의도치 않게 드물거나 고유한 데이터 시퀀스를 기억하는 경향이 있으며, 적절한 프롬프트가 표시되면 기억된 텍스트를 그대로 내보낼 수 있습니다[8]. 따라서 NLP 모델을 개인 사용자 데이터로 직접 훈련하면 민감한 정보가 노출될 위험이 더 커질 수 있습니다.* Meta에서 인턴십 중에 수행한 작업. 이러한 과제를 극복하기 위해 텍스트 데이터의 식별 정보를 일반 마커로 대체하는 방법이 모색되었습니다[9, 10, 11]. 보다 구체적으로, 민감하거나 개인적인 것으로 간주되는 토큰은 &quot;[MASK]&quot;와 같은 특수 기호를 사용하여 마스크 처리됩니다. 원시 텍스트 시퀀스가 &quot;Tom lives in Chicago&quot;인 예에서 &quot;Tom&quot;과 &quot;Chicago&quot;라는 단어를 개인으로 표시하여 마스크 기호로 바꿀 수 있습니다. 결과 시퀀스는 &quot;[MASK] lives in [MASK]&quot;이며, 이는 나중에 모델 적응 목적으로 서버나 로컬 장치에 저장됩니다. 이 전략은 사용자 데이터에 대한 개인 정보 보호를 제공할 수 있지만, 다운스트림 적응 작업을 위한 모든 NLP 모델의 학습에 상당한 복잡성을 도입합니다. 마커가 있으면 의미 구조가 깨지거나 언어의 일관성이 깨지거나 원래 텍스트 시퀀스의 의미를 보존하지 못할 수 있습니다. 결과적으로 마스크된 코퍼스에서 직접 학습한 모델은 개인 정보 보호 토큰 마스킹 없이 원시 코퍼스에서 학습한 모델에 비해 성능이 훨씬 떨어질 수 있습니다. 따라서 코퍼스에서 마스크된 토큰을 효과적으로 대체하고 적응 작업을 위한 NLP 모델의 정확도 격차를 메우는 고급 접근 방식이 필요합니다. 이 작업에서 우리는 대규모 언어 모델(LLM)을 사용하여 마스크된 코퍼스의 일반 마커를 채우기 위한 적절한 후보 토큰을 제공하는 것을 제안합니다. 주변 컨텍스트에 따라 마스크된 토큰을 예측하는 것은 마스크된 LM(MLM)의 작업으로 간주될 수 있으므로 BERT[13] 및 ROBERTa[14]와 같은 양방향 Transformer[12] 기반 사전 학습된 LLM이 이 노력에 적합할 것입니다. 디코더 전용 LLM에서 입증된 놀라운 기능을 관찰한 후 ChatGPT[15] 및 LLAMA2[16]와 같은 모델도 마스크된 토큰의 대체물을 제공하는 데 활용할 수 있습니다. 우리의 목표는 마스크 없이 원래 토큰에 대한 마커를 복원하는 것이 아니라 마스크된 토큰을 동일한 유형의 대체물로 대체하는 것입니다. 보다 구체적으로, 개인 정보 보호 마스크에서 복구하는 방법의 효율성은 난독화 코퍼스에서 학습된 NLP 모델을 통해 다운스트림 적응 작업에서 평가됩니다. 이 논문에서 우리는 언어 모델링과 LM 융합 자동 음성 인식(ASR) [17, 18, 19, 20, 21]을 다운스트림 작업으로 사용합니다. 우리는 다음과 같은 기여를 합니다. • 우리의 작업은 마스크된 토큰의 대체물을 제안하고 다운스트림 LM 및 ASR 작업에서 효과를 평가하기 위해 LLM을 활용한 최초의 작업입니다. • 우리는 여러 개의 사전 훈련되고 미세 조정된 LLM 기반 방법을 제안하고 다양한 NLP 데이터 세트에 대한 실증적 실험을 수행하여 그에 따라 적응된 모델을 비교합니다. 우리 실험 결과에 따르면 난독화 코퍼스에서 훈련된 모델은 개인 정보 보호 토큰 마스크 없이 원본 데이터에서 훈련된 모델과 비슷한 성능을 보입니다. • 우리는 또한 세 가지 토큰 마스크 기술을 제시하고 다운스트림 작업에서도 각각에 대한 제안된 방법의 성능을 측정합니다. 논문의 나머지 부분은 다음과 같이 구성됩니다. 우리는 다음을 검토합니다.
--- RELATED WORK ---
2절에서 설명합니다. 3절에서는 개인 정보 보호 토큰 마스킹과 LLM을 사용한 마스킹된 토큰의 대체에 대한 제안된 프레임워크의 세부 사항을 설명합니다. 다음으로, 4절에서는 LM 및 ASR의 다운스트림 작업에 대한 실험과 결과를 보여줍니다. 마지막으로, 5절에서 결론을 내립니다. 2. 관련 연구 개인 정보 보호는 NLP 연구에서 중요해지고 있습니다[10]. 이 분야의 한 가지 중요한 방향은 익명화를 통한 것으로, 텍스트 코퍼스에서 식별 정보를 제거하는 것을 포함합니다[9, 22, 23]. 최근에는 민감한 정보를 동일한 유형의 다른 대체물로 대체하는 난독화가 조사되었습니다. 특히, NLP에서의 욕설 난독화에 대한 조사가 [24]에서 수행됩니다. [25]의 저자는 원래 문장의 구문 관계를 보존하여 난독화된 문장을 원래 문장 대신 구문 분석할 수 있도록 하는 신경 모델을 사용합니다. 구문 파서에서 무작위 대체 기준선보다 성능이 뛰어납니다. [11]의 연구는 음성 복제를 사용하여 합성된 대체 명명된 엔터티를 식별, 교체 및 원본 오디오에 삽입하는 데 중점을 둔 음성의 명명된 엔터티 난독화를 연구합니다. [26]의 논문은 ASR의 교육 데이터에 가짜 텍스트 대체물을 포함하여 개인 식별자의 음성 인식을 개선합니다. 이러한 기존 연구 중 어느 것도 난독화에서 토큰 대체물을 제안하기 위해 다양한 LLM의 사용 및 비교를 탐구하지 않습니다. 3.
--- METHOD ---
에스.
--- EXPERIMENT ---
모든 결과에 따르면 난독화 코퍼스에서 학습된 모델은 개인 정보 보호 토큰 마스킹 없이 원본 데이터에서 학습된 모델과 비슷한 성능을 달성할 수 있습니다. 색인 용어 개인 정보 보호 머신 러닝, 언어 모델링, 대규모 언어 모델, 자동 음성 인식 1. 서론 중앙 서버나 사용자 장치에 머신 러닝 모델을 배포한 후 발생하는 일반적인 문제는 학습 데이터와 수신된 실제 사용자 데이터 간의 불일치입니다. 특히 자연어 처리(NLP) 응용 프로그램에서 실제 사용자의 텍스트 데이터의 의미적 특성과 주제는 모델 적응이 필수적인 시나리오인 서버 측 프록시 코퍼스와 매우 다를 수 있습니다[1, 2]. 모델 적응을 효과적으로 수행하기 위해 사용자의 텍스트 데이터는 일반적으로 서버나 장치에 저장되며, 다운스트림 NLP 모델은 이러한 도메인 내 데이터를 사용하여 학습됩니다. 그러나 사용자의 개인 데이터에는 이름, 주소, 신용 카드 번호와 같은 민감한 사용자 정보가 포함될 수 있습니다. 따라서 사용자 데이터를 저장하는 이러한 기존 관행은 적대자에게 사용자 정보를 노출할 위험으로 인해 개인 정보 보호 및 보안 문제를 일으킬 수 있습니다. 또한 최근 연구에 따르면 훈련 데이터 세트의 민감한 정보를 감지한 다음 예상치 못한 방식으로 추출할 수 있음이 밝혀졌습니다[3, 4, 5, 6, 7]. 특히 언어 모델(LMS)은 의도치 않게 드물거나 고유한 데이터 시퀀스를 기억하는 경향이 있으며 적절한 프롬프트가 표시되면 기억된 텍스트를 그대로 내보낼 수 있습니다[8]. 따라서 NLP 모델을 개인 사용자 데이터로 직접 훈련하면 민감한 정보가 노출될 위험이 더 커질 수 있습니다. * Meta에서 인턴십 중에 수행한 작업. 이러한 과제를 극복하기 위해 텍스트 데이터의 식별 정보를 일반 마커로 대체하는 방법이 모색되었습니다[9, 10, 11]. 보다 구체적으로, 민감하거나 개인적인 것으로 간주되는 토큰은 &quot;[MASK]&quot;와 같은 특수 기호를 사용하여 마스크 처리됩니다. 원시 텍스트 시퀀스가 &quot;Tom lives in Chicago&quot;인 예에서 &quot;Tom&quot;과 &quot;Chicago&quot;라는 단어를 개인으로 표시하여 마스크 기호로 바꿀 수 있습니다. 결과 시퀀스는 &quot;[MASK] lives in [MASK]&quot;이며, 이는 나중에 모델 적응 목적으로 서버나 로컬 장치에 저장됩니다. 이 전략은 사용자 데이터에 대한 개인 정보 보호를 제공할 수 있지만, 다운스트림 적응 작업을 위한 모든 NLP 모델의 학습에 상당한 복잡성을 도입합니다. 마커가 있으면 의미 구조가 깨지거나 언어의 일관성이 깨지거나 원래 텍스트 시퀀스의 의미를 보존하지 못할 수 있습니다. 결과적으로 마스크된 코퍼스에서 직접 학습한 모델은 개인 정보 보호 토큰 마스킹 없이 원시 코퍼스에서 학습한 모델에 비해 성능이 훨씬 떨어질 수 있습니다. 따라서 코퍼스에서 마스크된 토큰을 효과적으로 대체하고 적응 작업을 위한 NLP 모델의 정확도 격차를 메우는 고급 접근 방식이 필요합니다. 이 작업에서 우리는 대규모 언어 모델(LLM)을 사용하여 마스크된 코퍼스의 일반 마커를 채우기 위한 적절한 후보 토큰을 제공하는 것을 제안합니다. 주변 컨텍스트에 따라 마스크된 토큰을 예측하는 것은 마스크된 LM(MLM)의 작업으로 간주될 수 있으므로 BERT[13] 및 ROBERTa[14]와 같은 양방향 Transformer[12] 기반 사전 학습된 LLM이 이 노력에 적합할 것입니다. 디코더 전용 LLM에서 입증된 놀라운 기능을 관찰한 후 ChatGPT[15] 및 LLAMA2[16]와 같은 모델도 마스크된 토큰의 대체물을 제공하는 데 활용할 수 있습니다. 우리의 목표는 마스크 없이 원래 토큰에 대한 마커를 복원하는 것이 아니라 마스크된 토큰을 동일한 유형의 대체물로 대체하는 것입니다. 보다 구체적으로, 개인 정보 보호 마스크에서 복구하는 방법의 효율성은 난독화 코퍼스에서 학습된 NLP 모델을 통해 다운스트림 적응 작업에서 평가됩니다. 이 논문에서 우리는 언어 모델링과 LM 융합 자동 음성 인식(ASR) [17, 18, 19, 20, 21]을 다운스트림 작업으로 사용합니다. 우리는 다음과 같은 기여를 합니다. • 우리의 작업은 마스크된 토큰의 대체물을 제안하고 다운스트림 LM 및 ASR 작업에서 효과를 평가하기 위해 LLM을 활용한 최초의 작업입니다. • 우리는 여러 개의 사전 훈련되고 미세 조정된 LLM 기반 방법을 제안하고 다양한 NLP 데이터 세트에 대한 실증적 실험을 수행하여 그에 따라 적응된 모델을 비교합니다. 우리 실험 결과에 따르면 난독화 코퍼스에서 훈련된 모델은 프라이버시를 보호하는 토큰 마스크 없이 원본 데이터에서 훈련된 모델과 비슷한 성능을 보입니다. • 우리는 또한 세 가지 토큰 마스킹 기술을 제시하고 다운스트림 작업에서도 각각에 대한 제안된 방법의 성능을 측정합니다. 이 논문의 나머지 부분은 다음과 같이 구성됩니다. 2절에서 관련 연구를 검토한다. 3절에서는 개인 정보 보호 토큰 마스킹과 LLM을 사용한 마스킹된 토큰의 대체에 대한 제안된 프레임워크의 세부 사항을 설명한다. 다음으로, 4절에서는 LM과 ASR의 다운스트림 작업에 대한 실험과 결과를 보여준다. 마지막으로, 5절에서 결론을 내린다. 2. 관련 연구 개인 정보 보호는 NLP 연구에서 중요해지고 있다[10]. 이 분야의 한 가지 중요한 방향은 익명화를 통한 것으로, 텍스트 코퍼스에서 식별 정보를 제거하는 것을 포함한다[9, 22, 23]. 최근에는 민감한 정보를 동일한 유형의 다른 대체물로 대체하는 난독화가 조사되었다. 특히, NLP에서의 욕설 난독화에 대한 조사가 [24]에서 수행되었다. [25]의 저자는 원래 문장의 구문 관계를 보존하여 난독화된 문장을 원래 문장 대신 구문 분석할 수 있도록 하는 신경 모델을 사용한다. 구문 파서에서 무작위 대체 기준선보다 성능이 우수하다. [11]의 연구는 음성 복제를 사용하여 합성된 명명된 엔터티를 식별, 대체 및 원본 오디오에 삽입하는 데 중점을 둔 음성의 명명된 엔터티 난독화를 연구합니다. [26]의 논문은 ASR의 교육 데이터에 가짜 텍스트 대체물을 포함하여 개인 식별자의 음성 인식을 개선합니다. 이러한 기존 연구 중 어느 것도 난독화에서 토큰 대체물을 제안하기 위해 다양한 LLM의 사용과 비교를 탐구하지 않습니다. 3. 방법론 우리는 개인 정보 보호 토큰 마스킹과 LLM을 사용하여 마스크된 토큰의 대체물에 대한 제안된 접근 방식을 설명합니다. 구체적으로, 우리는 섹션 3.1에서 여러 토큰 마스킹 기술을 소개합니다. 마스크된 토큰을 대체하는 LLM 기반 방법은 섹션 3.2에 제시됩니다. 섹션 3.3에서는 언어 모델링 작업을 수행하기 위해 난독화 코퍼스를 사용하는 방법을 설명합니다. 전체 프레임워크는 그림 1에 나와 있습니다. 톰은 시카고에 살고 있습니다 [MASK]는 [MASK]에 살고 있습니다 샘은 보스턴에 살고 있습니다 그림 1. LLM. 원시 코퍼스 마스크된 코퍼스 허용 목록, 어휘 임계값, 난독화 코퍼스 엔터티 태거 LLM 대체 마스크된 토큰 다운스트림 작업 3.1을 사용한 토큰 마스킹 및 난독화 프레임워크.토큰 마스킹 기술 사용자 데이터에서 민감한 토큰을 마스킹하면 개인 정보 위험을 줄이고 개인 정보가 적대자에게서 유출되거나 추출되는 것을 방지할 수 있습니다.이러한 토큰 마스킹 작업은 실무자가 사용자의 개인 데이터에 주석을 달거나 레이블을 지정할 수 없기 때문에 인간 참여 없이 수행되어야 합니다.일부 개인 코퍼스에서 민감한 정보를 자동으로 숨기기 위해 다음과 같은 토큰 마스킹 기술을 제안합니다.• 허용 목록: 이것은 민감하지 않고 보관해도 안전한 것으로 간주되는 토큰의 미리 정의된 목록입니다.일반적으로 이러한 목록은 언어 전문가가 직접 작성합니다.그런 다음 마스킹 프로세스 중에 이 허용 목록에 없는 토큰은 마스크됩니다.• 어휘 임계값: 이것은 어휘에서 가장 빈번한 N개의 토큰을 민감하지 않은 토큰 목록으로 선택하는 것을 포함합니다. 즉, 특정 임계값보다 빈도가 낮은 토큰은 모두 마스크 처리됩니다. 여기서 어휘 집합은 일부 일반적인 대규모 코퍼스에서 구축할 수 있습니다. • entityTagger: 이 접근 방식에서 명명된 엔터티 인식(NER) 모델을 사용하여 개인 토큰으로 처리되고 마스크 처리되는 모든 개인 코퍼스의 잠재적 엔터티를 식별합니다. 이러한 엔터티에는 개인의 이름, 위치 및 조직이 포함되지만 이에 국한되지는 않습니다. 이러한 마스킹 기술 전반에 걸쳐 개인 정보가 희귀하거나 고유한 토큰과 더 관련이 있다고 가정하여 모든 코퍼스에서 일반적이지 않은 토큰을 마스크할 가능성이 더 큽니다. 마스킹을 적용한 후 마스크된 토큰이 &quot;[MASK]&quot; 기호로 대체된 마스크된 코퍼스를 얻습니다. 3.2. 마스킹에서 복구 방법 토큰 마스킹은 개인 정보 보호를 제공하지만 결과적으로 마스크된 코퍼스는 다운스트림 작업을 위한 NLP 모델을 훈련하는 데 직접 사용하기에 적합하지 않을 수 있습니다. 모든 마스크된 코퍼스가 주어지면 LLM을 사용하여 각 마스크 기호를 의미적 맥락과 일치하는 적절한 토큰으로 채우는 것을 제안합니다. 원시 코퍼스의 원래 토큰과 정확히 동일한 토큰을 예측하는 것이 목표가 아니라는 점에 유의하는 것이 중요합니다. 우리는 전체 문장을 언어적으로 정확하고 완전하게 만드는 토큰으로 대체할 것으로 예상합니다. 다음은 마스크된 토큰을 대체하기 위해 LLM을 활용하는 다양한 전략을 보여줍니다. • Top-1: 이 방법에서는 LLM에서 예측된 1-best 토큰을 직접 사용하여 마스크된 토큰을 대체합니다. 여기서 토큰 채우기는 마스크된 LM 작업으로 간주됩니다. 문장에 여러 마커가 있는 경우 한 번에 하나씩 왼쪽에서 오른쪽으로 순차적으로 대체됩니다. • Top-K: 이 접근 방식은 LLM의 예측에서 토큰 채우기 후보를 1-best에서 K-best로 확장합니다. 구체적으로, 우리는 상위 K 예측에서 무작위로 토큰을 선택합니다. 그런 다음 선택된 토큰을 사용하여 문장의 마커를 채웁니다. 허용 목록 또는 vocabThres 기반 마스킹 기술에서 마스크된 토큰을 대체하기 위해 예측된 토큰이 해당 토큰 목록에 포함되지 않는 것을 선호하므로 이 조건이 충족되거나 상위 K개 중에 예측된 토큰의 사용 가능한 후보가 없을 때까지 임의 샘플링 프로세스를 반복합니다.미세 조정(FT): 이전 두 가지 접근 방식에서 사전 학습된 LLM의 토큰 예측을 활용합니다.도메인 내 코퍼스를 사용하여 사전 학습된 LLM을 미세 조정하면 모델이 도메인별 지식을 얻는 데 도움이 되므로 마스크된 토큰 예측에서 성능이 향상됩니다.이를 달성하기 위해 마스크된 토큰이 없는 샘플을 미세 조정에 사용할 수 있습니다.그러나 많은 시나리오에서 대부분의 샘플에 하나 이상의 마스크 심볼이 포함되어 미세 조정이 덜 효과적일 수 있으며, 특히 코퍼스 크기가 작은 경우 더욱 그렇습니다. 또는 동일한 사전 학습된 LLM의 상위 1개 또는 상위 K개 예측을 먼저 사용하여 모든 샘플에서 마스크된 토큰을 대체한 다음 전체 난독화 코퍼스를 사용하여 LLM을 미세 조정할 수 있습니다. 미세 조정된 LLM이 있으면 마스크된 토큰을 대체하기 위해 상위 1개 또는 상위 K를 적용할 수 있습니다. 위의 프로세스는 여러 번 사용할 수 있습니다. 이러한 방법 중 하나를 적용한 후 마스크가 없는 난독화 코퍼스를 얻습니다. 3.3. 다운스트림 작업 수행 마스크된 토큰을 대체한 후 결과 코퍼스를 사용하여 모든 다운스트림 작업을 위한 머신 러닝 모델을 학습할 수 있습니다. 토큰 채우기 접근 방식의 효과는 이러한 다운스트림 작업에서 이러한 머신 러닝 모델의 성능으로 측정해야 합니다. 이 작업에서는 난독화 코퍼스에서 일반적인 사전 학습된 LM이 미세 조정되는 언어 모델링 적응 작업을 고려합니다. 이 적응형 LM은 원시 코퍼스와 동일한 도메인을 갖는 (마스크되지 않은) 테스트 세트에서 평가됩니다.LM의 성능은 복잡도 측면에서 측정됩니다.얕은 융합을 통해 적응형 LM을 ASR 모델과 통합할 때 단어 오류율(WER)도 발화 테스트 세트에서 평가할 수 있습니다.4.1. 데이터 세트 4. 실험 다운스트림 언어 모델링 작업에서 여러 기준선과 제안된 접근 방식의 성능을 비교하기 위해 실험에서 세 가지 데이터 세트를 탐색합니다.Fisher [27], Pushshift.io Reddit¹ [28], Wall Street Journal(WSJ) [29].이러한 데이터 세트의 통계는 표 1에 요약되어 있습니다.WSJ 데이터의 테스트 세트는 또한 음성 발화로 구성되므로 융합된 LM이 있는 ASR 모델을 평가하는 데 사용됩니다.4.2. 설정 Fisher Reddit WSJ 표 1. 데이터 정보. 학습 세트(#sent) 테스트 세트(#sent) 4.2.1. 다운스트림 작업 1,158,763,6,50,49, 다운스트림 LM은 6개 레이어, 12개 어텐션 헤드, 768개 숨겨진 유닛을 갖춘 Transformer입니다. 단어 어휘 세트는 약 &#39;Pushshift.io Reddit 데이터 세트는 이전에 제3자가 추출하여 얻은 데이터 세트로, 소셜 네트워크 Reddit에 게시되고 pushshift.io에서 호스팅하는 전처리된 댓글이 포함되어 있습니다. 이 논문의 나머지 부분에서는 이 데이터 세트를 &quot;Reddit&quot;이라고 합니다. 85K. LM은 WikiText-103 코퍼스[30]에서 사전 학습되었습니다. 이 연구에서 고려한 각 마스킹 기술에 대해 LM은 Fisher, Reddit 및 WSJ 데이터의 난독화 학습 세트에서 미세 조정됩니다. 이들의 복잡도는 해당 테스트 세트에서 평가됩니다. WSJ 테스트 세트에서 ASR 성능도 평가합니다. ASR 모델은 Emformer 인코더[31], LSTM 예측기 및 조이너를 갖춘 RNN-T 모델입니다.약 8,000만 개의 매개변수를 가지며 LibriSpeech ASR 코퍼스[32]의 학습 분할을 사용하여 처음부터 학습됩니다.4.2.2. 마스킹 기술 실험에서 allow List는 5,000개의 선별된 일반 단어 세트를 포함하고 vocabThres는 위에서 언급한 동일한 85,000개 단어 어휘 중 가장 빈번한 10,000개 단어로 구성됩니다.entityTagger 마스킹 기술의 경우 BERT-NER 모델[13, 33]을 활용하여 학습 세트에서 명명된 엔터티를 태그 지정합니다.이러한 각 마스킹 기술에 대해 표 2는 데이터 세트당 마스킹된 토큰의 백분율을 보여줍니다.allow List가 다른 두 기술보다 훨씬 더 많은 토큰을 마스킹한다는 것을 알 수 있습니다.표 2. 마스킹된 토큰의 백분율. allowList vocabThres entityTagger Fisher 12.5% 1.3% 1.7% Reddit 22.7% 11.9% WSJ 30.4% 11.2% 4.2% 9.1% 4.2.3. 기준선 우리는 다음 방법을 기준선으로 고려합니다.• Oracle: LM은 마스킹 없이 기준 진실 문장에 대해 훈련되며, 이는 각 데이터 세트에서 모델 성능에 대한 상한을 제공합니다.• Baseline0: LM은 마스크된 코퍼스에 대해 직접 훈련되며, 마스크 기호 &quot;[MASK]&quot;는 모델 훈련 중 특수 토큰으로 처리됩니다.• Baselinel: 모델 훈련 중 LM 손실 함수의 모든 마스크 기호 &quot;[MASK]&quot;에 가중치가 0으로 지정됩니다.각 방법의 경우 LM은 여전히 WikiText-103 코퍼스에 대해 사전 훈련됩니다.4.2.4. LLM 기반 방법 실험에서 우리는 모든 훈련 시퀀스에서 마스크된 토큰을 대체하기 위해 다음 LLM을 고려합니다.BERT(기본, 케이스 없음), ROBERTA(기본), LLAMA2(7B 모델 매개변수).BERT와 ROBERTA의 미세 조정을 위해 MLM을 훈련 과제로 사용합니다.사전 훈련되거나 미세 조정된 BERT와 ROBERTa를 사용하여 마스크된 토큰을 대체하는 추론 시간 동안, &quot;[MASK]&quot;의 연속된 마커는 하나의 마커로 병합됩니다.Top-K 방법에서 K = 10을 설정합니다.LLAMA2의 경우 자기 회귀 모델이므로 미세 조정 프로세스에 다른 접근 방식을 채택합니다.특히, 각 훈련 샘플에 대해 일부 지침, 입력 및 출력 텍스트를 결합하여 프롬프트를 생성합니다.지침에는 &quot;[MASK] 토큰을 주어진 문장에서 예측하십시오&quot;라는 텍스트가 포함됩니다.입력은 동일한 훈련 샘플이지만 몇 개의 토큰이 &quot;[MASK]&quot; 기호로 무작위로 대체되었습니다. 출력은 원래의 학습 샘플(마스킹 없음)입니다. 저희는 프롬프트 세트에서 LLAMA2를 미세 조정하기 위해 저순위 적응(LORA) 방법[34]을 활용합니다. 추론 시간 동안 미세 조정된 모델에 지침과 입력이 제공되어 모델이 계속해서 텍스트를 생성할 수 있습니다. 4.3. 결과 표 3은 Fisher 데이터 세트에 대한 기준선과 제안된 방법의 복잡도 결과를 보여줍니다. 다음과 같은 관찰 결과가 있습니다. • 모든 제안된 방법은 두 기준선 방법보다 낮은 복잡도 결과를 제공합니다. • 모든 시나리오에서 Top-K는 Top-1 기반 방법보다 성능이 우수합니다. 미세 조정된 BERT와 ROBERTA는 미세 조정이 없는 방법보다 더 나은 결과를 얻습니다. • 허용 목록으로 더 많은 토큰이 마스크되므로 Oracle과 다른 방법 간의 격차가 vocabThres 또는 entityTagger 마스킹 기술보다 훨씬 큽니다. • ROBERTA는 모든 마스킹 기술에서 가장 우수한 복잡도 성능을 제공합니다. 특히, vocabThres와 entityTagger의 경우, 미세 조정된 ROBERTa의 복잡도 결과는 Oracle의 결과와 매우 유사하여 대부분의 누락된 정보를 난독화 데이터 세트에서 복구할 수 있음을 나타냅니다.• LLAMA2(Top-1, FT)는 경쟁력 있는 방법이지만 이 작업의 경우 미세 조정된 BERT나 ROBERTA만큼 좋지 않습니다.표 3. Fisher 데이터 세트의 복잡도 결과.표 5와 표 6은 각각 WSJ 데이터 세트의 복잡도 및 WER 결과를 보여줍니다.다음과 같은 결과가 나왔습니다.• ASR 모델에서 도메인 적응을 수행하기 위해 융합된 LM을 사용하는 것이 효과적입니다.사전 훈련된 LM이 있는 ASR 모델과 Oracle LM 간의 WER을 비교한 결과, 후자가 15% 이상의 WER 개선을 달성했습니다.• 제안된 방법으로 얻은 최상의 WERS는 Oracle LM과 비교하여 갭이 비교적 작습니다. vocabThres와 entity Tagger 마스킹 기술의 경우, Oracle의 WERS는 각각 1%(10.7 대 10.6)와 5%(11.1 대 10.6)만 향상되었습니다. 즉, 제안된 방법은 사전 학습된 LM(적응 없음)에 비해 상당한 개선을 달성할 수 있으며 Oracle LM보다 더 나은 개인 정보 보호 기능을 제공합니다. Oracle 표 5. WSJ 데이터 세트에 대한 Perplexity 결과. allowList vocabThres entityTagger BaselineBaselinel BERT(상위 1) 86.86.86.309.144.204.210.122.198.205.119.149.ROBERTA(상위 1) 181.102.118.BERT(상위 K) 174.103.108.ROBERTA(상위 K) 114.93.98.BERT(상위 K, FT) 186.113.162.ROBERTA(상위 K, FT) 120.110.157.LLAMA2(상위 1, FT) 135.106.145.allowList vocabThres entity Tagger Oracle 37.37.37.Table 6. WSJ 데이터 세트의 WER 결과. allowList vocabThres entityTagger Baseline120.42.41.ASR-without-LM 14.14.14.Baselinel 109.41.41.Pre-Trained-LM 12.12.12.BERT(상위 1) 93.41.41.Oracle 10.10.10.ROBERTA(상위 1) 71.40.39.Baseline13.12.11.BERT(상위 K) 75.40.40.Baselinel 12.11.11.ROBERTA(상위 K) 70.38.38.BERT(상위 1) 12.11.11.BERT(상위 K, FT) 73.39.39.ROBERTA(상위 1) 12.10.11.ROBERTA (Top-K, FT) 65.38.38.BERT (Top-K) 12.11.11.LLAMA2 (Top-1, FT) 89.40.40.ROBERTA (Top-K) 11.10.11.BERT (Top-K, FT) 12.11.11.ROBERTA (Top-K, FT) LLAMA2 (Top-1, FT) 11.11.11.12.10.11.표 4는 Reddit 데이터 세트에 대한 실험 결과를 보여줍니다. 관찰 결과는 Fisher 데이터 세트의 관찰 결과와 유사합니다. 특히 ROBERTA (Top-K, FT)는 모든 마스킹 기술에 걸쳐 다시 가장 우수한 복잡도 결과를 달성합니다.표 4. Reddit 데이터 세트에 대한 복잡도 결과. allowList vocabThres 엔터티 태거 Oracle 76.76.76.Baseline339.168.82.Baselinel 221.134.79.BERT(상위 1) 196.121.78.ROBERTA(상위 1) 117.94.78.BERT(상위 K) 127.106.78.ROBERTA(상위 K) 123.92.77.BERT(상위 K, FT) 117.102.77.ROBERTA(상위 K, FT) 98.82.76.LLAMA2(상위 1, FT) 123.107.78.5.
--- CONCLUSION ---
이 논문에서는 텍스트 코퍼스에서 개인 정보 보호 토큰 마스킹을 복구하기 위해 사전 훈련되고 미세 조정된 여러 LLM 기반 방법을 제안하고 이러한 접근 방식을 비교하기 위해 다양한 데이터 세트에 대한 실증 연구를 수행합니다. 실험 결과는 난독화 코퍼스에서 훈련된 LM이 개인 정보 보호 토큰 마스킹 없이 원시 데이터에서 훈련된 LM과 비슷한 정확도를 얻을 수 있음을 보여줍니다. 향후 연구에는 다운스트림 NLP 작업과 더 직접적으로 관련되도록 설계된 객체 함수로 LLM을 미세 조정하는 것이 포함될 수 있습니다. 또한 이 세 가지 마스킹 기술을 조합하고 &quot;[PERSON]&quot;, &quot;[NUMBER]&quot; 등과 같은 클래스별 마커를 채택할 것입니다. 6. 참고문헌 [1] Ke Li, Zhe Liu, Tianxing He, Hongzhao Huang, Fuchun Peng, Daniel Povey, and Sanjeev Khudanpur, &quot;변압기 기반 신경 언어 모델 적응에 대한 실증적 연구&quot;, Proc. 영어: ICASSP, 2020. [2] Zhe Liu, Ke Li, Shreyan Bakshi 및 Fuchun Peng, &quot;음성 인식을 위한 개인 언어 모델 적응,&quot; arXiv 사전 인쇄본 arXiv:2110.10026, 2021. [3] Matt Fredrikson, Somesh Jha 및 Thomas Ristenpart, &quot;신뢰 정보와 기본 대책을 악용하는 모델 역전 공격,&quot; Proc. ACM SIGSAC, 2015. [4] Congzheng Song 및 Vitaly Shmatikov, &quot;텍스트 생성 모델에서 데이터 출처 감사,&quot; Proc. ACM SIGKDD, 2019. [5] Nicholas Carlini, Chang Liu, Úlfar Erlingsson, Jernej Kos, Dawn Song, &quot;비밀 공유자: 신경망에서 의도치 않은 기억력 평가 및 테스트&quot;, 제28회 USENIX 보안 심포지엄, 2019. [6] Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar Erlingsson, et al., &quot;대규모 언어 모델에서 학습 데이터 추출&quot;, 제30회 USENIX 보안 심포지엄, 2021. [7] W Ronny Huang, Steve Chien, Om Thakkar, Rajiv Mathews, &quot;언어 모델 융합 ASR에서 의도치 않은 기억력 감지&quot;, Proc. Interspeech, 2022. [8] Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian Tramer, Chiyuan Zhang, &quot;신경 언어 모델에서 기억 정량화&quot;, arXiv 사전 인쇄본 arXiv:2202.07646, 2022. [9] Sergio Martínez, David Sánchez, Aida Valls, Montserrat Batet, &quot;의미 기반 마스킹 방법을 통한 텍스트 속성의 개인 정보 보호&quot;, Information Fusion, vol. 13, no. 4, pp. 304–314, 2012. [10] Samuel Sousa와 Roman Kern, &quot;텍스트를 비공개로 유지하는 방법? 개인 정보를 보호하는 자연어 처리를 위한 딥 러닝 방법에 대한 체계적 검토&quot;, Artificial Intelligence Review, vol. 56, no. 2, pp. 1427-1492, 2023. [11] Judita Preiss, &quot;자동 명명된 엔터티 난독화&quot;, ACL 조사 결과, 2023. [12] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser 및 Illia Polosukhin, &quot;주의가 필요한 전부입니다.&quot; NeurIPS의 발전, 2017. [13] Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, &quot;BERT: 언어 이해를 위한 심층 양방향 변환기 사전 훈련&quot;, arXiv 사전 인쇄 arXiv:1810.04805, 2018. [14] Yinhan Liu, Myle Ott, Naman 고얄, 두징페이, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, “ROBERTa: 강력하게 최적화된 BERT 사전 학습 접근법,” arXiv 사전 인쇄본 arXiv:1907.11692, 2019. [15] OpenAI, &quot;ChatGPT: 대화를 위한 언어 모델 최적화,&quot; 2022년 2월. [16] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al., “Llama 2: Open foundation and finetuned chat models,&quot; arXiv 사전 인쇄본 arXiv:2307.09288, 2023. [17] Tomáš Mikolov, Martin Karafiát, Lukáš Burget, Jan Černockỳ, 및 Sanjeev Khudanpur, &quot;순환 신경망 기반 언어 모델&quot;, Proc. Interspeech, 2010. [18] Xie Chen, Xunying Liu, Mark JF Gales, 및 Philip C Woodland, &quot;순환 신경망 언어 모델의 학습 및 평가 효율성 개선&quot;, Proc. ICASSP, 2015. [19] Xunying Liu, Yongqiang Wang, Xie Chen, Mark JF Gales, 및 Philip C Woodland, &quot;순환 신경망 언어 모델을 사용한 효율적인 격자 재점수 매기기&quot;, Proc. ICASSP, 2014. [20] Anjuli Kannan, Yonghui Wu, Patrick Nguyen, Tara N Sainath, Zhijeng Chen, 및 Rohit Prabhavalkar, &quot;외부 언어 모델을 시퀀스 대 시퀀스 모델에 통합하는 것에 대한 분석&quot;, Proc. ICASSP, 2018. [21] Kazuki Irie, Albert Zeyer, Ralf Schlüter 및 Hermann Ney, &quot;심층 변환기를 사용한 언어 모델링&quot;, Proc. Interspeech, 2019. [22] Pierre Lison, Ildikó Pilán, David Sánchez, Montserrat Batet 및 Lilja Øvrelid, &quot;텍스트 데이터의 익명화 모델: 최신 기술, 과제 및 미래 방향&quot;, Proc. ACL, 2021. [23] Tzvika Hartman, Michael D Howell, Jeff Dean, Shlomo Hoory, Ronit Slyper, Itay Laish, Oren Gilon, Danny Vainstein, Greg Corrado, Katherine Chou 외, &quot;임상 기록의 익명화를 위한 사용자 정의 시나리오&quot;, BMC 의료 정보학 및 의사 결정, 제20권, 제1호, 1-9쪽, 2020. [24] Debora Nozza 및 Dirk Hovy, &quot;자연어 처리에서의 욕설 난독화 상태&quot;, arXiv 사전 인쇄본 arXiv:2210.07595, 2022. [25] Zhifeng Hu, Serhii Havrylov, Ivan Titov 및 Shay B. Cohen, &quot;개인 정보 보호를 위한 구문 분석을 위한 난독화&quot;, 2020. [26] Yochai Blau, Rohan Agrawal, Lior Madmony, Gary Wang, Andrew Rosenberg, Zhehuai Chen, Zorik Gekhman, Genady Beryozkin, Parisa Haghani, Bhuvana Ramabhadran, &quot;텍스트 주입을 사용하여 음성에서 개인 식별자 인식 개선,&quot; arXiv 사전 인쇄본 arXiv:2308.07393, 2023. [27] Christopher Cieri, David Miller, Kevin Walker, &quot;fisher 코퍼스: 차세대 음성-텍스트 리소스,&quot; 국제 언어 리소스 및 평가 컨퍼런스, 2004. [28] Jason Baumgartner, Savvas Zannettou, Brian Keegan, Megan Squire, Jeremy Blackburn, &quot;Pushshift reddit 데이터 세트,&quot; 국제 웹 및 소셜 미디어 컨퍼런스, 2020. [29] Lukas Drude, Jens Heitkaemper, Christoph Boeddeker 및 Reinhold Haeb-Umbach, &quot;SMS-WSJ: 다중 채널 소스 분리 및 인식을 위한 데이터베이스, 성능 측정 및 기준 레시피,&quot; arXiv 사전 인쇄본 arXiv:1910.13934, 2019. [30] Stephen Merity, Caiming Xiong, James Bradbury 및 Richard Socher, &quot;포인터 센티넬 혼합 모델,&quot; arXiv 사전 인쇄본 arXiv:1609.07843, 2016. [31] Yangyang Shi, Yongqiang Wang, Chunyang Wu, Ching-Feng Yeh, Julian Chan, Frank Zhang, Duc Le 및 Mike Seltzer, &quot;Emformer: 저지연 스트리밍 음성 인식을 위한 효율적인 메모리 변환기 기반 음향 모델,&quot; Proc. ICASSP, 2021. [32] Vassil Panayotov, Guoguo Chen, Daniel Povey, Sanjeev Khudanpur, &quot;LibriSpeech: 퍼블릭 도메인 오디오북을 기반으로 한 ASR 코퍼스&quot;, ICASSP 회의록, 2015. [33] Erik F. Tjong Kim Sang, Fien De Meulder, &quot;CONLL-2003 공유 과제 소개: 언어 독립적인 명명된 엔터티 인식&quot;, HLT-NAACL 2003에서 열린 제7회 자연어 학습 컨퍼런스 회의록, 2003. [34] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, &quot;LORA: 대규모 언어 모델의 저순위 적응&quot;, arXiv 사전 인쇄본 arXiv:2106.09685, 2021.
