--- ABSTRACT ---
이 논문은 하이퍼스케일에서 대규모 언어 모델(LLM)을 훈련하기 위한 저비용 네트워크 아키텍처를 제시합니다. LLM의 최적 병렬화 전략을 연구하고 LLM의 고유한 통신 패턴에 맞춰진 새로운 데이터센터 네트워크 설계를 제안합니다. LLM 훈련은 네트워크에서 희소한 통신 패턴을 생성하므로 효율적으로 완료하기 위해 임의 대 임의 전체 이분법 네트워크가 필요하지 않음을 보여줍니다. 결과적으로, 우리의 설계는 기존 GPU 클러스터에서 스파인 계층을 제거합니다. 이 설계를 Rail-only 네트워크라고 명명하고 기존 GPU 데이터센터에 비해 네트워크 비용을 38%~77%, 네트워크 전력 소비를 37%~75% 줄이면서도 동일한 훈련 성능을 달성함을 보여줍니다. 우리의 아키텍처는 또한 전달을 통한 all-to-all 통신을 갖춘 Mixture-of-Expert(MoE) 모델을 지원하며 all-to-all 트래픽에 대한 완료 시간 오버헤드는 8.2%~11.2%에 불과합니다. Rail-only 네트워크의 장애 견고성을 연구하고 다양한 네트워크 및 훈련 매개변수의 성능 영향에 대한 통찰력을 제공합니다. 나.
--- INTRODUCTION ---
대규모 언어 모델(LLM)은 가장 복잡하고 연산 집약적인 딥 뉴럴 네트워크(DNN)에 속합니다. 2020년의 GPT3 모델은 이미 Nvidia의 V100 GPU에서 GPU-년이 필요했습니다[1], [2]. 반면 최근의 GPT4 모델은 수조 개의 매개변수가 있고 학습하는 데 몇 달이 걸립니다[3], [4]. 무어의 법칙이 둔화됨에 따라 LLM 크기와 연산 요구 사항의 성장률이 가속기의 발전을 넘어서 하이퍼스케일 GPU 데이터 센터가 불가피해졌습니다. 업계의 주요 머신 러닝 아키텍트와의 대화에 따르면 차세대 LLM은 합리적인 시간 내에 학습을 완료하려면 30,000개 이상의 GPU 컴퓨팅 파워가 필요할 가능성이 높습니다. GPU 제조업체는 효율적인 다중 GPU 학습을 가능하게 하기 위해 NVLink[5] 및 Infinity Fabric[6]과 같은 고대역폭 플랫폼에 투자했습니다. 이러한 플랫폼은 몇 개의 GPU 내에서 수 Tbps의 대역폭을 제공하지만 확장할 수 없습니다. 여러 GPU 플랫폼을 연결하기 위해 최첨단 접근 방식은 RDMA over converged ethernet(ROCE) 또는 Infiniband와 같은 기존의 무손실 네트워크 솔루션에 의존합니다. 특히 오늘날의 GPU 클러스터는 &quot;레일 최적화&quot; 네트워크라는 아키텍처를 사용합니다. 이 아키텍처는 고전적인 Clos 네트워크[7]에서 파생되어 트레이닝 클러스터의 모든 GPU에 대한 임의 대 임의 연결을 제공합니다. 그러나 Clos 네트워크를 수만 개의 GPU로 확장하는 것은 어렵습니다. 이전 연구에 따르면 대규모 무손실 네트워크는 교착 상태와 PFC 스톰[8]이 발생하기 쉽고 성능이 저하됩니다[12]. 또한 규모가 커질수록 Clos 아키텍처는 엄청나게 비쌉니다[13]. 예를 들어 오늘날 30,000개의 GPU를 400Gbps 네트워크 용량으로 상호 연결하는 전체 이분 Clos 패브릭의 비용은 2억 달러입니다. 동시에 이러한 네트워크를 배포하려면 약 4.6메가와트의 피크 전력 소비를 프로비저닝해야 합니다. 결과적으로 데이터 센터 제공자는 비용과 에너지 소비를 억제하기 위해 과도한 구독을 사용하여 교착 상태와 성능 저하 문제를 악화시킵니다. 이 논문에서 우리는 LLM을 효율적으로 훈련하는 데 네트워크의 모든 GPU에서 모든 대 모든 연결이 필요하지 않음을 보여줍니다. 이는 희소하게 게이트된 Mixture-of-Expert(MOE) 계층이 있는 DNN의 경우에도 마찬가지입니다. 이 계층은 모든 대 모든 통신을 생성합니다(§III-C). 결과적으로 우리는 상용 전기 스위치가 있는 LLM 데이터 센터의 비용과 에너지 소비를 낮추는 즉시 배포 가능한 솔루션을 제안합니다. 이를 위해 우리는 두 가지 주요 기여를 합니다. 첫째, LLM 훈련의 트래픽 패턴을 분석합니다(§III). 우리는 최적의 병렬화 전략을 사용하면 LLM 훈련 워크로드에 GPU의 작은 하위 집합 내에서만 고대역폭 모든 대 모든 연결이 필요하고 각 하위 집합은 Nvidia DGX 서버와 같은 단일 GPU 플랫폼에 들어맞는다는 것을 보여줍니다. 플랫폼 전체에서 대부분의 통신은 클러스터 전체에서 동일한 순위를 가진 몇 개의 GPU 쌍 사이에서 발생합니다. 결과적으로 Clos 네트워크를 구축하기 위한 기존의 any-to-any 접근 방식은 분산 LLM 훈련에 불필요한 복잡성, 비용 및 전력 소비를 추가합니다. 위의 관찰에 의해 동기를 부여받아 LLM 통신 요구 사항을 정확하게 반영하는 저비용 네트워크 아키텍처인 Rail-only(§IV)를 제안합니다. 주요 GPU 제조업체[14]에서 옹호하는 것처럼 any-to-any 통신을 지원하기 위해 Clos를 형성하는 대신, 당사 아키텍처는 스위치의 스파인 계층을 제거하고 상당한 네트워크 트래픽이 있는 GPU 세트만 연결합니다. 따라서 최첨단 Rail 최적화 설계와 비교할 때 당사 네트워크 아키텍처는 상당한 트래픽을 전송하지 않는 네트워크 장비를 제거하고 Rail 최적화 네트워크와 동일한 성능을 달성합니다. 당사는 all-to-all 통신에 대한 최소한의 성능 오버헤드를 부과하는 라우팅 전략을 제공합니다. 또한 당사 설계의 내결함성 속성을 분석하고 장애 사례에서 복구 방법을 제공합니다(§IV-C). 분석적 공식을 사용하여 Rail 전용 네트워크 아키텍처의 성능을 평가하고 다양한 네트워크 및 훈련 매개변수의 성능 영향에 대한 통찰력을 제공합니다. 우리는 Rail 전용 네트워크의 비용과 전력 소비를 전체 이분 대역폭의 any-to-any Clos 네트워크와 비교하고 LLM 중심 네트워크 아키텍처가 네트워크 비용과 전력을 각각 38%-76%와 37%-75%만큼 줄인다는 것을 보여줍니다(§VE). 더욱이, 우리는 Rail 전용 네트워크가 MoE 계층이 없는 LLM의 경우 Rail 최적화 클러스터와 동일한 성능을 달성한다는 것을 보여줍니다. 마지막으로, 우리는 Rail 전용 상호 연결은 all-to-all 트래픽이 필요한 MoE가 있는 LLM의 경우 8.2%-11.2%의 처리량 오버헤드만 발생시킨다는 것을 보여줍니다. II. 배경 A. 플랫폼 내 연결: 고대역폭 도메인 리소스 집약적 ML 워크로드의 증가로 인해 다중 GPU 워크로드에 최적화된 GPU 중심 플랫폼이 우세해졌습니다. 이러한 플랫폼은 통신 수요를 수용하기 위해 GPU의 로컬 도메인 내에서 고대역폭 로컬 상호 연결을 사용합니다. 제조업체에 따라 이러한 GPU 중심 플랫폼은 컴퓨팅 FLOP, GPU 및 CPU 아키텍처 또는 물리적 상호 연결 기술에서 차이가 있습니다.그러나 이러한 플랫폼은 모두 통합된 속성을 공유합니다.GPU 전체에 걸쳐 수 Tbps의 내부 대역폭을 제공합니다.예를 들어, Nvidia의 DGX H100 서버[14]는 NVSwitch로 상호 연결된 8개의 H100 GPU로 구성되어 내부적으로 3.6Tbps의 비차단 대역폭을 제공합니다.최근 발표된 GBNVL72 컴퓨터는 GPU당 7.2Tbps의 랙 내에서 36개의 GBSuperchip을 5세대 NVLink와 연결합니다[15].반면에 AMD MI300X 플랫폼은 AMD의 Infinity Fabric을 사용하여 GPU당 3.6Tbps의 대역폭으로 풀 메시 토폴로지에서 8개의 MI300X 가속기를 연결합니다[6]. Nvidia의 DGX GH200 슈퍼 컴퓨터와 같은 유사 플랫폼은 3.6Tbps의 전체 이분법 GPU 내 대역폭을 유지하면서 플랫폼 크기를 최대 256개 GPU까지 확장하기 위해 다계층 NVSwich 토폴로지를 활용했습니다[16]. 이 논문에서는 Tbps 내부 대역폭 연결이 있는 플랫폼을 &quot;고대역폭(HB) 도메인&quot;이라고 하며, 해당 상호 연결을 HB 상호 연결(HBI)이라고 합니다. B. 플랫폼 간 연결: NIC 도메인 GPU 중심 플랫폼은 NVLink 또는 Infinity Fabric 기술을 사용하여 높은 내부 대역폭을 제공하지만 제한된 수의 GPU로만 확장할 수 있습니다. 단일 플랫폼을 넘어 확장하기 위해 운영자는 이더넷이나 Infiniband와 같은 기존 네트워크 기술을 사용하여 다른 플랫폼의 NIC를 연결합니다. 이 논문에서는 플랫폼 간 네트워크를 &quot;NIC 도메인&quot;이라고 합니다. NIC 도메인의 최첨단 상호 연결은 Rail 최적화 네트워크[17]라는 잘 알려진 네트워크 아키텍처를 기반으로 합니다. 이 아키텍처는 고성능 컴퓨팅(HPC) 워크로드에 널리 사용됩니다. 다음에서 논의하겠지만 Rail 최적화 네트워크는 기존 CPU 중심 데이터 센터 네트워크보다 DNN에 더 적합합니다. 그러나 Rail 최적화 네트워크는 주로 HPC 워크로드를 위해 설계되었기 때문에 고유한 트래픽 패턴을 더욱 활용할 수 있는 중요한 기회를 놓치고 있습니다. LLM 학습 워크로드(§III). 먼저, 예측 불가능하고 버스티한 CPU 집약적 워크로드를 처리하도록 특화된 기존 데이터 센터 설계를 고려해 보겠습니다. Clos 네트워크[7], [18]라고 알려진 이 아키텍처는 서버 쌍 간에 임의 대 임의 연결을 제공합니다. Clos 네트워크는 시스템 및 네트워킹 커뮤니티에서 잘 연구되었으며 스토리지, 클라우드 및 맵리듀스 워크로드를 위한 사실상의 인프라입니다. GPU 학습 클러스터를 위한 Rail 최적화 네트워크는 그림 1에 나와 있는 데이터 센터 Clos 네트워크[17], [19]에서 발전했습니다. 크기가 K인 HB 도메인이 있는 GPU 플랫폼의 경우 총 K개의 레일이 있는데, 여기서 레일은 다른 HB 도메인에 속하는 동일한 로컬 랭크를 가진 GPU로 구성됩니다[20]. Rail 최적화 네트워크는 이러한 GPU를 동일한 스위치 세트 아래에 배치하며, 이를 레일 스위치라고 합니다. 그림 1은 레일 1과 레일 K를 각각 빨간색과 노란색으로 강조 표시합니다. 동일한 랭크의 GPU를 동일한 레일 스위치에 연결하면 이들 간의 가능한 가장 낮은 지연 시간이 보장됩니다. 이러한 연결은 최적의 DNN 병렬화 전략이 동일한 로컬 랭크를 가진 GPU 간에 NIC 도메인 트래픽을 집중시키기 때문에 바람직합니다[17]. 레일 최적화 아키텍처는 동일한 레일에 있는 GPU 간에 낮은 지연 시간을 누립니다. 나머지 네트워크는 스파인 스위치 계층을 사용하여 레일 스위치를 연결하여 전체 이분법적 임의 대 임의 Clos 네트워크 토폴로지를 형성합니다. 이 네트워크는 다른 HB 도메인에 있는 모든 GPU 쌍이 수백 Gbps의 네트워크 회선 속도로 여전히 통신할 수 있도록 합니다. 예를 들어, GPU 1, 도메인 1과 GPU 1, 도메인 2 간의 트래픽은 레일 스위치 1만 통과하는 반면, GPU 1, 도메인 1과 GPU 2, 도메인 2 간의 트래픽은 해당 레일과 스파인 스위치를 통과합니다. 레일 최적화 네트워크 아키텍처는 동일한 ToR 스위치에 동일한 랭크의 GPU를 연결하여 DNN 학습 트래픽의 강력한 지역성을 활용하지만 근본적인 질문인 스파인 스위치가 필요한가를 간과합니다. 다음 섹션에서는 LLM 교육 트래픽을 더 자세히 분석하여 척추 없는 네트워크 아키텍처 설계의 잠재력을 탐색합니다.III. LLM 트래픽 패턴 분석 A. MegatronLM의 트래픽 패턴 이제 하이브리드 데이터, 텐서 및 파이프라인 병렬성을 사용하여 LLM에서 생성된 트래픽 패턴을 모델 하이퍼파라미터와 병렬화 전략에서 네트워크 전송 크기를 계산하여 분석합니다.먼저 MegatronLM [21] 논문의 표 1에 설명된 1,456억, 3,101억, 5,396억, 조 개의 매개변수가 있는 일련의 GPT 모델을 살펴보겠습니다.이 모델은 최대 3,072개의 GPU에 분산되어 있습니다.이 모델은 HB 도메인 크기가 8인 최대 384개의 DGX A100 서버 클러스터에 분산됩니다.분석에서는 최적의 GPU 활용을 보장하기 위해 MegatronLM의 동일한 병렬화 전략을 사용합니다.대역폭이 최적이고 NCCL의 기본 알고리즘인 링 기반 집합적 통신을 사용합니다. 통신에는 세 가지 주요 유형이 있습니다. 텐서 병렬 처리(TP)의 AllGather 및 ReduceScatter 트래픽, 데이터 병렬 처리(DP)의 AllReduce 트래픽 및 지점 간 Spine 스위치 TP 트래픽 DP 트래픽 PP 트래픽 300GB -10GB 레일 1 스위치 레일 2 스위치 레일 3 스위치 *** 레일 K 스위치 1GB 레일.레일 KGPU 1 GPU 2 GPU 3 *** GPU K GPU 1 GPU 2 GPU 3 GPU K GPU 1 GPU 2 GPU 3 *** GPU K고대역폭 상호 연결(HBI)HBIHBI M 고대역폭 도메인 1 고대역폭 도메인 10MB -1MB -10KB고대역폭 도메인 M같은 레일 같은 HBD그림 1. 레일 최적화된 모든 대 모든 Clos 네트워크를 갖춘 GPU 데이터 센터[19]. 24 32 4048144(a) GPT-1T MegatronLM 트래픽 매트릭스 GPU 1~48(하나의 파이프라인 단계) 트래픽 백분율■데이터 병렬 텐서 병렬 ■파이프라인 병렬 (b) GPT-1T MegatronLM 트래픽 매트릭스 GPU 1~192(4개의 파이프라인 단계) 그림 3. MegatronLM의 GPT-1T에 대한 트래픽 히트맵 [21]. 하이라이트는 동일한 HB 도메인 및 레일에 있는 GPU를 보여줍니다. GPU 쌍 백분율 GPT-146B GPT-310B GPT-530B GPT-1T 모델 (a) 트래픽 볼륨 분포 데이터 병렬 100.99.0.0.0.GPT-146B ■텐서 병렬 파이프라인 병렬 GPT-310B GPT-530B 모델 ■트래픽 없음 GPT-1T (b) 모든 GPU 쌍의 트래픽 유형 분포 그림 2. (a) 다른 병렬화 차원에서의 트래픽 볼륨; (b) 모든 GPU 쌍의 통신 유형. 파이프라인 병렬성(PP)에서 온 트래픽. 그림 2a는 한 번의 학습 반복에 대한 각 통신 유형의 볼륨 백분율을 보여줍니다. 그림 2b는 모든 GPU 쌍에서 통신 유형 분포를 보여줍니다. TP 트래픽은 HB 도메인을 차지하는 TP 순위에 참여하는 GPU 내에서 발생합니다. DP 및 PP 트래픽은 NIC 도메인에서 발생하며 그림 2a에서 볼 수 있듯이 볼륨이 TP 트래픽보다 상당히 작습니다. 다른 병렬 처리의 트래픽이 다른 GPU 쌍 사이에서 겹치지 않는 반면, 그림 2b는 GPU 쌍의 99% 이상이 트래픽을 전달하지 않고 GPU 쌍의 0.04% 미만이 TP 트래픽을 전달함을 나타냅니다. 동시에, 그림 2a는 TP 트래픽이 총 전송된 데이터의 75% 이상을 차지함을 나타냅니다. TP 트래픽이 HB 도메인 내에 머무르는 것을 상기하면 HB 도메인 대역폭의 효율적인 사용과 NIC 도메인의 낮은 수요를 시사합니다. 이 패턴은 우리가 연구한 모든 GPT 모델에서 일관되며, LLM 모델에 대해 HB 도메인 위에 anyto-any 연결이 있는 GPU 데이터 센터를 구축하는 것은 과도함을 나타냅니다. B. LLM의 NIC 도메인 트래픽 MegatronLM에 사용된 병렬화 전략은 HB 도메인에 비해 NIC 도메인에서 미미한 양의 트래픽을 유도합니다. 그림 3은 GPT-1T 모델을 학습하기 위한 트래픽 히트맵을 보여줍니다. 이 플롯에서 모든 연속된 8개 GPU 세트는 동일한 HB 도메인(주황색으로 강조 표시) 내에 있으며, 그 사이의 거리가 8인 GPU는 동일한 레일(분홍색으로 강조 표시)에 속합니다.그림 3a는 한 파이프라인 단계 내의 트래픽 패턴을 보여주고, 그림 3b는 처음 네 파이프라인 단계에 걸친 트래픽을 보여줍니다.HB 도메인에서 트래픽 볼륨은 상당하지만(GPU 쌍 전체에서 ~300GB) NIC 도메인에서 통신은 약 6GB로 떨어집니다.또한 NIC 도메인의 전송은 스파인 스위치를 통과하지 않으며 이러한 네트워크 전송은 레일 내에서만 발생합니다.최적의 병렬화 전략으로 분산된 희소 MoE 계층이 없는 모든 LLM은 항상 레일 내에서 희소하고 볼륨이 적은 트래픽을 유도한다고 주장합니다.설계상 HB 도메인에서 나가는 유일한 트래픽은 파이프라인 병렬성의 지점 간 트래픽이거나 TP 및 DP의 집합적 통신 트래픽(AllGather, ReduceScatter 및 AllReduce)입니다. PP의 경우 LLM 병렬화의 대칭성으로 인해 각 파이프라인 단계에는 동일한 수의 GPU가 포함됩니다. 결과적으로 파이프라인 단계는 항상 NIC 도메인에서 동일한 순위의 GPU만 통과하여 동일한 레일 내에 머무르도록 배치할 수 있습니다. TP와 DP는 HB와 NIC 도메인 모두에서 집합적 통신 트래픽을 유도할 수 있습니다. MegatronLM의 예에서는 항상 TP와 DP가 각각 HB와 NIC 도메인 내에만 포함됩니다. 이러한 분할은 LLM에서 일반적이지만 유비쿼터스는 아닙니다. 예를 들어 DP만 사용하여 더 작은 모델을 학습하면 모든 GPU가 동일한 DP 순위에 참여하고 따라서 HB와 NIC 도메인에서 동일한 AllReduce 작업이 수행됩니다. 이러한 경우 학습 클러스터는 거의 최적의 성능을 달성하는 계층적 집합적 통신 알고리즘을 사용할 수 있습니다. 아래에서 이러한 알고리즘을 소개하고 성능을 분석하며 NIC 도메인의 트래픽이 레일 내에 머무르는 것을 보여줍니다. 계층적 집단 커뮤니케이션 알고리즘은 다계층 네트워크 토폴로지를 위해 설계되었습니다. 여기서 계층적 AllGather 알고리즘을 소개하고 LLM 훈련에서 발생하는 다른 집단의 경우 ReduceScatter는 AllGather의 일정을 역전하여 동일한 성능을 달성하고 AllReduce는 ReduceScatter 다음에 AllGather가 오는 것과 동일하다는 점에 유의합니다. 우리는 데이터 전송을 고려하지 않고 지연 시간을 무시합니다.트래픽 백분율 TP 트래픽 DP(HB) DP(NIC) TP PP DP 트래픽 HB 도메인에서..ឬ 8 8 P 8 9 9 8 8 9 °64 128(b) GPT-1T GH200 트래픽 매트릭스, GPU 1~256(1개 HB 도메인)GPT-1T (a) 트래픽 볼륨 분포NIC 도메인의 DP 트래픽 →PP 트래픽 256 512 768-10GB 1GB -10MB 1MB -10KB 동일 레일 동일 HBD (c) GPT-1T GH200 트래픽 매트릭스 GPU 1~1024(2개 파이프라인 단계) 그림 4. 16개 DGX GH200에 분산된 GPT-1T의 트래픽 분포 및 히트맵. DP(NIC)가 전체 트래픽 백분율의 0.8%를 차지한다는 점에 유의하세요. 그림 4의 &quot;Same-Rail&quot; 범례는 순위가 256만큼 떨어진 GPU에 나타납니다. LLM 학습 중에 중요합니다. 따라서 통신 런타임은 대역폭이 지배적입니다. 표 I에는 이 섹션에서 사용된 변수가 나와 있습니다. AllGather 작업을 수행하는 GPU가 x × y 그리드로 배열되어 있다고 가정합니다. 여기서 각 x GPU는 동일한 HB 도메인에 속하고 총 y 개의 HB 도메인에 속합니다. 기본적인 계층적 AllGather는 두 단계로 실행됩니다. 먼저 알고리즘은 HB 도메인에서 데이터를 전송하지 않고 각 GPU 레일에 대한 부분 데이터를 수집합니다. AllGather를 실행하는 총 데이터 크기가 D인 경우 모든 GPU가 네트워크에서 교환하는 데이터 양은 D(y – 1)/x입니다. 이 작업은 각 HB 도메인 내에서 GPU가 AllGather를 다시 실행할 수 있도록 효과적으로 더 큰 데이터 샤드를 만듭니다. 따라서 각 HB 도메인은 두 번째 단계에서 AllGather를 수행하여 D(x - 1)의 총 전송을 유도합니다. HB 도메인 내의 x GPU가 대역폭 용량 CF를 가지고 있고 NIC 도메인의 y GPU가 대역폭 Cs를 가지고 있다고 가정하면 전체 AllGather 런타임은 (y-1)D (x − 1)D xyC의 xCF입니다.PP 통신과 마찬가지로 논리적 xxy GPU를 GPU 클러스터에 적절히 매핑함으로써 이 알고리즘은 동일한 레일 내의 GPU에 대한 트래픽만 유도합니다.AGtime (D, x, y, CF, ,Cs) = + (1) 그림 4a는 MegatronLM 사례와 달리 NIC 및 HB 도메인 모두에 걸쳐 계층적 집합 통신을 사용하여 GPT-1T를 학습하는 트래픽 패턴을 보여줍니다.16대의 Nvidia DGX GH200 슈퍼컴퓨터[16](4096개 GPU)로 구성된 클러스터에 분산된 4096의 배치 크기로 GPT1T 모델을 학습하는 트래픽 패턴을 계산하고 분석합니다. 각 DGX GH200 슈퍼컴퓨터는 2계층 NVSwitch 아키텍처로 구성되어 256개의 H100 GPU에서 3.6Tbps GPU-GPU 대역폭을 제공합니다. 또한 각 GPU에는 Connect-X7 HCA Infiniband 네트워크 인터페이스[16]가 있어 각 GPU에서 400Gbps 네트워크 대역폭을 제공합니다. 이 설정에서 각 DGX GH200 슈퍼컴퓨터는 HB 도메인을 형성합니다. 그림 4는 이 설정의 트래픽 볼륨 백분율과 히트맵을 보여줍니다. 병렬화 전략은 총 데이터 병렬도가 64이며, 각 HB 도메인에서 32개의 GPU와 네트워크 전체에서 2개의 HB 도메인에 걸쳐 있습니다. 그림 4b와 4c는 각 DP 그룹 간에 AllReduce 트래픽을 분할하는 계층적 AllReduce 알고리즘의 트래픽 히트맵을 보여줍니다. 네트워크 트래픽은 레일(256개의 GPU 간 거리) 내에 유지됩니다. 계층적 알고리즘은 HB 도메인의 대역폭을 효율적으로 활용하여 AllReduce 트래픽의 98%를 전송하는 반면, 네트워크 도메인은 나머지 2%를 전송합니다.C. 전문가 혼합 모델의 전체 대 전체 트래픽 희소하게 게이트된 전문가 혼합(MoE) 계층이 있는 LLM은 위에서 설명한 모델과 다른 트래픽 패턴을 보입니다.MoE 계층은 상당한 추가 계산 요구 사항을 도입하지 않고도 LLM의 크기를 늘리는 대체 방법을 제공합니다.MoE를 사용하면 모델의 일부가 &quot;전문가&quot; 신경망 세트로 대체되고, 여기서 게이팅 네트워크는 각 토큰을 다른 전문가에게 라우팅하여 모델의 일부만 활성화합니다.MoE의 일반적인 병렬화 전략은 전문가 병렬성으로, 각 전문가는 클러스터의 다른 GPU에 분산됩니다.기존 LLM과 달리 전문가 병렬성이 있는 MoE는 각 전문가가 나머지 모델과 통신해야 하므로 밀도가 높은 통신 패턴이 생성됩니다.정확한 트래픽 히트맵은 게이팅 네트워크와 토큰 분포에 따라 달라집니다.이 섹션에서는 단순화를 위해 균일한 토큰 분포를 가정합니다. 그림 5는 16개의 DGX A100 서버를 사용하여 DeepSpeedMoE [22]의 MoE-1.3B 모델을 학습하는 트래픽 행렬을 보여줍니다. 이 모델은 128명의 전문가를 포함합니다. 모델의 정적 부분은 DP를 사용하는 반면 MoE 부분은 전문가 병렬 처리를 사용합니다. 각 GPU에 다른 전문가가 포함되어 있으므로 균일한 토큰 분포는 네트워크 전체에서 균일한 all-to-all 트래픽 패턴을 생성합니다. 언뜻 보기에 이러한 트래픽 패턴은 다른 레일의 GPU 간 트래픽이 스파인 스위치를 통과하기 때문에 레일 최적화 네트워크에서 스파인 스위치를 중요하게 만듭니다. 그러나 다음 섹션에서 보여주듯이 스파인 스위치에 의존할 필요는 없습니다. HB 도메인을 전달 단계로 사용하면 거의 최적의 성능을 달성할 수 있습니다. IV. 레일 전용 네트워크 설계 위의 관찰을 바탕으로 이 섹션에서는 anyto-any GPU 연결 패러다임에서 벗어나는 새로운 네트워크 아키텍처인 Railonly를 제안합니다. 먼저 X Y CF CF D TRail-opt a2a TRail-only a2a 표 I 섹션 III 및 IV-B에서 사용된 변수를 소개합니다. HB 도메인의 GPU 그리드 차원. NIC 도메인의 GPU 그리드 차원. HB 도메인의 대역폭. NIC 도메인의 대역폭. 한 쌍의 GPU 간의 데이터 전송 크기. Rail-optimized 네트워크의 전체 대 전체 트래픽 완료 시간. Rail-only 네트워크의 전체 대 전체 트래픽 완료 시간. RailRail 1 Interconnect Rail 2 Interconnect Rail 3 Interconnect “ Rail K Interconnect Rail K GPU 1 GPUGPU 3 GPU K HBI M 고대역폭 도메인 M GPU 1 GPU 2 GPU 3 GPU K GPU 1 GPUGPU 3 GPU K HBI고대역폭 도메인고대역폭 상호 연결(HBI)고대역폭 도메인&quot;.. 그림 6. 제안: 개별 레일에 대한 완전 이분법 연결을 제공하는 레일 전용 네트워크. 트래픽 비율■DP(HB) DP(NIC) ■EPឬ 8 8 P 8 9 9 8 ន ន ។MOE-1.3B (a) 트래픽 볼륨 분포 (b) 균일한 토큰 분포를 사용한 MoE-1.3B 트래픽 행렬 -1 GB -10 MB -1 MB -10 KB -1 KB 그림 5. DeepSpeedMoE [22]에서 MoE-1.3B 모델에 대한 트래픽 볼륨 분포 및 히트맵, 가정 균일한 토큰 분배. Rail-only 네트워크의 아키텍처 설계. 그런 다음 Rail-only 상호 연결의 라우팅 정책과 내결함성 속성에 대해 논의합니다. A. 아키텍처 설계 그림 6은 Rail-only 네트워크 아키텍처를 보여줍니다. 그림 1에 표시된 기존의 Rail-optimized GPU 클러스터와 비교할 때, Rail-only 네트워크는 HB 도메인을 유지하지만 NIC 도메인의 모든 GPU에 대한 전체 이분법 연결을 생략합니다. 대신 각 레일 내의 GPU가 전체 이분법 네트워크로 연결되도록만 합니다. 제안된 아키텍처의 간단한 예는 스파인 스위치(그림 1)를 제거하고 레일 스위치를 스파인에 연결하는 업링크를 GPU에 대한 다운링크로 재활용하는 것입니다. 따라서 전용 Clos 네트워크가 각 레일을 연결합니다. Rail-optimized 아키텍처와 비교할 때 Railonly 설계는 개별 레일에 대해 여러 개의 작은 Clos 네트워크를 구축하여 스위치와 트랜시버의 수를 절약하고 네트워크에서 더 적은 스위치 계층이 필요합니다. B. Rail-only 네트워크의 라우팅 Rail-only 네트워크 아키텍처는 다른 레일의 다른 랭크를 가진 GPU에서 네트워크 연결을 제거합니다. 이러한 통신은 HB 도메인을 통해 데이터를 전달함으로써 여전히 가능합니다. 예를 들어, 그림 6에서 GPU 1, 도메인 1에서 GPU 2, 도메인 2로 전송되는 메시지는 먼저 첫 번째 HB 도메인을 거쳐 GPU 2, 도메인 1로 라우팅한 다음 네트워크를 통해 최종 목적지로 전송할 수 있습니다. 이전 연구에서는 이러한 라우팅 방식이 네트워크에서 전달로 인해 물리적 트래픽이 증가하는 대역폭 세금[13], [23], [24]을 유발한다는 것을 보여주었습니다. 그러나 이 섹션에서는 HB와 NIC 도메인 간의 대역폭 비대칭으로 인해 대역폭 세금으로 인한 성능 저하가 무시할 수 있음을 보여줍니다. 섹션 III-C에 설명된 MoE 계층이 있는 LLM을 예로 들어 어려운 전체 대 전체 통신 패턴을 생성합니다. 언뜻 보기에 이 트래픽 패턴은 철도 전용 네트워크에 어렵습니다. 대부분의 전체 대 전체 트래픽에는 전달이 필요합니다. 그러나 HB 도메인이 NIC 도메인보다 훨씬 빠르기 때문에 HB 도메인에서 네트워크 트래픽을 전달하면 약간의 오버헤드가 발생합니다. 아래에서는 Rail 전용 네트워크에 대한 2단계 전달 라우팅 알고리즘을 사용하여 균일한 전체 대 전체 트래픽에 대한 감속 요인을 도출합니다. 이 전략은 Rail 최적화 네트워크의 스파인 계층이 초과 구독된 경우 혼잡을 방지하기 위해 NCCL에 이미 &quot;PCIe x NVLink&quot;(PXN)로 구현되었습니다[17]. 다음 도출에서 표 I에 정의된 것과 동일한 변수를 사용합니다. x GPU가 HB 도메인에 배치되고 Rail 전용 또는 Rail 최적화 네트워크가 y HB 도메인을 연결하는 x × y GPU 그리드를 고려합니다. HB 도메인은 대역폭 CF를 가지고 있고 NIC 도메인은 GPU 쌍당 대역폭 C를 가지고 있음을 기억하세요. Rail 최적화 네트워크의 경우 모든 GPU는 HB 및 전체 이분법 NIC 도메인을 통해 대상지로 직접 트래픽을 보냅니다. 각 GPU 쌍이 크기 D의 트래픽을 통신한다고 가정하면 전체 전체 대 전체 완료 시간은 다음과 같습니다.TRail-opt a2a = max( (x − 1)D x(y – 1)D¸ x(y-1)D CF C&#39;s C&#39;s (2) Rail 전용 네트워크의 경우 2단계 알고리즘은 먼저 각 레일 내에서 전체 대 전체를 실행하여 각 GPU가 레일에서 보낼 모든 데이터를 준비합니다.그런 다음 각 레일 내에서 각 GPU는 HB 도메인에서 두 번째 전체 대 전체를 실행하여 효과적인 샤드 크기 xD로 전송을 완료합니다.여기서 두 번째 단계에는 대역폭 세금이 포함되어 있습니다.총 전송 시간은 y(x − 1)Dx(y – 1)D + CF C&#39;s TRail-only = a2a (3) 두 항은 y(x − 1)D/CF만큼 다르며 이는 HB 도메인 내에서 전달 비용입니다.y(x − 1) ≈ x(y − 1), 감속 요인은 약 Cs/CF로, GPU 플랫폼의 DGX A100 및 DGX H세대의 경우 각각 8.2% 및 11.2%에 해당합니다. 이 요인은 두 도메인 간의 대역폭 비대칭으로 인해 낮습니다. 또한 이 감속은 전체 트래픽의 27%를 차지하는 전체 대 전체 통신에만 적용되며, 그림 5에서 볼 수 있듯이 이 작은 오버헤드는 암다의 법칙에 따라 무시할 수 있습니다. 이러한 속성으로 인해 네트워크 설계가 다른 클래스의 DNN 모델에도 적합하다는 점에 유의합니다. C. 레일 전용 네트워크의 장애 허용 속성 장애 허용은 장기 LLM 학습 작업이 있는 대규모 GPU 클러스터에 매우 중요합니다. 이 섹션에서는 기존 레일 최적화 네트워크와 비교하여 레일 전용 네트워크의 장애 허용 속성을 조사합니다. 링크 및 스위치 오류. 레일 스위치 또는 링크에 오류가 발생했다고 가정합니다. 실패한 스위치 또는 링크에 연결된 GPU는 레일 최적화 및 레일 전용 네트워크 아키텍처에서 모두 사용할 수 없게 되어 스위치 및 링크의 내결함성과 관련하여 두 설계가 동일하게 됩니다. 그러나 당사 설계에는 더 적은 스위치가 필요하므로 자연스럽게 실패 지점이 줄어듭니다. 데이터 센터 운영자는 추가 레일 스위치를 포함하여 중복 용량을 추가할 수 있으며 당사 설계는 any-to-any 네트워크 설계보다 비용 효율적입니다. GPU 플랫폼 실패. DGX와 유사한 서버로 구성된 GPU 클러스터의 경우 각 서버는 HB 도메인입니다. 서버에 장애가 발생하면 네트워크 운영자는 작업을 다른 정상 서버로 마이그레이션합니다. 레일 전용 연결은 새 서버에서 동일하게 유지됩니다. GB200과 유사한 클러스터의 경우 슈퍼칩 모듈은 서버와 유사하므로 장애 모드는 단일 GPU 장애와 동일하며, 이에 대해서는 다음에 설명합니다. HB 도메인에서 유휴 GPU가 있는 단일 GPU 장애. 단일 GPU 장애에 대해 두 가지 개별 시나리오를 별도로 설명합니다. 첫 번째 사례는 다른 유휴 GPU가 실패한 GPU와 동일한 HB 도메인을 나타내는 경우입니다. 이 경우 Railoptimized 네트워크는 HB 도메인 무결성을 손상시키지 않고 실패한 GPU를 유휴 GPU로 직접 교체합니다. 가능한 한 가지 솔루션은 Rail 전용 네트워크에 광학 재구성 가능 스위치를 활용하는 것입니다. 견고성을 개선하기 위해 GPU와 레일 스위치 사이에 소수의 광학 스위치를 추가하여 레일의 동적 재구성을 허용합니다. GPU에 장애가 발생하면 광학 스위치가 재구성되어 장애가 발생한 GPU를 대체할 건강한 유휴 GPU를 가져옵니다. 이 접근 방식은 주로 광학 재구성 가능 스위치를 사용하는 네트워크 설계의 장애 복구 메커니즘과 개념적으로 유사합니다[13], [25], [26]. 광학 스위치가 있는 Rail 전용에 대한 심층 분석은 향후 작업으로 미룹니다. 완전히 점유된 HB 도메인에서 단일 GPU 장애. 또 다른 장애 모드는 완전히 점유된 HB 도메인에서 GPU가 장애가 발생하고 다른 HB 도메인에서 대체 GPU가 필요할 때 발생합니다. 이 경우 Rail 전용 설계는 장애가 발생한 GPU의 작업을 클러스터의 다른 유휴 GPU로 마이그레이션하는 것을 방지하는데, 이는 Rail 최적화 네트워크에서 가능합니다. 그러나 이러한 솔루션은 Rail 최적화 네트워크에서도 바람직하지 않습니다.새로운 GPU는 더 이상 실패한 GPU와 동일한 HB 도메인에 속하지 않아 HB 도메인을 NIC 도메인으로 느리게 만드는 병목 현상이 발생합니다.대신 두 가지 솔루션을 제안합니다.HB 도메인이 작은 플랫폼의 경우 실패한 GPU가 있는 전체 HB 도메인의 작업을 새 도메인으로 마이그레이션합니다.더 큰 HB 도메인(예: K = 256인 DGX GH200 슈퍼컴퓨터)의 경우 이러한 HB 도메인은 광 코어 계층이 있는 다계층 토폴로지를 구성합니다[16].가능한 한 가지 접근 방식은 이전 실패 사례와 마찬가지로 광 스위치를 추가하는 것입니다. 하드웨어 FLOPS 활용률(%) 기준 진실 모델(22B, 8) (175B, 64) (530B, 280) (530B, 2240) (1T, 512) (GPT 크기, GPU 수) 그림 7. 기준 진실[28]과 공식 간의 HFU 비교. GPU에 장애가 발생하면 광 스위치가 재구성되어 장애가 발생한 GPU를 포함한 소수의 GPU를 정상적인 GPU로 교체하여 HB 도메인의 무결성을 유지합니다. V. 평가 A. 반복 시간 모델링 학습 반복 시간의 분석 모델을 통해 Rail 전용 네트워크 설계의 성능을 평가합니다. 분석 모델은 Calculon[27]의 접근 방식과 유사하게 TP, DP 및 PP를 사용한 LLM 학습의 중요 경로를 고려합니다. 문헌에 발표된 결과와 하드웨어 FLOP 활용률(HFU) 추정치를 비교하여 분석 모델의 정확성을 보여줍니다. HFU는 피크 부동 소수점 연산에 대한 반복에서 수행되는 하드웨어의 부동 소수점 연산을 말합니다. 이전 작업에서는 평가 설정에서 전체 하이퍼파라미터 세트를 제공하여 분석 모델에서 추정된 HFUS를 실제 결과와 비교할 수 있었습니다[28]. 평가에서 1~280개의 DGX A100 서버 클러스터를 가정합니다. DNN 모델의 반복당 학습에 필요한 총 FLOP를 계산하기 위해 Korthikanti 등이 제안한 것과 동일한 공식을 사용합니다[28]. 그림 7은 분석 모델에서 근사한 HFU를 다양한 GPT 모델과 클러스터 스케일에 대한 실제 결과와 비교합니다. GPT-1T의 경우 계산된 HFU는 실제 결과와 1.8%만 다릅니다. 분석 모델과 실제 결과 간의 불일치는 GPU 계산 및 통신에 대한 이상주의적 모델링, 계산과 통신이 겹치는 방식에 대한 가정, 메모리 오버헤드의 과소평가에서 비롯됩니다. 이러한 불일치는 모델 크기가 감소함에 따라 커집니다. GPT-22B 모델의 경우 추정 오차는 실제 MFU와 비교하여 10.8%입니다. 이 섹션의 나머지 부분에서는 분석 모델을 활용하여 레일 전용 상호 연결의 학습 반복 시간을 추정합니다. B. HB 도메인의 최적 크기는 얼마입니까? 직관적으로 HB 도메인 크기를 늘리면 학습 중 플랫폼 간 네트워크 오버헤드가 줄어듭니다. 이 섹션에서는 다음 질문에 답합니다. 레일 전용 상호 연결에서 HB 도메인의 최적 크기는 얼마입니까? 그림 8에서 HB 도메인 크기(K)를 변경하고 16384, 32768, 65536개의 H100 GPU가 있는 클러스터에 대한 GPT-1T 및 GPT-146B MegatronLM의 학습 반복 시간을 표시합니다. globalIteration Time (s) ... Ideal N=Rail-only N=..... Ideal N=-Rail-only N=..... Ideal N=Rail-only N=0.Iteration Time (s) 0.0.0.1 28 16 32 64고대역폭 도메인 크기 1 2 4 8 16 32 64고대역폭 도메인 크기 (a) GPT-1T (b) GPT-146B 그림 8. HB 도메인 크기가 변경됨에 따른 반복 시간.반복 시간(초) ம 2.4Tbps HBD -4.8Tbps HBD 반복 시간(초)-7.2Tbps HBD 9.6Tbps HBD100네트워크 대역폭(Gbps) (a) K의 반복 시간=네트워크 대역폭(Gbps) (b) K의 반복 시간=그림 9. HB 도메인 대역폭 및 네트워크 대역폭에 따른 GPT-1T의 반복 시간은 HB 도메인 크기에 따라 다릅니다. 이 평가에서 배치 크기는 GPT-1T의 경우 4096이고 GPT-146B의 경우 1024입니다. 각 클러스터 크기에 대해 가능한 모든 병렬화 전략을 열거하고 DGX GH200의 대역폭 및 계산 능력 매개변수를 사용하여 분석 모델에서 발견된 최적의 병렬화 전략을 사용합니다. 또한 이상적인 반복 시간을 포착하기 위해 전체 이분법 모놀리식 NVLink 패브릭이 모든 GPU를 연결하는 경우(즉, K = N인 경우, 여기서 N은 총 GPU 수) 학습 반복 시간도 계산합니다. 그림 8에서 볼 수 있듯이 HB 도메인 크기가 증가함에 따라 반복 시간이 감소하여 더 큰 HB 도메인이 학습 중 네트워크 오버헤드를 줄인다는 것을 나타냅니다. 두 GPT 모델 모두 HB 도메인 크기가 256일 때 달성된 반복 시간이 거의 최적입니다. 이상적인 경우(모든 GPU가 단일 HB 도메인에 있음)와 비교했을 때, HB 도메인이 256인 GPT-146B는 4.1% 더 느리고, GPT-1T는 0.9% 더 느립니다. 그러나 HB 도메인 크기가 커질수록 한계 이득은 감소합니다. 더 큰 GPT-1T 모델의 경우, 암달의 법칙으로 인해 32개 GPU 이상에서 학습 반복 시간이 정체되어 더 큰 HB 도메인의 비용 증가로 인한 수익 감소를 시사합니다. 그림 8b에 표시된 더 작은 GPT-146B 모델의 경우, HB 도메인 크기가 증가함에 따른 한계 이득은 GPT-1T보다 높습니다. 크기가 8인 HB 도메인을 제공하면 크기가 1인 HB 도메인에 비해 반복 시간이 43.3% 감소하는 반면, HB 도메인 크기를 8에서 256으로 늘리면 반복 시간이 30.6% 감소합니다. 더 작은 LLM의 더 중요한 한계 이득은 더 큰 모델보다 동일한 클러스터에 분산될 때 더 많은 통신 오버헤드를 초래합니다. 이 효과는 LLM이 성장함에 따라 계산 및 통신 비용이 어떻게 확장되는지에서 발생합니다. 통신 요구 사항은 모델의 숨겨진 크기와 시퀀스 길이에 따라 선형적으로 증가합니다. 반면에 모델 FLOPS는 이전 작업[21]에서 알 수 있듯이 이 두 매개변수에 따라 이차적으로 증가합니다. 따라서 최적의 HB 도메인 크기는 GPT 모델의 크기에 따라 달라진다는 결론을 내립니다. C. HB 도메인 및 네트워크 대역폭의 영향 HB 및 NIC 도메인의 사용 가능한 대역폭은 학습 중 통신 시간을 결정합니다. 1조 개의 매개변수가 있는 GPT 모델의 반복 시간에 대한 이러한 대역폭의 영향을 분석합니다. 그림 9a 및 9b는 다양한 HB 도메인에 대한 반복 시간 변화를 보여줍니다. 반복 시간(초) -K=--K=-K=-Ideal (K=32768)Rel. 성능 0.0.0.0.0.512 1024 2048배치 크기(a) 반복 시간 256 512 1024 2048배치 크기(b) 이상적인 경우에 대한 상대적 성능 그림 10. GPT-1T에 대한 배치 크기가 변경됨에 따른 반복 시간과 이상적인 경우에 대한 상대적 성능. = 8, HB 도메인 크기 K = 8 및 256에 대한 대역폭(다른 라인) 및 레일(x축)의 네트워크 대역폭. 예상대로 두 대역폭이 증가하면 반복 시간이 감소합니다. 그러나 K = 8 경우는 HB 도메인 대역폭에 덜 민감합니다. GPU당 대역폭을 4배(2.4Tbps에서 9.6Tbps로) 늘리면 K의 반복 시간이 평균 8.0%만 개선되는 반면 K = 256의 경우 13.3%가 개선됩니다. 반면, 더 큰 HB 도메인 크기는 네트워크 대역폭 개선에 더 두드러집니다. 대역폭을 100Gbps에서 400Gbps로 늘리면 K = 8의 경우 35.9%가 개선되지만 K = 256의 경우 8.0%만 개선됩니다. 따라서 향후 HB 도메인 크기가 증가함에 따라 HB 도메인 대역폭을 개선하는 것이 LLM의 네트워크 대역폭보다 더 유익합니다. D. 네트워크 설계에 대한 배치 크기의 영향 배치 크기는 일반적으로 최적화를 위한 ML 중심 메트릭이지만, 분석 결과 배치 크기가 총 학습 시간에 미치는 영향은 수렴에 필요한 총 반복 횟수를 넘어선다는 것을 알 수 있습니다. 이러한 영향을 더 잘 이해하기 위해 HB 도메인 크기를 K = 8에서 32768로 변경하는 동안 32768 GPU 클러스터에서 GPT-1T 모델의 반복 시간을 분석합니다. 이 연구에서는 글로벌 배치 크기를 256에서 4096으로 변경합니다. 그림 10a는 배치 크기가 변함에 따라 반복 시간의 변화를 표시합니다. 반복 시간은 모든 HB 도메인 크기에 대해 유사한 궤적을 보입니다. 그러나 상대적 성능(HB 도메인 크기에 대한 반복 시간과 이상적인 경우의 반복 시간의 비율)은 배치 크기가 증가함에 따라 향상됩니다. 그림 10b는 이러한 추세를 나타냅니다. K = 256인 경우 배치 크기가 256에서 4096 시퀀스로 증가함에 따라 상대적 성능이 95%에서 99%로 증가합니다. HB 도메인 크기가 작을 때 반복 시간의 이점이 두드러집니다. K 8의 경우 배치 크기를 4096으로 늘리면 상대적 성능이 65%에서 85%로 개선되어 HB 도메인이 작은 클러스터의 경우 더 큰 배치 크기가 더 바람직하다는 것을 시사합니다.이전 연구에 따르면 LLM 교육은 더 큰 배치 크기[1], [29]에서 이점을 얻을 수 있으며, 특히 더 큰 모델의 경우 더욱 그렇습니다.따라서 Rail 전용 설계에 완벽하게 적합합니다.E. 네트워크 비용 및 전력 분석 Rail 전용 네트워크 아키텍처는 사용하지 않는 네트워크 하드웨어를 제거하여 LLM 교육을 위한 네트워크 리소스를 현명하게 줄입니다.이 섹션에서는 제안하는 접근 방식의 네트워크 비용과 전력을 최신 Railoptimized GPU 클러스터와 비교합니다. 우리는 각 네트워크 설계에 필요한 스위치(Nsw)와 트랜시버(NTR)의 수를 계산하고 이전 연구와 공급업체[13], [30], [31]에서 보고된 수치를 기반으로 네트워크 장비 비용과 최대 전력 소비량을 도출합니다.¹ 우리는 가변적인 클러스터 크기와 네트워크 스위치 기수를 고려하여 최첨단 네트워크 아키텍처와 제안하는 아키텍처를 구축하는 데 필요한 스위치와 트랜시버의 수를 표 II에 나열합니다. 각 아키텍처에 대해 제공된 스위치 기수를 사용하여 최소 계층 Clos 네트워크를 구축하고 원하는 연결을 달성하는 데 필요한 최소 스위치 및 트랜시버 수를 계산합니다. 각 아키텍처의 총 비용은 총 비용 = 가격 swNsw + 가격TR × NTR이고 전력은 다음과 같습니다. Pwr sw × Nsw + PwrTR × NTR (4) (5) 총 전력 표 II의 마지막 두 열은 최첨단 기술에 비해 레일 전용 상호 연결의 비용과 전력 절감을 제공합니다. 당사의 레일 전용 설계는 최첨단 설계와 비교했을 때 네트워크 비용을 38%~77%(1억 1,700만~2억 3,400만 달러)만큼, 전력 소비량을 37%~75%(1.7~6.9메가와트)만큼 현저히 줄이는 동시에 동등한 성능을 달성합니다. 이러한 감소는 스파인 레이어 스위치를 제거하고 각 레일 내의 스위치 계층 수를 줄임으로써 가능합니다. 놀랍게도, 라딕스가 64인 스위치는 두 클러스터 크기에서 최악의 비용 및 전력 감소를 제공합니다. 이 경우 최첨단 설계는 3계층 Clos 네트워크가 필요한 반면, 레일 전용 설계는 각 레일에 대해 2계층이 필요합니다. 그럼에도 불구하고, 당사의 설계는 최첨단 설계와 동일한 성능을 달성하면서 총 스위치 수의 4분의 3만 필요합니다. VI.
--- RELATED WORK ---
LLM 추세. 무어의 법칙이 둔화되면서 LLM 계산 및 속도 요구 사항의 현재 성장률은 AI 가속기 및 네트워크 속도의 발전을 앞지르고 있으며, 이로 인해 하이퍼 스케일 클러스터와 보다 효율적인 상호 연결이 필요해졌습니다[32], [33]. MegatornLM 작업 라인은 LLM 병렬화의 선구자입니다[21], [28], [34]. 제거하려는 당사의 입장 ¹비용: PriceTR = 트랜시버당 $199, Pricesw = 400Gbps의 경우 스위치 포트당 $694; 전력: PowerTR = 트랜시버당 9W, Power sw = 스위치 포트당 18W 표 II 다양한 클러스터에 대한 스위치 및 트랜시버 수. 절감 #GPU 스위치 Radix #스위치(Nsw) #트랜시버(NTR)SOTA 레일 전용SOTA 레일 전용 비용 전력38% 37%77% 75%62% 60%38% 37% 6553638% 37% 77% 75% 모든 네트워크 연결은 MegatronLM을 보완합니다.또한 성능을 저하시키지 않고 언어 모델의 크기와 리소스 요구 사항을 줄이기 위한 지속적인 노력에 감사드립니다[35].이러한 작업은 네트워크 리소스를 줄이고 더 작은 언어 모델과 클러스터에서도 성능을 유지하므로 설계를 보완합니다.마찬가지로 DeepSpeed Zero++와 같이 양자화 및 압축을 통해 통신 양을 직접 줄이는 것을 목표로 하는 연구 방향도 접근 방식을 보완합니다[36].LLM 추론.이 논문에서는 LLM의 학습 워크로드를 살펴보지만 추론은 LLM 제품 주기의 또 다른 중요한 부분을 나타냅니다. 추론은 LLM을 통해 이동하는 데이터가 적고 순방향 패스와 여러 패스만 계산하여 응답 토큰을 생성하므로 리소스가 덜 필요합니다[37].Pope 등은 TPU-v4 아키텍처에서 추론을 위한 특정 병렬 처리를 개발했습니다[38].우리의 설계에 따라 각 HB 도메인은 지연 시간이 짧은 추론 제공 도메인이 되고 Rail 전용 연결은 여러 추론 도메인의 부하 분산을 돕습니다.LLM 추론에 대한 자세한 조사는 향후 작업에 맡깁니다.다중 작업 학습.GPU 클러스터가 여러 개의 작은 작업을 동시에 학습하는 것은 일반적입니다.기존 연구는 Clos 기반 GPU 클러스터에 초점을 맞추고 더 나은 공정성과 더 짧은 작업 완료 시간을 위한 기술을 제공합니다[39]-[42].이 논문은 대규모 클러스터에서 단일 LLM을 학습하는 데 중점을 두고 있지만 Rail 전용 네트워크 설계도 다중 작업 설정에 적합합니다.전체 클러스터는 TPU-v4의 경우와 유사하게 더 작은 직사각형 파티션으로 타일링하여 임의로 분할할 수 있습니다[25].그런 다음 각 파티션은 독립적으로 더 작은 학습 작업을 실행합니다. ML 인프라 및 기타 ML 워크로드. 이전 연구에서는 ML 모델을 위한 하드웨어와 소프트웨어를 공동 설계하는 이점을 설명했습니다. 예를 들어, Google의 TPU 클러스터는 TPU에서 3D 병렬성을 갖춘 대형 모델을 학습하도록 최적화되어 있고[25], Meta의 Neo는 대규모 임베딩 테이블이 있는 추천 모델을 학습하는 데 중점을 둡니다[43]. 저희의 연구는 LLM을 효율적으로 학습하기 위한 비용 효율적인 네트워크를 설계하는 데 중점을 두고 있습니다. 저희가 제안한 Rail 전용 아키텍처는 LLM을 위한 네트워크 설계에 중점을 두고 있지만, 전달 오버헤드가 낮기 때문에 다른 노력과 결합하면 저희의 설계는 다른 많은 DNN 워크로드에 효율적입니다(§IV-B). 최근 연구에서는 모든 DNN 모델에 대해 병렬화 전략과 집단 통신 알고리즘을 대역폭 인식으로 만들고자 시도하고 있습니다[44]–[46], Rail 전용 네트워크에 이상적인 트래픽 패턴을 생성합니다.VII. 결론 이 논문에서는 하이브리드 병렬성을 갖춘 LLM 학습의 트래픽 패턴을 조사하고 분석합니다. 저희는 LLM의 고유한 특성과 요구 사항에 맞는 새로운 Rail 전용 아키텍처를 제안합니다. 당사의 아키텍처는 최첨단 GPU 네트워크와 동일한 성능을 유지하면서 38%~77%의 비용 절감과 37%~75%의 전력 절감을 이룹니다. 감사의 말 익명의 Hot Interconnects 검토자 여러분의 피드백에 감사드립니다. MIT 소속 저자들은 DARPA FastNIC 4202290027, NSF SHF-2107244, NSF CAREER2144766, NSF PPOSS-2217099, NSF CNS-2211382, NSF FuSe-TG-2235466, Sloan 펠로십 FG-2022-18504, Semiconductor Research Corporation(SRC) 및 DARPA가 후원하는 JUMP 2.0 프로그램의 ACE 및 CUbiC 센터의 지원을 받습니다. 참고문헌 [1] TB Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. HerbertVoss, G. Krueger, T. Henighan, R. Child, A. Ramesh, DM Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, D. Amodei, &quot;언어 모델은 소수 샷 학습자입니다.&quot;, 2020. [2] L. Labs, &quot;Openai의 gpt-3 언어 모델: 기술 개요&quot;, 2020. [온라인]. 사용 가능: https://lambdalabs.com/blog/demystifying-gpt-[3] OpenAI, &quot;Gpt-4 기술 보고서,&quot; 2023. [4] The-Decoder, &quot;Gpt-4 has a trillion parameters report,&quot; 2023. [온라인]. 사용 가능: https://the-decoder.com/gpt-4-has-a-trillion-parameters/ [5] Nvidia, &quot;Nvlink 및 nvswitch: 서버 내부 및 서버 간 고급 멀티 GPU 통신의 구성 요소.&quot; 2023. [온라인]. 사용 가능: https://www.nvidia.com/en-us/data-center/nvlink/ [6] AMD, &quot;Amd Instinct mi300x 플랫폼,&quot; 2023. [온라인]. 사용 가능: https://www.amd.com/en/products/accelerators/instinct/mi300/platform.html [7] M. Al-Fares, A. Loukissas, 및 A. Vahdat, &quot;확장 가능한 상용 데이터 센터 네트워크 아키텍처&quot;, ACM SIGCOMM 2008 데이터 통신 컨퍼런스 회의록, ser. SIGCOMM &#39;08. 뉴욕, 뉴욕, 미국: Association for Computing Machinery, 2008, p. 63-74. [온라인]. 사용 가능: https://doi.org/10.1145/1402958.[8] C. Guo, H. Wu, Z. Deng, G. Soni, J. Ye, J. Padhye, 및 M. Lipshteyn, &quot;대규모 Rdma over common ethernet&quot;, 2016 ACM SIGCOMM 컨퍼런스 회의록, ser. SIGCOMM &#39;16. 뉴욕, 뉴욕, 미국: Association for Computing Machinery, 2016, p. 202-215. [온라인]. 제공: https://doi.org/10.1145/2934872.[9] W. Bai, SS Abdeen, A. Agrawal, KK Attre, P. Bahl, A. Bhagat, G. Bhaskara, T. Brokhman, L. Cao, A. Cheema, R. Chow, J. Cohen, M. Elhaddad, V. Ette, I. Figlin, D. Firestone, M. George, I. German, L. Ghai, E. Green, A. Greenberg, M. Gupta, R. Haagens, M. Hendel, R. Howlader, N. John, J. Johnstone, T. Jolly, G. Kramer, D. Kruse, A. Kumar, E. Lan, I. Lee, A. Levy, M. Lipshteyn, X. Liu, C. Liu, G. Lu, Y. Lu, X. Lu, V. Makhervaks, U. Malashanka, DA Maltz, I. Marinos, R. Mehta, S. Murthi, A. Namdhari, A. Ogus, J. Padhye, M. Pandya, D. Phillips, A. Power, S. Puri, S. Raindel, J. Rhee, A. Russo, M. Sah, A. Sheriff, C. Sparacino, A. Srivastava, W. Sun, N. Swanson, F. Tian, L. Tomczyk, V. Vadlamuri, A. Wolman, Y. Xie, J. Yom, L. Yuan, Y. Zhang, B. Zill, &quot;Empowering Azure Storage with RDMA&quot;, 20차 USENIX 심포지엄 네트워크 시스템 설계 및 구현(NSDI) 23). 보스턴, 매사추세츠주: USENIX 협회, 2023년 4월, 49-67쪽. [온라인]. 사용 가능: https://www.usenix.org/conference/nsdi23/presentation/bai [10] T. Schneider, O. Bibartiu, 및 T. Hoefler, &quot;Ensuring deadlock-freedom in low-diameter infiniband networks,&quot; 2016 IEEE 24th Annual Symposium on High-Performance Interconnects(HOTI), 2016, pp. 1–8. [11] P. Goyal, P. Shah, K. Zhao, G. Nikolaidis, M. Alizadeh, 및 TE Anderson, &quot;Backpressure flow control,&quot; 19th USENIX Symposium on Renton, Networked Systems Design and Implementation(NSDI 22). WA: USENIX Association, 2022년 4월, pp. 779–805. [온라인]. 사용 가능: https://www.usenix.org/conference/nsdi22/presentation/goyal [12] S. Hu, Y. Zhu, P. Cheng, C. Guo, K. Tan, J. Padhye, K. Chen, &quot;데이터센터 네트워크의 교착 상태: 교착 상태의 원인과 방지 방법&quot;, ACM 15th Workshop on Hot Topics in Networks, ser. HotNets &#39;16의 회의록. 뉴욕, 뉴욕, 미국: Association for Computing Machinery, 2016, p. 92-98. [온라인]. 사용 가능: https://doi.org/10.1145/3005745.[13] W. Wang, M. Khazraee, Z. Zhong, M. Ghobadi, Z. Jia, D. Mudigere, Y. Zhang, A. Kewitsch, &quot;TopoOpt: 분산형 학습 작업을 위한 네트워크 토폴로지 및 병렬화 전략의 공동 최적화&quot;, 제20회 USENIX 네트워크 시스템 설계 및 구현 심포지엄(NSDI 23). 매사추세츠주 보스턴: USENIX 협회, 2023년 4월, 739-767쪽. [온라인]. 사용 가능: https://www.usenix.org/conference/nsdi23/presentation/wang-weiyang [14] NVIDIA, &quot;Dgx h100 computer,&quot; 2023. [온라인]. 사용 가능: https://www.nvidia.com/en-us/data-center/dgx-h100/ [15] &quot;Gb200 nv172 computer,&quot; 2024. [온라인]. 사용 가능: https://www.nvidia.com/en-us/data-center/gb200-nv172/ [16] Nvidia, “Nvidia dgx gh200,” 2023. [온라인]. 사용 가능: https://www.nvidia.com/en-us/data-center/dgx-gh200/ [17] &quot;Nvidia Collective Communication Library 2.12를 사용하여 all2all 성능 두 배로 높이기&quot;, 2022. [온라인]. 사용 가능: https://developer.nvidia.com/blog/doubling-all2all-performancewith-nvidia-collective-communication-library-2-12/ [18] Meta, &quot;Introducing data center fabric, the next-generation facebook data center network,&quot; 2014. [온라인]. 사용 가능: https://engineering.fb.com/2014/11/14/production-engineering/introducingdata-center-fabric-the-next-generation-facebook-data-center-network/ [19] Nvidia, &quot;Nvidia dgx superpod: AI 리더십을 위한 차세대 확장 가능 인프라, 참조 아키텍처,&quot; 2023. [온라인]. 사용 가능: https://docs.nvidia.com/dgx-superpod-reference-architecturewith-dgx-h100-systems.pdf [20] S. Coll, E. Frachtenberg, F. Petrini, A. Hoisie 및 L. Gurvits, &quot;고성능 클러스터에서 멀티레일 네트워크 사용&quot;, IEEE International Conference on Cluster Computing 회의록, 2001, 15-24쪽. [21] D. Narayanan, M. Shoeybi, J. Casper, P. LeGresley, M. Patwary, VA Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee 및 M. Zaharia, &quot;megatron-lm을 사용하여 GPU 클러스터에 대한 효율적인 대규모 언어 모델 훈련&quot;, 2021. [22] S. Rajbhandari, C. Li, Z. Yao, M. Zhang, RY Aminabadi, AA Awan, J. Rasley 및 Y. He, &quot;Deepspeed-moe: 차세대 AI 규모를 강화하기 위한 전문가 혼합 추론 및 훈련 발전&quot;, 2022. [23] WM Mellette, R. McGuinness, A. Roy, A. Forencich, G. Papen, AC 스노에렌, G. Porter, &quot;Rotornet: 확장 가능하고 복잡도가 낮은 광 데이터센터 네트워크&quot;, ACM 데이터 통신 특별 관심 그룹 회의록, ser. SIGCOMM &#39;17. 뉴욕, 뉴욕, 미국: Association for Computing Machinery, 2017, p. 267–280. [온라인]. 사용 가능: https://doi.org/10.1145/3098822.[24] WM Mellette, R. Das, Y. Guo, R. McGuinness, AC Snoeren, G. Porter, &quot;대역폭 효율성과 낮은 지연 시간을 제공하기 위한 시간 확장&quot;, 제17회 USENIX 네트워크 시스템 설계 및 구현 심포지엄(NSDI 20). 캘리포니아주 산타클라라: USENIX 협회, 2020년 2월, pp. 1-18. [온라인]. 사용 가능: https://www.usenix.org/conference/nsdi20/presentation/mellette [25] NP Jouppi, G. Kurian, S. Li, P. Ma, R. Nagarajan, L. Nai, N. Patil, S. Subramanian, A. Swing, B. Towles, C. Young, X. Zhou, Z. Zhou, D. Patterson, &quot;Tpu v4: 임베딩을 위한 하드웨어 지원을 갖춘 머신 러닝을 위한 광학적으로 재구성 가능한 슈퍼컴퓨터,&quot; 2023. [26] L. Poutievski, O. Mashayekhi, J. Ong, A. Singh, M. Tariq, R. Wang, J. Zhang, V. Beauregard, P. Conner, S. Gribble, R. Kapoor, S. Kratzer, N. Li, H. Liu, K. Nagaraj, J. Ornstein, S. Sawhney, R. Urata, L. Vicisano, K. Yasumura, S. Zhang, J. Zhou, A. Vahdat, &quot;Jupiter evolving: Transforming google&#39;s datacenter network via optical circuit switches and software-defined networking&quot;, ACM SIGCOMM 2022 Conference, ser. SIGCOMM &#39;22의 회의록. 뉴욕, 뉴욕, 미국: Association for Computing Machinery, 2022, p. 66–85. [온라인]. 사용 가능: https://doi.org/10.1145/3544216.[27] M. Isaev, N. Mcdonald, L. Dennison, R. Vuduc, &quot;Calculon: a
--- CONCLUSION ---
이 논문에서 우리는 하이브리드 병렬성을 갖춘 LLM 훈련의 트래픽 패턴을 조사하고 분석합니다. 우리는 LLM의 고유한 특성과 요구 사항에 맞는 새로운 Rail 전용 아키텍처를 제안합니다. 우리의 아키텍처는 최첨단 GPU 네트워크와 동일한 성능을 유지하면서 38%~77%의 비용 절감과 37%~75%의 전력 절감으로 이어집니다. 감사의 말 익명의 Hot Interconnects 검토자에게 피드백을 주셔서 감사드립니다. MIT에 소속된 저자들은 DARPA FastNIC 4202290027, NSF SHF-2107244, NSF CAREER2144766, NSF PPOSS-2217099, NSF CNS-2211382, NSF FuSe-TG-2235466, Sloan 펠로십 FG-2022-18504, Semiconductor Research Corporation(SRC)이 후원하는 ACE 및 CUbiC 센터와 JUMP 2.0 프로그램에 따라 DARPA의 지원을 받았습니다. 참고문헌 [1] TB Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. HerbertVoss, G. Krueger, T. Henighan, R. Child, A. Ramesh, DM Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, D. Amodei, &quot;언어 모델은 소수 샷 학습자입니다.&quot;, 2020. [2] L. Labs, &quot;Openai의 gpt-3 언어 모델: 기술 개요&quot;, 2020. [온라인]. 사용 가능: https://lambdalabs.com/blog/demystifying-gpt-[3] OpenAI, &quot;Gpt-4 기술 보고서,&quot; 2023. [4] The-Decoder, &quot;Gpt-4 has a trillion parameters report,&quot; 2023. [온라인]. 사용 가능: https://the-decoder.com/gpt-4-has-a-trillion-parameters/ [5] Nvidia, &quot;Nvlink 및 nvswitch: 서버 내부 및 서버 간 고급 멀티 GPU 통신의 구성 요소.&quot; 2023. [온라인]. 사용 가능: https://www.nvidia.com/en-us/data-center/nvlink/ [6] AMD, &quot;Amd Instinct mi300x 플랫폼,&quot; 2023. [온라인]. 사용 가능: https://www.amd.com/en/products/accelerators/instinct/mi300/platform.html [7] M. Al-Fares, A. Loukissas, 및 A. Vahdat, &quot;확장 가능한 상용 데이터 센터 네트워크 아키텍처&quot;, ACM SIGCOMM 2008 데이터 통신 컨퍼런스 회의록, ser. SIGCOMM &#39;08. 뉴욕, 뉴욕, 미국: Association for Computing Machinery, 2008, p. 63-74. [온라인]. 사용 가능: https://doi.org/10.1145/1402958.[8] C. Guo, H. Wu, Z. Deng, G. Soni, J. Ye, J. Padhye, 및 M. Lipshteyn, &quot;대규모 Rdma over common ethernet&quot;, 2016 ACM SIGCOMM 컨퍼런스 회의록, ser. SIGCOMM &#39;16. 뉴욕, 뉴욕, 미국: Association for Computing Machinery, 2016, p. 202-215. [온라인]. 제공: https://doi.org/10.1145/2934872.[9] W. Bai, SS Abdeen, A. Agrawal, KK Attre, P. Bahl, A. Bhagat, G. Bhaskara, T. Brokhman, L. Cao, A. Cheema, R. Chow, J. Cohen, M. Elhaddad, V. Ette, I. Figlin, D. Firestone, M. George, I. German, L. Ghai, E. Green, A. Greenberg, M. Gupta, R. Haagens, M. Hendel, R. Howlader, N. John, J. Johnstone, T. Jolly, G. Kramer, D. Kruse, A. Kumar, E. Lan, I. Lee, A. Levy, M. Lipshteyn, X. Liu, C. Liu, G. Lu, Y. Lu, X. Lu, V. Makhervaks, U. Malashanka, DA Maltz, I. Marinos, R. Mehta, S. Murthi, A. Namdhari, A. Ogus, J. Padhye, M. Pandya, D. Phillips, A. Power, S. Puri, S. Raindel, J. Rhee, A. Russo, M. Sah, A. Sheriff, C. Sparacino, A. Srivastava, W. Sun, N. Swanson, F. Tian, L. Tomczyk, V. Vadlamuri, A. Wolman, Y. Xie, J. Yom, L. Yuan, Y. Zhang, B. Zill, &quot;Empowering Azure Storage with RDMA&quot;, 20차 USENIX 심포지엄 네트워크 시스템 설계 및 구현(NSDI) 23). 보스턴, 매사추세츠주: USENIX 협회, 2023년 4월, 49-67쪽. [온라인]. 사용 가능: https://www.usenix.org/conference/nsdi23/presentation/bai [10] T. Schneider, O. Bibartiu, 및 T. Hoefler, &quot;Ensuring deadlock-freedom in low-diameter infiniband networks,&quot; 2016 IEEE 24th Annual Symposium on High-Performance Interconnects(HOTI), 2016, pp. 1–8. [11] P. Goyal, P. Shah, K. Zhao, G. Nikolaidis, M. Alizadeh, 및 TE Anderson, &quot;Backpressure flow control,&quot; 19th USENIX Symposium on Renton, Networked Systems Design and Implementation(NSDI 22). WA: USENIX Association, 2022년 4월, pp. 779–805. [온라인]. 사용 가능: https://www.usenix.org/conference/nsdi22/presentation/goyal [12] S. Hu, Y. Zhu, P. Cheng, C. Guo, K. Tan, J. Padhye, K. Chen, &quot;데이터센터 네트워크의 교착 상태: 교착 상태의 원인과 방지 방법&quot;, ACM 15th Workshop on Hot Topics in Networks, ser. HotNets &#39;16의 회의록. 뉴욕, 뉴욕, 미국: Association for Computing Machinery, 2016, p. 92-98. [온라인]. 사용 가능: https://doi.org/10.1145/3005745.[13] W. Wang, M. Khazraee, Z. Zhong, M. Ghobadi, Z. Jia, D. Mudigere, Y. Zhang, A. Kewitsch, &quot;TopoOpt: 분산형 학습 작업을 위한 네트워크 토폴로지 및 병렬화 전략의 공동 최적화&quot;, 제20회 USENIX 네트워크 시스템 설계 및 구현 심포지엄(NSDI 23). 매사추세츠주 보스턴: USENIX 협회, 2023년 4월, 739-767쪽. [온라인]. 사용 가능: https://www.usenix.org/conference/nsdi23/presentation/wang-weiyang [14] NVIDIA, &quot;Dgx h100 computer,&quot; 2023. [온라인]. 사용 가능: https://www.nvidia.com/en-us/data-center/dgx-h100/ [15] &quot;Gb200 nv172 computer,&quot; 2024. [온라인]. 사용 가능: https://www.nvidia.com/en-us/data-center/gb200-nv172/ [16] Nvidia, “Nvidia dgx gh200,” 2023. [온라인]. 사용 가능: https://www.nvidia.com/en-us/data-center/dgx-gh200/ [17] &quot;Nvidia Collective Communication Library 2.12를 사용하여 all2all 성능 두 배로 높이기&quot;, 2022. [온라인]. 사용 가능: https://developer.nvidia.com/blog/doubling-all2all-performancewith-nvidia-collective-communication-library-2-12/ [18] Meta, &quot;Introducing data center fabric, the next-generation facebook data center network,&quot; 2014. [온라인]. 사용 가능: https://engineering.fb.com/2014/11/14/production-engineering/introducingdata-center-fabric-the-next-generation-facebook-data-center-network/ [19] Nvidia, &quot;Nvidia dgx superpod: AI 리더십을 위한 차세대 확장 가능 인프라, 참조 아키텍처,&quot; 2023. [온라인]. 사용 가능: https://docs.nvidia.com/dgx-superpod-reference-architecturewith-dgx-h100-systems.pdf [20] S. Coll, E. Frachtenberg, F. Petrini, A. Hoisie 및 L. Gurvits, &quot;고성능 클러스터에서 멀티레일 네트워크 사용&quot;, IEEE International Conference on Cluster Computing 회의록, 2001, 15-24쪽. [21] D. Narayanan, M. Shoeybi, J. Casper, P. LeGresley, M. Patwary, VA Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee 및 M. Zaharia, &quot;megatron-lm을 사용하여 GPU 클러스터에 대한 효율적인 대규모 언어 모델 훈련&quot;, 2021. [22] S. Rajbhandari, C. Li, Z. Yao, M. Zhang, RY Aminabadi, AA Awan, J. Rasley 및 Y. He, &quot;Deepspeed-moe: 차세대 AI 규모를 강화하기 위한 전문가 혼합 추론 및 훈련 발전&quot;, 2022. [23] WM Mellette, R. McGuinness, A. Roy, A. Forencich, G. Papen, AC 스노에렌, G. Porter, &quot;Rotornet: 확장 가능하고 복잡도가 낮은 광 데이터센터 네트워크&quot;, ACM 데이터 통신 특별 관심 그룹 회의록, ser. SIGCOMM &#39;17. 뉴욕, 뉴욕, 미국: Association for Computing Machinery, 2017, p. 267–280. [온라인]. 사용 가능: https://doi.org/10.1145/3098822.[24] WM Mellette, R. Das, Y. Guo, R. McGuinness, AC Snoeren, G. Porter, &quot;대역폭 효율성과 낮은 지연 시간을 제공하기 위한 시간 확장&quot;, 제17회 USENIX 네트워크 시스템 설계 및 구현 심포지엄(NSDI 20). 캘리포니아주 산타클라라: USENIX 협회, 2020년 2월, pp. 1-18. [온라인]. 사용 가능: https://www.usenix.org/conference/nsdi20/presentation/mellette [25] NP Jouppi, G. Kurian, S. Li, P. Ma, R. Nagarajan, L. Nai, N. Patil, S. Subramanian, A. Swing, B. Towles, C. Young, X. Zhou, Z. Zhou, D. Patterson, &quot;Tpu v4: 임베딩을 위한 하드웨어 지원을 갖춘 머신 러닝을 위한 광학적으로 재구성 가능한 슈퍼컴퓨터,&quot; 2023. [26] L. Poutievski, O. Mashayekhi, J. Ong, A. Singh, M. Tariq, R. Wang, J. Zhang, V. Beauregard, P. Conner, S. Gribble, R. Kapoor, S. Kratzer, N. Li, H. Liu, K. Nagaraj, J. Ornstein, S. Sawhney, R. Urata, L. Vicisano, K. Yasumura, S. Zhang, J. Zhou, A. Vahdat, &quot;Jupiter evolving: Transforming google&#39;s datacenter network via optical circuit switches and software-defined networking,&quot; ACM SIGCOMM 2022 Conference, ser. SIGCOMM &#39;22의 회의록. 뉴욕, 뉴욕, 미국: Association for Computing Machinery, 2022, p. 66–85. [온라인]. 사용 가능: https://doi.org/10.1145/3544216.[27] M. Isaev, N. Mcdonald, L. Dennison, R. Vuduc, &quot;Calculon: 시스템 및 대규모 언어 모델의 고수준 공동 설계를 위한 방법론 및 도구,&quot; International Conference for High Performance Computing, Networking, Storage and Analysis, ser. SC &#39;23의 회의록. 뉴욕, 뉴욕, 미국: Association for Computing Machinery, 2023. [온라인]. 사용 가능: https://doi.org/10.1145/3581784.[28] V. Korthikanti, J. Casper, S. Lym, L. McAfee, M. Andersch, M. Shoeybi, B. Catanzaro, &quot;대형 변압기 모델에서 활성화 재계산 감소&quot;, 2022. [29] J. Kaplan, S. McCandlish, T. Henighan, TB Brown, B. Chess, R. Child, S. Gray, A. Radford, J. Wu, D. Amodei, &quot;신경 언어 모델의 스케일링 법칙&quot;, 2020. [30] Nvidia, &quot;Nvidia docs hub: Mma4z00-ns400 400gb/s 단일 포트 osfp 400gb/s 멀티모드 sr4 50m 연결 시나리오&quot;, 2023. [온라인]. 사용 가능: https://docs.nvidia.com/networking/display/mma4z00ns400/ [31] ལུ 연결성+시나리오#:~:text=%20400Gb%2Fs%20트랜시버% 20has, 최대 또는 8와트%20일반. &quot;Nvidia 문서 허브: Qm9700/qm9790 lu ndr 400gb/s infiniband 스위치 시스템 사용 설명서 사양,&quot; 2023. [온라인]. 사용 가능: https://docs.nvidia.com/networking/display/qm97x0pub/specifications [32] H. Ballani, P. Costa, R. Behrendt, D. Cletheroe, I. Haller, K. Jozwik, F. Karinou, S. Lange, K. Shi, B. Thomsen, and H. Williams, &quot;Sirius: A flat datacenter network with nanosecond optical switched,” in Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication, ser. SIGCOMM &#39;20. New York, NY, USA: Association for Computing Machinery, 2020, p. 782-797. [온라인]. 사용 가능: https://doi.org/ 10.1145/3387514.[33] OpenAI, &quot;Openai: Ai and Compute,&quot; 2023. [온라인]. 사용 가능: https://openai.com/research/ai-and-compute [34] M. Shoeybi, M. Patwary, R. Puri, P. LeGresley, J. Casper, B. Catanzaro, &quot;Megatron-lm: 모델 병렬 처리를 사용하여 수십억 개의 매개변수 언어 모델 훈련&quot;, 2020. [35] Databricks, &quot;Hello dolly: 개방형 모델을 사용하여 chatgpt의 마법을 민주화&quot;, 2023. [온라인]. 사용 가능: https://www.databricks.com/blog/2023/03/24/hello-dollydemocratizing-magic-chatgpt-open-models.html [36] Microsoft, “Deepspeed zero++: 4배 적은 커뮤니케이션으로 LLM 및 채팅 모델 학습 속도 향상,&quot; 2023. [온라인]. 사용 가능: https://www.microsoft.com/en-us/research/blog/deepspeed-zero-a-leap-inspeed-for-llm-and-chat-model-training-with-4x-less-communication/ [37] Z. Li, L. Zheng, Y. Zhong, V. Liu, Y. Sheng, X. Jin, Y. Huang, Z. Chen, H. Zhang, JE Gonzalez, I. Stoica, “AlpaServe: 딥 러닝 서빙을 위한 모델 병렬 처리를 통한 통계적 멀티플렉싱,” 제17회 USENIX 운영 체제 설계 및 구현 심포지엄(OSDI 23). 매사추세츠주 보스턴: USENIX 협회, 2023년 7월. [온라인]. 사용 가능: https://www.usenix.org/conference/osdi23/presentation/li-zhouhan [38] R. Pope, S. Douglas, A. Chowdhery, J. Devlin, J. Bradbury, A. Levskaya, J. Heek, K. Xiao, S. Agrawal, J. Dean, &quot;변압기 추론의 효율적인 확장&quot;, 2022. [39] W. Xiao, R. Bhardwaj, R. Ramjee, M. Sivathanu, N. Kwatra, Z. Han, P. Patel, X. Peng, H. Zhao, Q. Zhang, F. Yang, L. Zhou, &quot;Gandiva: 딥 러닝을 위한 내성적 클러스터 스케줄링&quot;, 제13회 운영 체제 설계 및 구현 USENIX 심포지엄(OSDI 18) 캘리포니아 칼스배드: USENIX 협회, 2018년 10월, 595-610쪽. [온라인]. 사용 가능: https://www.usenix.org/conference/osdi18/presentation/xiao [40] J. Gu, M. Chowdhury, KG Shin, Y. Zhu, M. Jeon, J. Qian, H. Liu, and C. Guo, “Tiresias: A GPU cluster manager for distributed deep learning,” in 16th USENIX Symposium on Networked Systems Design and Implementation (NSDI 19). Boston, MA: USENIX Association, Feb. 2019, pp. 485–500. [Online]. 사용 가능: https://www.usenix.org/conference/nsdi19/presentation/gu [41] Y. Zhao, Y. Liu, Y. Peng, Y. Zhu, X. Liu, and X. Jin, &quot;Multi-resource interleaving for deep learning training,&quot; in Proceedings of the ACM SIGCOMM 2022 Conference, ser. 시그컴 &#39;22. 뉴욕, 뉴욕, 미국: 컴퓨팅 기계 협회, 2022, p. 428-440. [온라인]. 이용 가능: https://doi.org/10.1145/3544216.[42] S. Rajasekaran, M. Ghobadi 및 A. Akella, &quot;Cassini: 기계 학습 클러스터의 네트워크 인식 작업 스케줄링&quot;, 2023. [43] D. Mudigere, Y. Hao, J. Huang, Z. Jia, A. Tulloch, S. Sridharan, X. Liu, M. Ozdal, J. Nie, J. Park, L. Luo, JA Yang, L. Gao, D. Ivchenko, A. Basant, Y. Hu, J. Yang, EK Ardestani, X. Wang, R. Komuravelli, C.-H. Chu, S. Yilmaz, H. Li, J. Qian, Z. Feng, Y. Ma, J. Yang, E. Wen, H. Li, L. Yang, C. Sun, W. Zhao, D. Melts, K. Dhulipala, K. Kishore, T. Graf, A. Eisenman, KK Matam, A. Gangidi, GJ Chen, M. Krishnan, A. Nayak, K. Nair, B. Muthiah, M. khorashadi, P. Bhattacharya, P. Lapukhov, M. Naumov, A. Mathews, L. Qiao, M. Smelyanskiy, B. Jia 및 V. Rao, &quot;딥 러닝 추천 모델의 빠르고 확장 가능한 교육을 위한 소프트웨어-하드웨어 공동 설계&quot;, 2023. [44] L. Zheng, Z. Li, H. Zhang, Y. Zhuang, Z. Chen, Y. 황, Y. Wang, Y. Xu, D. Zhuo, EP Xing, JE Gonzalez, I. Stoica, &quot;Alpa: 분산 딥 러닝을 위한 운영자 간 및 운영자 내 병렬 처리 자동화&quot;, 제16회 USENIX 운영 체제 설계 및 구현 심포지엄(OSDI 22). 캘리포니아 칼스배드: USENIX 협회, 2022년 7월, 559-578쪽. [온라인]. 사용 가능: https://www.usenix.org/conference/osdi22/presentation/zheng-lianmin [45] C. Unger, Z. Jia, W. Wu, S. Lin, M. Baines, CEQ Narvaez, V. Ramakrishnaiah, N. Prajapati, P. McCormick, J. Mohd-Yusof, X. Luo, D. Mudigere, J. Park, M. Smelyanskiy, and A. Aiken, “Unity: 대수 변환과 병렬화의 공동 최적화를 통한 DNN 학습 가속화,&quot; 제16회 USENIX 운영 체제 설계 및 구현 심포지엄(OSDI 22). 캘리포니아 칼스배드: USENIX 협회, 2022년 7월, 267-284쪽. [온라인]. 사용 가능: https://www.usenix.org/conference/osdi22/presentation/unger [46] L. Zhao와 A. Krishnamurthy, &quot;집단적 커뮤니케이션을 위한 대역폭 최적 파이프라인 일정&quot;, 2023.
