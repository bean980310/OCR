--- ABSTRACT ---
전문 사진작가가 수행하는 일반적인 편집 작업에는 정리 작업이 포함됩니다. 산만 요소를 강조하지 않고 피사체를 강조하는 작업입니다. 이러한 편집은 시청자의 주의를 조종하는 동시에 사진적 사실성을 유지하는 섬세한 균형을 필요로 합니다. 최근의 접근 방식은 주의 감쇠 또는 증폭의 성공적인 사례를 자랑할 수 있지만, 대부분은 빈번하게 비현실적인 편집으로 어려움을 겪습니다. 우리는 산만 요소를 약화하고 관심 대상을 증폭하는 동시에 다양한 이미지 유형에서 높은 사실성을 유지하기 위해 눈에 띄는 이미지 향상을 위한 사실성 손실을 제안합니다. 전문 사진작가와의 평가에 따르면 사실성과 효과성이라는 이중 목표를 달성하고 자체 데이터 세트에서 최근 접근 방식보다 성능이 뛰어나며 더 작은 메모리 공간과 런타임이 필요합니다. 따라서 이미지 향상 및 사진 정리 작업을 자동화하기 위한 실행 가능한 솔루션을 제공합니다. 1.
--- INTRODUCTION ---
일상 사진에서 사진의 구성은 일반적으로 사진작가가 다른 산만한 것들이 아닌 우리의 주의를 집중시키고자 하는 주제를 포함합니다. 산만한 것들을 피할 수 없을 때, 사진작가는 일상적으로 사진을 편집하여 그 주제를 강조하지 않습니다. 반대로, 주제가 충분히 보이지 않을 때, 사진작가는 일상적으로 그 주제를 강조합니다. 전문가가 수행하는 가장 일반적인 강조 및 강조 해제 작업 중에는 각 요소의 채도, 노출 또는 색상을 변경하는 기본적인 작업이 있습니다. 개념적으로 간단하지만 이러한 작업은 시청자의 주의에 미치는 영향과 사진적 사실성을 섬세하게 균형을 맞춰야 하기 때문에 적용하기 어렵습니다. 이 편집 프로세스를 자동화하기 위해 최근 연구에서는 눈에 띄는 부분 모델을 가이드로 사용합니다[1,2,4,8, 16, 17]. 이러한 눈에 띄는 부분 모델[3,7, 10, 14, 19]은 시청자의 주의를 끄는 이미지의 영역을 예측하는 것을 목표로 하며, 눈에 띄는 부분 가이드 이미지 편집 방법은 선택한 영역의 예측 눈에 띄는 부분을 늘리거나 줄이도록 최적화됩니다. 그러나 예측된 두드러짐에만 기반하여 최적화하면 그림 1에서와 같이 비현실적인 편집이 종종 발생합니다. 이 문제는 두드러짐 모델이 편집되지 않은 이미지에서 학습되기 때문에 이미지 편집 작업에서 두드러짐 모델의 불안정성으로 인해 발생합니다. 비현실적인 편집은 인간 관찰자에게 매우 눈에 띄더라도 예측된 두드러짐이 낮을 수 있으며 그 반대의 경우도 마찬가지입니다. 이는 Aberman et al. [1]에서도 언급되었으며 그림 2에 나와 있습니다. 이전 방법에서는 적대적 설정 [2,4,8, 17], GAN 사전 확률 [1,8] 또는 사이클 일관성 [2]을 사용하여 사실성을 강제하려고 시도했지만 제한적인 성공만 거두었습니다(그림 1). 이미지 편집이 더 이상 사실적으로 보이지 않는 정확한 지점을 찾는 것은 어렵습니다. 이 작업에서는 전체 이미지에 초점을 맞추기보다는 로컬 편집의 사실성을 측정하는 방법을 제안합니다. 네트워크를 훈련하기 위해 노출, 채도, 색상 또는 화이트 밸런스에 미묘한 섭동을 주어 사실적인 이미지 편집을 생성하고 극단적인 조정을 적용하여 매우 비현실적인 편집을 생성합니다. 네트워크는 극단에서 긍정적이고 부정적인 예만 사용하여 훈련되었지만 그림 3에 표시된 것처럼 다양한 편집 작업에 대한 사실성의 연속적 측정을 성공적으로 학습했습니다. 사실성 지표를 두드러짐 유도 이미지 편집에 적용하여 사실성에서 벗어난 부분에 대해 페널티를 받으면서 선택한 영역의 두드러짐을 최적화하도록 시스템을 훈련합니다. 결합된 손실을 통해 높은 사실성을 유지하면서 선택한 영역을 성공적으로 향상 또는 억제할 수 있음을 보여줍니다. 그림 1에 표시된 것처럼 사진의 여러 영역에도 방법을 적용할 수 있습니다. 전문 사진 작가 및 사진 편집자와의 평가는 높은 사실성을 유지하고 편집된 사진에서 주의를 돌리는 데 성공했다는 주장을 확인해줍니다. 또한, 결과는 인간의 얼굴을 포함한 다양한 유형의 이미지에 강력하며 편집 매개변수의 다양한 순열에 걸쳐 안정적입니다. 26Mb의 모델 크기와 8ms의 런타임을 종합해 보면, 이러한 결과는 지금까지 이런 작업에 사용 가능한 접근 방식보다 더 광범위한 용도로 사용할 수 있는 더욱 실행 가능한 솔루션을 가지고 있음을 보여줍니다.
--- RELATED WORK ---
다양한 이미지 향상
--- METHOD ---
이미지의 여러 영역에 적용하여 객체를 약화하거나(단계 1, 2) 피사체를 향상(단계 3, 4)할 수 있습니다.(아래) 저희의 새로운 사실성 손실을 통해 다양한 객체에 사실적인 편집을 적용할 수 있는 반면, 최첨단 방법[1, 17]은 덜 사실적인 편집 결과를 생성할 수 있습니다. 초록 전문 사진작가가 수행하는 일반적인 편집 작업에는 정리 작업이 포함됩니다. 산만 요소를 약화하고 피사체를 향상시킵니다. 이러한 편집은 까다로워서 사진적 사실성을 유지하면서도 시청자의 주의를 조종하는 섬세한 균형을 필요로 합니다. 최근의 접근 방식은 주의 감쇠 또는 증폭의 성공적인 사례를 자랑할 수 있지만, 대부분은 빈번한 비현실적인 편집으로 어려움을 겪습니다. 저희는 산만 요소를 약화하고 관심 있는 객체를 증폭하는 동시에 다양한 이미지 유형에서 높은 사실성을 유지하기 위해 눈에 띄는 요소 기반 이미지 향상을 위한 사실성 손실을 제안합니다. 전문 사진작가와의 평가에 따르면 사실성과 효과성이라는 이중 목표를 달성했으며, 더 작은 메모리 사용량과 런타임을 필요로 하면서도 자체 데이터 세트에서 최근 접근 방식보다 우수한 성과를 거두었습니다. 따라서 이미지 향상 및 사진 정리 작업을 자동화하기 위한 실행 가능한 솔루션을 제공합니다. 1. 서론 일상 사진에서 사진 구성은 일반적으로 다른 산만함을 주는 것들이 아니라 사진작가가 주의를 집중하고자 하는 주제를 포함합니다. 산만함을 주는 것들을 피할 수 없는 경우, 사진작가는 일상적으로 사진을 편집하여 강조를 약화합니다. 반대로, 피사체가 충분히 보이지 않는 경우, 사진작가는 일상적으로 강조합니다. 전문가가 수행하는 가장 일반적인 강조 및 강조 해제 작업 중에는 각 요소의 채도, 노출 또는 색상을 변경하는 기본적인 작업이 있습니다. 개념적으로 간단하지만 이러한 작업은 시청자의 주의에 미치는 영향과 사진적 사실성을 섬세하게 균형을 맞춰야 하기 때문에 적용하기 어렵습니다. 이 편집 프로세스를 자동화하기 위해 최근 작업에서는 눈에 띄는 모델을 가이드로 사용합니다[1,2,4,8, 16, 17]. 이러한 두드러짐 모델[3,7, 10, 14, 19]은 시청자의 주의를 끄는 이미지의 영역을 예측하는 것을 목표로 하며, 두드러짐 기반 이미지 편집 방법은 선택한 영역의 예측 두드러짐을 늘리거나 줄이도록 최적화됩니다. 그러나 예측 두드러짐에만 기반하여 최적화하면 그림 1에서와 같이 비현실적인 편집이 종종 발생합니다. 이 문제는 두드러짐 모델이 편집되지 않은 이미지에서 학습되기 때문에 이미지 편집 작업에서 두드러짐 모델의 불안정성으로 인해 발생합니다. 비현실적인 편집은 인간 관찰자에게 매우 눈에 띄더라도 예측 두드러짐이 낮을 수 있으며 그 반대의 경우도 마찬가지입니다. 이는 Aberman et al.[1]에서도 언급되었으며 그림 2에 나와 있습니다. 이전 방법에서는 적대적 설정[2,4,8, 17], GAN 사전 확률[1,8] 또는 사이클 일관성[2]을 사용하여 사실성을 강제하려고 했지만 성공은 제한적이었습니다(그림 1). 이미지 편집이 더 이상 현실적으로 보이지 않는 정확한 지점을 찾는 것은 어려운 일입니다. 이 작업에서는 전체 이미지에 초점을 맞추는 대신 로컬 편집의 현실성을 측정하는 방법을 제안합니다. 네트워크를 훈련하기 위해 노출, 채도, 색상 또는 화이트 밸런스에 미묘한 변화를 주어 현실적인 이미지 편집을 생성하고 극단적인 조정을 적용하여 매우 비현실적인 편집을 생성합니다. 네트워크는 극단에서 긍정적이고 부정적인 예만 사용하여 훈련되었지만 그림 3에 표시된 것처럼 다양한 편집 작업에 대한 현실성의 연속적 측정을 성공적으로 학습했습니다. 현실성 지표를 돌출성 기반 이미지 편집에 적용하여 시스템을 훈련하여 현실성에서 벗어나는 경우 페널티를 받으면서 선택한 영역의 돌출성을 최적화합니다. 결합된 손실을 통해 높은 현실성을 유지하면서 선택한 영역을 성공적으로 향상 또는 억제할 수 있음을 보여줍니다. 그림 1에 표시된 것처럼 사진의 여러 영역에도 방법을 적용할 수 있습니다. 전문 사진 작가 및 사진 편집자와의 평가를 통해 높은 현실성을 유지하고 편집된 사진에서 주의를 돌리는 데 성공했다는 주장이 확인되었습니다. 또한, 우리의 결과는 인간의 얼굴을 포함한 다양한 유형의 이미지에 강력하며, 편집 매개변수의 다양한 순열에서 안정적입니다.26Mb의 모델 크기와 8ms의 런타임과 함께 이러한 결과는 우리가 지금까지 이러한 작업에 사용할 수 있는 접근 방식보다 더 광범위하게 사용할 수 있는 더욱 실행 가능한 솔루션을 가지고 있음을 보여줍니다.2. 관련 연구 관심 영역을 확대하거나 산만함을 유발하는 영역을 약화하고, 이미지 미학을 개선하고, 시청자의 주의를 돌리기 위해 다양한 이미지 향상 방법이 문헌에 소개되었습니다.이 작업은 주의 리타겟팅[15] 또는 재주의[18]라고도 합니다.이전 방법[5,15,20,22,23]은 원하는 두드러짐 변화를 달성하기 위한 편집 프로세스를 안내하기 위해 두드러짐 단서(채도, 선명도, 색상, 색역 등)에 대한 사전 지식을 통합했습니다. 그러나 두드러짐 단서에만 의존하면 생성된 편집의 다양성이 제한되고 의미적 제약이 부족하여 비현실적인 편집이 생성됩니다. 원본 이미지 두드러짐 맵 편집된 이미지 두드러짐 맵 그림 2. 극단적인 편집이 적용된 원본 이미지와 편집된 버전에 대한 예측 두드러짐 맵[7]. 두드러짐 모델은 일반적으로 현실적인 이미지로 학습된다는 점에 유의하세요. 이는 위쪽 행의 녹색 여성이 두드러짐이 낮다고 추정한 것처럼 비현실적인 입력에 대해 부정확한 예측을 내릴 수 있게 합니다.
--- EXPERIMENT ---
s가 보여주듯이, OHR[15]은 의미적으로 올바르지 않은 비현실적인 색상 변화를 생성하는 경향이 있고, WRS[23]는 효과가 제한적인 대비 및 채도 조정에 국한됩니다.최근 연구에서는 이전의 두드러짐 신호에 의존하는 대신 원하는 두드러짐 맵을 최적화하기 위해 두드러짐 추정 네트워크[3, 7, 10, 14, 19]를 활용합니다.뛰어남 모델은 이미지에서 인간의 시선이 집중되는 곳을 나타내는 히트맵을 출력하도록 훈련됩니다.이러한 모델은 입력 이미지의 사실성에 반응하도록 훈련되지 않았습니다.따라서 비현실적이거나 의미적으로 있을 수 없는 편집이 적용될 때 영역의 두드러짐이 일관되지 않게 감소하거나 증가할 것으로 예측할 수 있으며, 이는 그렇지 않으면 인간 시청자에게 충격적일 것입니다(그림 2).뛰어남만을 감독으로 사용하면 비현실적인 이미지가 생성될 수 있습니다. 비현실적인 편집을 방지하기 위해 이전 연구에서는 허용되는 변경에 대한 제약을 적용하고 적대적 훈련[2,4,8, 17]을 사용하거나 GAN 기반 모델[1,8]에서 학습된 사전 확률을 활용합니다. 예를 들어, Mechrez 등[16]과 Aberman 등(Warping)[1]은 모양을 유지하기 위해 결과를 입력 콘텐츠와 일치하도록 제한합니다. Aberman 등(CNN 및 Recolorization)[1]은 사실성을 유지하기 위해 이미지가 겪을 수 있는 변화량을 제한하는 정규화 항을 사용합니다. Mejjati 등[17]은 편집 작업을 일반적인 사진 작업 세트로 제한하기 위해 전역 매개변수 접근 방식을 설계했습니다. Chen 등[2]은 사이클 일관성을 활용하여 출력을 입력 이미지의 도메인 내에 유지합니다. Gatys 등[4]은 사실성의 대리로 VGG 지각 손실과 함께 텍스처 손실을 사용합니다. Lalonde 등[11]은 인간이 객체 의미론에 관계없이 이미지 내에서 색상 일관성을 선호한다고 주장합니다. 그들은 색상 통계를 사용하여 사실성을 측정하고 합성 작업에서 배경과 일치하도록 이미지를 다시 색칠하는 데 사용합니다.Zhu et al.[26]은 자연스러운 이미지와 컴퓨터로 생성된 합성을 구별하는 네트워크를 훈련하고 합성 작업의 사실성 측정 기준으로 사용합니다.[9]에서 강조된 것처럼 사실성은 GAN에서도 중요한 요소입니다.노출 채도 실제 가짜 노출 [0.85, 1.15] [0.5, 0.75] U [1.5, 2] 가짜(사람 특정) [0.5, 0.75] U [1.25, 1.5] 채도 [0.85, 1.15] [0, 0.5] U [1.5 — 2] [0.5, 0.75] U [1.25, 1.5] 표 1. 사실성 추정 네트워크를 위한 실제 및 가짜 훈련 이미지를 생성하는 데 사용된 매개변수 값 범위. 화이트 밸런싱 색상 곡선 [0.85, 1.15] 허용되지 않음 [0.5,2] [0.5,2] [0.9, 1] 허용되지 않음 편집 횟수 [1,3] [2,4] [2,3] ཤྲཱ ཀྟེ ཏྱཾ རྦཱ སྠཽ སྦྱ 0.0.0.0.0.1.1.2.0.0.0.-0.0.0.0.0.0.0.0.-0.0.0.0.0.0.0.0.0.0.0.1.노출 매개변수 값: 1(편집 없음) 0.0.1.0.0.ཤྲཱ སྠཽ ིི ཏྱཾ ཀྑུཾ སྱཱ॰ 0.0.0.0.0.0.1.0 1.5 2.1.0.0.0.0.0.0.0.5 1.0 1.5 2. 채도 매개변수 값: 1(편집 없음) 0.0.0.1.1e-1.85.1.1.1.1.1.0.0.0.0.0.0.0.0.0.-0.0.0.0.0.0.0.0.0.0.0.1.1.1.1.그림 3. 다양한 노출 및 채도 조정에 따른 사실성 추정 네트워크의 효능을 보여줍니다. 왼쪽은 선택한 영역(세 번째 열)이 편집되었을 때 예시 이미지(두 번째 열)에 대한 AR(수직 축)을 플로팅한 것입니다. 오른쪽, 편집된 이미지는 추정된 사실성(삽입된 숫자)의 해당 변화와 적용된 편집 매개변수의 값(아래)과 함께 표시됩니다. 로컬 편집의 사실성을 추정하는 새로운 방법을 제시합니다. 사실성 손실과 두드러짐 가이드를 결합하여, 사실성으로 주석이 달린 데이터나 부피가 큰 GAN 사전 지식 없이도 최종 결과를 사실적으로 유지하면서 주의 감쇠 또는 증폭을 성공적으로 적용할 수 있음을 보여줍니다. 3. 사실성 네트워크 이미지의 특정 영역을 편집할 때 사진의 전반적인 사실성을 유지하는 것은 어렵습니다. 사실성이 저하되기 시작하는 속도는 이미지 영역의 내용과 크기, 장면의 전반적인 구성, 적용되는 편집 유형에 따라 달라집니다. 따라서 이미지 편집이 사실적으로 보이지 않게 되는 시점을 정확하게 정의하는 문제가 특히 어려워집니다. 이 작업에서 우리는 극단적인 사실적이고 비현실적인 예만 사용하여 사실성 네트워크를 학습하는 것을 제안합니다. 이미지 값을 약간 교란하여 사실적인 편집을 생성하고 공격적인 편집을 적용하여 비현실적인 편집을 생성합니다. 우리는 이진 데이터로 학습되었음에도 불구하고, 우리 네트워크가 다양한 유형의 이미지 영역과 장면에 적응할 수 있는 연속적인 사실성 점수를 추정할 수 있음을 보여줍니다. 우리의 접근 방식은 Zhu et al. [26]의 작업에서 영감을 얻었으며, 이들은 마찬가지로 이진 실수 및 합성 합성으로부터 사실성을 학습합니다. 실제 샘플과 가짜 샘플을 생성하기 위해 일반적으로 사용되는 편집 작업인 노출, 채도, 색상 곡선 및 화이트 밸런싱(보충 자료의 공식 정의)에 대해 다양한 매개변수 범위를 활용합니다. 예를 들어, 영역의 노출을 너무 많이 늘리면 비현실적인 이미지가 생성되는 반면, 채도를 미묘하게 높여도 사실성에 큰 영향을 미치지 않습니다. 실험을 바탕으로, 우리는 훈련 데이터를 생성하기 위해 이미지 영역에 적용할 표 1의 매개변수 범위 세트를 결정했습니다. 훈련 예제를 생성하기 위해 먼저 무작위 수의 편집(1-4 사이)을 선택한 다음 편집 작업(예: 노출, 채도, 색상 곡선, 화이트 밸런싱)에 대한 순서와 표 1에 미리 지정된 범위에서 무작위로 균일하게 샘플링한 각 작업에 대한 값을 선택합니다. 이러한 편집을 선택한 순서대로 MS-COCO 이미지의 영역 세그먼트에 적용합니다[12]. 가짜 예제는 의도적으로 극단적인 값을 선택하여 생성합니다. 실제 예제는 더 좁은 범위 내에서 미묘한 편집을 샘플링하여 생성합니다. 인간 얼굴의 의미적 중요성과 얼굴 영역의 편집에 대한 민감도 증가로 인해 얼굴에 편집을 적용할 때 더 작은 매개변수 범위를 적용합니다. 그림 4는 여러 예를 보여줍니다. Pix2Pix[6] 네트워크 아키텍처를 사용하여 두 개의 MLP 계층을 따라 입력의 사실성 점수 R을 추정합니다. 훈련 데이터의 샘플에 대해 R은 실제 샘플의 경우 1, 가짜 샘플의 경우 0으로 정의됩니다. 또한 영역의 마스크 M을 네트워크에 입력으로 제공하여 입력 영역에 대한 출력을 조건화합니다. 우리는 추정된 값에 대한 손실을 계산하기 위해 제곱 오차[13]를 비평가로 사용합니다.Ldisc == R(I fake, M)² + 1 (R(Ireal, M) - 1)² (1) 여기서 I fake와 Ireal은 생성된 가짜 샘플과 진짜 샘플입니다. 이미지의 사실성에 대한 편집의 효과를 측정하기 위해 우리는 원본 이미지 I와 편집된 이미지 I&#39;에 대해 추정된 점수와 원본 이미지 I&#39;에 대한 점수 간의 차이를 계산합니다.그림 4. 사실성 추정 네트워크를 학습하는 데 사용되는 가짜 및 진짜 이미지의 예.자세한 내용은 섹션 3을 참조하세요.AR(I&#39;, I, M) = R(I&#39;, M) — R(I, M), 여기서 편집된 영역은 마스크 M으로 정의됩니다.(2) 그림 3에서 보듯이 AR은 네트워크가 극단적인 경우에만 학습되었음에도 불구하고 다양한 편집 매개변수에 대해 연속적인 사실성 값을 제공합니다.또한 네트워크에서 사실적이라고 간주되는 편집 범위가 각 이미지에서 동일하지 않고 주제와 편집 작업에 따라 달라짐을 보여줍니다. 그림과 보충 자료에서 네트워크에 의해 현실적이거나 비현실적으로 분류된 편집의 더 많은 예를 보여줍니다.4. 두드러짐 유도 이미지 향상 우리는 주어진 마스크에 대해 현실적이고 효과적인 객체 향상 또는 방해 요소 억제 결과를 생성하기 위해 현실성 손실을 적용하는 두드러짐 유도 이미지 편집 파이프라인을 개발합니다.우리 시스템은 노출, 채도, 색상 곡선 및 화이트 밸런싱의 4가지 편집 연산자의 모든 순열에 대한 편집 매개변수 세트를 추정할 수 있습니다.우리 시스템을 구축할 때 기존의 두드러짐 유도 이미지 편집 문헌에서 많은 아이디어를 차용하고, 특히 제안된 현실성 손실을 포함하여 결과의 현실성을 개선하는 데 설계 개선에 집중합니다.이러한 편집 작업은 비선형이므로 편집의 순서가 다르면 최종 결과가 변경됩니다.결과적으로 우리는 순열을 네트워크에 입력으로 제공하여 편집 작업의 순열에 회귀된 매개변수를 조건화합니다.네트워크의 아키텍처와 순열을 인코딩하는 데 사용된 임베딩에 대한 자세한 내용은 보충 자료에 포함되어 있습니다. 영어: Saliency Loss 사전 학습된 saliency 모델[7](SalNet)은 편집을 적용하기 전과 후에 이미지 영역에 포착되는 시청자의 주의를 대신하여 이미지 편집 프로세스를 감독하는 데 사용됩니다. 마스크된 영역 내에서 상대적인 변화의 기대값으로 관심 영역의 saliency 변화를 측정합니다. S(I, I&#39;, M) = Em SalNet(I) - SalNet(I&#39;)] Sal Net(I) (3) 여기서 E는 기대값을 나타내고 M은 영역 마스크입니다. 그림 2에서 볼 수 있듯이 예측된 saliency 히트맵은 비현실적인 편집에 적용될 때 크게 바뀔 수 있습니다. 결과적으로 기존 메트릭(예: [1, 17]의 절대 및 상대 차이, [2]의 이진 교차 엔트로피, [4]의 KL-다이버전스)에 의존하여 saliency의 변화를 측정하면 최적화 중에 큰 보상이나 패널티가 발생할 수 있습니다. 비현실적인 편집에 대한 무한히 큰 보상은 최종 손실 함수에서 현실성 항의 효과를 감소시킵니다. 이 문제를 해결하기 위해 우리는 돌출성 손실 함수를 다음과 같이 정의합니다. Lsal exp (wsalS(I,I&#39;, M)) (4) 돌출성이 원하는 방향으로 이동하면 지수가 손실을 압축하여 최소로 수렴하고 페널티를 빠르게 줄여 소프트 마진 역할을 합니다. 이 수렴 동작은 훈련 중 비현실적인 편집으로 인해 생성될 수 있는 큰 보상을 방지합니다. 지수 항은 돌출성이 잘못된 방향으로 이동할 때 더 큰 페널티를 부과하여 이상치에 대한 견고성과 더 빠른 수렴을 제공합니다. Wsal은 손실의 절대값을 제어하여 최종 손실에서 돌출성 손실의 가중치를 균형 잡습니다. 우리는 각각 증폭과 감쇠에 대해 5와 -1로 설정합니다. 현실성 손실 현실성 손실은 다음과 같이 정의됩니다.Crealism ReLU(—AR(I&#39;, I, M) – br) (5) 이 손실은 비현실적인 편집에 페널티를 부여하는 반면, 입력의 추정 현실성 점수를 개선하는 편집에 대한 보상은 제공하지 않습니다.이를 통해 편집이 적용되기 전에도 낮은 현실성 점수를 받는 이미지로 인해 네트워크가 페널티를 받는 것을 방지할 수 있습니다.ReLU와 오프셋 br은 페널티 없이 현실성을 약간 감소시킬 수 있는 마진을 제공하며, 실험에서는 페널티를 0.1로 설정했습니다.각각에 대해 두 개의 별도 네트워크를 학습합니다.최종 네트워크 목적은 두 손실 함수의 곱입니다.L = (1 + 현실성) × Lsal. (6) 이 공식에서 현실성 점수는 두드러짐의 변화에 부과되는 페널티에 대한 가중치 역할을 합니다.이를 통해 현실성 및 두드러짐 목적을 균형 있게 조정할 수 있습니다. 입력 이미지 우리의 Deepsal [1] 접근 가능한 입구 접근 가능한 입구 그림 5. 저자가 프로젝트 웹페이지에서 제공한 이미지에서 Deepsal [1]과 비교한 두드러짐 감쇠. 우리의 방법은 비현실적인 위장을 적용하지 않고도 대상 영역의 두드러짐을 효과적으로 감쇠할 수 있습니다. 우리는 EfficientNet-lite3 [21] 백본과 계단식 MLP 계층을 디코더로 사용하여 각 편집 작업에 대한 매개변수를 추정합니다. 아키텍처 세부 정보, 데이터 세트 및 교육에 대한 자세한 설명은 보충 자료에 제공됩니다. 5. 실험 및 결과 우리는 우리의 방법을 최첨단 두드러짐 기반 이미지 편집 접근 방식인 Deepsal [1], Gazeshift [17] 및 MEC [16]과 비교합니다. MEC는 동일한 데이터 세트에서 WRS [23] 및 OHR [15]의 사전 계산된 결과와 함께 자체 데이터 세트에 대한 결과를 제공합니다. 이 데이터 세트를 사용하여 WRS 및 OHR과 MEC를 비교합니다. 아키텍처에 사용된 EfficientNet[21] 백본은 크기가 작은 것으로 알려져 있습니다. 따라서 더 큰 아키텍처와 느린 이미지당 최적화를 사용하는 다른 최신(SOTA) 방법보다 결과가 상당히 빠르게 생성됩니다. [17] 표 1c에 보고된 속도 측정에 따르면 MEC는 하루 이상 걸리고 OHR은 30초가 필요하며 Gazeshift는 각 이미지를 처리하는 데 8초가 걸리는 반면, 우리 모델은 이미지당 8ms만 필요합니다. 정성적 결과와 정량적 결과를 모두 제시합니다. 우리 방법은 추론 시간 동안 편집의 순열을 입력으로 사용하므로 달리 언급하지 않는 한 제시된 결과에 대해 무작위로 순열을 선택합니다. 5.1. 정성적 비교 ¹Deepsal, WRS 및 MEC는 오픈 소스 구현을 제공하지 않습니다. 따라서 프로젝트 페이지에 포함된 결과에 의존했습니다. 또한 Deepsal 저자는 친절하게도 &quot;합성 신경망&quot; 변형에 대한 Adobe Stock 데이터 세트에 대한 결과를 제공해 주었습니다. 그림 5, 6 및 7은 SOTA와 비교한 결과를 보여줍니다. 이는 저희 방법이 이미지의 내용에 따라 다른 편집을 수행함을 보여줍니다. 방해 요소를 위장하는 더 중요한 색상 변경(그림 6의 2번째와 4번째 행, 그림 5의 3번째 행)이나 인간의 얼굴에 대한 매우 미묘한 편집(그림 6의 1번째 행)을 적용할 수 있습니다. 적용된 편집의 강도와 특성은 의미론에 따라 달라집니다. Gazeshift [17]의 적대적 손실 사용과 Deepsal [1]에서 사용된 정규화는 사실성을 명시적으로 고려하지 않고 해당 방법이 적용하는 편집을 제한합니다. 결과에서 알 수 있듯이, 종종 비현실적인 편집(예: 그림 5의 위장된 표지판 또는 그림 6의 부자연스러운 피부 톤과 색상 아티팩트)이나 효과가 낮은 매우 미묘한 편집을 적용합니다. MEC[16]는 이미지에서 사용 가능한 색상 패턴과 텍스처를 재사용하여 대상 영역을 업데이트합니다. 반면에 다른 영역과 텍스처는 다른 의미론에 해당할 수 있습니다. 결과적으로 그림 7a에 나와 있듯이 이 방법은 비현실적인 편집(녹색 악어 눈, 주황색 교통 표지판)이나 비효과적인 향상(갈색 새)을 생성하는 데 호환되지 않는 색상 및 텍스처 값을 적용할 수 있습니다. 그림 7b는 방해 요소 억제 이미지 세트에 대한 비교를 제공합니다. 우리 방법은 효과성 측면에서 비슷한 성능을 발휘하고 일관되게 현실적인 결과를 생성합니다. OHR[15]은 이미지 향상 작업을 위해 마스크된 영역과 나머지 이미지 간의 색상 구분을 최대화하려고 합니다. 명시적인 사실주의 모델링 없이는 비현실적인 색상(예: 그림 7a의 파란색 악어, 새, 말)을 생성하는 경향이 있습니다. 잘못된 색상은 이러한 영역의 두드러짐을 증가시키지만 사실주의는 희생됩니다. 비슷한 이유로 이 방법은 방해 요소를 억제하는 데 효과적이지 않습니다(그림 7b). WRS[23]는 비현실적인 이미지를 생성하지 않지만 거의 눈에 띄지 않고 대상 영역을 향상 또는 억제하는 데 덜 효과적인 편집을 수행합니다.우리는 이것이 허용되는 편집 매개변수(광도, 채도 및 선명도)의 범위를 의도적으로 제한하기 때문이라고 생각합니다.5.2. 사진작가들은 어떻게 생각할까?전문 사진작가의 관점을 다른 결과와 비교할 때 포함시키기 위해 사용자 연구를 수행했습니다.우리는 세 가지 매개변수 순서를 선택하여 결과를 보고합니다.최고의 두드러짐을 달성하는 것, 최고의 사실성을 생성하는 것(사실성 추정 네트워크에 따름), 그리고 정성적 수치에 사용된 것처럼 무작위로 선택된 매개변수 순열을 선택합니다.사용자 연구우리는 Up Work에서 사진 촬영 경험이 수년간 있고 Photoshop을 사용하여 사진을 편집하는 전문가 8명을 모집했습니다.우리는 평가 작업을 호스팅하기 위해 Appen 플랫폼을 사용했습니다. 감쇠 증폭 입력 이미지 Ours Gazeshift [17] Deepsal [1] Ours gazeshift [17] 그림 6. [17]의 Adobe Stock 이미지에서 GazeShift [17] 및 Deepsal [1]과 비교한 Saliency 변조. 입력 이미지 OHR [15] WRS [23] Mechrez [16] Ours 브레이크 없는 트럭은 좌측 차선을 사용합니다 브레이크 없는 트럭은 좌측 차선을 사용합니다 브레이크 없는 트럭은 좌측 차선을 사용합니다 브레이크 없는 트럭은 좌측 차선을 사용합니다 브레이크 없는 트럭은 좌측 차선을 사용합니다 브레이크 없는 트럭은 좌측 차선을 사용합니다 입력 이미지 OHR [15] WRS [23] Mechrez [16] Ours 하버드 공학부 하버드 하버드 및 응용 과학부 공학 및 응용 과학부 공학 및 응용 과학부 하버드 공학 및 응용 과학부 하버드 공학 및 응용 과학부 (a) 이미지 향상(증폭) (b) 방해 요소 억제(감쇠) 그림 7. MEC [16], WRS [23] 및 OHR [15]은 Mechrez 데이터 세트 [16]에 대해 설명합니다. 저희 연구 참여자에게는 원본 이미지, 마스크, 평가된 방법 중 하나에서 편집된 결과의 3개 이미지 패널이 제공되었습니다. 참여자에게는 &quot;효과성과 사실성이라는 두 가지 기준에 따라 각 이미지를 평가&quot;하라는 요청을 받았으며, 작업의 감쇠 버전에 대한 정의는 다음과 같습니다. &quot;특정 객체와 영역을 덜 산만하게 만들기 위해 이미지를 편집했습니다. 마스크된 객체/영역이 실제로 산만하지 않게 된 경우 이미지 편집이 효과적입니다. 사진이 편집되지 않은 것처럼 보이면 이미지 편집이 사실적입니다.&quot; 작업의 증폭 버전에서 효과성에 대한 문구는 &quot;특정 객체와 영역을 튀어나오게(더욱 주의를 끌거나 두드러지게) 만들기 위해 이미지를 편집했습니다. 마스크된 객체/영역이 실제로 더욱 주의를 끌게 된 경우 이미지 편집이 효과적입니다.&quot; 각 작업에서 이미지를 무작위로 섞었으므로 사진작가는 이미지와 방법을 서로 독립적으로 평가했습니다. 표의 결과. 2 우리는 [17]의 30개 Adobe Stock 이미지에서 GazeShift와 Deepsal에 대한 우리의 접근 방식을 비교합니다. 우리는 우리의 접근 방식이 표 2의 GazeShift와 비교하여 효과성과 사실성 모두에서 상당히 높은 점수를 얻는다는 것을 발견했습니다. 30개 Adobe Stock 이미지의 데이터 세트에 대한 효과성(즉, 두드러짐의 감쇠 또는 증폭 목표 달성)과 사실성(즉, 사진이 자연스럽게 보임)에 대한 사진작가의 평가(1~10점 척도, 높을수록 좋음). 숫자는 8명의 사진작가의 평균 점수이고 표준 편차는 괄호 안에 있습니다. 방법 Saliency 감쇠 Saliency 증폭 효과성 ↑ 사실성 ↑ 입력 이미지 Ours 적대적 훈련 효과성 ↑ 사실성 ↑ GazeShift [17] 4.78 (2.89) 5.93 (3.13) 7.36 (2.37) 7.07 (2.76) DeepSal [1] 4.04 (2.90) 8.49 (2.72) Ours - 최상의 사실성 6.56 (2.73) 6.78 (2.70) 7.39 (2.17) 8.31 (1.89) Ours 무작위 6.36 (2.79) Ours 최상의 Saliency 6.64 (2.79) 6.34 (2.88) 6.31 (2.70) 7.50 (2.08) 7.36 (2.21) 8.27 (1.94) 8.15 (2.10) 표 3. 사진작가 평점은 표에 나와 있음. 2 (a) Mechrez [16] 데이터 세트 및 (b) DeepSal 프로젝트 웹페이지 [1]의 14개 이미지 Saliency Amplification Effectiveness↑ Realism ↑ Saliency Attenuation Method Method Deepsal [1] Ours Random Effectiveness ↑ 7.08 (2.84) Realism ↑ 5.82 (3.43) MEC [16] 7.06 (2.68) 7.31 (2.93) WRS [23] 5.41 (3.22) 7.97 (2.70) 6.83 (2.52) 7.41 (2.70) OHR [15] 7.04 (3.04) 5.18 (3.76) Ours - Random 6.24 (2.9) 8.88 (1.74) (a) (b) 그림 8. 모델을 통해 학습했을 때 영어: 적대적 훈련은 눈에 띄는 것을 줄이는 데 효과적인 결과를 생성하지만, 결과 이미지는 사용자 연구에 따르면 현실적이지 않습니다.표 4. 고정된 사실주의 네트워크 대신 적대적 훈련을 사용한 변형과 주요 방법을 비교하는 표 2와 같은 사진 작가 평가.눈부심 감쇠 방법 적대적 훈련 우리의 무작위 효과 ↑ 5.06(2.84) 6.36(2.79) 사실성 ↑ 7.36(3.07) 6.34(2.88) 감쇠 작업.이는 GazeShift가 방해 요소를 감쇠하는 작업에서 성공적이지 않다는 정성적 관찰과 일치합니다.GazeShift는 이미지 영역에서 눈에 띄는 것을 증폭하는 데 특화되어 있으며, 이 작업에서 비슷한 성과를 달성하는 동시에 상당히 높은 사실주의 수준을 유지합니다. 또한 결과는 그림 6에서 미묘한 편집으로 인해 Deepsal의 효과성 점수가 낮음을 보여줍니다. 미묘한 편집은 결과가 원본 이미지와 거의 동일하기 때문에 사실성 점수가 높게 유지됨을 의미합니다. Deepsal은 Adobe Stock 이미지에서 효과적이지 않았으므로 공정한 비교를 제공하기 위해 표 3a의 프로젝트 페이지에서 제공한 14개 이미지에서 Deepsal과도 비교했습니다. 방해 요소의 눈에 띄는 부분을 줄이는 데 유사하게 효과적이면서도 상당히 높은 사실성 점수를 얻었습니다. 이는 Deepsal 편집이 매우 극단적일 수 있고 항상 사진처럼 사실적이지 않다는 정성적 관찰과 일치합니다. 표 3b는 Mechrez 데이터 세트[16]에 대한 사용자 연구 결과를 보여줍니다. 데이터 세트에서 77개 이미지를 사용하여 사용자 연구를 수행했습니다. 결과는 우리의 결과가 사실성 측면에서 우수하고 MEC와 비교할 만한 효과성을 달성한다는 것을 확인합니다. WRS의 낮은 효과성은 결과가 입력과 거의 동일하기 때문에 높은 사실성 점수를 산출하는 반면 OHR에 의한 비현실적인 색상 변경은 낮은 사실성 및 효과성 점수를 초래합니다. 5.3. Ablation Study 우리는 고정된 현실성 점수 추정 모델 대신 판별기를 적대적 손실로 사용하는 방법의 변형을 훈련했습니다. 우리는 관련 연구[2,4,17]와 유사하게 적대적 훈련 접근 방식의 일부로 판별기를 훈련했습니다. 우리는 훈련 중에 입력 이미지를 실제 샘플로, 생성된 이미지를 가짜 샘플로 사용했습니다. 그림 8은 이 훈련 전략을 사용한 샘플 결과를 보여줍니다. 판별기는 &quot;모든 편집&quot;에 페널티를 부여하도록 훈련되었기 때문에 2 데이터 세트에는 감쇠 작업을 위한 이미지가 10개뿐이어서 의미 있는 사용자 연구에는 부족합니다. 따라서 우리는 증폭 결과만 제공합니다. 이전 훈련 단계에서 적용된 증폭 결과는 네트워크가 미묘한 편집을 적용하도록 장려하여 방법의 효과가 떨어집니다. 반면에 명시적인 현실성 훈련이 부족하기 때문에 편집은 비현실적이지만 효과는 합리적입니다. 표 4에 보고된 등급도 우리의 결과를 확인해줍니다. 5.4. 추정 편집의 다양성과 최적성 그림 9b는 ADE20K [24, 25] 데이터 세트의 다양한 이미지에 대해 매개변수 추정 네트워크에서 추정한 편집 매개변수의 분포를 보여줍니다. 편집 매개변수는 각 이미지마다 다르며 이미지의 내용에 따라 다릅니다. 또한 추정 편집 범위가 실제 샘플에 대한 표 1에서 사용된 범위와 같지 않음을 보여줍니다. 추정 편집이 사실성과 관련하여 최적에 가까운지 평가하기 위해 그림 9a를 제공합니다. 그림에서 채도와 노출의 추정 편집 매개변수에 작은 가산 상수를 추가하여 얻은 사실성 히트맵을 보여줍니다. 히트맵은 추정 편집 매개변수(히트맵의 중앙)가 최적 사실성 영역에 있음을 보여줍니다. 각 방향으로 편집 매개변수를 변경하면 최종 결과의 사실성이 감소합니다. 5.5. 여러 이미지 영역에 대한 일반화 모델은 관심 영역만 수정하고 효율적으로 순방향 패스를 수행하므로 반복적으로 각 영역에 대한 편집 매개변수를 생성하여 여러 영역과 여러 마스크에서 실행할 수 있습니다.그림 1과 10에 예가 나와 있습니다.우리는 Gazeshift[17]에서 동일한 접근 방식을 사용했는데, 이는 관심 영역(전경)과 배경에 대한 두 세트의 편집 매개변수를 추정하여 전체 이미지를 편집합니다.이러한 Gazeshift 공식화는 입력 이미지와 입력 이미지 사이에 모순되는 목표가 있기 때문에 반복적 편집을 비실용적으로 만듭니다.리얼리즘 히트맵 ㄖㄖ마스크 5 고 채도 노출 W✓ 빨간색 채널로 곱하기 (a) 히트맵은 추정 채도(x축)와 노출(y축)을 변경할 때 달성한 리얼리즘 점수를 시각화합니다.추정된 값(히트맵 중앙)은 최적의 리얼리즘을 달성하는 반면 어느 방향으로든 매개변수를 변경하면 리얼리즘이 감소합니다. 샘플 편집 이미지와 히트맵에서 해당 위치도 시각화합니다.색상 곡선 화이트 밸런스(b) ADE20K [24, 25] 데이터 세트에서 추정된 매개변수의 다양성.x축은 각 매개변수의 범위입니다.감쇠 작업은 파란색이고 증폭은 빨간색으로 표시됩니다.그림 9. 우리 방법으로 추정된 편집 매개변수의 다양성과 최적성 시각화 입력 이미지 마스크 감쇠 마스크 증폭 Gazeshift Gazeshift- 배경 없음 우리 입력 이미지 마스크 우리 Gazeshift MEC Deepsal 그림 10. 입력 이미지와 감쇠 및 증폭할 마스크(왼쪽)가 주어지면 각 객체에 반복적으로 Gazeshift를 사용하면 색상 아티팩트(가운데 위, 얼굴, 그릇 및 수박)가 발생합니다.우리의 결과는 훨씬 더 사실적이고 효과적입니다(오른쪽).배경과 전경에 적용된 편집의 모순된 목적, Gazeshift는 여러 영역으로 일반화하지 못하고 배경 편집(가운데 아래)을 생략하면 편집의 효과가 감소합니다. 이미지 출처: @tysonbrand 반복(한 반복에서 전경이었던 것이 다음 반복에서 배경이 됨). 보다 실용적인 비교를 위해 Gazeshift를 실행할 때 배경 편집을 생략합니다.그림 10은 반복적 두드러짐 향상 작업에서 Gazeshift 성능이 저하되지만, 저희 방법은 여러 영역으로 강력하게 일반화할 수 있음을 보여줍니다.5.6. 제한 사항 저희 방법과 Gazeshift [17] 모두에서 사용되는 전역 편집(마스크 내부의 모든 픽셀에 동일한 편집을 적용)에는 대상 영역의 정확한 마스크가 필요합니다.그림 11에서 볼 수 있듯이 마스크 불완전성으로 인해 경계 주변에 부드럽지 않은 전환이 발생할 수 있습니다.이러한 경우 Deepsal [1] 및 MEC [16]와 같은 픽셀별 최적화 접근 방식은 마스크 불완전성으로 인한 심각한 아티팩트가 발생하지 않습니다.그림 11. 부드럽지 않은 마스크 경계의 효과.왼쪽, 입력 이미지에는 날카로운 모서리가 있는 마스크가 있습니다. 중앙, 우리의 방법과 Gazeshift[17]는 마스크 영역 주위에 강한 경계 아티팩트를 생성합니다(삽입 참조). 오른쪽, MEC[16]와 Deepsal[1]은 픽셀 단위로 작동하기 때문에 이 문제가 나타나지 않습니다. 6.
--- CONCLUSION ---
및 향후 작업 우리는 기존 이미지 편집 연산자를 사용하여 대상 영역에서 포착된 주의를 약화하거나 증폭하면서 이미지 사실성을 유지하는 이미지를 편집하는 방법을 설명합니다. 사실성은 편집된 이미지를 구별하도록 사전 훈련된 명시적이고 별도의 사실성 네트워크를 도입하여 달성됩니다. 사실성을 달성하기 위한 이 전략은 적대적 훈련 계획을 포함한 일반적인 접근 방식과 다릅니다. 왜냐하면 사실적이고 비현실적인(&quot;가짜&quot;) 편집에 해당하는 매개변수 값의 범위를 수동으로 지정한 추가적인 형태의 약한 감독을 도입하기 때문입니다. 이 사실성 비평가를 사용하여 훈련하면 훨씬 더 사실적이고 견고한 눈에 띄는 조절 이미지 편집을 추정할 수 있습니다. 밀리초 수준의 추론 시간과 함께 우리의 접근 방식은 눈에 띄는 유도 이미지 편집의 실용적이고 배포 가능한 응용 프로그램을 제공합니다. 참고문헌 [1] Kfir Aberman, Junfeng He, Yossi Gandelsman, Inbar Mosseri, David E. Jacobs, Kai Kohlhoff, Yael Pritch, Michael Rubinstein. 시각적 산만함을 줄이기 위한 깊은 돌출성 사전. Proc. CVPR, 2021. 1, 2, 4, 5, 6, 7,[2] Yen-Chung Chen, Keng-Jui Chang, Yi-Hsuan Tsai, YuChiang Frank Wang, Wei-Chen Chiu. 눈을 안내하세요: 돌출성 안내에 따른 이미지 조작 학습. Proc. BMVC, 2019. 1, 2, 4,[3] Camilo Fosco, Anelise Newman, Pat Sukhum, Yun Bin Zhang, Nanxuan Zhao, Aude Oliva, Zoya Bylinskii. 시간이 얼마나 있습니까? 다중 지속 돌출성 모델링. Proc. CVPR, 2020. 1,[4] Leon A. Gatys, Matthias Kümmerer, Thomas SA Wallis, Matthias Bethge. 합성곱 신경망으로 인간의 시선 안내. arXiv: 2109.01980 [cs.CV], 2017. 1, 2, 4,[5] Aiko Hagiwara, Akihiro Sugimoto, Kazuhiko Kawamoto. 시각적 주의를 유도하기 위한 돌출성 기반 이미지 편집. Proc. PETMEI, 2011.[6] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A Efros. 조건부 적대 네트워크를 사용한 이미지 간 변환. Proc. CVPR, 2017.[7] Sen Jia, Neil DB Bruce. EML-NET: 돌출성 예측을 위한 확장 가능한 다층 네트워크. Image Vis. Comput., 95:103887, 2020. 1, 2,[8] Lai Jiang, Mai Xu, Xiaofei Wang, Leonid Sigal. 돌출성 유도 이미지 변환. Proc. CVPR, 2021. 1,[9] Alexia Jolicoeur-Martineau. 상대론적 판별자: 표준 gan에서 누락된 핵심 요소.Proc. ICLR, 2019.[10] Matthias Kummerer, Thomas SA Wallis, Leon A Gatys, Matthias Bethge. 고정 예측에 대한 저수준 및 고수준 기여 이해.Proc. CVPR, 2017. 1,[11] Jean-Francois Lalonde 및 Alexei A Efros. 이미지 사실성 평가를 위한 색상 호환성 사용.Proc. ICCV, 2007.[12] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, C Lawrence Zitnick. Microsoft coco: 맥락 내 공통 객체.Proc. ECCV, 2014.[13] Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, Zhen Wang, Stephen Paul Smolley. 최소 제곱 생성적 적대 네트워크. Proc. ICCV, 2017에서.[14] R. Margolin, A. Tal, L. Zelnik-Manor. 패치를 특별하게 만드는 것은 무엇인가? Proc. CVPR, 2013에서. 1,[15] Victor A. Mateescu와 Ivan V. Bajić. 이미지에서 색상 조작을 통한 주의 재타겟팅. Proc. PIPV, 2014에서. 2, 5, 6,[16] Roey Mechrez, Eli Shechtman, Lihi Zelnik-Manor. 눈에 띄는 이미지 조작. Mach. Vis. 영어: Appl., 30(2):189–202, 2019. 1, 2, 5, 6, 7,[17] Youssef Alami Mejjati, Celso F. Gomez, Kwang In Kim, Eli Shechtman, Zoya Bylinskii. 여기 보세요!시각적 주의를 재지시하는 매개변수 학습 기반 접근 방식.Proc. ECCV, 2020. 1, 2, 4, 5, 6, 7,[18] Tam Nguyen, Bingbing ni, Hairong Liu, Wei Xia, Jiebo Luo, Mohan Kankanhalli, Shuicheng Yan.영상 재주의화.IEEE Trans. Multimed., 15(8):1910–1919, 2013.[19] Junting Pan, Cristian Canton, Kevin McGuinness, Noel E. O&#39;Connor, Jordi Torres, Elisa Sayrol, Xavier 및 Giroi Nieto. Salgan: 생성적 적대적 네트워크를 사용한 시각적 두드러짐 예측. arXiv:1701.01081 [cs.CV], 2017. 1,[20] Sara L. Su, Frédo Durand, Maneesh Agrawala. 텍스처 파워 맵을 사용하여 산만해지는 이미지 영역의 강조 해제. Proc. APGV, 2005.[21] Mingxing Tan 및 Quoc Le. Efficientnet: 합성곱 신경망을 위한 모델 스케일링 재고. Proc. ICML, 2019.[22] Javier Vazquez-Corral 및 Marcelo Bertalmío. 시각적 주의 재타겟팅을 위한 색역 매핑. Proc. CIC, 2017.[23] Lai-Kuan Wong 및 Kok-Lim Low. Saliency retargeting: 이미지 미학을 향상시키는 접근법. Proc. WACV, 2011. 2,5,6,[24] Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso 및 Antonio Torralba. ade20k 데이터 세트를 통한 장면 구문 분석. Proc. CVPR, 2017. 7,[25] Bolei Zhou, Hang Zhao, Xavier Puig, Tete Xiao, Sanja Fidler, Adela Barriuso 및 Antonio Torralba. ade20k 데이터 세트를 통한 장면의 의미적 이해. Int. J. Comput. Vision, 127(3):302-321, 2019. 7,[26] Jun-Yan Zhu, Philipp Krähenbühl, Eli Shechtman 및 Alexei A. Efros. 합성 이미지에서 현실감 인식을 위한 차별 모델 학습. Proc. ICCV, 2015. 2,
