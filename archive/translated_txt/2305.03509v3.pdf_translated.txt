--- ABSTRACT ---
애니메이션과 대화형 요소를 통한 ion(그림 2, 그림 3). 초록 확산 기반 생성 모델은 설득력 있는 이미지를 만드는 인상적인 능력으로 전 세계적인 주목을 받았습니다. 그러나 복잡한 구조와 작동 방식은 비전문가가 이해하기 어려운 경우가 많습니다. Stable Diffusion이 텍스트 프롬프트를 이미지로 변환하는 방식을 설명하는 최초의 대화형 시각화 도구인 Diffusion Explainer를 소개합니다. Diffusion Explainer는 Stable Diffusion의 복잡한 구조에 대한 시각적 개요와 기본 작동에 대한 설명을 긴밀하게 통합합니다. 프롬프트 변형의 이미지 생성을 비교하여 사용자는 키워드 변경이 이미지 생성에 미치는 영향을 알아낼 수 있습니다. 56명의 참여자를 대상으로 한 사용자 연구에 따르면 Diffusion Explainer는 비전문가에게 상당한 학습 이점을 제공합니다. 이 도구는 https://poloclub.github.io/diffusion-explainer/에서 124개국의 10,300명 이상의 사용자가 사용했습니다.
--- INTRODUCTION ---
영어: Stable Diffusion[43] 및 DALL-E[31]와 같은 확산 기반 생성 모델[36, 43, 31]은 AI 개발자, 설계자부터 정책 입안자에 이르기까지 인상적인 이미지 생성 능력으로 전 세계의 주목을 받았습니다. 그러나 생성 AI 모델의 인기와 발전은 AI 이미지 생성기 개발자에 의한 예술적 스타일 도용 혐의[11, 12]와 같은 사회적 우려[44, 9, 11, 12]를 불러일으켰습니다. 정책 입안자들은 또한 악성 데이터 생성을 방지하고 저작권 정책을 개정하는 방법에 대해 논의하고 있습니다[14, 13, 38, 1]. Georgia Tech. {seongmin bhoov jayw|speng65|apwright|kevin.li| haekyu alexanderyang|polo}@gatech.edu IBM Research. hendrik.strobelt@ibm.com 다양한 분야의 개인이 생성 AI 모델이 어떻게 기능하는지 이해하고 AI 연구자 및 개발자와 효과적으로 소통할 수 있는 절실한 필요성이 있습니다[12, 17]. 안정적 확산을 위한 학습 도구를 설계하는 데 있어서의 주요 과제. 높은 수준에서 안정적 확산은 텍스트 프롬프트에 따라 노이즈를 고해상도 이미지의 벡터 표현으로 반복적으로 정제합니다. 내부적으로 프롬프트는 토큰화되고 CLIP 텍스트 인코더[35]에 의해 벡터 표현으로 인코딩됩니다. 텍스트 표현의 안내에 따라 안정적 확산은 UNet 신경망[37]을 사용하여 이미지의 벡터 표현을 점진적으로 노이즈 제거하여 이미지 품질과 프롬프트 준수를 개선합니다. 최종 이미지 표현은 고해상도 이미지로 업스케일됩니다[24]. 안정적 확산에 대한 학습의 핵심은 여러 하위 구성 요소 간의 복잡한 상호 작용, 복잡한 작업 및 정제의 반복적 특성에서 비롯되며, 이는 전문가조차도 이해하기 어렵습니다[47]. 일부 기사[3]와 비디오[19, 4]는 Stable Diffusion을 설명하지만, 종종 머신 러닝에 대한 상당한 지식을 전제로 하고 수학적 세부 사항에 초점을 맞춥니다.이 연구에서 우리는 다음에 기여합니다.⚫ Diffusion Explainer는 비전문가가 Stable Diffusion이 텍스트 프롬프트를 고해상도 이미지로 변환하는 방법을 설명하도록 설계된 최초의 대화형 시각화 도구로, Stable Diffusion을 위한 대화형 학습 도구를 개발하는 데 있어 주요한 설계 과제를 극복합니다(그림 1).이 도구는 Stable Diffusion의 복잡한 구조에 대한 시각적 개요를 애니메이션과 대화형 요소를 통해 기본 작업에 대한 자세한 설명과 긴밀하게 통합합니다(그림 2, 그림 3; § 4.2).또한 프롬프트 변형의 이미지 생성을 비교하여 키워드 변경이 복잡한 이미지 생성 프로세스에 미치는 영향을 시각화하는 새로운 방법을 제공합니다(그림 4; §4.3). • 56명의 비전문가를 대상으로 한 인간 평가에서 도출된 반성 및 디자인 수업은 일반적인 블로그 게시물 접근 방식과 비교했을 때 Diffusion Explainer가 비전문가에게 Stable Diffusion을 설명하는 데 상당한 이점을 제공한다는 것을 보여줍니다. 대다수가 Diffusion Explainer를 선호했으며, 이해하기 쉽고 학습을 개선하는 데 더 효과적이라고 평가했습니다. 우리는 비전문가에게 최신 AI 기술에 대한 교육을 제공하기 위해 시각화를 만드는 데 필요한 핵심 디자인 수업을 추출했습니다(§ 5). • 설치, 고급 하드웨어 또는 코딩 기술이 필요 없이 대중의 최신 생성 AI 기술에 대한 교육 접근성을 확대하는 웹 기반 구현. Diffusion Explainer는 사용자 브라우저에서 로컬로 실행되므로 많은 동시 사용자가 장치에서 직접 학습할 수 있습니다(§ 4.1). https://poloclub.github.io/diffusion-explainer/에서 제공되는 Diffusion Explainer는 오픈 소스입니다¹. 124개국에서 10,300명 이상의 사용자가 사용한 Diffusion Explainer는 AI 교육을 민주화하는 데 큰 진전을 이루고 있습니다. 2
--- EXPERIMENT ---
브라우저에서 직접 간단한 모델과 데이터 세트를 제공합니다. 보다 고급 기술을 설명하기 위해 연구자들은 대화형 문서[16, 10, 27, 2, 39, 30]를 개발했지만 종종 사전 머신 러닝 지식을 가정합니다. 비전문가의 요구를 충족하기 위해 CNN Explainer[48], GAN Lab[21], AdversarialPlayground[29]와 같은 대화형 시각화 도구가 개발되었습니다. 이러한 도구의 성공에 영감을 받아 교육에서 Stable Diffusion에 대한 접근성을 확대하기 위한 웹 기반 대화형 시각화 도구인 Diffusion Explainer를 개발했습니다. Stable Diffusion에 대한 설명. Stable Diffusion을 설명하는 온라인 문서는 종종 비전문가에게는 어려울 수 있는 전문 용어와 방정식을 사용하여 머신 러닝 전문 지식을 가정하는 반면[49, 3, 18, 6], 초보자를 위한 문서[46, 5]는 주로 배포 및 프롬프트 엔지니어링을 다룹니다. 또한, 그들은 상위 수준 구조[46, 5] 또는 하위 수준 작업[18, 6]에 초점을 맞추며, 포괄적인 이해의 필요성[21, 48]을 간과합니다.Google Colab 튜토리얼[33, 50]은 코딩 기술이 필요하여 학습에 어려움을 겪습니다.Diffusion Explainer는 코딩 없이도 쉽게 실험할 수 있게 해주며, 대화형 요소를 통해 Stable Diffusion의 아키텍처와 작업에 대한 명확한 설명을 제공합니다.설계 목표 문헌[36, 47]을 검토하여 네 가지 설계 목표를 설정했습니다.G1. Stable Diffusion의 시각적 요약.Stable Diffusion에는 여러 복잡한 모델 구성 요소[36, 47]와 노이즈에서 고해상도 이미지의 벡터 표현으로의 순환적 정제가 포함됩니다.Diffusion Explainer는 모델 아키텍처와 순환적 데이터 흐름에 대한 개요를 제공하여 사용자가 전체 구조를 빠르게 이해할 수 있도록 돕습니다[20](§ 4.2).G2. 다양한 추상화 수준을 긴밀하게 통합하는 대화형 인터페이스. Stable Diffusion의 이미지 생성 프로세스는 여러 하위 구성 요소와 복잡한 기본 작업 간의 복잡한 상호 작용으로 인해 이해하기 어렵습니다[47, 35, 36]. 저수준 작업을 효과적으로 설명하고 개념적으로 고수준 개요와 연결하기 위해 유동 애니메이션과 대화형 요소를 통해 여러 추상화 수준을 연결합니다[48, 21](§ 4.2). G3. 텍스트 프롬프트의 키워드 변경이 이미지 생성에 미치는 영향 시각화. 프롬프트에서 몇 개의 키워드를 수정하면 예기치 않게 생성된 이미지에 극적인 변화가 발생할 수 있습니다[25](예: &quot;매우&quot;를 여러 번 반복[32]). 따라서 사용자는 생성된 이미지에 미치는 이러한 영향을 인식하고 이해하는 것이 중요합니다[15]. 몇 개의 키워드만 다른 두 텍스트 프롬프트에 대한 정제 프로세스를 시각화하여 각 프롬프트의 안내에 따라 이미지 표현이 어떻게 다르게 진화하는지 비교합니다(§ 4.3). G4. 웹 기반 배포를 통한 액세스 확대. 다양한 분야의 많은 개인이 생성 AI[12, 13, 38]를 이해하는 데 관심이 있으므로 설치, 특수 하드웨어 또는 코딩이 필요 없이 사용자 장치에서 로컬로 실행되도록 Diffusion Explainer를 개발합니다. 실시간 대화형 학습 경험[48]을 제공하기 위해 브라우저 지원과 속도² 면에서 제한이 있는 신생 WebGPU 기술[22]을 사용하여 사용자가 제공한 프롬프트에 대한 이미지를 생성하는 대신 미리 결정된 프롬프트에 대한 집약적 프로세스를 미리 계산합니다. 새로운 프롬프트와 하이퍼파라미터 설정으로 쉽게 확장할 수 있도록 코드를 오픈 소스로 제공합니다. 4 시스템 설계 및 구현 4.1 개요 Diffusion Explainer는 Stable Diffusion이 텍스트 프롬프트에서 고해상도 이미지를 생성하는 방법을 설명하는 웹 기반 대화형 시각화입니다. 점차적으로 정제된 무작위 노이즈 애니메이션과 사용자가 각 정제 타임스텝을 방문할 수 있도록 하는 타임스텝 컨트롤러(그림 1D)를 통합합니다. 프롬프트 선택기(그림 1A)에서 사용자는 템플릿[42]을 따르고 문헌[32, 7, 34]에서 식별된 인기 키워드(예: 상세, artstation에서 트렌드)를 포함하는 13개 프롬프트 중 하나를 선택합니다.Diffusion Explainer는 두 가지 뷰로 구성됩니다.아키텍처 뷰(§ 4.2)는 대화형 요소와 애니메이션(G2)을 통해 Stable Diffusion의 아키텍처(G1)와 기본 작업에 대한 시각적 개요를 긴밀하게 통합하고, 세부화 비교 뷰(§4.3)는 두 개의 관련 프롬프트의 이미지 생성을 비교하여 프롬프트 키워드가 이미지 생성에 미치는 영향을 파악합니다(G3).시각화 아래에서 더 자세한 내용에 대한 텍스트 설명을 제공합니다.Diffusion Explainer는 표준 웹 기술 스택(HTML, CSS, JavaScript)과 D3.js[8] 라이브러리(G4)를 사용하여 구현됩니다. 4. 아키텍처 뷰 아키텍처 뷰는 텍스트 표현 생성기(그림 1A)가 텍스트 프롬프트를 벡터 표현으로 변환하여 이미지 표현 정제기(그림 1B)가 노이즈를 점진적으로 고해상도 이미지의 벡터 표현으로 정제하도록 안내하는 방법에 대한 시각적 개요(G1, 그림 1)를 보여줍니다. 사용자는 생성기를 클릭하여 기본 작업에 대한 자세한 정보로 확장할 수 있습니다. 텍스트 표현 생성기는 텍스트 프롬프트를 벡터 표현으로 변환합니다. 사용자는 이를 클릭하여 텍스트 작업 뷰(G2, 그림 2A)로 확장하여 프롬프트가 토큰으로 분할된 다음 토큰이 텍스트 인코더를 사용하여 벡터 표현으로 인코딩된다는 것을 알 수 있습니다. 텍스트 인코더를 클릭하면 텍스트 이미지 연결 설명(G2; 그림 2B)이 표시되어 CLIP[35] 텍스트 인코더가 이미지 생성을 안내하는 데 중요한 이미지 관련 정보가 있는 텍스트 표현을 생성한다는 것을 설명합니다. 이미지 표현 정제기는 무작위 노이즈를 텍스트 프롬프트에 맞는 이미지의 벡터 표현으로 점진적으로 정제합니다. 각 정제 단계의 이미지 표현은 (1) 선형 연산을 사용하여 작은 이미지로 디코딩[45]하고 (2) Stable Diffusion의 출력 해상도로 업스케일링하여 시각화합니다.이미지 표현 정제기를 클릭하면 이미지 작업 보기(G2, 그림 3A)로 확장되며, 이는 정제가 노이즈 예측 및 제거로 구성되어 있음을 설명합니다.텍스트 프롬프트에 대한 이미지의 부착 강도를 제어하는 안내 스케일 하이퍼파라미터는 하단에 설명되어 있으며 대화형 안내 설명(G2, 그림 3B)에서 자세히 설명합니다.이는 2 이 글을 쓰는 시점에서 WebGPU는 Chrome 브라우저에서만 지원되며 Stable Diffusion을 실행하려면 제한된 설정이 필요합니다[26].단일 이미지를 생성하는 데는 최소 몇 분이 걸리며 CPU에서는 더 오래 걸립니다.따라서 훨씬 더 많은 계산이 필요한 Stable Diffusion을 학습하는 것은 불가능합니다. 텍스트 표현 생성기 m 텍스트 작업 보기 텍스트 표현 생성기 프롬프트에 77개 이상의 토큰(단어)이 포함된 경우 잘라내기 다음으로 채우기<end> 토큰이 77개 미만인 경우 77개 토큰 각 토큰에 대한 토크나이저 텍스트 인코더 벡터<start> 귀엽고<start> 0.39 0.02 -0.귀여운 토끼, a 0.03-1.33 0.B 텍스트-이미지 연결 설명 흰 개 사진 노란색 꽃 그림 이미지 텍스트 인코더 인코더 하이브리드 텍스트-이미지 공간 0.5 1.3 0.10.4 1.1 0.4 3.3.8 0.2 1.1 5.A 이미지 작업 보기 이미지 표현 정제기 m 이미지 표현 정제기 시간 단계 표현 UNet은 노이즈를 예측합니다 노이즈 정제된 표현 약화하여 제거합니다 안내 스케일 7v는 이미지 표현이 텍스트 프롬프트에 얼마나 잘 부합하는지 제어합니다.높을수록 더 강한 부합성을 제공하지만 과장될 수 있습니다.어떻게?B 대화형 안내 설명 UNet은 노이즈를 예측합니다 노이즈 약화하여 제거합니다 안정적 확산은 텍스트와 이미지를 연결하는 특수한 텍스트 인코더를 사용합니다. 이미지-캡션 쌍의 경우, 텍스트 인코더는 캡션의 토큰을 하이브리드 텍스트-이미지 공간에서 쌍을 이룬 이미지 인코더(Stable Diffusion에서는 사용하지 않음)에서 생성된 이미지 벡터에 가까운 벡터로 변환합니다.그림 2: Stable Diffusion이 텍스트 프롬프트를 벡터 표현으로 변환하는 방법을 알아보려면 사용자가 텍스트 표현 생성기를 클릭합니다.이 생성기는 (A) 프롬프트가 토큰으로 분할되고 벡터 표현으로 인코딩되는 방법을 설명하는 텍스트 작업 보기로 원활하게 확장됩니다.(B) 텍스트-이미지 연결 설명은 Stable Diffusion이 텍스트와 이미지를 연결하여 텍스트 표현이 이미지 생성 프로세스를 안내할 수 있도록 하는 방법을 보여줍니다.슬라이더를 사용하여 다양한 안내 척도 값을 실험하여 값이 높을수록 더 강한 준수로 이어지는 방식을 더 잘 이해할 수 있습니다.4.세분화 비교 보기세분화 비교 보기는 프롬프트에서 몇 가지 키워드를 수정하면 생성된 이미지가 크게 변경될 수 있는 방법을 보여줍니다(G3; 그림 4).Diffusion Explainer의 각 프롬프트는 몇 가지 키워드만 다른 프롬프트와 쌍을 이룹니다. 예를 들어, 원래 프롬프트 &quot;귀엽고 사랑스러운 토끼... 픽사 캐릭터&quot;가 프롬프트 변형 &quot;귀엽고 사랑스러운 토끼...&quot;와 짝을 이룹니다(키워드는 굵은 글씨로 강조 표시). 원래 프롬프트와 모델 구성 요소의 위치를 유지하면서 Refinement Comparison View와 Architecture View 간의 전환을 부드럽게 애니메이션화하는 동시에 원래 프롬프트 아래에서 프롬프트 변형을 페이드 인합니다. 페어링된 프롬프트에 대한 이미지 표현의 진화 궤적을 시각화하여 프롬프트 키워드가 이미지 표현의 진화에 어떻게 영향을 미치는지 보여줍니다(G3). 진화 궤적의 각 지점은 각 타임스텝의 이미지 표현에 해당하며 타임스텝에 따른 진행은 애니메이션화됩니다. UMAP³ [28]를 사용하여 모든 타임스텝, 텍스트 프롬프트, 안내 척도 및 난수 시드에서 이미지 표현의 2차원 표현을 계산합니다. 5 인간 평가 Diffusion Explainer의 효과를 평가하기 위해 사용자 연구를 수행했습니다. 피험자 내 디자인[40]에 따라 Diffusion Explainer를 다른 공개적으로 액세스 가능한 설명과 비교했습니다. 3 UMAP 하이퍼파라미터의 경우, 우리는 광범위한 n 이웃(5~30), min_dist(0.1~0.99), 랜덤 시드(0, 1, 2)에 대해 광범위한 테스트를 수행했으며, 국소 구조에 상당한 영향을 미치지 않는 것으로 나타났습니다. 따라서 우리는 15의 n 이웃, 0.99의 min_dist, 0.m의 랜덤 시드의 고정 구성을 채택했습니다.그림 3: 사용자는 Stable Diffusion이 텍스트 프롬프트에 맞춰진 고해상도 이미지의 벡터 표현으로 노이즈를 정제하는 방법을 배우기 위해 이미지 표현 정제기를 클릭하여 (A) 이미지 표현에서 노이즈가 예측되고 제거되는 방식을 보여주는 이미지 작업 보기로 원활하게 확장합니다.(B) 대화형 안내 설명을 통해 사용자는 다양한 안내 척도 값(0, 1, 7, 20)으로 대화형으로 실험하여 값이 높을수록 더 강력한 준수로 이어지는 방식을 더 잘 이해할 수 있습니다.5. 절차 우리는 온라인 모집 플랫폼인 Prolific에서 참가자를 모집했습니다. 참가자가 동의서에 서명한 후 배경 조사를 실시했습니다. 이미지 생성 AI에 관심이 있는 비전문가만 포함시키기 위해 참가자에게 이미지 생성 AI에 대한 관심을 표시하고 AI와 이미지 생성 AI에 대한 지식을 1~5점 척도로 자체 보고하도록 요청했습니다. 관심을 표시하고 AI와 생성 AI에 대한 지식이 거의 없다고 스스로 밝힌 사람만 자격을 부여했습니다(1: 무엇인지 모름, 2: 들어본 적이 있을 뿐, 3: AI 기반 도구를 가끔 사용함). 그런 다음 각 참가자는 Diffusion Explainer와 Google에서 가장 높은 순위를 차지한 블로그 게시물을 사용하여 Stable Diffusion에 대해 알아보았습니다. 다른 소스(예: 비디오, Google Colab 튜토리얼)는 홍보용이거나 무료가 아니거나 고급 하드웨어 및 코딩 기술이 필요하므로 제외했습니다. 순서 효과를 상쇄하기 위해 참가자의 절반은 Diffusion Explainer로 시작했고 나머지 절반은 블로그 게시물 이후에 사용했습니다. 도구 참여를 확인하기 위해 참가자는 각 도구를 사용한 후 간단한 퀴즈 질문 세 개에 답했습니다. 우리는 두 도구에 대해 최소 두 가지 질문에 올바르게 답한 참가자의 응답만 고려했습니다. 두 도구를 사용한 후, 참가자들은 5점 리커트 척도 질문에 답하여 도구를 평가했습니다. 연구는 참가자 한 명당 약 40분 동안 진행되었고, 각각 10.00달러의 보상을 받았습니다. 56명의 참가자가 지식 및 참여 스크리닝을 통과했습니다. 평균적으로 AI에서 자체 평가된 지식 수준은 2.79였고 이미지 생성 AI에서는 2.41이었습니다. 참가자들은 예술, 교육, 공공 행정, 의료, 부동산, 금융, 소매, 건설, 제조 등 다양한 분야에서 왔습니다. 4https://www.prolific.com Shttp://jalammar.github.io/illustrated-stable-diffusion/ 6도구를 사용한 참가자에게는 퀴즈가 쉽습니다.예: &quot;Diffusion Explainer에서 지원하는 모든 안내 척도 값을 선택하세요&quot; ← 개요로 돌아가기 귀엽고 사랑스러운 토끼, 커다랗고 맑은 눈에 꽃다발을 들고 있음, 귀여운 픽사 캐릭터 스타일 SeedRandom 노이즈 K ► 시간 단계• 시간 단계에서 텍스트 표현 안내 척도 7v 생성기 귀엽고 사랑스러운 토끼, 커다랗고 맑은 눈에 꽃다발을 들고 있음 이미지 표현 정제기 ▼다른 프롬프트 선택 시간 단계에서 동일한 무작위 노이즈 업스케일 진화 궤적 2D 공간에 투사된 이미지 표현 +350% 업스케일 그림 4: 정제 비교 뷰를 통해 사용자는 UMAP을 사용하여 두 개의 관련 텍스트 프롬프트의 안내를 받을 때 정제 시간 단계에서 이미지 표현이 어떻게 다르게 진화하는지 비교하여 프롬프트가 이미지 생성에 미치는 영향을 알아낼 수 있습니다. 영어: &quot;pixar&quot; 문구를 추가하면 생성된 토끼의 스타일이 원래의 모습을 유지하면서 색상과 질감이 더 만화적이고 생동감 있게 변경됩니다. Diffusion Explainer와 블로그 게시물의 사용성 평가 전반적인 경험 사용하기 쉬움 5.2 결과 및 디자인 교훈 그림 5는 두 도구의 사용성을 비교한 참가자의 응답을 요약한 것입니다. 전반적으로 대다수가 블로그 게시물보다 Diffusion Explainer를 선호했습니다(참가자 56명 중 44명). 그들은 AI에 대한 전문 지식이 없어도 Diffusion Explainer가 더 즐겁고, 이해력을 향상시키는 데 도움이 되며, 이해하기 쉽다고 생각했습니다. 이해하기 쉬움 즐거움 친구에게 추천할 것임 이해력 향상 ■대부분이 Diffusion Explainer를 선호 그림 5: Diffusion Explainer는 블로그 게시물보다 사용하기 쉬움. 비전문가도 Diffusion Explainer를 쉽게 사용하여 Stable Diffusion에 대한 이해력을 향상시켰습니다. Diffusion Explainer의 모든 기능(그림 6)에 높은 평가를 내린 것을 보고 기쁩니다. 이는 블로그 게시물(그림 5, 그림 7)보다 상당한 교육적 이점을 보여줍니다. 예를 들어, 텍스트 프롬프트가 이미지 생성을 안내하는 방식을 설명할 때 Diffusion Explainer는 평균 4.18점을 받았으며, 블로그 게시물의 3.55점을 크게 넘어섰습니다(그림 7). Diffusion Explainer 기능의 유용성 4.13 개요 4.48 애니메이션 사용 3.98 타임스텝 컨트롤러 4.09 프롬프트 변경 4.38 세부 정보로 확장 4.11 두 개의 관련 프롬프트 비교 3.96 진화 궤적 4.16 시각화 아래의 텍스트 그림 6: 모든 기능이 높은 평가를 받았습니다. 추상화 수준(G1, G2)을 연결하는 데 중요한 사려 깊은 디자인. 저희 연구는 모든 정보를 한 번에 제공하여 사용자를 압도할 수 있는 정적 게시물에 비해 대화형 디자인의 주요 이점을 확인합니다. 참가자들은 Diffusion Explainer의 개요(4.13)와 세부 정보로의 애니메이션 확장(4.48)을 높이 평가했습니다. 블로그 게시물(그림 7)에서 자세히 설명한 UNet의 아키텍처와 Stable Diffusion의 훈련과 같은 고급 개념을 탐구하지 않기로 한 결정은 비전문가도 Diffusion Explainer를 쉽게 사용할 수 있도록 하기 위한 것입니다. 한 참가자는 &quot;[UNet 노이즈 예측기와 전문 용어의 레이어가 [블로그 게시물]을 너무 압도적이고 기술적으로 만들었습니다.&quot;라고 말했습니다. 이는 정보의 양과 사용자의 전문성을 균형 있게 조절하기 위해 시각화에 포함할 세부 정보를 신중하게 선택하는 것의 중요성을 강조합니다. 대화형 시각화는 하이퍼파라미터(G2)를 이해하는 데 고유한 학습 이점을 제공합니다. 참가자들은 Diffusion Explainer가 블로그 게시물보다 안내 척도(4.29 대 2.91)와 랜덤 시드(4.25 대 2.88)를 설명하는 데 훨씬 더 효과적이라고 생각했습니다(그림 7). 그들은 Diffusion Explainer를 빠르게 실험할 수 있는 기능을 높이 평가했습니다. 한 참가자는 &quot;[그것은] 포즈와 같습니다. 각 프롬프트에 대해 멋진 사진을 얻을 수 있는 멋진 게임 체인저 설정으로 텍스트에서 이미지를 만드는 방법을 배우는 데 도움이 됩니다.&quot;라고 말했습니다. 또한, 참가자들은 정적 블로그 게시물에서 쉽게 복제할 수 없는 프롬프트와 하이퍼파라미터 간의 복잡한 상호 작용을 파악할 수 있었습니다.또 다른 참가자는 &quot;최상의 이미지 품질을 위한 안내 척도는 프롬프트에 따라 달라집니다. 각 프롬프트에 대한 값을 신중하게 결정해야 합니다.&quot;라고 언급했습니다.Diffusion Explainer 대 블로그 게시물 프롬프트 수정의 영향에 대한 이해 향상 반복적 정제 고수준 구조 안정적 확산의 훈련 텍스트 표현 생성 텍스트-이미지 연결 프롬프트가 이미지 생성을 안내하는 방식 UNet의 내부 작동 프롬프트 변형을 비교하면 전문가가 아닌 사람도 프롬프트 키워드(G3)의 영향을 이해하는 데 도움이 됩니다. 프롬프트의 사소한 변경이 이미지 생성에 상당한 영향을 미칠 수 있는 방법에 대해 비전문가가 배우는 데 도움이 되도록 설계된 최초의 도구로서, Diffusion Explainer의 정제 비교 뷰가 호평을 받았다는 사실을 알게 되어 기쁩니다. 특히, 프롬프트 비교는 평균 4.11점을 받았고, 종종 고급 학습을 위해 고려되는 대부분의 안정적 확산 분석에 대한 블로그 게시물보다 효과적인 기술인 UMAP [28]의 Evolution Trajectory 기반 그림 7: 확산 설명자도 개념에 대해 좋은 평가를 받았습니다(3.96). 효과성은 확산 설명자가 프롬프트 수정이 이미지 생성에 미치는 영향에 대한 이해를 개선하는 데 상당히 높은 평가(4.16 대 2.86)를 받은 것으로 입증되었습니다(그림 7). 한 참가자는 &quot;확산 설명자를 사용하면 프롬프트의 미세한 변화가 그림의 스타일과 품질에 어떤 영향을 미치는지 볼 수 있어서 좋습니다. 두 가지 다른 프롬프트를 비교하고 시간이 지남에 따라 이미지와 표현이 어떻게 발전하는지 보는 것이 좋습니다.&quot;라고 말했습니다. 6
--- CONCLUSION ---
우리는 Stable Diffusion이 텍스트 프롬프트에서 고해상도 이미지를 생성하는 방법을 설명하는 최초의 대화형 웹 기반 시각화 도구인 Diffusion Explainer를 소개했습니다. 이 도구는 애니메이션과 대화형 요소를 통해 기본 작업에 대한 자세한 설명과 시각적 개요를 원활하게 통합합니다. 혁신적인 디자인은 프롬프트 키워드가 이미지 생성에 미치는 영향을 밝혀냅니다. 56명의 비전문가를 대상으로 한 사용자 연구는 인기 있는 블로그 게시물보다 Diffusion Explainer가 더 우수하다는 것을 보여줍니다. 우리의 연구가 사람들이 현대 AI 기술에 대한 이해를 높이기 위한 시각화의 추가 개발에 영감을 줄 수 있기를 바랍니다. 참고문헌 [1] 저작권 사무소가 새로운 인공 지능 이니셔티브를 시작합니다. https://www.copyright.gov/newsnet/2023/1004.html, 2023. 액세스일: 2023-04-30.[2] A. Agnihotri 및 N. Batra. 베이지안 최적화 탐색. Distill, 5(5):e26, 2020.[3] J. Alammar. 그림으로 표현된 안정적 확산. https://jalammar.github. io/illustrated-stable-diffusion/, 2022. 2023-04-30에 액세스. 1,[4] J. Alammar. AI 아트 설명: AI가 이미지를 생성하는 방법(안정적 확산, Midjourney 및 DALLE). https://youtu.be/MXmacOUJUaw, 2023. 2023-04-30에 액세스.[5] Andrew. 안정적 확산 AI 이미지에 대한 완전 초보자 가이드. https://stable-diffusion-art.com/beginners-guide/, 2023. 2023-04-30에 액세스.[6] Andrew. 안정적 확산은 어떻게 작동합니까? https://stable-diffusionart.com/how-stable-diffusion-work/, 2023. 액세스일: 2023-04-30.[7] Andrew. Stable Diffusion prompt: 확정적 가이드. https://stablediffusion-art.com/prompt-guide/, 2023. 액세스일: 2023-04-29.[8] M. Bostock, V. Ogievetsky, and J. Heer. D3 데이터 기반 문서. IEEE 시각화 및 컴퓨터 그래픽 거래, 17(12):2301-2309, 2011.[9] J. Brusseau. 가속 AI 윤리, 혁신과 안전 간의 논쟁, 안정성 AI의 확산 대 OpenAI의 Dall-E. arXiv 사전 인쇄본 arXiv:2212.01834, 2022.[10] S. Carter와 M. Nielsen. 인공지능을 사용하여 인간 지능을 증강합니다. Distill, 2017. https://distill.pub/2017/aia. doi:.23915/distill.00009[11] L. Choudhary. Stable Diffusion은 이제 예술 작품을 &#39;훔친&#39; 혐의로 고소당했습니다. https://analyticsindiamag.com/stable-diffusion-is-now-accused-of-stealing-artwork/, 2022. 2023-04-30에 액세스했습니다.[12] P. Dixit. AI 아트 생성기에 대한 획기적인 소송의 배후에 있는 세 명의 아티스트를 만나보세요. https://www.buzzfeednews.com/article/pranavdixit/ai-art-generators-lawsuit-stable-diffusion-midjourney, 2023. 2023-04-30에 액세스했습니다. 1,[13] A. Engler. ChatGPT와 같은 생성 AI 규제에 대한 초기 생각. Brookings Institution, 2023. 2023-04-30에 액세스. 1,[14] AG Eshoo. Eshoo가 NSA 및 OSTP에 안전하지 않은 AI 관행 해결을 촉구. https://eshoo.house.gov/media/press-releases/eshoo-urges-nsaostp-address-unsafe-ai-practices, 2022. 2023-04-30에 액세스.[15] Y. Feng, X. Wang, KK Wong, S. Wang, Y. Lu, M. Zhu, B. Wang, W. Chen. Promptmagician: 텍스트-이미지 생성을 위한 대화형 프롬프트 엔지니어링. IEEE 시각화 및 컴퓨터 그래픽스 저널, 2023.[16] G. Goh. 모멘텀이 실제로 작동하는 이유. Distill, 2(4):e6, 2017.[17] J. Hendrix. 생성 AI, 섹션 230 및 책임: 질문 평가. Tech Policy Press, 2023. 2023-04-30에 액세스.[18] Y. Hosni. 안정적 확산 시작하기. https://medium.com/towards-artificial-intelligence/getting-started-withstable-diffusion-f343639e4931, 2022. 2023-04-30에 액세스.[19] J. Howard. 딥 러닝 기초에서 안정적 확산까지. https://www.fast.ai/posts/part2-2023.html, 2023. 202304-30에 액세스.[20] M. Kahng, PY Andrews, A. Kalro 및 DH Chau. Activis: 산업 규모 딥 신경망 모델의 시각적 탐색. IEEE TVCG, 24(1):88-97, 2017.[21] M. Kahng, N. Thorat, DH Chau, F. Viégas 및 M. Wattenberg. GAN Lab: 대화형 시각적 실험을 사용하여 복잡한 딥 생성 모델 이해. IEEE 시각화 및 컴퓨터 그래픽스 저널, 25(1), 2019.[22] JB Kai Ninomiya, Brandon Jones. https://www.w3.org/TR/webgpu/, 2024.Webgpu. [23] A. Karpathy. ConvNetJS: 브라우저에서 딥 러닝. https://cs. stanford.edu/people/karpathy/convnetjs/index.html, 2014. 액세스일: 2023-11-26.[24] DP Kingma 및 M. Welling. 자동 인코딩 변분 베이즈. arXiv 사전 인쇄본 arXiv:1312.6114, 2013.[25] V. Liu 및 LB Chilton. 프롬프트 엔지니어링 텍스트-이미지 생성 모델을 위한 설계 지침. CHI, pp. 1-23, 2022.[26] 기계 학습 컴파일. 웹 안정 확산. https://mlc.ai/ web-stable-diffusion, 2024. 액세스일: 2024-04-28.[27] A. Madsen. rnns에서 기억 시각화. Distill, 2019. https://distill.pub/2019/memorization-in-rnns. doi: 10.23915/distill. 00016[28] L. McInnes, J. Healy, and J. Melville. Umap: Uniform Manifold Approximation and Projection for Dimension Reduction. arXiv 사전 인쇄본 arXiv:1802.03426, 2018. 3,[29] AP Norton and Y. Qi. Adversarial-Playground: A Visualization Suite Showing How Adversarial Examples Fool Deep Learning. In Visualization for Cyber Security (VizSec), 2017 IEEE Symposium on, pp. 1-4. IEEE, 2017.[30] C. Olah. colahś blog. http://colah.github.io, 2023. 액세스일: 202304-30.[31] OpenAI. DALL-E 2. https://openai.com/product/dall-e-2, 2022. 액세스일: 2022-09-28.[32] J. Oppenlaender. 텍스트-이미지 생성을 위한 프롬프트 수정자 분류. arXiv 사전 인쇄본 arXiv:2204.13988, 2022.[33] S. Patil, P. Cuenca, N. Lambert, and P. v. Platen. 확산기를 사용한 안정적 확산. https://huggingface.co/blog/stable_diffusion, 2022. 액세스일: 2023-04-30.[34] N. Pavlichenko and D. Ustalov. 텍스트-이미지 모델을 위한 최상의 프롬프트 및 찾는 방법.arXiv 사전 인쇄본 arXiv:2209.11711, 2022.[35] A. Radford, JW Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, et al. 자연어 감독에서 전이 가능한 시각적 모델 학습. 기계 학습에 관한 국제 컨퍼런스에서, pp. 8748–8763. PMLR, 2021. 1,[36] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer. 잠재 확산 모델을 사용한 고해상도 이미지 합성. CVPR, pp. 10684-10695, 2022. 1,[37] O. Ronneberger, P. Fischer, 및 T. Brox. U-net: 생물의학 영상 분할을 위한 합성 네트워크. Medical Image Computing and Computer-Assisted Intervention-MICCAI 2015: 제18회 국제 컨퍼런스, 독일 뮌헨, 2015년 10월 5-9일, 회의록, Part III 18, pp. 234-241. Springer, 2015.[38] T. Ryan-Mosley. 생성 AI에 대한 정책 수립을 위한 초기 가이드. MIT Technology Review, 2023. 액세스일: 2023-04-30. 1,[39] B. Sanchez-Lengeling, E. Reif, A. Pearce, 및 AB Wiltschko. 그래프 신경망에 대한 간단한 소개.Distill, 6(9):e33, 2021.[40] HJ Seltman.실험 설계 및 분석, 2012.[41] D. Smilkov, S. Carter, D. Sculley, FB Viégas, M. Wattenberg.딥 네트워크의 직접 조작 시각화.arXiv 사전 인쇄본 arXiv:1708.03788, 2017.[42] E. Smith.잠재 공간 여행 가이드, 2022.접속일: 2023-04-29.[43]안정성 AI.안정 확산 공개 릴리스.https://stability.ai/blog/stable-diffusion-public-release, 2022.접속일: 2022-08-22.[44] M. Sung.AI 초상화 앱인 Lensa의 인기가 급상승했습니다. 하지만 많은 예술가들이 AI 아트의 윤리에 의문을 제기합니다. NBC News, 2022. 2023-04-30에 액세스했습니다.[45] K. Turner. 업스케일링 없이 잠재 이미지를 RGB로 디코딩합니다. https://discuss.huggingface.co/t/decoding-latents-to-rgb-withoutupscaling/23204/2, 2022. 2023-04-30에 액세스했습니다.[46] C. van den Bogaard. 안정 확산에 대한 소개. https://medium.com/sogetiblogsnl/an-introduction-to-stablediffusion-efd5da6b3aeb, 2022. 2023-04-30에 액세스했습니다.[47] P. von Platen. 안정 확산 테스트는 어렵습니다. https://github.com/ huggingface/diffusers/issues/937, 2022. 액세스일: 2023-04-30. 1,[48] ZJ Wang, R. Turko, O. Shaikh, H. Park, N. Das, F. Hohman, M. Kahng, and DH Chau. CNN 설명: 대화형 시각화를 통한 합성 신경망 학습. IEEE 시각 분석 과학 및 기술 컨퍼런스(VAST), 2020.[49] L. Weng. 확산 모델이란 무엇인가? lilianweng.github.io, 2021년 7월.[50] J. Whitaker. 안정적 확산을 탐구하다. https://colab.research.google. com/drive/1dlgggNa5Mz8sEAGU0wFCHhGLFooW_pf1?usp= sharing, 2022. 액세스일: 2023-04-30.
