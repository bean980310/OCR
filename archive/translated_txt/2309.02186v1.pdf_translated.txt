--- ABSTRACT ---
인간 생성을 위한 이전의 애니메이션 가능한 3D 인식 GANS는 주로 인간의 머리나 전신에 초점을 맞추었습니다. 그러나 머리만 있는 비디오는 실제 생활에서 비교적 흔하지 않으며 전신 생성은 일반적으로 얼굴 표정 제어를 다루지 않으며 여전히 고품질 결과를 생성하는 데 어려움이 있습니다. 적용 가능한 비디오 아바타에 대해 얼굴 표정, 머리 포즈 및 어깨 움직임을 제어할 수 있는 초상화 이미지를 생성하는 애니메이션 가능한 3D 인식 GAN을 제시합니다. 3D 또는 비디오 데이터를 사용하지 않고 구조화되지 않은 2D 이미지 컬렉션에서 학습된 생성 모델입니다. 새로운 과제의 경우 생성적 광도 매니폴드 표현을 기반으로 방법을 설정하고 학습 가능한 얼굴 및 머리 어깨 변형을 제공합니다. 생성된 얼굴의 품질을 개선하기 위해 듀얼 카메라 렌더링 및 적대적 학습 체계를 제안하는데, 이는 초상화 이미지에 중요합니다. 포즈 변형 처리 네트워크가 개발되었습니다. *동등한 기여. YW가 MSRA에서 인턴으로 일할 때 수행한 작업. *연락 저자 및 프로젝트 책임자. 긴 머리카락과 같은 까다로운 영역에 대한 그럴듯한 변형을 생성합니다. 실험 결과, 구조화되지 않은 2D 이미지로 훈련된 저희 방법은 다양한 속성을 원하는 대로 제어하면서 다양하고 고품질의 3D 초상화를 생성할 수 있습니다. 1.
--- INTRODUCTION ---
애니메이션이 가능한 3D 인간 캐릭터의 자동 생성은 화상 회의, 영화 제작, 게임을 포함한 다양한 응용 분야에서 점점 더 중요한 주제가 되고 있습니다. 관련 기술은 최근 상당한 성장을 이루었으며 다양한 유망한 방법이 제안되었습니다[1, 7, 8, 16, 21, 38, 40, 42, 51, 52, 54, 60, 62]. 이러한 기술 중에서 3D 인식 생성 방법이 특히 유망한 수단으로 떠올랐습니다[1, 12, 21, 38, 51, 52, 60, 62]. 이러한 방법은 대규모로 획득하기 어려운 3D 스캔이나 다중 뷰 인간 이미지가 필요 없이 3D 인간 생성 학습을 위한 비정형 2D 데이터의 풍부한 가용성을 활용할 수 있습니다. 일반적으로 이러한 방법은 비지도 학습을 위해 생성적 적대 신경망(GANS) [18]을 사용하고, 3D 표현으로 신경 암묵적 필드 [34]를 사용하고, 캐릭터 제어를 위해 3D 얼굴 및 신체 매개변수 모델 [4, 29, 32]의 사전 확률을 통합합니다. 유망한 잠재력에도 불구하고 기존의 애니메이션 가능한 3D 인식 인간 생성은 인간의 머리 또는 전신에 초점을 맞추고 있으며 적용성에 한계가 있습니다. 머리 생성 방법 [51, 52, 60, 62]은 제어 가능한 얼굴 표정으로 고품질의 얼굴과 머리카락을 생성할 수 있습니다. 안타깝게도 인간의 머리만 등장하는 비디오는 일상 생활에서 비교적 흔하지 않으므로 이러한 방법은 실제 시나리오에서 적용하기가 어렵습니다. 반면 전신 생성 [1, 12, 21, 38, 65]은 명시적 포즈 제어로 몸통과 팔다리도 생성합니다. 그러나 신체 동작의 복잡성으로 인해 고품질의 전신 인간을 생성하는 것은 여전히 어렵습니다. 또한 얼굴 영역은 이러한 전신 방법에서 종종 과소 표현되고 표정 제어가 없습니다. 저희 논문은 인간의 머리와 어깨 영역의 애니메이션 생성에 초점을 맞춘 최초의 새로운 3D 인식 생성 방법을 제시합니다. 저희 방법은 얼굴 표정과 머리와 어깨 움직임에 대한 세밀한 제어를 가능하게 하여 화상 회의 및 가상 발표자와 같은 실제 응용 프로그램에 적합합니다. 이전의 3D 인식 GANS와 마찬가지로 저희 방법은 비정형 2D 이미지 세트에서 학습됩니다. 이 새로운 작업의 경우 이전 방법을 따라 GAN 학습 체계에서 3D 매개변수 모델 사전 확률을 사용하여 신경 광도 생성을 학습합니다. 저희 방법은 GRAM [9, 61]의 3D 인식 GAN 프레임워크를 기반으로 하고 3D 변형 가능 모델(3DMM) 사전 확률을 사용하여 얼굴 표정 제어를 위해 AniFaceGAN [60]을 따릅니다. 머리와 어깨 제어의 경우 변형 안내를 위해 SMPL [32] 신체 모델을 통합합니다. 그러나 우리는 이러한 기존 기술을 애니메이션 헤드숄더 초상화 생성 작업에 순진하게 확장하는 것이 부족하다는 것을 발견했습니다. 두드러진 문제 중 하나는 얼굴 품질에 대한 것인데, 이는 시각적 커뮤니케이션에 매우 중요합니다. 머리 위치와 방향의 큰 변화로 인해 발생하는 복잡한 이미지 분포를 처리하기 위해, 우리는 훈련을 위한 듀얼 카메라 렌더링 및 적대적 학습 방식을 제안합니다. 추가적인 동적 카메라가 머리 중심을 가리키는 인간의 머리 주위에 배치되어 구별을 위한 얼굴을 렌더링하여 얼굴 생성 품질을 크게 향상시킵니다. 또 다른 문제는 SMPL로 안내되는 인체 변형으로, 선형 블렌딩 스키닝을 기반으로 하는 일반적으로 사용되는 전략이 긴 머리를 가진 인간 캐릭터에 대해 설득력 있는 결과를 생성하지 못한다는 것을 확인했습니다. 머리 회전 시 머리카락 영역에서 날카로운 불연속성이 발생하여 상당한 아티팩트가 발생합니다. 이 문제를 해결하기 위해, 우리는 더 나은 변형을 학습하기 위한 포즈 변형 볼륨 처리 모듈을 제안하여 GAN 훈련을 안정화하고 시각적으로 그럴듯한 결과를 생성합니다. 우리는 SHHQ-HS라는 머리-어깨 초상화 데이터세트에서 모델을 훈련합니다.이것은 SHHQ 데이터세트[15]에 있는 40,000개의 인체 이미지를 잘라내고 초고해상화하여 구성됩니다.우리는 우리의 방법이 얼굴 표정과 머리-어깨 포즈를 포함한 다양한 속성을 유연하게 제어하여 다양하고 고품질의 3D 초상화 이미지를 생성할 수 있음을 보여줍니다.우리의 기여는 다음과 같이 요약될 수 있습니다.• 얼굴 표정과 머리-어깨 동작 제어를 사용하여 머리와 어깨 영역을 생성하는 최초의 애니메이션 가능한 3D 인식 초상화 GAN을 제안합니다.우리는 이러한 애니메이션 가능한 인간 캐릭터를 생성하는 것이 화상 회의 및 가상 발표자와 같은 실제 세계 애플리케이션을 위한 3D 인식 인간 GAN의 빠진 부분이라고 믿습니다.• 이전의 머리 전용 3D 인식 GAN과 비교할 수 있는 고품질 얼굴 생성을 가능하게 하는 듀얼 카메라 렌더링 및 적대적 학습 방식을 제안합니다.• 인간 머리카락에 대한 부드럽고 그럴듯한 포즈 기반 변형을 달성하는 포즈 변형 처리 모듈을 제안합니다.2.
--- RELATED WORK ---
3D 인식 이미지 생성 3D 인식 이미지 생성 모델은 2D 이미지에 대해서만 학습하여 3D 카메라 시점을 명시적으로 제어할 수 있는 이미지를 생성하는 것을 목표로 합니다. 대부분의 기존 작업은 생성 모델링을 위한 GAN 프레임워크를 기반으로 합니다. 이 문제에 대한 초기 접근 방식은 3D 합성곱을 사용하여 3D 피처 볼륨을 생성하고 이를 2D 평면에 투영하여 이미지를 생성합니다[35, 36]. 최근에는
--- METHOD ---
영어: 는 명시적으로 제어 가능한 3D 카메라 시점, 얼굴 표정, 머리 자세 및 어깨 움직임으로 다양한 가상 인간 초상화(512×512)를 생성할 수 있는 새로운 3D 인식 GAN입니다. 3D 또는 비디오 데이터 없이 비정형 2D 이미지에서 학습되었습니다. (확대하여 보는 것이 가장 좋습니다. 더 많은 샘플의 비디오는 프로젝트 페이지 참조) 초록 인간 생성을 위한 이전의 애니메이션 가능한 3D 인식 GANS는 주로 인간의 머리 또는 전신에 초점을 맞추었습니다. 그러나 머리만 있는 비디오는 실제로는 비교적 드물고 전신 생성은 일반적으로 얼굴 표정 제어를 다루지 않으며 여전히 고품질 결과를 생성하는 데 어려움이 있습니다. 적용 가능한 비디오 아바타에 대해 제어 가능한 얼굴 표정, 머리 자세 및 어깨 움직임으로 초상화 이미지를 생성하는 애니메이션 가능한 3D 인식 GAN을 제시합니다. 3D 또는 비디오 데이터를 사용하지 않고 비정형 2D 이미지 컬렉션에서 학습된 생성 모델입니다. 새로운 과제를 위해 우리는 생성적 광도 매니폴드 표현을 기반으로 방법을 구축하고 학습 가능한 얼굴 및 머리 어깨 변형을 제공합니다. 생성된 얼굴의 품질을 개선하기 위해 듀얼 카메라 렌더링 및 적대적 학습 체계를 제안하는데, 이는 초상화 이미지에 중요합니다. 포즈 변형 처리 네트워크가 개발되었습니다. *동등한 기여. YW가 MSRA에서 인턴으로 일할 때 수행한 작업. *연락 저자 및 프로젝트 책임자. 긴 머리와 같은 어려운 영역에 대한 그럴듯한 변형을 생성합니다.
--- EXPERIMENT ---
s는 구조화되지 않은 2D 이미지로 학습된 우리 방법이 다양한 속성을 원하는 대로 제어하여 다양하고 고품질의 3D 초상화를 생성할 수 있음을 보여줍니다. 1. 서론 애니메이션이 가능한 3D 인간 캐릭터의 자동 생성은 화상 회의, 영화 제작, 게임을 포함한 다양한 응용 분야에서 점점 더 중요한 주제가 되고 있습니다. 관련 기술은 최근 상당한 성장을 이루었으며 다양한 유망한 방법이 제안되었습니다[1, 7, 8, 16, 21, 38, 40, 42, 51, 52, 54, 60, 62]. 이러한 기술 중에서 3D 인식 생성 방법이 특히 유망한 수단으로 떠올랐습니다[1, 12, 21, 38, 51, 52, 60, 62]. 이러한 방법은 대규모로 획득하기 어려운 3D 스캔이나 멀티뷰 인간 이미지가 필요 없이 3D 인간 생성 학습을 위한 비정형 2D 데이터의 풍부한 가용성을 활용할 수 있습니다. 일반적으로 이러한 방법은 비지도 학습을 위해 생성적 적대 신경망(GANS)[18]을 사용하고, 3D 표현으로 신경 암묵적 필드[34]를 사용하고, 캐릭터 제어를 위해 3D 얼굴 및 신체 매개변수 모델[4, 29, 32]의 사전 확률을 통합합니다. 유망한 잠재력에도 불구하고 기존의 애니메이션 가능한 3D 인식 인간 생성은 인간의 머리 또는 전신에 초점을 맞추고 있으며 적용성에 한계가 있습니다. 머리 생성 방법[51, 52, 60, 62]은 조절 가능한 얼굴 표정으로 고품질 얼굴과 머리카락을 생성할 수 있습니다. 안타깝게도 일상 생활에서 인간의 머리만 등장하는 비디오는 비교적 흔하지 않기 때문에 이러한 방법은 실제 시나리오에서 적용성이 떨어집니다. 반면, 전신 생성[1, 12, 21, 38, 65]은 명시적 포즈 제어로 몸통과 팔다리도 생성합니다. 그러나 신체 동작의 복잡성으로 인해 고품질의 전신 인간을 생성하는 것은 여전히 어렵습니다. 또한 이러한 전신 방법에서는 얼굴 영역이 종종 과소 표현되고 표정 제어가 없습니다. 본 논문에서는 인간의 머리와 어깨 영역을 애니메이션으로 생성하는 데 초점을 맞춘 최초의 새로운 3D 인식 생성 방법을 제시합니다. 본 방법은 얼굴 표정과 머리와 어깨 움직임을 세밀하게 제어할 수 있어 화상 회의 및 가상 발표자와 같은 실제 응용 프로그램에 적합합니다. 이전의 3D 인식 GANS와 마찬가지로 본 방법은 비정형 2D 이미지 세트에서 학습됩니다. 이 새로운 과제를 위해 이전 방법을 따라 GAN 학습 체계에서 3D 매개변수 모델 사전 확률을 사용하여 신경 광휘 생성을 학습합니다. 우리는 GRAM [9, 61]의 3D 인식 GAN 프레임워크를 기반으로 방법을 설계하고 3D 변형 가능 모델(3DMM) 사전 확률을 사용하여 얼굴 표정을 제어하기 위해 AniFaceGAN [60]을 따릅니다. 머리와 어깨 제어를 위해 변형 안내를 위한 SMPL [32] 신체 모델을 통합합니다. 그러나 기존 기술을 애니메이션 가능한 머리 어깨 초상화 생성 작업으로 순진하게 확장하는 것은 부족하다는 것을 발견했습니다. 눈에 띄는 문제 중 하나는 시각적 커뮤니케이션에 가장 중요한 얼굴 품질에 대한 것입니다. 머리 위치와 방향의 큰 변화로 인해 발생하는 복잡한 이미지 분포를 처리하기 위해 훈련을 위한 듀얼 카메라 렌더링 및 적대적 학습 방식을 제안합니다. 추가적인 동적 카메라를 머리 중앙을 향하게 하여 구별을 위한 얼굴을 렌더링하여 얼굴 생성 품질을 크게 향상시킵니다. 또 다른 문제는 SMPL 안내 인체 변형으로, 선형 블렌딩 스키닝을 기반으로 하는 일반적으로 사용되는 전략이 긴 머리를 가진 인간 캐릭터에 대해 설득력 있는 결과를 생성하지 못한다는 것을 확인했습니다. 영어: 머리카락 영역의 머리 회전 시 날카로운 불연속성이 발생하여 상당한 아티팩트가 발생합니다. 이 문제를 해결하기 위해 포즈 변형 볼륨 처리 모듈을 제안하여 더 나은 변형을 학습하고, 이를 통해 GAN 학습이 안정화되고 시각적으로 그럴듯한 결과가 생성됩니다. SHHQ 데이터 세트[15]에 있는 40,000개의 인체 이미지를 잘라내고 초해상화하여 구성된 SHHQ-HS라는 머리-어깨 초상화 데이터 세트에서 모델을 학습합니다. 얼굴 표정과 머리-어깨 포즈를 포함한 다양한 속성을 유연하게 제어하여 다양하고 고품질의 3D 초상화 이미지를 생성할 수 있는 방법을 보여줍니다. 기여 사항은 다음과 같습니다. • 얼굴 표정과 머리-어깨 동작 제어를 사용하여 머리와 어깨 영역을 생성하는 최초의 애니메이션 가능한 3D 인식 초상화 GAN을 제안합니다. 이러한 애니메이션 가능한 인간 캐릭터를 생성하는 것이 화상 회의 및 가상 발표자와 같은 실제 세계 응용 프로그램을 위한 3D 인식 인간 GAN의 빠진 부분이라고 생각합니다. • 우리는 이전의 헤드 전용 3D 인식 GAN과 비교할 수 있는 고품질 얼굴 생성을 가능하게 하는 듀얼 카메라 렌더링 및 적대적 학습 방식을 제안합니다.• 우리는 인간 머리카락에 대한 부드럽고 그럴듯한 포즈 기반 변형을 달성하는 포즈 변형 처리 모듈을 제안합니다.2. 관련 연구 3D 인식 이미지 생성 3D 인식 이미지 생성 모델은 2D 이미지에 대해서만 학습하여 3D 카메라 관점을 명시적으로 제어할 수 있는 이미지를 생성하는 것을 목표로 합니다.대부분의 기존 연구는 생성 모델링을 위한 GAN 프레임워크를 기반으로 합니다.이 문제에 대한 초기 접근 방식은 3D 합성곱을 사용하여 3D 특징 볼륨을 생성하고 이를 2D 평면에 투영하여 이미지를 생성합니다[35, 36]. 최근, 보다 명확한 3D 표현과 미분 가능한 렌더링을 기반으로 하는 방법이 인기를 얻고 있습니다[5, 6, 9, 11, 19, 30, 37, 39, 44, 47, 49, 50, 53, 61, 66]. 널리 사용되는 3D 표현은 NeRF[34]와 그 변형으로, 실제 3D 장면을 모델링하는 강력한 기능을 갖추고 있습니다. 이러한 NeRF 기반 GAN 중 일부는 볼륨 렌더링을 사용하여 최종 이미지를 직접 생성하는데, 이는 다양한 뷰 간에 강력한 3D 일관성을 보장하지만 종종 높은 계산 비용이 듭니다. 다른 일부는 업샘플링을 위해 렌더링된 저해상도 2D 이미지나 피처 맵에 2D 합성곱을 적용하는데, 이는 계산 비용을 크게 줄이면서도 생성된 인스턴스의 다중 뷰 일관성을 희생합니다. 저희의 방법은 [61]의 고해상도 광도 매니폴드 표현을 사용하는데, 이는 강력한 다중 뷰 일관성을 갖춘 고해상도 이미지를 생성할 수 있습니다. 제어 가능한 인간 머리 및 몸 생성 최근 몇 년 동안 얼굴 및 몸 생성 모델링에 명시적 제어를 추가하는 것이 많은 주목을 받았습니다. 기존 연구는 주로 머리[1, 8, 51, 52, 60, 62] 또는 전신[1, 7, 12, 21, 38]에 초점을 맞추었으며, 3D 매개변수 모델의 사전 정보를 일반적으로 통합하여 의미적으로 의미 있는 제어를 달성했습니다. 표정 제어의 경우, 대부분의 머리 GANS[1, 8, 51, 52, 60]는 종종 훈련 프로세스에 3D 변형 가능 모델(3DMM)[4] 또는 FLAME 모델[29]을 통합합니다. 전신 GAN은 일반적으로 신체 포즈 애니메이션을 위해 SMPL 모델[32]에 의존하며(신체 골격을 사용하는 [38]과 같은 몇 가지 예외가 있음) 얼굴 표정 제어를 다루지 않는 경우가 많습니다. 이 작업은 새로운 인간 생성 작업을 다룹니다. 제어 가능한 얼굴 표정과 머리-어깨 포즈가 있는 머리와 어깨를 포함하는 초상화 인물을 생성합니다. 인간 이미지 및 비디오 조작 저희의 방법은 인간 애니메이션 비디오를 생성하는 인간 이미지 및 비디오 조작 접근 방식[13, 16, 17, 23, 27, 31, 42, 43, 48, 55, 58, 59, 63, 64]과도 관련이 있습니다. 그러나 이러한 방법의 목표와 기본 기술은 저희의 방법과 상당히 다릅니다. 이러한 방법은 주어진 이미지나 비디오에서 인간 캐릭터를 애니메이션화하는 것을 목표로 하며, 일반적으로 비디오나 이미지 쌍을 사용하여 지도 학습 방식으로 학습합니다. 이와 대조적으로 저희는 인간 생성 모델링과 새로운 캐릭터 생성을 다루며, 비지도 학습 또는 약한 지도 학습 방식으로 비정형 정지 이미지에서 학습합니다. 3. 방법 저희의 목표는 주어진 2D 이미지 컬렉션에서 학습하여 인간의 머리와 어깨 영역이 포함된 인간 초상화 이미지를 생성하는 것입니다. 표준 GAN 설정에서와 같이 무작위 잠재 코드를 샘플링하여 최종 출력 이미지에 매핑합니다. 생성기의 입력은 생성된 인간의 다양한 속성과 카메라 관점에 해당하는 여러 잠재 코드로 구성됩니다. 출력은 원하는 속성을 갖는 인간 초상 이미지입니다. 그림 2는 방법 개요를 보여줍니다. 전체 파이프라인은 (역) 변형과 결합된 표준 신경 광도 표현의 인기 있는 패러다임을 따릅니다[1, 21, 60]. 3.1. 잠재 코드 잠재 코드에는 인간 모양을 위한 식별 코드 Zid ERdi, 얼굴 표정을 위한 표현 코드 Zexp ERde, 머리와 어깨 포즈를 위한 Zpose ERdp, 외모와 같은 다른 속성을 제어하는 추가 노이즈 ε = R de가 포함됩니다. 의미적으로 의미 있는 제어를 달성하기 위해 사전 3D 인간 매개변수 모델을 통합하고 잠재 공간을 해당 모델과 맞춥니다. 구체적으로 식별 코드 zid는 3DMM[41] 얼굴 식별 계수와 SMPL[32] 신체 모양 계수를 연결하여 설계되었습니다. 포즈 코드 Zpose는 머리, 목, 좌우 칼라, 좌우 어깨의 6개 관절의 관절 변환으로 구성된 축소된 SMPL 포즈 매개변수입니다.표현 코드 Zexp는 3DMM 표현 계수와 동일합니다.3.2. 표준 광도 매니폴드 본 방법은 표준 인간을 표현하기 위해 광도 매니폴드[9, 61]를 활용합니다.이 표현은 3D 볼륨에서 학습된 암묵적 표면 집합에 대한 광도장 학습 및 렌더링을 조절합니다.엄격한 다중 뷰 일관성으로 고품질 인간 얼굴을 생성할 수 있습니다.매니폴드 초고해상도[61]를 사용하면 다중 뷰 일관성을 희생하지 않고도 고해상도 이미지를 효율적으로 생성할 수 있습니다.구체적으로 광도 생성을 위해 세 가지 네트워크를 적용합니다.매니폴드 예측 MLP M은 표준 공간의 점 x를 입력으로 받고 스칼라 s: M:xЄR³ SER을 예측합니다.(1) 표면을 정의하는 스칼라장을 모델링합니다. 영어: 광도 생성 MLP &amp;는 식별 코드 Zid, 노이즈 &amp; 및 뷰 방향 d가 주어진 표면의 점에 대한 색상과 불투명도를 생성합니다.Ó : (x, Zid, ɛ, d) Є Rdi+de+6 → (c, a) € R4. (2) 매니폴드 초고해상도 CNNU는 평탄화되고 이산화된 광도 맵 Rɩr을 고해상도 맵 Rhr로 업샘플링합니다.(3) U (Zid, E, Rir) → Rhr, 이 논문에서는 128² → 512² 업샘플링 설정을 사용합니다. 자세한 기술적 내용은 [9, 61]을 참조하세요.3.3 변형 필드 원하는 머리-어깨 포즈와 얼굴 표정을 가진 대상 공간에서 샘플링된 각 3D 점에 대해 변형을 적용하여 광도 검색을 위한 표준 공간으로 변환합니다. 2단계 변형 체계를 사용하여 포즈와 표정을 중화합니다. 3.3.포즈 변형 생성기 SMPL 모델[32]을 통합하고 선형 블렌드 스키닝(LBS) 체계[28]를 사용하여 변형을 안내합니다.모양 코드 Zid와 포즈 코드 Zpose가 주어지면 SMPL을 사용하여 포즈를 취한 인체 메시를 구성할 수 있습니다.SMPL 모델은 신체 표면의 각 정점에 대해 미리 정의된 스키닝 가중치 벡터 w Є RN을 제공합니다.여기서 NJ는 관절 번호입니다.신체 표면 변형을 전체 3D 공간으로 전파하는 간단한 방법은 모든 지점에 가장 가까운 신체 표면 정점의 스키닝 가중치를 할당하고 이를 사용하는 것입니다.Zid Zpose A. Zexp Λε 인물 카메라 ☐ 얼굴 카메라 Zid, Zexp Zid, ε Zid, Zpose 포즈 변형 지수 변형 광채 생성 볼륨 렌더링 Dface {x} 대상 공간 {x} {x} 중립 포즈 공간 중립 Pose&amp;Exp. 공간(정식 공간) Iface 얼굴 이미지 Iportrait 초상화 이미지 포즈 변형 표현 변형 광도 생성 수집 T DP XP Zid, Zexp XP Zid, ε— S De 모든 샘플, 모든 광선 xc - M x* $ c, a Get(역) LBS H×W×D×HxWxDxGet교차 변환.TE R4×3D 변환 네트 SMPL 메시 S(Zid, Zpose) 매니폴드 생성기 광도 생성기 그림 2: 방법 개요.위: 제어 가능한 3D 인식 초상화 GAN의 파이프라인.훈련을 위해 두 개의 이미지를 분리하여 렌더링하고 세 개의 판별기를 사용하는 듀얼 카메라 렌더링 방식을 적용합니다.아래: 변형 및 광도 생성 모듈의 구조(단순화를 위해 광도 매니폴드 초고해상도 단계는 생략함.자세한 내용은 텍스트 참조).변형합니다. 사실, 이 전략은 최첨단 애니메이션 인체 모델링 및 생성 방법[2, 12, 17, 22, 42, 65]에서 널리 사용됩니다. 기존의 전신 합성 방법에 대해서는 그럴듯한 결과를 제공하지만, 고해상도 초상화 합성에서는 상당한 시각적 결함이 발생한다는 것을 발견했습니다. 긴 머리카락을 가진 인간 캐릭터의 경우, 이 기본 전략은 어깨 위의 머리카락 영역에 급격한 변형 불연속성을 초래합니다(그림 6 참조). 이 문제를 해결하기 위해 변형 볼륨 처리 모듈을 제안합니다. 구체적으로, 가장 가까운 SMPL 바디 정점에서 검색된 스키닝 가중치 벡터 w가 있는 대상 공간의 점 x에 대해, 변형된 점은 역 LBS를 사용하여 계산할 수 있습니다. j=x² = LBS−¹(x², w) = T·x² = (Σ¾¾¾₁ w;T;)·x², (4) 여기서 TR4×4는 SMPL 조인트 변환 T; € SE(3)을 선형적으로 혼합하여 계산한 변환 행렬입니다. 우리는 모든 H x W 광선의 샘플링된 포인트에 대한 재구성된 변환 행렬을 텐서 TERH×W×D×16으로 수집합니다.여기서 D는 광선당 샘플링된 포인트 수이고, 이를 처리하기 위해 3D CNN DP를 적용합니다: TERH×W×D×H×W×D×DP: TERHX\ (5) 처리 후, 우리는 변환을 다시 재구성하고 샘플링된 포인트에 적용하여 포즈 변형을 달성합니다.3.3.2 표정 변형 생성기 우리는 또한 변형을 적용하여 대상 표정에서 얼굴 표정을 중화합니다.[60]에 따라 3DMM 모델[41]에 의해 안내되는 변형 필드를 도입합니다.특히, MLP De를 사용하여 포즈 정렬 공간의 포인트를 변형합니다: De(XP, Zid, Zexp) → xc. (6) 이 변형 네트워크는 3DMM에 따른 표현식을 갖는 얼굴을 생성하도록 훈련됩니다.(7) S = S(Zid, Zexp) = S + Bidzid + BexpZexp, 여기서 S는 3DMM 평균 얼굴이며, Bid와 Bexp는 각각 항등성과 표현식에 대한 PCA 기반입니다. 훈련 세부 정보는 이후 섹션에서 찾을 수 있습니다. 전체적으로 생성기 G에는 M, ò̟, U, DP, De의 5개 하위 네트워크가 있습니다. 최종 이미지 렌더링을 위해 변형된 광선 r(점 샘플)과 표준 매니폴드 사이의 M개 교차점 {x}를 계산합니다. 그런 다음 광도 맵 Rhr을 샘플링하여 {x}의 색상과 점유율을 얻고, 다음을 통해 색상을 합성합니다. MC(r) = ΣT(x²)a(x²)c(x;), T(x*) = [[(1 − a(x)). i=3.4. 듀얼 카메라 판별기 k
--- CONCLUSION ---
우리는 애니메이션이 가능한 머리-어깨 초상화 생성을 위한 새로운 3D 인식 GAN을 제시했습니다.이전 방법에서는 다루지 않았던 새로운 과제입니다.우리는 몇 가지 핵심적인 것을 식별했습니다.그림 8: 극단적인 표정과 감은 눈에 대한 한계.각 이미지 쌍에서 왼쪽은 참조 이미지이고 오른쪽은 애니메이션 결과입니다.이 새로운 과제에 기존 기술을 확장하고 이를 해결하기 위한 타겟 알고리즘을 제안할 때 사용합니다.우리는 구조화되지 않은 2D 이미지 코퍼스를 학습함으로써 우리 방법이 제어 가능한 얼굴 표정과 머리 및 어깨 움직임이 있는 다양하고 고품질의 3D 초상화를 생성할 수 있음을 보여줍니다.우리는 우리 작업이 실제 응용 프로그램을 위한 비디오 아바타를 자동으로 생성하는 데 있어 한 걸음 더 나아간 것이라고 믿습니다.제한 사항 우리 방법에는 여전히 몇 가지 제한이 있습니다.그림 8에서 볼 수 있듯이 학습 데이터 분포에 없는 인간의 포즈와 표정에서 아티팩트를 생성할 수 있습니다.사실, SHHQHS의 얼굴 표정 변화는 다소 제한적이며 극단적인 표정과 감은 눈의 이미지가 부족합니다. 영어: 내부 입 영역(예: 치아)의 시각적 품질이 만족스럽지 않은데, 이는 부분적으로 데이터 샘플이 제한적이기 때문이기도 합니다. 또한, 현재 방법은 시선 및 환경 조명과 같은 다른 속성을 제어할 수 있는 기능이 없습니다. 향후 연구에서 이러한 문제를 더 탐구하고 해결할 계획입니다. 윤리 및 책임 있는 AI 고려 사항 이 연구는 가상 아바타를 적용하기 위한 애니메이션 가능한 3D 인식 인간 초상화 생성 방법을 설계하는 것을 목표로 합니다. 오도하거나 속이는 데 사용되는 콘텐츠를 만드는 것이 아닙니다. 그러나 여전히 잠재적으로 오용될 수 있습니다. 우리는 오도하거나 해로운 콘텐츠를 만드는 모든 행위를 비난하며 이 기술을 고급 위조 감지에 적용하는 데 관심이 있습니다. 현재 이 방법으로 생성된 이미지에는 쉽게 식별할 수 있는 시각적 아티팩트가 포함되어 있습니다. 이 방법의 성능은 훈련 데이터의 편향에 영향을 받습니다. 데이터 수집 프로세스에 주의해야 하며 인종, 성별, 연령 등의 편향 없는 분포를 보장해야 합니다. 참고문헌 [1] Alexander Bergman, Petr Kellnhofer, Wang Yifan, Eric Chan, David Lindell, Gordon Wetzstein. 생성적 신경 관절 광도장. 신경 정보 처리 시스템의 발전, 2022년. 1, 2,[2] Bharat Lal Bhatnagar, Cristian Sminchisescu, Christian Theobalt, Gerard Pons-Moll. Loopreg: 3D 인간 메시 등록을 위한 암묵적 표면 대응, 포즈 및 모양의 자기 감독 학습. 신경 정보 처리 시스템의 발전, 12909-12922페이지, 2020년.[3] Mikołaj Bińkowski, Danica J Sutherland, Michael Arbel, Arthur Gretton. mmd gans의 신비 해제. 학습 표현 국제 컨퍼런스, 2018년.[4] Volker Blanz, Thomas Vetter. 3D 얼굴 합성을 위한 변형 가능 모델. Annual Conference on Computer Graphics and Interactive Techniques, 187-194페이지, 1999. 2,[5] Eric R Chan, Connor Z Lin, Matthew A Chan, Koki Nagano, Boxiao Pan, Shalini De Mello, Orazio Gallo, Leonidas J Guibas, Jonathan Tremblay, Sameh Khamis, et al. 효율적인 기하학 인식 3D 생성적 적대 네트워크. IEEE/CVF Conference on Computer Vision and Pattern Recognition, 16123-16133페이지, 2022. 2,[6] Eric R Chan, Marco Monteiro, Petr Kellnhofer, Jiajun Wu, Gordon Wetzstein. pi-gan: 3D 인식 이미지 합성을 위한 주기적 암묵적 생성적 적대 네트워크. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스, 5799-5809페이지, 2021. 2,[7] Xu Chen, Tianjian Jiang, Jie Song, Jinlong Yang, Michael J Black, Andreas Geiger, Otmar Hilliges. gDNA: 생성적 세부 신경 아바타를 향해. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스, 2042720437페이지, 2022. 1,[8] Yu Deng, Jiaolong Yang, Dong Chen, Fang Wen, Xin Tong. 3D 모방-대조 학습을 통한 풀림 및 제어 가능한 얼굴 이미지 생성. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스, 5154-5163페이지, 2020. 1,[9] Yu Deng, Jiaolong Yang, Jianfeng Xiang 및 Xin Tong. GRAM: 3D 인식 이미지 생성을 위한 생성적 광도 매니폴드. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스, 10673-10683페이지, 2022. 2, 3,[10] Yu Deng, Jiaolong Yang, Sicheng Xu, Dong Chen, Yunde Jia 및 Xin Tong. 약한 감독 학습을 통한 정확한 3D 얼굴 재구성: 단일 이미지에서 이미지 세트로. IEEE/CVF 컴퓨터 비전 및 패턴 인식 워크숍 컨퍼런스, 2019. 5,6,[11] Terrance DeVries, Miguel Angel Bautista, Nitish Srivastava, Graham W Taylor, Joshua M Susskind. 로컬 조건부 광도 필드를 사용한 제약 없는 장면 생성. IEEE/CVF 컴퓨터 비전 국제 컨퍼런스, 2021.[12] Zijian Dong, Xu Chen, Jinlong Yang, Michael J Black, Otmar Hilliges, Andreas Geiger. AG3D: 2D 이미지 컬렉션에서 3D 아바타 생성 방법 학습. arXiv 사전 인쇄본 arXiv:2305.02312, 2023. 1, 2, 3,[13] Michail Christos Doukas, Stefanos Zafeiriou, Viktoriia Sharmanska. Headgan: 원샷 신경 헤드 합성 및 편집. IEEE/CVF 국제 컴퓨터 비전 컨퍼런스, 14398-14407페이지, 2021.[14] Anna Frühstück, Krishna Kumar Singh, Eli Shechtman, Niloy J Mitra, Peter Wonka, Jingwan Lu. 전신 이미지 생성을 위한 Insetgan. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스, 77237732페이지, 2022.[15] Jianglin Fu, Shikai Li, Yuming Jiang, Kwan-Yee Lin, Chen Qian, Chen Change Loy, Wayne Wu, Ziwei Liu. Stylegan-human: 인간 생성의 데이터 중심 오디세이. 유럽 컴퓨터 비전 컨퍼런스, 1-19페이지, 2022. 2,[16] Guy Gafni, Justus Thies, Michael Zollhofer, Matthias Nießner. 단안 4D 얼굴 아바타 재구성을 위한 동적 신경 광도장. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스, 8649-8658쪽, 2021. 1,[17] Xiangjun Gao, Jiaolong Yang, Jongyoo Kim, Sida Peng, Zicheng Liu, Xin Tong. MPS-NeRF: 다중 뷰 이미지에서 일반화 가능한 3D 인간 렌더링. IEEE 패턴 분석 및 머신 인텔리전스 저널, 2022. 3,[18] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio. 생성적 적대적 네트워크. Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, KQ Weinberger 편집자, 신경 정보 처리 시스템의 발전, 2014년.[19] Jiatao Gu, Lingjie Liu, Peng Wang, Christian Theobalt. Stylenerf: 고해상도 이미지 합성을 위한 스타일 기반 3D 인식 생성기. 국제 학습 표현 컨퍼런스, 2022년.[20] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Sepp Hochreiter. 2시간 척도 업데이트 규칙으로 학습된 Gans는 국소 내쉬 균형으로 수렴합니다. 신경 정보 처리 시스템의 발전, 6626-6637페이지, 2017년.[21] Fangzhou Hong, Zhaoxi Chen, Yushi Lan, Liang Pan, Ziwei Liu. EVA3D: 2D 이미지 컬렉션에서 구성적인 3D 인간 생성. International Conference on Learning Representations, 2023. 1, 2,[22] Zeng Huang, Yuanlu Xu, Christoph Lassner, Hao Li, Tony Tung. Arch: 옷을 입은 인간의 애니메이션 재구성. IEEE/CVF Conference on Computer Vision and Pattern Recognition, 3093-3102페이지, 2020.[23] Kaiwen Jiang, Shu-Yu Chen, Feng-Lin Liu, Hongbo Fu, Lin Gao. Nerffaceediting: 신경 광도장에서 얽히지 않은 얼굴 편집. ACM SIGGRAPH Asia, 1-9페이지, 2022.[24] Hanbyul Joo, Natalia Neverova, Andrea Vedaldi. 야생에서 3D 인간 포즈 추정을 위한 3D 인간 모델 피팅을 위한 모범적 미세 조정. 국제 3D 비전 컨퍼런스, 42-52페이지, 2021. 5, 6,[25] Tero Karras, Samuli Laine, Timo Aila. 생성적 적대 네트워크를 위한 스타일 기반 생성기 아키텍처. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스, 4401-4410페이지, 2019.[26] Diederik P Kingma, Jimmy Ba. Adam: 확률적 최적화를 위한 방법. 국제 학습 표현 컨퍼런스, 2015.[27] Youngjoong Kwon, Dahun Kim, Duygu Ceylan, Henry Fuchs. 신경 인간 공연자: 인간 공연 렌더링을 위한 일반화 가능한 광도 필드 학습. 신경 정보 처리 시스템의 발전, 34:24741-24752, 2021.[28] John P Lewis, Matt Cordner, Nickson Fong. 포즈 공간 변형: 모양 보간 및 골격 기반 변형에 대한 통합된 접근 방식. 컴퓨터 그래픽 및 대화형 기술 연례 컨퍼런스, 165-172페이지, 2000년.[29] Tianye Li, Timo Bolkart, Michael J Black, Hao Li, Javier Romero. 4D 스캔에서 얼굴 모양 및 표정 모델 학습. ACM 그래픽스 트랜잭션, 36(6):194-1, 2017. 2,[30] Yiyi Liao, Katja Schwarz, Lars Mescheder, Andreas Geiger. 3D 제어 가능 이미지 합성을 위한 생성 모델의 비지도 학습을 향하여. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스, 5871-5880페이지, 2020년.[31] Lingjie Liu, Marc Habermann, Viktor Rudnev, Kripasindhu Sarkar, Jiatao Gu, Christian Theobalt. Neural actor: Neural free-view synthesis of human actors with pose control. ACM Transactions on Graphics, 40(6):1-16, 2021.[32] Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, Michael J Black. SMPL: 스키닝된 다중 사람 선형 모델. ACM Transactions on Graphics, 34(6):1-16, 2015. 2,[33] Lars Mescheder, Andreas Geiger, Sebastian Nowozin. 어떤 gans 훈련 방법이 실제로 수렴합니까? International Conference on Machine Learning, 3481-3490페이지, 2018.[34] Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik, Jonathan T Barron, Ravi Ramamoorthi, Ren Ng. NeRF: 뷰 합성을 위한 신경 광도 필드로 장면 표현. European Conference on Computer Vision, 405-421페이지, 2020.[35] Thu Nguyen-Phuoc, Chuan Li, Lucas Theis, Christian Richardt, Yong-Liang Yang. Hologan: 자연 이미지에서 3D 표현의 비지도 학습. IEEE/CVF International Conference on Computer Vision, 7588-7597페이지, 2019. [36] Thu Nguyen-Phuoc, Christian Richardt, Long Mai, YongLiang Yang, Niloy Mitra. BlockGAN: 레이블이 지정되지 않은 이미지에서 3D 객체 인식 장면 표현 학습. Advances in Neural Information Processing Systems, 2020.[37] Michael Niemeyer와 Andreas Geiger. 기린: 장면을 구성적 생성 신경 특징 필드로 표현. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스, 11453-11464페이지, 2021.[38] Atsuhiro Noguchi, Xiao Sun, Stephen Lin, Tatsuya Harada. 효율적인 지오메트리 인식 신경 관절 표현의 비지도 학습. 유럽 컴퓨터 비전 컨퍼런스, 597-614페이지, 2022. 1, 2,[39] Roy Or-El, Xuan Luo, Mengyi Shan, Eli Shechtman, Jeong Joon Park, Ira Kemelmacher-Shlizerman. Stylesdf: 고해상도 3D 일관성 이미지 및 지오메트리 생성. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스, 13503-13513페이지, 2022.[40] Hao Ouyang, Bo Zhang, Pan Zhang, Hao Yang, Jiaolong Yang, Dong Chen, Qifeng Chen, Fang Wen. 포즈 유도 다중 평면 이미지를 사용한 실시간 신경 문자 렌더링. European Conference on Computer Vision, 192-209페이지, 2022.[41] Pascal Paysan, Reinhard Knothe, Brian Amberg, Sami Romdhani, Thomas Vetter. 포즈 및 조명 불변 얼굴 인식을 위한 3D 얼굴 모델. IEEE International Conference on Advanced Video and Signal based Surveillance, 296-301페이지, 2009. 3,[42] Sida Peng, Junting Dong, Qianqian Wang, Shangzhan Zhang, Qing Shuai, Xiaowei Zhou, Hujun Bao. 동적 인체 모델링을 위한 애니메이션 가능한 신경 광도장. IEEE/CVF 국제 컴퓨터 비전 컨퍼런스, 14314-14323페이지, 2021. 1, 3,[43] Yurui Ren, Ge Li, Yuanqi Chen, Thomas H Li, Shan Liu. Pirenderer: 의미론적 신경 렌더링을 통한 제어 가능한 인물 이미지 생성. IEEE/CVF 국제 컴퓨터 비전 컨퍼런스, 13759-13768페이지, 2021.[44] Katja Schwarz, Yiyi Liao, Michael Niemeyer, Andreas Geiger. Graf: 3D 인식 이미지 합성을 위한 생성적 광도장. 신경 정보 처리 시스템의 발전, 2020.[45] Jie Shen, Stefanos Zafeiriou, Grigoris G Chrysos, Jean Kossaifi, Georgios Tzimiropoulos, Maja Pantic. 야생에서 얼굴 랜드마크 추적을 위한 첫 번째 도전: 벤치마크 및 결과. IEEE 국제 컴퓨터 비전 워크숍 컨퍼런스, 50-58페이지, 2015년.[46] Wenzhe Shi, Jose Caballero, Ferenc Huszár, Johannes Totz, Andrew P Aitken, Rob Bishop, Daniel Rueckert, Zehan Wang. 효율적인 하위 픽셀 합성 신경망을 사용한 실시간 단일 이미지 및 비디오 초고해상도. IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스, 1874-1883페이지, 2016년.[47] Yichun Shi, Divyansh Aggarwal, Anil K Jain. 3D 인식 얼굴 생성을 위한 2D 스타일간 리프팅. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스, 6258-6266페이지, 2021년.[48] Aliaksandr Siarohin, Stéphane Lathuilière, Sergey Tulyakov, Elisa Ricci, Nicu Sebe. 이미지 애니메이션을 위한 1차 동작 모델. 신경 정보 처리 시스템의 발전, 32, 2019.[49] Ivan Skorokhodov, Aliaksandr Siarohin, Yinghao Xu, Jian Ren, Hsin-Ying Lee, Peter Wonka, Sergey Tulyakov. ImageNet에서의 3D 생성. 학습 표현에 관한 국제 컨퍼런스, 2023.[50] Ivan Skorokhodov, Sergey Tulyakov, Yiqun Wang, Peter Wonka. Epigraf: 3D gans의 훈련 재고. 신경 정보 처리 시스템의 발전, 2022.[51] Jingxiang Sun, Xuan Wang, Lizhen Wang, Xiaoyu Li, Yong Zhang, Hongwen Zhang, Yebin Liu. Next3D: 3D 인식 헤드 아바타를 위한 생성적 신경 텍스처 래스터화. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스, 2023. 1, 2,[52] Keqiang Sun, Shangzhe Wu, Zhaoyang Huang, Ning Zhang, Quan Wang, HongSheng Li. 조건부 생성 점유 필드를 사용한 제어 가능한 3D 얼굴 합성. 신경 정보 처리 시스템의 발전, 2022. 1, 2,[53] Ayush Tewari, Xingang Pan, Ohad Fried, Maneesh Agrawala, Christian Theobalt, et al. Disentangled3d: 단안 이미지에서 얽힌 지오메트리와 모양으로 3D 생성 모델 학습. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스, 1516-1525쪽, 2022.[54] Daoye Wang, Prashanth Chandran, Gaspard Zoss, Derek Bradley, Paulo Gotardo. MORf: 다중 뷰 신경 헤드 모델링을 위한 변형 가능한 광도 필드. ACM SIGGRAPH 2022 컨퍼런스 회의록, 1-9페이지, 2022.[55] Ting-Chun Wang, Arun Mallya, Ming-Yu Liu. 화상 회의를 위한 원샷 자유 뷰 신경 토킹 헤드 합성. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스, 10039-10049페이지, 2021.[56] Xintao Wang, Yu Li, Honglun Zhang, Ying Shan. 생성적 얼굴 사전을 사용한 실제 맹인 얼굴 복원을 향해. IEEE/CVF 컴퓨터 비전 및 패턴 인식 컨퍼런스, 9168-9178페이지, 2021.[57] Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu, Chao Dong, Yu Qiao, Chen Change Loy. Esrgan: 향상된 초고해상도 생성적 적대 네트워크. European Conference on Computer Vision Workshops, 2018. 5,[58] Chung-Yi Weng, Brian Curless, Pratul P Srinivasan, Jonathan T Barron, Ira Kemelmacher-Shlizerman. Humannerf: 단안 비디오에서 움직이는 사람의 자유 시점 렌더링. IEEE/CVF Conference on Computer Vision and Pattern Recognition, 16210–16220페이지, 2022.[59] Olivia Wiles, A Koepke, Andrew Zisserman. X2face: 이미지, 오디오 및 포즈 코드를 사용하여 얼굴 생성을 제어하기 위한 네트워크. European Conference on Computer Vision, 670-686페이지, 2018.[60] Yue Wu, Yu Deng, Jiaolong Yang, Fangyun Wei, Qifeng Chen 및 Xin Tong. AniFaceGAN: 비디오 아바타를 위한 애니메이션 가능한 3D 인식 얼굴 이미지 생성. 신경 정보 처리 시스템의 발전, 2022. 1, 2, 3, 4, 5,[61] Jianfeng Xiang, Jiaolong Yang, Yu Deng 및 Xin Tong. GRAM-HD: 생성 복사 매니폴드를 사용하여 고해상도에서 3D 일관성이 있는 이미지를 생성합니다. 컴퓨터 비전에 관한 IEEE/CVF 국제 회의, 2023. 2, 3, 5,[62] Hongyi Xu, Guoxian Song, Zihang Jiang, Jianfeng Zhang, Yichun Shi, Jing Liu, Wanchun Ma, Jiashi Feng 및 Linjie Luo. OmniAvatar: 형상 안내에 따라 제어 가능한 3D 머리 합성. IEEE/CVF 국제 컴퓨터 비전 컨퍼런스, 2023. 1, 2,[63] Sicheng Xu, Jiaolong Yang, Dong Chen, Fang Wen, Yu Deng, Yunde Jia, Tong Xin. 단일 이미지에서 추출한 심층 3D 초상화. IEEE 컴퓨터 비전 및 패턴 인식 컨퍼런스, 7710-7720페이지, 2020.[64] Egor Zakharov, Aliaksandra Shysheya, Egor Burkov, Victor Lempitsky. 사실적인 신경 토킹 헤드 모델의 소수 샷 적대 학습. IEEE/CVF 국제 컴퓨터 비전 컨퍼런스, 9459-9468페이지, 2019.[65] Jianfeng Zhang, Zihang Jiang, Dingdong Yang, Hongyi Xu, Yichun Shi, Guoxian Song, Zhongcong Xu, Xinchao Wang, Jiashi Feng. Avatargen: 애니메이션이 가능한 인간 아바타를 위한 3D 생성 모델. European Conference on Computer Vision Workshops, 668-685페이지, 2022. 2,[66] Xiaoming Zhao, Fangchang Ma, David Güera, Zhile Ren, Alexander G Schwing, Alex Colburn. 생성적 다중 평면 이미지: 2D gan 3D 인식 만들기. European Conference on Computer Vision, 18-35페이지, 2022.A 그림 9: 큐레이션되지 않은 초상화 생성은 우리 방법의 결과입니다. T པ་ Zid, Zexp xp Zid, E Rlr 다운샘플 2x 3D 변환 FC+LReLU FC+LReLU FC+LReLU 업샘플 2x FC+LReLU 3D 변환 FC+LReLU RRDBs FC+LReLU A FILM SIREN A 하위 픽셀 변환 A FILM SIREN A 하위 픽셀 변환 A FILM SIREN A 변환 A FC XC FC A Rhr 포즈 변형 처리 네트워크 DP 표현 변형 네트워크 De 매니폴드 초해상도 네트워크 U 그림 10: 네트워크 구조.DP에는 커널 크기가 9 × 9 × 5인 두 개의 3D 변환 레이어가 있습니다.De와 U는 모두 매핑 MLP 네트워크와 백본이 있는 StyleGAN과 유사한 구조[25]를 갖습니다. De의 백본은 주로 3개의 FILM SIREN 레이어[6]를 기반으로 하는 반면 U는 4개의 Residual-in-Residual Dense Blocks(RRDB)[57]와 2개의 하위 픽셀 변환 레이어[46]를 사용합니다.
