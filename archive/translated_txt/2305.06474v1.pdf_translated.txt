--- INTRODUCTION ---
대규모 언어 모델(LLM)은 텍스트 생성[1, 2, 6, 26], 번역[36, 42], 요약[19]과 같은 광범위한 작업을 처리하는 놀라운 능력을 보여주었습니다. 대화에 대한 LLM의 최근 미세 조정과 지시 미세 조정[4] 및 인간 피드백을 통한 강화 학습(RLHF)[3]과 같은 기술을 사용함으로써 *두 저자는 이 작업에 동등하게 기여했습니다.저자 주소: Wang-Cheng Kang*, wckang@google.com, Google Research, Brain Team, 미국;Jianmo Ni*, jianmon@google.com, Google Research, Brain Team, 미국;Nikhil Mehta, nikhilmehta@google.com, Google Research, Brain Team, 미국;Maheswaran Sathiamoorthy, nlogn@google.com, Google Research, Brain Team, 미국;Lichan Hong, lichan@google.com, Google Research, Brain Team, 미국; Ed Chi, edchi@google.com, Google Research, Brain Team, 미국; Derek Zhiyuan Cheng, zcheng@google.com, Google Research, Brain Team, 미국. 이 저작물의 일부 또는 전부를 개인 또는 교실에서 사용하기 위해 디지털 또는 하드 카피로 만드는 것은 비용 없이 허가되며, 이 사본이 이익 또는 상업적 이익을 위해 만들어지거나 배포되지 않고 사본에 이 고지 사항과 첫 페이지에 있는 전체 인용문이 포함되어야 합니다. ACM이 아닌 다른 사람이 소유한 이 저작물의 구성 요소에 대한 저작권은 존중해야 합니다. 출처를 명시한 초록은 허용됩니다. 다른 방식으로 복사하거나, 재출판하거나, 서버에 게시하거나, 목록에 재배포하려면 사전에 구체적인 허가 및/또는 수수료가 필요합니다. permissions@acm.org로 허가를 요청하세요. © 2023 Association for Computing Machinery. ACM에 제출된 원고 ACMW.-C. Kang, et al.에 제출된 원고 Amazon-Books 0.0.0.700.65Flan-TFlan-U-PALM GPT-Global Average Rating Movielens-1M Amazon-Books Movielens-1M -0.-0.0.-0.-0.0.-1.-1.0.70-1.-1.0.-1.0.0.-1.30.550.55-1.-1.40.0.-1.-1.109 1010 1011개 매개변수 108 109 1010 1011개 매개변수 0.0.108 109 1010 1011개 매개변수 108 109 1010 1011개 매개변수 그림 1. Flan-T5(기본에서 XXL까지), GPT3를 포함한 다양한 모델 크기를 가진 LLM의 평가 예측을 위한 제로샷 성능 (Curie, Davinci) 및 Flan-U-PALM. 모델 크기를 늘리면 성능이 향상됩니다. 그 중 100B보다 큰 모델(Flan-U-PALM 540B 및 text-davinci-003 175B)은 RMSE와 AUC-ROC 모두에서 글로벌 평균 평가 기준선을 능가하거나 동등합니다. 매우 인간과 유사한 챗봇(예: ChatGPT[23] 및 Bard[10])을 일반 가정에 도입하는 데 큰 성공을 거두었습니다. LLM의 다재다능함과 효과성에 직접적으로 기여하는 세 가지 핵심 요인이 있습니다. (1) 인터넷 규모의 실제 세계 정보에서 얻은 지식: LLM은 방대한 양의 텍스트 데이터 세트에서 교육을 받아 풍부한 실제 세계 정보에 액세스할 수 있습니다. 이 정보는 질문에 답하고, 창의적으로 글을 쓰고(예: 시와 기사) 언어 간 번역하는 데 사용할 수 있는 지식으로 변환됩니다. (2) 효과적인 few-shot 학습을 통한 놀라운 일반화 능력: 특정 맥락 내에서 LLM은 극히 적은 수의 예제에서 새로운 작업을 학습할 수 있습니다(일명 few-shot 학습). 강력한 few-shot 학습 기능은 LLM이 새로운 작업에 매우 적응할 수 있도록 준비시킵니다.(3) 강력한 추론 능력: LLM은 사고의 사슬 과정을 통해 추론할 수 있어[40, 41] 많은 작업에서 성과를 크게 향상시킵니다[37]. 최근 LLM을 검색[20], 순위 학습[11, 45], 추천 시스템[5, 8, 18]에 활용하기 위한 초기 탐색 작업이 있었습니다. 특히 추천 시스템의 경우 P5[8]는 T5-small(60M)과 T5-base(220M)[27]를 미세 조정하여 순위, 검색 및 요약 설명과 같은 기타 작업을 하나의 모델로 통합합니다. M6-Rec [5]는 M6(300M) [17]이라는 LLM을 미세 조정하여 CTR 예측 작업을 처리합니다. Liu et al. [18]은 ChatGPT와 같은 대화형 에이전트가 프롬프트를 인터페이스로 사용하는 기성품 추천 모델 역할을 할 수 있는지 조사했으며 MF 및 MLP와 같은 기준선에 대한 평가 예측에서 제로샷 성능을 보고했습니다. 그러나 다양한 크기의 LLM을 세심히 평가하고 신중하게 최적화된 강력한 기준선과 대조하는 포괄적인 연구가 눈에 띄게 부족합니다. 이 논문에서는 추천 시스템에 기성품 대규모 언어 모델(LLM)을 사용하는 방법을 살펴봅니다. 250M에서 540B 매개변수에 이르는 다양한 크기의 다양한 LLM을 연구합니다. 사용자 평가 예측의 특정 작업에 초점을 맞추고 세 가지 다른 체제에서 이러한 LLM의 성능을 평가합니다. 1. 제로샷 2. 퓨어샷 3. 미세 조정. 그런 다음 널리 채택된 두 가지 추천 벤치마크 데이터 세트에서 최첨단 추천 모델과 신중하게 비교합니다. 저희의 기여는 세 가지입니다. • 저희는 다양한 모델 크기를 가진 기성품 LLM의 제로샷 및 퓨샷 성능을 경험적으로 연구합니다. 저희는 더 큰 모델(1000억 개 이상의 매개변수)이 콜드 스타트 시나리오에서 합리적인 추천을 제공할 수 있으며, 적절한 휴리스틱 기반 기준선과 비슷한 성능을 달성할 수 있음을 발견했습니다. ACM에 제출된 원고 LLM이 사용자 선호도를 이해하는가? 사용자 평가 예측에서 LLM 평가 • 저희는 제로샷 LLM이 여전히 인간 상호 작용 데이터를 활용하는 기존 추천 모델보다 뒤떨어져 있음을 보여줍니다. 제로샷 LLM은 항상 평균 항목 또는 사용자 평가를 예측하는 두 가지 놀랍도록 사소한 기준선보다 비슷한 성능을 달성할 뿐입니다. 더욱이 기존의 감독 추천 모델보다 상당히 낮은 성능을 보여 사용자 상호 작용 데이터의 중요성을 나타냅니다. • 인간 상호작용 데이터에 대한 LLM을 미세 조정하는 수많은 실험을 통해 미세 조정된 LLM이 극히 일부의 훈련 데이터만으로 기존 모델과 동등하거나 심지어 더 나은 성능을 달성할 수 있음을 보여주었으며, 이는 데이터 효율성 측면에서 유망함을 보여줍니다.
--- RELATED WORK ---
2. 추천 시스템에서의 자연어 사용 자연어 작업으로 추천 문제를 공식화하는 것을 탐구한 가장 초기의 작업 중 하나는 [44]입니다. 그들은 Movielens 데이터 세트[12]에서 BERT[6]와 GPT-2[25]를 사용하여 이러한 언어 모델이 GRU4Rec[15]와 같은 잘 조정된 기준선만큼 좋지는 않지만 놀라울 정도로 좋은 성능을 보인다는 것을 보여주었습니다. P5[8]는 인기 있는 오픈 소스 T5[27] 모델을 미세 조정하여 순위, 검색 및 요약 설명과 같은 다른 작업을 하나의 모델로 통합합니다. M6-Rec[5]는 또 다른 관련 작업이지만 M6[17]이라는 LLM을 미세 조정하여 CTR 예측 작업을 다룹니다. 최근 두 연구에서는 LLM을 사용하여 제로 샷 예측을 탐구합니다. ChatRec[7]은 제로 샷 예측을 처리하는 동시에 대화형이면서 설명을 제공합니다. [35]는 Movielens 데이터 세트에서 다음 항목 추천을 생성하기 위해 3단계 프롬핑 방식을 취하고 SASRec[16]과 같은 강력한 순차적 추천 기준선을 이길 수는 없지만 경쟁력 있는 지표를 달성합니다.2.2 대규모 언어 모델 사람들이 데이터와 모델의 크기를 확장하면 언어 모델에 도움이 된다는 것을 깨닫고 나서 일련의 대규모 언어 모델이 제안되고 구축되었습니다.예: PaLM[2], GPT-3[1] 및 최근의 OPT[43] 및 LLAMA[33].LLM의 고유한 능력 중 하나는 사물에 대해 추론하는 능력에 있으며, 이는 사고의 사슬 프롬핑[41], 자기 일관성[38] 및 자기 반성[30]과 같은 기술에 의해 더욱 향상됩니다.LLM의 또 다른 주요 강력한 능력은 모델이 주어진 자연어 지침을 따르면서 보이지 않는 작업으로 일반화할 수 있는 지침 따르기입니다. 연구자들은 지시 미세 조정[4] 및 RLHF[3]와 같은 기술이 인간의 선호도와 일치하는 자연어 설명이 주어진 경우 LLM의 작업 수행 능력을 크게 향상시킬 수 있다는 것을 발견했습니다. 자연어로 설명할 수 있는 작업 중 하나인 &#39;추천&#39;은 LLM에게 유망한 새로운 능력이 되었습니다. 이 연구에서 우리는 ChatGPT[23], GPT-3(text-davinci-003[22]), Flan-U-PaLM 및 Flan-T5[4]와 같이 지시 따르기 능력을 향상시키기 위해 미세 조정된 모델에 초점을 맞춥니다. 3
--- METHOD ---
이러한 작업의 경우 주로 방대한 양의 평가 데이터에 의존합니다. 반면 LLM은 일반적으로 영화나 제품과 같이 각 항목에 대한 광범위한 세계 지식을 유지하면서도 상당히 적은 데이터를 요구합니다. 이 논문에서는 사용자의 과거 평가를 기반으로 후보 항목에 대한 사용자 평가를 예측하는 고전적인 사용자 평가 예측 작업에서 CF와 LLM을 모두 철저히 검토합니다. 250M에서 540B 매개변수에 이르는 다양한 크기의 다양한 LLM을 조사하고 제로샷, 퓨어샷 및 미세 조정 시나리오에서 성능을 평가합니다. LLM과 강력한 CF 방법을 비교하기 위해 포괄적인 분석을 수행한 결과, 제로샷 LLM이 사용자 상호 작용 데이터에 액세스할 수 있는 기존 추천 모델보다 뒤떨어져 사용자 상호 작용 데이터의 중요성을 나타냅니다. 그러나 미세 조정을 통해 LLM은 훈련 데이터의 일부만으로 비슷하거나 더 나은 성능을 달성하여 데이터 효율성을 통해 잠재력을 입증합니다. ACM 참조 형식: Wang-Cheng Kang*, Jianmo Ni*, Nikhil Mehta, Maheswaran Sathiamoorthy, Lichan Hong, Ed Chi, Derek Zhiyuan Cheng. 2023. LLM이 사용자 선호도를 이해하는가? 사용자 평가 예측에 대한 LLM 평가. 1, 1(2023년 5월), 11페이지. https://doi.org/10. 1145/nnnnnnn.nnnnnnnn 서론 대규모 언어 모델(LLM)은 텍스트 생성[1, 2, 6, 26], 번역[36, 42], 요약[19]과 같은 다양한 작업을 처리하는 뛰어난 능력을 보여주었습니다. 대화에 대한 LLM의 최근 미세 조정과 지침 미세 조정[4] 및 인간 피드백(RLHF)을 통한 강화 학습[3]과 같은 기술을 사용함으로써 *두 저자는 이 작업에 동등하게 기여했습니다. 저자 주소: Wang-Cheng Kang*, wckang@google.com, Google Research, Brain Team, USA; Jianmo Ni*, jianmon@google.com, Google Research, Brain Team, USA; Nikhil Mehta, nikhilmehta@google.com, Google Research, Brain Team, USA; Maheswaran Sathiamoorthy, nlogn@google.com, Google Research, Brain Team, USA; Lichan Hong, lichan@google.com, Google Research, Brain Team, USA; Ed Chi, edchi@google.com, Google Research, Brain Team, USA; Derek Zhiyuan Cheng, zcheng@google.com, Google Research, Brain Team, USA. 이 저작물의 일부 또는 전부를 개인적 또는 교실에서 사용하기 위해 디지털 또는 하드 카피로 만드는 것은 비용 없이 허가되지만, 이 저작물을 수익 또는 상업적 이익을 위해 만들거나 배포하지 않고 이 고지 사항과 첫 페이지에 전체 인용문을 표시해야 합니다. ACM이 아닌 다른 사람이 소유한 이 저작물의 구성 요소에 대한 저작권은 존중해야 합니다. 출처를 명시한 초록은 허용됩니다. 다른 방식으로 복사하거나, 재출판하거나, 서버에 게시하거나, 목록에 재배포하려면 사전 특정 허가 및/또는 수수료가 필요합니다. permissions@acm.org로 허가를 요청하세요. © 2023 Association for Computing Machinery. ACM에 제출된 원고 ACMW.-C. Kang, et al.에 제출된 원고 Amazon-Books 0.0.0.700.65Flan-TFlan-U-PALM GPT-Global Average Rating Movielens-1M Amazon-Books Movielens-1M -0.-0.0.-0.-0.0.-1.-1.0.70-1.-1.0.-1.0.0.-1.30.550.55-1.-1.40.0.-1.-1.109 1010 1011개 매개변수 108 109 1010 1011개 매개변수 0.0.108 109 1010 1011개 매개변수 108 109 1010 1011개 매개변수 그림 1. Flan-T5(기본에서 XXL까지), GPT3를 포함한 다양한 모델 크기를 가진 LLM의 평가 예측을 위한 제로샷 성능 (Curie, Davinci) 및 Flan-U-PALM. 모델 크기를 늘리면 성능이 향상됩니다. 그 중 100B보다 큰 모델(Flan-U-PALM 540B 및 text-davinci-003 175B)은 RMSE와 AUC-ROC 모두에서 글로벌 평균 평가 기준선을 능가하거나 동등합니다. 매우 인간과 유사한 챗봇(예: ChatGPT[23] 및 Bard[10])을 일반 가정에 도입하는 데 큰 성공을 거두었습니다. LLM의 다재다능함과 효과성에 직접적으로 기여하는 세 가지 핵심 요인이 있습니다. (1) 인터넷 규모의 실제 세계 정보에서 얻은 지식: LLM은 방대한 양의 텍스트 데이터 세트에서 교육을 받아 풍부한 실제 세계 정보에 액세스할 수 있습니다. 이 정보는 질문에 답하고, 창의적으로 글을 쓰고(예: 시와 기사) 언어 간 번역하는 데 사용할 수 있는 지식으로 변환됩니다. (2) 효과적인 few-shot 학습을 통한 놀라운 일반화 능력: 특정 맥락 내에서 LLM은 극히 적은 수의 예제에서 새로운 작업을 학습할 수 있습니다(일명 few-shot 학습). 강력한 few-shot 학습 기능은 LLM이 새로운 작업에 매우 적응할 수 있도록 준비시킵니다.(3) 강력한 추론 능력: LLM은 사고의 사슬 과정을 통해 추론할 수 있어[40, 41] 많은 작업에서 성과를 크게 향상시킵니다[37]. 최근 LLM을 검색[20], 순위 학습[11, 45], 추천 시스템[5, 8, 18]에 활용하기 위한 초기 탐색 작업이 있었습니다. 특히 추천 시스템의 경우 P5[8]는 T5-small(60M)과 T5-base(220M)[27]를 미세 조정하여 순위, 검색 및 요약 설명과 같은 기타 작업을 하나의 모델로 통합합니다. M6-Rec [5]는 M6(300M) [17]이라는 LLM을 미세 조정하여 CTR 예측 작업을 처리합니다. Liu et al. [18]은 ChatGPT와 같은 대화형 에이전트가 프롬프트를 인터페이스로 사용하는 기성품 추천 모델 역할을 할 수 있는지 조사했으며 MF 및 MLP와 같은 기준선에 대한 평가 예측에서 제로샷 성능을 보고했습니다. 그러나 다양한 크기의 LLM을 세심히 평가하고 신중하게 최적화된 강력한 기준선과 대조하는 포괄적인 연구가 눈에 띄게 부족합니다. 이 논문에서는 추천 시스템에 기성품 대규모 언어 모델(LLM)을 사용하는 방법을 살펴봅니다. 250M에서 540B 매개변수에 이르는 다양한 크기의 다양한 LLM을 연구합니다. 사용자 평가 예측의 특정 작업에 초점을 맞추고 세 가지 다른 체제에서 이러한 LLM의 성능을 평가합니다. 1. 제로샷 2. 퓨어샷 3. 미세 조정. 그런 다음 널리 채택된 두 가지 추천 벤치마크 데이터 세트에서 최첨단 추천 모델과 신중하게 비교합니다. 저희의 기여는 세 가지입니다. • 저희는 다양한 모델 크기를 가진 기성품 LLM의 제로샷 및 퓨샷 성능을 경험적으로 연구합니다. 저희는 더 큰 모델(1000억 개 이상의 매개변수)이 콜드 스타트 시나리오에서 합리적인 추천을 제공할 수 있으며, 적절한 휴리스틱 기반 기준선과 비슷한 성능을 달성할 수 있음을 발견했습니다. ACM에 제출된 원고 LLM이 사용자 선호도를 이해하는가? 사용자 평가 예측에 대한 LLM 평가 • 저희는 제로샷 LLM이 여전히 인간 상호 작용 데이터를 활용하는 기존 추천 모델보다 뒤떨어져 있음을 보여줍니다. 제로샷 LLM은 항상 평균 항목 또는 사용자 평가를 예측하는 두 개의 놀랍도록 사소한 기준선보다 비슷한 성능을 달성합니다. 더욱이, 기존의 감독 추천 모델보다 상당히 낮은 성능을 보여 사용자 상호 작용 데이터의 중요성을 나타냅니다. • 수많은
--- EXPERIMENT ---
인간 상호작용 데이터에 대한 LLM을 미세 조정하는 s를 통해 미세 조정된 LLM이 훈련 데이터의 일부만으로 기존 모델과 동등하거나 더 나은 성능을 달성할 수 있음을 보여 데이터 효율성 측면에서 유망함을 보여줍니다.관련 작업 2. 추천 시스템에서 자연어 사용 자연어 작업으로 추천 문제를 공식화하는 것을 탐구한 가장 초기의 작업 중 하나는 [44]입니다.그들은 Movielens 데이터 세트[12]에서 BERT[6]와 GPT-2[25]를 사용하여 이러한 언어 모델이 GRU4Rec[15]와 같은 잘 조정된 기준선만큼 좋지는 않지만 놀라울 정도로 좋은 성능을 보인다는 것을 보여주었습니다.P5[8]는 인기 있는 오픈 소스 T5[27] 모델을 미세 조정하여 순위 지정, 검색 및 요약 설명과 같은 다른 작업을 하나의 모델로 통합합니다.M6-Rec[5]은 또 다른 관련 작업이지만 M6[17]이라는 LLM을 미세 조정하여 CTR 예측 작업을 다룹니다. 두 가지 최근 연구에서는 LLM을 사용하여 제로샷 예측을 처리하는 방법을 살펴봅니다. ChatRec[7]은 제로샷 예측을 처리하는 동시에 상호 작용하고 설명을 제공합니다. [35]는 Movielens 데이터 세트에서 다음 항목 추천을 생성하기 위해 3단계 프롬핑 방식을 사용하고 경쟁력 있는 지표를 달성하지만 SASRec[16]과 같은 강력한 순차적 추천 기준선을 이길 수는 없습니다. 2.2 대규모 언어 모델 사람들이 데이터와 모델의 크기를 확장하면 언어 모델에 도움이 된다는 것을 깨닫고 나서 일련의 대규모 언어 모델이 제안되고 구축되었습니다. 예를 들어 PaLM[2], GPT-3[1] 및 최근의 OPT[43]와 LLAMA[33]가 있습니다. LLM의 고유한 능력 중 하나는 사물에 대해 추론하는 능력으로, 생각의 사슬 프롬핑[41], 자기 일관성[38] 및 자기 반성[30]과 같은 기술을 통해 더욱 향상됩니다. LLM의 또 다른 주요 강력한 기능은 모델이 주어진 자연어 지침을 따름으로써 보이지 않는 작업으로 일반화할 수 있는 지시 따르기입니다. 연구자들은 지시 미세 조정[4] 및 RLHF[3]와 같은 기술이 인간의 선호도와 일치하는 자연어 설명이 주어졌을 때 LLM이 작업을 수행하는 기능을 크게 향상시킬 수 있다는 것을 발견했습니다. 자연어로 설명할 수 있는 작업 중 하나인 &#39;추천&#39;은 LLM의 유망한 새로운 기능이 되었습니다. 이 연구에서 우리는 ChatGPT[23], GPT-3(text-davinci-003[22]), Flan-U-PaLM 및 Flan-T5[4]와 같이 지시 따르기 기능을 개선하도록 미세 조정된 모델에 초점을 맞춥니다. 3 방법 3.1 문제 공식화 사용자 평가 예측 과제를 연구합니다.이 과제는 다음과 같이 공식화됩니다.사용자 u € U, 사용자 u의 과거 상호 작용 시퀀스 E&quot; = {e¼, e, ..., e} 및 아이템 i = I가 주어졌을 때, 사용자 u가 아이템 i에 줄 평가를 예측합니다.여기서 사용자 과거 상호 작용 시퀀스 E&quot;는 시간순으로 정렬되고(e는 사용자가 가장 최근에 사용한 아이템), ACMinteraction W.-C. Kang 등에 제출된 각 원고는 사용자가 사용한 아이템에 대한 정보(예: ID, 제목, 메타데이터 등)와 사용자가 아이템에 준 평가로 표현됩니다.3.2 평가 예측을 위한 제로샷 및 퓨샷 LLM 제로샷 사용자 평가 예측기 제목, 장르, 평가 형식으로 된 사용자의 과거 영화 평가가 주어졌을 때.평가 범위는 1.0~5.0입니다.Babe(1995), 아동용 | 코미디 드라마, There&#39;s Something About Mary (1998), 코미디, Awakenings (1990), 드라마, Simple Plan, A (1998), 범죄 스릴러, Bug&#39;s Life, A (1998), 애니메이션 | 어린이 | 코미디, Twelve Monkeys (1995), 드라마 | 공상과학, Pleasantville (1998), 코미디, Apollo 13 (1995), 드라마, Misery (1990), 공포, South Park: Bigger, Longer and Uncut (1999), 애니메이션 | 코미디, 후보 영화는 Player, The (1992), 코미디 | 드라마입니다. 사용자가 줄 평점은? Few-Shot 사용자 평점 예측기 영화 추천을 위해 사용자 평점을 예측해야 합니다. 평점 범위는 1.0~5.0입니다. 사용자의 과거 평가 내역이 제목, 장르, 평가 형식으로 제공됩니다. 예: 질문: 사용자 내역은 다음과 같습니다. 제리 맥과이어(1996), 드라마|로맨스, 2. 파이트 클럽(1999), 액션|범죄 드라마 스릴러, 4. 고스트버스터즈(일명 고스트 버스터즈)(1984), 액션 코미디 SF 4. 사용자가 시청한 작품(다섯 번째 요소, SF 액션)은 다른 내용 없이 하나의 숫자로 평가하세요. 이유는 설명하지 마세요. 답변: 4. 질문: 사용자 내역은 다음과 같습니다. 베이브(1995), 아동 코미디 드라마, 메리에겐 뭔가 특별한 게 있다(1998), 코미디, 미저리(1990), 공포, 사우스 파크: 빅거, 롱거 앤 언컷(1999), 애니메이션|코미디, 사용자가 시청한 작품(플레이어, 더(1992), 코미디 드라마)은 다른 내용 없이 하나의 숫자로 평가하세요. 추론을 제공하지 마십시오. A: 그림 2. 평가 예측을 위한 제로샷 및 퓨샷 LLM 프롬프트. 그림 2에서 MovieLens 데이터 세트의 평가 예측 작업에 사용된 제로샷 및 퓨샷 프롬프트를 보여줍니다. 그림에서 볼 수 있듯이 입력 프롬프트는 사용자의 과거 평가 내역 및 후보 항목 기능(제목 및 장르)을 포함하여 텍스트로 표현된 여러 가지 중요한 기능을 묘사합니다. 마지막으로, 평가 척도가 있는 모델에서 숫자 평가를 이끌어내기 위해 입력 프롬프트는 숫자 평가 척도를 지정합니다. 모델 응답은 모델에서 평가 출력을 추출하기 위해 구문 분석됩니다. 그러나 LLM은 입력 프롬프트에 매우 민감할 수 있으며 항상 제공된 지침을 따르지 않는다는 것을 발견했습니다. 예를 들어, 특정 LLM은 추가 추론을 제공하거나 숫자 평가를 전혀 제공하지 않을 수 있다는 것을 발견했습니다. 이를 해결하기 위해 &quot;설명 없이 단일 숫자를 평가로 제공&quot; 및 &quot;추론을 제공하지 마십시오&quot;와 같은 추가 지침을 입력 프롬프트에 추가하여 추가 프롬프트 엔지니어링을 수행했습니다. 3. 평가 예측을 위한 LLM 미세 조정 기존 추천 시스템 연구에서는 인간 상호 작용 데이터로 모델을 훈련하는 것이 사용자 선호도를 이해하는 추천자의 능력을 개선하는 데 효과적이고 중요하다는 것이 널리 입증되었습니다. 여기서는 인간 상호 작용으로 LLM을 훈련하는 방법을 살펴보고 이것이 모델 성능을 어떻게 개선할 수 있는지 연구합니다. 공개적으로 사용 가능하고 광범위한 벤치마크에서 경쟁력 있는 성능을 보이는 LLM 제품군인 Flan-T5의 미세 조정에 중점을 둡니다. 평가 예측 작업은 다음 두 작업 중 하나로 공식화할 수 있습니다. (1) 다중 클래스 분류; 또는 (2) 그림 3b에 표시된 대로 회귀. 다중 클래스 분류. LLM(디코더 전용 또는 인코더-디코더 아키텍처)은 기본적으로 크기 K의 고정 어휘에서 토큰을 예측하는 K-way 분류 작업으로 사전 학습됩니다. 그림 3b에서 볼 수 있듯이 마지막 계층의 출력을 어휘 크기로 투영하는 투영 계층이 있으며 사전 학습은 토큰 분류에 대한 교차 엔트로피 손실을 최적화합니다. 출력 로짓은 로짓 dec = Wprojhdec로 계산됩니다. 여기서 Wproj는 크기 (d, |V|)의 투영 행렬이고, hdec는 디코더의 마지막 변환기 계층의 출력이며, d는 디코더의 은닉 차원 크기이고, |V|는 어휘입니다. ACM에 제출된 원고 LLM이 사용자 선호도를 이해하는가? 사용자 평가 예측에 대한 LLM 평가 출력 4. LLM 디코더 인코딩된 컨텍스트 LLM 인코더 출력 4. 회귀 LLM 디코더 출력 분류 입력 (a) 디코더 전용 모델. 입력 (b) 인코더-디코더 모델.그림 3. 평가 예측 작업을 위한 두 가지 유형의 LLM.[4, 26]에 따라 평가 회귀 작업을 5방향 분류 작업으로 공식화하고, 여기서 5등급을 5개 클래스로 취합니다.학습하는 동안 아래에 표시된 것처럼 다른 분류 작업으로 교차 엔트로피 손실을 사용합니다.N Lcross_entropy == Σ r³log(logits&#39; dec), (1) i=여기서 r²는 i번째 항목에 대한 기준 진실 평가이고 N은 전체 학습 예제 수입니다.추론하는 동안 각 클래스의 모델 출력에 대한 로그 우도를 계산하고 최종 예측으로 확률이 가장 큰 클래스를 선택합니다.회귀.. 회귀 작업에 LLM을 사용하려면 투영 행렬 Wproj의 모양을 (d, 1)로 설정하여 1자리 로짓만 출력하도록 합니다. 방정식 2에서 볼 수 있듯이, 학습하는 동안 출력 로짓과 실제 평가에 따라 평균 제곱 오차(MSE) 손실을 적용합니다.NLregression |N| Σ (logits dec = r²)².i=실험 우리는 다음의 연구 질문에 답하기 위해 광범위한 실험을 수행합니다.RQ1: 기성형 LLM이 제로샷 및 퓨샷 추천에 대해 좋은 성과를 보입니까?RQ2: 공정한 환경에서 LLM을 기존 추천자와 비교하면 어떻습니까?RQ3: 추천자에 사용할 때 LLM의 모델 크기는 얼마나 중요합니까?RQ4: LLM이 기존 추천자 모델보다 더 빨리 수렴합니까?4.4.1.데이터 집합 및 평가 설정 데이터 집합.사용자 평가 예측 작업을 평가하기 위해 추천에 대한 모델 성능을 평가하기 위해 널리 채택된 두 가지 벤치마크 데이터 집합을 사용합니다. 두 데이터 세트 모두 1~5점 범위의 사용자 리뷰 평점으로 구성되어 있습니다.• MovieLens[13]: 영화에 대한 100만 개의 사용자 평점이 포함된 MovieLens-1M 버전을 사용합니다.• Amazon-Books[21]: 항목에 대한 사용자 평점이 있는 Amazon Review Dataset의 &quot;Books&quot; 카테고리를 사용합니다.상호 작용이 5회 미만인 사용자와 항목을 필터링하는 5코어 버전을 사용합니다.ACMTab에 제출된 원고표 1. 데이터 세트의 통계 데이터 세트 사용자 수 Movielens-1M 6, Amazon-Books 1,850, 항목 수 3,483, 학습 예제 수 테스트 예제 수 882, 17, 566, 2,000(75,880) 2,000(2,324,503) W.-C. Kang, et al. 특징 제목, 장르 제목, 브랜드 4.1.2 학습/테스트 분할. 훈련 및 테스트 세트를 생성하기 위해 단일 시간 지점 분할[32]을 따릅니다. 먼저 메타데이터가 없는 항목과 관련된 평가를 필터링한 다음 모든 사용자 평가를 시간순으로 정렬합니다. 마지막으로 처음 90% 평가를 훈련 세트로 사용하고 나머지를 테스트 세트로 사용합니다. 각 훈련 예제는 튜플입니다.<user_id, item_id, item_metadata, rating > , 여기서 레이블은 5 Likert 척도 평가입니다. 입력 기능은 user_id, item_id 및 item_metadata 기능 목록입니다. 데이터 세트의 통계는 표 1에 나와 있습니다. LLM을 기반으로 한 제로샷 및 퓨샷 실험의 높은 계산 비용으로 인해 각 데이터 세트의 테스트 세트에서 무작위로 샘플링하여 2,000개의 튜플로 작은 테스트 세트를 만듭니다. 모든 실험에서 샘플링된 테스트 세트의 결과를 보고합니다. 그리고 훈련 및 평가 중에 사용자 시퀀스를 가장 최근의 10개 상호 작용으로 자릅니다. 4.1.3 평가 지표. 널리 채택된 지표인 RMSE(Root Mean Squared Error) 및 MAE(Mean Average Error)를 사용하여 평가 예측에 대한 모델 성능을 측정합니다. 또한 ROC-AUC를 사용하여 순위 매기기에 대한 모델의 성능을 평가합니다. 여기서 4 이상인 평가는 긍정적으로 간주되고 나머지는 부정적으로 간주됩니다. 이 경우 AUC는 모델이 긍정을 부정보다 더 높게 평가하는지 측정합니다.4.2 기준선 및 LLM 4.2.1 기준선.• 기존 추천 모델: 1. 행렬 분해(MF) [29], 2. 다층 퍼셉트론(MLP) [14]을 포함하여 여러 기존 추천 모델을 강력한 기준선으로 고려합니다.MF 및 MLP의 경우 사용자 ID와 항목 ID만 입력 기능으로 사용됩니다.• 속성 및 등급 인식 순차적 등급 예측 모델: 실험에서 제목 및 범주와 같은 과거 항목 메타데이터와 과거 등급을 LLM에 제공합니다.그러나 저희가 아는 한 이 설정에 맞게 설계된 기존 방법은 없습니다¹.공정한 비교를 보장하기 위해 LLM에 제공된 동일한 입력 정보를 효율적으로 처리하는 Transformer-MLP 모델을 구성합니다.세 가지 주요 설계 선택 사항이 있습니다.(i) 기능 처리: 모든 기능을 희소 기능으로 처리하고 임베딩을 종단 간에 학습합니다. 예를 들어, 장르에 대해 원핫 인코딩을 사용하고 i번째 행이 장르 i의 임베딩인 임베딩 테이블을 만듭니다.마찬가지로, 제목에 토크나이저²를 적용하여 백오브워드 인코딩을 얻은 다음 해당 임베딩을 찾습니다.(ii) 사용자 모델링: 각 사용자 동작에 대해 Add 또는 Concat을 사용하여 모든 임베딩(예: 항목 ID, 제목, 장르/카테고리, 평점)을 하나로 집계한 다음 학습된 위치 임베딩이 있는 양방향 셀프 어텐션[34] 계층을 채택하여 사용자의 과거 동작을 모델링합니다.SASRec과 유사하게 가장 최근 동작의 출력 임베딩을 사용자 요약으로 사용합니다.(iii) 평점 예측을 위한 사용자 및 후보 융합: 다른 후보 항목 피처와 함께 사용자 임베딩 위에 MLP를 적용하여 최종 평점 예측을 생성하고 MSE를 최소화하도록 최적화합니다. ¹가장 관련성이 높은 연구는 SASRec [16]과 CARCA [28]이지만, 이 두 연구는 평가 예측 대신 다음 항목 예측을 위해 설계되었기 때문에 우리의 사례에 직접 적용할 수 없습니다. 2https://www.tensorflow.org/text/api_docs/python/text/WhitespaceTokenizer ACM에 제출된 원고 LLM은 사용자 선호도를 이해하는가? 사용자 평가 예측에 대한 LLM 평가 표 2. 사용자 평가 예측 결과. 가장 성과가 좋은 방법은 각 열에 굵은 글씨로 표시하고 각 그룹에 밑줄을 긋습니다. 모델 MovieLens Amazon-Books RMSE↓ MAE↓ AUC↑ RMSE↓ MAE↓ AUC↑ Zero-Shot LLMS Flan-U-PALM ChatGPT text-davinci-1.0677 0.7740 0.7084 0.9565 0.5569 0.1.0081 0.8193 0.6794 1.1.0460 0.7850 0.6951 0.0.8093 0.0.5442 0.Few-Shot LLMs Flan-U-PALM ChatGPT text-davinci-1.0721 0.7605 0.7094 1.1.0862 0.8203 0.6930 1.1.0867 0.8119 0.6963 1.0.5855 0.0.7760 0.0.7753 0.간단한 데이터 집합 통계 글로벌 평균 평점 후보 항목 평균 평점 사용자 이전 평균 평가 감독 추천 방법 MF MLP Transformer+MLP 1.1564 0.9758 0.5 0.0.9749 0.7778 0.7395 0.1.0196 0.7959 0.7266 0.0.0.0.7078 0.0.5502 0.0.9552 0.7436 0.0.9689 0.7452 0.0.8848 0.7036 0.1.7960 1.1070 0.0.8607 0.6384 0.0.8143 0.5541 0.Fine-tuned LLMS Flan-T5-Base (분류) 1.0110 0.6805 0.7590 0.9856 0.4685 0.0.9187 0.7092 0.7949 0.8413 0.5317 0.0.8979 0.6986 0.8042 0.8301 0.5122 0.Flan-T5-Base(회귀) Flan-T5-XXL(회귀) 기준 모델을 적절히 조정하기 위해 하이퍼 매개변수 검색 공간(예: 임베딩 차원, 학습률, 네트워크 크기, Add 또는 Concat 집계 등)을 정의하고 블랙박스 하이퍼 매개변수 최적화 도구인 Vizier[9]를 사용하여 100회 이상의 검색 시도를 수행했습니다. • 휴리스틱: 우리는 또한 세 가지 휴리스틱 기반 기준선을 포함합니다: (1) 글로벌 평균 평점: (2) 후보 항목 평균 평점, (3) 사용자 과거 평균 평점, 즉 모델의 예측은 (1) 모든 사용자 항목 평점 중 평균 평점, (2) 후보 항목의 평균 평점 또는 (3) 과거 사용자의 평균 평점에 따라 달라집니다.4.2.2 제로샷 및 퓨샷 학습을 위한 LLM.우리는 제로샷 및 퓨샷 학습에 아래에 나열된 LLM을 사용했습니다.우리는 모든 LLM에 대해 0.1의 온도를 사용합니다.우리의 경우 LLM의 출력은 단순히 평점 예측이기 때문입니다.우리는 OpenAI [24]의 GPT 모델을 사용합니다: (i) text-davinci-003 (175B): 인간 피드백(RLHF)을 통한 강화 학습을 갖춘 가장 유능한 GPT-3 모델 [31]; (ii) ChatGPT: 기본 모델은 gpt-3.5-turbo이며, 인간이 작성한 데모와 RLHF에서 미세 조정되었으며 대화에 맞게 추가로 최적화되었습니다.Flan-U-PaLM(540B)은 [4]에서 가장 크고 강력한 모델로, PaLM[2]에서 FLAN 명령어 조정[39]과 UL2 학습 목표[4]를 모두 적용합니다.4.2.3 미세 조정을 위한 LLM.미세 조정 방법의 경우 실험에서 Flan-T5-Base(250M) 및 Flan-T5-XXL(11B) 모델을 사용합니다.학습률을 5e-5, 배치 크기를 64, 드롭아웃률을 0.1로 설정하고 모든 데이터 세트에서 50k 단계를 학습합니다.4.3 Zero-Shot 및 Few-shot LLM(RQ1) 표 2에서 볼 수 있듯이, 우리는 zero-shot 설정에서 여러 기성품 LLM에 대한 실험을 수행합니다. LLM은 프롬프트 설명에서 작업을 이해하고 합리적인 평가를 예측하는 것으로 나타났습니다. LLM은 대부분의 경우 글로벌 평균 평가를 능가하며 항목 또는 사용자 평균 평가와 비슷한 성과를 보입니다. 예를 들어, text-davinci-performs는 Movielens에서 후보 항목 평균 평가보다 약간 낮지만 Amazon-Books에서는 더 나은 성과를 보입니다. ACM RMSE2.1.1.04.3.53.RMSE AUC Flan-T5-XXL 0.Transformer+MLP 0.AUC 0.0.0.0.Flan-T5-XXL Transformer+MLP Training Epoch (a) MovieLens RMSE 4.4.3.3.2.2.1.1.RMSE W.-C. Kang, et al.에 제출된 원고의 경우 AUC 0.Flan-T5-XXL Transformer+MLP 0.0.AUC 0.0.0.0.0.Flan-T5-XXL Transformer+MLP 0.0.1.1.2.2.3.Training Epoch 0.0.1.1.2.2.3.Training Epoch (b) Amazon Books 그림 4. 데이터 효율성: 수렴 곡선. few-shot 실험의 경우 프롬프트(3-shot)에 3가지 예를 제공합니다. zero-shot과 비교했을 때 few-shot LLM의 AUC가 개선된 반면 RMSE와 MAE에는 명확한 패턴이 없습니다. 또한 zero-shot과 few-shot LLM 모두 상호 작용 데이터로 학습한 기존 추천 모델보다 성능이 떨어지는 것을 발견했습니다. 표 2에서 볼 수 있듯이 GPT-3 및 Flan-U-PaLM 모델은 지도 학습 모델에 비해 상당히 낮은 성능을 달성합니다. 낮은 성능은 LLM의 사전 훈련에서 사용자-항목 상호 작용 데이터가 부족하여 다양한 추천 작업에 대한 인간의 선호도에 대한 지식이 없기 때문일 수 있습니다.또한 추천 작업은 데이터 세트에 따라 크게 달라집니다.예: 같은 영화가 플랫폼마다 평균 평점이 다를 수 있습니다.따라서 데이터 세트별 통계를 알지 못하면 LLM이 모든 데이터 세트에 적합한 보편적인 예측을 제공하는 것은 불가능합니다.4.4 LLM 대 기존 추천 모델(RQ2) LLM 미세 조정은 데이터 세트 통계를 LLM에 공급하는 효과적인 방법이며 미세 조정 LLM의 성능이 0/few-shot LLM보다 훨씬 우수하다는 것을 발견했습니다.또한 분류 손실로 Flan-T5 기반 모델을 미세 조정할 때 세 가지 메트릭 모두에서 회귀 손실로 미세 조정하는 것보다 성능이 훨씬 나쁩니다.이는 LLM 미세 조정을 위해 올바른 최적화 목표를 선택하는 것이 중요함을 나타냅니다. 가장 강력한 기준 Transformer-MLP와 비교했을 때, 미세 조정된 Flan-T5-XXL이 더 나은 MAE와 AUC를 가지고 있는 것을 발견했는데, 이는 미세 조정된 LLM이 순위 지정 작업에 더 적합할 수 있음을 의미합니다. 4. 모델 크기의 효과(RQ3) 우리가 연구한 모든 LLM의 경우, 모델 크기가 250M에서 500B 매개변수로 다양하며, 제로샷 또는 퓨어샷 프롬프트를 사용하여 1~5 사이의 등급 예측을 출력할 수 있었습니다. 이는 이러한 LLM(Flan-T5, Flan-U-PaLM, GPT-3)이 프롬프트를 따를 수 있도록 하는 명령어 조정의 효과를 보여줍니다. 또한 그림 1에서 보듯이 크기가 100B보다 큰 LLM만이 제로샷 설정에서 평가 예측에서 상당히 좋은 성과를 거두는 것을 발견했습니다. 미세 조정 실험의 경우, 표 2의 마지막 두 행에 보듯이 Flan-T5-XXL이 두 데이터 세트 모두에서 Flan-T5-Base보다 성능이 뛰어난 것을 발견했습니다. 4.6 LLM의 데이터 효율성(RQ4) LLM은 사전 학습 중에 방대한 양의 세계 지식을 학습한 반면, 기존 추천 모델은 처음부터 학습하므로 그림 4에서 수렴 곡선을 비교하여 LLM의 데이터 효율성이 더 나은지 살펴봅니다. RMSE의 경우 두 방법 모두 ACM에 제출된 원고의 일부만으로 상당히 좋은 성능으로 수렴할 수 있음을 알 수 있습니다. LLM은 사용자 선호도를 이해하는가? 사용자 평가 예측에서 LLM 평가. 이는 모든 항목의 평균 평가도 RMSE가 비교적 낮기 때문일 수 있으며, 따라서 모델이 평균 평가에 가까운 평가를 예측하는 법을 배우는 한 상당히 좋은 성능을 달성할 수 있을 것입니다. AUC의 경우 추세가 더 명확합니다. 평균 평가를 예측하면 AUC가 0.5가 됩니다. LLM이 좋은 성과를 거두려면 소량의 데이터만 필요한 반면 Transformer+MLP는 수렴을 위해 훨씬 더 많은 훈련 데이터(최소한 에포크)가 필요합니다.
--- CONCLUSION ---
이 논문에서 우리는 세 가지 설정에서 사용자 평가 예측을 위한 추천 시스템으로서 대규모 언어 모델의 효과를 평가합니다. 1. 제로샷; 2. 퓨어샷; 3. 미세 조정. 기존의 추천 방법과 비교했을 때, 우리의 결과는 제로샷 및 퓨어샷 LLM의 LLM이 완전 지도 학습 방법보다 뒤떨어져 LLM에 대상 데이터 세트 분포를 통합하는 것이 중요함을 시사합니다. 반면, 미세 조정된 LLM은 주요 지표에서 신중하게 설계된 기준선과의 격차를 크게 줄일 수 있습니다. LLM 기반 추천자는 여러 가지 이점이 있습니다. (i) 더 나은 데이터 효율성; (ii) 기능 처리 및 모델링의 단순성: 다양한 종류의 정보를 처리하기 위해 기능 처리 전략, 임베딩 방법 및 네트워크 아키텍처를 수동으로 설계하지 않고도 정보를 프롬프트로 변환하기만 하면 됩니다. (iii) 대화형 추천 기능의 잠재력. 영어: 저희의 연구는 LLM 기반 추천 시스템의 현재 상태를 밝혀주며, 앞으로는 프롬프트 튜닝과 같은 방법을 통해 성능을 개선하고 LLM이 가능하게 한 새로운 추천 애플리케이션을 탐색할 것입니다.참고문헌 [1] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877–1901. [2] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: 경로를 통한 언어 모델링 확장. arXiv 사전 인쇄 arXiv:2204.02311 (2022). [3] Paul Francis Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg 및 Dario Amodei. 2017. 인간 선호도를 통한 심층 강화 학습. ArXiv ABS/1706.03741 (2017). [4] 정형원, Le Hou, S. Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Wei Yu, Vincent Zhao, Yanping Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov, Ed Huai hsin Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le 및 Jason Wei. 2022. Scaling Instruction-Finetuned 언어 모델. ArXiv ABS/2210.11416 (2022). [5] Zeyu Cui, Jianxin Ma, Chang Zhou, Jingren Zhou 및 Hongxia Yang. 2022. M6-Rec: 생성적 사전 학습된 언어 모델은 개방형 추천 시스템입니다.arXiv 사전 인쇄본 arXiv:2205.08084(2022). [6] Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. 2018. Bert: 언어 이해를 위한 딥 양방향 변환기의 사전 학습.arXiv 사전 인쇄본 arXiv:1810.04805(2018). [7] Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang, Jiawei Zhang. 2023. Chat-REC: 대화형 및 설명 가능한 LLM을 향한 증강 추천 시스템.arXiv 사전 인쇄본 arXiv:2303.14524(2023). [8] Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, Yongfeng Zhang. 2022. 언어 처리(RLP)로서의 권장 사항: 통합 사전 학습, 개인화된 프롬프트 및 예측 패러다임(P5). arXiv 사전 인쇄본 arXiv:2203.13366(2022). [9] Daniel Golovin, Benjamin Solnik, Subhodeep Moitra, Greg Kochanski, John Karro, D. Sculley. 2017. Google Vizier: 블랙박스 최적화를 위한 서비스. 2017년 8월 13일-17일, 캐나다 노바스코샤 주 핼리팩스에서 열린 제23회 ACM SIGKDD 지식 발견 및 데이터 마이닝 국제 컨퍼런스 회의록. ACM, 1487-1495. 한국어: https://doi.org/10.1145/3097983.[10] Google. 2023. Bard: Google AI의 대규모 언어 모델. https://bard.google.com/ [11] Shuguang Han, Xuanhui Wang, Mike Bendersky, and Marc Najork. 2020. TF-Ranking에서 BERT를 사용한 순위 학습. arXiv:2004.08476 [cs.IR] [12] F Maxwell Harper and Joseph A Konstan. 2015. movielens 데이터 세트: 이력 및 맥락. ACM 대화형 지능형 시스템(tiis) 거래 5, 4(2015), 1-19. [13] F. Maxwell Harper and Joseph A. Konstan. 2016. MovieLens 데이터 세트: 이력 및 맥락. ACM Trans. Interact. Intell. Syst. 5 (2016), 19:1–19:19. [14] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua. 2017. 신경 협력 필터링. 2017년 4월 3-7일, 호주 퍼스에서 열린 제26회 월드 와이드 웹 국제 컨퍼런스(WWW 2017)의 회의록에서 Rick Barrett, Rick Cummings, Eugene Agichtein, Evgeniy Gabrilovich(편). ACM, 173–182. https://doi.org/10.1145/3038912. ACMW-C. Kang 등에 제출된 원고. [15] Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, Domonkos Tikk. 2015. 순환 신경망을 사용한 세션 기반 권장 사항. arXiv 사전 인쇄 arXiv:1511.06939 (2015). [16] 강왕청(Wang-Cheng Kang)과 줄리안 맥컬리(Julian McAuley). 2018. 자기 주의적 순차 추천. 2018년 IEEE 데이터마이닝 국제회의(ICDM)에서. IEEE, 197-206. [17] Junyang Lin, Rui Men, An Yang, Chang Zhou, Ming Ding, Yichang Zhang, Peng Wang, Ang Wang, Le Jiang, Xianyan Jia 등. 2021. M6: 중국 다중 모드 프리트레이너. arXiv 사전 인쇄 arXiv:2103.00823(2021). [18] Junling Liu, Chao Liu, Renjie Lv, Kang Zhou 및 Yan Zhang. 2023. ChatGPT는 좋은 추천인가요? 예비 연구.arXiv:2304.10149 [cs.IR] [19] Yang Liu 및 Mirella Lapata.2019. 사전 학습된 인코더를 사용한 텍스트 요약.arXiv:1908.08345 [cs.CL] [20] Microsoft.2023. 새로운 AI 기반 Bing 및 Edge로 검색을 재창조, 웹의 조종사.https://news.microsoft.com/the-new-Bing/ [21] Jianmo Ni, Jiacheng Li 및 Julian McAuley.2019. Distantly-Labeled Reviews 및 Fine-Grained Aspects를 사용하여 권장 사항 정당화.자연어 처리의 경험적 방법에 대한 컨퍼런스에서.[22] OpenAI.2022. 지침을 따르도록 언어 모델 정렬.https://openai.com/research/instruction-following.[23] OpenAI. 2022. ChatGPT 소개. https://openai.com/blog/chatgpt. [24] OpenAI. 2023. GPT 모델 문서. https://platform.openai.com/docs/models/overview [25] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever 외. 2019. 언어 모델은 비지도 멀티태스크 학습기입니다. OpenAI 블로그 1, 8(2019), 9. [26] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu. 2020. 통합 텍스트-텍스트 변환기를 사용하여 전이 학습의 한계 탐색. J. Mach. Learn. Res. 21, 1, Article 140(2020년 1월), 67페이지. [27] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu. 2020. 통합 텍스트-텍스트 변환기를 사용하여 전이 학습의 한계 탐색. The Journal of Machine Learning Research 21, 1(2020), 5485-5551. [28] Ahmed Rashed, Shereen Elsayed, Lars Schmidt-Thieme. 2022. CARCA: CrossAttention을 통한 컨텍스트 및 속성 인식 다음 항목 권장 사항. arXiv 사전 인쇄본 arXiv:2204.06519(2022). [29] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner 및 Lars Schmidt-Thieme. 2012. BPR: 암묵적 피드백에서 베이지안 개인화 순위. arXiv 사전 인쇄본 arXiv:1205.2618(2012). [30] Noah Shinn, Beck Labash 및 Ashwin Gopinath. 2023. Reflexion: 동적 메모리와 자기 반성을 갖춘 자율적 에이전트. arXiv 사전 인쇄본 arXiv:2303.11366(2023). [31] Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M. Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei 및 Paul F. Christiano. 2020. 인간 피드백에서 요약하는 법 학습. CoRR abs/2009.01325(2020). arXiv:2009.01325 https://arxiv.org/abs/2009.[32] 아이신 선. 2022. 평가 관점에서 추천 시스템을 새롭게 살펴보세요. [33] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar 등. 2023. Llama: 개방적이고 효율적인 기초 언어 모델. arXiv 사전 인쇄 arXiv:2302.13971 (2023). [34] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser 및 Illia Polosukhin. 2017. 주의만 있으면 됩니다. 신경 정보 처리 시스템의 발전 30(2017). [35] Lei Wang 및 Ee-Peng Lim. 2023. 대규모 사전 학습된 언어 모델을 사용한 Zero-Shot Next-Item 추천. arXiv 사전 인쇄본 arXiv:2304.(2023). [36] Qiang Wang, Bei Li, Tong Xiao, Jingbo Zhu, Changliang Li, Derek F. Wong 및 Lidia S. Chao. 2019. 기계 번역을 위한 딥 트랜스포머 모델 학습. arXiv:1906.01787 [cs.CL] [37] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery 및 Denny Zhou. 2023. 자기 일관성은 언어 모델에서 사고의 사슬 추론을 개선합니다. arXiv:2203.11171 [cs.CL] [38] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Denny Zhou. 2022. 자기 일관성은 언어 모델에서 사고의 사슬 추론을 개선합니다. arXiv 사전 인쇄본 arXiv:2203.11171(2022). [39] Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, Quoc V. Le. 2022. 미세 조정된 언어 모델은 제로샷 학습자입니다. 제10회 학습 표현 국제 컨퍼런스, ICLR 2022, 가상 이벤트, 2022년 4월 25-29일. OpenReview.net. https://openreview.net/forum?id=gEZrGCozdqR [40] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean 및 William Fedus. 2022. 대규모 언어 모델의 새로운 능력. arXiv:2206.07682 [cs.CL] [41] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le 및 Denny Zhou. 2022. 생각의 연쇄 자극은 대규모 언어 모델에서 추론을 이끌어냅니다. arXiv 사전 인쇄 arXiv:2201.11903 (2022). [42] Jiacheng Yang, Mingxuan Wang, Hao Zhou, Chengqi Zhao, Weinan Zhang, Yong Yu 및 Lei Li. 2020. 신경 기계 번역에서 bert를 최대한 활용하는 방향으로. 인공 지능에 관한 AAAI 회의 진행 중, Vol. 34. 9378-9385. [43] Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin 등. 2022. Opt: 사전 훈련된 변환기 언어 모델을 공개합니다. arXiv 사전 인쇄 arXiv:2205.01068 (2022). [44] Yuhui Zhang, Hao Ding, Zeren Shui, Yifei Ma, James Zou, Anoop Deoras 및 Hao Wang. 2021. 추천 시스템으로서의 언어 모델: 평가 및 한계. (2021). ACM에 제출된 원고 LLM이 사용자 선호도를 이해하는가? 사용자 평가 예측에 대한 LLM 평가[45] Lixin Zou, Shengqiang Zhang, Hengyi Cai, Dehong Ma, Suqi Cheng, Shuaiqiang Wang, Daiting Shi, Zhicong Cheng, Dawei Yin. 2021. Baidu 검색에서 사전 학습된 언어 모델 기반 순위. 제27회 ACM SIGKDD 지식 발견 및 데이터 마이닝 컨퍼런스(가상 이벤트, 싱가포르)(KDD &#39;21) 회의록에서. Association for Computing Machinery, 뉴욕, 뉴욕, 미국, 4014-4022. https://doi.org/10.1145/3447548. ACM에 제출된 원고
