--- ABSTRACT ---
기존의 대화 상태 추적(DST) 문제는 사용자 에이전트 대화에서 사용자 선호도와 의도를 추적하는 것을 목표로 합니다. 좁은 도메인 애플리케이션을 지원하는 작업 지향 대화 시스템에는 충분하지만, LLM(Large Language Model) 기반 채팅 시스템의 등장으로 인해 오픈 도메인 대화에 많은 실제 복잡성이 도입되었습니다. 이러한 복잡성은 맥락적 상호 작용의 복잡성 증가, 다양한 주제를 아우르는 확장된 대화 세션, 더 빈번한 맥락적 변화의 형태로 나타납니다. 진화하는 LLM 기반 채팅 시스템에서 발생하는 이러한 복잡성을 처리하기 위해 오픈 도메인 대화 시스템에서 세그먼트당 공동 대화 분할 및 상태 추적을 제안합니다. 진정한 오픈 도메인 대화 시스템에 적합한 제로샷 설정을 가정하여, 긴 맥락 추적을 개선하기 위해 설계한 새로운 접지 메커니즘인 사전 분석 기억(Pre-Analytical Recollection)을 활용하는 구조화된 프롬프트 기술인 S3-DST를 제안합니다. 공동 세분화 및 상태 추적에서 제안된 접근 방식의 효능을 입증하기 위해 독점적인 익명화된 오픈 도메인 대화 데이터 세트와 공개적으로 사용 가능한 DST 및 세분화 데이터 세트에서 S3-DST를 평가합니다. 모든 데이터 세트와 설정에서 S3-DST는 최첨단 기술을 지속적으로 능가하여 차세대 LLM 기반 채팅 시스템의 효능과 견고성을 입증합니다. 1
--- INTRODUCTION ---
ChatGPT 및 Bing Chat과 같은 오픈 도메인 대규모 언어 모델(LLM) 기반 채팅 시스템의 출현으로 대화 시스템의 새로운 시대가 열렸습니다. 이전에는 대화 시스템이 범위와 기능이 비교적 제한되어 일반적으로 좁은 작업 중심 대화나 소셜 잡담에 국한되었습니다(Gao et al., 2018). 반면 LLM 기반 채팅 시스템은 겉보기에 무한한 주제에 대해 사용자와 유연하게 대화할 수 있고 다음을 수행할 수 있기 때문에 주목할 만합니다. 사용자: 주석이 달린 참고 문헌을 만들어 주세요... AI: 주석이 달린 몇 가지 예는 다음과 같습니다... 사용자: 이러한 인용 스타일을 설명해 주시겠습니까? AI: 물론입니다. 인용 스타일은 다음과 같은 집합... ... 사용자: 감사합니다! 오늘은 어떻게 지내세요? AI: 지금까지 좋은 하루를 보내고 있습니다. 감사합니다... 사용자: 다음 주 날씨는 어때요? AI: 내 검색 결과에 따르면... 그림 1: 오픈 도메인 대화에서 하나의 의도는 여러 턴에 걸쳐 있을 수 있으며, 하나의 대화는 여러 의도를 포함할 수 있습니다.익명화된 Bing Chat 로그에서 영감을 얻은 합성 대화.다른 사용자 의도(주석이 달린 참고 문헌 작성, 소셜 잡담, 날씨 확인)는 다른 색상으로 강조 표시됩니다.이전에 코드 생성, 질의 응답 등과 같이 특수 시스템이 필요했던 많은 사용자 작업이 즉시 사용 가능합니다.이 논문에서는 LLM 기반 채팅 시스템이 인간-AI 대화의 환경을 크게 바꾸었기 때문에 이러한 대화에서 사용자 의도를 이해하려면 새로운 분석 및 태그 지정 프레임워크가 필요하다고 주장합니다.특히 대화 상태 추적(DST) 작업에 중점을 둡니다.기존 DST는 작업 지향 대화 시스템에서 사용자의 의도를 추출하여 구조화된 백엔드 스키마(Williams et al., 2016; Budzianowski et al., 2018)와 일치시키는 것으로 구성됩니다.그러나 오픈 도메인 대화의 DST는 아직 정의되지 않았습니다. 따라서 이 논문에서 우리는 LLM 기반 채팅 시스템에서 관심 있는 상태 값을 식별하는 첫 번째 시도를 합니다. 그림 1에서 예시된 것처럼, 우리는 실제 오픈 도메인 대화가 종종 단일 의도나 주제를 추구하기 위해 당사자 간에 광범위한 왕복(예: 설명, 협상 등)을 보이며, 맥락은 관련 없는 의도 및/또는 주제 사이에서 단일 대화 내에서 여러 번 바뀔 수 있다는 주요 관찰을 합니다. 이러한 관찰을 바탕으로, 우리는 오픈 도메인 대화에서 세그먼트와 상태를 모두 추적할 것을 제안합니다. 세분화는 맥락적으로 응집된 대화 &quot;단위&quot;의 시작과 끝을 표시하는 경계를 식별하는 데 도움이 되는 반면, 상태는 세그먼트별로 적용되는 우리가 추적하고자 하는 관심 있는 의도 변수입니다. DST를 오픈 도메인 대화와 LLM 시대로 끌어들이는 것 외에도, 우리는 오픈 도메인 DST를 위한 LLM 기반 솔루션을 소개합니다. 레이블링 비용 때문에 현실적인 대화 태그 지정에 대한 제로샷 설정을 가정하여, 우리는 오픈 도메인 DST를 위한 구조화된 프롬프트 접근 방식인 S3-DST를 소개합니다. S3-DST 내에서 우리는 각 출력 상태 예측을 해당 대화 턴의 내용에 기반하는 새로운 사전 분석 기억(PAR) 프롬프트 전략을 제안하여 LLM이 잊거나 환각 없이 긴 대화 맥락을 추적할 수 있도록 돕습니다. 우리는 공개 DST 및 세분화 벤치마크와 함께 Microsoft의 Bing Chat 시스템에서 수집한 완전히 익명화된 오픈 도메인 대화 데이터 세트에서 S3-DST를 평가합니다.¹ S3-DST 모든 벤치마크에서 비슷한 기준선에 비해 큰 성과를 거두어, 오픈 도메인 대화 모델링에 대한 추가 연구를 위한 시작점으로 적합함을 시사합니다. 요약하자면, 우리의 기여는 다음과 같습니다. • 오픈 도메인 DST 문제 정의: 우리는 대화 상태 추적을 오픈 도메인 LLM 채팅 시대로 가져왔습니다. 우리는 익명화된 Bing Chat 로그 데이터에서 실제 오픈 도메인 인간-AI 대화가 어떻게 수행되는지에 대한 관찰에서 동기를 얻어 문제를 공동 분할 및 상태 추적 작업으로 규정했습니다. • 제로샷 S3-DST 접근 방식: 우리는 오픈 도메인, 다중 의도 대화를 위한 구조화된 제로샷 공동 분할 및 상태 추적 접근 방식인 S3-DST를 제안합니다. S3-DST는 구조화된 프롬프트 템플릿 및 대화 태그 생성을 위한 새로운 접근 방식과 긴 컨텍스트 추적을 개선하는 기반 기술인 사전 분석 기억(PAR)을 제공합니다. • 광범위한 실험 및 분석: 우리는 독점 및 공개 데이터 세트에 대한 광범위한 실험을 수행하여 비슷한 제로샷 프롬프트에 비해 큰 성과를 거두었습니다. S3DST는 최첨단 제로샷 per&#39;Bing Chat 로그를 사용하는 것은 DialSeg711 대화 주제 세분화 벤치마크와 함께 MWOZ 2.1 및 2.4 DST 벤치마크에서 조건을 준수합니다.2 문제 정의 비공식적으로, 기존 DST의 목표는 사용자와 에이전트의 발화 턴 시퀀스 C₁ = [U₁, A1, ..., Ut, At]²이 주어진 대화 상태 yt를 예측하는 것입니다.상태 yt는 슬롯-값 쌍의 집합으로 구성되며, 여기서 슬롯은 특정 애플리케이션 도메인의 의도 속성(예: &quot;레스토랑 이름&quot;, &quot;호텔 주소&quot;)에 해당하고 값은 미리 정의된 범주형 옵션 또는 제한 없는 텍스트(Budzianowski et al., 2018)에 해당합니다. 그러나 앞서 논의했듯이 단일 오픈 도메인 대화는 종종 다양한 주제에 걸쳐 잠재적으로 관련성이 없는 여러 의도로 구성됩니다. 실제로 10,000개의 익명화된 Bing Chat 대화에 대한 예비 분석에 따르면, 대화의 50% 이상이 여러 사용자 의도를 표시하고 대화의 90% 이상이 여러 주제에 대한 토론을 포함한다고 추정합니다. 따라서 대화 분할을 병합하여 더 큰 대화 내에서 맥락적으로 응집력 있는 &quot;대화 단위&quot;를 찾는 것을 목표로 하며, 대화 상태 추적을 제안합니다. 특히, 세그먼트 수준에서 상태 추적을 수행하는데, 여기서 목표는 각 세그먼트에 관심 있는 슬롯과 값으로 레이블을 지정하여 대화 내의 여러 세그먼트가 발산하거나 상충되는 상태 값을 가질 수 있도록 하여 오픈 도메인 채팅의 진정한 다양성을 반영하는 것입니다. 이 섹션의 나머지 부분에서는 분할과 상태를 정의하고 마지막으로 공동 작업을 공식화합니다. 2.1 세그먼트 대화 주제 분할(Xing 및 Carenini, 2021; Xia 등, 2022; Gao 등, 2023)에 대한 이전 연구에 따라 대화 세그먼트를 모든 사용자 및 에이전트 발화가 주제적으로 관련된 Ct의 연속된 하위 시퀀스로 정의합니다. 형식적으로 B₁ = [b₁,……., bt−[b₁, … …. …, bt−]는 Ct에서 인접한 사용자-에이전트 발화 쌍 사이의 경계 인덱스를 나타냅니다. 분할의 출력은 경계 인덱스 Bk C BŁ의 집합입니다. 여기서 k는 분할 알고리즘에 의해 결정된 경계 수와 Bing Chat 사용에 대한 범위 [Um, Am, . . . Un, An]을 나타냅니다. 2현재 LLM 기반 채팅 시스템에서는 사용자가 단일 에이전트 응답이 발행되기 전에 여러 발화를 발행할 수 있습니다. 이러한 (드물게) 경우에 우리는 에이전트 응답 이전의 모든 사용자 발화를 단일 발화로 그룹화합니다. 경계 bm과 bn 사이의 연속된 세그먼트를 보냅니다. 여기서 m = [1, t − 1] 및 n ≤ [m, t − 1]. 2.2 세그먼트 상태 일반적으로 대화 상태 추적 방법은 각 턴에서 상태의 새로운 요소를 추출합니다(Hu et al., 2022). 그러나 이는 DST 평가 벤치마크가 사용자가 각 턴에서 새롭고 관련성 있는 의도 요소를 제공하고 의도가 서로를 기반으로 하거나 보완하지만 대화 전체에서 근본적으로 변경되거나 충돌하지 않는다는 비교적 좁은 가정을 하기 때문입니다. 이전에 논의했듯이 오픈 도메인 대화는 훨씬 더 다양한 특성을 보이며 다중 의도 및/또는 다중 도메인 대화가 비교적 일반적입니다. = 따라서 턴 수준이 아닌 세그먼트에서 상태를 추출할 것을 제안합니다. 세그먼트 수준 상태를 {Sm:n = (smin, vmn), i 1... Nm:n}으로 정의합니다. 여기서 son은 경계 bm에서 bn까지의 세그먼트에 적용된 i번째 슬롯을 나타냅니다. (i) vm:n은 슬롯의 해당 값을 나타내고 Nm:n은 이 세그먼트에 적용된 슬롯의 총 수를 나타냅니다. 슬롯 값 쌍의 스키마는 여기에서 유효합니다. § 4.1과 부록 B에서 Bing Chat에 대한 특정 상태 스키마를 설명합니다. 2.3 문제 설명 세그먼트와 세그먼트별 상태를 정의했으므로 오픈 도메인 DST에 대한 전체 정의를 설명할 수 있습니다. 사용자-에이전트 발화 쌍 C₁ = [U₁, A1, ..., Ut, At]의 시퀀스가 주어지면 오픈 도메인 대화 상태 추적의 목표를 Yt = Bk U {Sm:n; V(bm, bn) Є Bk}, (1) 여기서 Bk C Bt는 이전에 설명한 세그먼트 경계 인덱스를 나타내고 Sm:n은 경계 bm과 bn 사이의 세그먼트 상태를 나타내며, 이는 N개의 임의의 슬롯 값 쌍으로 구성됩니다. Sm:n = {(s):n, v(n), i = 1 . . . Nm:n}. (2) 3가지 프롬프트 전략 이전에 논의했듯이 실제 대화는 종종 다양한 주제를 논의하기 위해 여러 대화 턴에 걸쳐 확장되는 광범위한 담론을 보입니다. 이러한 장기간의 대화적 특성으로 인해 문맥적 일관성을 추적하기가 매우 어렵습니다. 이전 연구(Hu et al., 2022)는 개별 대화 턴을 분리하고 대화 상태 변경을 추적하기 위해 하나씩 처리하는 것을 목표로 했으며, 이는 미리 정의된 좁은 도메인에 국한된 작업 지향 대화에서 상당히 잘 작동했습니다. 그러나 실제 대화는 일반적으로 문맥적 뉘앙스를 적절히 이해하기 위해 여러 차례의 전환이 필요한데, 이는 Transformers가 특히 중간에 긴 입력 맥락을 처리할 때 여전히 어려움을 겪기 때문에 어려운 문제입니다(Liu et al., 2023). 이러한 어려움을 해결하기 위해 입력과 출력에 구조를 제공하면서 프로세스의 맥락을 정확하게 보존하는 새로운 차례별 프롬프트 기술을 제안합니다. 아래에서 프롬프트의 이러한 디자인 측면에 대해 설명합니다. 3. 구조화된 출력 및 입력 구조화된 출력 목표는 세그먼트 경계(바이너리 레이블)와 상태 값(범주형 레이블 또는 오픈 텍스트)을 나타내는 대화 차례당 레이블 집합입니다. LLM의 출력에 유연하면서도 구조화된 형식을 제공하기 위해 계층적 XML 형식으로 출력을 생성하도록 지시하는 것을 제안합니다. 우리는 XML이 DST 작업에 코드와 같은 구조를 제공하기 때문에 유리하다고 생각합니다. 이는 일반 텍스트 출력에 비해 성능을 크게 향상시키는 것으로 나타났으며, SQL과 같은 보다 엄격한 출력 형식에 비해 확장 가능하고 유연합니다(Hu et al., 2022). 우리의 접근 방식은 1에서 t까지의 각 턴이 XML 트리를 구성하는 XML 형식을 사용합니다.<T{id}> ...</T{id}> 그리고 그 안에 여러 개의 중첩된 XML 태그가 있습니다. 이러한 중첩된 태그의 레이블(예:<preceding_topical_relation> ...</preceding_topical_relation> ,<intent> ...</intent> , 그리고<domain> ...</domain> 그림 2(iii))는 세그먼트 경계와 관심 슬롯을 나타내며, 여는 태그와 닫는 태그 사이의 각 값은 모델의 추론된 값을 나타냅니다. 이 전략은 두 가지 측면에서 유익합니다. (i) 경계가 있는 잘 정의된 구조화된 형식으로 인해 생성된 출력은 자유형 텍스트보다 레이블 지정 지침과 일치할 가능성이 더 높고 (ii) 잘 구성된 구조화된 출력 형식은 구문 분석하기가 더 쉬워 후처리 요구 사항이 줄어듭니다. 구조화된 입력 LLM을 프롬프트하는 경우 분석 및 추론을 위해 일반 대화 기록을 평면 형식으로 채널링하는 것은 사소한 일이지만 이 선형 구성에 내재된 비구조적 특성으로 인해 참조하고 활용하기 어렵습니다. 원시 대화 사용자: 주석이 달린 참고 문헌을 제공하세요... AI: 다음은 몇 가지 다른 참고 문헌입니다... 사용자: (i) 대화와 지침을 구조화된 프롬프트 템플릿에 삽입<valid preceding_topical_relation><item><name> 예</name><description> ...</description></item></valid_preceding_topical_relation><valid intents><item> ...</item></valid_intents> ## 대화 (iii) 생각의 사슬을 통해 구조화된 차례차례 대화 태그를 생성합니다.<T1><summary> 사용자는 주석이 달린...을 요청합니다.</summary><preceding_topical_relation> 아니요</preceding_topical_relation><intent> 창조</intent><domain> 저널리즘 쓰기와 출판</domain> 법학 석사</T1><T2> 일체 포함:<T1><User> ...을 제공해 주세요.</User><AI> 여기에 몇 가지 예가 있습니다...</AI></T1><T2><summary> ...</summary><preceding_topical_relation> ...</preceding_topical_relation><intent> ...</intent> &#39;<domain> ...</domain></T2> 구조화된 턴<User> ...</User><AI> ...</AI></T2> (ii) 사전 분석 기억(PAR) 각 턴에서 출력을 근거로 컨텍스트 보존 그림 2: S3-DST의 프롬프트 흐름. 원시 대화가 주어지면 (i) 계층적 XML 구조 표현으로 변환하여 유사하게 구조화된 프롬프트 템플릿에 삽입합니다. 프롬프트를 LLM에 전달하고 (ii) 계층적 XML 구조 출력을 얻습니다. 여기서 각 턴에는 (iii) 원하는 세분화 및 상태 레이블 예측과 함께 대화에 대한 PAR 근거 참조가 포함됩니다. 여러 대화 턴에서 다른 정보를 연령화합니다. 출력 형식과 일관되게 이 과제를 처리하기 위해 각 대화 내역이 계층적 XML 형식으로 형성되고 대화 턴이 턴 ID 번호로 표시되는 구조화된 입력 형식을 제안합니다.<T{id}> ...</T{id}> 1에서 t까지 번호가 매겨지고 각 대화 차례는 적절한 XML 태그로 표시된 중첩된 사용자 및 에이전트 차례로 구성됩니다.<user> ...</user> 그리고<agent> ...</agent> ). 출력 중에 턴당 레이블을 추론하도록 LLM에 지시하는 것을 제안하기 때문에 이 입력 체계는 입력 턴을 정확하게 참조하고 긴 대화 맥락에서도 일관성을 유지하는 데 도움이 됩니다. 이 XML 태그 입력 형식과 일관되게 다음 구조를 사용하여 XML 형식 목록에서 모든 유효한 세그먼트 및 상태 범주를 형식화합니다.<valid_category_name><item> {라벨 이름}</item><description> {라벨 설명(있는 경우)}</description><valid_category_name> 경험적으로, 이 구조화된 입력 및 프롬프트 형식은 LLM 생성이 레이블 지정 지침을 따르도록 제한하는 데 도움이 됩니다. 그림 2(i)는 각 유효한 세그먼트 경계와 상태 범주가 먼저 XML 형식의 목록에서 준비되고 이어서 입력 대화가 계층적 구성으로 표시되는 이 형식을 보여줍니다. 3. 사전 분석 기억(PAR) 이전에 논의했듯이, 오픈 도메인 대화는 길고 대화 흐름이 매우 다양할 수 있습니다. 따라서 LLM이 잊거나 환각하지 않고 진화하는 대화 맥락을 정확하게 모니터링할 수 있도록 하는 것이 중요합니다. 이를 위해, 우리는 LLM이 먼저 다음을 사용하여 차례를 요약하도록 지시하는 차례 차례 프롬프트를 위한 기초 전략인 사전 분석 기억(PAR)을 제안합니다.<summary> ...</summary> 영어: 세그먼트 및 상태 값을 제공하기 전에 3개 이하의 문장으로 태그를 지정합니다.PAR은 추론 정확도를 개선하기 위해 관련 중간 출력을 생성하는 기술이기 때문에 사고의 사슬 프롬프트(Wei et al., 2022)에서 영감을 받았습니다.그러나 사고의 사슬과 달리 PAR은 모델의 출력에서 대화에 직접 참조를 제공하는 접지 기술이기도 합니다.그림 2(ii)는 PAR이 대화 상태를 추론하기 위해 분석하기 전에 각 대화 차례의 내용을 다시 참조하는 방법을 보여줍니다.3.3 최종 프롬프트 구성 S3-DST의 최종 프롬프트 흐름은 그림 2에 나와 있습니다.원시 대화와 미리 정의된 세그먼트 및 상태 레이블 집합이 주어지면 레이블을 구조화된 프롬프트 템플릿에 삽입하고 대화를 계층적 XML 구조 표현으로 포맷합니다.프롬프트를 LLM으로 전달하여 PAR을 따르도록 지시한 다음 공동으로 표 1: 평가 테스트 집합 통계. # 전환 # 회전 # 세그먼트/전환 Bing ChatMWOZ 2.1, MWOZ 2. DialSeg1, (평균) 1.3. 세그먼트별로 적용되는 계층적 턴바이턴 분할 및 상태 레이블을 생성합니다. 프롬프트의 전체 텍스트는 부록 A.1에 제공됩니다. 4 실험 여러 데이터 세트에 대해 포괄적인 평가를 수행합니다. 주로 도메인 전문가가 주석을 단 완전히 익명화된 Bing Chat 로그에 대한 접근 방식을 평가합니다. 또한 공개 벤치마크 데이터 세트 MultiWOZ(Budzianowski et al., 2018) 및 DialSeg(Xu et al., 2021)를 사용하여 표준 작업 지향 DST 및 분할 작업에서 S3-DST를 평가합니다. 이러한 데이터 세트에 대한 자세한 설명은 표 1의 데이터 세트 통계와 함께 아래에 제공됩니다.4. 내부 인간-LLM 대화 데이터 세트 실제 오픈 도메인 인간-LLM 대화에 대한 접근 방식의 효능을 평가하기 위해 Bing 검색 엔진이 지원하는 LLM 채팅 인터페이스인 Microsoft의 Bing Chat 시스템에서 익명화된 채팅 로그 데이터를 수집했습니다.벤치마크 구축 2023년 4월 5일부터 2023년 4월 30일까지 Bing Chat에서 진행된 484개의 영어 대화를 두 가지 접근 방식을 통해 샘플링합니다.(i) 무작위 및 (ii) 5턴 이상인 &quot;긴&quot; 대화. 이 두 가지 접근 방식을 50/50으로 균형 있게 조정합니다. 제로샷 가정에서 작동하므로 학습 데이터가 필요하지 않습니다. 따라서 개발을 위해 150개의 대화를 유지하고 나머지 334개를 테스트용으로 유지합니다.주석 평가를 위한 기준 진실 레이블을 얻기 위해 세그먼트 및 상태에 대한 인간 주석을 수집했습니다. 우리는 Bing Chat 시스템에 대한 높은 수준의 기술적 전문성과 친숙함을 갖춘 사내 주석자 3명을 모집했습니다. 각 턴에 대해 주석자에게 이진 IsSegmentBoundary 레이블, 범주형 SegmentIntent 레이블, 범주형 SegmentDomain 레이블을 제공하도록 지시했습니다. 턴과 이전 컨텍스트 간의 주제적 관계를 식별할 수 없는 경우 주석자에게 세그먼트 경계를 표시하도록 지시했습니다. 의도와 도메인의 경우 Bing Chat 시스템을 위해 사내에서 개발한 택소노미를 사용했는데, 여기에는 4개의 의도(정보 탐색, 분석, 생성 및 개방형 발견)와 49개의 도메인이 포함됩니다(전체 목록은 부록 B.1 참조). 도메인 수가 많기 때문에 턴당 주석자에게 4개의 후보 도메인 값과 &quot;기타&quot; 옵션을 제공했습니다. 부록 B에는 주석 체계와 도메인 샘플링 절차에 대한 자세한 내용이 나와 있습니다. 전체 데이터 세트에 레이블을 지정하기 전에 주석자 간 일치를 보장하기 위해 먼저 무작위로 선택한 10개의 대화(총 68개의 턴)에 대한 주석을 수집하고 레이블 유형별로 Fleiss 카파(Fleiss, 1971)를 계산했습니다. IsSegmentBoundary의 경우 k = 0.83, SegmentIntent의 경우 k = 0.74, SegmentDomain의 경우 K = 0.88의 Fleiss 카파를 관찰했는데, 이는 모두 Fleiss 카파 척도에서 높은 일치로 간주됩니다. 4.2 공개 벤치마크 광범위하게 오픈된 도메인인 Bing Chat 데이터를 반영하는 기존의 공개 대화 벤치마크는 알려진 바가 없습니다. 따라서 세 가지 데이터 세트를 사용하여 공개 벤치마크에서 별도의 DST 및 세분화 평가를 수행합니다. MultiWOZ MultiWOZ(MWOZ) 다중 도메인 대화 데이터 세트(Budzianowski et al., 2018)는 현재 가장 일반적인 DST 벤치마크입니다. MWOZ는 1,000개의 테스트 대화로 구성된 작업 지향 데이터 세트입니다. 저희는 원본의 두 가지 업데이트된 버전인 MWOZ 2.1(Eric et al., 2019)과 2.4(Ye et al., 2021)를 사용합니다. 후자는 MWOZ의 &quot;가장 깨끗한&quot; 버전으로 간주되는 반면 전자는 문헌에서 더 자주 사용되었습니다. DialSeg711 DialSeg711 벤치마크는 (Xu et al., 2021)에 의해 도입되었으며 최근 대화 분할 연구에 자주 사용되었습니다. 기존 작업 지향 대화 코퍼스에서 대화를 결합하여 711개의 다중 세그먼트 대화를 구성하는 영어 데이터 세트입니다. 4.3 기준선 저희는 S3-DST와의 공정한 비교를 위해 제로샷 LLM 프롬프트만 기준선으로 고려합니다. 저희는 아래에서 다양한 데이터 세트에 대한 기준선과 고려 사항을 논의합니다. 모든 원래 프롬프트는 부록 A에 제공됩니다. LLM 호출당 최대 1500개의 출력 토큰을 설정했으며 온도는 0입니다. 표 2: S3-DST는 내부 Bing Chat 벤치마크에서 상태 추적에 대한 최첨단 성능을 달성합니다. 모든 프롬프트는 GPT4로 실행됩니다. 개별 정확도 JGA 세그먼트 의도 도메인 I/DS/I/D TBT-DST 0.0.0.IC-DST 0.0.0.0.4610 0.S3-DST(PAR 없음) 0.0.7173 0.0.4377 0.S3-DST(비구조화 입력) S3-DST 0.0.7163 0.0.4640 0.0.0.7366 0.0.4752 0.Bing Chat 이 데이터 세트에서 우리는 IC-DST를 기본 기준으로 간주합니다. 이는 (Hu et al., 2022)에서 도입한 프롬프팅 전략의 제로샷 버전으로, 세그먼트 및 대화 상태를 공동으로 추적하기 위해 오픈 도메인 대화 설정에 크게 적용되었습니다. TBT-DST 기준선은 분할 지침을 포함하지 않고 S3DST의 한 버전으로, S3-DST 프롬프트 구성을 사용하여 차례대로 의도 및 도메인 레이블을 얻습니다. 또한 프롬프트의 두 가지 핵심 측면인 PAR과 XML 구조적 포맷팅의 중요성을 분석하기 위해 S3-DST의 두 가지 절제도 고려합니다. PAR 없음은 PAR 지침이 없는 S3-DST 프롬프트를 나타내고, 구조화되지 않은 입력은 모든 지침과 대화를 XML이 아닌 일반 텍스트로 포맷하는 S3-DST 프롬프트를 나타냅니다. 모든 프롬프트에 백본 LLM으로 GPT4를 사용합니다. MWOZ MWOZ 작업 지향 대화 상태 추적 데이터 세트의 경우 Hu et al.(2022)에서 보고한 Codex-175B를 사용하여 IC-DST와 비교합니다. 또한 기준선 성능에서 백본 모델 개선을 설명하기 위해 GPT-로 제로샷 IC-DST를 재평가합니다. 마지막으로, (Heck et al., 2023)에서 보고한 MWOZ 2.1에서의 제로샷 ChatGPT 성능과 비교합니다. DialSeg711 우리는 비지도 TextTiling(Hearst, 1997), CSM(Xing and Carenini, 2021), DialStart(Gao et al., 2023) 방법을 고려합니다. 우리는 (Gao et al., 2023)의 모든 숫자를 다시 인쇄합니다. 마지막으로, 우리는 원래 IC-DST(Hu et al., 2022)와 동일한 SQL 출력 형식으로 세분화 레이블을 유도하도록 프롬프트된 IC-DST 기준선을 사용합니다. 4.4 메트릭 상태 추적을 위해, 우리는 모든 상태 값이 올바르게 추론되는 턴의 비율을 측정하는 Joint Goal Accuracy(JGA)를 고려합니다. Bing Chat의 경우 Binned JGA(I/D) 0.0.0.500.0.(0,3] S3-DST .-X. S3-DST(PAR 없음) IC-DST(3,5] (5,10] 대화 길이(턴 수) (10,20] 그림 3: S3-DST는 컨텍스트 추적을 강조하여 모든 길이의 대화에 대한 기준선보다 성능이 뛰어납니다. 길이에 따라 Bing Chat 대화를 빈으로 나누고 빈당 JGA를 표시합니다. 대화 길이가 길어질수록 두 기준선 모두 성능이 크게 저하되므로 PAR 기반 전략의 중요성을 확인할 수 있습니다. 표 3: S3-DST는 공개 대화 상태 추적 벤치마크 MWOZ 2.1 + 2.4에서 제로샷 LLM 기준선과 비교하여 최첨단 JGA를 달성합니다. JGA MWOZ 2.MWOZ 2.IC-DST(Codex) IC-DST (GPT4) 0.0.0.0.ChatGPT 0.S3-DST 0.0.intent 및 domain(I/D)은 관심 있는 실제 상태 값이고, 완전성을 위해 세그먼트, 의도 및 도메인 정확도(S/I/D)가 있는 JGA입니다. 또한 Bing Chat에서 세분화, 의도 및 도메인 정확도를 별도로 보고하여 오픈 도메인 대화 데이터에서 LLM의 현재 기능과 한계를 파악합니다. 세분화의 경우 PK 및 WindowDiff(Pevzner 및 Hearst, 2002)를 고려합니다. 둘 다 오류 메트릭(즉, 낮을수록 좋음)으로, 조정 가능한 슬라이딩 윈도우를 사용하여 예측된 세그먼트 경계와 기준 진실 세그먼트 경계 간의 차이를 정량화합니다. 표 4: MWOZ 2.1에서 제로 샷 도메인별 비교(JGA). 표 5: S3-DST는 공개 세분화 벤치마크 DialSeg711에서 최첨단 성능을 달성합니다. attr. hotel 도메인별 JGA rest. Pk(↓) WindowDiff (↓) 택시 기차 TextTiling 0.0.IC-DST (Codex) IC-DST (GPT4) ChatGPT S3-DST 0.5997 0.4669 0.5728 0.7135 0.0.7177 0.4872 0.6526 0.7781 0.0.5270 0.4200 0.5580 0.7090 0.0.6781 0.5215 0.6713 0.8258 0.CSM 0.0.DialSTART 0.0.IC-DST 0.0.S3-DST 0.0.4.5 결과 Bing Chat 표 2에서 볼 수 있듯이, S3-DST 프롬프트는 턴 전체에서 의도, 도메인 및 JGA에서 가장 높은 성능을 달성합니다. 우리는 다음과 같은 관찰을 합니다. 첫째, 세분화를 명시적으로 수행하지 않는 TBT-DST는 지금까지 가장 약한 기준선입니다. 이는 LLM에 세그먼트 내에서 동일한 의도와 도메인을 사용하도록 지시하지 않으면 LLM이 더 완전한 이전 맥락을 고려하지 않고 턴의 내용을 과도하게 인덱싱하는 경향이 있기 때문입니다. 이로 인해 일관된 단일 주제 대화 내에서 턴 간에 충돌하는 의도 및 도메인 레이블이 발생합니다. 둘째, IC-DST의 수정된 버전은 매우 강력한 기준선입니다. 그러나 IC-DST는 구조화된 출력을 사용하지만 해당 구조화된 입력 표현이 없습니다. 존재하지 않는 턴에 대한 환각이 S3-DST에 비해 비교적 흔하기 때문에 어떤 경우에는 이로 인해 성능이 저하됩니다. 마지막으로 S3-DST의 두 가지 절제는 모두 S3-DST에 비해 성능이 낮아 LLM이 생성 중에 참조할 수 있는 PAR 및 구조화된 입력의 중요성을 확인합니다. 실제로 대화 길이와 성능 간의 관계를 나타낸 그림 3은 S3-DST가 대화가 길어짐에 따라 no-PAR ablation의 성능이 급격히 저하되는 것을 방지한다는 것을 보여줍니다. 예를 들어, no-PAR ablation은 3턴 이하의 대화에서는 S3-DST와 비슷한 성능을 보이지만, 턴 이상의 대화에서는 JGA가 10포인트 이상 떨어집니다. 이러한 결과는 특히 긴 대화에서 PAR의 필요성을 강조합니다. MWOZ 표 3과 4는 전체 및 도메인별 MWOZ 숫자를 제공합니다. S3-DST는 강력한 LLM에 비해 최첨단 제로샷 JGA를 큰 차이로 달성합니다. 가장 강력한 제로샷 기준선인 IC-DST(GPT4)조차도 MWOZ 2.1에서는 JGA가 거의 5포인트, MWOZ 2.4에서는 JGA가 . 거의 모든 개별 도메인에서 S3-DST는 IC-DST(GPT4)보다 성능이 뛰어나고, 예를 들어 트레인 도메인에서 13포인트 이상의 JGA 개선과 같이 큰 차이로 더 뛰어납니다. DialSeg711 마지막으로 표 5는 DialSeg711의 성능을 보여줍니다. S3-DST는 이 데이터 세트에서 거의 오류가 없으며, 데이터 세트의 구성을 감안하면 놀라운 일이 아닙니다. 구체적으로 DialSeg711은 매우 다른 주제에 대한 대화를 결합하여 구성되므로 세그먼트 간에 매우 인위적이고 갑작스러운 컨텍스트 전환이 발생합니다. 그러나 IC-DST 프롬프트 기준선은 S3-DST보다 훨씬 더 높은 오류를 발생시킵니다. 자세히 살펴보면 LLM이 데이터 세트의 여러 대화에 대한 대화 컨텍스트를 추적하지 못해 원래 대화 컨텍스트를 잊어버리는 것을 알 수 있습니다. 이러한 결과는 성공적인 세분화를 위해 PAR 및 대화 컨텍스트 추적의 중요성을 강조합니다. S3-DST의 강력한 성능은 DialSeg711이 앞으로 LLM에 충분히 어려운 작업이 아닐 수 있음을 시사하며, 궁극적으로 분할의 목표가 상태 추적 성능을 개선하는 것이므로 공동 분할 및 상태 추적의 필요성을 더욱 부추깁니다. 5
--- RELATED WORK ---
5.1 대화 상태 추적 인간-AI 대화의 흐름을 정확하게 추적하려면 사용자의 의도와 목표를 추론하는 데 강력한 상태 추적이 중요합니다. MultiWOZ(Budzianowski et al., 2018) 데이터 세트가 커뮤니티에 도입된 이후 DST 성능을 개선하기 위한 수많은 기술이 제안되었습니다. 복사 메커니즘(Lei et al., 2018), 전이 학습(Wu et al., 2019), 데이터 증강(Zhang et al., 2020), 대조 사전 학습(Wu et al., 2020) 등을 포함한 이전 시도는 감독 미세 조정 시나리오에서 개선을 가져왔습니다. 한편, MultiWOZ도 여러 번의 주석 개정을 거쳤습니다(Eric et al., 2019; Ye et al., 2021; Zang et al., 2020; Han et al., 2020). 다른 기술(Peng 등, 2021; Lin 등, 2020; Zhao 등, 2022; Yu 등, 2020; Platanios 등, 2021)도 제안되었지만, 데이터 레이블링의 리소스 집약적이고 힘든 특성으로 인해 점차적으로 주목이 소수 및 제로 샷 대화 상태 추적(Shin 등, 2022; Hu 등, 2022; Heck 등, 2023) 탐색으로 옮겨갔습니다. 이 분야의 최첨단 접근 방식(Hu 등, 2022)은 상태 추적을 위해 LLM을 활용할 수 있지만, 실제 확장 대화 세션에서 성능을 잠재적으로 저하시킬 수 있는 적절한 접지 메커니즘이 현저히 부족합니다. 더욱이, 앞서 언급한 이전 작업 중 어느 것도 유연한 오픈 도메인 LLM 기반 채팅 시스템에서 널리 퍼져 있는 주제 일관성 및 컨텍스트 전환을 설명하지 않습니다. 5.2 대화 주제 세분화 대화를 주제별로 일관된 단위로 세분화하는 것은 다운스트림 대화 모델링의 성공에 기초가 됩니다. 주석이 달린 데이터의 부족은 대화 주제 세분화에 어려움이었지만, 최근의 비지도 시도는 주제 세분화에서 몇 가지 유망한 결과를 보여주었습니다. 더 구체적으로, 고전적인 텍스트 세분화 알고리즘인 TextTiling(Hearst, 1997)을 기반으로 하는 확장은 이 측면에서 주로 벤치마크를 주도했습니다(Song et al., 2016). 더 최근에는 텍스트 쌍 일관성 스코어링(Xing and Carenini, 2021)과 주제 인식 표현 학습(Gao et al., 2023)이 최첨단 기술을 발전시켰습니다. 그럼에도 불구하고 이러한 모든 기술은 대화의 완전한 맥락적 본질(즉, 의도 및 기타 중요한 상태 변수를 명시적으로 모델링)을 설명하는 데 부족하여 최적이 아닌 결과를 초래할 수 있습니다. 5.3 의도 분류 대화 상태 추적과 관련하여 작업 지향 대화 시스템의 또 다른 근본적인 문제는 의도 분류(IC)입니다. 종종 다른 보완적 문제 슬롯 채우기(SF)와 짝을 이루어, 연구자들은 수년에 걸쳐 광범위한 기술을 제안해 왔습니다(Liu와 Lane, 2016; Zhang과 Wang, 2016; Goo 등, 2018; Qin 등, 2019, 2021). 인기 있는 공개 데이터 세트에서 인상적인 성과를 달성했습니다. Few-shot 기술도 공동 IC/SF 작업을 위한 데이터 제약 시나리오에서 조사되었습니다(Krone 등, 2020; Bhathiya와 Thayasivam, 2020; Liu 등, 2021). DST와 관련이 있지만, IC/SF는 주로 개별 발화를 격리하여 처리하므로 대화 세션 내에서 여러 발화에 걸쳐 복잡한 맥락적 연결을 모델링해야 하는 실제 인간-AI 대화에는 적합하지 않습니다. 6 논의 및 결론 LLM 기반 채팅 시스템은 인간-AI 대화의 지평을 넓혀 새로운
--- METHOD ---
s는 각 턴에서 새로운 상태 요소를 추출합니다(Hu et al., 2022). 그러나 이는 DST 평가 벤치마크가 사용자가 각 턴에서 새롭고 관련성 있는 의도 요소를 제공하고 의도가 서로를 기반으로 하거나 보완하지만 대화 전체에서 근본적으로 변경되거나 충돌하지 않는다는 비교적 좁은 가정을 하기 때문입니다. 앞서 논의했듯이 오픈 도메인 대화는 훨씬 더 다양한 특성을 보이며 다중 의도 및/또는 다중 도메인 대화가 비교적 일반적입니다. = 따라서 턴 수준이 아닌 세그먼트에서 상태를 추출할 것을 제안합니다. 세그먼트 수준 상태를 {Sm:n = (smin, vmn), i 1... Nm:n}으로 정의합니다. 여기서 son은 경계 bm에서 bn까지 세그먼트에 적용된 i번째 슬롯을 나타냅니다. (i) vm:n은 슬롯의 해당 값을 나타내고 Nm:n은 이 세그먼트에 적용된 총 슬롯 수를 나타냅니다. 슬롯-값 쌍의 모든 스키마가 여기에서 유효합니다. 우리는 § 4.1과 부록 B에서 Bing Chat에 대한 특정 상태 스키마를 설명합니다. 2.3 문제 설명 세그먼트와 세그먼트별 상태를 정의했으므로 오픈 도메인 DST에 대한 전체 정의를 설명할 수 있습니다. 사용자-에이전트 발화 쌍 C₁ = [U₁, A1, ..., Ut, At]의 시퀀스가 주어지면 오픈 도메인 대화 상태 추적의 목표를 Yt = Bk U {Sm:n; V(bm, bn) Є Bk}를 공동으로 예측하는 것으로 정의합니다. (1) 여기서 Bk C Bt는 이전에 설명한 세그먼트 경계 인덱스를 나타내고 Sm:n은 경계 bm과 bn 사이의 세그먼트 상태를 나타내며 이는 N개의 임의의 슬롯 값 쌍으로 구성됩니다. Sm:n = {(s):n, v(n), i = 1 . . . Nm:n}. (2) 3가지 프롬프트 전략 이전에 논의했듯이, 실제 대화는 종종 다양한 주제를 논의하기 위해 여러 대화 턴에 걸쳐 확장되는 광범위한 담론을 보입니다. 이러한 장기간의 대화적 특성으로 인해 문맥적 일관성을 추적하기가 매우 어렵습니다. 이전 연구(Hu et al., 2022)는 개별 대화 턴을 분리하고 대화 상태 변화를 추적하기 위해 하나씩 처리하는 것을 목표로 했으며, 이는 미리 정의된 좁은 영역에 국한된 작업 지향 대화에서 상당히 잘 작동했습니다. 그러나 실제 대화는 일반적으로 문맥적 뉘앙스를 적절히 이해하기 위해 여러 턴이 필요한데, 이는 Transformers가 특히 중간에 긴 입력 컨텍스트를 처리할 때 여전히 어려움을 겪기 때문에 어려운 문제입니다(Liu et al., 2023). 이러한 어려움을 해결하기 위해 입력과 출력에 구조를 제공하면서 프로세스의 컨텍스트를 정확하게 보존하는 새로운 턴바이턴 프롬프트 기술을 제안합니다. 아래에서 프롬프트의 이러한 디자인 측면에 대해 논의합니다. 3. 구조화된 출력 및 입력 구조화된 출력 우리의 목표는 세그먼트 경계(바이너리 레이블)와 상태 값(범주 레이블 또는 오픈 텍스트)을 나타내는 대화 턴당 레이블 세트입니다. LLM의 출력에 유연하면서도 구조화된 형식을 제공하기 위해 계층적 XML 형식으로 출력을 생성하도록 지시하는 것을 제안합니다. 우리는 XML이 DST 작업에 코드와 같은 구조를 제공하기 때문에 유리하다고 생각합니다. 이는 일반 텍스트 출력에 비해 성능을 크게 향상시키는 것으로 나타났으며, SQL과 같은 보다 엄격한 출력 형식에 비해 확장 가능하고 유연합니다(Hu et al., 2022). 우리의 접근 방식은 1에서 t까지의 각 턴이 XML 트리를 구성하는 XML 형식을 사용합니다.<T{id}> ...</T{id}> 그리고 그 안에 여러 개의 중첩된 XML 태그가 있습니다. 이러한 중첩된 태그의 레이블(예:<preceding_topical_relation> ...</preceding_topical_relation> ,<intent> ...</intent> , 그리고<domain> ...</domain> 그림 2(iii))는 세그먼트 경계와 관심 슬롯을 나타내며, 여는 태그와 닫는 태그 사이의 각 값은 모델의 추론된 값을 나타냅니다. 이 전략은 두 가지 측면에서 유익합니다. (i) 경계가 있는 잘 정의된 구조화된 형식으로 인해 생성된 출력은 자유형 텍스트보다 레이블 지정 지침과 일치할 가능성이 더 높고 (ii) 잘 구성된 구조화된 출력 형식은 구문 분석하기가 더 쉬워 후처리 요구 사항이 줄어듭니다. 구조화된 입력 LLM을 프롬프트하는 경우 분석 및 추론을 위해 일반 대화 기록을 평면 형식으로 채널링하는 것은 사소한 일이지만 이 선형 구성에 내재된 비구조적 특성으로 인해 참조하고 활용하기 어렵습니다. 원시 대화 사용자: 주석이 달린 참고 문헌을 제공하세요... AI: 다음은 몇 가지 다른 참고 문헌입니다... 사용자: (i) 대화와 지침을 구조화된 프롬프트 템플릿에 삽입<valid preceding_topical_relation><item><name> 예</name><description> ...</description></item></valid_preceding_topical_relation><valid intents><item> ...</item></valid_intents> ## 대화 (iii) 생각의 사슬을 통해 구조화된 차례차례 대화 태그를 생성합니다.<T1><summary> 사용자는 주석이 달린...을 요청합니다.</summary><preceding_topical_relation> 아니요</preceding_topical_relation><intent> 창조</intent><domain> 저널리즘 쓰기와 출판</domain> 법학 석사</T1><T2> 일체 포함:<T1><User> ...을 제공해 주세요.</User><AI> 여기에 몇 가지 예가 있습니다...</AI></T1><T2><summary> ...</summary><preceding_topical_relation> ...</preceding_topical_relation><intent> ...</intent> &#39;<domain> ...</domain></T2> 구조화된 턴<User> ...</User><AI> ...</AI></T2> (ii) 사전 분석 기억(PAR) 각 턴에서 출력을 근거로 컨텍스트 보존 그림 2: S3-DST의 프롬프트 흐름. 원시 대화가 주어지면 (i) 계층적 XML 구조 표현으로 변환하여 유사하게 구조화된 프롬프트 템플릿에 삽입합니다. 프롬프트를 LLM에 전달하고 (ii) 계층적 XML 구조 출력을 얻습니다. 여기서 각 턴에는 (iii) 원하는 세분화 및 상태 레이블 예측과 함께 대화에 대한 PAR 근거 참조가 포함됩니다. 여러 대화 턴에서 다른 정보를 연령화합니다. 출력 형식과 일관되게 이 과제를 처리하기 위해 각 대화 내역이 계층적 XML 형식으로 형성되고 대화 턴이 턴 ID 번호로 표시되는 구조화된 입력 형식을 제안합니다.<T{id}> ...</T{id}> 1에서 t까지 번호가 매겨지고 각 대화 차례는 적절한 XML 태그로 표시된 중첩된 사용자 및 에이전트 차례로 구성됩니다.<user> ...</user> 그리고<agent> ...</agent> ). 출력 중에 턴당 레이블을 추론하도록 LLM에 지시하는 것을 제안하기 때문에 이 입력 체계는 입력 턴을 정확하게 참조하고 긴 대화 맥락에서도 일관성을 유지하는 데 도움이 됩니다. 이 XML 태그 입력 형식과 일관되게 다음 구조를 사용하여 XML 형식 목록에서 모든 유효한 세그먼트 및 상태 범주를 형식화합니다.<valid_category_name><item> {라벨 이름}</item><description> {라벨 설명(있는 경우)}</description><valid_category_name> 경험적으로, 이 구조화된 입력 및 프롬프트 형식은 LLM 생성이 레이블 지정 지침을 따르도록 제한하는 데 도움이 됩니다. 그림 2(i)는 각 유효한 세그먼트 경계와 상태 범주가 먼저 XML 형식의 목록에서 준비되고 이어서 입력 대화가 계층적 구성으로 표시되는 이 형식을 보여줍니다. 3. 사전 분석 기억(PAR) 이전에 논의했듯이, 오픈 도메인 대화는 길고 대화 흐름이 매우 다양할 수 있습니다. 따라서 LLM이 잊거나 환각하지 않고 진화하는 대화 맥락을 정확하게 모니터링할 수 있도록 하는 것이 중요합니다. 이를 위해, 우리는 LLM이 먼저 다음을 사용하여 차례를 요약하도록 지시하는 차례 차례 프롬프트를 위한 기초 전략인 사전 분석 기억(PAR)을 제안합니다.<summary> ...</summary> 영어: 세그먼트 및 상태 값을 제공하기 전에 3개 이하의 문장으로 태그를 지정합니다.PAR은 추론 정확도를 개선하기 위해 관련 중간 출력을 생성하는 기술이기 때문에 사고의 사슬 프롬프트(Wei et al., 2022)에서 영감을 받았습니다.그러나 사고의 사슬과 달리 PAR은 모델의 출력에서 대화에 직접 참조를 제공하는 접지 기술이기도 합니다.그림 2(ii)는 PAR이 대화 상태를 추론하기 위해 분석하기 전에 각 대화 차례의 내용을 다시 참조하는 방법을 보여줍니다.3.3 최종 프롬프트 구성 S3-DST의 최종 프롬프트 흐름은 그림 2에 나와 있습니다.원시 대화와 미리 정의된 세그먼트 및 상태 레이블 집합이 주어지면 레이블을 구조화된 프롬프트 템플릿에 삽입하고 대화를 계층적 XML 구조 표현으로 포맷합니다.프롬프트를 LLM으로 전달하여 PAR을 따르도록 지시한 다음 공동으로 표 1: 평가 테스트 집합 통계. # 전환 # 회전 # 세그먼트/전환 Bing ChatMWOZ 2.1, MWOZ 2.DialSeg1,(평균) 1.3. 세그먼트별로 적용되는 계층적 턴바이턴 세분화 및 상태 레이블 생성. 프롬프트의 전체 텍스트는 부록 A.1.4에 제공됩니다.
--- EXPERIMENT ---
s 및 분석: 우리는 독점적 데이터 세트와 공개 데이터 세트 모두에서 광범위한 실험을 수행하여 비슷한 제로샷 프롬프트에 비해 큰 성과를 달성했습니다. S3DST는 최첨단 제로샷 프롬프트를 달성합니다. Bing Chat 로그를 사용하는 것은 DialSeg711 대화 주제 세분화 벤치마크와 함께 MWOZ 2.1 및 2.4 DST 벤치마크에서 조건을 준수합니다. 2 문제 정의 비공식적으로, 기존 DST의 목표는 사용자와 에이전트의 발화 턴 시퀀스 C₁ = [U₁, A1, ..., Ut, At]²가 주어졌을 때 대화 상태 yt를 예측하는 것입니다. 상태 yt는 슬롯-값 쌍의 집합으로 구성되며, 여기서 슬롯은 특정 애플리케이션 도메인의 의도 속성(예: &quot;레스토랑 이름&quot;, &quot;호텔 주소&quot;)에 해당하고 값은 미리 정의된 범주형 옵션 또는 제한 없는 텍스트에 해당합니다(Budzianowski et al., 2018). 그러나 이전에 논의했듯이 단일 오픈 도메인 대화는 종종 다양한 주제에 걸쳐 잠재적으로 관련성이 없는 여러 의도로 구성됩니다. 실제로 10,000개의 익명화된 Bing Chat 대화에 대한 예비 분석에 따르면 대화의 50% 이상이 여러 사용자 의도를 표시하고 대화의 90% 이상이 여러 주제에 대한 토론을 포함한다고 추정합니다. 따라서 더 큰 대화 내에서 맥락적으로 응집력 있는 &quot;대화 단위&quot;를 찾는 것을 목표로 하는 대화 세분화를 대화 상태 추적과 병합할 것을 제안합니다. 특히 세그먼트 수준에서 상태 추적을 수행하는데, 여기서 목표는 각 세그먼트에 관심 있는 슬롯과 값으로 레이블을 지정하여 대화 내의 여러 세그먼트가 발산하거나 상충되는 상태 값을 가질 수 있도록 하는 것입니다. 이는 오픈 도메인 채팅의 진정한 다양성을 반영합니다. 이 섹션의 나머지 부분에서는 세분화와 상태를 정의하고 마지막으로 공동 작업을 공식화합니다. 2.1 세그먼트 대화 주제 분할(Xing 및 Carenini, 2021; Xia 등, 2022; Gao 등, 2023)에 대한 이전 연구에 따라 대화 세그먼트를 모든 사용자 및 에이전트 발화가 주제적으로 관련된 Ct의 연속된 하위 시퀀스로 정의합니다. 형식적으로 B₁ = [b₁,……., bt−[b₁, … …. …, bt−]는 Ct에서 인접한 사용자-에이전트 발화 쌍 사이의 경계 인덱스를 나타냅니다. 분할의 출력은 경계 인덱스 Bk C BŁ의 집합입니다. 여기서 k는 분할 알고리즘에 의해 결정된 경계 수와 Bing Chat 사용에 대한 범위 [Um, Am, . . . Un, An]을 나타냅니다. 2현재 LLM 기반 채팅 시스템에서는 사용자가 단일 에이전트 응답이 발행되기 전에 여러 발화를 발행할 수 있습니다. 이러한 (드물게) 경우에 우리는 에이전트 응답 이전의 모든 사용자 발화를 단일 발화로 그룹화합니다. 경계 bm과 bn 사이의 연속된 세그먼트를 보냅니다. 여기서 m = [1, t − 1] 및 n ≤ [m, t − 1]. 2.2 세그먼트 상태 일반적으로 대화 상태 추적 방법은 각 턴에서 상태의 새로운 요소를 추출합니다(Hu et al., 2022). 그러나 이는 DST 평가 벤치마크가 사용자가 각 턴에서 새롭고 관련성 있는 의도 요소를 제공하고 의도가 서로를 기반으로 하거나 보완하지만 대화 전체에서 근본적으로 변경되거나 충돌하지 않는다는 비교적 좁은 가정을 하기 때문입니다. 이전에 논의했듯이 오픈 도메인 대화는 훨씬 더 다양한 특성을 보이며 다중 의도 및/또는 다중 도메인 대화가 비교적 일반적입니다. = 따라서 턴 수준이 아닌 세그먼트에서 상태를 추출할 것을 제안합니다. 세그먼트 수준 상태를 {Sm:n = (smin, vmn), i 1... Nm:n}으로 정의합니다. 여기서 son은 경계 bm에서 bn까지의 세그먼트에 적용된 i번째 슬롯을 나타냅니다. (i) vm:n은 슬롯의 해당 값을 나타내고 Nm:n은 이 세그먼트에 적용된 슬롯의 총 수를 나타냅니다. 슬롯 값 쌍의 스키마는 여기에서 유효합니다. § 4.1과 부록 B에서 Bing Chat에 대한 특정 상태 스키마를 설명합니다. 2.3 문제 설명 세그먼트와 세그먼트별 상태를 정의했으므로 오픈 도메인 DST에 대한 전체 정의를 설명할 수 있습니다. 사용자-에이전트 발화 쌍 C₁ = [U₁, A1, ..., Ut, At]의 시퀀스가 주어지면 오픈 도메인 대화 상태 추적의 목표를 Yt = Bk U {Sm:n; V(bm, bn) Є Bk}, (1) 여기서 Bk C Bt는 이전에 설명한 세그먼트 경계 인덱스를 나타내고 Sm:n은 경계 bm과 bn 사이의 세그먼트 상태를 나타내며, 이는 N개의 임의의 슬롯 값 쌍으로 구성됩니다. Sm:n = {(s):n, v(n), i = 1 . . . Nm:n}. (2) 3가지 프롬프트 전략 이전에 논의했듯이 실제 대화는 종종 다양한 주제를 논의하기 위해 여러 대화 턴에 걸쳐 확장되는 광범위한 담론을 보입니다. 이러한 장기간의 대화적 특성으로 인해 문맥적 일관성을 추적하기가 매우 어렵습니다. 이전 연구(Hu et al., 2022)는 개별 대화 턴을 분리하고 대화 상태 변경을 추적하기 위해 하나씩 처리하는 것을 목표로 했으며, 이는 미리 정의된 좁은 도메인에 국한된 작업 지향 대화에서 상당히 잘 작동했습니다. 그러나 실제 대화는 일반적으로 문맥적 뉘앙스를 적절히 이해하기 위해 여러 차례의 전환이 필요한데, 이는 Transformers가 특히 중간에 긴 입력 맥락을 처리할 때 여전히 어려움을 겪기 때문에 어려운 문제입니다(Liu et al., 2023). 이러한 어려움을 해결하기 위해 입력과 출력에 구조를 제공하면서 프로세스의 맥락을 정확하게 보존하는 새로운 차례별 프롬프트 기술을 제안합니다. 아래에서 프롬프트의 이러한 디자인 측면에 대해 설명합니다. 3. 구조화된 출력 및 입력 구조화된 출력 목표는 세그먼트 경계(바이너리 레이블)와 상태 값(범주형 레이블 또는 오픈 텍스트)을 나타내는 대화 차례당 레이블 집합입니다. LLM의 출력에 유연하면서도 구조화된 형식을 제공하기 위해 계층적 XML 형식으로 출력을 생성하도록 지시하는 것을 제안합니다. 우리는 XML이 DST 작업에 코드와 같은 구조를 제공하기 때문에 유리하다고 생각합니다. 이는 일반 텍스트 출력에 비해 성능을 크게 향상시키는 것으로 나타났으며, SQL과 같은 보다 엄격한 출력 형식에 비해 확장 가능하고 유연합니다(Hu et al., 2022). 우리의 접근 방식은 1에서 t까지의 각 턴이 XML 트리를 구성하는 XML 형식을 사용합니다.<T{id}> ...</T{id}> 그리고 그 안에 여러 개의 중첩된 XML 태그가 있습니다. 이러한 중첩된 태그의 레이블(예:<preceding_topical_relation> ...</preceding_topical_relation> ,<intent> ...</intent> , 그리고<domain> ...</domain> 그림 2(iii))는 세그먼트 경계와 관심 슬롯을 나타내며, 여는 태그와 닫는 태그 사이의 각 값은 모델의 추론된 값을 나타냅니다. 이 전략은 두 가지 측면에서 유익합니다. (i) 경계가 있는 잘 정의된 구조화된 형식으로 인해 생성된 출력은 자유형 텍스트보다 레이블 지정 지침과 일치할 가능성이 더 높고 (ii) 잘 구성된 구조화된 출력 형식은 구문 분석하기가 더 쉬워 후처리 요구 사항이 줄어듭니다. 구조화된 입력 LLM을 프롬프트하는 경우 분석 및 추론을 위해 일반 대화 기록을 평면 형식으로 채널링하는 것은 사소한 일이지만 이 선형 구성에 내재된 비구조적 특성으로 인해 참조하고 활용하기 어렵습니다. 원시 대화 사용자: 주석이 달린 참고 문헌을 제공하세요... AI: 다음은 몇 가지 다른 참고 문헌입니다... 사용자: (i) 대화와 지침을 구조화된 프롬프트 템플릿에 삽입<valid preceding_topical_relation><item><name> 예</name><description> ...</description></item></valid_preceding_topical_relation><valid intents><item> ...</item></valid_intents> ## 대화 (iii) 생각의 사슬을 통해 구조화된 차례차례 대화 태그를 생성합니다.<T1><summary> 사용자는 주석이 달린...을 요청합니다.</summary><preceding_topical_relation> 아니요</preceding_topical_relation><intent> 창조</intent><domain> 저널리즘 쓰기와 출판</domain> 법학 석사</T1><T2> 일체 포함:<T1><User> ...을 제공해 주세요.</User><AI> 여기에 몇 가지 예가 있습니다...</AI></T1><T2><summary> ...</summary><preceding_topical_relation> ...</preceding_topical_relation><intent> ...</intent> &#39;<domain> ...</domain></T2> 구조화된 턴<User> ...</User><AI> ...</AI></T2> (ii) 사전 분석 기억(PAR) 각 턴에서 출력을 근거로 컨텍스트 보존 그림 2: S3-DST의 프롬프트 흐름. 원시 대화가 주어지면 (i) 계층적 XML 구조 표현으로 변환하여 유사하게 구조화된 프롬프트 템플릿에 삽입합니다. 프롬프트를 LLM에 전달하고 (ii) 계층적 XML 구조 출력을 얻습니다. 여기서 각 턴에는 (iii) 원하는 세분화 및 상태 레이블 예측과 함께 대화에 대한 PAR 근거 참조가 포함됩니다. 여러 대화 턴에서 다른 정보를 연령화합니다. 출력 형식과 일관되게 이 과제를 처리하기 위해 각 대화 내역이 계층적 XML 형식으로 형성되고 대화 턴이 턴 ID 번호로 표시되는 구조화된 입력 형식을 제안합니다.<T{id}> ...</T{id}> 1에서 t까지 번호가 매겨지고 각 대화 차례는 적절한 XML 태그로 표시된 중첩된 사용자 및 에이전트 차례로 구성됩니다.<user> ...</user> 그리고<agent> ...</agent> ). 출력 중에 턴당 레이블을 추론하도록 LLM에 지시하는 것을 제안하기 때문에 이 입력 체계는 입력 턴을 정확하게 참조하고 긴 대화 맥락에서도 일관성을 유지하는 데 도움이 됩니다. 이 XML 태그 입력 형식과 일관되게 다음 구조를 사용하여 XML 형식 목록에서 모든 유효한 세그먼트 및 상태 범주를 형식화합니다.<valid_category_name><item> {라벨 이름}</item><description> {라벨 설명(있는 경우)}</description><valid_category_name> 경험적으로, 이 구조화된 입력 및 프롬프트 형식은 LLM 생성이 레이블 지정 지침을 따르도록 제한하는 데 도움이 됩니다. 그림 2(i)는 각 유효한 세그먼트 경계와 상태 범주가 먼저 XML 형식의 목록에서 준비되고 이어서 입력 대화가 계층적 구성으로 표시되는 이 형식을 보여줍니다. 3. 사전 분석 기억(PAR) 이전에 논의했듯이, 오픈 도메인 대화는 길고 대화 흐름이 매우 다양할 수 있습니다. 따라서 LLM이 잊거나 환각하지 않고 진화하는 대화 맥락을 정확하게 모니터링할 수 있도록 하는 것이 중요합니다. 이를 위해, 우리는 LLM이 먼저 다음을 사용하여 차례를 요약하도록 지시하는 차례 차례 프롬프트를 위한 기초 전략인 사전 분석 기억(PAR)을 제안합니다.<summary> ...</summary> 영어: 세그먼트 및 상태 값을 제공하기 전에 3개 이하의 문장으로 태그를 지정합니다.PAR은 추론 정확도를 개선하기 위해 관련 중간 출력을 생성하는 기술이기 때문에 사고의 사슬 프롬프트(Wei et al., 2022)에서 영감을 받았습니다.그러나 사고의 사슬과 달리 PAR은 모델의 출력에서 대화에 직접 참조를 제공하는 접지 기술이기도 합니다.그림 2(ii)는 PAR이 대화 상태를 추론하기 위해 분석하기 전에 각 대화 차례의 내용을 다시 참조하는 방법을 보여줍니다.3.3 최종 프롬프트 구성 S3-DST의 최종 프롬프트 흐름은 그림 2에 나와 있습니다.원시 대화와 미리 정의된 세그먼트 및 상태 레이블 집합이 주어지면 레이블을 구조화된 프롬프트 템플릿에 삽입하고 대화를 계층적 XML 구조 표현으로 포맷합니다.프롬프트를 LLM으로 전달하여 PAR을 따르도록 지시한 다음 공동으로 표 1: 평가 테스트 집합 통계. # 전환 # 회전 # 세그먼트/전환 Bing ChatMWOZ 2.1, MWOZ 2. DialSeg1, (평균) 1.3. 세그먼트별로 적용되는 계층적 턴바이턴 분할 및 상태 레이블을 생성합니다. 프롬프트의 전체 텍스트는 부록 A.1에 제공됩니다. 4 실험 여러 데이터 세트에 대해 포괄적인 평가를 수행합니다. 주로 도메인 전문가가 주석을 단 완전히 익명화된 Bing Chat 로그에 대한 접근 방식을 평가합니다. 또한 공개 벤치마크 데이터 세트 MultiWOZ(Budzianowski et al., 2018) 및 DialSeg(Xu et al., 2021)를 사용하여 표준 작업 지향 DST 및 분할 작업에서 S3-DST를 평가합니다. 이러한 데이터 세트에 대한 자세한 설명은 표 1의 데이터 세트 통계와 함께 아래에 제공됩니다.4. 내부 인간-LLM 대화 데이터 세트 실제 오픈 도메인 인간-LLM 대화에 대한 접근 방식의 효능을 평가하기 위해 Bing 검색 엔진이 지원하는 LLM 채팅 인터페이스인 Microsoft의 Bing Chat 시스템에서 익명화된 채팅 로그 데이터를 수집했습니다.벤치마크 구축 2023년 4월 5일부터 2023년 4월 30일까지 Bing Chat에서 진행된 484개의 영어 대화를 두 가지 접근 방식을 통해 샘플링합니다.(i) 무작위 및 (ii) 5턴 이상인 &quot;긴&quot; 대화. 이 두 가지 접근 방식을 50/50으로 균형 있게 조정합니다. 제로샷 가정에서 작동하므로 학습 데이터가 필요하지 않습니다. 따라서 개발을 위해 150개의 대화를 유지하고 나머지 334개를 테스트용으로 유지합니다.주석 평가를 위한 기준 진실 레이블을 얻기 위해 세그먼트 및 상태에 대한 인간 주석을 수집했습니다. 우리는 Bing Chat 시스템에 대한 높은 수준의 기술적 전문성과 친숙함을 갖춘 사내 주석자 3명을 모집했습니다. 각 턴에 대해 주석자에게 이진 IsSegmentBoundary 레이블, 범주형 SegmentIntent 레이블, 범주형 SegmentDomain 레이블을 제공하도록 지시했습니다. 턴과 이전 컨텍스트 간의 주제적 관계를 식별할 수 없는 경우 주석자에게 세그먼트 경계를 표시하도록 지시했습니다. 의도와 도메인의 경우 Bing Chat 시스템을 위해 사내에서 개발한 택소노미를 사용했는데, 여기에는 4개의 의도(정보 탐색, 분석, 생성 및 개방형 발견)와 49개의 도메인이 포함됩니다(전체 목록은 부록 B.1 참조). 도메인 수가 많기 때문에 턴당 주석자에게 4개의 후보 도메인 값과 &quot;기타&quot; 옵션을 제공했습니다. 부록 B에는 주석 체계와 도메인 샘플링 절차에 대한 자세한 내용이 나와 있습니다. 전체 데이터 세트에 레이블을 지정하기 전에 주석자 간 일치를 보장하기 위해 먼저 무작위로 선택한 10개의 대화(총 68개의 턴)에 대한 주석을 수집하고 레이블 유형별로 Fleiss 카파(Fleiss, 1971)를 계산했습니다. IsSegmentBoundary의 경우 k = 0.83, SegmentIntent의 경우 k = 0.74, SegmentDomain의 경우 K = 0.88의 Fleiss 카파를 관찰했는데, 이는 모두 Fleiss 카파 척도에서 높은 일치로 간주됩니다. 4.2 공개 벤치마크 광범위하게 오픈된 도메인인 Bing Chat 데이터를 반영하는 기존의 공개 대화 벤치마크는 알려진 바가 없습니다. 따라서 세 가지 데이터 세트를 사용하여 공개 벤치마크에서 별도의 DST 및 세분화 평가를 수행합니다. MultiWOZ MultiWOZ(MWOZ) 다중 도메인 대화 데이터 세트(Budzianowski et al., 2018)는 현재 가장 일반적인 DST 벤치마크입니다. MWOZ는 1,000개의 테스트 대화로 구성된 작업 지향 데이터 세트입니다. 저희는 원본의 두 가지 업데이트된 버전인 MWOZ 2.1(Eric et al., 2019)과 2.4(Ye et al., 2021)를 사용합니다. 후자는 MWOZ의 &quot;가장 깨끗한&quot; 버전으로 간주되는 반면 전자는 문헌에서 더 자주 사용되었습니다. DialSeg711 DialSeg711 벤치마크는 (Xu et al., 2021)에 의해 도입되었으며 최근 대화 분할 연구에 자주 사용되었습니다. 기존 작업 지향 대화 코퍼스에서 대화를 결합하여 711개의 다중 세그먼트 대화를 구성하는 영어 데이터 세트입니다. 4.3 기준선 저희는 S3-DST와의 공정한 비교를 위해 제로샷 LLM 프롬프트만 기준선으로 고려합니다. 저희는 아래에서 다양한 데이터 세트에 대한 기준선과 고려 사항을 논의합니다. 모든 원래 프롬프트는 부록 A에 제공됩니다. LLM 호출당 최대 1500개의 출력 토큰을 설정했으며 온도는 0입니다. 표 2: S3-DST는 내부 Bing Chat 벤치마크에서 상태 추적에 대한 최첨단 성능을 달성합니다. 모든 프롬프트는 GPT4로 실행됩니다. 개별 정확도 JGA 세그먼트 의도 도메인 I/DS/I/D TBT-DST 0.0.0.IC-DST 0.0.0.0.4610 0.S3-DST(PAR 없음) 0.0.7173 0.0.4377 0.S3-DST(비구조화 입력) S3-DST 0.0.7163 0.0.4640 0.0.0.7366 0.0.4752 0.Bing Chat 이 데이터 세트에서 우리는 IC-DST를 기본 기준으로 간주합니다. 이는 (Hu et al., 2022)에서 도입한 프롬프팅 전략의 제로샷 버전으로, 세그먼트 및 대화 상태를 공동으로 추적하기 위해 오픈 도메인 대화 설정에 크게 적용되었습니다. TBT-DST 기준선은 분할 지침을 포함하지 않고 S3DST의 한 버전으로, S3-DST 프롬프트 구성을 사용하여 차례대로 의도 및 도메인 레이블을 얻습니다. 또한 프롬프트의 두 가지 핵심 측면인 PAR과 XML 구조적 포맷팅의 중요성을 분석하기 위해 S3-DST의 두 가지 절제도 고려합니다. PAR 없음은 PAR 지침이 없는 S3-DST 프롬프트를 나타내고, 구조화되지 않은 입력은 모든 지침과 대화를 XML이 아닌 일반 텍스트로 포맷하는 S3-DST 프롬프트를 나타냅니다. 모든 프롬프트에 백본 LLM으로 GPT4를 사용합니다. MWOZ MWOZ 작업 지향 대화 상태 추적 데이터 세트의 경우 Hu et al.(2022)에서 보고한 Codex-175B를 사용하여 IC-DST와 비교합니다. 또한 기준선 성능에서 백본 모델 개선을 설명하기 위해 GPT-로 제로샷 IC-DST를 재평가합니다. 마지막으로, (Heck et al., 2023)에서 보고한 MWOZ 2.1에서의 제로샷 ChatGPT 성능과 비교합니다. DialSeg711 우리는 비지도 TextTiling(Hearst, 1997), CSM(Xing and Carenini, 2021), DialStart(Gao et al., 2023) 방법을 고려합니다. 우리는 (Gao et al., 2023)의 모든 숫자를 다시 인쇄합니다. 마지막으로, 우리는 원래 IC-DST(Hu et al., 2022)와 동일한 SQL 출력 형식으로 세분화 레이블을 유도하도록 프롬프트된 IC-DST 기준선을 사용합니다. 4.4 메트릭 상태 추적을 위해, 우리는 모든 상태 값이 올바르게 추론되는 턴의 비율을 측정하는 Joint Goal Accuracy(JGA)를 고려합니다. Bing Chat의 경우 Binned JGA(I/D) 0.0.0.500.0.(0,3] S3-DST .-X. S3-DST(PAR 없음) IC-DST(3,5] (5,10] 대화 길이(턴 수) (10,20] 그림 3: S3-DST는 컨텍스트 추적을 강조하여 모든 길이의 대화에 대한 기준선보다 성능이 뛰어납니다. 길이에 따라 Bing Chat 대화를 빈으로 나누고 빈당 JGA를 표시합니다. 대화 길이가 길어질수록 두 기준선 모두 성능이 크게 저하되므로 PAR 기반 전략의 중요성을 확인할 수 있습니다. 표 3: S3-DST는 공개 대화 상태 추적 벤치마크 MWOZ 2.1 + 2.4에서 제로샷 LLM 기준선과 비교하여 최첨단 JGA를 달성합니다. JGA MWOZ 2.MWOZ 2.IC-DST(Codex) IC-DST (GPT4) 0.0.0.0.ChatGPT 0.S3-DST 0.0.intent 및 domain(I/D)은 관심 있는 실제 상태 값이고, 완전성을 위해 세그먼트, 의도 및 도메인 정확도(S/I/D)가 있는 JGA입니다. 또한 Bing Chat에서 세분화, 의도 및 도메인 정확도를 별도로 보고하여 오픈 도메인 대화 데이터에서 LLM의 현재 기능과 한계를 파악합니다. 세분화의 경우 PK 및 WindowDiff(Pevzner 및 Hearst, 2002)를 고려합니다. 둘 다 오류 메트릭(즉, 낮을수록 좋음)으로, 조정 가능한 슬라이딩 윈도우를 사용하여 예측된 세그먼트 경계와 기준 진실 세그먼트 경계 간의 차이를 정량화합니다. 표 4: MWOZ 2.1에서 제로 샷 도메인별 비교(JGA). 표 5: S3-DST는 공개 세분화 벤치마크 DialSeg711에서 최첨단 성능을 달성합니다. attr. hotel 도메인별 JGA rest. Pk(↓) WindowDiff (↓) 택시 기차 TextTiling 0.0.IC-DST (Codex) IC-DST (GPT4) ChatGPT S3-DST 0.5997 0.4669 0.5728 0.7135 0.0.7177 0.4872 0.6526 0.7781 0.0.5270 0.4200 0.5580 0.7090 0.0.6781 0.5215 0.6713 0.8258 0.CSM 0.0.DialSTART 0.0.IC-DST 0.0.S3-DST 0.0.4.5 결과 Bing Chat 표 2에서 볼 수 있듯이, S3-DST 프롬프트는 턴 전체에서 의도, 도메인 및 JGA에서 가장 높은 성능을 달성합니다. 우리는 다음과 같은 관찰을 합니다. 첫째, 세분화를 명시적으로 수행하지 않는 TBT-DST는 지금까지 가장 약한 기준선입니다. 이는 LLM에 세그먼트 내에서 동일한 의도와 도메인을 사용하도록 지시하지 않으면 LLM이 더 완전한 이전 맥락을 고려하지 않고 턴의 내용을 과도하게 인덱싱하는 경향이 있기 때문입니다. 이로 인해 일관된 단일 주제 대화 내에서 턴 간에 충돌하는 의도 및 도메인 레이블이 발생합니다. 둘째, IC-DST의 수정된 버전은 매우 강력한 기준선입니다. 그러나 IC-DST는 구조화된 출력을 사용하지만 해당 구조화된 입력 표현이 없습니다. 존재하지 않는 턴에 대한 환각이 S3-DST에 비해 비교적 흔하기 때문에 어떤 경우에는 이로 인해 성능이 저하됩니다. 마지막으로 S3-DST의 두 가지 절제는 모두 S3-DST에 비해 성능이 낮아 LLM이 생성 중에 참조할 수 있는 PAR 및 구조화된 입력의 중요성을 확인합니다. 실제로 대화 길이와 성능 간의 관계를 나타낸 그림 3은 S3-DST가 대화가 길어짐에 따라 no-PAR ablation의 성능이 급격히 저하되는 것을 방지한다는 것을 보여줍니다. 예를 들어, no-PAR ablation은 3턴 이하의 대화에서는 S3-DST와 비슷한 성능을 보이지만, 턴 이상의 대화에서는 JGA가 10포인트 이상 떨어집니다. 이러한 결과는 특히 긴 대화에서 PAR의 필요성을 강조합니다. MWOZ 표 3과 4는 전체 및 도메인별 MWOZ 숫자를 제공합니다. S3-DST는 강력한 LLM에 비해 최첨단 제로샷 JGA를 큰 차이로 달성합니다. 가장 강력한 제로샷 기준선인 IC-DST(GPT4)조차도 MWOZ 2.1에서는 JGA가 거의 5포인트, MWOZ 2.4에서는 JGA가 . 거의 모든 개별 도메인에서 S3-DST는 IC-DST(GPT4)보다 성능이 뛰어나고, 예를 들어 트레인 도메인에서 13포인트 이상의 JGA 개선과 같이 큰 차이로 더 뛰어납니다. DialSeg711 마지막으로 표 5는 DialSeg711의 성능을 보여줍니다. S3-DST는 이 데이터 세트에서 거의 오류가 없으며, 데이터 세트의 구성을 감안하면 놀라운 일이 아닙니다. 구체적으로 DialSeg711은 매우 다른 주제에 대한 대화를 결합하여 구성되므로 세그먼트 간에 매우 인위적이고 갑작스러운 컨텍스트 전환이 발생합니다. 그러나 IC-DST 프롬프트 기준선은 S3-DST보다 훨씬 더 높은 오류를 발생시킵니다. 자세히 살펴보면 LLM이 데이터 세트의 여러 대화에 대한 대화 컨텍스트를 추적하지 못해 원래 대화 컨텍스트를 잊어버리는 것을 알 수 있습니다. 이러한 결과는 성공적인 세분화를 위해 PAR 및 대화 컨텍스트 추적의 중요성을 강조합니다. S3-DST의 강력한 성능은 또한 DialSeg711이 앞으로 LLM에게 충분히 어려운 작업이 아닐 수 있음을 시사하며, 궁극적으로 상태 추적 성능을 개선하는 것이 분할의 목표이기 때문에 공동 분할 및 상태 추적의 필요성을 더욱 부추깁니다.5 관련 연구 5.1 대화 상태 추적 인간-AI 대화의 흐름을 정확하게 추적하려면 사용자의 의도와 목표를 추론하는 데 강력한 상태 추적이 중요합니다.MultiWOZ(Budzianowski et al., 2018) 데이터 세트를 커뮤니티에 도입한 이후 DST 성능을 개선하기 위한 수많은 기술이 제안되었습니다.복제 메커니즘(Lei et al., 2018), 전이 학습(Wu et al., 2019), 데이터 증강(Zhang et al., 2020), 대조적 사전 학습(Wu et al., 2020) 등을 포함한 이전 시도는 감독 미세 조정 시나리오에서 개선을 가져왔습니다. 한편, MultiWOZ도 여러 차례 주석 개정을 거쳤습니다(Eric 등, 2019; Ye 등, 2021; Zang 등, 2020; Han 등, 2020). 다른 기술(Peng 등, 2021; Lin 등, 2020; Zhao 등, 2022; Yu 등, 2020; Platanios 등, 2021)도 제안되었지만, 데이터 레이블링의 리소스 집약적이고 힘든 특성으로 인해 점차 few-shot 및 zero-shot 대화 상태 추적 탐색으로 관심이 옮겨갔습니다(Shin 등, 2022; Hu 등, 2022; Heck 등, 2023). 이 분야의 최첨단 접근 방식(Hu et al., 2022)은 상태 추적을 위해 LLM을 활용할 수 있지만, 실제 확장 대화 세션에서 성능을 잠재적으로 저하시킬 수 있는 적절한 접지 메커니즘이 현저히 부족합니다.게다가 앞서 언급한 이전 작업 중 어느 것도 유연한 오픈 도메인 LLM 기반 채팅 시스템에서 널리 퍼져 있는 주제 일관성과 컨텍스트 전환을 설명하지 않습니다.5.2 대화 주제 세분화 대화를 주제별로 일관된 단위로 세분화하는 것은 다운스트림 대화 모델링의 성공에 기초가 됩니다.주석이 달린 데이터의 부족은 대화 주제 세분화에서 과제였지만, 최근의 비지도 시도는 주제 세분화에서 몇 가지 유망한 결과를 보여주었습니다.더 구체적으로, 고전적인 텍스트 세분화 알고리즘인 TextTiling(Hearst, 1997)을 기반으로 하는 확장은 이 측면에서 주로 벤치마크를 주도했습니다(Song et al., 2016). 더 최근에는 텍스트 쌍 일관성 점수(Xing 및 Carenini, 2021)와 주제 인식 표현 학습(Gao 등, 2023)이 최첨단 기술을 발전시켰습니다. 그럼에도 불구하고 이러한 모든 기술은 대화의 완전한 맥락적 본질을 설명하는 데 부족합니다(즉, 의도 및 기타 중요한 상태 변수를 명시적으로 모델링). 이는 최적이 아닌 결과로 이어질 수 있습니다. 5.3 의도 분류 대화 상태 추적과 관련하여 작업 지향 대화 시스템의 또 다른 근본적인 문제는 의도 분류(IC)입니다. 종종 다른 보완적인 문제 슬롯 채우기(SF)와 함께 연구자들은 수년에 걸쳐 광범위한 기술을 제안하여(Liu 및 Lane, 2016; Zhang 및 Wang, 2016; Goo 등, 2018; Qin 등, 2019, 2021) 인기 있는 공개 데이터 세트에서 인상적인 성과를 달성했습니다. Few-shot 기법은 또한 공동 IC/SF 작업을 위한 데이터 제약 시나리오에서 조사되었습니다(Krone et al., 2020; Bhathiya and Thayasivam, 2020; Liu et al., 2021). DST와 관련이 있지만 IC/SF는 주로 개별 발화를 격리하여 처리하므로 대화 세션 내에서 여러 발화에 걸쳐 복잡한 맥락적 연결을 모델링해야 하는 실제 인간-AI 대화에는 적합하지 않습니다. 6 토론 및
--- CONCLUSION ---
LLM 기반 채팅 시스템은 인간-AI 대화의 지평을 넓혀 사용자 의도를 추적하기 위한 새로운 방법을 보장합니다. 따라서 주제별로 일관된 세그먼트와 세그먼트당 상태 의도 변수를 공동으로 추적하여 대화 상태 추적을 오픈 도메인 대화 시스템 영역으로 가져옵니다. 모든 분야에서 주석을 달기에는 비실용적이기 때문에 제로샷 설정을 가정해야 하므로 오픈 도메인 상태 추적을 위해 제로샷 프롬프팅을 사용하는 구조화된 분할 및 상태 추적 방식인 S3-DST를 제안합니다. S3-DST는 프롬프트를 XML 형식으로 구조화하고 제안된 그라운딩 메커니즘(PAR)을 활용하여 긴 컨텍스트 추적을 수행합니다. 독점 및 공개 데이터 세트에 대한 광범위한 실험을 통해 S3-DST는 대화 상태 추적 및 분할 방식에서 최첨단 제로샷 기술보다 성능이 크게 향상되었습니다. 앞으로 LLM 기반 채팅 시스템이 더 보편화됨에 따라 대화 시스템 연구가 오픈 도메인 대화를 이해하고 모델링하는 방향으로 더욱 이동할 것으로 예상합니다. 이와 관련하여, 우리는 확장된 컨텍스트 보존을 위한 기술을 더욱 연구하고 개발하여 다른 중요한 대화 모델링 작업과 함께 DST에서 그라운딩을 개선하는 것을 목표로 합니다. 참고문헌 Hemanthage S Bhathiya 및 Uthayasanker Thayasivam. 2020. Meta learning for few-shot joint intent detection and slot-filling. 제5회 기계 학습 기술 국제 컨퍼런스 회의록, 86-92페이지. Paweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, Iñigo Casanueva, Stefan Ultes, Osman Ramadan 및 Milica Gasic. 2018. Multiwoz-작업 지향 대화 모델링을 위한 대규모 다중 도메인 wizard-of-oz 데이터 세트. 2018년 자연어 처리 경험적 방법 컨퍼런스 회의록, 5016-5026페이지. Mihail Eric, Rahul Goel, Shachi Paul, Adarsh Kumar, Abhishek Sethi, Peter Ku, Anuj Kumar Goyal, Sanchit Agarwal, Shuyang Gao, Dilek Hakkani-Tur. 2019. Multiwoz 2.1: 상태 수정 및 상태 추적 기준이 있는 통합 다중 도메인 대화 데이터 세트. arXiv 사전 인쇄본 arXiv:1907.01669. Joseph L Fleiss. 1971. 여러 평가자 간의 명목 척도 일치도 측정. Psychological Bulletin, 76(5):378. Haoyu Gao, Rui Wang, Ting-En Lin, Yuchuan Wu, Min Yang, Fei Huang, Yongbin Li. 2023. 주제 인식 발화 표현을 사용한 비지도 대화 주제 분할. 정보 검색 연구 및 개발에 관한 제46회 국제 ACM SIGIR 연례 컨퍼런스 회의록. Jianfeng Gao, Michel Galley, and Lihong Li. 2018. Neural approach to conversational ai. In The 41st international ACM SIGIR conference on research &amp; development in information retrieval, pages 13711374. Chih-Wen Goo, Guang Gao, Yun-Kai Hsu, Chih-Li Huo, Tsung-Chieh Chen, Keng-Wei Hsu, and Yun-Nung Chen. 2018. Slot-gated modeling for joint slot filling and intent prediction. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 753-757. Ting Han, Ximing Liu, Ryuichi Takanobu, Yixin Lian, Chongxuan Huang, Wei Peng, and Minlie Huang. 2020. Multiwoz 2.3: 주석 수정 및 공동 참조 주석으로 강화된 다중 도메인 작업 지향 데이터 세트. arXiv 사전 인쇄본 arXiv:2010.05594. Marti A Hearst. 1997. 텍스트 타일링: 텍스트를 다중 단락 하위 주제 구절로 분할. 계산 언어학, 23(1):33–64. Michael Heck, Nurul Lubis, Benjamin Ruppik, Renato Vukovic, Shutong Feng, Christian Geishauser, Hsienchin Lin, Carel van Niekerk, Milica Gasic. 2023. 제로샷 대화 상태 추적을 위한 ChatGPT: 솔루션인가 기회인가? 계산 언어학 협회(제2권: 단편 논문) 제61회 연례 회의록, 936-950쪽, 캐나다 토론토. Association for Computational Linguistics. Yushi Hu, Chia-Hsuan Lee, Tianbao Xie, Tao Yu, Noah A. Smith, and Mari Ostendorf. 2022. Incontext learning for few-shot dialogue state tracking. In Findings of the Association for Computational Linguistics: EMNLP 2022, pages 2627-2643, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics. Jason Krone, Yi Zhang, and Mona Diab. 2020. Learning to classify intents and slot label given a few examples. arXiv preprint arXiv:2004.10793. Wenqiang Lei, Xisen Jin, Min-Yen Kan, Zhaochun Ren, Xiangnan He, and Dawei Yin. 2018. Sequicity: Simplifying task-driven dialogue systems with single sequence-to-sequence architectures. 제56회 연례 총회 논문집(제1권: 장문 논문), 1437-1447쪽. Zhaojiang Lin, Andrea Madotto, Genta Indra Winata, Pascale Fung. 2020. Mintl: 과제 지향 대화 시스템을 위한 최소 전이 학습. arXiv 사전 인쇄본 arXiv:2009.12005. Bing Liu와 Ian Lane. 2016. 조인트 의도 감지 및 슬롯 채우기를 위한 주의 기반 순환 신경망 모델. arXiv 사전 인쇄본 arXiv:1609.01454. Han Liu, Feng Zhang, Xiaotong Zhang, Siyang Zhao, Xianchao Zhang. 2021. fewshot 의도 분류 및 슬롯 채우기를 위한 명시적 조인트 및 지도 대조 학습 프레임워크. arXiv 사전 인쇄본 arXiv:2110.13691. Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2023. Lost in the middle: How language models use long contexts. arXiv 사전 인쇄본 arXiv:2307.03172. Baolin Peng, Chunyuan Li, Jinchao Li, Shahin Shayandeh, Lars Liden, and Jianfeng Gao. 2021. Soloist: Building task bots at scale with transfer learning and machine teaching. Transactions of the Association for Computational Linguistics, 9:807–824. Lev Pevzner and Marti A Hearst. 2002. A critique and improvement of an evaluation metric for text segmentation. Computational Linguistics, 28(1):19– 36. Emmanouil Antonios Platanios, Adam Pauls, Subhro Roy, Yuchen Zhang, Alexander Kyte, Alan Guo, Sam Thomson, Jayant Krishnamurthy, Jason Wolfe, Jacob Andreas, Dan Klein. 2021. 값에 독립적인 대화 의미 구문 분석. 제59회 전산 언어학 협회 연례 회의록 및 제11회 자연어 처리 국제 공동 컨퍼런스(제1권: 장문 논문), 3666-3681쪽, 온라인. 전산 언어학 협회. Libo Qin, Wanxiang Che, Yangming Li, Haoyang Wen, Ting Liu. 2019. 구어 이해를 위한 토큰 수준 의도 감지 기능이 있는 스택 전파 프레임워크. arXiv 사전 인쇄본 arXiv:1909.02188. Libo Qin, Tailu Liu, Wanxiang Che, Bingbing Kang, Sendong Zhao, and Ting Liu. 2021. 조인트 슬롯 채우기 및 의도 감지를 위한 공동 상호 작용 변환기. ICASSP 2021-2021 IEEE 국제 음향, 음성 및 신호 처리 컨퍼런스(ICASSP), 8193-8197페이지. IEEE. 신재민, 유한열, 문형돈, 안드레아 마도토, 박준영. 2022. 대화 요약을 대화 상태로(DS2), few-shot 대화 상태 추적을 위한 템플릿 기반 요약. ACL 2022의 연구 결과, 3824-3846페이지, 더블린, 아일랜드. ACL. Yiping Song, Lili Mou, Rui Yan, Li Yi, Zinan Zhu, Xiaohua Hu, and Ming Zhang. 2016. 임베딩 강화 텍스트 타일링을 통한 대화 세션 분할. arXiv 사전 인쇄본 arXiv:1610.03955. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824-24837. Jason D Williams, Antoine Raux, and Matthew Henderson. 2016. 대화 상태 추적 챌린지 시리즈: 리뷰. Dialogue &amp; Discourse, 7(3):4–33. Chien-Sheng Wu, Steven CH Hoi, Richard Socher, and Caiming Xiong. 2020. TOD-BERT: 과제 지향 대화를 위한 사전 훈련된 자연어 이해. 2020 자연어 처리 경험적 방법(EMNLP) 컨퍼런스 회의록, 917-929쪽, 온라인. Association for Computational Linguistics. Chien-Sheng Wu, Andrea Madotto, Ehsan Hosseini-Asl, Caiming Xiong, Richard Socher, Pascale Fung. 2019. 과제 지향 대화 시스템을 위한 이전 가능한 다중 도메인 상태 생성기. Association for Computational Linguistics의 제57회 연례 회의 회의록, 808-819쪽, 이탈리아 피렌체. Association for Computational Linguistics. Jinxiong Xia, Cao Liu, Jiansong Chen, Yuchen Li, Fan Yang, Xunliang Cai, Guanglu Wan, Houfeng Wang. 2022. 이웃 평활화를 사용한 병렬 추출 네트워크를 통한 대화 주제 분할. 정보 검색 연구 및 개발에 관한 제45회 국제 ACM SIGIR 컨퍼런스 회의록, 2126-2131쪽. Linzi Xing과 Giuseppe Carenini. 2021. 발화 쌍 일관성 점수로 비지도 대화 주제 분할 개선. 담화 및 대화에 관한 특별 관심 그룹의 제22회 연례 회의 회의록, 167-177쪽, 싱가포르 및 온라인. 계산 언어학 협회. Yi Xu, Hai Zhao, Zhuosheng Zhang. 2021. Topicaware 다중 턴 대화 모델링. 인공지능에 관한 AAAI 컨퍼런스 회의록, 35권, 14176-14184쪽. Fanghua Ye, Jarana Manotumruksa, Emine Yilmaz. 2021. Multiwoz 2.4: 상태 추적 평가를 개선하기 위한 필수 주석 수정이 포함된 다중 도메인 작업 지향 대화 데이터 세트. arXiv 사전 인쇄본 arXiv:2104.00773. Tao Yu, Rui Zhang, Alex Polozov, Christopher Meek, Ahmed Hassan Awadallah. 2020. Score: 대화 의미 구문 분석에서 맥락 표현을 위한 사전 학습. International Conference on Learning Representations에서. Xiaoxue Zang, Abhinav Rastogi, Srinivas Sunkara, Raghav Gupta, Jianguo Zhang, Jindong Chen. 2020. Multiwoz 2.2: 추가 주석 수정 및 상태 추적 기준이 포함된 대화 데이터 세트. arXiv 사전 인쇄본 arXiv:2007.12720. Xiaodong Zhang 및 Houfeng Wang. 2016. 구어체 이해를 위한 의도 결정 및 슬롯 채우기의 공동 모델. IJCAI, 16권, 2993-2999페이지. Yichi Zhang, Zhijian Ou, Zhou Yu. 2020. 동일한 맥락에서 여러 가지 적절한 응답을 고려하는 작업 지향적 대화 시스템. AAAI 인공지능 컨퍼런스 회의록, 34권, 9604-9611페이지. Jeffrey Zhao, Raghav Gupta, Yuan Cao, Dian Yu, Mingqiu Wang, Harrison Lee, Abhinav Rastogi, Izhak Shafran, Yonghui Wu. 2022. 설명 중심 작업 지향적 대화 모델링. arXiv 사전 인쇄본 arXiv:2201.08904. A 프롬프트<preceding_topical_relation> {유효한 선행 A.1 S3-DST 프롬프트 Bing Chat 아래는 S3-DST에 대한 전체 프롬프트이며, 템플릿 값은 중괄호로 묶인 의도 레이블 이름 또는 설명으로 대체됩니다. 부록 B는 상태 값의 전체 목록을 제공합니다.<valid_domains><item> {유효한 도메인 라벨 이름}</item> 주제별 관계 라벨}</preceding_topical_relation><intent> {유효한 의도 라벨}</intent><domain> {유효한 도메인 라벨}</domain></T{turn number}> ## 입력 ## {XML 구조의 대화} ## 출력 ##</valid_domains><valid_preceding_topical_relation><item><name> 예</name><desc> 현재 차례는 대화 맥락과 어느 정도 주제/하위 주제와 관련이 있습니다.</desc></item><item><name> 아니요</name> 또는 이전의**<desc> 현재 턴은 이전 대화 맥락과 주제/하위 주제와 전혀 관련이 없거나 대화의 첫 번째 턴으로, 새로운 대화 세그먼트의 시작을 나타냅니다.</desc></item></valid_preceding_topical_relation><valid_intents><item><name> {유효한 의도 레이블 이름}</name><desc> {의도 설명}</desc></item> &quot;No PAR&quot; 기준선의 경우 프롬프트에서 턴 요약 지침과 요약 태그를 제거합니다. &quot;Unstructured input&quot; 기준선의 경우 대화를 T1에서 T{t}까지 번호가 매겨진 일반 텍스트 턴 목록으로 입력합니다. TBT-DST 기준선의 경우 프롬프트에서 모든 세분화 지침과 레이블을 제거하고 모델에서 턴당 유효한 의도와 도메인을 출력하도록 합니다. DialSeg711 데이터 세트의 경우 의도와 도메인과 관련된 모든 지침과 값을 제거하고 모델에서 턴 수준 요약과 세그먼트 레이블만 출력하도록 합니다. MWOZ 아래는 MWOZ 데이터 세트의 S3-DST 프롬프트입니다. 슬롯에 대한 모든 설명은 GPT4에서 생성되었습니다.<slots><item><name> 택시로 출발하다</name><description> 사용자가 택시를 타고 싶어하는 시간</description></item><item></valid_intents> ## 작업 ## T로 시작하는 턴으로 구성된 사용자와 에이전트 간의 대화가 제공됩니다. 각 턴에 대해 다음 질문에 답해야 합니다. - 턴을 &lt;=3개 문장으로 요약합니다. 다음을 사용하여 prior_topical_relation 레이블을 출력합니다.<valid_preceding_topical_relation> ...</valid_preceding_topical_relation> list 의도 레이블을 출력합니다.<valid_intents> ...</valid_intents> list 도메인 레이블을 출력합니다.<valid_domains> ...</valid_domains> list - leading_topical_relation이 YES인 경우 세그먼트의 모든 턴에 대해 정확히 동일한 의도 및 도메인 레이블을 사용해야 합니다. ## 출력 형식 ##<T{turn number}><summary> {3개 이하의 문장으로 요약을 작성하세요}</summary><name> {도메인}-{의도} </name><description{description of slot}</description><valid_values> {해당되는 경우 슬롯에 대한 유효한 범주형 값, 그렇지 않으면 이 태그가 나타나지 않음}</valid_values></item> ...</slots> ## 작업 ## T로 시작하는 턴으로 구성된 사용자와 에이전트 간의 대화가 주어집니다. 각 턴마다 다음 질문에 답해야 합니다. 사용자 발화를 그대로 출력합니다. - 해당 발화를 기반으로 관련 슬롯에 대한 사용자 선호도에 대한 관련 정보를 추출합니다.<slots> ...</slots> 그리고 [&#39;{SLOT}-{value}&#39;] 형식을 따르는 태그 목록으로 표현합니다. 여기서 value는 해당 SLOT에 대한 구체적인 정보입니다. - 목록에서 중복 또는 충돌하는 쌍을 제거합니다. 같은 SLOT이 목록에 두 번 이상 나타나는 경우 사용자 발화에서 가장 최근 또는 관련성 있는 값만 유지합니다. - 같은 SLOT에 대한 값이 서로 모순되는 경우 **가장 최근의** 사용자 제공 값을 유지하여 충돌을 해결합니다. 최종 목록을 작업 결과로 출력합니다. [&#39;{SLOT}-{value}&#39;]에 대한 출력 예. 예를 들어, 출력은 [&#39;hotel-book day-monday&#39;, &#39;hotel-book number_of people-3&#39;, &#39;hotel-book number_of_days-4&#39;, &#39;hotel-name-wartworth&#39;, &#39;hotel-parking-yes&#39;, &#39;hotel-area-east&#39;, &#39;hotel-stars-4&#39;, &#39;hotel-internet-yes&#39;, &#39;train-book number_of_people-1&#39;, &#39;train-destination-bishops stortford&#39;, &#39;train-day-friday&#39;, &#39;train-arrive_by_time-19:45&#39;, &#39;train-departure-cambridge&#39;]와 같을 수 있습니다. 선택된 슬롯이 미리 정의된 슬롯에서만 사용되는지 확인하십시오.<slots> ...</slots> 목록. 만약<valid_values> ...</valid_values> 슬롯에 대해 언급된 경우 해당 슬롯에 유효한 값 중 하나를 사용해야 합니다. - 사용자가 명시적으로 언급한 경우에만 dontcare 값을 사용합니다. 이제 **모든 턴**에 대해 다음 질문에 답하세요.<T{turn number}><agent_context> {마지막 에이전트 발언 그대로}</agent_context><user_utterance> {턴의 사용자 발언 그대로}</user_utterance> ) /* ## 선택한 열-값 쌍에 대한 설명: leading_topical_relation-NO: 현재 턴은 이전 대화 맥락과 **전혀** 주제/하위 주제 관계가 없거나 대화의 첫 번째 턴으로, 새 대화 세그먼트의 시작을 표시합니다. - leading_topical_relation-YES: 현재 턴은 이전 대화 맥락과 **일부 또는 일부** 주제/하위 주제 관계가 있습니다. intent-정보 검색: 사용자가 사실 정보나 특정 질문에 대한 답변을 찾고자 합니다. {나머지 의도와 설명은 여기에 있습니다} */ ## 작업 ## 유효한 SQLite를 사용하여 위에 제공된 표에 대한 다음 다중 턴 대화 질문에 답합니다. 다음 단계를 사용합니다. - T로 시작하는 각 사용자 에이전트 턴에 대해 답변 SQL 쿼리를 출력합니다. - leading_topical_relation이 YES인 경우 세그먼트의 모든 턴에 대해 정확히 동일한 의도와 도메인 레이블을 사용해야 합니다. T로 시작하는 차례당 하나의 SQL 쿼리를 포함하여 답변을 목록으로 출력합니다. ## 출력 형식 ## T{차례 번호}. SELECT * from states WHERE leading_topical_relation = {귀하의 답변} AND intent = {귀하의 답변} AND domain = {귀하의 답변}; ## 입력 ##<updated_slot_value> [&#39;{슬롯}-{값}&#39;]<slots> ...</slots> 값&gt;...</valid_values> 슬롯 목록을 업데이트하고 사용 중입니다. <valid_appropriate {input dialogue} ## OUTPUT ## slots </updated_slot_value></T{turn number}>##INPUT## {XML 구조 대화} ##OUTPUT## A.2 IC-DST 프롬프트 아래는 Bing Chat 데이터 세트에 맞게 조정된 IC-DST 프롬프트입니다. DialSeg711 데이터 세트의 경우 도메인 및 의도 열과 지침을 간단히 제거합니다. CREATE TABLE states( domain text CHECK (domain IN ({valid domain names)), prioring_topical_relation text CHECK (preceding_topical_relation IN (YES, NO)), intent text CHECK (intent IN ({valid intent names)), B Annotation Details B.1 annotators에게 제공된 레이블 아래에서는 Bing Chat 데이터세트 annotators에게 제공된 레이블과 설명(있는 경우)을 제공합니다. Intent와 domain의 경우, GPT4에 대화 로그 샘플을 요약하고, 주요 테마를 추출하고, 이러한 테마를 비교하여 다양한 유형의 Intent와 domain 간의 주요 차이점을 식별하도록 요청하는 반복적이고 반자동화된 프로세스를 사용하여 레이블 이름과 Intent 설명을 개발했습니다. IsSegmentBoundary • NO: 현재 턴은 이전 대화 컨텍스트와 구문적, 의미적 또는 주제적 관계가 없거나 대화의 첫 번째 턴입니다. • YES: 현재 턴은 이전 대화 컨텍스트와 구문적, 의미적 또는 주제적 관계가 있습니다. SegmentIntent • 정보 탐색: 사용자는 사실 정보나 특정 질문에 대한 답을 찾고 싶어합니다. • 분석: 사용자는 복잡한 주제나 문제에 대한 분석적 또는 개념적 질문을 합니다. 사용자의 질문에는 어느 정도의 추론, 해석, 논증, 비교 및/또는 데이터 처리가 필요합니다. • 생성: 사용자는 에이전트에게 지정된 기준이나 제약 조건에 따라 원본 콘텐츠를 생성하거나 기존 콘텐츠를 새 콘텐츠로 변환하도록 요청합니다. • 개방형 발견: 사용자는 호기심, 지루함 또는 유머로 인해 에이전트와 캐주얼하게 채팅하거나 놀고 싶어하거나 사용자의 의도가 너무 불분명하거나 구체적으로 지정되지 않아 다른 의도 클래스로 분류하는 것이 불가능합니다. 사용자는 주로 에이전트를 대화나 수다스러운 파트너로 취급하며 다른 의도 카테고리는 할당할 수 없습니다. SegmentDomain • AI 머신 러닝 및 데이터 과학 • 점성술 • 생물학 및 생명 과학 • 비즈니스 및 마케팅 • 경력 및 구직 신청 • 의류 및 패션 • 요리 음식 및 음료 • 공예 • 문화 및 역사 • 사이버 보안 • 데이트 우정 및 관계 ⚫ 디자인 • 교육 • 엔터테인먼트 • 환경 농업 및 에너지 • 가족 양육 및 결혼 • 금융 및 경제 • 게임 • 지리 및 지질학 • 건강 및 의학 • 주택 및 주택 • 유머 및 풍자 • 언어 • 법률 및 정치 • 문학 및 시 • 제조 및 재료 • 수학 논리 및 통계 • 음악 및 오디오 • 뉴스 • 반려동물 및 동물 ⚫ 철학 • 물리학 화학 및 천문학 • 생산성 • 심리학 및 감정 • 종교 및 신화 • 배송 및 배달 • 쇼핑 및 선물 • 잡담 • 소셜 미디어 • 소프트웨어 및 웹 개발 • 스포츠 및 피트니스 • 과세 • 기술 • 시간 및 날짜 • 운송 자동차 및 항공우주 • 여행 • 시각 예술 및 사진 • 날씨 • 글쓰기 저널리즘 및 출판 B.2 도메인 라벨링 절차 도메인 값의 수가 많고 의견 불일치와 인지 과부하가 발생할 가능성이 높기 때문에 주석자에게 턴당 전체 도메인 목록에서 선택하도록 요청하지 않았습니다. 대신, 우리는 턴당 5개의 옵션 드롭다운 목록을 제공했습니다. 한 옵션은 저자가 직접 옳거나 거의 옳다고 선택했습니다. 두 옵션은 Python을 사용하여 무작위로 선택했습니다. 한 옵션은 &quot;OTHER&quot;로, 이 경우 주석자는 49개 도메인의 전체 목록에서 올바른 도메인을 선택하고 선택 사항을 설명해야 했습니다. 마지막으로, 마지막 옵션은 다음 절차를 사용하여 선택한 &quot;hard negative&quot;였습니다. 먼저, 우리는 도메인을 STEM, 예술, 사회 과학, 건강, 상거래, 전문직, 개인 및 여가의 8개 상위 클러스터로 수동으로 그룹화했습니다. 그런 다음 저자가 선택한 앞서 언급한 &quot;ground-truth&quot; 도메인이 주어지면, ground-truth 레이블과 동일한 상위 클러스터에서 다른 도메인을 무작위로 샘플링했습니다. 예를 들어, groundtruth 도메인이 &quot;BIOLOGY AND LIFE SCIENCE&quot;로 선택된 경우, 우리는 STEM 클러스터에서 다른 도메인을 최종 도메인 후보로 샘플링했습니다.
