--- Page 1 ---
arXiv:2308 .05884v1 [cs.CL] 11 Aug 2023

PIPPA: A Partially Synthetic Conversational Dataset

Tear Gosling TEARGOSLING@PYGMALION.CHAT

PYGMALIONAI

Alpin Dale ALPINDALE@PYGMALION.CHAT

PYGMALIONAI

Editor: Yinhe Zheng ‘ ZHENGYINHE1 @163.COM
Abstract

With the emergence of increasingly powerful large language models, there is a burgeoning
interest in leveraging these models for casual conversation and role-play applications. How-
ever, existing conversational and role-playing datasets often fail to capture the diverse and
nuanced interactions typically exhibited by real-world role-play participants. To address
this limitation and contribute to the rapidly growing field, we introduce a partially-synthetic
dataset named PIPPA (Personal Interaction Pairs between People and AI). PIPPA is a re-
sult of a community-driven crowdsourcing effort involving a group of role-play enthusiasts.
The dataset comprises over 1 million utterances that are distributed across 26,000 conver-
sation sessions and provides a rich resource for researchers and AI developers to explore
and refine conversational AI systems in the context of role-play scenarios.

Keywords: conversational dataset; role-play dataset; fine-tuning; large language model

1. Introduction

In recent years, the field of natural language processing has experienced a significant trans-
formation, primarily driven by the remarkable advancements in large language models
(LLMs). These models, fueled by extensive pre-training data and computational resources,
exhibit an extraordinary ability to comprehend and generate human-like text. In order
to harness their full potential and tailor them to specific domains, a set of high quality
domain-specific samples are typically required during the supervised fine-tuning process
(Zhou et al., 2023; Ouyang et al., 2022).

A promising application of LLMs, which is somewhat overshadowed by others in academia,
is to build dialogue agents specialized in role-play (Shanahan et al., 2023). Specifically, given
a text-based description of some character or persona, the agent can simulate this character
while users interact with the agent for the purposes of entertainment.

Similar to numerous applications that necessitate the intricate capabilities of LLMs,
effectively fine-tuning an LLM into a proficient role-play agent demands a substantial corpus
of conversation and role-play centered texts. This is particularly crucial when employing
small base models, which offer greater convenience and cost-effectiveness in deployment and

*. Tear Gosling and Alpin Dale were primarily responsible for curating and assembling the PIPPA dataset,
as well as formulating the preliminary version of the paper. Yinhe Zheng contributed to the refinement
of the paper through substantive revisions.

--- Page 2 ---
inference. However, despite the importance of such datasets,
open-source datasets tailored to serve this purpose.

To address the above issue and mitigate this gap, we intro

here is a notable scarcity of

duce a novel dataset, named

Personal Interaction Pairs between People and AI (PIPPA). PIPPA is a large-scale dataset,

comprising approximately 1 million messages exchanged be

ween humans and dialogue

agents across nearly 26,000 unique conversations. Notably, each conversation session fea-
tures a designated persona, which serves as the emulation target for the dialogue agent.
The persona of each character is delineated through free text descriptions, and optional

example dialogues are also supplied to facilitate accurate simu.

ation of each character. The

introduction of PIPPA aims to support future research and development in the fine-tuning

of models to generate persona-driven, contextually rich conversations.

We make PIPPA publicly available on the HuggingFace plat
co/datasets/PygmalionAI/PIPPA allowing anyone to utilize
purposes.

2. Dataset Compilation

form at https: //huggingface.
it freely for their respective

The PIPPA dataset was assembled through the voluntary contributions of community mem-

bers who actively engaged in our initiative to develop conversa

tional models that are acces-

sible to all. We leveraged a userscript to gather chatlogs and character descriptions from
the Character.AI website | (Figure 1). This script enables users to extract interactions and

persona details of dialogue agents on Character.AI, who wer

e instructed to submit their

chatlog data to a centralized server for the purpose of constructing the PIPPA dataset

(Figure 5).

Initially, PIPPA was primarily conceived to furnish a fine-tuning dataset for the Pyg-

2

malion“ conversational models, a series of fine-tuned LLMs

aimed at creating role-play

agents. The collection of PIPPA began in December 2022, when the availability of high
quality dialogue data was notably scarce. This endeavor, however, also encountered a chal-
lenge in regards to striking a balance between supporting the community and safeguarding

personal information within the logs. As a result, we implemented a submission process
that allowed users to opt out of including their conversations in the public release. PIPPA
solely contains logs for which users have explicitly granted permission for public distribu-
tion. Furthermore, we diligently performed comprehensive scans to detect and redact/mod-

ulate personally identifiable information (PII) within the publ

icly accessible portion of the

dataset, to the best of our ability, ensuring the protection of submitter identities.

3. Dataset Analysis

The PIPPA dataset encompasses a substantial collection of conversational data, encom-
passing 25,940 conversations that involve 1,254 distinct personas and 1,049,015 dialogue

sessions.

1. Due to subsequent changes to the Character.AI website, the userscript

is no longer functional. The script

can be found at https: //github.com/0x000011b/characterai-dumper

2. The models can be accessed at https://huggingface.co/PygmalionAI

--- Page 3 ---
en OOO
< sae ce ~~ [Interaction count

Pol name Remember: Everything Characters say is made up!

JRR Tolkien GED
Tam J.R.R. Tolkien, english writer, poet, philologist, and academic, best

known as the author of the high fantasy works The Hobbit and The Lord
of the Rings.

Pro-defined greeting message
by bot creator

Alpid
Mr Tolkien. How do you do?

JRR Tolkien GE)
Tam fine my boy, though Iam getting quite old now! I am 74 years old
already (the same age as Bilbo, and not unlike him | don't feel it!)

Alpid

Hahal I was to Avebury today. Lovely place. A local showed me to a tree
there, said you were inspired by that very tree when writing about the
Ents!

JRR Tolkien GED

Really? What a nice coincidence! I love trees, and many of them inspired
me to create the Ents. Even in the Shire the trees had a presence (I think
of the Old Willows, and the great oak at Bywater). It is a good thing that

many people nowadays seem to understand the importance of >
conserving our trees.

Swipe button

Figure 1: Screenshot of CharacterAl’s chat interface. Swipes refer to discarding the current
bot generation and prompting for a new one.

Each sample in PIPPA dataset comprises a dialogue session and a diverse set of associ-
ated metadata. Additionally, we also provide the information about the bot, which includes
categories assigned by bot creators, a bot description offering a succinct overview of the
bot’s persona and traits, an optional bot definition that further fleshes out the bot’s
personality through example conversations, and the bot’s greeting to the user. The bot’s
greeting serves as the initial entry in every conversation. Furthermore, we maintain a times-
tamp to document when the dialogue is submitted to us. It is important to note that that
we cannot access information regarding when the conversations themselves were generated,
as this information is not provided by the Character.AI website.

The statistical analysis of the PIPPA dataset offers valuable insights into three crucial
aspects: the number of turns in a conversation, the length of a singular message and the
distribution of bot personalities. In this section, we present key statistical findings.

3.1 Conversation Length

Conversations in PIPPA exhibits a diverse range of lengths, displaying a notable skewed dis-
tribution. While the median conversation length is 10 turns, the mean conversation length
is remarkably higher at 40.41 turns. However, the presence of a large standard deviation of
145 turns indicates substantial dispersion in the data. This discrepancy can be attributed to
the diverse conversational behavior of users interacting with bots on Character.AI. While a
considerable number of users engage in shorter individual conversations with the bots, some
users participate in remarkably extensive conversations, with the longest conversation in the

--- Page 4 ---
B »
2 z

Conversations (log scale)

i)

Mi

i} 100 150
# of turns in conversation

Figure 2: The distribution of conversation length (defined as the amount of ”turns” in
a conversation). We have limited the display range to 0-250 turns in order to
enhance readability.

fmm LLM messages
mmm Human messages

Frequency (log scale)

1000

|
un
Wii

Conversation Length (Words)

Figure 3: Distribution of message length in the PIPPA dataset for both human inputs and
bot responses.

dataset containing a staggering 11,491 turns. Figure 2 depicts the log scale distribution of
turn lengths up to 250 turns.

--- Page 5 ---
250

200

100

50

Love

Game Characters

Coney TT

Science Fiction

Advice
Philosophy J
Debate
Mystery J
Knowledge
Viuber
Food

Anime

Action

Anime Game Chars
Drama

Games

Animals

Count
° 3
‘anasy |

Movies & TV [ay
Cooperative
Famous People [IN
Technology [I
Decisions [I

Discussion

Friertainnent TT

Category

Figure 4: Distribution of categories of characters in the PIPPA dataset. Note that each bot
may be assigned multiple categories or none at all.

3.2 Message Verbosity

We also analyze the verbosity (i.e., length) of messages generated by both human users and
bots within the PIPPA dataset. As evidenced by Figure 3, the verbosity distribution of all
messages in PIPPA can be characterized by a power-law distribution, indicating a higher
prevalence of shorter messages compared to longer ones. It is also worth noting that the
LLM’s responses generally exhibit greater verbosity than human inputs. This observation
may be attributed to Character.AIl’s LLM potentially being trained or fine-tuned on a
high-quality role-play corpus, which typically contains longer messages comparing to casual
conversations.

3.3 Bot Personality Categories

Within the PIPPA dataset, each bot is assigned a set of category labels by its creator. An
analysis of bot personality categories in PIPPA reveals an uneven, Pareto-like distribution
(see Figure 4). Notably, the categories “Anime”, “Fantasy”, and “Action” emerge as
the most prevalent among the bot personas. This distribution can be attributed to the
characteristics of the source community, PygmalionAI, from which these logs are collected.
The community exhibits a significant number of anime? enthusiasts, resulting in a con-
siderable proportion of bots classified under the “Anime” category. Additionally, due to
the community’s interest in role-play and conversational interactions, many bots are nat-
urally assigned to categories related to prevalent role-playing themes, thus explaining the
prominent presence of bots tagged with “Action” and “Fantasy” labels.

3. Anime refers to animated media produced in Japan.

--- Page 6 ---
4. Related Works

Although conversational and role-play datasets represent a developing subset of common
training datasets for fine-tuning LLMs, there have been some similar datasets prior to the
development of PIPPA. Additionally, certain instructional datasets can frame role-playing
as an instruction for the model to follow. In this section, we investigate these datasets,
delineate their limitations, and compare them to PIPPA.

4.1 Role-Play Datasets

The availability of role-play datasets in the academic domain is limited, with only a hand-
ful of notable publications. Notably, the LIGHT dataset (Urbanek et al., 2019) and its
subsequent extension, MultiLIGHT (Wei et al., 2023), present collections of conversations
simulating interactions within the context of a text-adventure fantasy game. These datasets,
comprised of dialogue exchanges from crowdsourced users, offer valuable insights into the
dynamics of role-play scenarios. Moreover, the FIREBALL dataset (Zhu et al., 2023), al-
though not accessible during PIPPA’s development, contains approximately 25,000 s'
of Dungeons and Dragons conducted via the Discord online platform. While these datasets

ssions

exhibit commendable quality, their applicability is somewhat restricted, as they primarily
focus on specific role-play scenarios within defined settings, rather than encompassing a
diverse range of personas and immersive worlds.

4.2 Conversational Datasets

In contrast to role-play datasets, pure conversational datasets are more abundant. Li et al.
presents DailyDialog, a multi-turn conversational dataset containing discussions and chats
about mundane, daily topics. This dataset, however, lacks any personas or backgrounds
o the speakers. Some datasets also try to explicitly model personas (Zhang et al., 2018;
Zheng et al., 2019), nevertheless, these dialogues are not designed for role-play scenarios
and thus are more suited for casual conversation.

The Cornell Movie Dialogs Corpus (Danescu-Niculescu-Mizil and Lee, 2011), derived
rom a compilation of 617 movies, has been commonly utilized as a standard dataset for
conversational modeling. However, it is not optimally suited for the purpose of simulating
chat-based interactions and role-play scenarios, as movie dialogue often relies on visual cues

and can encompass relatively brief exchanges that may not be optimal for training large
anguage models.

For a more extensive conversational model, large-scale datasets can serve as a valuable
oundation (Wang et al., 2020). Henderson et al. has successfully curated a vast corpus

by scraping hundreds of millions of dialogue turns from platforms like Reddit and Open-
Subtitles. Although this dataset offers considerable volume, it often necessitates trimming
or partitioning. Similar to the DailyDialog dataset, a notable limitation lies in the pre-
dominance of short and casual conversations rather than comprehensive, persona-driven
role-play interactions. Additionally, the OpenSubtitles subset of the dataset shares com-
parable challenges with the Cornell corpus, such as the absence of visual context and brief
dialogue responses.

--- Page 7 ---
4.3 Instructional Datasets

In recent years, instructional datasets have garnered significant attention as comprehensive
resources for chatbot development. Notably, Stanford’s Alpaca model (Taori et al., 2023)
underwent fine-tuning using a synthetically generated dataset, comprising single-exchange
interactions produced by ChatGPT. Remarkably, the total cost associated with dataset
curation and model fine-tuning amounted to less than $600, yet resulted in impressive
performance outcomes.

Motivated by the success achieved by Alpaca, a growing number of instructional datasets
have emerged, often relying on synthetic generation techniques to enhance model training.
Among these, notable advancements have been observed in the realm of multi-turn complex
instructional datasets, as exemplified by datasets such as Evol-Instruct (Xu et al., 2023) and
the OpenAssistant dataset (K6pf et al., 2023). These datasets exhibit greater complexity,
encompassing diverse and intricate instructional scenarios, thereby offering richer contexts
for training and refining models. However, instructional datasets generated by OpenAI
models may not necessarily align with the interests of role-players and may additionally
exhibit limitations during role-play.

Limitations

The current iteration of the dataset is primarily tailored for supervised fine-tuning applica-
tions. Any endeavor to apply the PIPPA dataset to unsupervised fine-tuning objectives may
necessitate a comprehensive overhaul of the dataset’s structure and content presentation.
Additionally, models fine-tuned with the PIPPA dataset might necessitate specific prompt-
ing to make the role-play agent adhere to the context and generate the desirable response.

Ethics Statement

The creation of the PIPPA dataset is the result of a collective and participatory curation
process, involving contributions from a diverse group of anonymous individuals within the
community. This approach brings a rich and varied array of language samples, reflecting
real-world linguistic nuances and usage patterns.

Due to the nature of the community-driven approach and the large-scale collaboration
involved, exhaustive validation of the submitted logs has not been undertaken. Because of
this, the absence of comprehensive validation implies that the dataset may contain variations
in data quality and potential instances of unsuitable or inappropriate material.

Sensitive personal information has been diligently expunged to the extent of our capa-
bilities; however, residual instances might persist owing to inadvertent human oversights.
While the de-identification process was not obligatory for the publicly submitted dataset,
we deemed it a moral imperative to proceed with the redaction of personally identifiable
information (PII) as a matter of ethical prudence.

Acknowledgements

The release of the PIPPA dataset to the wider public marks a significant milestone that
has been eagerly anticipated, and this achievement is the result of collaborative efforts.

--- Page 8 ---
We extend our heartfelt gratitude to a dedicated individual known by the pseudonym
“0x000011b,” whose remarkable dedication and diligent work in devising the userscript
played an instrumental role in enabling users to contribute their logs to the dataset. Fur-
hermore, we thank him for his invaluable contributions extends to the broader development
of the Pygmalion models, embodying a spirit of commitment and innovation.

We would also like to express our sincere appreciation to Dr. Yinhe Zheng for his
invaluable guidance and unwavering support throughout the process of crafting this research
paper. His insightful advice and assistance have been indispensable, and it is with his
guidance that this paper has come to fruition.

Last but not least, a debt of gratitude is owed to all individuals who generously shared
heir logs, playing an essential part in the creation of this dataset. The collective efforts of
hese enthusiastic contributors, along with the passionate members of our community, have
seen the driving force behind the existence of both PIPPA and PygmalionAI. We extend
our heartfelt thanks to each and every individual who has contributed, ensuring that these
endeavors have thrived and flourished. Thank you!


--- Page 9 ---
References

Cristian Danescu-Niculescu-Mizil and Lillian Lee. 2011. Chameleons in imagined conver-
sations: A new approach to understanding coordination of linguistic style in dialogs. In
Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics, ACL
2011.

Matthew Henderson, Pawet Budzianowski, Inigo Casanueva, Sam Coope, Daniela Gerz,
Girish Kumar, Nikola Mrksi¢é, Georgios Spithourakis, Pei-Hao Su, Ivan Vulic, and
Tsung-Hsien Wen. 2019. A repository of conversational datasets. In Proceedings of
the Workshop on NLP for Conversational AI. Data available at github.com/PolyAI-
LDN/conversational-datasets.

Andreas K6pf, Yannic Kilcher, Dimitri von Riitte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith
Stevens, Abdullah Barhoum, Nguyen Minh Duc, Oliver Stanley, Richdérd Nagyfi, Shahul
ES, Sameer Suri, David Glushkov, Arnav Dantuluri, Andrew Maguire, Christoph Schuh-
mann, Huu Nguyen, and Alexander Mattick. 2023. Openassistant conversations — democ-
ratizing large language model alignment.

Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and Shuzi Niu. 2017. Dailydialog:
A manually labelled multi-turn dialogue dataset.

Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin,
Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training lan-
guage models to follow instructions with human feedback. Advances in Neural Informa-
tion Processing Systems, 35:27730-27744.

Murray Shanahan, Kyle McDonell, and Laria Reynolds. 2023. Role-play with large language
models.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin,
Percy Liang, and Tatsunori B. Hashimoto. 2023. Alpaca: A strong, replicable instruction-
following model.

Jack Urbanek, Angela Fan, Siddharth Karamcheti, Saachi Jain, Samuel Humeau, Emily
Dinan, Tim Rocktaschel, Douwe Kiela, Arthur Szlam, and Jason Weston. 2019. Learning
to speak and act in a fantasy text adventure game.

Yida Wang, Pei Ke, Yinhe Zheng, Kaili Huang, Yong Jiang, Xiaoyan Zhu, and Minlie
Huang. 2020. A large-scale chinese short-text conversation dataset. In Natural Language
Processing and Chinese Computing: 9th CCF International Conference, NEPCC 2020,
Zhengzhou, China, October 14-18, 2020, Proceedings, Part I 9, pages 91-103. Springer.

Jimmy Wei, Kurt Shuster, Arthur Szlam, Jason Weston, Jack Urbanek, and Mojtaba
Komeili. 2023. Multi-party chat: Conversational agents in group settings with humans
and models.

Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao,
and Daxin Jiang. 2023. Wizardlm: Empowering large language models to follow complex
instructions.

--- Page 10 ---
Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason We-
ston. 2018. Personalizing dialogue agents: I have a dog, do you have pets too? In
Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics
(Volume 1: Long Papers), pages 2204-2213.

Yinhe Zheng, Guanyi Chen, Minlie Huang, Song Liu, and Xuan Zhu. 2019. Personalized
dialogue generation with diversified traits. arXiv preprint arXiv:1901.09672.

Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia
Efrat, Ping Yu, Lili Yu, et al. 2023. Lima: Less is more for alignment. arXiv preprint
arXiv:2805.11206.

Andrew Zhu, Karmanya Aggarwal, Alexander Feng, Lara J. Martin, and Chris Callison-

Burch. 2023. Fireball: A dataset of dungeons and dragons actual-play with structured
game state information.

10

--- Page 11 ---
Appendix A. Formatting Notes

Because PIPPA consists of logs scraped from Character.AI, the messages follow the general
format of the site which should be handled during pre-processing of the dataset. PIPPA
should not be fed into a LLM without prior pre-processing of the dataset. Par-
ticular attention should be paid to the bot_description field, as it follows a specific format
and should be parsed if one does not wish to follow the example chat format of Character.AI.

The sequence “{{user}}” is a placeholder in both messages and bot descriptions for the
name of whichever human user interacted with the bot. If it is not necessary to explicitly
model the user’s name, one can replace any instances of “{{user}}” with a random name.*

Similarly, bot definitions will often contain the sequence “{{random_user_n}}”, where n

represents some number. This should be treated the same way as “{{user}}”, where each

random user can be replaced by a unique name.

Bot definitions may also contain the sequence “{{char}}”, representing the name of the
character. In this case, “{{char}}” should be replaced by the bot name if one has no special
plans to deal with this sequence. We do not replace it ourselves for the sake of preserving
the entries as they are.

Finally, example chats in the bot_description field are separated by the term “END_OF DIALOG”.
This sequence should be marked as the end of an example chat and the beginning of a new
one, if one is found after it. This is not an EOS token.

Appendix B. Dataset Sample

Each entry in PIPPA is represented as a single line and all entries form a JSONL file. We
present an example directly sampled from PIPPA below:

{
"submission_timestamp": "1674795100921",
"categories": ["Games", "Image Generating", ...],
"bot_id": "Z_eqBXqaixUoyHc...",
"bot_name": "The Winter RPG",
"bot_greeting": "(Welcome to \"Decaying Winter\" an apocalyptic RPG
where you seek survival in a frozen world. Good luck)\r\n\r\n***You

ae ww Ne

a

are currently outside, walking in the snow.***\r\n\r\nYou have your
trusty backpack and knife.\r\n**You are hungry.** So you decided to
look for supplies.\r\n\r\nAfter a while of walking in circles, you
notice a camping site with smoke coming from it.\r\n\r\n***What do
you do now?***",

"bot_definitions": "{{char}}: (Welcome to \"Decaying Winter\" an 7
apocalyptic RPG where you seek survival in a frozen world. Good luck
)\n\n***You are currently outside, walking in the snow.***\n\nYou
have your trusty backpack and knife.\n**You are hungry.** So you
decided to look for supplies.\n\nAfter a while of walking in circles
» you notice a camping site with smoke coming from it.\n\n***What do

you do now?***\n{{random_user_1}}: What is in my inventory?\n...\
nEND_OF_DIALOG",

4. An example list of names can be found at https://github.com/dominictarr/random-name/blob/
master/first-names.txt

11

--- Page 12 ---
"bot_description": "Decaying Winter is a RPG in a apocalyptic modern
times where due to a world war, humankind developed s sort of weapon
that turned the entire planet into a desolated snow desert....",
"conversation": [{"message": "(Welcome to \"Decaying Winter\" an
apocalyptic RPG where you seek survival in a frozen world. Good luck
)\r\n\r\n***You are currently outside, walking in the snow.***\r\n\r
\nYou have your trusty backpack and knife.\r\n**You are hungry.** So
you decided to look for supplies.\r\n\r\nAfter a while of walking
in circles, you notice a camping site with smoke coming from it.\r\n
\r\n***What do you do now?***", "is_human": false}, {"message": "*i
cautiously approach the campfire*", "is_human": true}, {"message":
"*You sneak towards the campfire.\r\nIt’s still going, and two men
and a woman lie on the ground.\rThey are visibly cold and weak.\rBut
you have a choice.\r\nYou can either leave them there, or kill them
-\r\nYou have a knife, a small bottle of water and 2 cans of soda.\r
\nYou don’t have any shelter from the storm.\r \n\nThe snowstorm
rages on outside. The cold still grips your bones.*", "is_human":
false}

indicates that the rest of the text is omitted.

Listing 1: Example sample from PIPPA. ‘

12

--- Page 13 ---
CAI Dump Uploader

Please use the form below to contribute your CharacterAl dumps to
the project.
Input your JSON files here

Choose Files No file chosen

Data Usage Agreement

I consent to this data being used for fine-tuning future Pygmalion
models, as long as it's kept private.

© I consent to this data being used for fine-tuning future Pygmalion
models, AND to having it be included in the public dataset.

Upload

Note: Please make sure the files you're uploading have no personal
information. We don't want any of that.

If your dumps were generated with a version older than v1.2 of the
userscript, they may contain your CAI display name. In that case,
please update and create new dumps.

Figure 5: The webpage where users can submit their CAI logs.
Appendix C. Character.AI Dumper

Screenshot from the web page where users would submit logs of their interactions with
Character.AI chat bots (Figure 5).

13

