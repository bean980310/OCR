arXiv:2309.03185v1 [cs.CV] 6 Sep 2023
Bayes' Rays: Uncertainty Quantification for Neural Radiance Fields
1,2,3
Lily Goli¹ Cody Reading² Silvia Sellán¹ Alec Jacobson 1,4 Andrea Tagliasacchi 1,2
University of Toronto¹ Simon Fraser University2 Google DeepMind³ Adobe Research4
Bayes' Rays
Our Spatial Uncertainty
Train
F
NeRF
Novel View
thresholding by uncertainty
Clean Novel View
Figure 1. We introduce BayesRays, a post-hoc algorithm to estimate the spatial uncertainty of any pre-trained NeRF of any arbitrary
architecture. Our method requires no additional training and can be used to clean up NeRF artifacts caused by occluded or incomplete data.
Abstract
Neural Radiance Fields (NeRFs) have shown promise in
applications like view synthesis and depth estimation, but
learning from multiview images faces inherent uncertain-
ties. Current methods to quantify them are either heuristic
or computationally demanding. We introduce Bayes Rays,
a post-hoc framework to evaluate uncertainty in any pre-
trained NeRF without modifying the training process. Our
method establishes a volumetric uncertainty field using spa-
tial perturbations and a Bayesian Laplace approximation.
We derive our algorithm statistically and show its superior
performance in key metrics and applications. Additional re-
sults available at: https://bayesrays.github.io
1. Introduction
Neural Radiance Fields (NeRFs) are a class of learned vol-
umetric implicit scene representations that have exploded
in popularity due to their success in applications like novel
view synthesis and depth estimation. The process of learning
a NERF from a discrete set of multiview images is plagued
with uncertainty: even in perfect experimental conditions,
occlusions and missing views will limit the epistemic knowl-
edge that the model can acquire about the scene.
Studying the epistemic uncertainty in NeRF is fundamen-
tal for tasks like outlier detection [21] and next-best-view
planning [31] that expand NeRF's performance and applica-
tion domain to critical areas like autonomous driving [11].
However, quantifying the uncertainty contained in a NeRF
model is a relatively new area of study, with existing meth-
ods proposing either heuristic proxies without theoretical
guarantees [14, 58] or probabilistic techniques that require
costly computational power [47] and/or elaborate changes
to the conventional NeRF training pipeline [41, 42].
We draw inspiration from triangulation problems in clas-
sic photogrammetry [45], where uncertainty is often mod-
eled through distributions of feature point positions in image
space that are then projected onto 3D (see Figure 2). In-
tuitively, this distribution measures how much a feature’s
position can be perturbed while maintaining multi-view con-
sistency. We apply a similar intuition to NeRF, identifying
the regions of the radiance field that can be spatially per-
turbed with minimal impact on the reconstruction loss.
Traditional
photogrammetry
O O
Our NeRF
uncertainty
00
Figure 2. Inspired by uncertainty quantification in classic pho-
togrammetry (left), we find epistemic uncertainty in NeRF (right).
1
We propose BayesRays, a post-hoc framework for
quan-
tifying the uncertainty of any arbitrary pre-trained NeRF.
Without requiring any changes to the training pipeline and
regardless of the architecture in use in the given NeRF (see
Figure 3), our method simulates spatially parametrized per-
turbations of the radiance field and uses a Bayesian Laplace
approximation to produce a volumetric uncertainty field,
which can be rendered like an additional color channel.
In this work, we show that our calculated uncertainties
are not only statistically meaningful but also outperform pre-
vious works on key metrics like correlation to reconstructed
depth error. Furthermore, they provide a framework for criti-
cal applications like removing floater artifacts from NeRF,
matching or improving the state-of-the-art (see Figure 1).
In summary, our main contributions are:
• We introduce a plug-and-play probabilistic method to
quantify the uncertainty of any pre-trained Neural Ra-
diance Field independently of its architecture, and without
needing training images or costly extra training.
• In little over a minute, we compute a spatial uncertainty
field that can be rendered as an additional color channel.
• We propose thresholding our uncertainty field to remove
artifacts from pre-trained NeRFs interactively in real time.
2. Related work
Uncertainty Quantification studies the distribution of the
responses of a system conditioned on a set of measurable
input variables [43]. As a field of statistics, it has grown over
many decades out of the need to measure the accuracy of
scientific predictions in areas like physics [13], chemistry
[39] or meteorology [30].
Uncertainty in Computer Vision. Closer to our application,
estimating the uncertainty of Computer Vision systems has
been a subject of study even long before the Deep Learning
revolution; for example, in Structure from Motion and Bun-
dle Adjustment [45, Section 11.4][51]. In these problems
from classic photogrammetry, scene geometry and camera
parameters are jointly optimized in a process filled with un-
certainty [46, 54], often modeled through 2D image-space
Gaussians projected to 3D [8, 26, 45, 51] (see Figure 2).
Uncertainty in Deep Learning. The process of fitting a
neural network to observed data typically contains two fun-
damentally different sources of uncertainty [1, 17]. Aleatoric
uncertainty refers to the inherent randomness contained in
the data (e.g., due to instrument error or uncontrolled in-
fluences) and is often captured by fitting not just one func-
tion but a parametric distribution (e.g., Gaussians) to the
data [4, 17, 25]. On the other hand, epistemic uncertainty
quantifies the lack of knowledge that a model has over the
system it is trying to replicate; for example, due to miss-
ing data. Commonly, this is achieved through a Bayesian
framework that estimates the posterior distribution of the
Train
Mip NeRF
'Nerfacto
Instant
NGP
Our architecture-independent
uncertainty quantification
Figure 3. BayesRays applied to different NeRF architectures.
"Lego" [24] is only trained with cameras on its left hemisphere.
model given observed data. The most straightforward-yet-
expensive way of achieving this is via the use of Deep Ensem-
bles that quantify the differences in optimized parameters
after training many identical, yet differently initialized, net-
works on the same data [19, 57]. A popular alternative to
ensembles are variational Bayesian Neural Networks, which
model each network parameter with an independent distribu-
tion that is sampled at each training iteration and adjusted
through a KL loss to approximate the true model poste-
rior [9, 28]. This significant change to the training pipeline
comes at a computational cost, which recent works have
proposed circumventing through the use of post-hoc Laplace
Approximations (see [12, 37], or [50] for a Computer Vision
application) that only estimate the network weight posterior
near their already-trained value using derivative information.
Uncertainty in Neural Radiance Fields. NeRFs [23] rep-
resent 3D scenes through a neural volumetric encoding that
is optimized to match the images produced from multiple
camera views. Aleatoric uncertainty presents itself in this
process through the presence of transient objects in the scene
or changes in lighting and camera specifications. These phe-
nomena are quantified by the pioneering work NeRF-W [22]
and subsequent follow-ups [16, 31, 35] through a combina-
tion of standard aleatoric Deep Learning techniques [1] and
a learned appearance latent embedding [10].
Distinctly, we concern ourselves with the epistemic uncer-
tainty of Neural Radiance Fields, the source of which is often
missing data due to occlusions, ambiguities and limited cam-
era views. Many of the general Deep Learning techniques
to quantify this uncertainty have been applied to NeRF with
limited success. Works like [47] propose uncertainty esti-
mation through ensemble learning, which can be time and
memory consuming. Shen et al. [41] and its follow-up [42]
model the problem through variational inference and KL
divergence optimization in a way that is not too dissimilar in
2
principle, yet shown to be superior, to standard variational
Bayesian neural networks. All these methods require intri-
cate changes to the NeRF training pipeline. In contrast, we
introduce BayesRays, the first framework that allows the use
of Laplace approximations for NeRF uncertainty quantifica-
tion, avoids variational optimization and can thus be applied
on any pretrained NeRF of any arbitrary pipeline.
Away from the traditional Deep Learning uncertainty
quantification frameworks, other works propose using NeRF-
specific proxies for uncertainty. For example, Zhan et al.
[58] propose computing the uncertainty as entropy of ray
termination in NeRF model. While high entropy can be
a good indicator of uncertainty in modeling solid objects,
such assumption can fail while using density regularizers
like the distortion loss proposed in [7]. Hoffman et al. [14]
suggest quantifying uncertainty as the variance in scenes
produced by a generative model when conditioned on partial
observations, relying heavily on the specific model's priors.
Other related works. As we show in Section 4, our uncer-
tainty quantification relies on the sensitivity of any trained
NeRF to perturbations, a concept recently explored in an
unpublished preprint by Yan et al. [55] for applications out-
side NeRF and through a continual learning framework. To
make our method computationally tractable and architecture-
independent, we introduce a spatial deformation field similar
to the one suggested by [32, 33], albeit we interpret it in-
stead as a re-parametrization of the NeRF model on which
to perform a Laplace Approximation to quantify its uncer-
tainty. One of the many uses we propose for our output
spatial uncertainty field is to avoid common spatial NeRF ar-
tifacts. Instead of changing the optimization at training time
by adding regularizers [7, 29, 34, 36], we propose removing
them from any pre-trained NeRF in a post-processing step, a
task that has been tackled recently by diffusion-based works
like Nerfbusters [52]. As we show in Section 5, our algo-
rithm matches or improves the performance of Nerfbusters
in this specific application while being more general and
requiring no additional training.
3. Background
We propose a general framework for applying Laplace ap-
proximations to quantify the epistemic uncertainty of any
pre-trained NeRF. We will briefly review both these concepts
before exploring the difficulties one encounters when trying
to combine them naively, thus motivating our perturbation-
based approach described in Sec. 4.
3.1. Neural Radiance Fields
Conventional NeRFs [23] learn to map each point in 3D
space to a view-dependent radiance and a view-independent
density value:
Century
Pikachu
Flowers
Base Nerfacto
Uncertainty
Ours
Nerfbusters
Method
Nerfacto (base)
Nerfbusters
PSNR ↑
SSIM↑ LPIPS↓
Coverage ↑
16.83
0.52
0.39
0.89
17.99
0.60
0.25
0.63
Bayes Rays-0.9
17.66
0.56
0.34
0.83
Bayes Rays-0.4
17.78
0.57
0.31
0.78
Bayes Rays-best
18.27
0.60
0.27
0.70
Figure 4. We propose cleaning up a learned scene by thresholding
it based on our computed uncertainty, matching or surpassing the
state of the art at a much lower computational and memory cost.
where > represent the learnable parameters in the neural field.
The color of each pixel in an image can then be rendered
through compositing the density and color of a series of
points {t} along the ray r = or + t dr, using volume
rendering [48]:
Σαν - Σ)
Co (r) = Σ exp
2
Σ Tj dj (1-exp(-Tidi))Ci, (2)
where S; denotes the distance between each pair of succes-
sive points. The network parameters are optimized to
minimize reconstruction loss defined as the squared distance
between the predicted color C(r) and ground truth Cº for
each ray r sampled from image In of training set images
I = {I}0. From a Bayesian perspective, this is equivalent
to assuming a Gaussian likelihood p(C4|4) ~ N(C, 1/2)
and finding *, the mode of the posterior distribution
N
$*
=
arg max p(T)
&
(3)
which, by Bayes' rule, is the same as minimizing the negative
log-likelihood
c4(x,d), T$(x) = R(x, d; ø)
(1)
3
*
= arg min E¿ Er~I || Cø (r) – Cgt (r) ||
(4)
3.2. Neural Laplace Approximations
A common strategy to quantify the epistemic uncertainty of
any neural network trained on some data I is to study the pos-
terior distribution of the network parameters 0 conditioned
on the data, p(0|I). In contrast to variational Bayesian
neural networks, which propose using Bayes' rule and a vari-
ational optimization to estimate this distribution, Laplace ap-
proximations [12, 37] rely on simply training the network by
any conventional means until convergence; i.e., on obtaining
the likeliest network weights 0* – the mode of p(0|I). Then,
the posterior is approximated by a multivariate Gaussian dis-
tribution centered at the obtained mode p(0|I) ~ N(0*, Σ).
The covariance Σ of this distribution is then computed via a
second-order Taylor expansion of the negative log-likelihood
h(0) = log p(0|1) about 0*:
1
h(0) ≈ h(0*) + (0—0*)˜H(0*) (0–0*), (5)
where first order terms are discarded since 0* is a maximum
of h(0) and H(0*) is the Hessian matrix of second deriva-
tives of h(0) evaluated at 0*. Identifying the terms in Eq. 5
with the usual log squared exponential Gaussian likelihood
of N(0*, Σ), one obtains
Σ = − H(0*)¯¹
(6)
Unfortunately, a naive application of this framework to
NeRF by identifying ¤ with ☀ is impracticable, as it would
have three potentially fatal flaws:
•
•
• First, as we show in Section 4.4, the parameters of the
NeRF are strongly correlated with each other, making it
difficult to accurately estimate the posterior distribution
with any guarantees without computing, (and storing) all
the entries in H, a (potentially fully, at least block-) dense
matrix with dimensions matching the number of network
weights, before carrying out a costly inversion step.
Secondly, even if one perfectly computed Σ, the parameter
correlations and network non-linearities would make it
such that transferring this distribution to any geometrically
meaningful one like a distribution over densities or pixel
values would require repeatedly and expensively drawing
samples from the full N(*, Σ).
Finally, beyond computational constraints, estimating un-
certainty directly on the NeRF parameters would require
our algorithm to have knowledge of (and, potentially, de-
pendence on) the specific internal NeRF architecture used.
Below, we solve all of these problems by introducing
a parametric perturbation field on which to perform the
Laplace approximation. Our algorithm is completely in-
dependent of the specific NeRF architecture used and can
guarantee minimal correlations between parameters, allow-
ing us to calculate a meaningful spatial uncertainty field
without the need to draw any distribution samples.
4. Method
As input, we assume that are given a pre-trained radiance
field R with radiance function c, density 7 and optimized
parameters *, as well as ground truth camera parame-
ters {T} corresponding to the N training images. Our
method makes no assumption about the specific architecture
of R and is designed for any arbitrary framework that pro-
duces a learned density 76* and radiance co*, which we will
treat as differentiable black boxes.
We begin by noting that, while the neural network
weights & may serve as a useful parametrization of R during
training, a Laplace approximation can be formulated on any
re-parametrization Re for any parameter set 0 € ☺, as long
as one knows the mode of the distribution p(0|Z).
We follow by taking inspiration from the key insight
behind NeRFs themselves: namely, that one can achieve
impressive performance even in 2D tasks by explicitly mod-
eling the 3D scene through a volumetric field. We also take
inspiration from Computer Graphics, where global, volu-
metric deformation fields have been proposed as tools for
manipulating implicitly represented objects [40, 44]. Finally,
we draw inspiration from photogrammetry, where recon-
struction uncertainty is often modeled by placing Gaussian
distributions on the spatial positions of identified feature
points (see Fig. 2).
4.1. Intuition
The intuition behind our re-
parametrization is better seen with
the simple scene shown in the inset.
Consider a single solid blue segment
with a green center embedded in the
2D plane. Imagine that this object
is observed by two simplified cameras that capture rays
in a 60-degree cone, and let us now consider the NeRF
reconstruction problem as stated on this small dataset.
"perfect"
reconstructions
Trivially, the problem is an under-
determined one: as shown in the inset,
the green segment could be substituted
by many possible curves while still re-
sulting in a "perfect" photometric recon-
struction according to the four pixels in
our dataset. Indeed, there is a whole
null-space of solutions (green shaded region) to which the
green segment could be perturbed without affecting the re-
construction loss, and a NeRF trained on this dataset may
converge to any one of these configurations depending on
the training seed. Hence, one may quantify the uncertainty
of a trained NeRF by asking "how much can one perturb it
without hurting the reconstruction accuracy?"
'Note this is analogous to the condition number of near/far-field triangu-
lation from photogrammetry that was discussed in Section 1.
4
Crucially, this quantity will vary
spatially: some regions of:
space
will
be more constrained by the training
set and will allow only a limited per-
turbation before having an adverse
less
Train
uncertain
AUSE = 0.247
AUSE=0.170
AUSE = 0.167
RGB
323
grid
256'
10243
more
uncertain
effect on the loss (e.g., the edges of the segment, orange in
the inset) while others will be much more uncertain (e.g.,
the middle of the segment, purple in the inset). Hence, we
will be able to quantify the spatial uncertainty of any trained
NeRF by asking "which regions can one perturb without
hurting the reconstruction accuracy?"
front
side
This quantity will be helpful beyond
simple didactic examples: indeed, even
general 3D scenes like the one in the
inset can seem like pixel-perfect re-
constructions from all training camera
views (in this case, we trained a Ner-
facto [49] model for 30,000 epochs with 40 front and back
views of the laptop) but reveal large geometric artifacts when
seen from a different angle.
4.2. Modeling perturbations
Inspired by all the considerations above, we introduce a
deformation field D : RD → RD, which one can interpret as
a block that is ran on the input coordinates before the NeRF
network. We choose a spatially meaningful parametrization
in the form of vector displacements stored on the vertices of
a grid of length M, allowing 0 to be represented as a matrix
ЄRMD XD, and defining a deformation for every spatial
coordinate via trilinear interpolation
De(x) = Trilinear(x, 0).
Figure 5. Very low resolutions may cause uncertainties to be
underestimated, with diminishing returns for M > 256.
and formulating the posterior p(0|I) whose negative log-
likelihood h(0) is given by
h(0) = EnEr~1„ || Če(r) – Cgt (r)||| + \||0||² .
=
-
=
(10)
The minimum of (10) must be obtained when 0 = 0, as
in that case 70(x)
To* (x), čo (x) Co* (x, d) and thus
Čo(r) = Cô(r). Thus, zero is the mode of the distribution
p(0|I) and we are finally in the ideal conditions for a Laplace
approximation around 0* 0. Following Sec. 3.2, this result
in a distribution ~ N(0, Σ) where
=
Σ = -H(0)=1
(11)
where H is the Hessian matrix of second derivatives of h(0)
evaluated at zero. Computing these second derivatives is a
computationally intensive task; however, as we show below,
a combination of statistical and NeRF-specific tools allows
us to approximate it in terms of first derivatives only.
4.3. Approximating H
For any parametric family of statistical distributions pe, the
Hessian of the log-likelihood with respect to the parameters
is also known as the Fisher information
(7)
I(0) = -Ex~pe 20]
Ꮎ =
-H(0), (12)
We can now reparametrize the radiance field R with 0 by
perturbing each coordinate x before applying the already-
optimized NeRF neural network
[ð²h(X; 0)
002
which (under reasonable regularity assumptions) can also be
defined as the variance of the parametric score [20, 5.3]
T
I(0) = Ex~pe
70(x) = To* (x + Do(x)),
čo (x) = C++ (x + De(x), d),
(8)
Əh(X; 0) ǝh(X; 0)
ae
Ꮎ
(13)
(9)
resulting in the predicted pixel colors
Let us now denote the pair of random variables correspond-
ing to a ray and its predicted color as (r, y), where r ~ {In}
and y = C(r). In our case, (13) takes the form
Cale)-Σexp(-Σ5%) (1
=
i
Σjd; (1 exp(-ñidi)) či ·
j<i
We proceed by assuming a likelihood of the same form as
with the NeRF parametrization, Co|0 ~ N(C, ½). Under
our assumption that * are the optimal parameters obtained
from NeRF training, it would be unreasonable to expect
any non-trivial deformation to decrease the reconstruction
loss; thus, it makes sense to place a regularizing indepen-
dent Gaussian prior 0 ~ N(0, -¹) on our new parameters
which can easily be computed via backpropagation.
1(0) = E(r,y) [4 €o(r) Jø(r)˜Jø(r)] + 21
where (r) is the ray residual error
(14)
€(r) = ||Ñø(r) – Cgt (r)||2
and Jo (r) is the Jacobian of first derivatives
ace(r)
Jø(r)
(15)
5
Further, as we typically do not have multiple observations
of ray color for a single ray r, we can further simplify the
above using the definition of conditional expectation
1(0) = Er [4 Eyr [€o(r)] Jø(r)˜Jø(r)] +2XI, (16)
noting that Eyr [€ (r)] is nothing more than 1, the variance
of our stated likelihood N(C¾, ½),
1(0) = Er [2 Jo(r)¯Jo(r)] +2\I.
(17)
Combining (17) with (12) and approximating the expectation
via sampling of R rays, we have our final expression for H:
H(0) ≈ -
// Jo(r) Jo(r) – 2XI, (18)
r
It is worth remarking that, while H contains in it all the
information that we will need to quantify the epistemic un-
certainty of the given radiance field, its computation in (18)
does not explicitly rely on the data from the training images
but only on information contained in the pre-trained model
and the training camera parameters.
4.4. Spatial uncertainty
H(o)
H(0)
We can now fully take advantage of our
proposed reparametrization. First, since
each vector entry in 0 corresponds to
a vertex on our grid, its effect will be
spatially limited to the cells containing
it, making H(0) necessarily sparse and
minimizing the number of correlated
parameters (see inset, which compares
the sparsity of H(0) to the that of an
NeRF's MLP parameters ). In fact, thanks to this low num-
ber of correlations, we will proceed like Ritter et al. [37] and
approximate Σ only through the diagonal entries of H:
Σdiag Σ Je(r) Jo(r) + 2AI
r
=
-1
(19)
Secondly, by measuring the variance of our deformation
field (intuitively, how much one could change the NeRF ge-
ometry without harming reconstruction quality), Σ critically
encodes the spatial uncertainty of the radiance field. We can
formalize this by considering the (root) diagonal entries of Σ,
which define a marginal variance vector σ (σx, y, oz).
Much like in the photogrammetry works discussed in Sec-
tion 2 and Figure 2, at each grid vertex, σ defines a spatial
ellipsoid within which it can be deformed to minimal recon-
struction cost. The norm of this vector σ = ||0|| 2 is then a
positive scalar that measures the local spatial uncertainty of
the radiance field at each grid vertex. Through it, we can
define our spatial uncertainty field U: R³ → R+ given by
U(x) = Trilinear(x, σ),
(20)
which intuitively encodes how much the positioning of geo-
metric region in our reconstruction can be trusted. Strictly
speaking, as defined above, U measures the uncertainty at
(1+Dė)¯¹ (x), not x; however, we note that these are equiv-
alent for the trained NeRF for which Do*
= 0.
The uncertainty field U is the main output of our algo-
rithm and serves to illustrate the success of our approach. It
is a first-of-its-kind theoretically derivated spatial measure of
uncertainty that can be computed on any NeRF architecture,
without the need for additional training, expensive sampling
or even access to the training images. We will now validate
it experimentally and show potential applications.
5. Experiments & Applications
We validate our theoretically-derived algorithm through our
uncertainty field's correlation with the depth prediction error
in a given NeRF (Section 5.1), show a prototypical applica-
tion to a NeRF clean-up task (Section 5.2) and justify our
parametric choices through ablation studies (Section 5.3).
=
Implementation. Unless specified otherwise, all NeRFs
used throughout this paper use Nerfstudio's Nerfacto [49] as
the base architecture and are pre-trained for 30,000 steps. We
extract our uncertainty field U using 1,000 random batches
of 4,096 rays each sampled from a scene's training cam-
eras, with M
256 and = 10-4/M3, in a process that
takes around 90 seconds on an NVIDIA RTX 6000. Once
computed for a given scene, our derived uncertainty field
conveniently functions as an additional color channel that
can be volumetrically rendered in a form (and cost) anal-
ogous to the usual RGB. For visualization clarity, all our
results use a logarithmic scale, rendering logu instead of U.
5.1. Uncertainty Evaluation – Figures 6
-
We evaluate the estimated uncertainty of BayesRays by show-
ing its correlation with the NeRF depth error. We choose
the error in predicted depth as the best signal that conveys
NeRF's unreliability in geometric prediction, as RGB error
has been shown to not be representative of true uncertainty
due to radiance accumulation and model biases [47].
Metric. We measure correlation through the Area Under
Sparsification Error (AUSE) [5, 15]. The pixels in each
test image are removed gradually ("sparsified") twice: first,
according to their respective depth error; second, by their
uncertainty measure. The difference between the Mean Ab-
solute depth Error (AMAE) of the remaining pixels in both
processes, at each stage, provides the sparsification curves.
Data. In Figure 6, we use 4 ScanNet scenes (#0000-001,
#0079-000, #0158-000, #0316-000) with groundtruth depths
provided. Each scene employs 40 images split into 5 test and
35 train images, following NerfingMVS [53]. Additionally,
we use 4 scenes from the Light Field dataset [56, 59] (torch,
statue, basket, africa), with the same train-test split and
pseudo-ground-truth depth map approach as CF-NeRF [42].
6
AMAE
2.0
1.6
statue
1.2
0.8
AMAE
1.0
CF-NeRF
0.8
0.6
0.4
scene #0316
CF-NeRF
Ours
Ensemble
0.4
Ours
0.2
Ensemble
Most uncertain
pixel
50% percentile
Most certain
Most uncertain
pixel
pixel
50% percentile
Most certain
pixel
Scene
africa
basket
statue
torch
#0000
#0079
#0158
#0316
Method
Ensemble
0.18
0.24
0.15
0.19
0.28
0.36
0.19
0.26
CF-NeRF
0.35
0.31
0.46
0.97
0.59
0.43
0.55
0.54
Ours
0.27
0.28
0.17
0.22
0.28
0.35
0.20
0.29
Figure 6. The uncertainties computed with our algorithm on the ScanNet and Light Field dataset are significantly more calibrated to the real
NeRF depth error than the previous state-of-the-art CF-NeRF [42], even matching the performance of extremely costly ensembles. Images
are colored by uncertainty / depth error percentile instead of value to be comparable.
Baselines. For Figure 6, we display sparsification curves
derived from our uncertainty field, with the previous state-
of-the-art CF-NeRF [42] and with the standard deviations
obtained by the costly process of training an ensemble of
ten identical yet differently seeded NeRFs. Next to each
graph, we visualize the depth error together with the (as-
cending) per-pixels rank produced by each method (i.e., the
ordering that produces the curves). It is worth noting that,
unlike CF-NeRF [42], we do not measure disparity error due
to its heightened sensitivity to low-range depth errors and
significant underestimation of errors in distant points.
Results. The results are consistent across Figure 6.
BayesRays's uncertainty shows significant improvement in
correlation with depth error compared to CF-NeRF [42],
both quantitatively and qualitatively. Further, our uncertainty
is extremely close to the standard deviation of a costly ensem-
ble in both AUSE and sparsification plots, while requiring
no additional trained NeRFs, saving time and memory.
5.2. NeRF Clean Up – Figures 1 and 4
-
A common reconstruction artifact in NeRFs are "Floaters",
often caused by a lack of information in training data. These
inherently correspond to regions of high uncertainty; there-
fore, we propose removing them by thresholding the scene
according to our uncertainty field U during rendering.
In Figure 4, we compare our algorithm's performance
to the current state of the art for post-hoc floater removal,
Nerfbusters [52], which employs a 3D diffusion model and
a "visibility mask" to guide additional training steps during
which some floaters are removed. For our comparison, we
use the same dataset proposed by Nerfbusters along with
their proposed metric of Coverage, together with more com-
mon measures of image quality. An ideal clean-up would
boost image quality while keeping pixel coverage high.
When using fixed threshold values like 0.9 or 0.4,
BayesRays obtains similar PSNR values to Nerfbusters while
allowing for a higher coverage. If one selects the best possi-
ble threshold value for each scene out of ten equally spaced
ones, BayesRays outperforms Nerfbusters in both PSNR
and coverage. It is worth noting that BayesRays achieves
with a significantly lower computational footprint: unlike
Nerfbusters, we do not require storing and evaluating a 3D
diffusion model, we are faster (96 seconds vs 20 minutes) by
eliminating the need for additional training and we circum-
vent the use of a “visibility mask" altogether by storing all
necessary information in our computed Hessian H.
Our qualitative results in Figure 4 show that our method
can filter floaters that are missed by Nerfbusters (Century),
is not prone to sampling artifacts caused by floater re-
moval (Flowers) and provides the parametric flexibility nec-
essary to avoid over-filtering (Pikachu).
5.3. Algorithmic ablations – Figures 3, 5 and 8
In Section 4, we justified our introduction of the perturbation
field D partly through the desire to make our algorithm inde-
pendent to the specific NeRF architecture used. In Figure 3,
we show that this is indeed the case, as we obtain quali-
tatively similar results for three representatively different
architectures (Mip NeRF [6], Instant NGP [27] and Nerfacto
[49]) on the "Lego" scene from the NeRF Synthetic dataset
[24] with 60 training views from its left hemisphere.
7
Inconsistent
Floater
Low Uncertainty
Train Views
Novel View RGB
0.0
Novel View Uncertainty
Figure 7. BayesRays quantifies only epistemic uncertainty in NeRF
and is thus unable to capture aleatoric effects like those stemming
from training inconsistencies.
This success introduces an algorithmic choice; namely,
the discretization of the deformation field. In Section 4, we
propose storing it in a uniform spatial grid of size M³ from
which deformation values can be trilinearly interpolated.
The value of M thus becomes an algorithmic parameter,
which we explore for the same example in Figure 5. We
find that surface uncertainty can be missed for small values
of M, resulting in a generally more certain map that is only
activated on points of very high uncertainty, with diminishing
returns being obtained for larger, more costly M > 256.
Finally, our algorithm's flagship application to NeRF arti-
fact removal also contains a parameter choice, in the form
of the uncertainty threshold. As we show in Figure 8, de-
creasing this parameter can a gradually clean a floater-heavy
scene leaving a floater-free clean capture of the target object.
Since our uncertainty field only needs to be computed once,
we suggest that this threshold can serve as real-time user
control in interactive NeRF setups like Nerfstudio [49].
6. Conclusions
We have introduced BayesRays, an algorithm to quantify the
uncertainty of any trained Neural Radiance Field without
independently of its architecture and without additional train-
ing nor access to the original training images. Our algorithm
outputs a spatial uncertainty field, which we have shown is
meaningfully correlated to the NeRF depth error and can be
thresholded for use in applications like NeRF cleanup.
We discretize our spatial deformation field using a uni-
form grid, which can lead to a high memory cost being
incurred in regions of little geometric interest. Future work
may significantly improve our performance by considering
more complex hierarchical data structures like octrees. Sep-
arately, in our algorithm's derivation, we focus only on the
diagonal of H, disregarding (minimal) inter-parametric cor-
relations. Future applications may require their inclusion,
possibly through low-rank matrix decompositions [2, 3].
At a higher level, our algorithm's stated goal is to capture
only the epistemic uncertainty of the NeRF, often present
through missing or occluded data. As such, aleatoric un-
certainty caused by noise or inconsistencies between views
is not captured by our method (see Figure 7). We are opti-
mistic that combining our work with current frameworks for
100
0.8,
0.6
0.2
0.05
PSNR
16
15.5
Uncertainty thresholds
for NeRF clean-up
15
14.5
95
90
85
80
75
70
65
% Coverage
Figure 8. Applying different thresholds to uncertainty for the NeRF
clean up task on the "garbage” scene from Nerfbusters dataset [52].
Rightmost image (threshold=00) shows the original.
aleatoric quantification like [22, 38] will result in a complete
study of all sources of uncertainty in NeRF.
More broadly, our algorithm is limited to quantifying the
uncertainty of NeRFs, and cannot be trivially translated to
other frameworks. Nonetheless, we look forward to similar
deformation-based Laplace approximations being formu-
lated for more recent spatial representations like 3D Gaus-
sian splatting [18]. As the Deep Learning revolution takes
Computer Vision algorithms to new horizons of performance
and increasingly critical applications, we hope that works
like ours can aid in understanding what our models know
and do not know as well as the confidence of their guesses.
Acknowledgements
We would like to thank Alireza Mousavi-Hosseini,
Agustinus Kristiadi, Towaki Takikawa, Kevin Swersky,
Richard Szeliski, Aaron Hertzmann, Georgios Kopanas,
Vladimir Kim, and Nathan Carr for helpful discussions and
feedback. The third author is funded in part by an NSERC
Vanier Scholarship and an Adobe Research Fellowship.
References
[1] Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Reza-
zadegan, Li Liu, Mohammad Ghavamzadeh, Paul Fieguth,
Abbas Khosravi, U Rajendra Acharya, Vladimir Makarenkov,
and Saeid Nahavandi. A review of uncertainty quantification
in deep learning: Techniques, applications and challenges.
arXive preprint at arXiv:2011.06225, 2021. 2
[2] Sivaram Ambikasaran and Eric Darve. An\mathcal o (n\log
n) o (n log n) fast direct solver for partial hierarchically semi-
separable matrices: With application to radial basis function
interpolation. Journal of Scientific Computing, 2013. 8
[3] Sivaram Ambikasaran, Michael O'Neil, and Karan Raj Singh.
8
Fast symmetric factorization of hierarchical matrices with
applications. arXiv preprint arXiv:1405.0223, 2014. 8
[4] Murat Seckin Ayhan and Philipp Berens. Test-time data
augmentation for estimation of heteroscedastic aleatoric un-
certainty in deep neural networks. Medical Imaging with
Deep Learning, 2022. 2
[5] Gwangbin Bae, Ignas Budvytis, and Roberto Cipolla. Es-
timating and exploiting the aleatoric uncertainty in surface
normal estimation. ICCV, 2021. 6
[6] Jonathan T. Barron, Ben Mildenhall, Matthew Tancik, Peter
Hedman, Ricardo Martin-Brualla, and Pratul P. Srinivasan.
Mip-nerf: A multiscale representation for anti-aliasing neural
radiance fields. ICCV, 2021. 7
[7] Jonathan T. Barron, Ben Mildenhall, Dor Verbin, Pratul P.
Srinivasan, and Peter Hedman. Mip-nerf 360: Unbounded
anti-aliased neural radiance fields. CVPR, 2021. 3
[8] Adrien Bartoli. Towards gauge invariant bundle adjustment:
A solution based on gauge dependent damping. ICCV, 2003.
2
[9] Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and
Daan Wierstra. Weight uncertainty in neural networks. ICML,
2015. 2
[10] Piotr Bojanowski, Armand Joulin, David Lopez-Paz, and
Arthur Szlam. Optimizing the latent space of generative
networks. ICML, 2019. 2
[11] Kashyap Chitta, Aditya Prakash, and Andreas Geiger. Neat:
Neural attention fields for end-to-end autonomous driving.
ICCV, 2021. 1
[12] Erik Daxberger, Agustinus Kristiadi, Alexander Immer, Runa
Eschenhagen, Matthias Bauer, and Philipp Hennig. Laplace
redux - effortless bayesian deep learning. NeuRIPS, 2021. 2,
4
[13] John Ellis, Mary K Gaillard, Dimitri V Nanopoulos, and
Serge Rudaz. Uncertainties in the proton lifetime. Nuclear
Physics B, 1980. 2
[14] Matthew D. Hoffman, Tuan Anh Le, Pavel Sountsov, Christo-
pher Suter, Ben Lee, Vikash K. Mansinghka, and Rif A.
Saurous. Probnerf: Uncertainty-aware inference of 3d shapes
from 2d images. AISTATS, 2022. 1,3
[15] Eddy Ilg, Özgün Çiçek, Silvio Galesso, Aaron Klein, Osama
Makansi, Frank Hutter, and Thomas Brox. Uncertainty esti-
mates and multi-hypotheses networks for optical flow. ECCV,
2018. 6
[16] Liren Jin, Xieyuanli Chen, Julius Rückin, and Marija Popovic.
Neu-nbv: Next best view planning using uncertainty estima-
tion in image-based neural rendering. IROS, 2023. 2
[17] Alex Kendall and Yarin Gal. What uncertainties do we need
in bayesian deep learning for computer vision? NeuRIPS,
2017. 2
[18] Bernhard Kerbl, Georgios Kopanas, Thomas Leimkühler, and
George Drettakis. 3d gaussian splatting for real-time radiance
field rendering. ACM Trans. Graph., 2023. 8
[19] Balaji Lakshminarayanan, Alexander Pritzel, and Charles
Blundell. Simple and scalable predictive uncertainty estima-
tion using deep ensembles. NeuRIPS, 2016. 2
[20] Erich L. Lehmann and George Casella. Theory of Point Esti-
mation. Springer-Verlag, second edition, 1998. 5
[21] Sergio Naval Marimont and Giacomo Tarroni. Implicit field
learning for unsupervised anomaly detection in medical im-
ages. MICCAI, 2021. 1
[22] Ricardo Martin-Brualla, Noha Radwan, Mehdi Sajjadi,
Jonathan T. Barron, Alexey Dosovitskiy, and Daniel Duck-
worth. NeRF in the Wild: Neural radiance fields for uncon-
strained photo collections. CVPR, 2020. 2, 8
[23] Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik,
Jonathan T. Barron, Ravi Ramamoorthi, and Ren Ng. NeRF:
Representing scenes as neural radiance fields for view synthe-
sis. ECCV, 2020. 2, 3
[24] Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik,
Jonathan T. Barron, Ravi Ramamoorthi, and Ren Ng. Nerf:
Representing scenes as neural radiance fields for view synthe-
sis. ECCV, 2020. 2, 7
[25] Miguel Monteiro, Loïc Le Folgoc, Daniel Coelho de Castro,
Nick Pawlowski, Bernardo Marques, Konstantinos Kamnitsas,
Mark van der Wilk, and Ben Glocker. Stochastic segmentation
networks: Modelling spatially correlated aleatoric uncertainty.
Advances in neural information processing systems, 2020. 2
[26] Daniel Morris, Kenichi Kanatani, and Takeo Kanade. Uncer-
tainty modeling for optimal structure from motion. Workshop
on Vision Algorithms, 1999. 2
[27] Thomas Müller, Alex Evans, Christoph Schied, and Alexan-
der Keller. Instant neural graphics primitives with a multires-
olution hash encoding. SIGGRAPH, 2022. 7
[28] Radford M. Neal. Bayesian Learning for Neural Networks.
Springer-Verlag, 1995. 2
[29] Michael Niemeyer, Jonathan T. Barron, Ben Mildenhall,
Mehdi S. M. Sajjadi, Andreas Geiger, and Noha Radwan.
Regnerf: Regularizing neural radiance fields for view synthe-
sis from sparse inputs. CVPR, 2021. 3
[30] Tim N Palmer. Predicting uncertainty in forecasts of weather
and climate. Reports on progress in Physics, 2000. 2
[31] Xuran Pan, Zihang Lai, Shiji Song, and Gao Huang. Ac-
tivenerf: Learning where to see with uncertainty estimation.
ECCV, 2022. 1,2
[32] Keunhong Park, Utkarsh Sinha, Jonathan T. Barron, Sofien
Bouaziz, Dan B. Goldman, Steven M. Seitz, and Ricardo
Martin-Brualla. Deformable neural radiance fields. ICCV,
2020. 3
[33] Keunhong Park, Utkarsh Sinha, Peter Hedman, Jonathan T.
Barron, Sofien Bouaziz, Dan B Goldman, Ricardo Martin-
Brualla, and Steven M. Seitz. Hypernerf: A higher-
dimensional representation for topologically varying neural
radiance fields. ACM Trans. Graph., 2021. 3
[34] Keunhong Park, Philipp Henzler, Ben Mildenhall, Jonathan T.
Barron, and Ricardo Martin-Brualla. Camp: Camera precon-
ditioning for neural radiance fields, 2023. 3
[35] Yunlong Ran, Jing Zeng, Shibo He, Jiming Chen, Lincheng
Li, Yingfeng Chen, Gimhee Lee, and Qi Ye. NeurAR: Neural
uncertainty for autonomous 3d reconstruction with implicit
neural representations. IEEE Robotics and Automation Let-
ters, 2023. 2
[36] Daniel Rebain, Mark Matthews, Kwang Moo Yi, Dmitry
Lagun, and Andrea Tagliasacchi. Lolnerf: Learn from one
look. CVPR, 2022. 3
9
[37] Hippolyt Ritter, Aleksandar Botev, and David Barber. A
scalable laplace approximation for neural networks. ICLR,
2018. 2, 4, 6
[38] Sara Sabour, Suhani Vora, Daniel Duckworth, Ivan Krasin,
David J. Fleet, and Andrea Tagliasacchi. Robustnerf: Ignoring
distractors with robust losses. CVPR, 2023. 8
[39] William D Schecher and Charles T Driscoll. An evaluation
of the equilibrium calculations within acidification models:
the effect of uncertainty in measured chemical components.
Water Resources Research, 1988. 2
[40] Dario Seyb, Alec Jacobson, Derek Nowrouzezahrai, and Wo-
jciech Jarosz. Non-linear sphere tracing for rendering de-
formed signed distance fields. ACM Trans. Graph., 2019.
4
[41] Jianxiong Shen, Adria Ruiz, Antonio Agudo, and Francesc
Moreno-Noguer. Stochastic neural radiance fields: Quantify-
ing uncertainty in implicit 3d representations. 3DV, 2021. 1,
2
[42] Jianxiong Shen, Antonio Agudo, Francesc Moreno-Noguer,
and Adria Ruiz. Conditional-flow nerf: Accurate 3d mod-
elling with reliable uncertainty quantification. ECCV, 2022.
1, 2, 6, 7
[43] Ralph C Smith. Uncertainty quantification: theory, imple-
mentation, and applications. Siam, 2013. 2
[44] Masamichi Sugihara, Brian Wyvill, and Ryan Schmidt.
Warpcurves: A tool for explicit manipulation of implicit sur-
faces. Computers & Graphics, 2010. 4
[45] Richard Szeliski. Computer vision: algorithms and applica-
tions. Springer Nature, 2022. 1,2
[46] Richard Szeliski and Sing Bing Kang. Shape ambiguities
in structure from motion. Pattern Analysis and Machine
Intelligence, IEEE Transactions on, 1997. 2
[47] Niko Sünderhauf, Jad Abou-Chakra, and Dimity Miller.
Density-aware nerf ensembles: Quantifying predictive un-
certainty in neural radiance fields. ICRA, 2023. 1,2,6
[48] Andrea Tagliasacchi and Ben Mildenhall. Volume rendering
digest (for nerf). arXiv preprint arXiv:2209.02417, 2022. 3
[49] Matthew Tancik, Ethan Weber, Evonne Ng, Ruilong Li, Brent
Yi, Terrance Wang, Alexander Kristoffersen, Jake Austin,
Kamyar Salahi, Abhik Ahuja, David Mcallister, Justin Kerr,
and Angjoo Kanazawa. Nerfstudio: A modular framework for
neural radiance field development. Special Interest Group on
Computer Graphics and Interactive Techniques Conference
Conference Proceedings, 2023. 5,6,7,8
[50] Anastasia Tkach, Andrea Tagliasacchi, Edoardo Remelli,
Mark Pauly, and Andrew Fitzgibbon. Online generative model
personalization for hand tracking. ACM Trans. Graph., 2017.
2
[51] Bill Triggs, Philip F. McLauchlan, Richard I. Hartley, and
Andrew William Fitzgibbon. Bundle adjustment - a modern
synthesis. Workshop on Vision Algorithms, 1999. 2
[52] Frederik Warburg, Ethan Weber, Matthew Tancik, Aleksander
Holynski, and Angjoo Kanazawa. Nerfbusters: Removing
ghostly artifacts from casually captured nerfs. ICCV, 2023.
3,7,8
[53] Yi Wei, Shaohui Liu, Yongming Rao, Wang Zhao, Jiwen Lu,
and Jie Zhou. Nerfingmvs: Guided optimization of neural
radiance fields for indoor multi-view stereo. ICCV, 2021. 6
[54] Kyle Wilson and Scott Wehrwein. Visualizing spectral bundle
adjustment uncertainty. 2020 International Conference on 3D
Vision (3DV), 2020. 2
[55] Zike Yan, Haoxiang Yang, and Hongbin Zha. Active neural
mapping. arXiv preprint arXiv:2308.16246, 2023. 3
[56] Kaan Yücer, Alexander Sorkine-Hornung, and Oliver Disney.
Efficient 3 d object segmentation from densely sampled light
fields with applications to 3 d reconstruction. ACM TOG,
2016. 6
[57] Sheheryar Zaidi, Arber Zela, Thomas Elsken, Christopher C.
Holmes, Frank Hutter, and Yee Whye Teh. Neural ensemble
search for uncertainty estimation and dataset shift. NeuRIPS,
2021. 2
[58] Huangying Zhan, Jiyang Zheng, Yi Xu, Ian Reid, and Hamid
Rezatofighi. Activermap: Radiance field for active mapping
and planning. arXiv preprint arXiv:2211.12656, 2022. 1,3
[59] Kai Zhang, Gernot Riegler, Noah Snavely, and Vladlen
Koltun. Nerf++: Analyzing and improving neural radiance
fields. preprint arXiv:2010.07492, 2020. 6
10
