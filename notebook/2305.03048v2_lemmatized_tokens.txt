oct personalize segment anything model one shot renrui zhengkai ziyu shilin junting xianzheng hao dongÂª yu peng hongsheng mmlab shanghai artificial intelligence laboratory institute automation chinese academy science school c peking university zhangrenrui gaopeng guoziyu qiaoyu hsli abstract driven segment anything model sam demonstrated powerful promptable framework revolutionizing tion field despite generality customizing sam specific visual concept without prompting automatically segmenting pet dog numerous image paper introduce personalization approach sam termed persam given data single image reference mask first obtain cation prior target concept new image aided target visual semantics empower sam personalized object segmentation via two posed technique attention prompting way effectively customize sam private use without training alleviate ambiguity segmentation scale present efficient variant freezing entire sam introduce aggregate mask tune parameter within second improved performance demonstrate efficacy construct new dataset perseg evaluation personalized object segmentation also test method various image video segmentation benchmark besides propose leverage persam improve dreambooth personalized synthesis mitigating disturbance background approach showcase better target appearance generation higher fidelity input text prompt code released http user provides learning personalized segmentation one image one mask persam various pose scene figure personalization segment anything model customize segment anything model sam kirillov et specific visual concept pet dog data introduce two efficient solution persam equal contribution corresponding author parameter persam user provides dreambooth assisted persam second hat teddy bear photo v cat v cat beach various pose scene body robot toy figure personalized segmentation ples persam left segment personal object context favorable mance right alleviates ambiguity issue introduction photo v backpack v backpack table classroom figure improving dreambooth ruiz et persam mitigating bance background training proach help achieve alized generation foundation model vision li et zou et wang et language brown et touvron et radford et radford et jia et li et gained unprecedented prevalence attributed availability datasets computational resource demonstrate extraordinary generalization capacity scenario display versatile interactivity incorporating human feedback inspired segment anything kirillov et develops delicate data engine collecting data subsequently train segmentation foundation model known sam defines novel promptable segmentation framework taking input handcrafted prompt returning expected mask allows segmenting object visual context however sam inherently loses capability segment specific visual concept imagine intending crop lovely pet dog thick photo album find missing clock picture bedroom utilizing vanilla sam would highly image must precisely find target object within complicated context activate sam proper prompt segmentation considering ask personalize sam automatically segment visual concept simple efficient manner end introduce persam personalization approach segment anything model shown figure method efficiently customizes sam using data reference image rough mask personal concept specifically first obtain location confidence map target object test image feature similarity considers appearance every foreground pixel according confidence score two point selected location prior finally encoded prompt token fed sam decoder segmentation within decoder propose inject visual semantics target object unleash sam personalized segmentation power two technique attention guide every layer sam decoder location confidence map explicitly compels prompt token mainly concentrate foreground target region intensive feature aggregation prompting explicitly provide sam target semantics fuse original prompt token embedding target object provides positional prompt additional visual cue personalized segmentation aforementioned design along cascaded persam exhibit favorable personalized segmentation performance unique subject variety pose scene notably approach cope well scenario require segmenting one object among multiple similar one simultaneously segmenting several identical object image tracking different object along video nevertheless shown figure might occasional failure case object comprises visually distinct subpart hierarchical structure segmented hat top teddy bear head robot toy ambiguity cast challenge persam determining appropriate scale mask output since local part global shape regarded valid mask sam alleviate issue propose variant approach freeze entire sam preserve versatile knowledge parameter within second single gpu detail enable sam produce several potential segmentation result different mask scale adaptively select best scale varying object employ learnable relative weight mask scale conduct weighted summation final output efficient training avoids data exhibit better segmentation accuracy shown figure right moreover observe approach also assist dreambooth ruiz et better diffusion model personalized generation shown figure given image containing specific visual concept pet cat backpack dreambooth learns convert image identifier v word embedding space however simultaneously include background information stair forest would override newly prompted background disturb target appearance generation therefore propose leverage persam segment target object within training image supervise dreambooth foreground area enabling synthesis higher quality summarize contribution paper follows personalized object segmentation first investigate customize purpose segmentation model sam personalized scenario minimal expense end introduce two efficient effective method along new segmentation dataset perseg evaluation personalized object segmentation persam persam propose three technique guide sam semantics target object design parameter second well alleviate mask ambiguity issue approach achieves competitive result various task including perseg benchmark part semantic segmentation video object segmentation addition persam enhance dreambooth better personalized synthesis related work foundation model powerful generalization capacity foundation model adapted various downstream scenario attain promising performance natural language processing bert devlin et lu et gpt series brown et openai radford narasimhan radford et llama zhang et demonstrated remarkable learning ability transferred new task specific prompt similarly clip radford et align jia et conduct contrastive learning pair exhibit exceptional accuracy visual recognition painter wang et introduces vision model unifies network architecture prompt accomplish diverse vision task without downstream cafo zhang et cascade different foundation model collaborates knowledge robust image classification sam kirillov et present foundation model image segmentation billion mask conduct segmentation concurrent work extending sam segmentation ke et faster inference speed zhao et zhang et matching liu et reconstruction cen et object tracking yang et medical wang huang et image processing another perspective propose personalize segmentation foundation model sam specific visual concept adapts generalist specialist one shot method also assist personalization image foundation model stable diffusion rombach et imagen saharia et improves generation quality segmenting foreground target object background disturbance large model segmentation fundamental task computer vision segmentation long et jiang et zhao et xu et jiang et lin et requires comprehension image various task explored semantic segmentation classifying pixel predefined set class narayanan et chen et zheng et cheng et xie et song et instance segmentation focusing identification individual object instance et wang et tian et panoptic segmentation assigning class label instance identification kirillov et li et interactive segmentation involving human intervention refinement hao et chen et recently inspired language foundation model zhang et brown et several concurrent work proposed vision model image segmentation extensive mask data exhibit strong generalization capability numerous image distribution segment anything model sam kirillov et utilizes data engine tation learn promptable segmentation framework generalizes downstream scenario manner painter wang et seggpt wang et introduce robust learning paradigm segment image given prompt seem zou et present general segmentation model prompted reference language audio incorporating versatile semantic knowledge study introduce new task termed personalized object segmentation annotate new dataset perseg evaluation instead developing large segmentation model goal personalize segment object pose scene propose two approach persam efficiently customize sam personalized segmentation directly tuning entire foundation model downstream task computationally expensive posing challenge constrained application address issue recent work focused developing efficient method sung et et rebuffi et qin eisner freeze weight foundation model append module prompt tuning lester et zhou et jia et liu et suggests using learnable soft prompt alongside frozen model perform specific downstream task achieving competitive performance scale robust domain transfer compared full model tuning adaption lora hu et cuenca paul zhang et hedegaard et injects trainable rank decomposition matrix concurrently weight significantly reduces number learnable parameter required downstream task adapter houlsby et pfeiffer et lin et chen et designed inserted layer original transformer introducing lightweight mlps feature transformation different existing work adopt efficient adaption method delicately designed sam parameter second effectively avoids issue data alleviates ambiguity segmentation scale superior performance method section first briefly revisit segment anything model sam kirillov et introduce task definition personalized object segmentation illustrate methodology persam section respectively finally utilize approach assist dreambooth ruiz et better generation section personalized object segmentation revisit segment anything sam consists three component prompt encoder image encoder lightweight mask decoder respectively denoted encp enc decÐ¼ promptable framework sam take input image set prompt p point box coarse mask specifically sam first utilizes enc obtain input image feature adopts encp encode prompt length k prompt token fi enc tp encp p encode cosine similarity ft test image target local feature fr fr encode persam decoder attention prompting si local confidence map modulate aggregate attention matrix local feature token overall confidence map aggregate concat repeat overall confidence map tm ÑÑ tr image ir mask mr positive prior negative prior figure location prior calculate location confidence map target object new test image ance local part select tion prior point prompt persam positional prompt semantic prompt figure attention left prompting right ject sam target semantics explicitly guide layer propose additional prompting cue rhxwxc tp Ñ rkxc h w denoting resolution image feature map c denoting feature dimension encoded image prompt fed decoder decÐ¼ feature interaction sam construct input token decoder concatenating several learnable mask token tÐ¼ prefix prompt token tp mask token responsible generating mask output formulated decÐ¼ fi concat tm tp denotes final segmentation mask predicted sam task definition although sam generalized enough object prompting lack ability automatically segment specific subject instance considering define new task personalized object segmentation user provides single reference image mask indicating target visual concept given mask either accurate segmentation rough sketch drawn goal customize sam segment designated object within new image video without additional human prompting evaluation annotate new dataset personalized segmentation named perseg raw image collected work diffusion model gal et ruiz et kumari et containing various category visual concept different pose scene paper propose two efficient solution task specifically illustrate follows persam location confidence map conditioned image ir mask mr persam first obtains confidence map indicates location target object new test image shown figure apply image encoder extract visual feature ir encoder sam frozen backbone vision model adopt sam image encoder enc default formulate process enc fr enci ir fr Ñ utilize reference mask mr Ñ crop feature foreground pixel within visual concept fr resulting set n local feature mr fr Ñ denotes multiplication calculate n confidence map foreground pixel cosine similarity test image feature fÄ¯ rhxw note fi represents distribution probability different local part object test image head body paw dog top adopt average pooling aggregate n local map obtain overall confidence map target object n n siÑrhxw incorporating confidence every foreground pixel take visual appearance different object part consideration acquire relatively comprehensive location estimation location prior provide persam location prior test image select two point highest lowest confidence value denoted pÉ² pÉ© respectively former represents likely center position target object latter inversely indicates background regarded positive negative point prompt fed prompt encoder tp encp ph Ñ denote prompt token sam decoder way sam would tend segment contiguous region surrounding positive point discarding negative one image attention although point prompt obtained propose explicit semantic guidance operation sam decoder concentrate feature aggregation within foreground target region shown figure overall confidence map equation clearly indicate rough region target visual concept test image hotter color indicate higher score based property utilize guide attention map every layer decoder specifically denote every attention map softmax function rhxw modulate attention distribution softmax softmax denotes balancing factor attention bias mask prompt token compelled capture visual semantics associated target subject unimportant background area contributes effective feature aggregation attention mechanism enhances final segmentation accuracy persam manner prompting vanilla sam receives prompt positional information coordinate point box provide sam decoder level cue propose utilize visual feature target concept additional semantic prompting first obtain global embedding tr object reference image average pooling different local feature n tr ÏÏÎ± n add tr input token test image equation feeding decoder block shown figure repeat tr concat tm tp denotes input token guided target semantics decoder decÐ¼ repeat operation duplicate target visual embedding aided simple token incorporation persam prompted location point also target visual cue test image persam output three scale random noise dreambooth v cat reconstruction loss f user provides output mask weighted summation freeze persam background disturbance decouple figure alleviate scale ambiguity adopts two learnable weight adaptively aggregating mask figure dreambooth utilize persam decouple target jects background improving generation dreambooth cascaded via technique obtain initial segmentation mask test image sam decoder however might include rough edge isolated background noise refinement iteratively feed mask back decoder decÐ¼ first step prompt decoder currently predicted mask along previous point prompt second step acquire bounding box enclosing mask first step prompt decoder additionally box accurate object localization iterate lightweight decoder without image encoder efficient cost extra latency ambiguity segmentation scale persam tackle case tory segmentation accuracy however target object contain hierarchical structure lead ambiguity mask scale shown figure teapot top platform comprised two part lid body positive point prompt denoted green pentagram located body negative prompt denoted red pentagram exclude platform similar color persam would misled segmentation issue also discussed sam kirillov et proposes alternative simultaneously generate multiple mask three scale corresponding whole part subpart object user required manually select one mask three effective consumes extra manpower contrast personalized task aim customize sam automatic object segmentation without need human prompting motivates u develop version persam adaptive segmentation appropriate scale introduce variant unlike model producing one mask first follows persam obtain location prior refers sam original solution output mask denoted respectively top adopt two learnable mask weight calculate final mask output weighted summation initialized learn optimal weight conduct tuning reference image regard given mask ground truth note freeze entire sam model preserve knowledge parameter within second single gpu way efficiently learns semantics object adaptively output best segmentation scale different concept improving generalization capacity persam table personalized object segmentation perseg dataset compare overall miou blou learnable parameter different method bar et wang et zou et along miou object perseg denotes work concurrent method miou blou param barn clock cat teddy duck thin red pack bear toy bird cartoon robot toy painter vp seem seggpt persam table video object tation davis val tuset et utilize gray color denote method involving training table semantic part segmentation li et gupta et part morabia et ramanathan et report miou score utilize gray color denote method involving training semantic seg part seg painter seem seggpt persam method j f Ñ agss f method hsnet vat painter seggpt persam dreambooth personalized synthesis dreambooth ruiz et diffusion model given photo specific object pet cat learns generate cat referred text prompt v cat calculates loss entire reconstructed image would inject redundant background information training image identifier v therefore shown figure introduce strategy alleviate disturbance background dreambooth given object mask image leverage persam segment foreground target discard gradient pixel belonging background area stable diffusion memorize visual appearance target object supervision imposed background assisted dreambooth synthesize target object better visual correspondence also increase diversity new background guided input text prompt experiment first evaluate approach personalized segmentation perseg section along various existing segmentation benchmark section illustrate effectiveness dreambooth section finally conduct several ablation study investigate design perseg section personalized evaluation perseg dataset test personalization capacity construct new segmentation dataset termed perseg raw image collected training data diffusion work ruiz et gal et kumari et perseg contains object various category total including daily necessity animal building different pose scene object associated image mask fix one pair data miou blou cheng et adopted evaluation please refer appendix implementation detail enlarged data scale perseg ring clock teapot tray backpack carried top part woman figure visualization provement well alleviate scale ambiguity persam figure visualization video object mentation approach performs well segmenting multiple object video performance table observe achieves best result effectively enhances persam overall miou biou show tion improvement figure visual prompting vp bar et painter wang et seem zou et seggpt wang et learner also segment object according given prompt data shown persam already achieve better performance painter vp seem different margin efficient surpasses powerful seggpt overall miou biou different motivation develop segmentation generalist method specially designed personalized object segmentation exhibit much efficiency time computational resource existing segmentation benchmark video object segmentation given image object mask persam achieve competitive object segmentation tracking performance validation set davis et shown table compared method without video training persam largely surpasses painter j f score achieve better performance seggpt notably approach outperform method lin et liang et fully trained extensive video data result fully illustrate strong generalization ability temporal video data complex scenario contain multiple similar occluded object visualized figure semantic part segmentation table evaluate approach image segmentation respectively four datasets li et gupta et morabia et ramanathan et follow matcher liu et data evaluation shown attains consistently better result painter performs comparably seggpt model min et hong et training approach achieve higher score hsnet experiment well demonstrate proposed approach limited segmentation also work personalization sam dreambooth follow hyperparameters dreambooth ruiz et stable diffusion rombach et personalized image synthesis addition figure visualize example dreambooth figure dog lying grey sofa jungle snow dreambooth still sofa green white decoration assisted background totally decoupled sofa well corresponds textual prompt barn front mountain approach also alleviates background disturbance correctly generate forest blue sky user provides dreambooth assisted persam user provides dreambooth assisted persam photo dog v dog jungle photo barn v barn forest background v dog snow v barn blue sky background figure visualization dreambooth improved dreambooth ruiz et better preserve diversity synthesizing various context new image table ablation main ponents proposed method variant table ablation different method table ablation using reference miou gain method persam param miou method mask box painter prompt tuning vp adapter seem guided attention semantic prompt lora seggpt mask weight scale tuning persam positive prior negative prior ablation study main component table investigate different component starting baseline adopts positive location prior add negative point prompt cascaded enhancing miou respectively top introduce target semantics sam decoder attention guidance semantic prompting resulting improvement fully indicate significance finally via efficient boost score demonstrating superior accuracy different method table experiment peft method prompt tuning liu et adapter houlsby et lora hu et freeze entire sam tune peft module injected every transformer block persam decoder shown prompt tuning adapter would data severely degrade accuracy instead best improve performance persam tuning least learnable parameter using reference requiring accurate mask data might strict user table relax input restriction bounding box designating expected object method regard box prompt utilize sam generate mask therefore box reference lead marginal performance drop persam severely influence method conclusion paper propose personalize segment anything model sam specific visual concept data firstly introduce persam injects target semantics sam technique top present variant learnable parameter effectively alleviates ambiguity mask scale achieves leading performance various benchmark besides also verify efficacy approach assist dreambooth better diffusion model hope work may expand applicability sam wider range scenario reference vijay badrinarayanan alex kendall roberto cipolla segnet deep convolutional decoder architecture image segmentation ieee transaction pattern analysis machine intelligence amir bar yossi gandelsman trevor darrell amir globerson alexei efros visual prompting via image inpainting advance neural information processing system tom brown benjamin mann nick ryder melanie subbiah jared kaplan prafulla dhariwal arvind neelakantan pranav shyam girish sastry amanda askell et al language model learner advance neural information processing system jiazhong cen zanwei zhou jiemin fang wei shen lingxi xie xiaopeng zhang qi tian segment anything nerfs arxiv preprint chen george papandreou iasonas kokkinos kevin murphy alan l yuille deeplab semantic image segmentation deep convolutional net atrous convolution fully connected crfs ieee transaction pattern analysis machine intelligence xi chen zhiyan zhao feiwu yu yilei zhang manni duan conditional diffusion interactive segmentation proceeding ieee international conference computer vision pp zhe chen yuchen duan wenhai wang junjun tong lu jifeng dai yu qiao vision transformer adapter dense prediction arxiv preprint bowen cheng ross girshick piotr dollÃ¡r alexander c berg alexander kirillov boundary iou improving image segmentation evaluation proceeding conference computer vision pattern recognition pp bowen cheng ishan misra alexander g schwing alexander kirillov rohit girdhar attention mask transformer universal image segmentation proceeding conference computer vision pattern recognition pp pedro cuenca sayak paul using lora efficient stable diffusion http hugging january jacob devlin chang kenton lee kristina toutanova bert deep bidirectional transformer language understanding arxiv preprint rinon gal yuval alaluf yuval atzmon patashnik amit h bermano gal chechik daniel image worth one word personalizing generation using textual inversion arxiv preprint agrim gupta piotr dollar ross girshick lvis dataset large vocabulary instance segmentation proceeding ieee conference computer vision pattern recognition pp yuying hao yi liu zewu wu lin han yizhou chen guowei chen lutao chu shiyu tang zhiliang yu zeyu chen et al edgeflow achieving practical interactive segmentation flow proceeding ieee international conference computer vision pp junxian chunting zhou xuezhe taylor graham neubig towards unified view transfer learning international conference learning representation url http kaiming georgia gkioxari piotr dollÃ¡r ross girshick mask proceeding ieee international conference computer vision pp lukas hedegaard aman alok juby jose alexandros iosifidis structured pruning adapter arxiv preprint sunghwan hong seokju cho jisu nam stephen lin seungryong kim cost aggregation convolutional swin transformer segmentation european conference computer vision pp springer neil houlsby andrei giurgiu stanislaw jastrzebski bruna morrone quentin de laroussilhe andrea gesmundo mona attariyan sylvain gelly transfer learning nlp international conference machine learning pp pmlr edward j hu yelong shen phillip wallis zeyuan yuanzhi li shean wang lu wang weizhu chen lora adaptation large language model arxiv preprint yuhao huang xin yang lian liu han zhou ao chang xinrui zhou rusi chen junxuan yu jiongquan chen chaoyu chen et al segment anything model medical image arxiv preprint chao jia yinfei yang ye xia chen zarana parekh hieu pham quoc le sung zhen li tom duerig scaling visual representation learning noisy text supervision international conference machine learning pp pmlr menglin jia luming tang chen claire cardie serge belongie bharath hariharan lim visual prompt tuning european conference computer vision pp springer zhengkai jiang yuxi li ceyuan yang peng gao yabiao wang ying tai chengjie wang totypical contrast adaptation domain adaptive semantic segmentation european conference computer vision pp springer zhengkai jiang zhangxuan gu jinlong peng hang zhou liang liu yabiao wang ying tai chengjie wang liqing zhang stc contrastive learning video instance segmentation european conference computer vision workshop pp springer lei ke mingqiao ye martin danelljan yifan liu tai tang fisher yu segment anything high quality arxiv preprint alexander kirillov kaiming ross girshick carsten rother piotr dollÃ¡r panoptic tation proceeding ieee conference computer vision pattern recognition pp alexander kirillov eric mintun nikhila ravi hanzi mao chloe rolland laura gustafson tete xiao spencer whitehead alexander c berg lo et al segment anything arxiv preprint nupur kumari bingliang zhang richard zhang eli shechtman zhu customization diffusion arxiv preprint brian lester ramus noah constant power scale prompt tuning arxiv preprint hao li jinguo zhu xiaohu jiang xizhou zhu hongsheng li chun yuan xiaohua wang yu qiao xiaogang wang wenhai wang et al generalist model vision task arxiv preprint junnan li dongxu li silvio savarese steven hoi bootstrapping training frozen image encoders large language model arxiv preprint xiang li tianhan wei yau pun chen tai tang dataset segmentation proceeding ieee conference computer vision pattern recognition pp yanwei li xinze chen zheng zhu lingxi xie guan huang dalong du xingang wang unified network panoptic segmentation proceeding ieee ence computer vision pattern recognition pp yongqing liang xin li navid jafari jim chen video object segmentation adaptive feature bank refinement advance neural information processing system huaijia lin xiaojuan qi jiaya jia attention guided video object segmentation proceeding ieee international conference computer vision pp zhaojiang lin andrea madotto pascale fung exploring versatile generative language model via transfer learning arxiv preprint ziyi lin shijie geng renrui zhang peng gao gerard de melo xiaogang wang jifeng dai yu qiao hongsheng li frozen clip model efficient video learner european conference computer vision pp springer xiao liu kaixuan ji yicheng fu weng lam tam zhengxiao du zhilin yang jie tang prompt tuning comparable universally across scale task arxiv preprint yang liu muzhi zhu hengtao li hao chen xinlong wang chunhua shen matcher segment anything one shot using feature matching arxiv preprint jonathan long evan shelhamer trevor darrell fully convolutional network semantic segmentation proceeding ieee conference computer vision pattern recognition pp jiasen lu dhruv batra devi parikh stefan lee vilbert pretraining visiolinguistic representation task advance neural information processing system neurips pp jun bo wang segment anything medical image arxiv preprint juhong min dahyun kang minsu cho hypercorrelation squeeze segmentation proceeding international conference computer vision pp keval morabia jatin arora tara vijaykumar joint detection object semantic part arxiv preprint openai technical report arxiv jonas pfeiffer aishwarya kamath andreas rÃ¼cklÃ© kyunghyun cho iryna gurevych fusion task composition transfer learning arxiv preprint jordi federico perazzi sergi caelles pablo arbelÃ¡ez alex luc van gool davis challenge video object segmentation arxiv preprint guanghui qin jason eisner learning ask querying lm mixture soft prompt arxiv preprint alec radford karthik narasimhan improving language understanding generative alec radford jeffrey wu rewon child david luan dario amodei ilya sutskever et al language model unsupervised multitask learner openai blog alec radford jong wook kim chris hallacy aditya ramesh gabriel goh sandhini agarwal girish sastry amanda askell pamela mishkin jack clark et al learning transferable visual model natural language supervision international conference machine learning pp pmlr vignesh ramanathan anmol kalia vladan petrovic yi wen baixue zheng baishan guo rui wang aaron marquez rama kovvuri abhishek kadian et al paco part attribute common object proceeding ieee conference computer vision pattern recognition pp rebuffi hakan bilen andrea vedaldi learning multiple visual domain residual adapter advance neural information processing system robin rombach andreas blattmann dominik lorenz patrick esser bjÃ¶rn ommer resolution image synthesis latent diffusion model proceeding ence computer vision pattern recognition pp nataniel ruiz yuanzhen li varun jampani yael pritch michael rubinstein kfir aberman dreambooth fine tuning diffusion model generation arxiv preprint chitwan saharia william chan saurabh saxena lala li jay whang emily l denton kamyar ghasemipour raphael gontijo lope burcu karagol ayan tim salimans et al photorealistic diffusion model deep language understanding advance neural information processing system lin song yanwei li zhengkai jiang zeming li xiangyu zhang hongbin sun jian sun nanning zheng rethinking learnable tree filter generic feature transform advance neural information processing system sung jaemin cho mohit bansal transfer learning task proceeding conference computer vision pattern recognition pp zhi tian chunhua shen hao chen conditional convolution instance segmentation european conference computer vision pp springer hugo touvron thibaut lavril gautier izacard xavier martinet lachaux timothÃ©e lacroix baptiste roziÃ¨re naman goyal eric hambro faisal azhar aurelien rodriguez armand joulin edouard grave guillaume lample llama open efficient foundation language model arxiv preprint xinlong wang rufeng zhang tao kong lei li chunhua shen dynamic fast instance segmentation advance neural information processing system xinlong wang wen wang yue cao chunhua shen tiejun huang image speak image generalist painter visual learning arxiv preprint xinlong wang xiaosong zhang yue cao wen wang chunhua shen tiejun huang seggpt segmenting everything context arxiv preprint enze xie wenhai wang zhiding yu anima anandkumar jose alvarez ping luo segformer simple efficient design semantic segmentation transformer advance neural information processing system mutian xu junhao zhang zhipeng zhou mingye xu xiaojuan qi yu qiao learning representation complementary understanding object point cloud proceeding aaai conference artificial intelligence volume pp jinyu yang mingqi gao zhe li shang gao fangjing wang feng zheng track anything segment anything meet video arxiv preprint chaoning zhang dongshen han yu qiao jung uk kim bae seungkyu lee choong seon hong faster segment anything towards lightweight sam mobile application arxiv preprint qingru zhang minshuo chen alexander bukharin pengcheng yu cheng weizhu chen tuo zhao adaptive budget allocation arxiv preprint renrui zhang jiaming han aojun zhou xiangfei hu shilin yan pan lu hongsheng li peng gao yu qiao efficient language model attention arxiv preprint renrui zhang xiangfei hu bohao li siyuan huang hanqiu deng hongsheng li yu qiao peng gao prompt generate cache cascade foundation model make strong learner arxiv preprint hengshuang zhao jianping shi xiaojuan qi xiaogang wang jiaya jia pyramid scene parsing network proceeding ieee conference computer vision pattern recognition pp xu zhao wenchao ding yongqi yinglong du tao yu min li ming tang jinqiao wang fast segment anything arxiv preprint sixiao zheng jiachen lu hengshuang zhao xiatian zhu zekun luo yabiao wang yanwei fu jianfeng feng tao xiang philip h torr et al rethinking semantic segmentation perspective transformer proceeding conference computer vision pattern recognition pp kaiyang zhou jingkang yang chen change loy ziwei liu learning prompt language model international journal computer vision xueyan zou jianwei yang hao zhang feng li linjie li jianfeng gao yong jae lee segment everything everywhere arxiv preprint