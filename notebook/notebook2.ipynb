{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "GOOGLE_API_KEY=os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./Street_1330_2000x.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from google.cloud import vision\n",
    "\n",
    "\n",
    "def analyze_image_from_uri(\n",
    "    image_uri: str,\n",
    "    feature_types: Sequence,\n",
    ") -> vision.AnnotateImageResponse:\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = image_uri\n",
    "    features = [vision.Feature(type_=feature_type) for feature_type in feature_types]\n",
    "    request = vision.AnnotateImageRequest(image=image, features=features)\n",
    "\n",
    "    response = client.annotate_image(request=request)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def print_labels(response: vision.AnnotateImageResponse):\n",
    "    print(\"=\" * 80)\n",
    "    for label in response.label_annotations:\n",
    "        print(\n",
    "            f\"{label.score:4.0%}\",\n",
    "            f\"{label.description:5}\",\n",
    "            sep=\" | \",\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " 98% | Red  \n",
      " 90% | Orange\n",
      " 88% | Neon \n",
      " 85% | Electronic signage\n",
      " 82% | Neon sign\n",
      " 71% | Night\n",
      " 62% | Sign \n"
     ]
    }
   ],
   "source": [
    "image_uri = \"https://www.neoncreations.co.uk/cdn/shop/products/Street_1330_2000x.jpg\"\n",
    "features = [vision.Feature.Type.LABEL_DETECTION]\n",
    "\n",
    "response = analyze_image_from_uri(image_uri, features)\n",
    "print_labels(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_text(response: vision.AnnotateImageResponse):\n",
    "    print(\"=\" * 80)\n",
    "    for annotation in response.text_annotations:\n",
    "        vertices = [f\"({v.x},{v.y})\" for v in annotation.bounding_poly.vertices]\n",
    "        print(\n",
    "            f\"{repr(annotation.description):42}\",\n",
    "            \",\".join(vertices),\n",
    "            sep=\" | \",\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "'YOUR\\nAVE\\nTEXT HERE\\nBLVD'               | (76,89),(437,89),(437,323),(76,323)\n",
      "'YOUR'                                     | (146,139),(344,98),(355,153),(157,194)\n",
      "'AVE'                                      | (351,96),(385,89),(388,104),(354,111)\n",
      "'TEXT'                                     | (85,216),(231,241),(222,294),(76,269)\n",
      "'HERE'                                     | (245,244),(395,270),(386,322),(236,296)\n",
      "'BLVD'                                     | (401,273),(437,279),(434,293),(399,287)\n"
     ]
    }
   ],
   "source": [
    "image_uri = \"https://static.easycanvasprints.com/Upload/mkt/PLA/ECP/BAS_SEM_20170824_MetalStretSigns_2Up_Green_Texthere.jpg\" \n",
    "features = [vision.Feature.Type.TEXT_DETECTION]\n",
    "\n",
    "response = analyze_image_from_uri(image_uri, features)\n",
    "print_text(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text: str) -> dict:\n",
    "    \"\"\"Detects the text's language.\"\"\"\n",
    "    from google.cloud import translate_v2 as translate\n",
    "\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    # Text can also be a sequence of strings, in which case this method\n",
    "    # will return a sequence of results for each text.\n",
    "    result = translate_client.detect_language(text)\n",
    "\n",
    "    print(f\"Text: {text}\")\n",
    "    print(\"Confidence: {}\".format(result[\"confidence\"]))\n",
    "    print(\"Language: {}\".format(result[\"language\"]))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: YOUR\n",
      "Confidence: 1\n",
      "Language: en\n",
      "Text: AVE\n",
      "Confidence: 0.8893280625343323\n",
      "Language: en\n",
      "Text: TEXT\n",
      "Confidence: 0.98828125\n",
      "Language: en\n",
      "Text: HERE\n",
      "Confidence: 1\n",
      "Language: en\n",
      "Text: BLVD\n",
      "Confidence: 1\n",
      "Language: en\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'language': 'en', 'confidence': 1, 'input': 'YOUR'},\n",
       " {'language': 'en', 'confidence': 0.8893280625343323, 'input': 'AVE'},\n",
       " {'language': 'en', 'confidence': 0.98828125, 'input': 'TEXT'},\n",
       " {'language': 'en', 'confidence': 1, 'input': 'HERE'},\n",
       " {'language': 'en', 'confidence': 1, 'input': 'BLVD'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[detect_language(response.text_annotations[i+1].description) for i in range(len(response.text_annotations)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(target: str, text: str) -> dict:\n",
    "    \"\"\"Translates text into the target language.\n",
    "\n",
    "    Target must be an ISO 639-1 language code.\n",
    "    See https://g.co/cloud/translate/v2/translate-reference#supported_languages\n",
    "    \"\"\"\n",
    "    from google.cloud import translate_v2 as translate\n",
    "\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    if isinstance(text, bytes):\n",
    "        text = text.decode(\"utf-8\")\n",
    "\n",
    "    # Text can also be a sequence of strings, in which case this method\n",
    "    # will return a sequence of results for each text.\n",
    "    result = translate_client.translate(text, target_language=target)\n",
    "\n",
    "    print(\"Text: {}\".format(result[\"input\"]))\n",
    "    print(\"Translation: {}\".format(result[\"translatedText\"]))\n",
    "    print(\"Detected source language: {}\".format(result[\"detectedSourceLanguage\"]))\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: YOUR\n",
      "Translation: 당신의\n",
      "Detected source language: en\n",
      "Text: AVE\n",
      "Translation: 아베\n",
      "Detected source language: en\n",
      "Text: TEXT\n",
      "Translation: 텍스트\n",
      "Detected source language: en\n",
      "Text: HERE\n",
      "Translation: 여기\n",
      "Detected source language: en\n",
      "Text: BLVD\n",
      "Translation: 블버드\n",
      "Detected source language: en\n"
     ]
    }
   ],
   "source": [
    "response=[translate_text(\"ko\", response.text_annotations[i+1].description) for i in range(len(response.text_annotations)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['당신의', '아베', '텍스트', '여기', '블버드']\n"
     ]
    }
   ],
   "source": [
    "print([response[i]['translatedText'] for i in range(len(response))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_text=[response[i]['translatedText'] for i in range(len(response))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['당신의', '아베', '텍스트', '여기', '블버드']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('image_translated.txt', 'w') as f:\n",
    "    for i in range(len(translated_text)):\n",
    "        f.write(translated_text[i])\n",
    "        f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
