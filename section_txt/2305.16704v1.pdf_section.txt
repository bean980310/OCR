--- ABSTRACT ---
In-context learning, a capability that enables a model to learn from input examples on the fly without necessitating weight updates, is a defining characteristic of large language models. In this work, we follow the setting proposed in (Garg et al., 2022) to better understand the generality and limitations of in-context learning from the lens of the simple yet fundamental task of linear regression. The key question we aim to address is: Are transformers more adept than some natural and simpler architectures at performing in-context learning under varying distribution shifts? To compare transformers, we propose to use a simple architecture based on set-based Multi-Layer Perceptrons (MLPs). We find that both transformers and set-based MLPs exhibit in-context learning under in-distribution evaluations, but transformers more closely emulate the performance of ordinary least squares (OLS). Transformers also display better resilience to mild distribution shifts, where set-based MLPs falter. However, under severe distribution shifts, both models’ in-context learning abilities diminish. 1
--- INTRODUCTION ---
Transformers (Vaswani et al., 2017) form the backbone of modern large language models (LLMs) including the likes of GPT-3 (Brown et al., 2020) and GPT-4 (OpenAI, 2023). These LLMs demonstrate remarkable capabilities, such as in-context learning and natural language-based algorithmic reasoning. However, we are only beginning to understand the origins, limitations, and generality of these capabilities, which is essential for developing safe and reliable LLMs. In-context learning (ICL) refers to a model’s capability to acquire knowledge on the fly from examples provided at test time without requiring any weight updates. This ability is especially useful when the model has to adapt to new tasks from a few demonstrations in the test prompt, for example, adapting a model to drive in a new region with few demonstrations. Understanding ICL for LLMs such as GPT-3 trained on raw text data is particularly challenging. In Garg et al. (2022), the authors propose an insightful training setup, which abstracts away the raw nature of text data. In their work, transformer models from GPT-2 family are trained on prompts comprising of input, label demonstrations and shown to emulate the ordinary least squares (OLS) algorithm. Certain natural questions arise at this point. What specifics of the transformer are responsible for the emergence of this behvavior? Can simpler architectures exhibit the same capabilities? How resilient is ICL to distribution shifts? These are the questions that motivate our work. To compare with transformers, we propose a natural baseline that is based on set-based MLPs Zaheer et al. (2017); Lopez-Paz et al. (2017) that exploit the permutation-invariant nature of the task. Depending on the distribution of test prompts, we categorize in-context learning into in-distribution ICL (ID-ICL) and out-of-distribution ICL (OOD-ICL). Under ID-ICL, the train “Correspondance to kartikahuja@meta.com --- --distribution of the prompt is identical to the test distribution of the prompt. Under OOD-ICL, the test distribution of prompt sequence is different from the train distribution. When evaluating OOD-ICL, we are particularly interested in the case when the test distribution of prompts is centered on the tail of the train distribution of prompts. We summarize our key contributions below. + First, we derive conditions under which the the optimal model that predicts the label for the current query based on the prompt coincide with the OLS or ridge regression. These are based on known arguments, yet it is important to provide them for completeness. + Despite set-based MLPs being particularly suited for this permutation-invariant task, we find that transformers (GPT-2 family) exhibit better ID-ICL abilities. + Under mild distribution shifts, we find that transformers degrade more gracefully than set-based MLPs. Under more severe distribution shifts, both transformers and set-based MLPs do not exhibit ICL abilities. + ID-ICL performance is not predictive of OOD-ICL performance for both architecture choices. Moving forward, several questions need to be answered. Why are transformers better than set-based MLPs at ICL? How can we improve the OOD-ICL abilities of these architectures? 2
