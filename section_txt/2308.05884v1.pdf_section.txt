--- ABSTRACT ---
With the emergence of increasingly powerful large language models, there is a burgeoning interest in leveraging these models for casual conversation and role-play applications. However, existing conversational and role-playing datasets often fail to capture the diverse and nuanced interactions typically exhibited by real-world role-play participants. To address this limitation and contribute to the rapidly growing field, we introduce a partially-synthetic dataset named PIPPA (Personal Interaction Pairs between People and AI). PIPPA is a result of a community-driven crowdsourcing effort involving a group of role-play enthusiasts. The dataset comprises over 1 million utterances that are distributed across 26,000 conversation sessions and provides a rich resource for researchers and AI developers to explore and refine conversational AI systems in the context of role-play scenarios. Keywords: conversational dataset; role-play dataset; fine-tuning; large language model 1.
--- INTRODUCTION ---
In recent years, the field of natural language processing has experienced a significant transformation, primarily driven by the remarkable advancements in large language models (LLMs). These models, fueled by extensive pre-training data and computational resources, exhibit an extraordinary ability to comprehend and generate human-like text. In order to harness their full potential and tailor them to specific domains, a set of high quality domain-specific samples are typically required during the supervised fine-tuning process (Zhou et al., 2023; Ouyang et al., 2022). A promising application of LLMs, which is somewhat overshadowed by others in academia, is to build dialogue agents specialized in role-play (Shanahan et al., 2023). Specifically, given a text-based description of some character or persona, the agent can simulate this character while users interact with the agent for the purposes of entertainment. Similar to numerous applications that necessitate the intricate capabilities of LLMs, effectively fine-tuning an LLM into a proficient role-play agent demands a substantial corpus of conversation and role-play centered texts. This is particularly crucial when employing small base models, which offer greater convenience and cost-effectiveness in deployment and *. Tear Gosling and Alpin Dale were primarily responsible for curating and assembling the PIPPA dataset, as well as formulating the preliminary version of the paper. Yinhe Zheng contributed to the refinement of the paper through substantive revisions. --- --inference. However, despite the importance of such datasets, open-source datasets tailored to serve this purpose. To address the above issue and mitigate this gap, we intro here is a notable scarcity of duce a novel dataset, named Personal Interaction Pairs between People and AI (PIPPA). PIPPA is a large-scale dataset, comprising approximately 1 million messages exchanged be ween humans and dialogue agents across nearly 26,000 unique conversations. Notably, each conversation session features a designated persona, which serves as the emulation target for the dialogue agent. The persona of each character is delineated through free text descriptions, and optional example dialogues are also supplied to facilitate accurate simu. ation of each character. The introduction of PIPPA aims to support future research and development in the fine-tuning of models to generate persona-driven, contextually rich conversations. We make PIPPA publicly available on the HuggingFace plat co/datasets/PygmalionAI/PIPPA allowing anyone to utilize purposes. 2. Dataset Compilation form at https: //huggingface. it freely for their respective The PIPPA dataset was assembled through the voluntary contributions of community mem bers who actively engaged in our initiative to develop conversa tional models that are acces sible to all. We leveraged a userscript to gather chatlogs and character descriptions from the Character.AI website | (Figure 1). This script enables users to extract interactions and persona details of dialogue agents on Character.AI, who wer e instructed to submit their chatlog data to a centralized server for the purpose of constructing the PIPPA dataset (Figure 5). Initially, PIPPA was primarily conceived to furnish a fine-tuning dataset for the Pyg-malion“ conversational models, a series of fine-tuned LLMs aimed at creating role-play agents. The collection of PIPPA began in December 2022, when the availability of high quality dialogue data was notably scarce. This endeavor, however, also encountered a challenge in regards to striking a balance between supporting the community and safeguarding personal information within the logs. As a result, we implemented a submission process that allowed users to opt out of including their conversations in the public release. PIPPA solely contains logs for which users have explicitly granted permission for public distribution. Furthermore, we diligently performed comprehensive scans to detect and redact/mod ulate personally identifiable information (PII) within the publ icly accessible portion of the dataset, to the best of our ability, ensuring the protection of submitter identities. 3. Dataset Analysis The PIPPA dataset encompasses a substantial collection of conversational data, encompassing 25,940 conversations that involve 1,254 distinct personas and 1,049,015 dialogue sessions. 1. Due to subsequent changes to the Character.AI website, the userscript is no longer functional. The script can be found at https: //github.com/0x000011b/characterai-dumper 2. The models can be accessed at https://huggingface.co/PygmalionAI --- --en OOO < sae ce ~~ [Interaction count Pol name Remember: Everything Characters say is made up! JRR Tolkien GED Tam J.R.R. Tolkien, english writer, poet, philologist, and academic, best known as the author of the high fantasy works The Hobbit and The Lord of the Rings. Pro-defined greeting message by bot creator Alpid Mr Tolkien. How do you do? JRR Tolkien GE) Tam fine my boy, though Iam getting quite old now! I am 74 years old already (the same age as Bilbo, and not unlike him | don't feel it!) Alpid Hahal I was to Avebury today. Lovely place. A local showed me to a tree there, said you were inspired by that very tree when writing about the Ents! JRR Tolkien GED Really? What a nice coincidence! I love trees, and many of them inspired me to create the Ents. Even in the Shire the trees had a presence (I think of the Old Willows, and the great oak at Bywater). It is a good thing that many people nowadays seem to understand the importance of > conserving our trees. Swipe button Figure 1: Screenshot of CharacterAl’s chat interface. Swipes refer to discarding the current bot generation and prompting for a new one. Each sample in PIPPA dataset comprises a dialogue session and a diverse set of associated metadata. Additionally, we also provide the information about the bot, which includes categories assigned by bot creators, a bot description offering a succinct overview of the bot’s persona and traits, an optional bot definition that further fleshes out the bot’s personality through example conversations, and the bot’s greeting to the user. The bot’s greeting serves as the initial entry in every conversation. Furthermore, we maintain a timestamp to document when the dialogue is submitted to us. It is important to note that that we cannot access information regarding when the conversations themselves were generated, as this information is not provided by the Character.AI website. The statistical analysis of the PIPPA dataset offers valuable insights into three crucial aspects: the number of turns in a conversation, the length of a singular message and the distribution of bot personalities. In this section, we present key statistical findings. 3.1 Conversation Length Conversations in PIPPA exhibits a diverse range of lengths, displaying a notable skewed distribution. While the median conversation length is 10 turns, the mean conversation length is remarkably higher at 40.41 turns. However, the presence of a large standard deviation of 145 turns indicates substantial dispersion in the data. This discrepancy can be attributed to the diverse conversational behavior of users interacting with bots on Character.AI. While a considerable number of users engage in shorter individual conversations with the bots, some users participate in remarkably extensive conversations, with the longest conversation in the --- --B » 2 z Conversations (log scale) i) Mi i} 100# of turns in conversation Figure 2: The distribution of conversation length (defined as the amount of ”turns” in a conversation). We have limited the display range to 0-250 turns in order to enhance readability. fmm LLM messages mmm Human messages Frequency (log scale)| un Wii Conversation Length (Words) Figure 3: Distribution of message length in the PIPPA dataset for both human inputs and bot responses. dataset containing a staggering 11,491 turns. Figure 2 depicts the log scale distribution of turn lengths up to 250 turns. --- ---Love Game Characters Coney TT Science Fiction Advice Philosophy J Debate Mystery J Knowledge Viuber Food Anime Action Anime Game Chars Drama Games Animals Count °‘anasy | Movies & TV [ay Cooperative Famous People [IN Technology [I Decisions [I Discussion Friertainnent TT Category Figure 4: Distribution of categories of characters in the PIPPA dataset. Note that each bot may be assigned multiple categories or none at all. 3.2 Message Verbosity We also analyze the verbosity (i.e., length) of messages generated by both human users and bots within the PIPPA dataset. As evidenced by Figure 3, the verbosity distribution of all messages in PIPPA can be characterized by a power-law distribution, indicating a higher prevalence of shorter messages compared to longer ones. It is also worth noting that the LLM’s responses generally exhibit greater verbosity than human inputs. This observation may be attributed to Character.AIl’s LLM potentially being trained or fine-tuned on a high-quality role-play corpus, which typically contains longer messages comparing to casual conversations. 3.3 Bot Personality Categories Within the PIPPA dataset, each bot is assigned a set of category labels by its creator. An analysis of bot personality categories in PIPPA reveals an uneven, Pareto-like distribution (see Figure 4). Notably, the categories “Anime”, “Fantasy”, and “Action” emerge as the most prevalent among the bot personas. This distribution can be attributed to the characteristics of the source community, PygmalionAI, from which these logs are collected. The community exhibits a significant number of anime? enthusiasts, resulting in a considerable proportion of bots classified under the “Anime” category. Additionally, due to the community’s interest in role-play and conversational interactions, many bots are naturally assigned to categories related to prevalent role-playing themes, thus explaining the prominent presence of bots tagged with “Action” and “Fantasy” labels. 3. Anime refers to animated media produced in Japan. --- --4.
