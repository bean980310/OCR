--- ABSTRACT ---
Imaginative play is an area of creativity that could allow robots to engage with the world around them in a much more personified way. Imaginary play can be seen as taking real objects and locations and using them as imaginary objects and locations in virtual scenarios. We adopted the story generation capability of large language models (LLMs) to obtain the stories used for imaginary play with human-written prompts. Those generated stories will be simplified and mapped into action sequences that can guide the agent in imaginary play. To evaluate whether the agent can successfully finish the imaginary play, we also designed a text adventure game to simulate a house as the playground for the agent to interact. 1
--- INTRODUCTION ---
In recent years, the domain of agents has experienced extraordinary progress, driving the creation of intelligent machines that connect the realms of science fiction and reality. As researchers, engineers, and innovators collaborate, the evolution of agents keeps pushing the limits of technology. However, how do we ensure that agents have a persistent, yet non-intrusive presence in the household? Considering kids: they are never idle — they find ways to occupy their time through play and if that play is imaginative play, then the entire home becomes a playground. We propose to develop the computational capability for agents to engage in imaginative play and link that play to navigation through the home. This will increase the presence of the agent in the home without directly demanding attention from people, but also using curiosity to invite engagement. Imaginative play is an exemplar of everyday human creativity in which real-world, mundane objects and locations act as substitutes for imaginary objects and locations as part of a pretend scenario(Zook, Magerko, and Riedl 2011). A terrarium can be a garden for growing magic seeds, a kitchen can be a laboratory, or a broom handle can be a light saber. Imaginative play is fundamental to human creativity. Computational systems that can engage in imaginative play can create a sense of presence and persona and provide opportunities for improvisational interactions. *These authors contributed equally. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. In this paper, we are focusing on exploring how to guide an agent to execute imaginary play with large language models such as ChatGPT (OpenAI 2022). Text adventure games serve as useful test beds because they have also been demonstrated to transfer to visual and real-world domains (Wang et al. 2022; Shridhar et al. 2021; Peng, Riedl, and Ammanabrolu 2022). 2
--- EXPERIMENT ---
(See Section 3). Most stories required several iterations of revision (Refer to Table 1) until they included the win state in the action sequence. Two limitations of the current model are limited prompting formats and difficulty in understanding interactive actions in the text game. The first relates to the drawback of the language model is that the generation is uncontrolled. Aside from an initial prompt, generative language models are guided by word cooccurrence, which can lead to repetition, as well as a tendency to focus on descriptive details that do not move a story forward. To solve the problem, we kept crafting prompts to direct the model to create coherent and executable stories with a clear goal and formed a fixed prompting format. The format limits the adaptivity of the agent to varied types of imaginary play. If the setting in imaginary play is modified, the model needs new prompts for the changes. The other limitation is the difficulty forChatGPT to understand connections between objects in the text game. The generated story cannot associate the objects picked from a previous room with those in the current room if no detailed prompts. That may lead to generating actions not allowed within the text game in the action sequence. The solution to alleviate such problems is to introduce the missing connections into the prompting and have more iterations of story generation to update the prompt with the generated output. Game Results with Promptings. Results from our sample stories indicate that the agent cannot determine the final win state by itself. To increase the possibility of win, we record the result and feed it back to the language model (ChatGPT). The model knows whether the agent successfully reaches the win state from the previous round’s score. If the agent doesn’t win, the prompt will tell the model to generate more descriptions of directional information in new stories to guide the agent in the next round. Although new instructions might not give the expected results every time, we still are able to catch the pattern and re-prompting ChatGPT to better train in zero-shot learning. 6
--- CONCLUSION ---
s Imaginary play is a creative direction for developing agent learning abilities. With the help of story generation from LLMs (such as ChatGPT (OpenAI 2022)), we can tell the model to generate imaginary play stories that guide the agent’s interactions through prompts. Story generation allows the agent to develop interesting imaginative stories with the objects and topic given, allowing the agent to engage in imaginative play in the real world. We use text games to model what happens within a given story and the interactions the agent generates with the setting, making the interaction controllable and explainable. Through mapping imaginative play to real-world scenarios through text games, we figured out how to use rewards to better prompt the model and construct the stories that can guide the agent in imaginary play. --- --References Coté, M.-A.; Kadar, A.; Yuan, X.; Kybartas, B.; Barnes, T.; Fine, E.; Moore, J.; Hausknecht, M.; Asri, L. E.; Adada, M.; et al. 2018. Textworld: A learning environment for textbased games. In Workshop on Computer Games, 41-75. Springer. Martin, L.; Ammanabrolu, P.; Wang, X.; Hancock, W.; Singh, S.; Harrison, B.; and Riedl, M. 2018. Event Representations for Automated Story Generation with Deep Neural Nets. Proceedings of the AAAI Conference on Artificial Intelligence, 32(1). Narasimhan, K.; Kulkarni, T.; and Barzilay, R. 2015. Language Understanding for Text-based Games Using Deep Reinforcement Learning. arXiv:1506.08941. OpenAI. 2022. ChatGPT: A Large-Scale Open-Domain Chatbot. https://openai.com/blog/chatgpt/. Peng, X.; Cui, C.; Zhou, W.; Jia, R.; and Riedl, M. 2023. Story Shaping: Teaching Agents Human-like Behavior with Stories. arXiv:2301.10107. Peng, X.; Li, S.; Wiegreffe, S.; and Riedl, M. 2022a. Inferring the Reader: Guiding Automated Story Generation with Commonsense Reasoning. In Findings of the Association for Computational Linguistics: EMNLP 2022, 7008-7029. Peng, X.; Riedl, M.; and Ammanabrolu, P. 2022. Inherently explainable reinforcement learning in natural language. Advances in Neural Information Processing Systems, 35: 16178-16190. Peng, X.; Xie, K.; Alabdulkarim, A.; Kayam, H.; Dani, S.; and Riedl, M. 2022b. Guiding Neural Story Generation with Reader Models. In Findings of the Association for Computational Linguistics: EMNLP 2022, 7087-7111. Shridhar, M.; Yuan, X.; Coté, M.-A.; Bisk, Y.; Trischler, A.; and Hausknecht, M. 2021. ALFWorld: Aligning Text and Embodied Environments for Interactive Learning. In Proceedings of the International Conference on Learning Representations (ICLR). Wang, R.; Jansen, P.; Coté, M.-A.; and Ammanabrolu, P. 2022. ScienceWorld: Is your Agent Smarter than a Sth Grader? Zook, A.; Magerko, B.; and Riedl, M. 2011. Formally modeling pretend object play. In Proceedings of the 8th ACM Conference on Creativity and Cognition, 147-156.
