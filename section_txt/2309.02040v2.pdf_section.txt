--- ABSTRACT ---
Inverse design refers to the problem of optimizing the input of an objective function in order to enact a target outcome. For many real-world engineering problems, the objective function takes the form of a simulator that predicts how the system state will evolve over time, and the design challenge is to optimize the initial conditions that lead to a target outcome. Recent developments in learned simulation have shown that graph neural networks (GNNs) can be used for accurate, efficient, differentiable estimation of simulator dynamics, and support high-quality design optimization with gradient- or sampling-based optimization procedures. However, optimizing designs from scratch requires many expensive model queries, and these procedures exhibit basic failures on either non-convex or high-dimensional problems. In this work, we show how denoising diffusion models (DDMs) can be used to solve inverse design problems efficiently and propose a particle sampling algorithm for further improving their efficiency. We perform experiments on a number of fluid dynamics design challenges, and find that our approach substantially reduces the number of calls to the simulator compared to standard techniques. 1.
--- METHOD ---
Given some task specification c, we have a target distribution of designs 7 (a) which we want to optimize w.r.t. 2. To simplify notation, we do not emphasize the dependence of --- --Diffusion Generative Inverse Design a Generating and Evaluating Designs Diffusion Generative Model Learned Simulator # a x,~ MOD) Xy~ a(x) 8, a >| () Energy Function S + b__ Diffusion Model Trained on Prior Optimized Designs Reverse diffusion x Diffusion C Optimizing design samples for reward Guided Sampling Figure 1. (a) Given initial conditions governed by 4c, energy function parameters 0, and learned GNN dynamics model fz, design samples a from the diffusion model are assigned a cost (a). (b) Schematic of the DDM training (c) Gradients VE and conditioning set (0 and £) inform energy and conditional guidance, resp. m on c. This distribution is a difficult object to handle, since a highly non-convex cost landscape might hinder efficient optimization. We can capture prior knowledge over ‘sensible’ designs in form of a prior distribution p(a) learned from existing data. Given a prior, we may sample from the distribution (ew) x p(a)n(a), a) which in this work is achieved by using a diffusion method with guided sampling. The designs will subsequently be evaluated by a learned forward model comprised of a pretrained GNN simulator and a reward function (Allen et al., 2022; Pfaff et al., 2021; Sanchez-Gonzalez et al., 2020) (see Appendix A). Let E : X +> R be the cost (or “energy”) of a design x € X for a specific task c under the learned simulator (dependence of E on c is omitted for simplicity). The target distribution of designs (a) is defined by the Boltzmann distribution n(n) =F exp (-=@) , (2) T where Z denotes the unknown normalizing constant and T a temperature parameter. As 7 — 0, this distribution concentrates on its modes, that is on the set of the optimal designs for the cost H°(a). Direct methods to sample from 7(a) rely on expensive Markov chain Monte Carlo techniques or variational methods minimizing a reverse KL criterion. We will rely on a data-driven prior learned by the diffusion model from previous optimization attempts. We collect optimization trajectories of designs for different task parametrizations c using Adam (Kingma & Ba, 2015) or CEM (Rubinstein, 1999) to optimize a. Multiple entire optimization trajectories of designs are included in the training set for the generative model, providing a mix of design quality. These optimization trajectories are initialized to flat tool(s) below the fluid (see Figure 5), which can be more easily shaped into successful tools than a randomly initialized one. Later, when we compare the performance of the DDM to Adam and CEM, we will be using randomly initialized tools for Adam and CEM, which is substantially more challenging. 2.1. Diffusion generative models We use DDMs to fit p(x) (Ho et al., 2020; Song et al., 2020b). The core idea is to initialize using training data Xo ~ p, captured by a diffusion process (21) +¢[o,1) defined by day, = —Bya,dt + /2B;dwy, (3) where (wz) te [0,1] denotes the Wiener process. We denote by p(x) the distribution of x, under (3). For 3; large enough, pi(x) © N(x; 0, I). The time-reversal of (3) satisfies da, = —ifar + 2V a log p:(a:)|dt + /28idw;, (4) where (w; )ze{0,1] is a Wiener process when time flows backwards from t = 1 to t = 0, and d¢ is an infinitesimal negative timestep. By initializing (4) using x21 ~ pi, we obtain a ~ p. In practice, the generative model is obtained by sampling an approximation of (4), replacing p;(a) by M(a;0, J) and the intractable score V,, log p;(a) by s(x, t). The score estimate g(a, t) is learned by denoising score matching, i.e. we use the fact that V, log p,(x) = f V2 log p(a:|xo)p(ao|a1)dao where p(x,|ao) = N (a1; /arxo, VI — a:Z) is the transition density of (3), a, being a function of (Bs) sefo.¢) (Song et al., 2020b). It follows straightforwardly that the score satisfies V,, log p;(a) = —Efe|a, = a] //1 — a; for --- --Diffusion Generative Inverse Design x, = ,/a,Xq + 1 — aye. We then learn the score by minimizing L(O) = Eayxp,tru(0,1),e~N(0,1)l|€o(@e,t) — €l|?, (5) where €9(a,t) is a denoiser estimating Ele|”, = a]. The score function s9(a,t) © Vz log p;(a) is obtained using so(x,t) = — (6) Going forward, V refers to V2, unless otherwise stated. We can also sample from p(x) using an ordinary differential equation (ODE) developed in (Song et al., 2020b). Let us define % = a@;/\/ay and o = V1 —a;//a%. Then by initializing 2, ~ N(0,J), equivalently Z| ~ N(0,a;,1Z) and solving backward in time _ Lt dz, = &\ (3m) don, (7) op +then ao = \/a; Zp is an approximate sample from p(). 2.2. Approximately sampling from target 7(2) We want to sample 7(a) defined in (1) where p(a) can be sampled from using the diffusion model. We describe two possible sampling procedures with different advantages for downstream optimization. Energy guidance. Observe that F(a) = [ #20)nleileo)dar, and the gradient satisfies V log t,(a.) = V log p, (a1) + V log (22), where 7;(a@,) = f 1(ao)p(ao|a@-)dap. We approximate this term by making the approximation “ estimated ao” 1 (&z(az, t)). (8) Tm (a) © Now, by (6), and the identity Vlog 7(a) = —r~!VE(2), we may change the reverse sampling procedure by a modified denoising vector éo(az,t) = eo(az,t) + AT 1 V1 — a VE(&(a1,t)), (9) with \ being an hyperparameter. We defer the results on energy guidance Appendix E. Conditional guidance. Similarly to classifier-free guidance (Ho & Salimans, 2022), we explore conditioning on Algorithm 1 Particle optimization of base distribution. input energy function E, diffusion generative model po, temperature 7, noise scale o, rounds K. 2: 89 = {wi}®, fora’ ‘NO, 1) So = 0,S1 = W#t = Oand t = 1 sample sets 4: for k € {0...K}do Compute S* = {x} }\_, from S¥ by solving reverse ODE in Eq. (7). 6: So =So USK,S; = S1 USE Compute normalized importance weights w= {w| wo exp (— 220), ay € So} 8: setSP*! = {ai}! foray SON wid, (@) set Skt! = (ai }!9t! for ai ~ N(@; zi, 071) 10: end for return arg ming cg, E(«) cost (energy) e and task c. A modified denoising vector in the reverse process follows as a combination between the denoising vector of a conditional denoiser ey and unconditional denoiser €g €(wz,,c,e,t) = (1+ A)eg (a1, €, €,t) — A€o(ai,t), (10) where €,, is learned by conditioning on c and cost e from optimization trajectories. In our
--- EXPERIMENT ---
s on a number of fluid dynamics design challenges, and find that our approach substantially reduces the number of calls to the simulator compared to standard techniques. 1. Introduction Substantial improvements to our way of life hinge on devising solutions to engineering challenges, an area in which Machine Learning (ML) advances is poised to provide positive real-world impact. Many such problems can be formulated as designing an object that gives rise to some desirable physical dynamics (e.g. designing an aerodynamic car or a watertight vessel). Here we are using ML to accelerate 'Max Planck Institute for Intelligent Systems, Tiibingen, Germany *Google DeepMind, London, UK *Columbia University, New York, NY. Correspondence to: Marin Vlastelica <marin.vlastelica@tue.mpg.de>, Kimberly Stachenfeld <stachenfeld@deepmind.com>. Preprint. Copyright 2023 by the authors. this design process by learning both a forward model of the dynamics and a distribution over the design space. Prior approaches to ML-accelerated design have used neural networks as a differentiable forward model for optimization (Challapalli et al., 2021; Christensen et al., 2020; GomezBombarelli et al., 2018). We build on work in which the forward model takes the specific form of a GNN trained to simulate fluid dynamics (Allen et al., 2022). Since the learned model is differentiable, design optimization can be accomplished with gradient-based approaches (although these struggle with zero or noisy gradients and local minima) or sampling-based approaches (although these fare poorly in high-dimensional design spaces). Both often require multiple expensive calls to the forward model. However, generative models can be used to propose plausible designs, thereby reducing the number of required calls (Forte et al., 2022; Zheng et al., 2020; Kumar et al., 2020). In this work, we use DDMs to optimize designs by sampling from a target distribution informed by a learned data-driven prior. DDMs have achieved extraordinary results in image generation (Song et al., 2020a;b; Karras et al., 2022; Ho et al., 2020), and has since been used to learn efficient planners in sequential decision making and reinforcement learning (Janner et al., 2022; Ajay et al., 2022), sampling on manifolds (De Bortoli et al., 2022) or constrained optimization formulations (Graikos et al., 2022). Our primary contribution is to consider DDMs in the setting of physical problem solving. We find that such models combined with continuous sampling procedures enable to solve design problems orders of magnitude faster than off-the-shelf optimizers such as CEM and Adam. This can be further improved by utilizing a particle sampling scheme to update the base distribution of the diffusion model which by cheap evaluations (few ODE steps) with a learned model leads to better designs in comparison to vanilla sampling procedures. We validate our findings on multiple experiments in a particle fluid design environment. 2. Method Given some task specification c, we have a target distribution of designs 7 (a) which we want to optimize w.r.t. 2. To simplify notation, we do not emphasize the dependence of --- --Diffusion Generative Inverse Design a Generating and Evaluating Designs Diffusion Generative Model Learned Simulator # a x,~ MOD) Xy~ a(x) 8, a >| () Energy Function S + b__ Diffusion Model Trained on Prior Optimized Designs Reverse diffusion x Diffusion C Optimizing design samples for reward Guided Sampling Figure 1. (a) Given initial conditions governed by 4c, energy function parameters 0, and learned GNN dynamics model fz, design samples a from the diffusion model are assigned a cost (a). (b) Schematic of the DDM training (c) Gradients VE and conditioning set (0 and £) inform energy and conditional guidance, resp. m on c. This distribution is a difficult object to handle, since a highly non-convex cost landscape might hinder efficient optimization. We can capture prior knowledge over ‘sensible’ designs in form of a prior distribution p(a) learned from existing data. Given a prior, we may sample from the distribution (ew) x p(a)n(a), a) which in this work is achieved by using a diffusion method with guided sampling. The designs will subsequently be evaluated by a learned forward model comprised of a pretrained GNN simulator and a reward function (Allen et al., 2022; Pfaff et al., 2021; Sanchez-Gonzalez et al., 2020) (see Appendix A). Let E : X +> R be the cost (or “energy”) of a design x € X for a specific task c under the learned simulator (dependence of E on c is omitted for simplicity). The target distribution of designs (a) is defined by the Boltzmann distribution n(n) =F exp (-=@) , (2) T where Z denotes the unknown normalizing constant and T a temperature parameter. As 7 — 0, this distribution concentrates on its modes, that is on the set of the optimal designs for the cost H°(a). Direct methods to sample from 7(a) rely on expensive Markov chain Monte Carlo techniques or variational methods minimizing a reverse KL criterion. We will rely on a data-driven prior learned by the diffusion model from previous optimization attempts. We collect optimization trajectories of designs for different task parametrizations c using Adam (Kingma & Ba, 2015) or CEM (Rubinstein, 1999) to optimize a. Multiple entire optimization trajectories of designs are included in the training set for the generative model, providing a mix of design quality. These optimization trajectories are initialized to flat tool(s) below the fluid (see Figure 5), which can be more easily shaped into successful tools than a randomly initialized one. Later, when we compare the performance of the DDM to Adam and CEM, we will be using randomly initialized tools for Adam and CEM, which is substantially more challenging. 2.1. Diffusion generative models We use DDMs to fit p(x) (Ho et al., 2020; Song et al., 2020b). The core idea is to initialize using training data Xo ~ p, captured by a diffusion process (21) +¢[o,1) defined by day, = —Bya,dt + /2B;dwy, (3) where (wz) te [0,1] denotes the Wiener process. We denote by p(x) the distribution of x, under (3). For 3; large enough, pi(x) © N(x; 0, I). The time-reversal of (3) satisfies da, = —ifar + 2V a log p:(a:)|dt + /28idw;, (4) where (w; )ze{0,1] is a Wiener process when time flows backwards from t = 1 to t = 0, and d¢ is an infinitesimal negative timestep. By initializing (4) using x21 ~ pi, we obtain a ~ p. In practice, the generative model is obtained by sampling an approximation of (4), replacing p;(a) by M(a;0, J) and the intractable score V,, log p;(a) by s(x, t). The score estimate g(a, t) is learned by denoising score matching, i.e. we use the fact that V, log p,(x) = f V2 log p(a:|xo)p(ao|a1)dao where p(x,|ao) = N (a1; /arxo, VI — a:Z) is the transition density of (3), a, being a function of (Bs) sefo.¢) (Song et al., 2020b). It follows straightforwardly that the score satisfies V,, log p;(a) = —Efe|a, = a] //1 — a; for --- --Diffusion Generative Inverse Design x, = ,/a,Xq + 1 — aye. We then learn the score by minimizing L(O) = Eayxp,tru(0,1),e~N(0,1)l|€o(@e,t) — €l|?, (5) where €9(a,t) is a denoiser estimating Ele|”, = a]. The score function s9(a,t) © Vz log p;(a) is obtained using so(x,t) = — (6) Going forward, V refers to V2, unless otherwise stated. We can also sample from p(x) using an ordinary differential equation (ODE) developed in (Song et al., 2020b). Let us define % = a@;/\/ay and o = V1 —a;//a%. Then by initializing 2, ~ N(0,J), equivalently Z| ~ N(0,a;,1Z) and solving backward in time _ Lt dz, = &\ (3m) don, (7) op +then ao = \/a; Zp is an approximate sample from p(). 2.2. Approximately sampling from target 7(2) We want to sample 7(a) defined in (1) where p(a) can be sampled from using the diffusion model. We describe two possible sampling procedures with different advantages for downstream optimization. Energy guidance. Observe that F(a) = [ #20)nleileo)dar, and the gradient satisfies V log t,(a.) = V log p, (a1) + V log (22), where 7;(a@,) = f 1(ao)p(ao|a@-)dap. We approximate this term by making the approximation “ estimated ao” 1 (&z(az, t)). (8) Tm (a) © Now, by (6), and the identity Vlog 7(a) = —r~!VE(2), we may change the reverse sampling procedure by a modified denoising vector éo(az,t) = eo(az,t) + AT 1 V1 — a VE(&(a1,t)), (9) with \ being an hyperparameter. We defer the results on energy guidance Appendix E. Conditional guidance. Similarly to classifier-free guidance (Ho & Salimans, 2022), we explore conditioning on Algorithm 1 Particle optimization of base distribution. input energy function E, diffusion generative model po, temperature 7, noise scale o, rounds K. 2: 89 = {wi}®, fora’ ‘NO, 1) So = 0,S1 = W#t = Oand t = 1 sample sets 4: for k € {0...K}do Compute S* = {x} }\_, from S¥ by solving reverse ODE in Eq. (7). 6: So =So USK,S; = S1 USE Compute normalized importance weights w= {w| wo exp (— 220), ay € So} 8: setSP*! = {ai}! foray SON wid, (@) set Skt! = (ai }!9t! for ai ~ N(@; zi, 071) 10: end for return arg ming cg, E(«) cost (energy) e and task c. A modified denoising vector in the reverse process follows as a combination between the denoising vector of a conditional denoiser ey and unconditional denoiser €g €(wz,,c,e,t) = (1+ A)eg (a1, €, €,t) — A€o(ai,t), (10) where €,, is learned by conditioning on c and cost e from optimization trajectories. In our experiments we shall choose c to contain the design cost percentile and target goal destination 0 for fluid particles (Figure Ic). 2.3. A modified base distribution through particle sampling Our generating process initializes samples at time t =from N(x; 0,1) © pi (a). The reverse process with modifications from subsection 2.2 provides approximate samples from 7(a) at t = 0. However, as we are approximately solving the ODE of an approximate denoising model with an approximate cost function, this affects the quality of samples with respect to E'. Moreover, “bad” samples from N (a; 0, J) are hard to correct by guided sampling. To mitigate this, instead of using samples from NV’ (a; 0, J) to start the reverse process of 7(a), we use a multi-step particle sampling scheme which evaluates the samples {ari}, by a rough estimate of the corresponding {a}, }*._, derived froma few-step reverse process and evaluation with F. The particle procedure relies on re-sampling from a weighted particle approximation of (a) and then perturbing the resampled particles, see |. This heuristic does not provide samples from 7 but we found that it provides samples of lower energy samples across tasks. However, with N samples in each of the k rounds, it still requires O( Nk) evaluations of E, which may be prohibitively expensive depending on the choice of FE. ‘Ideally at test time we would evaluate the samples with the ground-truth dynamics model, but we have used the approximate GNN model due to time constraints on the project. --- --Diffusion Generative Inverse Design without shift with shift [ — Diff % -1000 MN 3 — cem mi & & 1500 + =2000 | — nf 0 200 400 600 800 © 200 400 600# queries # queries Figure 2. Performance of the different optimization methods in the angle optimization task. We observe that the diffusion generative model requires a small number of model queries, whereas Adam in comparison requires many expensive model queries. 3. Experiments We evaluate our approach on a 2D fluid particle environment with multiple tasks of varying complexity, which all involve shaping the tool (Figure la, black lines) such that the fluid particles end up in a region of the scene that minimizes the cost FE (Allen et al., 2022). As baselines, we use the Adam optimizer combined with a learned model of the particles and the CEM optimizer which also optimizes with a learned model. For all experiments we have used a simple MLP as the denoising model and GNN particle simulation model for evaluation of the samples. The first task is a simple “Contain” task with a single source of water particles, a goal position above the floor specified by c = (x,y), and an articulated tool with 16 joints whose angles are optimized to contain the fluid near the goal (see Allen et al. (2022)). In Figure 2a, we see that both the Adam optimizer and CEM are able to optimize the task. However with training a prior distribution on optimization trajectories and guided sampling we are able to see the benefits of having distilled previous examples of optimized designs into our prior, and achieve superior performance with fewer samples in unseen tasks sampled in-distribution. Effect of Design Dataset Cost Cutoff Dg wu a ° Both Matching Non-match Cutoff mmmmmmmmmmmFigure 3. Generative models were trained on a dataset of designs produced from CEM- and Adam-optimized designs on either of two tasks Matching, Non-matching, or Both. Designs in the train dataset were filtered to have costs below the specified cutoff. If we modify the task by introducing a parameter controlling x,y shift parameter, we observe that Adam fails. This is because there are many values of the shift for which the tool makes no contact with the fluid (see Figure 2b), and therefore gets no gradient information from E’. We provide results for more complex tasks in Appendix C (Figure 5). Overall, we find that this approach is capable of tackling a number of different types of design challenges, finding effective solutions when obstacles are present, for multimodal reward functions, and when multiple tools must be coordinated. 3.1. Dataset quality impact We analyzed how the model performs with conditional guidance when trained on optimization trajectories of CEM that optimize the same task (matching), a different task (nonmatching), or a mix of tasks (Figure 3). The two tasks were “Contain” (described above) and “Ramp” (transport fluid to the far lower corner). Unsurprisingly, the gap between designs in the training dataset and the solution for the current task has a substantial impact on performance. We also control the quality of design samples by filtering out samples above a certain cost level for the c with which they were generated. Discarding bad samples from the dataset does not improve performance beyond a certain point: best performance is obtained with some bad-performing designs in the dataset. Intuitively, we believe this is because limiting the dataset to a small set of optimized designs gives poor coverage of the design space, and therefore generalizes poorly even to in-distribution test problems. Further, training the generative model on samples from optimization trajectories of only a non-matching task has a substantial negative impact on performance. We expect the energy guidance not to suffer from the same transfer issues as conditional guidance, since more information about the task is given through the energy function. Since we indeed obtain data to fit p(a) from Adam and CEM runs, why is diffusion more efficient? We discuss this in Appendix B. 3.2. Particle optimization in base distribution We also observe performance improvements by using the particle search scheme from subsection 2.3, see Figure 4. -— Gauss -1850 — PS Cost il ---is cy 16# Samples Figure 4. Gaussian base distribution vs. particle sampling (PS). --- --Diffusion Generative Inverse Design We hypothesize that the reason for this is because of function approximation. Since we are dealing with approximate scores, it is hard for the learned generative model to pinpoint the optima, therefore a sampling-based search approach helps. We note that the evaluation of a sample with E requires solving the ODE for sample x1, we use a 1-step reverse process making use of the relation in (8). Consequently, we can expect that linearizing the sampling will improve the particle search. 4.
--- CONCLUSION ---
In this work we have demonstrated the benefits of using diffusion generative models in simple inverse designs tasks where we want to sample from high probability regions of a target distribution 7(a) defined via E, while having access to optimization data. We analyzed energy-based and conditional guidance where the energy function involves rolling out a GNN. We find that energy guidance is a viable option, but conditional guidance works better in practice, and that performance depends heavily on the generative model’s training data. Finally, we have introduced particle search in the base distribution as a means to improve quality of the samples and demonstrated this on multiple tasks. 5. Acknowledgments We would like to thank Conor Durkan, Charlie Nash, George Papamakarios, Yulia Rubanova, and Alvaro SanchezGonzalez for helpful conversations about the project. We would also like to thank Alvaro Sanchez-Gonzalez for comments on the manuscript. References Ajay, A., Du, Y., Gupta, A., Tenenbaum, J. B., Jaakkola, T. S., and Agrawal, P. Is conditional generative modeling all you need for decision-making? In NeurIPSFoundation Models for Decision Making Workshop, 2022. Allen, K. R., Lopez-Guevara, T., Stachenfeld, K. L., Sanchez-Gonzalez, A., Battaglia, P. W., Hamrick, J. B., and Pfaff, T. Physical design using differentiable learned simulators. CoRR, abs/2202.00728, 2022. URL https: //arxiv.org/abs/2202.00728. Battaglia, P. W., Hamrick, J. B., Bapst, V., SanchezGonzalez, A., Zambaldi, V., Malinowski, M., Tacchetti, A., Raposo, D., Santoro, A., Faulkner, R., et al. Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv: 1806.01261, 2018. Challapalli, A., Patel, D., and Li, G. Inverse machine learning framework for optimizing lightweight metamaterials. Materials & Design, 208:109937, 2021. Christensen, T., Loh, C., Picek, S., Jakobovié, D., Jing, L., Fisher, S., Ceperic, V., Joannopoulos, J. D., and Soljacié, M. Predictive and generative machine learning models for photonic crystals. Nanophotonics, 9(13):4183-4192, 2020. De Bortoli, V., Mathieu, E., Hutchinson, M., Thornton, J., Teh, Y. W., and Doucet, A. Riemannian score-based generative modelling. In Advances in Neural Information Processing Systems, 2022. Forte, A. E., Hanakata, P. Z., Jin, L., Zari, E., Zareei, A., Fernandes, M. C., Sumner, L., Alvarez, J. T., and Bertoldi, K. Inverse design of inflatable soft membranes through machine learning. Advanced Functional Materials, 32, 2022. Gilmer, J., Schoenholz, S. S., Riley, P. F, Vinyals, O., and Dahl, G. E. Neural message passing for quantum chem istry. In International Conference on Machine Learning, 2017. G6émez-Bombarelli, R., Wei, J. N., Duvenaud, D., Hernandez-Lobato, J., Sanchez-Lengeling, B., Sheberla, D., Aguilera-Iparraguirre, J., Hirzel, T. D., Adams, R. P., and Aspuru-Guzik, A. Automatic chemical design using a data-driven continuous representation of molecules. ACS Central Science, 4(2):268—276, 02 2018. Graikos, A., Malkin, N., Jojic, N., and Samaras, D. Diffusion models as plug-and-play priors. In Advances in Neural Information Processing Systems, 2022. Ho, J. and Salimans, T. Classifier-free diffusion guidance. arXiv preprint arXiv:2207.12598, 2022. Ho, J., Jain, A., and Abbeel, P. Denoising diffusion probabilistic models. Advances in Neural Information Processing Systems, 33:6840-685 1, 2020. Janner, M., Du, Y., Tenenbaum, J., and Levine, S. Planning with diffusion for flexible behavior synthesis. In International Conference on Machine Learning, 2022. Karras, T., Aittala, M., Aila, T., and Laine, S. Elucidating the design space of diffusion-based generative models. In Advances in Neural Information Processing Systems, 2022. Kingma, D. P. and Ba, J. Adam: A method for stochastic optimization. In International Conference on Learning Representations, 2015. Kumar, S., Tan, S., Zheng, L., and Kochmann, D. M. Inverse-designed spinodoid metamaterials. npj Computational Materials, 6:1-10, 2020. --- --Diffusion Generative Inverse Design Pfaff, T., Fortunato, M., Sanchez-Gonzalez, A., and Battaglia, P. Learning mesh-based simulation with graph networks. In International Conference on Learning Representations, 2021. Rubinstein, R. The cross-entropy method for combinatorial and continuous optimization. Methodology and Computing in Applied Probability, 1:127-190, 1999. Sanchez-Gonzalez, A., Godwin, J., Pfaff, T., Ying, R., Leskovec, J., and Battaglia, P. Learning to simulate complex physics with graph networks. In International Conference on Machine Learning, 2020. Song, J., Meng, C., and Ermon, S. Denoising diffusion implicit models. In International Conference on Learning Representations, 2020a. Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. Score-based generative modeling through stochastic differential equations. In International Conference on Learning Representations, 2020b. Zheng, L., Kumar, S., and Kochmann, D. M. Data-driven topology optimization of spinodoid metamaterials with seamlessly tunable anisotropy. ArXiv, abs/2012.15744, 2020. --- --Diffusion Generative Inverse Design Appendix for Diffusion Generative Inverse Design A. Learned simulation with graph neural networks As in Allen et al. (2022), we rely on the recently developed MESHGNN model (Pfaff et al., 2021), which is an extension of the GNS model for particle simulation (SanchezGonzalez et al., 2020). MESHGNN is a type of messagepassing graph neural network (GNN) that performs both edge and node updates (Battaglia et al., 2018; Gilmer et al., 2017), and which was designed specifically for physics simulation. We consider simulations over physical states represented as graphs G € G. The state G = (V,E) has nodes V connected by edges EF, where each node v € V is associated with a position u,, and additional dynamical quantities q,,. In this environment, each node corresponds to a particle and edges are computed dynamically based on proximity. The simulation dynamics on which the model is trained are given by a “ground-truth” simulator which maps the state G’ at time t to the state G'+! at time t + At. The simulator can be applied iteratively over K time steps to yield a trajectory of states, or a “rollout,” which we denote (G'e, ...,G'*). The GNN model M is trained on these trajectories to imitate the ground-truth simulator fs. The learned simulator fy can be similarly applied to produce rollouts (G", G, ...,G"*), where Gi? = G° represents initial conditions given as input. Joint Angle + Shift B. Further discussion on results We trained the diffusion model on data generated from Adam and CEM optimization runs and noticed an improvement over Adam and CEM on the evaluation tasks. The reason for this is that both Adam and CEM need good initializations to solve the tasks efficiently, for example in Figure 2 for each run the initial design for Adam has uniformly sampled angles and x, y coordinates within the bounds of the environment, which would explain why we obtain worse results on average for Adam than Allen et al. (2022). Similarly, for CEM we use a Gaussian sampling distribution which is initialized with zero mean and identity covariance. If most of the density of the initial CEM distribution is not concentrated near the optimal design, then CEM will require many samples to find it. In comparison, the diffusion model learns good initializations of the designs through p(a) which can further be improved via guided sampling, as desired. C. Particle environments For evaluation, we consider similar fluid particle-simulation environments as in Allen et al. (2022). The goal being to design a ‘tool’ that brings the particles in a specific configuration. We defined the energy as the radial basis function t B(x) = exp =) peP With obstacle woe § Ney) Mal —_— Initial Optimized Initial Optimized Bi-modal Multi-tool > °r . . 3 3 H _ : : . 7 7 + & . > / e i ; ™ i= + + + |) e ~D + A - ’ ioned . ene $b 4 ee ieeeentied ee) ional Initial Optimized Initial Optimized Figure 5. Examples of guided-diffusion generated designs for different tasks c that we consider in this work. The initial designs start off completely at random, and the optimized ones solve the task. --- --Diffusion Generative Inverse Design Adam CEM Diffusion oe Optimized Joint Angles nN, —<— Optimized Joint Angles + Shift \s Figure 6. Examples of designs optimized with Adam, CEM, and guided diffusion using the generative model. Designs are initialized as random joint angles. Each design shown is the top scoring design for that optimizer, evaluated under the learned model, after having been trained on 1000 calls to the simulator (the limit of the x-axis in Figure 2). where x, are the coordinates of particle p after rolling out the simulation with the model fy¢ with initial conditons O1¢ and parameters 0;;. Note that the energy is evaluated on the last state of the simulation, hence VE needs to propagate through the whole simulation rollout. In additon to the “Contain” environments described in section 3, we provide further example environments that we used for evaluation with the resulting designs from guided diffusion can be seen in Figure 5. The task with the obstacle required that the design is fairly precise in order to bring the fluid into the cup, this is to highlight that the samples found from the diffusion model with conditional guidance + particle sampling in base distribution are able to precisely pinpoint these types of designs. For the bi-modal task, where we have two possible minima of the cost function, we are able to capture both of the modes with the diffusion model. In the case where we increase the dimensionality of the designs where we have «x, y shift parameters for each of the tool joints, and the tools are disjoint, the diffusion model is able to come up with a parameterization that brings the particles in a desired configuration. However, the resulting designs are not robust and smooth, indicating that further modifications need to be made in form of constraints or regularization while guiding the reverse process to sample from 7 (a). D. Discussion on choice of guidance As we will see in section 3, conditional guidance with corrected base distribution sampling tends to work better than energy guidance. In cases where the gradient of the energy function is expensive to evaluate, an energy-free alternative might be better, however this requires learning a conditional 8 samples samples per task per task A —Gauss —PS Figure 7. Sampling (random search) from p; (a) and particle sampling in the bi-modal environment. We observe that even after increasing the number of samples, particle search further improves performance with same number of samples. model, i.e. necessitates access to conditional samples. E. Energy guidance We have found that using the gradient of the energy function as specified in equation (9) is a viable way of guiding the samples, albeit coming with the caveat of many expensive evaluations, see Figure 8. The guidance is very sensitive to the choice of the scaling factor A, in our experiments we have found that a smaller scaling factor with many integration steps achieves better sample quality. Intuitively, this follows from the fact that it is difficult to guide ‘bad’ samples in the base distribution p;(a), which motivates the particle energy-based sampling scheme introduced in algorithm |. Further, we have looked at how to combine the gradient of the energy with the noised marginal score. We have found that re-scaling to have the same norm as the noised marginal improves the stability of guidance, as shown in Figure 8. Here, we have analyzed multiple functions with which we combined the energy gradient and the noised marginal score, we have looked at the following variants: --- --Diffusion Generative Inverse Design= linear —linear-unit —linear-norm = cvx Figure 8. Performance of energy guidance depending on guidance scale (x axis) for different modifications to score of noised marginal. * linear - simple linear addition of AVE. * linear-unit - linear addition of ATSaT: * cvx - convex combination of VE and eg. ) VElleoll * linear-norm - linear addition of TVET --- --Diffusion Generative Inverse Design Contain Ramp With obstacle Bi-modal Multi-tool Environment size xl Ixl Ixl Ixl Ixl Rollout length 150 150 150 150Initial fluid box(es) left 0.2 0.2 0.45 0.25, 0.65 0.right 0.3 0.3 0.55 0.35, 0.75 0.bottom 0.5 0.5 0.5 0.5 0.top 0.6 0.6 0.6 0.6 0.Reward sampling box left 0.4 0.8 0.2 0.25, 0.65 0.right 0.6 1.0 0.2 0.35, 0.75 0.bottom 0.1 0.0 0.2 0.1 0.top 0.3 0.2 0.2 0.2 0.Reward o 0.1 0.1 0.05 0.1 0.# tools 1 1 1 1# joint angles 16 16 16 16Design parameters | jointangles, joint angles joint angles, joint angles, shift shift (optional) shift shift Tool position (left) [0.15, 0.35] (0.15, 0.35] [0.25, 0.35] (0.3, 0.6] [0.15-0.2, 0.35-0.4] Tool Length 0.8 0.8 0.6 0.4 0.Additional obstacles — — barrier halfway — — between cup and fluid, cup around goal Table 1. Task Parameters.
